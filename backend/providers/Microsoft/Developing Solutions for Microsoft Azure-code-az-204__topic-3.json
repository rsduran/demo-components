[
  {
    "topic": 3,
    "index": 1,
    "url": "https://www.examtopics.com/discussions/microsoft/view/37399-exam-az-204-topic-3-question-1-discussion/",
    "body": "HOTSPOT -<br>You are developing a solution that uses the Azure Storage Client library for .NET. You have the following code: (Line numbers are included for reference only.)<br><img src=\"/assets/media/exam-media/04273/0020500001.jpg\" class=\"in-exam-image\"><br>For each of the following statements, select Yes if the statement is true. Otherwise, select No.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04273/0020600001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04273/0020600002.png\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: Yes -<br>AcquireLeaseAsync does not specify leaseTime.<br>leaseTime is a TimeSpan representing the span of time for which to acquire the lease, which will be rounded down to seconds. If null, an infinite lease will be acquired. If not null, this must be 15 to 60 seconds.<br><br>Box 2: No -<br>The GetBlockBlobReference method just gets a reference to a block blob in this container.<br><br>Box 3: Yes -<br>The BreakLeaseAsync method initiates an asynchronous operation that breaks the current lease on this container.<br>Reference:<br>https://docs.microsoft.com/en-us/dotnet/api/microsoft.azure.storage.blob.cloudblobcontainer.acquireleaseasync https://docs.microsoft.com/en-us/dotnet/api/microsoft.azure.storage.blob.cloudblobcontainer.getblockblobreference https://docs.microsoft.com/en-us/dotnet/api/microsoft.azure.storage.blob.cloudblobcontainer.breakleaseasync",
    "votes": [],
    "comments": [
      {
        "date": "2020-12-13T07:05:00.000Z",
        "voteCount": 46,
        "content": "I think the answer is correct:\n\nOptional. Version 2012-02-12 and newer. For a break operation, this is the proposed duration of seconds that the lease should continue before it is broken, between 0 and 60 seconds. This break period is only used if it is shorter than the time remaining on the lease. If longer, the time remaining on the lease is used. A new lease will not be available before the break period has expired, but the lease may be held for longer than the break period. If this header does not appear with a break operation, a fixed-duration lease breaks after the remaining lease period elapses, and an infinite lease breaks immediately.\nFrom: https://docs.microsoft.com/en-us/rest/api/storageservices/lease-blob"
      },
      {
        "date": "2021-06-20T05:18:00.000Z",
        "voteCount": 3,
        "content": "It talks about the header values only ReleaseLeaseasync release lease"
      },
      {
        "date": "2021-05-15T14:22:00.000Z",
        "voteCount": 4,
        "content": "Last few words \"infinite lease breaks immediately\" is the key for this context."
      },
      {
        "date": "2020-11-20T07:26:00.000Z",
        "voteCount": 24,
        "content": "I think Box 3 should be no insetad of yes. BreakRelease don`t release the lease directly. \n\nYou use ReleaseLease to do this:\nhttps://docs.microsoft.com/en-us/dotnet/api/microsoft.azure.storage.blob.cloudblobcontainer.releaselease?view=azure-dotnet-legacy"
      },
      {
        "date": "2020-11-26T07:16:00.000Z",
        "voteCount": 4,
        "content": "Ah I think modele is right:\nBreakLeaseAsync (TimeSpan? breakPeriod)\n\nbreakPeriod\nNullable&lt;TimeSpan&gt;\nA TimeSpan representing the amount of time to allow the lease to remain, which will be rounded down to seconds. If null, the break period is the remainder of the current lease, or zero for infinite leases."
      },
      {
        "date": "2022-11-04T15:53:00.000Z",
        "voteCount": 1,
        "content": "ya!!! an infinite lease breaks immediately"
      },
      {
        "date": "2024-09-14T15:44:00.000Z",
        "voteCount": 3,
        "content": "The code creates an infinite lease:\nThe AcquireLeaseAsync method is called with null as the parameter, which does not create an infinite lease. To create an infinite lease, it should be called with -1.\nAnswer: No\nThe code at line 06 always creates a new blob:\nLine 06 (var dst = container.GetBlockBlobReference(src.Name);) gets a reference to an existing blob with the same name as src. It does not create a new blob but rather references an existing one.\nAnswer: No\nThe finally block releases the lease:\nThe finally block contains await src.BreakLeaseAsync(new TimeSpan(0));, which releases the lease on the blob.\nAnswer: Yes\nThanks for pointing that out! Is there anything else you\u2019d like to discuss or clarify?"
      },
      {
        "date": "2024-08-29T15:17:00.000Z",
        "voteCount": 1,
        "content": "Lease Duration:\nNo, the code does not create an infinite lease. The lease acquired at line 5 (await src.AcquireLeaseAsync(null)) does not specify a duration (the null argument). By default, this results in a finite lease.\nIf you want to create an infinite lease, you can provide a non-null TimeSpan argument to AcquireLeaseAsync, specifying the desired lease duration.\nCreating a New Blob:\nNo, the code at line 6 (var dst = container.GetBlockBlobReference(src.Name);) does not always create a new blob. Instead, it creates a new CloudBlockBlob reference named dst that points to the same blob as src.\nEssentially, dst refers to the blob with the same name as src.\nReleasing the Lease:\nYes, the final code ensures that the lease is released.\nIn the finally block (lines 15-25), it checks if src is not null:\nFetches attributes of src.\nIf the lease state of src is not available (meaning it\u2019s still leased), it breaks the lease using src.BreakLeaseAsync(new TimeSpan(0))."
      },
      {
        "date": "2024-08-12T09:23:00.000Z",
        "voteCount": 1,
        "content": "Finally block doesn't release the lease. Is nobody else able to see the if above the BreakLeaseAsync?"
      },
      {
        "date": "2024-08-12T09:35:00.000Z",
        "voteCount": 1,
        "content": "Sorry, take it back. LeaseState.Available means not LeaseState.Leased, so not Available means Leased, and so the lease can be broken."
      },
      {
        "date": "2024-03-20T11:14:00.000Z",
        "voteCount": 1,
        "content": "Answer is Correct.\nBlobLease.BreakLeaseAsync:\nIf the break period is not specified, the default value is 0 (immediate break)."
      },
      {
        "date": "2023-12-23T15:10:00.000Z",
        "voteCount": 2,
        "content": "I think the answer is correct"
      },
      {
        "date": "2023-09-05T12:23:00.000Z",
        "voteCount": 2,
        "content": "So, when you provide a TimeSpan value of 0, it essentially means \"break the lease right now without any delay.\" This behavior aligns with the statement you provided: \"If null, the break period is the remainder of the current lease, or zero for infinite leases.\" When you explicitly set it to 0, it ensures an immediate lease termination. It is a matter of knowing the English Language."
      },
      {
        "date": "2023-07-12T11:29:00.000Z",
        "voteCount": 1,
        "content": "to break the lease it will have to enter in the if block ..and since the lease \u00a1state will be always be available since it is infinite ...it will never enter that block...so the answer is no"
      },
      {
        "date": "2023-01-12T05:38:00.000Z",
        "voteCount": 1,
        "content": "Yes, No, Yes"
      },
      {
        "date": "2023-01-12T05:39:00.000Z",
        "voteCount": 2,
        "content": "AcquireLease(null)--&gt;Creates infinite lease"
      },
      {
        "date": "2023-01-12T05:44:00.000Z",
        "voteCount": 1,
        "content": "AcquireLease(-1) will also create infinite lease"
      },
      {
        "date": "2022-10-04T02:21:00.000Z",
        "voteCount": 1,
        "content": "version 11 is legacy. \nSimilar code for version 12 see \nhttps://learn.microsoft.com/en-us/azure/storage/blobs/storage-blob-copy?tabs=dotnet"
      },
      {
        "date": "2022-10-04T01:18:00.000Z",
        "voteCount": 2,
        "content": "This is Microsoft.Azure.Storage.Blob v11.1.0 code, it is a legacy library. Did anyone got this on the exam recently?"
      },
      {
        "date": "2022-09-06T07:28:00.000Z",
        "voteCount": 3,
        "content": "i'm looking for an explanation on what a \"lease\" is, or what is intended by it, and cannot find any explanatory resource. Does anyone have a reference to it ?"
      },
      {
        "date": "2022-09-06T23:54:00.000Z",
        "voteCount": 4,
        "content": "https://www.c-sharpcorner.com/article/implementing-blob-leasing-understanding-blob-storage-part-9/\n\nThe Lease Blob operation establishes and manages a lock on a blob for write and delete operations. The lock duration can be 15 to 60 seconds or it can be infinite. Once you have the lease, you can update the Blob or delete the Blob without worrying about another process changing it underneath you. When a Blob is leased, other processes can still read it but any attempt to update it will fail. You can also update Blobs without taking a lease first, but you do run the chance of another process also attempting to modify it at the same time."
      },
      {
        "date": "2022-08-25T04:57:00.000Z",
        "voteCount": 3,
        "content": "Correct answer:\nYES\nNO\nYES"
      },
      {
        "date": "2022-08-17T06:55:00.000Z",
        "voteCount": 4,
        "content": "If the finally code releases the lease, then 1st is wrong. The code doesn't create an infinite lease. Answer is NO."
      },
      {
        "date": "2023-11-28T04:53:00.000Z",
        "voteCount": 1,
        "content": "I agree. It's a bit silly to create a lease and then removing it, but that is in my opinion what is happing here. Why do people agree that the first one should be YES?"
      },
      {
        "date": "2022-03-26T23:16:00.000Z",
        "voteCount": 15,
        "content": "Tried to execute the code sample:\n1) If acquires lease on the blob with null parameter, means the infinite lease is acquired [1]\n2) On line 6 it gets reference to existing source blob, so no new blob is created there\n3) It fails on start copy operation, because it tries to copy onto itself and the lease is already acquired\n4) Goes to catch and then finally block\n5) In finally breaks the lease with (Zero) parameter that means the immediate lease break [2]\n\n[1] https://docs.microsoft.com/en-us/dotnet/api/microsoft.azure.storage.blob.cloudblobcontainer.acquireleaseasync?view=azure-dotnet-legacy#microsoft-azure-storage-blob-cloudblobcontainer-acquireleaseasync(system-nullable((system-timespan))-system-string)\n[2] https://docs.microsoft.com/en-us/dotnet/api/microsoft.azure.storage.blob.cloudblobcontainer.breakleaseasync?view=azure-dotnet-legacy#microsoft-azure-storage-blob-cloudblobcontainer-breakleaseasync(system-nullable((system-timespan)))"
      },
      {
        "date": "2022-02-26T14:37:00.000Z",
        "voteCount": 2,
        "content": "Answer to the third statement is 'Yes'.\nBreakLeaseAsync(mew TimsSpan(0)) will break/release an infinite lease (which is true in this scenario).\nSource: https://docs.microsoft.com/en-us/dotnet/api/microsoft.azure.storage.blob.cloudblobcontainer.breakleaseasync?view=azure-dotnet-legacy"
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 2,
    "url": "https://www.examtopics.com/discussions/microsoft/view/37262-exam-az-204-topic-3-question-2-discussion/",
    "body": "You are building a website that uses Azure Blob storage for data storage. You configure Azure Blob storage lifecycle to move all blobs to the archive tier after 30 days.<br>Customers have requested a service-level agreement (SLA) for viewing data older than 30 days.<br>You need to document the minimum SLA for data recovery.<br>Which SLA should you use?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tat least two days",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tbetween one and 15 hours\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tat least one day",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tbetween zero and 60 minutes"
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 10,
        "isMostVoted": true
      },
      {
        "answer": "A",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2020-11-18T15:29:00.000Z",
        "voteCount": 44,
        "content": "Answer is correct"
      },
      {
        "date": "2023-04-17T03:44:00.000Z",
        "voteCount": 4,
        "content": "received 2023-04-17 went given answer, score 926"
      },
      {
        "date": "2024-01-02T05:04:00.000Z",
        "voteCount": 1,
        "content": "Got this today.\nWent with answer here.\nScore 927"
      },
      {
        "date": "2021-05-23T06:55:00.000Z",
        "voteCount": 25,
        "content": "Correct Answer: B\n\n-\tStandard priority: The rehydration request will be processed in the order it was received and may take up to 15 hours.\n-\tHigh priority: The rehydration request will be prioritized over Standard requests and may finish in under 1 hour for objects under ten GB in size.\n\nReference:\n\nhttps://docs.microsoft.com/en-us/azure/storage/blobs/storage-blob-storage-tiers?tabs=azure-portal#archive-access-tier\n\nhttps://docs.microsoft.com/en-us/azure/storage/blobs/storage-blob-rehydration?tabs=azure-portal"
      },
      {
        "date": "2024-08-21T21:13:00.000Z",
        "voteCount": 1,
        "content": "Retrieving from the Archive tier takes 12 to 48 hours"
      },
      {
        "date": "2024-01-09T04:55:00.000Z",
        "voteCount": 1,
        "content": "The SLA for data recovery from the archive tier in Azure Blob storage is indeed between zero and 60 minutes. Option B (\"between one and 15 hours\") is not accurate in the context of Azure Blob storage archive tier recovery. The correct answer should be:\n\nD. between zero and 60 minutes"
      },
      {
        "date": "2023-06-29T06:38:00.000Z",
        "voteCount": 1,
        "content": "Got this on 6/28/2023 and passed with 850.  Went with answer."
      },
      {
        "date": "2023-05-12T12:07:00.000Z",
        "voteCount": 1,
        "content": "Got this 2023-05-12.\nEasy one.\nMy case:\ncase: You need to configure authorization.\ncase: You need to ensure the app does not time out and processes the blob data\ncase study: VanArsdel Inc Canada"
      },
      {
        "date": "2023-11-30T03:22:00.000Z",
        "voteCount": 2,
        "content": "These are some random bot anwers."
      },
      {
        "date": "2023-03-30T01:32:00.000Z",
        "voteCount": 1,
        "content": "Question was in Exam 2023-03-30"
      },
      {
        "date": "2023-03-19T13:01:00.000Z",
        "voteCount": 2,
        "content": "Got this question in the exam on 16/03/2023. Went with proposed solution. Make sure to prepare for case studies. I got city and lights case study."
      },
      {
        "date": "2022-11-19T03:19:00.000Z",
        "voteCount": 1,
        "content": "B. between one and 15 hour"
      },
      {
        "date": "2022-11-14T08:23:00.000Z",
        "voteCount": 1,
        "content": "Correct Answer: B,"
      },
      {
        "date": "2022-08-25T04:59:00.000Z",
        "voteCount": 4,
        "content": "This question is sooo open for interpretation: \"For small objects, a high priority rehydrate may retrieve the object from archive in under 1 hour.\". \n\nWhere is this 15 hours coming from?"
      },
      {
        "date": "2022-07-18T02:48:00.000Z",
        "voteCount": 2,
        "content": "B - Because it takes between one and 15 hours to recover data from the archive tier."
      },
      {
        "date": "2022-06-09T07:16:00.000Z",
        "voteCount": 2,
        "content": "B is correct answer.\nGen 1 storage used to be up to 24 hours, now gen 2 is up to 15 hours. \n\nhttps://docs.microsoft.com/en-us/azure/storage/blobs/archive-rehydrate-overview#rehydration-priority"
      },
      {
        "date": "2022-03-12T20:33:00.000Z",
        "voteCount": 1,
        "content": "Got it on 03/2022, I chose B. between one and 15 hours"
      },
      {
        "date": "2022-01-28T06:43:00.000Z",
        "voteCount": 1,
        "content": "Correct Answer is between 1-15 hours"
      },
      {
        "date": "2022-01-19T10:05:00.000Z",
        "voteCount": 1,
        "content": "Answer is correct"
      },
      {
        "date": "2021-11-21T14:35:00.000Z",
        "voteCount": 1,
        "content": "The answer is correct.  Per the provided reference URL https://docs.microsoft.com/en-us/azure/storage/blobs/access-tiers-overview?tabs=azure-portal\n\nArchive tier-An offline tier optimized for storing data that is rarely accessed, and that has flexible latency requirements, on the order of hours.  Data in the Archive tier should be stored for a minium of 108 days."
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 3,
    "url": "https://www.examtopics.com/discussions/microsoft/view/36534-exam-az-204-topic-3-question-3-discussion/",
    "body": "HOTSPOT -<br>You are developing a ticket reservation system for an airline.<br>The storage solution for the application must meet the following requirements:<br>\u2711 Ensure at least 99.99% availability and provide low latency.<br>\u2711 Accept reservations even when localized network outages or other unforeseen failures occur.<br>\u2711 Process reservations in the exact sequence as reservations are submitted to minimize overbooking or selling the same seat to multiple travelers.<br>\u2711 Allow simultaneous and out-of-order reservations with a maximum five-second tolerance window.<br>You provision a resource group named airlineResourceGroup in the Azure South-Central US region.<br>You need to provision a SQL API Cosmos DB account to support the app.<br>How should you complete the Azure CLI commands? To answer, select the appropriate options in the answer area.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04273/0020900001.jpg\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04273/0021100001.jpg\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: BoundedStaleness -<br>Bounded staleness: The reads are guaranteed to honor the consistent-prefix guarantee. The reads might lag behind writes by at most \"K\" versions (that is,<br>\"updates\") of an item or by \"T\" time interval. In other words, when you choose bounded staleness, the \"staleness\" can be configured in two ways:<br>The number of versions (K) of the item<br>The time interval (T) by which the reads might lag behind the writes<br>Incorrect Answers:<br><br>Strong -<br>Strong consistency offers a linearizability guarantee. Linearizability refers to serving requests concurrently. The reads are guaranteed to return the most recent committed version of an item. A client never sees an uncommitted or partial write. Users are always guaranteed to read the latest committed write.<br>Box 2: --enable-automatic-failover true\\<br>For multi-region Cosmos accounts that are configured with a single-write region, enable automatic-failover by using Azure CLI or Azure portal. After you enable automatic failover, whenever there is a regional disaster, Cosmos DB will automatically failover your account.<br>Question: Accept reservations event when localized network outages or other unforeseen failures occur.<br>Box 3: --locations'southcentralus=0 eastus=1 westus=2<br>Need multi-region.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/cosmos-db/consistency-levels https://github.com/MicrosoftDocs/azure-docs/blob/master/articles/cosmos-db/manage-with-cli.md",
    "votes": [],
    "comments": [
      {
        "date": "2020-11-26T14:10:00.000Z",
        "voteCount": 71,
        "content": "Answer is correct."
      },
      {
        "date": "2021-02-13T18:44:00.000Z",
        "voteCount": 7,
        "content": "Last option is correct as well\nhttps://stackoverflow.com/questions/51197375/creating-cosmosdb-with-azure-cli-in-powershell"
      },
      {
        "date": "2021-02-13T18:46:00.000Z",
        "voteCount": 5,
        "content": "I guess there is a typo on quotes though."
      },
      {
        "date": "2021-08-03T04:10:00.000Z",
        "voteCount": 61,
        "content": "No need to overthink here, max-interval, indicates this must be bounded-slateness, enable-automatic-failover, indicated this must be multi-region"
      },
      {
        "date": "2022-12-09T06:13:00.000Z",
        "voteCount": 2,
        "content": "this is best explanation"
      },
      {
        "date": "2024-03-13T05:20:00.000Z",
        "voteCount": 3,
        "content": "Confused how most of the people here scored same score - 927.\nI see 927 everywhere."
      },
      {
        "date": "2024-08-12T23:08:00.000Z",
        "voteCount": 1,
        "content": "Bots, buddy. They're bots."
      },
      {
        "date": "2023-08-17T05:10:00.000Z",
        "voteCount": 3,
        "content": "It's important to carefully read the entire question."
      },
      {
        "date": "2023-07-25T02:05:00.000Z",
        "voteCount": 1,
        "content": "I think that enable-automatic-failover = true option does not make any sense without other regions specified but given syntax for regions and priorities is wrong and does not work"
      },
      {
        "date": "2023-04-17T17:28:00.000Z",
        "voteCount": 2,
        "content": "I think ans should be using chat gpt:\n1.  Eventual : maintain high availability and low latency\n2.  enable-automatic-failover = true\n3.  locations \"South Central US\"=0 : This is primary region"
      },
      {
        "date": "2023-07-02T03:47:00.000Z",
        "voteCount": 9,
        "content": "Eventual is definitely not correct"
      },
      {
        "date": "2023-03-08T01:22:00.000Z",
        "voteCount": 2,
        "content": "BoundedStaleness doesn't guarantee the order of the order, that's session consistency. Where am I wrong?"
      },
      {
        "date": "2023-02-13T06:00:00.000Z",
        "voteCount": 5,
        "content": "It was there in 13 Feb 2023 exam"
      },
      {
        "date": "2022-12-07T09:06:00.000Z",
        "voteCount": 2,
        "content": "got this on 2022-12-7"
      },
      {
        "date": "2022-03-16T10:43:00.000Z",
        "voteCount": 3,
        "content": "esse aqui ta tudo errado"
      },
      {
        "date": "2021-05-14T00:20:00.000Z",
        "voteCount": 2,
        "content": "correct"
      },
      {
        "date": "2021-04-27T06:06:00.000Z",
        "voteCount": 11,
        "content": "The strong consistency doesn't work here:\n1) there is a --max-interval property which is being used with bounded staleness only\n2) there is a requirement \"Accept reservations event when localized network outages or other unforeseen failures occur.\" which points us to multiple writes for multiple regions which is not being supported by the Strong consistency.\n--locations syntax looks like obsolete as for late march 2021"
      },
      {
        "date": "2021-05-17T13:25:00.000Z",
        "voteCount": 3,
        "content": "Ad. 2 - it is not true that it implies writes to multiple regions. In this case there is single write region with automatic failover configured (which provides write availability). Besides with write to multiple regions BoundedStaleness minimum time is 300 seconds, while requirement is 5 seconds (which is actually a minimum for BoundedStaleness with single write region)"
      },
      {
        "date": "2021-04-21T09:00:00.000Z",
        "voteCount": 4,
        "content": "Answer is wrong .. \"strong\" instead of \"boundedStaleness\""
      },
      {
        "date": "2021-05-15T03:56:00.000Z",
        "voteCount": 7,
        "content": "Are you sure? If then, elaborate why. Does this option --max-interval work for strong?"
      },
      {
        "date": "2021-01-10T09:13:00.000Z",
        "voteCount": 3,
        "content": "I think this should be \"locations southcentralus\". The requirement for 99.99% availability is covered by a single region and the syntax for providing multiple regions is wrong.\nhttps://docs.microsoft.com/en-us/azure/cosmos-db/high-availability\nhttps://docs.microsoft.com/en-us/cli/azure/cosmosdb?view=azure-cli-latest#az_cosmosdb_check_name_exists-optional-parameters"
      },
      {
        "date": "2021-01-14T19:34:00.000Z",
        "voteCount": 3,
        "content": "I agree with you.... 99,99 can be reached with only one region.\nWhy it's not the right solution (someone can helps please) ?"
      },
      {
        "date": "2021-01-27T21:00:00.000Z",
        "voteCount": 5,
        "content": "Because of the need for high availability during local network outages. Hence the auto failover selection."
      },
      {
        "date": "2021-02-27T14:00:00.000Z",
        "voteCount": 2,
        "content": "Agreed, also according to the documentation, multiple regions have a min T of 300s:\n\"For a single region account, the minimum value of K and T is 10 write operations or 5 seconds. For multi-region accounts the minimum value of K and T is 100,000 write operations or 300 seconds.\""
      },
      {
        "date": "2021-01-09T06:55:00.000Z",
        "voteCount": 4,
        "content": "Given Answer is Correct"
      },
      {
        "date": "2021-01-05T05:21:00.000Z",
        "voteCount": 8,
        "content": "--locations                               : Add a location to the Cosmos DB database account.\n        Usage:          --locations KEY=VALUE [KEY=VALUE ...]\n        Required Keys:  regionName, failoverPriority\n        Optional Key:   isZoneRedundant\n        Default:        single region account in the location of the specified resource group.\n        Failover priority values are 0 for write regions and greater than 0 for read regions. A\n        failover priority value must be unique and less than the total number of regions.\n        Multiple locations can be specified by using more than one `--locations` argument."
      },
      {
        "date": "2021-01-10T09:29:00.000Z",
        "voteCount": 4,
        "content": "You are correct about this - none of the given options will work (all wrong syntax).\nBut I think they \"meant\" to use the 3 regions answer."
      },
      {
        "date": "2020-12-22T18:02:00.000Z",
        "voteCount": 2,
        "content": "Tried the CLI in the portal's Cloud Shell:\n--locations has wrong syntax in the options.\naz cosmosdb create -n myaccount4 --enable-automatic-failover true --max-interval 5 -g myRG --locations regionname=eastus --default-consistency-level=BoundedStaleness\n\n--locations needs regionname. Because it also takes in failoverPriority and isZoneRedundant params.\n\nSo either the option with just the SouthCentralUS should work or if the rest of the regions need to be mentioned, then it's a deprecated syntax which makes no sense to answer now."
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 4,
    "url": "https://www.examtopics.com/discussions/microsoft/view/48852-exam-az-204-topic-3-question-4-discussion/",
    "body": "HOTSPOT -<br>You are preparing to deploy a Python website to an Azure Web App using a container. The solution will use multiple containers in the same container group. The<br>Dockerfile that builds the container is as follows:<br><img src=\"/assets/media/exam-media/04273/0021300001.png\" class=\"in-exam-image\"><br>You build a container by using the following command. The Azure Container Registry instance named images is a private registry.<br><img src=\"/assets/media/exam-media/04273/0021300002.png\" class=\"in-exam-image\"><br>The user name and password for the registry is admin.<br>The Web App must always run the same version of the website regardless of future builds.<br>You need to create an Azure Web App to run the website.<br>How should you complete the commands? To answer, select the appropriate options in the answer area.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04273/0021400001.jpg\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04273/0021500001.jpg\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: --SKU B1 --hyper-v -<br>--hyper-v<br>Host web app on Windows container.<br>Box 2: --deployment-source-url images.azurecr.io/website:v1.0.0<br>--deployment-source-url -u<br>Git repository URL to link with manual integration.<br>The Web App must always run the same version of the website regardless of future builds.<br>Incorrect:<br>--deployment-container-image-name -i<br>Linux only. Container image name from Docker Hub, e.g. publisher/image-name:tag.<br>Box 3: az webapp config container set -url https://images.azurecr.io -u admin -p admin az webapp config container set<br>Set a web app container's settings.<br>Paremeter: --docker-registry-server-url -r<br>The container registry server url.<br>The Azure Container Registry instance named images is a private registry.<br>Example:<br>az webapp config container set --docker-registry-server-url https://{azure-container-registry-name}.azurecr.io<br>Reference:<br>https://docs.microsoft.com/en-us/cli/azure/appservice/plan",
    "votes": [],
    "comments": [
      {
        "date": "2021-05-14T00:39:00.000Z",
        "voteCount": 154,
        "content": "--sku B1 --is-linux\n--deployment-container-image-name images.azurecr.io/website:v1.0.0\n-- container set --docker-registry-server-url https://images.azurecr.io -u admin -p admin"
      },
      {
        "date": "2023-07-30T07:16:00.000Z",
        "voteCount": 4,
        "content": "got this question today, go with this answer - 7/30/2023, score 895/1000"
      },
      {
        "date": "2023-01-12T22:01:00.000Z",
        "voteCount": 2,
        "content": "https://www.linkedin.com/pulse/how-quickly-create-micro-service-azure-webapp-fastapi-bonnet-?trk=pulse-article_more-articles_related-content-card"
      },
      {
        "date": "2021-04-05T00:12:00.000Z",
        "voteCount": 44,
        "content": "\"use multiple containers in the same container group\" this not is possible in windows. \nSolution is:\n--is-linux\n--deployment-container-image-name"
      },
      {
        "date": "2021-06-19T12:10:00.000Z",
        "voteCount": 5,
        "content": "True! also last response is correct with \n-- container set --docker-registry-server-url https://images.azurecr.io -u admin -p admin"
      },
      {
        "date": "2021-04-07T11:02:00.000Z",
        "voteCount": 11,
        "content": "That's true.\n\"Multi-container groups are currently restricted to Linux containers.\"\nhttps://docs.microsoft.com/en-us/azure/container-instances/container-instances-multi-container-group"
      },
      {
        "date": "2024-05-18T02:47:00.000Z",
        "voteCount": 6,
        "content": "Box 1 \u2013 --sku B1 --is-linux. You need an application service plan that supports Linux because your Docker container is based on Linux images (python:3). SKU B1 is the basic level and can run on Linux, which should suit your requirements.\nBox 2 \u2013 --deployment-container-image-name images.azurecr.io/website:v1.0.0. You need to specify a specific container image name to ensure that the Web App always runs the same version of the website. Using the v1.0.0 tag ensures that this version will not change when new builds are released.\nBox 3 \u2013 -- container set --docker-registry-server-url https://images.azurecr.io -u admin -p admin. You need to configure Docker registry credentials so that Web App can pull images from the Azure Container Registry. This selection provides the correct URL of the registry and the admin login information you provided."
      },
      {
        "date": "2024-04-28T00:46:00.000Z",
        "voteCount": 1,
        "content": "Got it on 20 April 2024...Marks &gt; 900...answer is correct....all questions from examtopics 400 question bank\nAnswer is correct"
      },
      {
        "date": "2024-01-10T00:10:00.000Z",
        "voteCount": 2,
        "content": "This question was on exam. 09/01/2024. Passed 872."
      },
      {
        "date": "2023-09-25T09:19:00.000Z",
        "voteCount": 1,
        "content": "Got this quesiton in examn, went with answer. - 2023.09.25. Got Case Study Contoso"
      },
      {
        "date": "2023-07-25T20:32:00.000Z",
        "voteCount": 1,
        "content": "Had this question today: 2023-07-26"
      },
      {
        "date": "2023-04-15T10:22:00.000Z",
        "voteCount": 9,
        "content": "microsoft promote good practises for -u and -p ( \u0361\u00b0 \u035c\u0296 \u0361\u00b0)"
      },
      {
        "date": "2023-04-04T20:58:00.000Z",
        "voteCount": 5,
        "content": "Got this in exam today (5 April 2023)"
      },
      {
        "date": "2023-02-21T16:12:00.000Z",
        "voteCount": 5,
        "content": "Received this in my exam today (22/02/2023). Selected linux, --deployment-container...:v1.0.0, and container set ... in --u admin --p admin. Score 927."
      },
      {
        "date": "2023-02-13T06:00:00.000Z",
        "voteCount": 4,
        "content": "It was there in 13 Feb 2023 exam"
      },
      {
        "date": "2023-01-03T16:10:00.000Z",
        "voteCount": 1,
        "content": "this answer are not wrong, if you must know, these question and answer are giving by microsoft , so how can it be wrong if microsoft support those answer?"
      },
      {
        "date": "2023-02-14T23:08:00.000Z",
        "voteCount": 5,
        "content": "The answers are not provided by Microsoft but by the community/Examtopics, sometimes given answers are wrong. But the discussions are great to help you with that! In this case I believe the highest voted answers are correct (from aperez1979)."
      },
      {
        "date": "2022-07-02T01:38:00.000Z",
        "voteCount": 3,
        "content": "Linux for multiple containers"
      },
      {
        "date": "2022-07-01T02:38:00.000Z",
        "voteCount": 6,
        "content": "Another wrong answer - this site riddled with wrong answers"
      },
      {
        "date": "2022-06-09T07:32:00.000Z",
        "voteCount": 4,
        "content": "--sku B1 --is-linux\n--deployment-container-image-name images.azurecr.io/website:v1.0.0\n-- container set --docker-registry-server-url https://images.azurecr.io -u admin -p admin"
      },
      {
        "date": "2021-12-29T04:22:00.000Z",
        "voteCount": 6,
        "content": "The suggested answer is for Windows, but Python is deprecated for Windows, as well as multiple containers are not possible in Windows.\nSo it must be Linux, and based on this article https://docs.microsoft.com/en-us/azure/app-service/tutorial-custom-container?pivots=container-linux\nthe answer must be:\n1. --sku B1 --is-linux\n2. --deployment-container-image-name ... :v1.0.0\n3. container set ...  https://images.azurecr.io ..."
      },
      {
        "date": "2021-12-24T00:17:00.000Z",
        "voteCount": 4,
        "content": "for answer 3: Can somebody tell me why its images.azurecr.io and not images.azurecr.io/website?"
      },
      {
        "date": "2022-01-23T18:53:00.000Z",
        "voteCount": 9,
        "content": "The command requires the URL of the registry, not the image name.  That is appended later.\n\"--docker-registry-server-url \nThe container registry server url.\""
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 5,
    "url": "https://www.examtopics.com/discussions/microsoft/view/47173-exam-az-204-topic-3-question-5-discussion/",
    "body": "HOTSPOT -<br>You are developing a back-end Azure App Service that scales based on the number of messages contained in a Service Bus queue.<br>A rule already exists to scale up the App Service when the average queue length of unprocessed and valid queue messages is greater than 1000.<br>You need to add a new rule that will continuously scale down the App Service as long as the scale up condition is not met.<br>How should you configure the Scale rule? To answer, select the appropriate options in the answer area.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04273/0021700001.jpg\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04273/0021900001.jpg\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: Service bus queue -<br>You are developing a back-end Azure App Service that scales based on the number of messages contained in a Service Bus queue.<br><br>Box 2: ActiveMessage Count -<br>ActiveMessageCount: Messages in the queue or subscription that are in the active state and ready for delivery.<br><br>Box 3: Count -<br><br>Box 4: Less than or equal to -<br>You need to add a new rule that will continuously scale down the App Service as long as the scale up condition is not met.<br>Box 5: Decrease count by",
    "votes": [],
    "comments": [
      {
        "date": "2021-04-23T22:31:00.000Z",
        "voteCount": 126,
        "content": "The correct answers are \n1) Service bus queue\n2) Active message count\n3) Average\n4) Less than or equal to \n5) Decrease count by"
      },
      {
        "date": "2023-07-30T07:17:00.000Z",
        "voteCount": 2,
        "content": "got this question today, go with this answer - 7/30/2023, score 895/1000"
      },
      {
        "date": "2021-06-19T12:14:00.000Z",
        "voteCount": 42,
        "content": "this is correct (the \"official\" solution is wrong)\nAlso check the proper image https://vceguide.com/wp-content/uploads/2019/10/Microsoft-AZ-203-date-01-06-2019-00001_Page_062_Image_0001.jpg"
      },
      {
        "date": "2022-04-29T09:49:00.000Z",
        "voteCount": 1,
        "content": "How often are the responses scrubbed for updates/corrections?"
      },
      {
        "date": "2022-11-11T10:02:00.000Z",
        "voteCount": 7,
        "content": "I think the #4 is should be \"Less than\" only, because you don't want to trigger the Scale up and Scale down at the same time."
      },
      {
        "date": "2022-11-11T10:05:00.000Z",
        "voteCount": 1,
        "content": "Here is a reference why I think it should be Less than,\nhttps://learn.microsoft.com/en-us/training/modules/scale-apps-app-service/5-autoscale-best-practices?ns-enrollment-type=learningpath&amp;ns-enrollment-id=learn.wwl.create-azure-app-service-web-apps"
      },
      {
        "date": "2023-01-23T09:44:00.000Z",
        "voteCount": 4,
        "content": "I won't trigger at same time as question says \"average queue length of unprocessed and valid queue messages is greater than 1000\""
      },
      {
        "date": "2021-05-23T12:48:00.000Z",
        "voteCount": 79,
        "content": "Full image: https://vceguide.com/wp-content/uploads/2019/10/Microsoft-AZ-203-date-01-06-2019-00001_Page_062_Image_0001.jpg"
      },
      {
        "date": "2021-06-01T20:28:00.000Z",
        "voteCount": 12,
        "content": "You are providing invaluable help, by clarifying the questions,"
      },
      {
        "date": "2021-05-23T12:53:00.000Z",
        "voteCount": 38,
        "content": "Box 1: Service bus queue\nYou are developing a back-end Azure App Service that scales based on the number of messages contained in a Service Bus queue.\n\nBox 2: ActiveMessage Count\nActiveMessageCount: Number of messages in the queue or subscription that are in the active state and ready for delivery.\n\nBox 3: Average\nFor special metrics such as Storage or Service Bus Queue length metric, the threshold is the average number of messages available per current number of instances.\n\nBox 4: Less than or equal to\nYou need to add a new rule that will continuously scale down the App Service, as long as the scale up condition is not met.\n\nBox 5: Decrease count by"
      },
      {
        "date": "2021-05-23T12:53:00.000Z",
        "voteCount": 9,
        "content": "Reference:\n\nhttps://docs.microsoft.com/en-us/azure/azure-monitor/autoscale/autoscale-best-practices#considerations-for-scaling-threshold-values-for-special-metrics\n\nhttps://docs.microsoft.com/en-us/azure/service-bus-messaging/message-counters"
      },
      {
        "date": "2023-02-23T21:15:00.000Z",
        "voteCount": 1,
        "content": "https://learn.microsoft.com/en-us/azure/azure-monitor/autoscale/autoscale-best-practices#considerations-for-scaling-when-multiple-rules-are-configured-in-a-profile\npoints Less than"
      },
      {
        "date": "2024-04-28T00:48:00.000Z",
        "voteCount": 1,
        "content": "Got it on 20 April 2024...Marks &gt; 900...All questions from examtopics 400 questions...\nanswer is correct...\nThe correct answers are\n1) Service bus queue\n2) Active message count\n3) Average\n4) Less than or equal to\n5) Decrease count by"
      },
      {
        "date": "2023-07-25T20:32:00.000Z",
        "voteCount": 2,
        "content": "Had this question today: 2023-07-26"
      },
      {
        "date": "2023-01-10T11:55:00.000Z",
        "voteCount": 3,
        "content": "Got this on my exam, January 10, 2023 (I passed)\nMy answer: \nBox 1: Service bus queue\nBox 2: Active Message Count\nBox 3: Average\nBox 4: Less than or equal to\nBox 5: Decrease count by"
      },
      {
        "date": "2022-12-30T21:16:00.000Z",
        "voteCount": 1,
        "content": "In 28-12-2022 exam, Answers.\nService Bus queue\nactive message count\ncount\nless than equal to\ndecrease count"
      },
      {
        "date": "2022-11-11T20:25:00.000Z",
        "voteCount": 2,
        "content": "Got it on 10/2022, I chose as below:\nBox 1: Service bus queue\nBox 2: Active Message Count\nBox 3: Average\nBox 4: Less than or equal to\nBox 5: Decrease count by"
      },
      {
        "date": "2022-09-26T09:35:00.000Z",
        "voteCount": 4,
        "content": "Admin, Request to please update the full image. Current image is cut and options 4 and 5 are not visible"
      },
      {
        "date": "2022-03-12T20:39:00.000Z",
        "voteCount": 3,
        "content": "Got it on 03/2022, I chose as below:\nBox 1: Service bus queue\nBox 2: ActiveMessage Count\nBox 3: Average\nBox 4: Less than or equal to\nBox 5: Decrease count by"
      },
      {
        "date": "2021-07-27T06:10:00.000Z",
        "voteCount": 2,
        "content": "Just a question but how are you going to reduce the count if there is now count to reduce?"
      },
      {
        "date": "2021-05-14T00:45:00.000Z",
        "voteCount": 4,
        "content": "The correct answers are\n1) Service bus queue\n2) Active message count\n3) Average\n4) Less than or equal to\n5) Decrease count by"
      },
      {
        "date": "2021-03-21T15:51:00.000Z",
        "voteCount": 15,
        "content": "I believe the answers are:\n1st box: as given, since we're analyzing the state of messages in the Service Bus Queue\n2nd box: as given, because Active Message Count will show us just the count of messages that are in the active state and ready for delivery, while Message Count would show us all the messages.\n3rd box: Average, since we should stay consistent with the Scale Up time grain, which is also \"Average\" - this way, when we use \"average\" on both, we have consistent and clear conditions when to go up and when to go down"
      },
      {
        "date": "2021-03-21T04:01:00.000Z",
        "voteCount": 6,
        "content": "I think the 3rd option should be \"Average\" since the scale up rule is based off average, it makes sense to make the scale down rule work on the same principal."
      },
      {
        "date": "2021-03-15T05:33:00.000Z",
        "voteCount": 3,
        "content": "The image is cut so i cant see the bottom 2 dropdowns but they sound alright in the answer explanation bellow. \n\nAlso the 2nd box should be Message Count.\n\nReason:\nIn the question it is said:\n\"when the average queue length of unprocessed AND valid queue messages\"\n\nIf it was just valid Queue messages it would have been enough to set it on Active Message Count... but they want Valid AND Unproscessed messages... so i think it should be Message Count. \n(i am not 100% sure but unprosessed message should not count as an active message)"
      },
      {
        "date": "2021-04-03T01:56:00.000Z",
        "voteCount": 3,
        "content": "Messagecount is false because it also contains deadlettered messages among others. Unprocessed messages are active because they are \"ready to delivery\".  So i think \"Active Message Count\" is correct"
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 6,
    "url": "https://www.examtopics.com/discussions/microsoft/view/47403-exam-az-204-topic-3-question-6-discussion/",
    "body": "DRAG DROP -<br>You have an application that uses Azure Blob storage.<br>You need to update the metadata of the blobs.<br>Which three methods should you use to develop the solution? To answer, move the appropriate methods from the list of methods to the answer area and arrange them in the correct order.<br>Select and Place:<br><img src=\"/assets/media/exam-media/04273/0022100001.jpg\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04273/0022100002.jpg\" class=\"in-exam-image\">",
    "answerDescription": "Metadata.Add example:<br>// Add metadata to the dictionary by calling the Add method<br>metadata.Add(\"docType\", \"textDocuments\");<br>SetMetadataAsync example:<br>// Set the blob's metadata.<br>await blob.SetMetadataAsync(metadata);<br>// Set the blob's properties.<br>await blob.SetPropertiesAsync();<br>Reference:<br>https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blob-properties-metadata",
    "votes": [],
    "comments": [
      {
        "date": "2021-03-21T16:04:00.000Z",
        "voteCount": 258,
        "content": "Since we're talking about updating the metadata, \n- first we need to fetch it, to populate blob's properties and metadata (we want to update it - without fetching we would just set the new metadata):\n  FetchAttributesAsync\n- second, we need to manipulate the metadatas to update them and the best fitting is\n  Metadata.Add\n- third, we have to persist our changes. We can use a method that initiates an asynchronous operation to update the blob's metadata, which is\n  SetMetadataAsync"
      },
      {
        "date": "2021-07-23T02:05:00.000Z",
        "voteCount": 20,
        "content": "Based on MS documentation referenced it should be:\n\n// Get the blob's properties and metadata. \nBlobProperties properties = await blob.GetPropertiesAsync();\n\n// Add metadata to the dictionary by calling the Add method \nproperties.metadata.Add(\"docType\", \"textDocuments\"); \n\n// Add metadata to the dictionary by using key/value syntax \nproperties.metadata[\"category\"] = \"guidance\"; \n\n// Set the blob's metadata. \nawait blob.SetMetadataAsync(properties.metadata);"
      },
      {
        "date": "2021-11-23T12:24:00.000Z",
        "voteCount": 2,
        "content": "But there is no option for GetProperties !"
      },
      {
        "date": "2022-10-04T23:46:00.000Z",
        "voteCount": 3,
        "content": "Yes there is, in version 12. The exam topic references for version 11 (legacy)"
      },
      {
        "date": "2021-06-19T12:17:00.000Z",
        "voteCount": 4,
        "content": "This is the best response (the \"official\" response is wrong)"
      },
      {
        "date": "2021-03-25T09:25:00.000Z",
        "voteCount": 2,
        "content": "correct!"
      },
      {
        "date": "2021-05-15T18:33:00.000Z",
        "voteCount": 3,
        "content": "nicely explained!"
      },
      {
        "date": "2021-04-07T11:33:00.000Z",
        "voteCount": 55,
        "content": "I suppose there are two correct answers, depending on the version of Azure.Storage.Blobs. For v11: FetchAttributesAsync, Metadata.Add, SetMetadataAsync.\nFor v12: GetPropertiesAsync, Metadata.Add, SetMetadataAsync.\nJust look here, there are two tabs with source code. One for v11, one for v12:\nhttps://docs.microsoft.com/en-us/azure/storage/blobs/storage-blob-properties-metadata?tabs=dotnet#set-and-retrieve-metadata"
      },
      {
        "date": "2021-06-28T21:06:00.000Z",
        "voteCount": 14,
        "content": "Correct. But GetPropertiesAsync not mentioned in answer options. We can go with FetchAttributesAsync"
      },
      {
        "date": "2022-06-23T01:08:00.000Z",
        "voteCount": 1,
        "content": "MS updated their pages. \nNow, to set metadata, you need to add it either with metadata.Add, or metadata[key] = value. \nAfter, you just need to save it, by calling SetMetadataAsync. \nNo other operations are required as we do not care what metadata is already on the blob set."
      },
      {
        "date": "2023-08-20T07:37:00.000Z",
        "voteCount": 1,
        "content": "Yeah, But the question forces you to pick 3 options. So FetchAtrributeAsync is probably the closest one."
      },
      {
        "date": "2024-03-14T01:28:00.000Z",
        "voteCount": 1,
        "content": "Sure, here are three methods you could use to update the metadata of blobs in Azure Blob storage-\nSetBlobMetadata\nSetMetadataAsync\nSetPropertiesAsync\nFOr more details - https://sysconverter.com/blog/import-pst-to-shared-mailbox-office-365/"
      },
      {
        "date": "2024-03-13T13:50:00.000Z",
        "voteCount": 2,
        "content": "Got it in exam on 13.03.2024. Score: 910."
      },
      {
        "date": "2023-12-14T00:45:00.000Z",
        "voteCount": 2,
        "content": "Got it in the exam 14/12/23. Went with given answer. All questions are from ExamTopics. Case study - VanArsdel, Ltd (11 questions)"
      },
      {
        "date": "2023-11-03T07:41:00.000Z",
        "voteCount": 2,
        "content": "On exam 3-Nov-2023. Went with most-voted answer - 932/1000.\n1) FetchAtrributesAsync\n2) Metadata.Add\n3) SetMetadataAsync"
      },
      {
        "date": "2023-10-05T02:23:00.000Z",
        "voteCount": 1,
        "content": "On my exam 2023-10 before the Update of the Exam"
      },
      {
        "date": "2023-09-22T03:02:00.000Z",
        "voteCount": 1,
        "content": "Had this on my exam today."
      },
      {
        "date": "2023-09-19T21:21:00.000Z",
        "voteCount": 3,
        "content": "I got this same question. Provided answers are correct. (Note: I failed the exam 20/Sept/23. I only scored 644 and I felt bad. I think because many questions here in Examtopics are not correct or already outdated. I suggest following the most voted answers and not rely on Examtopics answers. At the beginning of the exam, you will be asked which programming languages you want to use. C#/Python. I chose C#. Also, I just want to add that some questions here in the actual exams, but the choices are written and formatted differently. Please be aware of that. Goodluck. I feel bad for failing it, but I want to retake next month. I will try Python. T_T"
      },
      {
        "date": "2023-09-23T02:34:00.000Z",
        "voteCount": 1,
        "content": "Sorry to hear that. I have exam soon. Were all the questions from ExamTopics&gt; Any tips you would like to share please, Thanks"
      },
      {
        "date": "2024-04-18T11:37:00.000Z",
        "voteCount": 1,
        "content": "Do the questions you found in the exam all come from here?"
      },
      {
        "date": "2023-11-06T22:55:00.000Z",
        "voteCount": 1,
        "content": "I would say 30% percent of the questions here really shown to my exam. But after I purchased contributor access, I would say 90 percent of the questions here. In my first attempt, I almost lose my hope of passing because of the case study. So, I highly recommend you review case studies. really difficult. And like I said, some question and answer format are quite different from the actual exam. Good luck. I'm gonna retake before end of Nov.2023 because of the recent update from MS. AZ-204 was updated."
      },
      {
        "date": "2023-08-03T05:29:00.000Z",
        "voteCount": 2,
        "content": "It should be FetchAttributesAsync, Metadata.Add, SetMetadataAsync"
      },
      {
        "date": "2023-07-06T02:42:00.000Z",
        "voteCount": 4,
        "content": "This was on the exam (July 2023). Went with fetch/metadata.add/setMetadata. Scored 917"
      },
      {
        "date": "2023-06-16T03:24:00.000Z",
        "voteCount": 4,
        "content": "Just for information: I just had this question on my AZ204 exam - 16-jun-2023.\nI barely made it (with only 767 points) so I can't inform anyony if this answer is correct or not, just stating that this is an actual exam question."
      },
      {
        "date": "2022-12-30T09:20:00.000Z",
        "voteCount": 2,
        "content": "Got this in exam 12/30/2022"
      },
      {
        "date": "2022-12-09T06:19:00.000Z",
        "voteCount": 2,
        "content": "thanks to all who have mentioned the exam dates"
      },
      {
        "date": "2022-11-30T10:27:00.000Z",
        "voteCount": 3,
        "content": "FetchAttributesAsync\nMetadata.Add\nSetMetadataAsync"
      },
      {
        "date": "2022-10-20T18:29:00.000Z",
        "voteCount": 2,
        "content": "Got it in exam 20/10/2022"
      },
      {
        "date": "2022-10-04T23:43:00.000Z",
        "voteCount": 4,
        "content": "FetchAttributesAsync is version 11 (legacy)\nIn version 12 is would be :\n1. await blob.GetPropertiesAsync();\n2. metadata.Add(\"docType\", \"textDocuments\");\n3. await blob.SetMetadataAsync(metadata);\nhttps://learn.microsoft.com/en-us/azure/storage/blobs/storage-blob-properties-metadata"
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 7,
    "url": "https://www.examtopics.com/discussions/microsoft/view/46892-exam-az-204-topic-3-question-7-discussion/",
    "body": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.<br>After you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.<br>You are developing an Azure solution to collect point-of-sale (POS) device data from 2,000 stores located throughout the world. A single device can produce<br>2 megabytes (MB) of data every 24 hours. Each store location has one to five devices that send data.<br>You must store the device data in Azure Blob storage. Device data must be correlated based on a device identifier. Additional stores are expected to open in the future.<br>You need to implement a solution to receive the device data.<br>Solution: Provision an Azure Event Grid. Configure the machine identifier as the partition key and enable capture.<br>Does the solution meet the goal?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tYes",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tNo\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 30,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-03-23T09:22:00.000Z",
        "voteCount": 148,
        "content": "I don't know who gave all the answer, but that person definitely failed the exam.."
      },
      {
        "date": "2021-06-26T22:10:00.000Z",
        "voteCount": 1,
        "content": "what is the answer?"
      },
      {
        "date": "2021-05-23T08:49:00.000Z",
        "voteCount": 4,
        "content": "Good one... :)"
      },
      {
        "date": "2021-08-11T00:27:00.000Z",
        "voteCount": 24,
        "content": "Its Event Hub not, Grid."
      },
      {
        "date": "2023-08-10T17:08:00.000Z",
        "voteCount": 6,
        "content": "I honestly think that this is on purpose so people actually discuss the questions. Reverse psychology. LOL"
      },
      {
        "date": "2024-08-12T23:22:00.000Z",
        "voteCount": 1,
        "content": "If they posted the real answers they would have Microsoft on their tail immediately."
      },
      {
        "date": "2021-03-13T07:37:00.000Z",
        "voteCount": 52,
        "content": "I think event hub. Azure Event Hub can be used to get the messages from the various devices. Azure Event Hub capture can then be used to persist the events to Azure Blob storage."
      },
      {
        "date": "2021-04-16T12:33:00.000Z",
        "voteCount": 11,
        "content": "I agree. The solution says \"enable capture\". I have found capture only for Event Hub, not for Event Grid.\nhttps://docs.microsoft.com/en-us/azure/event-hubs/event-hubs-capture-overview"
      },
      {
        "date": "2023-01-30T21:16:00.000Z",
        "voteCount": 1,
        "content": "Agreed"
      },
      {
        "date": "2023-12-11T04:00:00.000Z",
        "voteCount": 2,
        "content": "Its Eventhub, grid is primarly for event routing, allowing other resources like functions to react to changes from a blobstorage etc. Event hub is the choice for streaming telemetry data from thousands of sources to a blobstorage.Here is a digestable documentation for understanding the difference between Hub, Grid and ServiceBus: https://arindam-das.medium.com/demystifying-azures-eventing-services-a-comparison-of-event-hub-event-grid-and-service-bus-d578693dcf16"
      },
      {
        "date": "2023-10-10T04:10:00.000Z",
        "voteCount": 1,
        "content": "It should be EventHub, not EventGrid."
      },
      {
        "date": "2023-10-05T02:24:00.000Z",
        "voteCount": 1,
        "content": "Had this series of questions On my exam 2023-10 before the Update of the Exam"
      },
      {
        "date": "2023-08-20T07:41:00.000Z",
        "voteCount": 4,
        "content": "The answer is Azure Event Hub, not Event Grid."
      },
      {
        "date": "2023-04-20T13:11:00.000Z",
        "voteCount": 8,
        "content": "How come almost every answer marked by examtopic is incorrect. Whats the purpose of marking answers then if you have to follow discussion thread for each question?"
      },
      {
        "date": "2023-11-06T23:04:00.000Z",
        "voteCount": 2,
        "content": "Yeah, it is confusing. I failed in my first attempt. scored 644 only."
      },
      {
        "date": "2023-03-11T08:51:00.000Z",
        "voteCount": 4,
        "content": "\"device data from 2,000 stores located throughout the world.\" It is a distributed data streaming. Answer is EventHub"
      },
      {
        "date": "2023-02-26T23:51:00.000Z",
        "voteCount": 4,
        "content": "Given solution does not meet the goal because you are using Event Grid instead of Event Hubs. Event Grid does not have a capture feature and it does not store data in Blob storage. You need to use Event Hubs as your source and enable capture with Blob storage as your destination."
      },
      {
        "date": "2023-01-23T10:49:00.000Z",
        "voteCount": 4,
        "content": "B. No.\nAzure Event Grid is an event routing service that allows you to handle events from various Azure services and your own applications. It can be used to send events from an application to multiple subscribers, but it is not well suited for receiving data from thousands of devices and storing them in Azure Blob storage.\nAzure Event Grid is also not meant for long-term data storage and it is not a good fit for this scenario, where large amounts of data need to be stored and correlated based on a device identifier."
      },
      {
        "date": "2022-12-26T04:09:00.000Z",
        "voteCount": 1,
        "content": "B is the correct answer"
      },
      {
        "date": "2022-08-18T22:04:00.000Z",
        "voteCount": 3,
        "content": "The reason for No is due to the max no. of partition. The question demands 5x2000 = 10000 parition, which is more than all tiers available.\n\nhttps://docs.microsoft.com/en-us/azure/event-hubs/event-hubs-quotas#basic-vs-standard-vs-premium-vs-dedicated-tiers"
      },
      {
        "date": "2022-08-06T04:06:00.000Z",
        "voteCount": 1,
        "content": "EventHub not EventGrid"
      },
      {
        "date": "2022-07-28T01:41:00.000Z",
        "voteCount": 1,
        "content": "B is the correct answer"
      },
      {
        "date": "2022-07-18T02:52:00.000Z",
        "voteCount": 2,
        "content": "No - Capture is a feature of EventHub, not EventGrid."
      },
      {
        "date": "2022-07-02T01:51:00.000Z",
        "voteCount": 2,
        "content": "is event hub, not grid"
      },
      {
        "date": "2022-06-18T02:49:00.000Z",
        "voteCount": 1,
        "content": "Event Hub is the correct option. Sensors are sending data, they aren't just notifying you that something happened."
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 8,
    "url": "https://www.examtopics.com/discussions/microsoft/view/46919-exam-az-204-topic-3-question-8-discussion/",
    "body": "You develop Azure solutions.<br>A .NET application needs to receive a message each time an Azure virtual machine finishes processing data. The messages must NOT persist after being processed by the receiving application.<br>You need to implement the .NET object that will receive the messages.<br>Which object should you use?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tQueueClient\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSubscriptionClient",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tTopicClient",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCloudQueueClient"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 12,
        "isMostVoted": true
      },
      {
        "answer": "B",
        "count": 2,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2021-05-23T07:22:00.000Z",
        "voteCount": 89,
        "content": "Correct Answer: A\n\nAzure.Storage.Queues.QueueClient: .NET v12\nAzure.Storage.Queues.CloudQueueClient: .NET v11 (Legacy)\n\n\nSo, the question is really about what kind of queue message tool you should use. And the key word here is that \"message must NOT persist after being processed\". \n\nAzure.Storage.Queues.QueueClient supports \"At-Most-Once\" deliver mode, while Azure.Storage.Queues.CloudQueueClient doesn't.\n\n\nReference:\n\nhttps://docs.microsoft.com/en-us/dotnet/api/azure.storage.queues.queueclient?view=azure-dotnet\n\nhttps://docs.microsoft.com/en-us/dotnet/api/microsoft.azure.storage.queue.cloudqueueclient?view=azure-dotnet-legacy"
      },
      {
        "date": "2023-01-20T07:07:00.000Z",
        "voteCount": 3,
        "content": "It's QueueClient of Service Bus."
      },
      {
        "date": "2021-10-04T03:51:00.000Z",
        "voteCount": 2,
        "content": "It seems the CloudQueueClient is a legacy class and is used for creation of QueueClient instances.\nhttps://docs.microsoft.com/en-us/dotnet/api/microsoft.azure.storage.queue.cloudqueueclient.getqueuereference"
      },
      {
        "date": "2024-01-11T05:29:00.000Z",
        "voteCount": 1,
        "content": "but when you do receive message on storage queue it wont delete message automatically"
      },
      {
        "date": "2021-05-20T12:06:00.000Z",
        "voteCount": 19,
        "content": "First of all - question is not precise as we don't know which QueueClient they are asking about. There are two options:\n- Microsoft.AzureService.Bus.QueueClient?\n- Azure.Storage.Queues.QueueClient?\n\nI would say it is about Microsoft.AzureService.Bus.QueueClient as the difference between Azure.Storage.Queues.CloudQueueClient (v12) is just a legacy version of the Azure.Storage.Queues.QueueClient (v11)\nSo the question is really about what kind of queue message tool you should use. And the key word here is that \"message must NOT persist after being processed\". So correct answer would be Microsoft.AzureService.Bus.QueueClient (A) as it supports \"At-Most-Once\" deliver mode while Azure.Storage.Queues.CloudQueueClient doesn't."
      },
      {
        "date": "2023-08-10T17:12:00.000Z",
        "voteCount": 1,
        "content": "I agree. Plus that Azure.Storage.Queues.QueueClient AFAIK is more appropriate for data intensive scenarios."
      },
      {
        "date": "2024-08-05T08:59:00.000Z",
        "voteCount": 1,
        "content": "The answer is \"QueueClient\":The CloudQueueClient from Azure Storage Queue requires manual deletion of messages, while the QueueClient from Azure Service Bus can use the ReceiveAndDelete mode to automatically delete messages after processing."
      },
      {
        "date": "2024-03-07T08:05:00.000Z",
        "voteCount": 2,
        "content": "SubscriptionClient Given the requirement for messages to not persist after being processed and the implied need for a publish/subscribe model"
      },
      {
        "date": "2024-01-19T03:18:00.000Z",
        "voteCount": 2,
        "content": "Think it the servicebus namespace because it is messaging not the storagequeue namespace. The QueueClient is deprecated for Servicebus. It is not in the answers but it should be ServiceBusClient. So in this case I would go for the depricated object answer A"
      },
      {
        "date": "2023-10-01T04:23:00.000Z",
        "voteCount": 2,
        "content": "@Admin Please correct answer.\nAs per MS Doc and ChatGPT correct ans is A so please correct ans and its explanation"
      },
      {
        "date": "2023-01-23T10:51:00.000Z",
        "voteCount": 1,
        "content": "A. QueueClient"
      },
      {
        "date": "2022-11-30T10:29:00.000Z",
        "voteCount": 1,
        "content": "A. QueueClient"
      },
      {
        "date": "2022-10-06T23:18:00.000Z",
        "voteCount": 7,
        "content": "Microsoft creates all these random naming convention showing how disorganized they are in individual islands and they dare to ask questions along this fault lines."
      },
      {
        "date": "2022-08-02T22:23:00.000Z",
        "voteCount": 3,
        "content": "A is correct, the new API calls it QueueClient. See also most upvoted answer."
      },
      {
        "date": "2024-09-18T05:34:00.000Z",
        "voteCount": 1,
        "content": "QueueClient: This is used for Azure Service Bus Queues, which follows a one-to-one messaging pattern, meaning only one receiver can process a message. However, messages in a queue persist until they are explicitly deleted or expire, which does not fit the requirement."
      },
      {
        "date": "2022-06-18T02:51:00.000Z",
        "voteCount": 1,
        "content": "A - version 12\nD - \"legacy\" version 11"
      },
      {
        "date": "2022-02-27T06:23:00.000Z",
        "voteCount": 1,
        "content": "What about SeviceBus QueueClient in the old API?\nhttps://docs.microsoft.com/en-us/dotnet/api/microsoft.azure.servicebus.queueclient?view=azure-dotnet"
      },
      {
        "date": "2022-02-18T03:52:00.000Z",
        "voteCount": 3,
        "content": "A is the correct answer"
      },
      {
        "date": "2022-02-06T14:52:00.000Z",
        "voteCount": 1,
        "content": "So the explanation for why A is wrong is incorrect? It states you cannot access the VM using A"
      },
      {
        "date": "2021-05-25T00:18:00.000Z",
        "voteCount": 1,
        "content": "yes A is correct"
      },
      {
        "date": "2021-05-14T07:45:00.000Z",
        "voteCount": 2,
        "content": "A. QueueClient"
      },
      {
        "date": "2021-03-13T11:18:00.000Z",
        "voteCount": 4,
        "content": "Why not A?"
      },
      {
        "date": "2021-03-22T08:55:00.000Z",
        "voteCount": 3,
        "content": "See the answer information:\nA queue allows processing of a message by a single consumer. Need a CloudQueueClient to access the Azure VM."
      },
      {
        "date": "2022-06-12T04:22:00.000Z",
        "voteCount": 2,
        "content": "I really don't know why you need to access the Azure VM, it makes no sense. Whatever the VM does, in the end, it add a message to a queue in Azure. And you don't need to access the VM to access the queue. This explanation is very awkward.\nAlso, is it true that CloudQueueClient can access a VM? That sounds really strange, it goes beyond the purpose of a \"queue client\". It's like using a fork as a screwdriver...\nThe only difference between CloudQueueClient and QueueClient I've found so far is that CloudQueueClient is the legacy version of the client (v11) and QueueClient is the newest version (v12).\nSo, I would choose A."
      },
      {
        "date": "2021-03-17T01:55:00.000Z",
        "voteCount": 18,
        "content": "Agreed, A is the new-style API, and D is the old-style API, so IMHO, A is better.\n\nLink (A): https://docs.microsoft.com/en-us/dotnet/api/azure.storage.queues.queueclient?view=azure-dotnet\nLink (D): https://docs.microsoft.com/en-us/dotnet/api/microsoft.azure.storage.queue.cloudqueueclient?view=azure-dotnet-legacy"
      },
      {
        "date": "2021-03-26T10:31:00.000Z",
        "voteCount": 7,
        "content": "You're right.\nnew version --&gt; .NET v12 --&gt; QueueClient\nold version --&gt; .NET v11 --&gt; CloudQueueClient\nLink --&gt; https://docs.microsoft.com/en-us/azure/storage/queues/storage-dotnet-how-to-use-queues?tabs=dotnet#create-the-queue-storage-client\nTherefore, the answer is QueueClient."
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 9,
    "url": "https://www.examtopics.com/discussions/microsoft/view/46962-exam-az-204-topic-3-question-9-discussion/",
    "body": "DRAG DROP -<br>You are maintaining an existing application that uses an Azure Blob GPv1 Premium storage account. Data older than three months is rarely used.<br>Data newer than three months must be available immediately. Data older than a year must be saved but does not need to be available immediately.<br>You need to configure the account to support a lifecycle management rule that moves blob data to archive storage for data not modified in the last year.<br>Which three actions should you perform in sequence? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.<br>Select and Place:<br><img src=\"/assets/media/exam-media/04273/0022400001.jpg\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04273/0022400002.jpg\" class=\"in-exam-image\">",
    "answerDescription": "Step 1: Upgrade the storage account to GPv2<br>Object storage data tiering between hot, cool, and archive is supported in Blob Storage and General Purpose v2 (GPv2) accounts. General Purpose v1 (GPv1) accounts don't support tiering.<br>You can easily convert your existing GPv1 or Blob Storage accounts to GPv2 accounts through the Azure portal.<br>Step 2: Copy the data to be archived to a Standard GPv2 storage account and then delete the data from the original storage account<br>Step 3: Change the storage account access tier from hot to cool<br>Note: Hot - Optimized for storing data that is accessed frequently.<br>Cool - Optimized for storing data that is infrequently accessed and stored for at least 30 days.<br>Archive - Optimized for storing data that is rarely accessed and stored for at least 180 days with flexible latency requirements, on the order of hours.<br>Only the hot and cool access tiers can be set at the account level. The archive access tier can only be set at the blob level.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blob-storage-tiers",
    "votes": [],
    "comments": [
      {
        "date": "2021-04-12T05:05:00.000Z",
        "voteCount": 122,
        "content": "Since we already have a premium P1 account with gpv1. Why not:\n- Upgrade the existing one to GPv2\n- Create a new GPV2 standard account with default access level to cool\n- And then copy archive data to the GPV2 and delete the data from original storage account. \nThat makes sense to me."
      },
      {
        "date": "2021-06-09T07:33:00.000Z",
        "voteCount": 2,
        "content": "Is there any requirement in question, which says set default access tier to COOL?\nPlease clarify."
      },
      {
        "date": "2021-06-24T06:53:00.000Z",
        "voteCount": 3,
        "content": "I have 2 ideas:\n1. \n- One HOT for newer than 3 months\n- One COOL for older than 3 months and Archive data.\n2.\n- One HOT for non-archived data. Can be accessed immediately. Because they just said \"Older than 3 months data are rarely accessed\" but didn't tell us anything about can it be accessed immediately.\n- One COOL for archived data. Archived tier can just be set at blob level. \"Only the hot and cool access tiers can be set at the account level. The archive access tier can only be set at the blob level\" https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blob-storage-tiers"
      },
      {
        "date": "2021-04-16T17:49:00.000Z",
        "voteCount": 2,
        "content": "does this mean at the end, we have 2 GPv2 storage accounts, one access level is cool (for archive data) and the other is hot?"
      },
      {
        "date": "2021-04-19T09:05:00.000Z",
        "voteCount": 1,
        "content": "I would say so."
      },
      {
        "date": "2021-04-19T09:06:00.000Z",
        "voteCount": 4,
        "content": "Also look at this blog:\nhttps://www.apptio.com/blog/essential-guide-azure-blob-storage-pricing/\nOnly GPv2 and Blob storage accounts support tiering. If you are using GPv1, and you want to leverage tiering, convert your account to GPv2 through the Azure portal."
      },
      {
        "date": "2021-05-17T23:18:00.000Z",
        "voteCount": 1,
        "content": "My choice as well"
      },
      {
        "date": "2021-07-29T13:19:00.000Z",
        "voteCount": 1,
        "content": "I agree. But can the first step be the last?\n- Create a new GPV2 standard account with default access level to cool\n- And then copy archive data to the GPV2 and delete the data from original storage account.\n- Upgrade the existing one to GPv2"
      },
      {
        "date": "2021-05-23T07:47:00.000Z",
        "voteCount": 23,
        "content": "Step 1: Upgrade the storage account to GPv2\nObject storage data tiering between hot, cool, and archive is supported in Blob Storage and General Purpose v2 (GPv2) accounts. General Purpose v1 (GPv1) accounts don't support tiering. You can easily convert your existing GPv1 or Blob Storage accounts to GPv2 accounts through the Azure portal.\n\nStep 2: Create a new GPV2 standard account with default access level to cool\n\nStep 3: Copy the data to be archived to a Standard GPv2 storage account and then delete the data from the original storage account"
      },
      {
        "date": "2022-06-18T19:34:00.000Z",
        "voteCount": 4,
        "content": "Agreed:  1. upgrade storage account 1 from GPv1 -&gt; v2 (hot),  2. create storage account 2 GPv2 (cool) 3. copy data from account 1 to account 2. End result: account 1 (hot), account 2(cool and archive) both accounts can set lifecycle policy"
      },
      {
        "date": "2021-05-30T05:54:00.000Z",
        "voteCount": 2,
        "content": "Reference:\n\nhttps://docs.microsoft.com/en-us/azure/storage/blobs/storage-blob-storage-tiers\n\nhttps://docs.microsoft.com/en-us/azure/storage/common/storage-account-upgrade?tabs=azure-portal"
      },
      {
        "date": "2021-05-30T05:55:00.000Z",
        "voteCount": 4,
        "content": "Although Step 3 seems unusual and not necessary."
      },
      {
        "date": "2021-10-15T02:03:00.000Z",
        "voteCount": 1,
        "content": "every time with good explanation but step 3 needed because why not transfer the old data that needed to new one and delete the old one for saving cost"
      },
      {
        "date": "2024-08-05T09:12:00.000Z",
        "voteCount": 1,
        "content": "In real practice, I just keep one account: upgrade the account to GPV2 which supports tier, change the account tier to cool since the data in the account is infrequently used, and achieve the blob which is not modified for more than 1 year."
      },
      {
        "date": "2024-08-04T21:37:00.000Z",
        "voteCount": 1,
        "content": "Upgrade , Create and Copy"
      },
      {
        "date": "2023-11-21T05:41:00.000Z",
        "voteCount": 2,
        "content": "Why to upgrade the storage account to GPv2?"
      },
      {
        "date": "2023-11-14T02:06:00.000Z",
        "voteCount": 2,
        "content": "The requirement is just: You need to configure the account to SUPPORT a lifecycle management rule.\n\nSo you only need \"Upgrade the existing one to GPv2\"\nNo more steps from the list are required\n\nThen you could configure the lifecycle management rule.\nOnce you apply the rule, the files tier will be changed automatically"
      },
      {
        "date": "2023-04-16T13:06:00.000Z",
        "voteCount": 1,
        "content": "Azure Blob storage lifecycle management offers a rich, rule-based policy for General Purpose v2 and Blob storage accounts."
      },
      {
        "date": "2023-03-27T21:00:00.000Z",
        "voteCount": 3,
        "content": "Create , change , copy\n\nData stored in a premium block blob storage account cannot be tiered to Hot, Cool, or Archive using Set Blob Tier or using Azure Blob Storage lifecycle management. To move data, you must synchronously copy blobs from the block blob storage account to the Hot tier in a different account using the Put Block From URL API or a version of AzCopy that supports this API."
      },
      {
        "date": "2023-03-22T04:39:00.000Z",
        "voteCount": 2,
        "content": "Just for reference: GPv2 supports Hot, Cool, and Archive tiers"
      },
      {
        "date": "2023-02-09T08:00:00.000Z",
        "voteCount": 2,
        "content": "Upgrade-Create-Copy"
      },
      {
        "date": "2023-01-30T04:11:00.000Z",
        "voteCount": 2,
        "content": "Seems like we don't have the entire world view, and that there's already an existing standard v2 account elsewhere. If that's the case we're starting with v1 storage where the data currently is and we also have a default v2 storage that exists.\n\nWe upgrade the current v1 to v2 so we can access lifetime management\nwe copy the data to be archived to the standard v2 (that already existed, and by default has hot tier)\nthen we set the tier to be cool (where the archive data was just copied to).\n\nI think the current answer is correct."
      },
      {
        "date": "2022-11-11T10:30:00.000Z",
        "voteCount": 2,
        "content": "The answer doesn't make any sense to me.\nin the 2nd step, it says copy the data from old storage account to new one, it means there are 2 storage accounts, why you need to upgrade the existing?"
      },
      {
        "date": "2022-10-23T04:16:00.000Z",
        "voteCount": 1,
        "content": "Upgrade to GPv2\nCopy data\nChange tier to cool\nYou can't create the second account in a cool tier because of this:\nData stored in a premium block blob storage account cannot be tiered to hot, cool, or archive using Set Blob Tier or using Azure Blob Storage lifecycle management. To move data, you must synchronously copy blobs from the block blob storage account to the hot tier in a different account using ...\nhttps://learn.microsoft.com/en-us/azure/storage/blobs/access-tiers-overview#blob-lifecycle-management"
      },
      {
        "date": "2022-06-28T14:05:00.000Z",
        "voteCount": 7,
        "content": "Upgrade\nCreate\nCopy"
      },
      {
        "date": "2022-04-08T10:05:00.000Z",
        "voteCount": 3,
        "content": "Agree with voting/answer, but the question itself seems flawed.  Need to learn not to read anything else into the questions and not add steps/requirements that yes, would make sense."
      },
      {
        "date": "2022-03-09T13:57:00.000Z",
        "voteCount": 5,
        "content": "Got it in exam 03/22"
      },
      {
        "date": "2022-02-05T03:52:00.000Z",
        "voteCount": 1,
        "content": "for me not have sense - Upgrade the existing one to GPv2\nSo:\n-create ..\n-change..\n-copy"
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 10,
    "url": "https://www.examtopics.com/discussions/microsoft/view/28649-exam-az-204-topic-3-question-10-discussion/",
    "body": "You develop Azure solutions.<br>You must connect to a No-SQL globally-distributed database by using the .NET API.<br>You need to create an object to configure and execute requests in the database.<br>Which code segment should you use?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tnew Container(EndpointUri, PrimaryKey);",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tnew Database(EndpointUri, PrimaryKey);",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tnew CosmosClient(EndpointUri, PrimaryKey);\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 6,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2020-08-15T04:54:00.000Z",
        "voteCount": 48,
        "content": "The Answer is correct!"
      },
      {
        "date": "2021-05-23T07:07:00.000Z",
        "voteCount": 22,
        "content": "Correct Answer: C\n\nAzure Cosmos DB is a fully managed NoSQL database for modern app development. Single-digit millisecond response times, and automatic and instant scalability, guarantee speed at any scale.\n\n// Create a new instance of the Cosmos Client\nthis.cosmosClient = new CosmosClient(EndpointUri, PrimaryKey)\n//ADD THIS PART TO YOUR CODE\nawait this.CreateDatabaseAsync();\n\n\nReference:\n\nhttps://docs.microsoft.com/en-us/dotnet/api/microsoft.azure.cosmos.cosmosclient?view=azure-dotnet\n\nhttps://docs.microsoft.com/en-us/azure/cosmos-db/sql-api-get-started"
      },
      {
        "date": "2024-09-06T08:40:00.000Z",
        "voteCount": 1,
        "content": "wow. finally one correct answer."
      },
      {
        "date": "2023-02-09T08:05:00.000Z",
        "voteCount": 2,
        "content": "I dont get this question, Cosmos DB is a No-SQL globally-distributed database, but there are others that .NET can connect."
      },
      {
        "date": "2023-01-02T08:00:00.000Z",
        "voteCount": 1,
        "content": "Correct Answer: C"
      },
      {
        "date": "2022-12-14T22:52:00.000Z",
        "voteCount": 1,
        "content": "CosmosClient(String, String, CosmosClientOptions)\n\nhttps://learn.microsoft.com/en-us/dotnet/api/microsoft.azure.cosmos.cosmosclient?view=azure-dotnet"
      },
      {
        "date": "2022-11-19T03:41:00.000Z",
        "voteCount": 1,
        "content": "C. new CosmosClient(EndpointUri, PrimaryKey);"
      },
      {
        "date": "2022-08-22T02:38:00.000Z",
        "voteCount": 1,
        "content": "The Answer is correct!"
      },
      {
        "date": "2022-06-10T02:42:00.000Z",
        "voteCount": 2,
        "content": "C is correct answer. \nGlobal fully managed No-SQL DB = CosmosDB"
      },
      {
        "date": "2022-03-09T13:57:00.000Z",
        "voteCount": 2,
        "content": "Got it in exam 03/22"
      },
      {
        "date": "2022-02-23T03:57:00.000Z",
        "voteCount": 1,
        "content": "The correct answer is C."
      },
      {
        "date": "2022-02-07T03:45:00.000Z",
        "voteCount": 5,
        "content": "Got this one 02/2022. Went with highly voted answer."
      },
      {
        "date": "2022-01-21T03:00:00.000Z",
        "voteCount": 5,
        "content": "Got this in the exam 01/22"
      },
      {
        "date": "2022-01-19T07:36:00.000Z",
        "voteCount": 5,
        "content": "Got this one 01/2022. Went with most voted (to avoid writing answers again)"
      },
      {
        "date": "2021-10-07T02:45:00.000Z",
        "voteCount": 2,
        "content": "Answer : C"
      },
      {
        "date": "2021-10-04T21:31:00.000Z",
        "voteCount": 3,
        "content": "Order:\nCosmos Client &gt; Database &gt; Container &gt; Item"
      },
      {
        "date": "2021-06-28T13:12:00.000Z",
        "voteCount": 4,
        "content": "But why we assume it is Cosmos? \nApp needs to access some No-SQL database that may already exist - maybe it is Cosmos, maybe not"
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 11,
    "url": "https://www.examtopics.com/discussions/microsoft/view/49088-exam-az-204-topic-3-question-11-discussion/",
    "body": "You have an existing Azure storage account that stores large volumes of data across multiple containers.<br>You need to copy all data from the existing storage account to a new storage account. The copy process must meet the following requirements:<br>\u2711 Automate data movement.<br>\u2711 Minimize user input required to perform the operation.<br>\u2711 Ensure that the data movement process is recoverable.<br>What should you use?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzCopy\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure Storage Explorer",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure portal",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t.NET Storage Client Library"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 11,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-06-26T22:28:00.000Z",
        "voteCount": 40,
        "content": "Answer \u2013 AzCopy, The Azcopy tool can be used to copy data from one storage account to another. You can use the tool within automation scripts to ensure the data can be copied automatically."
      },
      {
        "date": "2021-05-23T07:03:00.000Z",
        "voteCount": 10,
        "content": "Correct Answer: C\n\nAzure Storage Explorer uses AzCopy to perform all of its data transfer operations. But in this questions, there is a requirement to minimize user interaction which is why AzCopy is more appropriate.\n\nReference:\n\nhttps://docs.microsoft.com/en-us/azure/storage/common/storage-use-azcopy-v10\n\nhttps://docs.microsoft.com/en-us/azure/storage/common/storage-use-azcopy-blobs-copy"
      },
      {
        "date": "2021-06-20T04:40:00.000Z",
        "voteCount": 47,
        "content": "AzCopy is A...  please do not write confusing responses...\nresponse is already correct, A - AzCopy"
      },
      {
        "date": "2021-11-21T02:18:00.000Z",
        "voteCount": 5,
        "content": "But read very first requirement. It needs to be Automated. I agree with alperc, you are misanswering, even such a silly question."
      },
      {
        "date": "2021-11-04T04:36:00.000Z",
        "voteCount": 8,
        "content": "please stop commenting..you are always misanswering."
      },
      {
        "date": "2024-03-21T12:38:00.000Z",
        "voteCount": 1,
        "content": "It's no brainer. AzCopy is the answer with no or minimal human intervention."
      },
      {
        "date": "2023-02-18T13:32:00.000Z",
        "voteCount": 2,
        "content": "Typical AzCopy"
      },
      {
        "date": "2022-12-14T22:53:00.000Z",
        "voteCount": 2,
        "content": "AzCopy \nReference: https://learn.microsoft.com/en-us/azure/storage/common/storage-use-azcopy-v10"
      },
      {
        "date": "2022-11-19T03:42:00.000Z",
        "voteCount": 1,
        "content": "A. AzCopy"
      },
      {
        "date": "2022-10-25T07:52:00.000Z",
        "voteCount": 1,
        "content": "Correct answer is A\nAzCopy is a command-line utility that you can use to copy blobs or files to or from a storage account"
      },
      {
        "date": "2022-08-29T01:02:00.000Z",
        "voteCount": 1,
        "content": "AzCopy"
      },
      {
        "date": "2022-08-27T07:34:00.000Z",
        "voteCount": 1,
        "content": "AzCopy is best option to move data around in blob storage"
      },
      {
        "date": "2022-06-18T03:10:00.000Z",
        "voteCount": 1,
        "content": "You will use AzCopy. It can be automated in a script, reducing user interaction and you can also recover"
      },
      {
        "date": "2022-06-10T02:42:00.000Z",
        "voteCount": 1,
        "content": "A is the correct answer.\nEverytime."
      },
      {
        "date": "2022-03-12T19:50:00.000Z",
        "voteCount": 2,
        "content": "Got it on 03/2022, I chose the A. AzCopy"
      },
      {
        "date": "2022-02-18T03:55:00.000Z",
        "voteCount": 3,
        "content": "AzCopy is the correct answer"
      },
      {
        "date": "2021-12-10T00:59:00.000Z",
        "voteCount": 1,
        "content": "https://docs.microsoft.com/en-us/azure/storage/common/storage-use-azcopy-configure\nAns: should be AzCopy. This link show you can recover the AzCopy from where it failed.\n\nazcopy jobs resume &lt;job-id&gt; --source-sas=\"&lt;sas-token&gt;\" --destination-sas=\"&lt;sas-token&gt;\"\nAzure Data Factory in the Azure portal may need much configuration by user to setup the pipeline to perform copy."
      },
      {
        "date": "2021-06-06T08:56:00.000Z",
        "voteCount": 6,
        "content": "got this in the exam :)"
      },
      {
        "date": "2021-06-13T04:51:00.000Z",
        "voteCount": 4,
        "content": "Then ? please suggest the correct answer?"
      },
      {
        "date": "2021-10-04T21:36:00.000Z",
        "voteCount": 1,
        "content": "A lot of these questions are common in the exam it seems."
      },
      {
        "date": "2021-05-20T06:25:00.000Z",
        "voteCount": 4,
        "content": "The Answer is correct!"
      },
      {
        "date": "2021-05-15T23:51:00.000Z",
        "voteCount": 3,
        "content": "correct"
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 12,
    "url": "https://www.examtopics.com/discussions/microsoft/view/49787-exam-az-204-topic-3-question-12-discussion/",
    "body": "DRAG DROP -<br>You are developing a web service that will run on Azure virtual machines that use Azure Storage. You configure all virtual machines to use managed identities.<br>You have the following requirements:<br>\u2711 Secret-based authentication mechanisms are not permitted for accessing an Azure Storage account.<br>\u2711 Must use only Azure Instance Metadata Service endpoints.<br>You need to write code to retrieve an access token to access Azure Storage. To answer, drag the appropriate code segments to the correct locations. Each code segment may be used once or not at all. You may need to drag the split bar between panes or scroll to view content.<br>NOTE: Each correct selection is worth one point.<br>Select and Place:<br><img src=\"/assets/media/exam-media/04273/0022700003.jpg\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04273/0022800001.jpg\" class=\"in-exam-image\">",
    "answerDescription": "Azure Instance Metadata Service endpoints \"/oauth2/token\"<br>Box 1: http://169.254.169.254/metadata/identity/oauth2/token<br>Sample request using the Azure Instance Metadata Service (IMDS) endpoint (recommended):<br>GET 'http://169.254.169.254/metadata/identity/oauth2/token?api-version=2018-02-01&amp;resource=https://management.azure.com/' HTTP/1.1 Metadata: true<br>Box 2: JsonConvert.DeserializeObject&lt;Dictionary&lt;string,string&gt;&gt;(payload);<br>Deserialized token response; returning access code.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/active-directory/managed-identities-azure-resources/how-to-use-vm-token https://docs.microsoft.com/en-us/azure/service-fabric/how-to-managed-identity-service-fabric-app-code",
    "votes": [],
    "comments": [
      {
        "date": "2021-05-30T05:58:00.000Z",
        "voteCount": 66,
        "content": "Box 1: http://169.254.169.254/metadata/identity/oauth2/token\nSample request using the Azure Instance Metadata Service (IMDS) endpoint (recommended):\nGET 'http://169.254.169.254/metadata/identity/oauth2/token?api-version=2018-02-01&amp;resource=https://management.azure.com/' HTTP/1.1 Metadata: true\n\nBox 2: JsonConvert.DeserializeObject&lt;Dictionary&lt;string,string&gt;&gt;(payload);\nDeserialized token response; returning access code.\n\n\nReference:\n\nhttps://docs.microsoft.com/en-us/azure/active-directory/managed-identities-azure-resources/how-to-use-vm-token\n\nhttps://docs.microsoft.com/en-us/azure/service-fabric/how-to-managed-identity-service-fabric-app-code"
      },
      {
        "date": "2022-08-18T23:15:00.000Z",
        "voteCount": 7,
        "content": "IMDS is a REST API that's available at a well-known, non-routable IP address ( 169.254.169.254 ). You can only access it from within the VM.\nhttps://docs.microsoft.com/en-us/azure/virtual-machines/windows/instance-metadata-service?tabs=windows"
      },
      {
        "date": "2023-02-24T10:49:00.000Z",
        "voteCount": 2,
        "content": "Powerful Words And The Magic Of Abracadabra :)"
      },
      {
        "date": "2024-01-02T05:05:00.000Z",
        "voteCount": 3,
        "content": "Got this today.\nWent with answer here.\nScore 927"
      },
      {
        "date": "2023-09-19T21:24:00.000Z",
        "voteCount": 16,
        "content": "I got this same question. Provided answers are correct. (Note: I failed the exam 20/9/23. I only scored 644 and I felt bad. I think because many questions here in Examtopics are not accurate. I suggest following the most voted answers and don't just not rely on Examtopics answers. At the beginning of the exam, you will be asked which programming languages you want to use. C#/Python. I chose C#. Also, I just want to add that some questions here are really in the actual exams, but the choices are written and formatted differently. Please be aware of that. Goodluck. I feel bad for failing it, but I want to retake next month. I will try Python. T_T"
      },
      {
        "date": "2024-08-10T19:30:00.000Z",
        "voteCount": 2,
        "content": "Man I respect you for the fact that you are the only one commenting, with honest, that you failed the exam, obviously all other people (or bots) got 925 points and passed the exam. \nAll the best and wish you passed the second attempt :D"
      },
      {
        "date": "2024-03-28T04:10:00.000Z",
        "voteCount": 1,
        "content": "Hey man, heads up! 644 is a decent score I'd say. Did you pass the test the 2nd time? :)"
      },
      {
        "date": "2023-08-31T01:16:00.000Z",
        "voteCount": 2,
        "content": "Correct!\nhttps://learn.microsoft.com/en-us/azure/active-directory/managed-identities-azure-resources/how-to-use-vm-token"
      },
      {
        "date": "2023-08-30T02:08:00.000Z",
        "voteCount": 1,
        "content": "Got it in exam 28/08/23. Went with proposed answer. Scored 912"
      },
      {
        "date": "2023-08-20T07:58:00.000Z",
        "voteCount": 1,
        "content": "Answer is correct!"
      },
      {
        "date": "2023-07-06T02:43:00.000Z",
        "voteCount": 3,
        "content": "This was on the exam (July 2023). Went with proposed. Scored 917"
      },
      {
        "date": "2023-07-06T02:42:00.000Z",
        "voteCount": 1,
        "content": "This was on the exam (July 2023). Went with proposed. Scored 917"
      },
      {
        "date": "2023-04-04T20:59:00.000Z",
        "voteCount": 4,
        "content": "Got this in exam today (5 April 2023)"
      },
      {
        "date": "2023-02-13T06:01:00.000Z",
        "voteCount": 6,
        "content": "It was there in 13 Feb 2023 exam"
      },
      {
        "date": "2022-10-20T02:22:00.000Z",
        "voteCount": 1,
        "content": "I was taught to use $IDENTITY_ENDPOINT but indeed that always seems to refer to the 169.254.169.254 address"
      },
      {
        "date": "2022-06-18T08:05:00.000Z",
        "voteCount": 2,
        "content": "I get confused because of the IP, I get we shouldn't go for the local one, but why is this an AIPIPA IP adress?\n\nis there a reason for that?"
      },
      {
        "date": "2022-04-20T02:23:00.000Z",
        "voteCount": 2,
        "content": "Got this on 20 Apr 2022"
      },
      {
        "date": "2021-06-26T22:31:00.000Z",
        "voteCount": 5,
        "content": "BOX1 - http://169.254.169.254/metadata/identity/oauth2/token  ,To get the metadata from the local service on the machine, the right URL is http://169.254.169.254/metadata/identity/oauth2/token \n\nBOX2 \u2013 JsonConvert.DeserializeObject&lt;string,string&gt;(payload) \n\nYou can deserialize the response using the JsonConvert.DeserializeObject method. You can then get a dictionary collection and then get the access key from there."
      },
      {
        "date": "2021-06-24T15:36:00.000Z",
        "voteCount": 2,
        "content": "Correct"
      },
      {
        "date": "2021-05-20T06:31:00.000Z",
        "voteCount": 2,
        "content": "Correct ! =&gt; https://docs.microsoft.com/fr-fr/azure/active-directory/managed-identities-azure-resources/how-to-use-vm-token"
      },
      {
        "date": "2021-05-15T23:53:00.000Z",
        "voteCount": 2,
        "content": "correct"
      },
      {
        "date": "2021-04-15T15:36:00.000Z",
        "voteCount": 12,
        "content": "It is correct.\nhttps://docs.microsoft.com/en-us/azure/active-directory/managed-identities-azure-resources/how-to-use-vm-token"
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 13,
    "url": "https://www.examtopics.com/discussions/microsoft/view/36279-exam-az-204-topic-3-question-13-discussion/",
    "body": "DRAG DROP -<br>You are developing a new page for a website that uses Azure Cosmos DB for data storage. The feature uses documents that have the following format:<br><img src=\"/assets/media/exam-media/04273/0022900001.png\" class=\"in-exam-image\"><br>You must display data for the new page in a specific order. You create the following query for the page:<br><img src=\"/assets/media/exam-media/04273/0022900002.png\" class=\"in-exam-image\"><br>You need to configure a Cosmos DB policy to support the query.<br>How should you configure the policy? To answer, drag the appropriate JSON segments to the correct locations. Each JSON segment may be used once, more than once, or not at all. You may need to drag the split bar between panes or scroll to view content.<br>NOTE: Each correct selection is worth one point.<br>Select and Place:<br><img src=\"/assets/media/exam-media/04273/0023000001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04273/0023100001.png\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: compositeIndexes -<br>You can order by multiple properties. A query that orders by multiple properties requires a composite index.<br><br>Box 2: descending -<br>Example: Composite index defined for (name ASC, age ASC):<br>It is optional to specify the order. If not specified, the order is ascending.<br>{<br>\"automatic\":true,<br>\"indexingMode\":\"Consistent\",<br>\"includedPaths\":[<br>{<br>\"path\":\"/*\"<br>}<br>],<br>\"excludedPaths\":[],<br>\"compositeIndexes\":[<br>[<br>{<br>\"path\":\"/name\",<br>},<br>{<br>\"path\":\"/age\",<br>}<br>]<br>]<br>}",
    "votes": [],
    "comments": [
      {
        "date": "2020-11-16T01:57:00.000Z",
        "voteCount": 90,
        "content": "ORDER BY queries on multiple properties:\n    The composite index also supports an ORDER BY clause with the opposite order on all paths.\n\nSo I think it's about reversed index to the query. Answer should be 'ascending'. You cannot support ASC (default), DESC query with DESC, DESC index."
      },
      {
        "date": "2023-07-12T09:39:00.000Z",
        "voteCount": 2,
        "content": "No. It supports, but it is not required. You can have (ASC, ASC), (DESC, DESC), (ASC, DESC), (DESC, ASC). So the answer is Descending"
      },
      {
        "date": "2024-04-28T00:50:00.000Z",
        "voteCount": 2,
        "content": "answer is not descending"
      },
      {
        "date": "2021-12-07T06:13:00.000Z",
        "voteCount": 33,
        "content": "The problem here is the SQL that makes many people think that\n\"ORDER BY p.name, p.city DESC\"\nmeans it's ordered by name and city both descending.\nBut the DESC only applies to city. name is ASC - this would be less confusing:\n\"ORDER BY p.name ASC, p.city DESC\"\n\nThus in the JSON you can only state ascending+descending or the opposite: descending+ascending.\nSince descending for name is already set the answer is \"ascending\".\n\nAt first I had misread the SQL wrong myself and didn't understand kayleena's comment right away."
      },
      {
        "date": "2024-01-24T07:14:00.000Z",
        "voteCount": 2,
        "content": "I just tried it.\n\n1) Using Indexing Policy (name -&gt; descending, city -&gt; descending) gives an error:\n\"The order by query does not have a corresponding composite index that it can be served from.\"\n2) Using Indexing Policy (name -&gt; descending, city -&gt; ascending) works correcly, lists items.\n\nSo yes, people above have right.\n- ASC is default for name, so query is equivalent to: \nSELECT * FROM People p ORDER BY p.name ASC, p.city DESC\n- \"The composite index also supports an ORDER BY clause with the opposite order on all paths.\" \nhttps://learn.microsoft.com/en-us/azure/cosmos-db/index-policy#order-by-queries-on-multiple-properties"
      },
      {
        "date": "2020-11-06T10:30:00.000Z",
        "voteCount": 34,
        "content": "\"name\" field should be marked ascending (default if not specified). It's mislabeled"
      },
      {
        "date": "2020-11-17T08:25:00.000Z",
        "voteCount": 15,
        "content": "I think so. The answer is correct, but the name field should be marked ascending(default).\nWe can find an example in the following link.\nhttps://docs.microsoft.com/en-us/azure/cosmos-db/how-to-manage-indexing-policy?tabs=dotnetv2%2Cpythonv3\nhttps://docs.microsoft.com/en-us/azure/cosmos-db/how-to-manage-indexing-policy?tabs=dotnetv2%2Cpythonv3"
      },
      {
        "date": "2023-02-24T11:31:00.000Z",
        "voteCount": 1,
        "content": "The client wants to walk with his back to the front. Who are we to tell him what to do?"
      },
      {
        "date": "2021-02-12T10:54:00.000Z",
        "voteCount": 31,
        "content": "NO. Box 2 is \"ascending\"\nSee explanation here: \nhttps://docs.microsoft.com/en-us/azure/cosmos-db/index-policy#order-by-queries-on-multiple-properties\n\"The composite index also supports an ORDER BY clause with the __opposite order on all paths__.\"\nThe table in the section also shows an example similar to this question."
      },
      {
        "date": "2022-03-24T07:20:00.000Z",
        "voteCount": 2,
        "content": "the table also seems to suggest DESC followed by ASC is not supported by composite index? Confused"
      },
      {
        "date": "2022-03-24T07:32:00.000Z",
        "voteCount": 1,
        "content": "Looking again i think it refers to \" What it will not support is non-matching clauses. if ASC, ASC or DESC, DESC will not match our question.\" as mentioned by edengoforit.\nHas to be opposites to make any sense."
      },
      {
        "date": "2022-09-20T03:13:00.000Z",
        "voteCount": 1,
        "content": "I agree with you. For example index on (A asc, B asc) works for queries with ORDER BY (A asc, B asc) and (A desc, B desc).\nNot working with ORDER BY (A asc, B desc), (A desc, B asc) or even (B asc, A asc)."
      },
      {
        "date": "2023-07-12T09:30:00.000Z",
        "voteCount": 1,
        "content": "No. Box 2 is Descending"
      },
      {
        "date": "2024-09-03T15:38:00.000Z",
        "voteCount": 1,
        "content": "{\n  \"indexingPolicy\": {\n    \"compositeIndexes\": [\n       {\n          \"path\": \"/name\",\n          \"order\": \"ascending\"\n       },\n       {\n          \"path\": \"/city\",\n          \"order\": \"descending\"\n       }\n    ]\n  }\n}"
      },
      {
        "date": "2024-04-28T00:50:00.000Z",
        "voteCount": 6,
        "content": "Got it on 20 April 2024...Marks &gt; 900...All questions from examtopics 400 questions...\n\nThis questions came in 3 exams me and my friend gave....and don't get confused with answer\n\nIt is\nComposite indexes\nascending\nas some people in comment have explained..\ndescending doesn't go....scored very good marks based on these answers"
      },
      {
        "date": "2024-02-22T07:13:00.000Z",
        "voteCount": 1,
        "content": "Composite Index\t      Sample ORDER BY Query\t             Supported by Composite Index?\n(name ASC, age ASC)\tSELECT * FROM c ORDER BY c.name ASC, c.age asc\t      Yes\n(name ASC, age ASC)\tSELECT * FROM c ORDER BY c.age ASC, c.name asc \t       No\n(name ASC, age ASC)\tSELECT * FROM c ORDER BY c.name DESC, c.age DESC\t      Yes\n\nThe 1st and 3rd lines have opposite order-by value, but the composite index (name ASC, age ASC) still supports them.\nThe value for city should be ascending."
      },
      {
        "date": "2023-12-18T19:16:00.000Z",
        "voteCount": 1,
        "content": "Got that question on my exam DEC 18. went with given answer. scored 842. CAse Study : Van Arsdel inc."
      },
      {
        "date": "2023-11-26T17:49:00.000Z",
        "voteCount": 3,
        "content": "The only way to confirm the answer is to try it out.\n\n\"ascending\" is the correct answer.\n\n\"descending\" - will result to \"Message: {\"Errors\":[\"The order by query does not have a corresponding composite index that it can be served \""
      },
      {
        "date": "2023-11-17T09:16:00.000Z",
        "voteCount": 4,
        "content": "Just tested with proposed answer. If you run the query you will get the following error:\n{\"Errors\":[\"The order by query does not have a corresponding composite index that it can be served from.\"]}\n\nIf you instead use \"ascending\" as the top voted answer here suggest, the query passes.\nSo correct answer is:\n1. compositeIndexes\n2. ascending"
      },
      {
        "date": "2023-11-08T23:34:00.000Z",
        "voteCount": 2,
        "content": "On exam 9 Nov 2023, went with given answer, socre 865. Case Study: Farmers and Distributors"
      },
      {
        "date": "2023-11-03T07:45:00.000Z",
        "voteCount": 2,
        "content": "On exam 3-Nov-2023. Selected:\n1) compositeIndexes\n2) descending"
      },
      {
        "date": "2023-09-28T13:01:00.000Z",
        "voteCount": 2,
        "content": "Got on 9/25/2023\ncompositeindexes\nascending"
      },
      {
        "date": "2023-09-25T09:18:00.000Z",
        "voteCount": 1,
        "content": "Got this quesiton in examn - 2023.09.25. Got Case Study Contoso"
      },
      {
        "date": "2023-08-30T02:08:00.000Z",
        "voteCount": 1,
        "content": "Got it in exam 28/08/23. Went with proposed answer. Scored 912"
      },
      {
        "date": "2023-08-10T18:07:00.000Z",
        "voteCount": 1,
        "content": "Got this one on 2023-08-08"
      },
      {
        "date": "2023-07-30T07:19:00.000Z",
        "voteCount": 3,
        "content": "got this question today, answer compositeIndex, descending - 7/30/2023, score 895/1000"
      },
      {
        "date": "2023-07-25T20:33:00.000Z",
        "voteCount": 1,
        "content": "Had this question today: 2023-07-26"
      },
      {
        "date": "2023-07-06T02:43:00.000Z",
        "voteCount": 3,
        "content": "This was on the exam (July 2023). Went with proposed (city should be \"asc\"). Scored 917"
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 14,
    "url": "https://www.examtopics.com/discussions/microsoft/view/36722-exam-az-204-topic-3-question-14-discussion/",
    "body": "HOTSPOT -<br>You are building a traffic monitoring system that monitors traffic along six highways. The system produces time series analysis-based reports for each highway.<br>Data from traffic sensors are stored in Azure Event Hub.<br>Traffic data is consumed by four departments. Each department has an Azure Web App that displays the time series-based reports and contains a WebJob that processes the incoming data from Event Hub. All Web Apps run on App Service Plans with three instances.<br>Data throughput must be maximized. Latency must be minimized.<br>You need to implement the Azure Event Hub.<br>Which settings should you use? To answer, select the appropriate options in the answer area.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04273/0023300001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04273/0023400001.png\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: 6 -<br>The number of partitions is specified at creation and must be between 2 and 32.<br>There are 6 highways.<br><br>Box 2: Highway -<br>Reference:<br>https://docs.microsoft.com/en-us/azure/event-hubs/event-hubs-features",
    "votes": [],
    "comments": [
      {
        "date": "2020-12-03T09:12:00.000Z",
        "voteCount": 136,
        "content": "Partitions relate to producers - and the logical way to partition the incoming data is by the only value you have at that point, the highway name/id. So the selected answer is correct (6 Partitions, by Highway).\n\nPeople are getting confused by the departments which would actually each be an event consumer with an associated Consumer Group which would have it's own isolated view of each of the highway partitions."
      },
      {
        "date": "2021-10-08T00:21:00.000Z",
        "voteCount": 2,
        "content": "One thought...\nThe assignment mentions \"Partition Key\" (not \"Partition Id\").\n\n\"Producers can provide a value for the event key. When they do, a hashing-based partitioner determines a hash value from the key. The event then goes to the partition associated with that hash value.\"\nhttps://docs.microsoft.com/en-us/azure/architecture/reference-architectures/event-hubs/partitioning-in-event-hubs-and-kafka#distribute-events-to-partitions\n\nSo it is possible for 2 or more highways to be - by a chance - hashed to a single partition leaving 1 or more partitions idle at all. If really unlucky then all 6 highways would be hashed to one partition.\n\nThe very same situation is with Highway, Department and VM name used as the \"Partition Key\" as they are discrete values (6 highways, 4 departments, N virtual machines). The Timestamp could do a better job - but \"spraying\" data from one highway across all partitions...\n\nThe best job could do \"Partition Id\".\n\"Producers can specify a partition ID with an event. The event then goes to the partition with that ID.\" So each highway could get hardcoded its own partition preserving order of the data."
      },
      {
        "date": "2021-11-30T13:22:00.000Z",
        "voteCount": 1,
        "content": "I guess you're right, although losing maximum availability."
      },
      {
        "date": "2022-08-25T09:13:00.000Z",
        "voteCount": 2,
        "content": "If we have 4 groups of consumers and each consumer group, according to the theory, reads independently and isolated from the rest, highways and 6 partitions makes a lot of sense"
      },
      {
        "date": "2021-07-02T11:40:00.000Z",
        "voteCount": 9,
        "content": "https://docs.microsoft.com/en-us/azure/event-hubs/event-hubs-faq\nThe number of partitions in an event hub directly relates to the number of concurrent readers you expect to have"
      },
      {
        "date": "2021-11-30T13:26:00.000Z",
        "voteCount": 2,
        "content": "If you read the features page you'll understand that this is not the simple answer to the question. https://docs.microsoft.com/en-us/azure/event-hubs/event-hubs-features\nEvent receivers organised in consumer groups read all partitions. Via a leasing mechanism the receiver within a consumer group can make sure they don't read duplicate data.\nPartitions are more related to Event producers (can be 1-on-1)"
      },
      {
        "date": "2022-02-26T06:41:00.000Z",
        "voteCount": 2,
        "content": "it's a best practice for publishers(producers) to remain unaware of the specific partitioning model chosen for an event hub and to only specify a partition key that is used to consistently assign related events to the same partition."
      },
      {
        "date": "2022-02-26T07:07:00.000Z",
        "voteCount": 1,
        "content": "oh nevermind, I guess it would be most effective when partitions num matches the producers num."
      },
      {
        "date": "2020-11-26T08:59:00.000Z",
        "voteCount": 43,
        "content": "The answer should be 4 and Highway. \nExam Topics - Please provide correct answers. What is the use of buying questions on your site...if you are not sure of the answer yourself"
      },
      {
        "date": "2021-04-13T00:45:00.000Z",
        "voteCount": 2,
        "content": "But theres 6 highways, so why not 6 partitions?"
      },
      {
        "date": "2021-04-14T17:40:00.000Z",
        "voteCount": 2,
        "content": "There are 4 consumers.\nPartitions are a data organization mechanism that relates to the downstream parallelism required in consuming applications. The number of partitions in an event hub directly relates to the number of concurrent readers you expect to have.\nhttps://docs.microsoft.com/en-us/azure/event-hubs/event-hubs-faq"
      },
      {
        "date": "2021-05-02T02:36:00.000Z",
        "voteCount": 6,
        "content": "But each department has 3 instances of the Web App/Job. So isn't there 12 consumers?"
      },
      {
        "date": "2023-02-24T12:41:00.000Z",
        "voteCount": 1,
        "content": "\"The event publisher is only aware of its partition key, not the partition to which the events are published. This decoupling of key and partition insulates the sender from needing to know too much about the downstream processing. A per-device or user unique identity makes a good partition key, but other attributes such as geography can also be used to group related events into a single partition.\n\nSpecifying a partition key enables keeping related events together in the same partition and in the exact order in which they arrived. The partition key is some string that is derived from your application context and identifies the interrelationship of the events. A sequence of events identified by a partition key is a stream. A partition is a multiplexed log store for many such streams.\""
      },
      {
        "date": "2022-01-22T18:22:00.000Z",
        "voteCount": 1,
        "content": "https://www.linkedin.com/pulse/azure-event-hub-understanding-designing-partitions-unit-kamal-pathak"
      },
      {
        "date": "2021-04-28T04:19:00.000Z",
        "voteCount": 11,
        "content": "There are 6 highways and 6 reports.  Each department only needs to read one partition to produce their report on that one highway.  If you had 4 partitions you would have to duplicate all the data 4 times (BAD) and then each department would need to read all the data and filter the data for one report (VERY BAD)."
      },
      {
        "date": "2021-05-02T04:36:00.000Z",
        "voteCount": 3,
        "content": "When you create the Hub it does not know either the Departments or the VMs"
      },
      {
        "date": "2024-07-24T04:48:00.000Z",
        "voteCount": 2,
        "content": "copilot : 6 and Highway"
      },
      {
        "date": "2024-02-22T06:46:00.000Z",
        "voteCount": 1,
        "content": "If your partition key is highway, no way your number can be 12. Only when your partition key is department, you can put 12 instances. \nEven chatgpt and bard are proposing both aproaches but propose scailing it to the consumer side.\nAfter long consideration, I sitl think highway and 6 instances is correct."
      },
      {
        "date": "2023-11-21T06:37:00.000Z",
        "voteCount": 1,
        "content": "When a client application sends events to an event hub without specifying a partition, events are automatically distributed among partitions in your event hub. If a partition isn't available for some reason, events are distributed among the remaining partitions. This behavior allows for the greatest amount of up time. For use cases that require the maximum up time, this model is preferred instead of sending events to a specific partition.\n\nSo maybe 12 &amp; VM?\n\nhttps://learn.microsoft.com/en-us/azure/event-hubs/event-hubs-availability-and-consistency?tabs=dotnet#availability"
      },
      {
        "date": "2023-11-14T05:02:00.000Z",
        "voteCount": 1,
        "content": "Partition key: \nHighway (Partitions relate to producers) You should not base your data on the architecture this is not scalable\n\nPartitions: (Hub partitions not data partition this last are implicit by the Highway Partition key)\n12\nPartitioning allows for multiple parallel logs to be used for the same event hub and therefore multiplying the available raw IO throughput capacity.\nhttps://learn.microsoft.com/en-us/azure/event-hubs/event-hubs-features#advantages-of-using-partitions\n\nMapping of events to partitions\nThe event publisher is only aware of its partition key, not the partition to which the events are published. This decoupling of key and partition insulates the sender from needing to know too much about the downstream processing. A per-device or user unique identity makes a good partition key...\nhttps://learn.microsoft.com/en-us/azure/event-hubs/event-hubs-features#number-of-partitions\n\nThen in each VM the webjob can split the processes in batches using the Highway to speed up the query."
      },
      {
        "date": "2023-03-28T18:02:00.000Z",
        "voteCount": 1,
        "content": "6 and highway chatGPT"
      },
      {
        "date": "2023-08-20T08:11:00.000Z",
        "voteCount": 1,
        "content": "Lol , i asked ChatGPT and it said 12. 4 departments * 3 instances = 12 partitionkey needed"
      },
      {
        "date": "2023-02-11T17:40:00.000Z",
        "voteCount": 1,
        "content": "12 (4*3) physical partitions; timestamp as partition key"
      },
      {
        "date": "2023-02-09T08:41:00.000Z",
        "voteCount": 1,
        "content": "The number of partitions to use in Azure Event Hub depends on the desired level of parallelism and the expected ingress rate. For maximum data throughput, you would want to use as many partitions as possible. Each partition allows for a separate stream of events to be processed in parallel, increasing the ingress rate. On the other hand, having too many partitions can lead to increased latency, as the events must be divided among the partitions\n\nAnswer is 12.\n\nThe partition key is a value that determines which partition an event should be sent to. The events with the same partition key are guaranteed to be ordered and processed by the same partition. In a traffic monitoring system, the partition key could be related to the highway being monitored.\n\nAnswer is highway."
      },
      {
        "date": "2022-11-28T12:31:00.000Z",
        "voteCount": 1,
        "content": "https://learn.microsoft.com/en-us/azure/event-hubs/event-hubs-features\n\"Your own applications must be able to keep up with processing the volume of events that are being sent into an event hub\"\nIn our case events are highway reports (6). 4 applications are consumers.\n6 is correct."
      },
      {
        "date": "2022-11-19T06:24:00.000Z",
        "voteCount": 1,
        "content": "selected answer is correct"
      },
      {
        "date": "2022-10-15T05:26:00.000Z",
        "voteCount": 2,
        "content": "Number of partitions \u2013 6 \u2013 selected because there are 6 highways.\nPartition Key \u2013 Highway \u2013 map the incoming events into specific partition. Partition-Key is sender supplied value passed into event-hub. \nhttps://learn.microsoft.com/en-us/azure/event-hubs/event-hubs-features#partitions"
      },
      {
        "date": "2022-04-21T01:34:00.000Z",
        "voteCount": 4,
        "content": "got this on exam"
      },
      {
        "date": "2022-04-20T02:24:00.000Z",
        "voteCount": 3,
        "content": "Got this on 20 Apr 2022"
      },
      {
        "date": "2022-04-12T23:05:00.000Z",
        "voteCount": 1,
        "content": "Thinking this is about how to choose partions when there's an ordered delivery requirement. The question states 'The system produces time series analysis-based reports for each highway' and there's six highways.\n\nEvent Hubs ensures that all events sharing a partition key value are stored together and delivered in order of arrival. So if 6 partitions are selected then the consumers can read the events in order and create the time series reports.\n\nRef. https://docs.microsoft.com/en-us/azure/event-hubs/event-hubs-features#publishing-an-event"
      },
      {
        "date": "2022-03-15T10:37:00.000Z",
        "voteCount": 2,
        "content": "Partitions - 4,  because there are 4 departments. Partitioning is about slicing data for concurrent reading, it has nothing to do with duplication of data, like some silly \"explanations\" below. \n\nThe partition key should be the Highway because that will be your main filter when creating your reports and is also a good identifier for the event source."
      },
      {
        "date": "2021-12-21T23:38:00.000Z",
        "voteCount": 1,
        "content": "To partition we will depends on the producer which is highways,\nfor consumers(Applications) we will use 4 \"consumer groups\" ,one consumer group for each application ,so each App will have his specific view for the data,each consumer group will include 3 instances of the app, no more than one instance from the same consumer group can share the same portion at the same time.\nSo since we will have 6 consumer groups ,then we can assign 2 portions for each instance"
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 15,
    "url": "https://www.examtopics.com/discussions/microsoft/view/36645-exam-az-204-topic-3-question-15-discussion/",
    "body": "DRAG DROP -<br>You are developing a microservices solution. You plan to deploy the solution to a multinode Azure Kubernetes Service (AKS) cluster.<br>You need to deploy a solution that includes the following features:<br>\u2711 reverse proxy capabilities<br>\u2711 configurable traffic routing<br>\u2711 TLS termination with a custom certificate<br>Which components should you use? To answer, drag the appropriate components to the correct requirements. Each component may be used once, more than once, or not at all. You may need to drag the split bar between panes or scroll to view content.<br>NOTE: Each correct selection is worth one point.<br>Select and Place:<br><img src=\"/assets/media/exam-media/04273/0023500004.jpg\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04273/0023600001.jpg\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: Helm -<br>To create the ingress controller, use Helm to install nginx-ingress.<br><br>Box 2: kubectl -<br>To find the cluster IP address of a Kubernetes pod, use the kubectl get pod command on your local machine, with the option -o wide .<br><br>Box 3: Ingress Controller -<br>An ingress controller is a piece of software that provides reverse proxy, configurable traffic routing, and TLS termination for Kubernetes services. Kubernetes ingress resources are used to configure the ingress rules and routes for individual Kubernetes services.<br>Incorrect Answers:<br>Virtual Kubelet: Virtual Kubelet is an open-source Kubernetes kubelet implementation that masquerades as a kubelet. This allows Kubernetes nodes to be backed by Virtual Kubelet providers such as serverless cloud container platforms.<br>CoreDNS: CoreDNS is a flexible, extensible DNS server that can serve as the Kubernetes cluster DNS. Like Kubernetes, the CoreDNS project is hosted by the<br>CNCF.<br>Reference:<br>https://docs.microsoft.com/bs-cyrl-ba/azure/aks/ingress-basic https://www.digitalocean.com/community/tutorials/how-to-inspect-kubernetes-networking",
    "votes": [],
    "comments": [
      {
        "date": "2021-05-30T04:56:00.000Z",
        "voteCount": 73,
        "content": "Box 1: Helm\nHelm helps you manage Kubernetes applications \u2014 Helm Charts help you define, install, and upgrade even the most complex Kubernetes application. To create the ingress controller, use Helm to install nginx-ingress.\n\nBox 2: Kubectl\nThe Kubernetes command-line tool, kubectl, allows you to run commands against Kubernetes clusters. To find the cluster IP address of a Kubernetes pod, use the kubectl get pod command on your local machine, with the option -o wide .\n\nBox 3: Ingress Controller\nAn ingress controller is a piece of software that provides reverse proxy, configurable traffic routing, and TLS termination for Kubernetes services. Kubernetes ingress resources are used to configure the ingress rules and routes for individual Kubernetes services. Using an ingress controller and ingress rules, a single IP address can be used to route traffic to multiple services in a Kubernetes cluster."
      },
      {
        "date": "2022-04-03T21:14:00.000Z",
        "voteCount": 10,
        "content": "Correct, I am a certified CKA und CKAD. The question isn't that well written though as you could also deploy a solution with kubectl..."
      },
      {
        "date": "2021-05-30T04:56:00.000Z",
        "voteCount": 9,
        "content": "Reference:\n\nhttps://helm.sh\n\nhttps://kubernetes.io/docs/tasks/tools\n\nhttps://kubernetes.io/docs/concepts/services-networking/ingress-controllers\n\nhttps://docs.microsoft.com/bs-cyrl-ba/azure/aks/ingress-basic\n\nhttps://www.digitalocean.com/community/tutorials/how-to-inspect-kubernetes-networking"
      },
      {
        "date": "2020-11-10T01:59:00.000Z",
        "voteCount": 19,
        "content": "I believe there is no AKS question in the exam:\nhttps://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE4oZ7B"
      },
      {
        "date": "2021-02-07T17:28:00.000Z",
        "voteCount": 4,
        "content": "I've also seen a lot of people mentioned in facebook groups they got kubernetes questions on the real exam az-204"
      },
      {
        "date": "2022-03-24T08:27:00.000Z",
        "voteCount": 1,
        "content": "I'm pretty sure I got this question on the exam, they be messin' with us"
      },
      {
        "date": "2020-11-25T12:53:00.000Z",
        "voteCount": 6,
        "content": "Haven't done the exam yet, but found many comments (eg. on Udemy tutorials) that Kuberentes actually IS part of the exam."
      },
      {
        "date": "2020-12-09T04:36:00.000Z",
        "voteCount": 4,
        "content": "It's not: https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE4oZ7B\n\"Azure Kubernetes Service (AKS) is out of scope\""
      },
      {
        "date": "2021-02-22T10:18:00.000Z",
        "voteCount": 1,
        "content": "I also thought AKS was excluded but people say they have had AKS questions in the exam. I don't understand why they would want to exclude it."
      },
      {
        "date": "2020-12-22T14:07:00.000Z",
        "voteCount": 7,
        "content": "And yet, here we are with this question. I'm guessing it has appeared in the exam and hence here. I am wondering what's actually \"excluded\" from Azure in this weird exam. Can't say it for many, but this one is a poorly constructed exam."
      },
      {
        "date": "2024-03-11T09:20:00.000Z",
        "voteCount": 2,
        "content": "Kubernetes is no longer covered in the exam"
      },
      {
        "date": "2023-12-23T15:33:00.000Z",
        "voteCount": 1,
        "content": "It is correct."
      },
      {
        "date": "2023-02-19T21:02:00.000Z",
        "voteCount": 7,
        "content": "out-of-the-scope for the AZ-204 Exam; please remove from the Question Bank"
      },
      {
        "date": "2023-08-20T08:16:00.000Z",
        "voteCount": 4,
        "content": "Microsoft doesn't give a f about the scope. Better safe than sorry!"
      },
      {
        "date": "2022-09-29T19:58:00.000Z",
        "voteCount": 2,
        "content": "Box 1: Kubectl or Helm"
      },
      {
        "date": "2021-06-20T05:49:00.000Z",
        "voteCount": 5,
        "content": "It is correct.\nHelm\nKubeCtl\nIngress\nsimple as that."
      },
      {
        "date": "2021-05-23T06:49:00.000Z",
        "voteCount": 8,
        "content": "Answer seems legit, but it's weird getting Kubernetes questions, when AKS is out of the scope of the exam."
      },
      {
        "date": "2021-05-13T06:38:00.000Z",
        "voteCount": 1,
        "content": "correct."
      },
      {
        "date": "2021-05-13T01:27:00.000Z",
        "voteCount": 4,
        "content": "Answer:\n1.\tKubeCtl or Helm\n2.\tKubeCtl\n3.\tIngress Controller"
      },
      {
        "date": "2021-04-09T08:00:00.000Z",
        "voteCount": 7,
        "content": "Just took this test last week (last week of March) AKS -- WAS IN FACT -- In the test."
      },
      {
        "date": "2021-04-20T02:24:00.000Z",
        "voteCount": 2,
        "content": "Is these questions still valid? I'm taking the exam this week can I depend on these?? please answer me"
      },
      {
        "date": "2021-04-01T04:51:00.000Z",
        "voteCount": 4,
        "content": "helm and kubectl can both be used to deploy."
      },
      {
        "date": "2021-02-07T20:44:00.000Z",
        "voteCount": 2,
        "content": "Answer is right"
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 16,
    "url": "https://www.examtopics.com/discussions/microsoft/view/37038-exam-az-204-topic-3-question-16-discussion/",
    "body": "DRAG DROP -<br>You are implementing an order processing system. A point of sale application publishes orders to topics in an Azure Service Bus queue. The Label property for the topic includes the following data:<br><img src=\"/assets/media/exam-media/04273/0023700001.png\" class=\"in-exam-image\"><br>The system has the following requirements for subscriptions:<br><img src=\"/assets/media/exam-media/04273/0023700002.png\" class=\"in-exam-image\"><br>You need to implement filtering and maximize throughput while evaluating filters.<br>Which filter types should you implement? To answer, drag the appropriate filter types to the correct subscriptions. Each filter type may be used once, more than once, or not at all. You may need to drag the split bar between panes or scroll to view content.<br>NOTE: Each correct selection is worth one point.<br>Select and Place:<br><img src=\"/assets/media/exam-media/04273/0023800001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04273/0023900001.png\" class=\"in-exam-image\">",
    "answerDescription": "FutureOrders: SQLFilter -<br>HighPriortyOrders: CorrelationFilter<br><br>CorrelationID only -<br><br>InternationalOrders: SQLFilter -<br>Country NOT USA requires an SQL Filter<br><br>HighQuantityOrders: SQLFilter -<br>Need to use relational operators so an SQL Filter is needed.<br><br>AllOrders: No Filter -<br>SQL Filter: SQL Filters - A SqlFilter holds a SQL-like conditional expression that is evaluated in the broker against the arriving messages' user-defined properties and system properties. All system properties must be prefixed with sys. in the conditional expression. The SQL-language subset for filter conditions tests for the existence of properties (EXISTS), as well as for null-values (IS NULL), logical NOT/AND/OR, relational operators, simple numeric arithmetic, and simple text pattern matching with LIKE.<br>Correlation Filters - A CorrelationFilter holds a set of conditions that are matched against one or more of an arriving message's user and system properties. A common use is to match against the CorrelationId property, but the application can also choose to match against ContentType, Label, MessageId, ReplyTo,<br>ReplyToSessionId, SessionId, To, and any user-defined properties. A match exists when an arriving message's value for a property is equal to the value specified in the correlation filter. For string expressions, the comparison is case-sensitive. When specifying multiple match properties, the filter combines them as a logical<br>AND condition, meaning for the filter to match, all conditions must match.<br>Boolean filters - The TrueFilter and FalseFilter either cause all arriving messages (true) or none of the arriving messages (false) to be selected for the subscription.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/service-bus-messaging/topic-filters",
    "votes": [],
    "comments": [
      {
        "date": "2020-11-21T12:27:00.000Z",
        "voteCount": 145,
        "content": "I think that it should be \n-Correlation Filter (with the not existing value of any filed to avoid getting any message)\n-SQL filter (as we need  to get all high priority AND international orders, but for Correlation filter: A match exists when an arriving message's value for a property is equal to the value specified in the correlation filter and we need not equal) \n-SQL filter\n-SQL filter\n-No Filter"
      },
      {
        "date": "2021-05-17T06:05:00.000Z",
        "voteCount": 16,
        "content": "FutureOrder, not based on the property -&gt; Correlation Filter.\nAllOrders, it's clear.. no filter.\nThe rest is based on one or more properties --&gt; SQL filter\n\nI agree with @stylebc"
      },
      {
        "date": "2022-05-27T14:21:00.000Z",
        "voteCount": 1,
        "content": "How do you justify No Filter for All Orders when you need to take action?\n\nEach newly created topic subscription has an initial default subscription rule. If you don't explicitly specify a filter condition for the rule, the applied filter is the true filter that enables all messages to be selected into the subscription. The default rule has no associated annotation action\nhttps://docs.microsoft.com/en-us/azure/service-bus-messaging/topic-filters"
      },
      {
        "date": "2022-05-27T14:41:00.000Z",
        "voteCount": 1,
        "content": "Check this example with Action which is a requirement for AllOrders.\nhttps://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-filter-examples#net-example-for-creating-subscription-filters"
      },
      {
        "date": "2022-05-27T14:50:00.000Z",
        "voteCount": 2,
        "content": "FutureOrders should be SQLFilter as you can check with the condition on AuditedAt user's property or EnqueuedTimeUtc system property but that is required a greater than condition but correlation filter condition needs to be matched.\n\nCorrelation Filters - A CorrelationFilter holds a set of conditions that are matched against one or more of an arriving message's user and system properties.\nhttps://docs.microsoft.com/en-us/azure/service-bus-messaging/topic-filters"
      },
      {
        "date": "2022-05-27T14:27:00.000Z",
        "voteCount": 2,
        "content": "HighPriorityOrders: CorrelationFilter\nYou can apply to multiple system or user-defined properties and when multiple properties then filter combined them with AND logical operator.\n\nhttps://docs.microsoft.com/en-us/azure/service-bus-messaging/topic-filters\n\nCorrelation Filters - A CorrelationFilter holds a set of conditions that are matched against one or more of an arriving message's user and system properties. A common use is to match against the CorrelationId property, but the application can also choose to match against the following properties:\n\nContentType\nLabel\nMessageId\nReplyTo\nReplyToSessionId\nSessionId\nTo\nany user-defined properties.\nA match exists when an arriving message's value for a property is equal to the value specified in the correlation filter. For string expressions, the comparison is case-sensitive. When specifying multiple match properties, the filter combines them as a logical AND condition, meaning for the filter to match, all conditions must match."
      },
      {
        "date": "2020-11-19T02:55:00.000Z",
        "voteCount": 40,
        "content": "The Correct answers are:\nNo Filter\nCorreleation Filter\nSQL filter\nSQL filter\nSQL filter"
      },
      {
        "date": "2024-07-24T04:55:00.000Z",
        "voteCount": 1,
        "content": "no sense at all , you want future filters and do nothing? , you want all the orders and you apply filter?"
      },
      {
        "date": "2020-11-21T13:01:00.000Z",
        "voteCount": 3,
        "content": "Why a filter for all orders?"
      },
      {
        "date": "2020-11-25T21:43:00.000Z",
        "voteCount": 2,
        "content": "See the basic is subscription does not have filter then does not receive any data. And since all orders needs all the orders it should have SQL filter with 1=1 so that all orders are passed to it."
      },
      {
        "date": "2020-11-26T08:15:00.000Z",
        "voteCount": 24,
        "content": "https://docs.microsoft.com/en-us/azure/service-bus-messaging/topic-filters\n\"If you don't explicitly specify a filter condition for the rule, the applied filter is the true filter that enables all messages to be selected into the subscription.\""
      },
      {
        "date": "2021-02-05T13:59:00.000Z",
        "voteCount": 3,
        "content": "So.. The answer is correct."
      },
      {
        "date": "2021-05-11T06:28:00.000Z",
        "voteCount": 11,
        "content": "if no filter explicitly specified, the true filter will be assigned which enables ALL messages. So your comment is wrong and makes confused."
      },
      {
        "date": "2022-12-19T10:43:00.000Z",
        "voteCount": 2,
        "content": "I somewhat agree with this answer after going through lot of resources. The only thing that bothers me is answer for the first and last question.\nWhen you create a subscription by default a SQL filter is added which is 1=1 i.e. always evaluates to true.\nSo my source of confusion is how \"No Filter\" is treated. I have two interpretations either \"No Filter\" is we don't add any filter or the other is absence of a filter.\nMostly I believe it is treated as absence of a filter in which case the this answer looks correct."
      },
      {
        "date": "2021-02-13T16:36:00.000Z",
        "voteCount": 13,
        "content": "How do you justify Correlation Filter for HighPriorityOrders, when it involves Region &lt;&gt; US ?\nI think it should be SQL filter as well."
      },
      {
        "date": "2024-09-18T10:30:00.000Z",
        "voteCount": 1,
        "content": "Final Answer:\nFutureOrders: SQLFilter\nHighPriorityOrders: CorrelationFilter\nInternationalOrders: SQLFilter\nHighQuantityOrders: SQLFilter\nAllOrders: No Filter"
      },
      {
        "date": "2024-07-26T02:02:00.000Z",
        "voteCount": 1,
        "content": "copilot : \nfor futures ---&gt; correlation,\nhighpriority , internal , hightQuantity -------&gt; SQLFilter\nall --------------------&gt; no filter"
      },
      {
        "date": "2024-06-23T09:05:00.000Z",
        "voteCount": 1,
        "content": "1) SQL 1=0\n2) SQL\n3) SQL\n4) SQL \n5) No filter - takes all"
      },
      {
        "date": "2024-04-28T00:52:00.000Z",
        "voteCount": 6,
        "content": "Got it on 20 April 2024...Marks &gt; 900...All questions from examtopics 400 questions...\nwent with below answer based on the example given on microsoft learn....go with it...scored very good marks may be highest with these answers\n-SQL filter\n-Correlation Filter\n-SQL filter\n-SQL filter\n-No Filter"
      },
      {
        "date": "2024-03-21T13:35:00.000Z",
        "voteCount": 2,
        "content": "Given answer is correct."
      },
      {
        "date": "2024-01-22T01:03:00.000Z",
        "voteCount": 1,
        "content": "Missing the Boolean filter option in the possible answers. Because that would be the one to choose for the future order rule. Otherwise I think you can choose SQL filter or correlation filter for the future order by making the condition always filter out all messages.\nThe other ones I agree with the given answers."
      },
      {
        "date": "2023-12-24T16:53:00.000Z",
        "voteCount": 1,
        "content": "- No Filter\n- Correlation\n- Correlation\n- SQL Filter\n- SQL Filter"
      },
      {
        "date": "2023-11-29T10:37:00.000Z",
        "voteCount": 4,
        "content": "Just tested this in azure portal\n- No filter (if default sql 1=1 filter is removed) results in no messages\n- sql filter 1=0 can be used for same purpose\n- sql filter 1=1 will match everything and is the default when adding a subscription\nTherefore:\nNo filter\nSql (need to match hi pri AND international orders)\nSql\nSql\nSql (default 1=1)"
      },
      {
        "date": "2023-09-25T09:18:00.000Z",
        "voteCount": 3,
        "content": "Got this quesiton in examn, went with answer. - 2023.09.25. Got Case Study Contoso"
      },
      {
        "date": "2023-08-03T05:53:00.000Z",
        "voteCount": 2,
        "content": "It should be  SQL, Correlation, SQL, SQL and NO Filter"
      },
      {
        "date": "2023-07-30T07:21:00.000Z",
        "voteCount": 2,
        "content": "got this question today, go with answer - \nCorrelation\nCorrelation\nSQL\nSQL\nNo filter\n7/30/2023, score 895/1000"
      },
      {
        "date": "2023-07-25T20:37:00.000Z",
        "voteCount": 10,
        "content": "Had this question today: 2023-07-26\nI went: \n- Correlation Filter\n- SQL Filter\n- SQL Filter\n- SQL Filter\n- No Filter\nEvery question on the exam was on ExamTopics. I entered every recommended answer and got 940"
      },
      {
        "date": "2023-11-21T04:36:00.000Z",
        "voteCount": 3,
        "content": "How do you remember all 375 questions?"
      },
      {
        "date": "2023-03-24T02:30:00.000Z",
        "voteCount": 2,
        "content": "CorrelationFilter\nSqlFilter\nSqlFilter\nSqlFilter\nfilterType"
      },
      {
        "date": "2023-02-28T14:07:00.000Z",
        "voteCount": 3,
        "content": "On my exam 2023-02-25"
      },
      {
        "date": "2023-02-22T06:34:00.000Z",
        "voteCount": 3,
        "content": "Priotity should have a Correlation filter according to the example in Microsoft documentation: https://learn.microsoft.com/en-us/azure/service-bus-messaging/topic-filters"
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 17,
    "url": "https://www.examtopics.com/discussions/microsoft/view/37178-exam-az-204-topic-3-question-17-discussion/",
    "body": "DRAG DROP -<br>Your company has several websites that use a company logo image. You use Azure Content Delivery Network (CDN) to store the static image.<br>You need to determine the correct process of how the CDN and the Point of Presence (POP) server will distribute the image and list the items in the correct order.<br>In which order do the actions occur? To answer, move all actions from the list of actions to the answer area and arrange them in the correct order.<br>Select and Place:<br><img src=\"/assets/media/exam-media/04273/0024100001.jpg\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04273/0024100002.jpg\" class=\"in-exam-image\">",
    "answerDescription": "Step 1: A user requests the image..<br>A user requests a file (also called an asset) by using a URL with a special domain name, such as &lt;endpoint name&gt;.azureedge.net. This name can be an endpoint hostname or a custom domain. The DNS routes the request to the best performing POP location, which is usually the POP that is geographically closest to the user.<br>Step 2:  If no edge servers in the POP have the..<br>If no edge servers in the POP have the file in their cache, the POP requests the file from the origin server. The origin server can be an Azure Web App, Azure<br>Cloud Service, Azure Storage account, or any publicly accessible web server.<br>Step 3: The origin server returns the..<br>The origin server returns the file to an edge server in the POP.<br>An edge server in the POP caches the file and returns the file to the original requestor (Alice). The file remains cached on the edge server in the POP until the time-to-live (TTL) specified by its HTTP headers expires. If the origin server didn't specify a TTL, the default TTL is seven days.<br>Step 4: Subsequent requests for..<br>Additional users can then request the same file by using the same URL that the original user used, and can also be directed to the same POP.<br>If the TTL for the file hasn't expired, the POP edge server returns the file directly from the cache. This process results in a faster, more responsive user experience.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/cdn/cdn-overview",
    "votes": [],
    "comments": [
      {
        "date": "2020-11-17T13:20:00.000Z",
        "voteCount": 92,
        "content": "Given ans is correct"
      },
      {
        "date": "2021-06-20T00:33:00.000Z",
        "voteCount": 64,
        "content": "It feels so good when there are no debates on what is the correct answer."
      },
      {
        "date": "2023-03-23T22:08:00.000Z",
        "voteCount": 5,
        "content": "correct, in 2023Mar24, score: 904/1000"
      },
      {
        "date": "2020-12-13T06:46:00.000Z",
        "voteCount": 10,
        "content": "The given answer is correct."
      },
      {
        "date": "2023-09-11T04:26:00.000Z",
        "voteCount": 2,
        "content": "Got on my exam 2023sept"
      },
      {
        "date": "2023-02-24T22:01:00.000Z",
        "voteCount": 1,
        "content": "\"... returns the file directly from the cache. This process results in a faster, more responsive user experience\" - last in order.\nHmmm. Fine"
      },
      {
        "date": "2022-08-05T03:54:00.000Z",
        "voteCount": 2,
        "content": "Given answer is correct."
      },
      {
        "date": "2022-06-10T05:54:00.000Z",
        "voteCount": 2,
        "content": "Answer is correct."
      },
      {
        "date": "2022-04-26T13:09:00.000Z",
        "voteCount": 2,
        "content": "Got it in April 2023"
      },
      {
        "date": "2022-11-19T07:03:00.000Z",
        "voteCount": 10,
        "content": "time travel!!"
      },
      {
        "date": "2022-03-12T19:52:00.000Z",
        "voteCount": 2,
        "content": "Got it on 03/2022, chose the same as the given answer."
      },
      {
        "date": "2021-06-17T16:41:00.000Z",
        "voteCount": 2,
        "content": "The given answer is correct"
      },
      {
        "date": "2021-05-30T04:57:00.000Z",
        "voteCount": 5,
        "content": "The Answer is correct\n\nReference:\n\nhttps://docs.microsoft.com/en-us/azure/cdn/cdn-overview"
      },
      {
        "date": "2023-02-24T21:31:00.000Z",
        "voteCount": 1,
        "content": "\"How it works\" does not exactly represent the order.\n\"returns the file from cache if\" should be before \"if no ... image in cache\""
      },
      {
        "date": "2023-02-24T21:52:00.000Z",
        "voteCount": 1,
        "content": "I know that \"Subsequent\" is the bad word for this choice and the author could be stupid enough to use wrong order."
      },
      {
        "date": "2021-05-24T23:29:00.000Z",
        "voteCount": 1,
        "content": "correct ans"
      },
      {
        "date": "2021-05-20T04:54:00.000Z",
        "voteCount": 2,
        "content": "The given answer is correct."
      },
      {
        "date": "2021-05-13T06:52:00.000Z",
        "voteCount": 1,
        "content": "correct."
      },
      {
        "date": "2021-01-26T14:11:00.000Z",
        "voteCount": 5,
        "content": "The az-204 exam voucher costs 100 euros.\nThis value includes Study material + dump"
      },
      {
        "date": "2021-06-20T06:01:00.000Z",
        "voteCount": 11,
        "content": "And? this comment is silly and does not help.\nIt's like saying: the sky is blue, except when it is clouded (or dark).\nAdmin: can you delete this useless message above? (and mine)"
      },
      {
        "date": "2021-09-25T05:08:00.000Z",
        "voteCount": 4,
        "content": "Lol..."
      },
      {
        "date": "2022-10-07T00:17:00.000Z",
        "voteCount": 2,
        "content": "Admin, can you delete all \"this answer is correct\" minus one, and not delete the comment of Fr3ddy?"
      },
      {
        "date": "2023-02-16T01:13:00.000Z",
        "voteCount": 2,
        "content": "Admin, can you delete this whole discussion? I don't see any comment that would have any value whatsoever."
      },
      {
        "date": "2021-01-26T02:30:00.000Z",
        "voteCount": 2,
        "content": "correct!"
      },
      {
        "date": "2020-12-15T01:08:00.000Z",
        "voteCount": 5,
        "content": "Answer is correct."
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 18,
    "url": "https://www.examtopics.com/discussions/microsoft/view/37295-exam-az-204-topic-3-question-18-discussion/",
    "body": "You are developing an Azure Cosmos DB solution by using the Azure Cosmos DB SQL API. The data includes millions of documents. Each document may contain hundreds of properties.<br>The properties of the documents do not contain distinct values for partitioning. Azure Cosmos DB must scale individual containers in the database to meet the performance needs of the application by spreading the workload evenly across all partitions over time.<br>You need to select a partition key.<br>Which two partition keys can you use? Each correct answer presents a complete solution.<br>NOTE: Each correct selection is worth one point.<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ta single property value that does not appear frequently in the documents",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ta value containing the collection name",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ta single property value that appears frequently in the documents",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ta concatenation of multiple property values with a random suffix appended\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ta hash suffix appended to a property value\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "DE",
    "answerDescription": "",
    "votes": [
      {
        "answer": "DE",
        "count": 13,
        "isMostVoted": true
      },
      {
        "answer": "CE",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2020-11-19T02:57:00.000Z",
        "voteCount": 73,
        "content": "The given answer is correct"
      },
      {
        "date": "2021-05-30T05:09:00.000Z",
        "voteCount": 18,
        "content": "D and E\n\nReference:\n\nhttps://docs.microsoft.com/en-us/azure/cosmos-db/synthetic-partition-keys"
      },
      {
        "date": "2024-03-21T13:50:00.000Z",
        "voteCount": 1,
        "content": "Copilot says C and E\nWith D - random suffice for each item may be an overkill."
      },
      {
        "date": "2023-11-27T06:30:00.000Z",
        "voteCount": 2,
        "content": "D. a concatenation of multiple property values with a random suffix appended Most Voted\nE. a hash suffix appended to a property value Most Voted"
      },
      {
        "date": "2023-07-12T10:39:00.000Z",
        "voteCount": 1,
        "content": "Given answer is incorrect. Correct answer: AE"
      },
      {
        "date": "2023-10-17T02:03:00.000Z",
        "voteCount": 1,
        "content": "That is not the given answer? It is D and E."
      },
      {
        "date": "2023-01-28T12:28:00.000Z",
        "voteCount": 2,
        "content": "It's the best practice to have a partition key with many distinct values, such as hundreds or thousands. The goal is to distribute your data and workload evenly across the items associated with these partition key values. If such a property doesn\u2019t exist in your data, you can construct a synthetic partition key"
      },
      {
        "date": "2022-12-07T09:07:00.000Z",
        "voteCount": 5,
        "content": "got this on 2022-12-7"
      },
      {
        "date": "2022-11-19T07:22:00.000Z",
        "voteCount": 2,
        "content": "D. a concatenation of multiple property values with a random suffix appended Most Voted\nE. a hash suffix appended to a property value Most Voted"
      },
      {
        "date": "2022-11-15T06:48:00.000Z",
        "voteCount": 4,
        "content": "Did my exam on 15th November 2022. This question was on it."
      },
      {
        "date": "2022-10-26T22:54:00.000Z",
        "voteCount": 2,
        "content": "at option E : a hash value will always deliver the same result on the same data. It is not a random value as  stated in the proposed solution. \nSince A,B and C fall off, and two answers must be chosen still I would go for D,E."
      },
      {
        "date": "2022-06-18T03:27:00.000Z",
        "voteCount": 6,
        "content": "If no property in the document data will have unique values, you need to make one. \nThis is called a synthetic partition key. \nThese sorts of keys are made by adding a unique suffix at the end of some property. \nOne other way is to create a property that will have the hashed data + a random suffix. \nThe objective is to have a property that is random enough so that you can rely on it to be your key."
      },
      {
        "date": "2022-06-10T05:58:00.000Z",
        "voteCount": 1,
        "content": "D &amp; E are the correct answers."
      },
      {
        "date": "2022-04-20T02:24:00.000Z",
        "voteCount": 2,
        "content": "Got this on 20 Apr 2022"
      },
      {
        "date": "2022-02-07T03:51:00.000Z",
        "voteCount": 6,
        "content": "Got this one 02/2022. Went with highly voted answer."
      },
      {
        "date": "2022-01-21T03:00:00.000Z",
        "voteCount": 6,
        "content": "Got this in the exam 01/22"
      },
      {
        "date": "2021-12-23T06:52:00.000Z",
        "voteCount": 1,
        "content": "the given answer is correct."
      },
      {
        "date": "2021-10-07T03:48:00.000Z",
        "voteCount": 1,
        "content": "seems, the given answer is correct."
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 19,
    "url": "https://www.examtopics.com/discussions/microsoft/view/53970-exam-az-204-topic-3-question-19-discussion/",
    "body": "HOTSPOT -<br>You are developing an Azure-hosted e-commerce web application. The application will use Azure Cosmos DB to store sales orders. You are using the latest SDK to manage the sales orders in the database.<br>You create a new Azure Cosmos DB instance. You include a valid endpoint and valid authorization key to an appSettings.json file in the code project.<br>You are evaluating the following application code: (Line number are included for reference only.)<br><img src=\"/assets/media/exam-media/04273/0024400001.png\" class=\"in-exam-image\"><br>For each of the following statements, select Yes if the statement is true. Otherwise, select No.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04273/0024500001.jpg\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04273/0024500002.jpg\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: Yes -<br>The createDatabaseIfNotExistsAsync method checks if a database exists, and if it doesn't, create it.<br>The Database.CreateContainerAsync method creates a container as an asynchronous operation in the Azure Cosmos service.<br><br>Box 2: Yes -<br>The CosmosContainer.CreateItemAsync method creates an item as an asynchronous operation in the Azure Cosmos service.<br><br>Box 3: Yes -<br>Reference:<br>https://docs.microsoft.com/en-us/dotnet/api/microsoft.azure.cosmos.cosmosclient.createdatabaseifnotexistsasync https://docs.microsoft.com/en-us/dotnet/api/microsoft.azure.cosmos.database.createcontainerasync https://docs.microsoft.com/en-us/dotnet/api/azure.cosmos.cosmoscontainer.createitemasync",
    "votes": [],
    "comments": [
      {
        "date": "2021-05-31T11:00:00.000Z",
        "voteCount": 87,
        "content": "Box 1: Yes\nThe createDatabaseIfNotExistsAsync method checks if a database exists, and if it doesn't, create it. (Line 22)\nThe Database.CreateContainerAsync method creates a container as an asynchronous operation in the Azure Cosmos service. (Line 23 and 24)\n\nBox 2: Yes\nThe CosmosContainer.CreateItemAsync method creates an item as an asynchronous operation in the Azure Cosmos service. (Line 26 and 28)\n\nBox 3: Yes\nThe CosmosContainer.CreateItemAsync method creates an item as an asynchronous operation in the Azure Cosmos service. (Line 30)"
      },
      {
        "date": "2023-01-31T06:34:00.000Z",
        "voteCount": 1,
        "content": "Agreed"
      },
      {
        "date": "2022-12-23T10:09:00.000Z",
        "voteCount": 1,
        "content": "The first box is not correct, the name of database is database and not salesOrder !"
      },
      {
        "date": "2022-12-23T10:11:00.000Z",
        "voteCount": 1,
        "content": "SalesOrders is the databaseID, not the name !"
      },
      {
        "date": "2022-12-23T10:15:00.000Z",
        "voteCount": 1,
        "content": "// New instance of Database class referencing the server-side database\n// The name of instance is database2, and we need an ID to create it !\nDatabase database2 = await client.CreateDatabaseIfNotExistsAsync(\n    id: \"adventureworks-2\"\n);"
      },
      {
        "date": "2023-09-11T00:06:00.000Z",
        "voteCount": 1,
        "content": "You are right but in Azure Cosmos DB, the database name is typically the same as the database ID, but spaces in the ID are replaced with hyphens (\"-\")."
      },
      {
        "date": "2023-09-11T00:06:00.000Z",
        "voteCount": 1,
        "content": "So, this answer is correct one."
      },
      {
        "date": "2021-05-31T11:01:00.000Z",
        "voteCount": 7,
        "content": "Reference:\n\nhttps://docs.microsoft.com/en-us/dotnet/api/microsoft.azure.cosmos.cosmosclient.createdatabaseifnotexistsasync\n\nhttps://docs.microsoft.com/en-us/dotnet/api/microsoft.azure.cosmos.database.createcontainerasync\n \nhttps://docs.microsoft.com/en-us/dotnet/api/azure.cosmos.cosmoscontainer.createitemasync"
      },
      {
        "date": "2021-08-18T13:04:00.000Z",
        "voteCount": 7,
        "content": "Line 21 is tricky, it assumes the database is already created as it calls DeleteStreamAsync. I'm confused."
      },
      {
        "date": "2023-02-25T00:56:00.000Z",
        "voteCount": 1,
        "content": "It returns ResponseMessage which is IDisposable"
      },
      {
        "date": "2022-08-19T00:14:00.000Z",
        "voteCount": 1,
        "content": "// Delete a Database resource where database_id is the ID property of the Database resource you wish to delete.\nDatabase database = this.cosmosClient.GetDatabase(database_id);\nawait database.DeleteStreamAsync();\n\nThat is deleted so the create if not exist will surely create the DB"
      },
      {
        "date": "2022-10-07T01:04:00.000Z",
        "voteCount": 2,
        "content": "\"using\" is equal to a \"try-finaly\" with noting in finaly so the null exeption is already been taken care of . https://stackoverflow.com/questions/2522822/will-dispose-be-called-in-a-using-statement-with-a-null-object"
      },
      {
        "date": "2023-08-21T10:43:00.000Z",
        "voteCount": 4,
        "content": "On my exam 2023-08-20. Scored 925\nYes\nYes\nYes"
      },
      {
        "date": "2023-07-19T03:22:00.000Z",
        "voteCount": 1,
        "content": "Box 1: Yes\nBox 2: Yes\nBox 3: No - container2.Create is called only once"
      },
      {
        "date": "2023-08-20T20:18:00.000Z",
        "voteCount": 2,
        "content": "I think you are confused! It said container2 has 1 item. So box3 - Yes is correct"
      },
      {
        "date": "2024-07-24T05:08:00.000Z",
        "voteCount": 1,
        "content": "exactly"
      },
      {
        "date": "2023-02-28T14:07:00.000Z",
        "voteCount": 1,
        "content": "On my exam 2023-02-25"
      },
      {
        "date": "2022-12-30T21:20:00.000Z",
        "voteCount": 3,
        "content": "In 28-12-2022 exam"
      },
      {
        "date": "2022-11-15T06:49:00.000Z",
        "voteCount": 2,
        "content": "Did my exam on 15th November 2022. This question was on it."
      },
      {
        "date": "2022-10-06T07:26:00.000Z",
        "voteCount": 1,
        "content": "yes yes yes"
      },
      {
        "date": "2022-12-23T10:10:00.000Z",
        "voteCount": 1,
        "content": "No, it's not correct, The first box is not correct, the name of database on the code is database and not salesOrder !"
      },
      {
        "date": "2022-12-23T10:12:00.000Z",
        "voteCount": 1,
        "content": "SalesOrders is the databaseID, not the name !"
      },
      {
        "date": "2022-06-10T06:05:00.000Z",
        "voteCount": 1,
        "content": "Answer is correct:\nYes\nYes \nYes"
      },
      {
        "date": "2022-12-23T10:12:00.000Z",
        "voteCount": 1,
        "content": "No, it's not correct, The first box is not correct, the name of database on the code is database and not salesOrders !\nSalesOrders is the ID of the database not it's name !"
      },
      {
        "date": "2022-12-25T08:47:00.000Z",
        "voteCount": 4,
        "content": "there is no name of database, that s a variable called database of type Databse and it will receive the newly created database with name salesOrder !"
      },
      {
        "date": "2021-06-21T22:33:00.000Z",
        "voteCount": 2,
        "content": "I'm just curious, how do you know that Container 1 contains 2 items and container2 contains 1 item and not the opposite? I see that we are partitionning on the account number, but not sure to understand how the partition is made?"
      },
      {
        "date": "2021-06-22T09:23:00.000Z",
        "voteCount": 5,
        "content": "see Lines 26 &amp; 28 contain items for Container 1\nOnly Line 30 containers an item for Container 2"
      },
      {
        "date": "2021-06-22T11:58:00.000Z",
        "voteCount": 6,
        "content": "container1 is called two times adding the items, container2 just one."
      },
      {
        "date": "2022-08-19T00:13:00.000Z",
        "voteCount": 1,
        "content": "container 1 will have 2 partitions, container 2 only 1 partition because partition key is the account number. But container 1 will still have 2 items, 1 item per partition. Hope this help."
      },
      {
        "date": "2021-06-19T21:21:00.000Z",
        "voteCount": 1,
        "content": "Correct Answer"
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 20,
    "url": "https://www.examtopics.com/discussions/microsoft/view/56321-exam-az-204-topic-3-question-20-discussion/",
    "body": "DRAG DROP -<br>You develop an Azure solution that uses Cosmos DB.<br>The current Cosmos DB container must be replicated and must use a partition key that is optimized for queries.<br>You need to implement a change feed processor solution.<br>Which change feed processor components should you use? To answer, drag the appropriate components to the correct requirements. Each component may be used once, more than once, or not at all. You may need to drag the split bar between panes or scroll to view the content.<br>NOTE: Each correct selection is worth one point.<br>Select and Place:<br><img src=\"/assets/media/exam-media/04273/0024700001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04273/0024700002.png\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: The monitored container -<br>The monitored container has the data from which the change feed is generated. Any inserts and updates to the monitored container are reflected in the change feed of the container.<br><br>Box 2: The lease container -<br>The lease container acts as a state storage and coordinates processing the change feed across multiple workers. The lease container can be stored in the same account as the monitored container or in a separate account.<br>Box 3: The host: A host is an application instance that uses the change feed processor to listen for changes. Multiple instances with the same lease configuration can run in parallel, but each instance should have a different instance name.<br><br>Box 4: The delegate -<br>The delegate is the code that defines what you, the developer, want to do with each batch of changes that the change feed processor reads.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/cosmos-db/change-feed-processor",
    "votes": [],
    "comments": [
      {
        "date": "2021-06-30T06:03:00.000Z",
        "voteCount": 60,
        "content": "The given answer is correct."
      },
      {
        "date": "2021-07-03T16:46:00.000Z",
        "voteCount": 11,
        "content": "You are right. The given answer is correct."
      },
      {
        "date": "2021-12-07T07:58:00.000Z",
        "voteCount": 19,
        "content": "And your given answer, that MattXu is right, is also correct."
      },
      {
        "date": "2021-12-13T05:30:00.000Z",
        "voteCount": 15,
        "content": "that observation is correct, john"
      },
      {
        "date": "2023-11-22T17:10:00.000Z",
        "voteCount": 2,
        "content": "dbobspurfpoo, you are right to say that the observation of john is correct."
      },
      {
        "date": "2022-10-04T23:25:00.000Z",
        "voteCount": 12,
        "content": "Microsoft has obscrure names in documentation and has nothing to do with the azure component itself. \"Delegate\", \"Host component\", \"Compute instance\". How's remembering this from one page they wrote mean anything. We do not call any of them these when we implement the change feed processor"
      },
      {
        "date": "2024-07-17T11:20:00.000Z",
        "voteCount": 1,
        "content": "Got this Q on 07/07. Went with given answer."
      },
      {
        "date": "2023-09-26T18:35:00.000Z",
        "voteCount": 3,
        "content": "It was on my exam today (2023-09-26) I went with the examtopics answer - score 850"
      },
      {
        "date": "2023-09-22T04:07:00.000Z",
        "voteCount": 2,
        "content": "Question in my exam 22sept 2023"
      },
      {
        "date": "2023-09-26T10:28:00.000Z",
        "voteCount": 1,
        "content": "me too today"
      },
      {
        "date": "2023-09-11T04:27:00.000Z",
        "voteCount": 2,
        "content": "On my exam 2023sept"
      },
      {
        "date": "2023-08-14T01:35:00.000Z",
        "voteCount": 4,
        "content": "1. Monitored container\n&gt; You want to track changes of the data you store\n\n2. Lease container\n&gt; A lease container is responsible for maintaining information about which workers are processing which data from the Monitored Container\n\n3. Host\n&gt; They represent the worker instances responsible for processing changes from the change feed\n\n4. Delegates\n&gt; Methods you define to handle actual changes detected by the change feed (so when the change feed receives changes, it invokes delegate methods)\n\nThe difference between a monitored container and a host is that a host actually distributes work to delegates, while a monitored container tracks changes in data and gives that info to the change feed processor."
      },
      {
        "date": "2023-08-01T23:14:00.000Z",
        "voteCount": 1,
        "content": "please provide correct answers"
      },
      {
        "date": "2023-07-24T04:53:00.000Z",
        "voteCount": 2,
        "content": "The discussions are meant to help prepare for the exam so please try to be helpful"
      },
      {
        "date": "2023-07-24T04:52:00.000Z",
        "voteCount": 2,
        "content": "People are commenting here to be funny, but can they care to provide an explanation?"
      },
      {
        "date": "2023-06-15T02:08:00.000Z",
        "voteCount": 2,
        "content": "Received this on 15th of June 2023. Went with the given answer."
      },
      {
        "date": "2023-02-28T14:08:00.000Z",
        "voteCount": 3,
        "content": "On my exam 2023-02-25"
      },
      {
        "date": "2022-12-07T09:07:00.000Z",
        "voteCount": 3,
        "content": "got this on 2022-12-7"
      },
      {
        "date": "2022-11-15T06:49:00.000Z",
        "voteCount": 5,
        "content": "Did my exam on 15th November 2022. This question was on it."
      },
      {
        "date": "2022-12-12T20:39:00.000Z",
        "voteCount": 2,
        "content": "I also Got same in 5 dec exam."
      },
      {
        "date": "2022-04-06T01:19:00.000Z",
        "voteCount": 5,
        "content": "Answer is correct.\n\n*Note that the \"Host\" Component should be called Compute Instance instead.\n \nhttps://docs.microsoft.com/en-us/azure/cosmos-db/change-feed-processor"
      },
      {
        "date": "2022-03-09T13:58:00.000Z",
        "voteCount": 2,
        "content": "Got it in exam 03/22"
      },
      {
        "date": "2022-02-07T03:52:00.000Z",
        "voteCount": 5,
        "content": "Got this one 02/2022. Went with the given answer"
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 21,
    "url": "https://www.examtopics.com/discussions/microsoft/view/74782-exam-az-204-topic-3-question-21-discussion/",
    "body": "HOTSPOT -<br>You are developing a web application that will use Azure Storage. Older data will be less frequently used than more recent data.<br>You need to configure data storage for the application. You have the following requirements:<br>\u2711 Retain copies of data for five years.<br>\u2711 Minimize costs associated with storing data that is over one year old.<br>\u2711 Implement Zone Redundant Storage for application data.<br>What should you do? To answer, select the appropriate options in the answer area.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04273/0024800004.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04273/0024900001.png\" class=\"in-exam-image\">",
    "answerDescription": "Reference:<br>https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blob-storage-tiers https://docs.microsoft.com/en-us/azure/storage/common/storage-redundancy?toc=/azure/storage/blobs/toc.json",
    "votes": [],
    "comments": [
      {
        "date": "2022-10-04T23:59:00.000Z",
        "voteCount": 36,
        "content": "So, because it is ZRS, and that does not support arhive tier, it cannot be moved to archive tier even though the questions mention the red-herring key-word \"infrequently accessed\" (which triggers feelings for archive tier). For no logically apparent reason Microsoft decided not to support archive tier in ZRS and unfortunately I have to remember that Microsoft \"feature\"?"
      },
      {
        "date": "2024-08-13T00:15:00.000Z",
        "voteCount": 1,
        "content": "Archive data is physically disconnected from the web, if it has to be zone-redundant then it needs to be online, so it cannot be archived."
      },
      {
        "date": "2022-11-19T21:47:00.000Z",
        "voteCount": 13,
        "content": "ZRS, and that does not support arhive tier - this is key point, Thanks"
      },
      {
        "date": "2023-04-15T22:24:00.000Z",
        "voteCount": 2,
        "content": "also GZRS and RA-GZRS does not support archieve tier\nhttps://learn.microsoft.com/en-us/azure/storage/blobs/access-tiers-overview#archive-access-tier"
      },
      {
        "date": "2023-08-17T06:16:00.000Z",
        "voteCount": 1,
        "content": "I assume they wanted to charge people more money for ZRS and thus no Archive tier."
      },
      {
        "date": "2022-12-10T08:26:00.000Z",
        "voteCount": 11,
        "content": "Got in exam. go with given answer"
      },
      {
        "date": "2023-03-23T22:09:00.000Z",
        "voteCount": 3,
        "content": "correct, in 2023Mar24, score: 904/1000"
      },
      {
        "date": "2023-03-31T19:17:00.000Z",
        "voteCount": 3,
        "content": "were all the questions from the exam topic?"
      },
      {
        "date": "2024-04-28T00:54:00.000Z",
        "voteCount": 3,
        "content": "Got it on 20 April 2024...Marks &gt; 900...All questions from examtopics 400 questions...\nanswer is correct..."
      },
      {
        "date": "2023-12-31T04:31:00.000Z",
        "voteCount": 9,
        "content": "Correct answer.  Got this in exam on 30/12/2023.  \nCase study: Contoso Ltd.\nTotal questions: 46\nTime: 1:40 minutes\nScore: 940\n\n43 questions from Exam Topics.  Just 3 questions outside of it."
      },
      {
        "date": "2023-09-26T18:35:00.000Z",
        "voteCount": 2,
        "content": "It was on my exam today (2023-09-26) I went with the examtopics answer - score 850"
      },
      {
        "date": "2023-07-30T07:23:00.000Z",
        "voteCount": 1,
        "content": "got this question today, go with the provided answer - 7/30/2023, score 895/1000"
      },
      {
        "date": "2023-02-20T01:24:00.000Z",
        "voteCount": 3,
        "content": "On exam 20-02-2023"
      },
      {
        "date": "2023-01-19T02:34:00.000Z",
        "voteCount": 2,
        "content": "1. Implement storage V2\n2. Set lifecycle management policy to move to cool tier\n\nwhich means given answers are correct"
      },
      {
        "date": "2023-09-21T04:49:00.000Z",
        "voteCount": 2,
        "content": "Why not Blob storage ?"
      },
      {
        "date": "2024-02-08T00:09:00.000Z",
        "voteCount": 2,
        "content": "Blob Storage is not a type of *Account*"
      },
      {
        "date": "2022-10-15T10:04:00.000Z",
        "voteCount": 4,
        "content": "Given answer is correct. Data retention policy relay on cool tier"
      },
      {
        "date": "2022-10-04T23:31:00.000Z",
        "voteCount": 6,
        "content": "Microsoft plays on the unfortunate choice of words in their documentation: \"Rarely used\", \"Infrequently used\". The difference I cannot find"
      },
      {
        "date": "2022-09-27T03:26:00.000Z",
        "voteCount": 1,
        "content": "Given answer is correct or not?"
      },
      {
        "date": "2022-11-11T16:48:00.000Z",
        "voteCount": 5,
        "content": "Yup, the answer is correct \nBased on this: https://learn.microsoft.com/en-us/azure/storage/blobs/access-tiers-overview?source=recommendations\nOnly storage accounts that are configured for LRS, GRS, or RA-GRS support moving blobs to the archive tier. The archive tier isn't supported for ZRS, GZRS, or RA-GZRS accounts. For more information about redundancy configurations for Azure Storage, see Azure Storage redundancy."
      },
      {
        "date": "2022-09-20T05:16:00.000Z",
        "voteCount": 3,
        "content": "Only storage accounts that are configured for LRS, GRS, or RA-GRS support moving blobs to the Archive tier. The Archive tier isn't supported for ZRS, GZRS, or RA-GZRS accounts.\nhttps://learn.microsoft.com/en-us/azure/storage/blobs/access-tiers-overview?source=recommendations"
      },
      {
        "date": "2022-09-06T02:19:00.000Z",
        "voteCount": 2,
        "content": "Correct. Can't pick the archive option since ZRS needs to be used."
      },
      {
        "date": "2022-09-03T09:04:00.000Z",
        "voteCount": 2,
        "content": "Data in all tiers, including the Archive tier, is always copied from the primary to the secondary during geo-replication. The Archive tier for Blob Storage is currently supported for LRS, GRS, and RA-GRS accounts, but not for ZRS, GZRS, or RA-GZRS accounts. \n\nhttps://docs.microsoft.com/en-us/azure/storage/common/storage-redundancy"
      },
      {
        "date": "2022-04-28T08:24:00.000Z",
        "voteCount": 1,
        "content": "https://docs.microsoft.com/ko-kr/azure/storage/common/storage-account-overview"
      },
      {
        "date": "2023-01-02T08:53:00.000Z",
        "voteCount": 1,
        "content": "here is en-us link : https://learn.microsoft.com/en-us/azure/storage/common/storage-account-overview"
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 22,
    "url": "https://www.examtopics.com/discussions/microsoft/view/74568-exam-az-204-topic-3-question-22-discussion/",
    "body": "HOTSPOT -<br>A company develops a series of mobile games. All games use a single leaderboard service.<br>You have the following requirements:<br>\u2711 Code must be scalable and allow for growth.<br>\u2711 Each record must consist of a playerId, gameId, score, and time played.<br>\u2711 When users reach a new high score, the system will save the new score using the SaveScore function below.<br>Each game is assigned an Id based on the series title.<br><img src=\"/assets/media/exam-media/04273/0024900005.png\" class=\"in-exam-image\"><br>You plan to store customer information in Azure Cosmos DB. The following data already exists in the database:<br><img src=\"/assets/media/exam-media/04273/0025000001.png\" class=\"in-exam-image\"><br>You develop the following code to save scores in the data store. (Line numbers are included for reference only.)<br><img src=\"/assets/media/exam-media/04273/0025000002.png\" class=\"in-exam-image\"><br>You develop the following code to query the database. (Line numbers are included for reference only.)<br><img src=\"/assets/media/exam-media/04273/0025000003.jpg\" class=\"in-exam-image\"><br>For each of the following statements, select Yes if the statement is true. Otherwise, select No.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04273/0025100001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04273/0025100002.png\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: Yes -<br>Create a table.<br>A CloudTableClient object lets you get reference objects for tables and entities. The following code creates a CloudTableClient object and uses it to create a new<br>CloudTable object, which represents a table<br>// Retrieve storage account from connection-string.<br>CloudStorageAccount storageAccount =<br>CloudStorageAccount.parse(storageConnectionString);<br>// Create the table client.<br>CloudTableClient tableClient = storageAccount.createCloudTableClient();<br>// Create the table if it doesn't exist.<br>String tableName = \"people\";<br>CloudTable cloudTable = tableClient.getTableReference(tableName); cloudTable.createIfNotExists();<br><br>Box 2: No -<br>New records are inserted with TableOperation.insert. Old records are not updated.<br>To update old records TableOperation.insertOrReplace should be used instead.<br><br>Box 3: No -<br><br>Box 4: Yes -<br>Reference:<br>https://docs.microsoft.com/en-us/azure/cosmos-db/table-storage-how-to-use-java",
    "votes": [],
    "comments": [
      {
        "date": "2023-01-09T08:23:00.000Z",
        "voteCount": 14,
        "content": "given answer is correct."
      },
      {
        "date": "2023-01-19T02:56:00.000Z",
        "voteCount": 3,
        "content": "yes, you are correct! given answers are correct"
      },
      {
        "date": "2023-07-13T02:56:00.000Z",
        "voteCount": 4,
        "content": "Incorrect. First one is \"No\""
      },
      {
        "date": "2022-10-31T08:58:00.000Z",
        "voteCount": 7,
        "content": "the given answer seems correct"
      },
      {
        "date": "2024-02-08T01:03:00.000Z",
        "voteCount": 1,
        "content": "Is the implementation of the PlayerScore viewable in the exam? Wouldn't questions about partition/row key would be settled there?"
      },
      {
        "date": "2024-01-22T02:19:00.000Z",
        "voteCount": 3,
        "content": "See: https://learn.microsoft.com/en-us/dotnet/api/overview/azure/data.tables-readme?view=azure-dotnet"
      },
      {
        "date": "2024-01-22T02:15:00.000Z",
        "voteCount": 3,
        "content": "CloudStorageClient is deprecated for CosmosDb it is now changed to TableServiceClient and then you have TableClient to store the data. So probably this question wil be different in the upcoming exam"
      },
      {
        "date": "2023-09-24T23:14:00.000Z",
        "voteCount": 1,
        "content": "Yes, SaveScore will work with CosmosDb.\nThis is an example of Azure Cosmos DB for Table.\nhttps://learn.microsoft.com/en-us/azure/cosmos-db/table/quickstart-dotnet?tabs=azure-cli%2Cwindows"
      },
      {
        "date": "2023-07-13T02:54:00.000Z",
        "voteCount": 3,
        "content": "No, No, No, Yes"
      },
      {
        "date": "2023-01-12T16:42:00.000Z",
        "voteCount": 3,
        "content": "Inserting will fail, this would require InsertOrReplace to work"
      },
      {
        "date": "2022-12-26T18:01:00.000Z",
        "voteCount": 2,
        "content": "For box 2 there will be an exception if the same partition key and row key already exist."
      },
      {
        "date": "2023-02-25T10:22:00.000Z",
        "voteCount": 1,
        "content": "So you need to answer box 3 first ;)"
      },
      {
        "date": "2022-11-25T05:29:00.000Z",
        "voteCount": 2,
        "content": "It seems that in the code no partition key for scoreTable is specified, which means that here we are using a single-partition collection. I would say in this case 3rd option is No, so no automatical partitioning will happen."
      },
      {
        "date": "2022-10-24T01:27:00.000Z",
        "voteCount": 1,
        "content": "Y,N,Y,Y"
      },
      {
        "date": "2022-10-07T06:12:00.000Z",
        "voteCount": 4,
        "content": "What code should be there if doing automatic partitioning (C) remains a total secret to me. Should be somewhere on the table level..."
      },
      {
        "date": "2022-09-14T17:23:00.000Z",
        "voteCount": 2,
        "content": "The given answer looks right to me,\nhttps://docs.microsoft.com/en-us/dotnet/api/microsoft.azure.cosmos.table?view=azure-dotnet"
      },
      {
        "date": "2022-09-09T02:36:00.000Z",
        "voteCount": 5,
        "content": "CloudTableClient is for Table storage - CosmosClient is for Cosmos DB I don't think it will work with Cosmos"
      },
      {
        "date": "2022-09-20T04:24:00.000Z",
        "voteCount": 1,
        "content": "https://learn.microsoft.com/en-us/dotnet/api/microsoft.azure.cosmos.table.cloudtableclient?view=azure-dotnet"
      },
      {
        "date": "2022-09-20T04:22:00.000Z",
        "voteCount": 2,
        "content": "Cosmos DB offers Table API, you can use CosmosClient to connect to this."
      },
      {
        "date": "2022-09-20T05:24:00.000Z",
        "voteCount": 1,
        "content": "Please do a simple bing search and you'll see it is Cosmos Db\nhttps://learn.microsoft.com/en-us/dotnet/api/microsoft.azure.cosmos.table.cloudtableclient?view=azure-dotnet"
      },
      {
        "date": "2023-06-22T01:03:00.000Z",
        "voteCount": 3,
        "content": "A = No\nSaveScore() method uses a storage account connectionString:\n   CloudStorageAccount storageAccount = CloudStorageAccount.Parse(connectionString);\nand uses storageAccount to create CloudTableClient.\n\nThis is not a CosmosDB connection string, CosmosDB requires a Uri + credential (not given in given code!) So given code wil not work 100% to connect to CosmosDB even though it uses a compatible API."
      },
      {
        "date": "2022-09-06T02:20:00.000Z",
        "voteCount": 2,
        "content": "Correct 100%!"
      },
      {
        "date": "2022-04-26T01:54:00.000Z",
        "voteCount": 3,
        "content": "Answer is Correct."
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 23,
    "url": "https://www.examtopics.com/discussions/microsoft/view/74569-exam-az-204-topic-3-question-23-discussion/",
    "body": "You develop and deploy a web application to Azure App Service. The application accesses data stored in an Azure Storage account. The account contains several containers with several blobs with large amounts of data. You deploy all Azure resources to a single region.<br>You need to move the Azure Storage account to the new region. You must copy all data to the new region.<br>What should you do first?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tExport the Azure Storage account Azure Resource Manager template\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tInitiate a storage account failover",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure object replication for all blobs",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse the AzCopy command line tool",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a new Azure Storage account in the current region",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"F\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tF.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a new subscription in the current region"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 14,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2022-04-27T00:43:00.000Z",
        "voteCount": 11,
        "content": "We can create a new Storage account in the new region, using the existing storage account ARM template. All we need to do is change the region name after exporting the ARM of existing account.."
      },
      {
        "date": "2022-10-05T00:45:00.000Z",
        "voteCount": 4,
        "content": "And the name of the storage account which needs to be unique. I think all these questions are about some sentence in some azure documentation."
      },
      {
        "date": "2022-04-26T01:56:00.000Z",
        "voteCount": 10,
        "content": "Answer is correct."
      },
      {
        "date": "2022-12-31T06:21:00.000Z",
        "voteCount": 9,
        "content": "Step One is always \"Export\""
      },
      {
        "date": "2022-11-19T21:59:00.000Z",
        "voteCount": 3,
        "content": "A. Export the Azure Storage account Azure Resource Manager template"
      },
      {
        "date": "2022-11-15T06:49:00.000Z",
        "voteCount": 6,
        "content": "Did my exam on 15th November 2022. This question was on it."
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 24,
    "url": "https://www.examtopics.com/discussions/microsoft/view/74783-exam-az-204-topic-3-question-24-discussion/",
    "body": "HOTSPOT -<br>You are developing an application to collect the following telemetry data for delivery drivers: first name, last name, package count, item id, and current location coordinates. The app will store the data in Azure Cosmos DB.<br>You need to configure Azure Cosmos DB to query the data.<br>Which values should you use? To answer, select the appropriate options in the answer area.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04273/0025400001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04273/0025500001.png\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: Core (SQL)<br>Core(SQL) API stores data in document format. It offers the best end-to-end experience as we have full control over the interface, service, and the SDK client libraries. SQL API supports analytics and offers performance isolation between operational and analytical workloads.<br><br>Box 2: item id -<br>item id is a unique identifier and is suitable for the partition key.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/cosmos-db/choose-api<br>https://docs.microsoft.com/en-us/azure/cosmos-db/partitioning-overview",
    "votes": [],
    "comments": [
      {
        "date": "2022-09-29T10:57:00.000Z",
        "voteCount": 37,
        "content": "Without knowing the functionality or the usage pattern or what it is for. Good lord, Microsoft"
      },
      {
        "date": "2022-09-11T00:26:00.000Z",
        "voteCount": 22,
        "content": "Got this in 09/22 , went with SQL and Item Id, score 927."
      },
      {
        "date": "2024-01-02T05:06:00.000Z",
        "voteCount": 6,
        "content": "Got this today.\nWent with answer here.\nScore 927"
      },
      {
        "date": "2024-05-12T23:39:00.000Z",
        "voteCount": 1,
        "content": "Core sql api removed now, it should be no sql api"
      },
      {
        "date": "2023-09-11T04:27:00.000Z",
        "voteCount": 8,
        "content": "On my exam 2023sept"
      },
      {
        "date": "2023-07-25T20:42:00.000Z",
        "voteCount": 5,
        "content": "Had this question in today's exam: 2023-07-26"
      },
      {
        "date": "2023-07-13T03:16:00.000Z",
        "voteCount": 7,
        "content": "Answer seems correct, but the question is very bad. It doesn't even tell about the usage, so it could be Table API as well"
      },
      {
        "date": "2023-03-19T13:05:00.000Z",
        "voteCount": 5,
        "content": "Got this question in the exam on 16/03/2023. Went with SQL and Item Id . Make sure to prepare for case studies. I got city and lights case study."
      },
      {
        "date": "2023-06-08T11:34:00.000Z",
        "voteCount": 3,
        "content": "where can one find these case studies?"
      },
      {
        "date": "2023-11-28T09:38:00.000Z",
        "voteCount": 1,
        "content": "Page 32 and above"
      },
      {
        "date": "2024-02-26T12:55:00.000Z",
        "voteCount": 1,
        "content": "did contributor access is needed to pass the exam?"
      },
      {
        "date": "2024-08-16T00:08:00.000Z",
        "voteCount": 1,
        "content": "yes it is"
      },
      {
        "date": "2023-02-25T23:00:00.000Z",
        "voteCount": 10,
        "content": "They changed names again. \"Core (SQL)\" is \"Api for NoSQL\" now. Its wonderful to choose \"SQL\" for \"NoSQL\". \nhttps://www.c-sharpcorner.com/article/road-to-az-2044/#:~:text=Core%20SQL%20API%2C%20default%20API%20for%20using%20Azure%20Cosmos%20DB%20enables%20querying%20your%20data%20with%20a%20language%20very%20close%20to%20SQL%3B\nhttps://learn.microsoft.com/en-us/azure/cosmos-db/choose-api#coresql-api:~:text=API%20for%20NoSQL%20is%20native%20to%20Azure%20Cosmos%20DB."
      },
      {
        "date": "2023-01-19T03:08:00.000Z",
        "voteCount": 2,
        "content": "given answers are correct"
      },
      {
        "date": "2022-11-19T22:16:00.000Z",
        "voteCount": 2,
        "content": "SQL and Item Id"
      },
      {
        "date": "2022-10-25T12:40:00.000Z",
        "voteCount": 2,
        "content": "correct"
      },
      {
        "date": "2022-09-11T10:45:00.000Z",
        "voteCount": 4,
        "content": "Answer is correct:\nhttps://docs.microsoft.com/en-us/azure/cosmos-db/choose-api"
      },
      {
        "date": "2022-04-29T09:28:00.000Z",
        "voteCount": 4,
        "content": "Received this in test on 4/29 and passed the test. \n\nWent with Table API and Item ID.    I do not know if Table API is correct, but I am confident that Item ID is."
      },
      {
        "date": "2023-11-28T09:39:00.000Z",
        "voteCount": 1,
        "content": "Table API is for manage tables, SQL is for queries"
      },
      {
        "date": "2022-04-28T08:25:00.000Z",
        "voteCount": 1,
        "content": "https://docs.microsoft.com/ko-kr/azure/cosmos-db/choose-api"
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 25,
    "url": "https://www.examtopics.com/discussions/microsoft/view/79410-exam-az-204-topic-3-question-25-discussion/",
    "body": "DRAG DROP -<br>You are implementing an Azure solution that uses Azure Cosmos DB and the latest Azure Cosmos DB SDK. You add a change feed processor to a new container instance.<br>You attempt to read a batch of 100 documents. The process fails when reading one of the documents. The solution must monitor the progress of the change feed processor instance on the new container as the change feed is read. You must prevent the change feed processor from retrying the entire batch when one document cannot be read.<br>You need to implement the change feed processor to read the documents.<br>Which features should you use? To answer, drag the appropriate features to the cored requirements. Each feature may be used once, more than once, or not at all. You may need to drag the split bar between panes or scroll to view content.<br>NOTE: Each cored selection is worth one point.<br>Select and Place:<br><img src=\"/assets/media/exam-media/04273/0025600001.jpg\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04273/0025700001.jpg\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: Change feed estimator -<br>You can use the change feed estimator to monitor the progress of your change feed processor instances as they read the change feed or use the life cycle notifications to detect underlying failures.<br><br>Box 2: Dead-letter queue -<br>To prevent your change feed processor from getting \"stuck\" continuously retrying the same batch of changes, you should add logic in your delegate code to write documents, upon exception, to a dead-letter queue. This design ensures that you can keep track of unprocessed changes while still being able to continue to process future changes. The dead-letter queue might be another Cosmos container. The exact data store does not matter, simply that the unprocessed changes are persisted.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/cosmos-db/sql/change-feed-processor",
    "votes": [],
    "comments": [
      {
        "date": "2022-09-02T06:43:00.000Z",
        "voteCount": 16,
        "content": "The answer is correct."
      },
      {
        "date": "2024-09-22T10:07:00.000Z",
        "voteCount": 1,
        "content": "1. Monitor the progress of the change feed processor\nFeature: Lease container\nReason: The Lease container is responsible for tracking the progress of the change feed processor. It maintains state information, ensuring that the change feed processor knows where it left off and can resume from the correct point in the feed. This allows the system to monitor the progress and distribute the workload across multiple instances if needed.\n\n2. Prevent the change feed processor from retrying the entire batch when one document cannot be read\nFeature: Dead-letter queue\nReason: The Dead-letter queue allows you to handle documents that cannot be processed. If a document cannot be read or processed, instead of failing the entire batch, the problematic document is moved to a dead-letter queue, allowing the change feed processor to continue processing the rest of the batch without retrying the failed document."
      },
      {
        "date": "2023-03-19T13:07:00.000Z",
        "voteCount": 13,
        "content": "Got this on 16/03/23. Went with proposed solution. Make sure to prepare for case study. I got city and lights case study. No Kubernetes, Search, Logic Apps questions for me."
      },
      {
        "date": "2023-12-18T19:18:00.000Z",
        "voteCount": 2,
        "content": "On my exam Dec 18. went with the given answer. scored 842"
      },
      {
        "date": "2023-11-03T07:47:00.000Z",
        "voteCount": 4,
        "content": "On exam 3-Nov-2023. Went with proposed anwer - 932/1000.\n1) Change feed estimator\n2) Dead letter queue"
      },
      {
        "date": "2023-09-19T21:25:00.000Z",
        "voteCount": 9,
        "content": "I got this same question. Provided answers are correct. (Note: I failed the exam 20/9/23. I only scored 644 and I felt bad. I think because many questions here in Examtopics are not accurate. I suggest following the most voted answers and don't just not rely on Examtopics answers. At the beginning of the exam, you will be asked which programming languages you want to use. C#/Python. I chose C#. Also, I just want to add that some questions here are really in the actual exams, but the choices are written and formatted differently. Please be aware of that. Goodluck. I feel bad for failing it, but I want to retake next month. I will try Python. T_T"
      },
      {
        "date": "2023-09-21T18:15:00.000Z",
        "voteCount": 2,
        "content": "this is a bad site"
      },
      {
        "date": "2023-08-14T03:26:00.000Z",
        "voteCount": 1,
        "content": "The answer is correct\n\nA change feed estimator is used to monitor teh progress of your change feed processor instances as they read the change feed\n\nA dead-letter queue is holding a queue for messages that cannot bbe delivered to their destination\n\n\n\nA deployment unit is to provide a container for an application or service, which is not relevant\n\nThe lease container is used to coordinate processing the change feed, which is not relevant aswell"
      },
      {
        "date": "2023-08-08T05:30:00.000Z",
        "voteCount": 2,
        "content": "I got this question on 6th August 2023. chose highly voted. passed with 904. I got Case study: city and Lights. All questions are from ExamTopics."
      },
      {
        "date": "2023-06-29T06:40:00.000Z",
        "voteCount": 2,
        "content": "Got this on 6/28/2023 and passed with 850.  Went with answer."
      },
      {
        "date": "2023-05-12T12:10:00.000Z",
        "voteCount": 1,
        "content": "Got this 2023-05-12.\n\nMy case:\ncase: You need to configure authorization.\ncase: You need to ensure the app does not time out and processes the blob data\ncase study: VanArsdel Inc Canada"
      },
      {
        "date": "2023-01-28T13:07:00.000Z",
        "voteCount": 1,
        "content": "The answer is correct.\nTo prevent your change feed processor from getting \"stuck\" continuously retrying the same batch of changes, you should add logic in your delegate code to write documents, upon exception, to an errored-message queue. This design ensures that you can keep track of unprocessed changes while still being able to continue to process future changes. The errored-message queue might be another Azure Cosmos DB container. The exact data store does not matter, simply that the unprocessed changes are persisted.\nError handling section - https://learn.microsoft.com/en-us/azure/cosmos-db/nosql/change-feed-processor?tabs=dotnet"
      },
      {
        "date": "2023-01-19T03:34:00.000Z",
        "voteCount": 1,
        "content": "Given answers are correct!"
      },
      {
        "date": "2023-01-19T03:40:00.000Z",
        "voteCount": 2,
        "content": "To prevent your change feed processor from getting \"stuck\" continuously retrying the same batch of changes, you should add logic in your delegate code to write documents, upon exception, to an errored-message queue. This design ensures that you can keep track of unprocessed changes while still being able to continue to process future changes. The errored-message queue might be another Azure Cosmos DB container. The exact data store does not matter, simply that the unprocessed changes are persisted.\n\nIn addition, you can use the change feed estimator to monitor the progress of your change feed processor instances as they read the change feed or use the life cycle notifications to detect underlying failures."
      },
      {
        "date": "2022-11-15T08:25:00.000Z",
        "voteCount": 3,
        "content": "got in 11/11/2022"
      },
      {
        "date": "2022-10-21T09:01:00.000Z",
        "voteCount": 3,
        "content": "Got this on 10/21/2022"
      },
      {
        "date": "2022-10-31T09:05:00.000Z",
        "voteCount": 1,
        "content": "thanks for mentioning the date"
      },
      {
        "date": "2022-10-05T00:54:00.000Z",
        "voteCount": 1,
        "content": "Sure, this is also taken from a certification. But where does a dead letter queue come in change feed processor. If this comes, yes, this is the correct answer. But it all doesn't make any sense"
      },
      {
        "date": "2022-10-07T07:31:00.000Z",
        "voteCount": 3,
        "content": "It is do-it-your self stuff:\n\"To prevent your change feed processor from getting \"stuck\" continuously retrying the same batch of changes, you should add logic in your delegate code to write documents, upon exception, to a dead-letter queue \"\nhttps://learn.microsoft.com/en-us/azure/cosmos-db/sql/change-feed-processor?tabs=dotnet"
      },
      {
        "date": "2022-11-02T07:47:00.000Z",
        "voteCount": 1,
        "content": "If just for saving the last position, I think it should be lease container.\n\"When the delegate finishes processing the changes successfully, update the lease store with the latest processed point in time and go to #1\"\nDead-letter queue seems to be prevent re-trying too much instead of resuming at the last done position."
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 26,
    "url": "https://www.examtopics.com/discussions/microsoft/view/79151-exam-az-204-topic-3-question-26-discussion/",
    "body": "HOTSPOT -<br>You are developing an application that uses a premium block blob storage account. The application will process a large volume of transactions daily. You enable<br>Blob storage versioning.<br>You are optimizing costs by automating Azure Blob Storage access tiers. You apply the following policy rules to the storage account. (Line numbers are included for reference only.)<br><img src=\"/assets/media/exam-media/04273/0025800001.png\" class=\"in-exam-image\"><br>For each of the following statements, select Yes if the statement is true. Otherwise, select No.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04273/0025900001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04273/0025900002.png\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: No -<br>Would be true if daysAfterModificationGreaterThan was used, but here daysAfterCreationGreaterThan<br><br>Box 2: No -<br>Would need to use the daysAfterLastAccessTimeGreaterThan predicate.<br><br>Box 3: Yes -<br><br>Box 4: Yes -<br>With the lifecycle management policy, you can:<br>Transition blobs from cool to hot immediately when they are accessed, to optimize for performance.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/storage/blobs/lifecycle-management-overview",
    "votes": [],
    "comments": [
      {
        "date": "2022-09-01T13:00:00.000Z",
        "voteCount": 25,
        "content": "With this image, all answers are NO:\n\n- Container named transaction is not in code\n- is no present line \"enableAutoTierToHotFromCool\": true"
      },
      {
        "date": "2022-09-10T12:35:00.000Z",
        "voteCount": 59,
        "content": "I guess, third statement (The policy rule tiers..) result is Yes.\nContainer name \"transactions\" is in prefixMatch.\n\nhttps://docs.microsoft.com/en-us/azure/storage/blobs/lifecycle-management-overview#archive-data-after-ingest\n\nSolution is:\n- No\n- No\n- Yes\n- No"
      },
      {
        "date": "2022-09-15T03:17:00.000Z",
        "voteCount": 2,
        "content": "Container name \"transactions\" is in prefixMatch means its name must start from \"transactions\". Its name is not \"transactions\". Dani_ac7's answer looks correct"
      },
      {
        "date": "2022-09-20T04:56:00.000Z",
        "voteCount": 1,
        "content": "Looks like 3rd is NO, according to filter's guide:\n\n\"Filter blobs by name or first letters. To find items in a specific container, enter the name of the container followed by a forward slash, then the blob name or first letters. For example, to show all blobs starting with \"a\", type: \"mycontainer/a\".\"\n\nSo it looks like we are searching blobs with \"transactions\" prefix in all containers in 3rd."
      },
      {
        "date": "2022-09-20T03:06:00.000Z",
        "voteCount": 5,
        "content": "But name \"transactions\" satisfies rule `name must start from \"transactions\"`, why  it doesn't fit?"
      },
      {
        "date": "2023-01-19T04:37:00.000Z",
        "voteCount": 1,
        "content": "Correct: if you want to match the blobs within a specific container, you should mention the conatiner name/blob name\n\n{\n  \"rules\": [\n    {\n      \"name\": \"agingRule\",\n      \"enabled\": true,\n      \"type\": \"Lifecycle\",\n      \"definition\": {\n        \"filters\": {\n          \"blobTypes\": [ \"blockBlob\" ],\n          \"prefixMatch\": [ \"sample-container/blob1\", \"container2/blob2\" ]\n        },\n        \"actions\": {\n          \"baseBlob\": {\n            \"tierToCool\": { \"daysAfterModificationGreaterThan\": 30 },\n            \"tierToArchive\": { \"daysAfterModificationGreaterThan\": 90 }\n          }\n        }\n      }\n    }\n  ]\n}"
      },
      {
        "date": "2024-02-18T06:39:00.000Z",
        "voteCount": 1,
        "content": "wrong:\nAn array of strings for prefixes to be matched. Each rule can define up to 10 case-sensitive prefixes. A prefix string must start with a container name. For example, if you want to match all blobs under https://myaccount.blob.core.windows.net/sample-container/blob1/... for a rule, the prefixMatch is sample-container/blob1"
      },
      {
        "date": "2023-02-14T07:12:00.000Z",
        "voteCount": 24,
        "content": "No - Not modified, created.\nNo - Not accessed, created.\nYes - Rules are matching the statement. The prefix \"transactions\" can be applicable for containers as well. \"container\" / \"container/blob\" or \"blob\" can be used under this context.\nSource: https://learn.microsoft.com/en-us/azure/storage/blobs/lifecycle-management-overview#archive-data-after-ingest\nNo - \"enableAutoTierToHotFromCool\": \"true\" should be enabled."
      },
      {
        "date": "2024-08-22T04:31:00.000Z",
        "voteCount": 1,
        "content": "Block blobs prefixed with \u201ctransactions\u201d will transition blobs that have not been modified in over 60 days to cool storage, and delete blobs not modified in 365 days.\nYes. This is correct based on the rule provided.\nBlobs are moved to cool storage if they have not been accessed for 60 days.\nNo. The rule is based on the creation date, not access date.\nThe policy rule tiers previous versions within a container named \u201ctransactions\u201d that are 60 days or older to the cool tier and deletes previous versions that are 365 days or older.\nNo. The rule applies to block blobs with the prefix \u201ctransactions,\u201d not specifically to previous versions within a container.\nBlobs will automatically be tiered from cool back to hot if accessed again after being tiered to cool.\nNo. As you correctly pointed out, the rule does not specify \u201cenableAutoTierToHotFromCool\u201d as true.\nSo, the correct answers should be: Yes, No, No, No."
      },
      {
        "date": "2024-08-16T00:16:00.000Z",
        "voteCount": 1,
        "content": "NO , NO ,YES ,NO . Last one is NO becouse you don't see \"enableAutoTierToHotFromColl\" : true"
      },
      {
        "date": "2024-03-22T06:56:00.000Z",
        "voteCount": 3,
        "content": "policy doesn't mention baseblob.\nSolution is:\n- No\n- No\n- Yes\n- No"
      },
      {
        "date": "2024-02-14T18:05:00.000Z",
        "voteCount": 6,
        "content": "Premium Block Blobs wont support access tiers and Lifecycle management policies (tiering)\nhttps://learn.microsoft.com/en-us/azure/storage/blobs/storage-feature-support-in-storage-accounts#premium-block-blob-accounts"
      },
      {
        "date": "2023-10-31T01:07:00.000Z",
        "voteCount": 3,
        "content": "3rd is YES, check the reference: \nhttps://learn.microsoft.com/en-us/azure/storage/blobs/lifecycle-management-overview\n\nOn the page it says: \"A prefix string must start with a container name. For example, if you want to match all blobs under https://myaccount.blob.core.windows.net/sample-container/blob1/... for a rule, the prefixMatch is sample-container/blob1.\" This means that the container name is \"transactions\"\n\nSo the only one that make me confusing is the 4th. According to the discussion, you have to manually enable \"enableAutoTierToHotFromCool\". And it is also mentioned above in the link that \"The enableAutoTierToHotFromCool action is available only when used with the daysAfterLastAccessTimeGreaterThan run condition. \" As in our case, the prerequisite for the auto tier to hot from cool is not even fulfilled, so it is not possible to expect an \"AutoTierToHotFromCool\" effect.\n\n I would go with a NO for the 4th."
      },
      {
        "date": "2023-09-26T10:29:00.000Z",
        "voteCount": 1,
        "content": "Question was on exam 2023-09-26"
      },
      {
        "date": "2023-09-26T10:31:00.000Z",
        "voteCount": 1,
        "content": "sorry, not this one, but similar with containers and numbers :)"
      },
      {
        "date": "2023-05-13T13:48:00.000Z",
        "voteCount": 2,
        "content": "Got this 2023-05-12.\nWithout 4th question.\n\nmy cases also:\ncase: You need to configure authorization.\ncase: You need to ensure the app does not time out and processes the blob data\ncase study: VanArsdel Inc Canada"
      },
      {
        "date": "2023-05-12T12:11:00.000Z",
        "voteCount": 1,
        "content": "Got this 2023-05-12.\n\nMy case:\ncase: You need to configure authorization.\ncase: You need to ensure the app does not time out and processes the blob data\ncase study: VanArsdel Inc Canada"
      },
      {
        "date": "2023-04-17T03:43:00.000Z",
        "voteCount": 8,
        "content": "received 2023-04-17 went N,N,Y, score 926\nlast box was not there only first three"
      },
      {
        "date": "2023-04-04T11:01:00.000Z",
        "voteCount": 4,
        "content": "premium block blob storage does not support access tiers. This is confusing"
      },
      {
        "date": "2023-03-30T01:38:00.000Z",
        "voteCount": 1,
        "content": "Question was in Exam 2023-03-30"
      },
      {
        "date": "2023-03-19T13:08:00.000Z",
        "voteCount": 4,
        "content": "Got this on 16/03/23. Make sure to prepare for case study. I got city and lights case study. No Kubernetes, Search, Logic Apps questions for me."
      },
      {
        "date": "2023-03-11T05:08:00.000Z",
        "voteCount": 2,
        "content": "Box 3: No ?\n'DayAfterCreationGraterThan 60' does not include 'just 60 days'. Therefore, if something has been made for 60 days, it would not be included in '60 days or later', so box 3 would be NO ?"
      },
      {
        "date": "2023-02-27T07:00:00.000Z",
        "voteCount": 3,
        "content": "Was on the exam 27.02.2023\nWent with NNYN.\nScore 870"
      },
      {
        "date": "2023-02-26T00:09:00.000Z",
        "voteCount": 2,
        "content": "Box 1, 2: No - this is about past versions, not about blobs \nBox 3: Yes - exactly policy description\nBox 4: No - first this is about past version not blob, second even blob moving back needs  enableAutoTierToHotFromCool"
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 27,
    "url": "https://www.examtopics.com/discussions/microsoft/view/79429-exam-az-204-topic-3-question-27-discussion/",
    "body": "An organization deploys Azure Cosmos DB.<br>You need to ensure that the index is updated as items are created, updated, or deleted.<br>What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSet the indexing mode to Lazy.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSet the value of the automatic property of the indexing policy to False.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSet the value of the EnableScanInQuery option to True.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSet the indexing mode to Consistent.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 5,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2022-09-02T07:29:00.000Z",
        "voteCount": 13,
        "content": "Correct !!!"
      },
      {
        "date": "2023-08-14T03:50:00.000Z",
        "voteCount": 4,
        "content": "Answer: D (consistent)\nSetting indexing mode to consistent ensures that index is updated in sync with data\n\nSetting it to lazy means index is updated async, meaning you may not get latest version of data\n\nSetting the value of the automatic property to false means you have to manually manage indexing of data\n\nSetting EnableScanInQuery to true allows query operations to perform scans across all documents, this is not really relevant + it provides poor performance"
      },
      {
        "date": "2023-07-11T11:53:00.000Z",
        "voteCount": 1,
        "content": "Setting the indexing mode to Consistent ensures that the index is always kept up to date with the changes made to the items in Azure Cosmos DB. With this mode, whenever an item is created, updated, or deleted, the index is automatically updated in real-time to reflect those changes."
      },
      {
        "date": "2023-03-12T11:34:00.000Z",
        "voteCount": 1,
        "content": "D indexing mode ensures that the index is always up-to-date with the data stored in the container and changes are immediately reflected in the index."
      },
      {
        "date": "2023-01-19T23:18:00.000Z",
        "voteCount": 3,
        "content": "Given answer is correct.\n\nConsistent: The index is updated synchronously as you create, update or delete items. This means that the consistency of your read queries will be the consistency configured for the account.\nNone: Indexing is disabled on the container. This mode is commonly used when a container is used as a pure key-value store without the need for secondary indexes. It can also be used to improve the performance of bulk operations. After the bulk operations are complete, the index mode can be set to Consistent and then monitored using the IndexTransformationProgress until complete."
      },
      {
        "date": "2022-12-01T08:24:00.000Z",
        "voteCount": 3,
        "content": "D. Set the indexing mode to Consistent."
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 28,
    "url": "https://www.examtopics.com/discussions/microsoft/view/79154-exam-az-204-topic-3-question-28-discussion/",
    "body": "You are developing a .Net web application that stores data in Azure Cosmos DB. The application must use the Core API and allow millions of reads and writes.<br>The Azure Cosmos DB account has been created with multiple write regions enabled. The application has been deployed to the East US2 and Central US regions.<br>You need to update the application to support multi-region writes.<br>What are two possible ways to achieve this goal? Each correct answer presents part of the solution.<br>NOTE: Each correct selection is worth one point.<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUpdate the ConnectionPolicy class for the Cosmos client and populate the PreferredLocations property based on the geo-proximity of the application.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUpdate Azure Cosmos DB to use the Strong consistency level. Add indexed properties to the container to indicate region.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUpdate the ConnectionPolicy class for the Cosmos client and set the UseMultipleWriteLocations property to true.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate and deploy a custom conflict resolution policy.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUpdate Azure Cosmos DB to use the Session consistency level. Send the SessionToken property value from the FeedResponse object of the write action to the end-user by using a cookie."
    ],
    "answer": "AC",
    "answerDescription": "",
    "votes": [
      {
        "answer": "AC",
        "count": 23,
        "isMostVoted": true
      },
      {
        "answer": "CD",
        "count": 5,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2022-10-09T12:58:00.000Z",
        "voteCount": 18,
        "content": "The goal is \n\n\"You need to update the application to support multi-region writes\", \n\nthat is enable multi-region writes (bool, option C) and add the regions (option A)\nThen you have to apply the Conflict resolution policies.This can be LLW(default, not mentioned) or custom (option D). \n\nHence :  there is only ONE way to to support multi-region writes (both apply C AND A) and there are subsequently TWO ways to apply the Conflict resolution policies (@ SQL) to solve write, update and delete conflicts of which one is mentioned in the question (D). \nTo support multi-region writes I would answer A and C , but they have to be set both, not one or the other.\nSee https://learn.microsoft.com/en-us/azure/cosmos-db/sql/how-to-multi-master?tabs=api-async and https://learn.microsoft.com/en-us/azure/cosmos-db/conflict-resolution-policies"
      },
      {
        "date": "2022-12-22T09:26:00.000Z",
        "voteCount": 4,
        "content": "From the documentation you provided:\nWithin the ConnectionPolicy, set UseMultipleWriteLocations to true and pass the name of the region where the application is deployed to ApplicationRegion. This will populate the PreferredLocations property based on the geo-proximity from location passed in. If a new region is later added to the account, the application does not have to be updated or redeployed, it will automatically detect the closer region and will auto-home on to it should a regional event occur.\n\nI take that paragraph to mean that it automatically updates the PreferredLocations property, when you set the UseMultipleWriteLocations property with true and pass the region name.\n\nThat means you actually only need to update UseMultipleWriteLocations, thus C.\n\nAnd as you mentioned, apply the Conflict resolution policies (D)."
      },
      {
        "date": "2023-02-26T00:46:00.000Z",
        "voteCount": 2,
        "content": "It's a trick. \"you must make two changes in your application to the ConnectionPolicy\" \"pass the name of the region where the application is deployed to ApplicationRegion. This will populate the PreferredLocations property\". I think this is an \"update\"\nhttps://learn.microsoft.com/en-us/azure/cosmos-db/nosql/how-to-multi-master?tabs=api-async#:~:text=you%20must%20make%20two%20changes%20in%20your%20application%20to%20the%20ConnectionPolicy"
      },
      {
        "date": "2023-02-14T07:32:00.000Z",
        "voteCount": 11,
        "content": "A + C = \nClearly stated in documentation that both are required: https://learn.microsoft.com/en-us/azure/cosmos-db/nosql/how-to-multi-master?tabs=api-async.\nAnd according to the question \"Each correct answer presents part of the solution\". \"Part\"\n\nNot D -&gt; \"Custom conflict resolution policy is available only for API for NoSQL accounts and can be set only at creation time.\" The question states the account was already created.\nSource: https://learn.microsoft.com/en-us/azure/cosmos-db/conflict-resolution-policies"
      },
      {
        "date": "2024-08-05T13:56:00.000Z",
        "voteCount": 1,
        "content": "D is not answer, Conflict resolution policy can only be specified at container creation time and cannot be modified after container creation, however the question mentions that \"You need to update the application to support multi-region writes.\", so we suppose that the containter has been created before we update ConnectionPolicy, so D is not applicable.\nThe answer is C+A, set UseMultipleWriteLocation and PreferredLocation."
      },
      {
        "date": "2023-12-26T17:49:00.000Z",
        "voteCount": 1,
        "content": "C. Setting the UseMultipleWriteLocations property to true allows the Cosmos DB SDK to automatically route write operations to the closest available write region, improving write latency. This is a key configuration for enabling multi-region writes.\nD -  is relevant in scenarios where conflict resolution needs customization,"
      },
      {
        "date": "2023-07-30T07:25:00.000Z",
        "voteCount": 1,
        "content": "got this question today, answer A,C - 7/30/2023, score 895/1000"
      },
      {
        "date": "2023-06-29T06:40:00.000Z",
        "voteCount": 2,
        "content": "Got this on 6/28/2023 and passed with 850.  Went with A, C."
      },
      {
        "date": "2023-05-22T21:13:00.000Z",
        "voteCount": 2,
        "content": "A&amp;C to support multi-region writes"
      },
      {
        "date": "2023-04-22T06:47:00.000Z",
        "voteCount": 2,
        "content": "A &amp; C\nhttps://learn.microsoft.com/en-us/azure/cosmos-db/sql/how-to-multi-master?tabs=api-async"
      },
      {
        "date": "2023-04-12T15:57:00.000Z",
        "voteCount": 2,
        "content": "A,C chat gpt"
      },
      {
        "date": "2023-02-15T00:17:00.000Z",
        "voteCount": 1,
        "content": "A&amp;C\n\n\nConnectionPolicy, set UseMultipleWriteLocations to true and pass the name of the region where the application is deployed to ApplicationRegion. This will populate the PreferredLocations property based on the geo-proximity from location passed in\n\nhttps://learn.microsoft.com/en-us/azure/cosmos-db/nosql/how-to-multi-master?tabs=api-async"
      },
      {
        "date": "2023-02-06T02:30:00.000Z",
        "voteCount": 2,
        "content": "Answer should be CD\nThe questions mentions .NET web application and if you check below link you can see for .net the option C goes \nAnd for multi write scenarios conflict might arise and hence option D\nhttps://learn.microsoft.com/en-us/azure/cosmos-db/nosql/how-to-multi-master?tabs=api-async"
      },
      {
        "date": "2023-01-19T23:42:00.000Z",
        "voteCount": 1,
        "content": "AC are the correct answers as per microsoft docs\nhttps://learn.microsoft.com/en-us/azure/cosmos-db/nosql/how-to-multi-master?tabs=api-async"
      },
      {
        "date": "2023-01-08T17:13:00.000Z",
        "voteCount": 4,
        "content": "Option C: Update the ConnectionPolicy class for the Cosmos client and set the UseMultipleWriteLocations property to true. This will enable the application to use multiple write regions when storing data in Azure Cosmos DB.\nOption A: Update the ConnectionPolicy class for the Cosmos client and populate the PreferredLocations property based on the geo-proximity of the application. This will allow the application to use the closest write region to the application's location, improving performance and reducing latency.\nOther options, such as updating the consistency level or creating a custom conflict resolution policy, are not directly related to enabling multi-region writes and are not necessary for this goal."
      },
      {
        "date": "2022-12-30T05:41:00.000Z",
        "voteCount": 2,
        "content": "As stated by others"
      },
      {
        "date": "2022-12-23T01:50:00.000Z",
        "voteCount": 4,
        "content": "Correct answers should be A and C\n\nConnectionPolicy policy = new ConnectionPolicy\n    {\n        ConnectionMode = ConnectionMode.Direct,\n        ConnectionProtocol = Protocol.Tcp,\n        UseMultipleWriteLocations = true ----&gt; C\n    };\npolicy.SetCurrentLocation(\"West US 2\"); -----&gt; A"
      },
      {
        "date": "2022-12-23T01:55:00.000Z",
        "voteCount": 1,
        "content": "Sorry SetCurrentLocation is only the region in which the application is being deployed and where Azure Cosmos DB is replicated. But the ConnectionPolicy class does also have a property PreferredLocations: Gets and sets the preferred locations (regions) for geo-replicated database accounts in the Azure Cosmos DB service. For example, \"East US\" as the preferred location."
      },
      {
        "date": "2022-10-03T22:42:00.000Z",
        "voteCount": 1,
        "content": "C and D are the correct answers?"
      },
      {
        "date": "2022-12-24T08:06:00.000Z",
        "voteCount": 1,
        "content": "IMO C and D"
      },
      {
        "date": "2022-09-30T00:20:00.000Z",
        "voteCount": 2,
        "content": "The documentation says: \" To enable multi-region writes in your application, set ApplicationRegion to the region in which the application is being deployed and where Cosmos DB is replicated\"\nNow the option to use that property is in .Net SDK V2. Microsoft says I do not need to know .Net for this exam and they ask questions from V2? So, I should try this in both v2 and v3 to be able to pass this exam."
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 29,
    "url": "https://www.examtopics.com/discussions/microsoft/view/79375-exam-az-204-topic-3-question-29-discussion/",
    "body": "HOTSPOT -<br>You are developing a solution to store documents in Azure Blob storage. Customers upload documents to multiple containers. Documents consist of PDF, CSV,<br>Microsoft Office format and plain text files.<br>The solution must process millions of documents across hundreds of containers. The solution must meet the following requirements:<br>\u2711 Documents must be categorized by a customer identifier as they are uploaded to the storage account.<br>\u2711 Allow filtering by the customer identifier.<br>\u2711 Allow searching of information contained within a document<br>\u2711 Minimize costs.<br>You create and configure a standard general-purpose v2 storage account to support the solution.<br>You need to implement the solution.<br>What should you implement? To answer, select the appropriate options in the answer area.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04273/0026300001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04273/0026400001.png\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: Azure Blob index tags -<br>As datasets get larger, finding a specific object in a sea of data can be difficult. Blob index tags provide data management and discovery capabilities by using key- value index tag attributes. You can categorize and find objects within a single container or across all containers in your storage account. As data requirements change, objects can be dynamically categorized by updating their index tags. Objects can remain in-place with their current container organization.<br><br>Box 2: Azure Cognitive Search -<br>Only index tags are automatically indexed and made searchable by the native Blob Storage service. Metadata can't be natively indexed or searched. You must use a separate service such as Azure Search.<br>Azure Cognitive Search is the only cloud search service with built-in AI capabilities that enrich all types of information to help you identify and explore relevant content at scale. Use cognitive skills for vision, language, and speech, or use custom machine learning models to uncover insights from all types of content.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/storage/blobs/storage-manage-find-blobs https://azure.microsoft.com/en-us/services/search/",
    "votes": [],
    "comments": [
      {
        "date": "2022-09-02T04:29:00.000Z",
        "voteCount": 19,
        "content": "right\nAzure Blob Index tags: https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blob-index-how-to?tabs=azure-portal\nAzure Cognitive Search: Search inside documents"
      },
      {
        "date": "2022-11-15T06:49:00.000Z",
        "voteCount": 7,
        "content": "Did my exam on 15th November 2022. This question was on it."
      },
      {
        "date": "2024-09-22T09:42:00.000Z",
        "voteCount": 1,
        "content": "1. Search and filter by customer identifier:\nSolution: Azure Blob index tags\nReason: Azure Blob index tags allow you to tag blobs with metadata such as a customer identifier. These tags make it easy to search and filter blobs based on specific attributes without the need to load or examine the entire content of the blob. This solution is efficient for filtering blobs by customer identifier.\n\n2. Search information inside documents:\nSolution: Azure Cognitive Search\nReason: Azure Cognitive Search is the appropriate solution for searching within the content of documents. It allows you to index the content of blobs stored in Azure Blob Storage, including PDFs, CSVs, Microsoft Office formats, and more. Cognitive Search extracts text and metadata from the documents, enabling advanced search functionality."
      },
      {
        "date": "2024-04-28T00:54:00.000Z",
        "voteCount": 2,
        "content": "Got it on 20 April 2024...Marks &gt; 900...All questions from examtopics 400 questions...\nanswer is correct..."
      },
      {
        "date": "2024-01-23T01:34:00.000Z",
        "voteCount": 4,
        "content": "Answer is correct but keep in mind that Azure Cognitive Search is renamed to Azure AI Search. See: https://learn.microsoft.com/en-us/azure/search/search-what-is-azure-search"
      },
      {
        "date": "2023-11-08T23:35:00.000Z",
        "voteCount": 7,
        "content": "On exam 9 Nov 2023, went with given answer, socre 865. Case Study: Farmers and Distributors"
      },
      {
        "date": "2023-11-10T00:22:00.000Z",
        "voteCount": 6,
        "content": "Farmers and Distributors is that a new case study?"
      },
      {
        "date": "2024-01-20T05:38:00.000Z",
        "voteCount": 2,
        "content": "Yes, now is present in ExamTopics."
      },
      {
        "date": "2023-10-01T09:11:00.000Z",
        "voteCount": 1,
        "content": "As per Goodle Bard this is correct ans.\nAzure Blob index tags\nAzure Cognitive Search"
      },
      {
        "date": "2023-07-13T04:09:00.000Z",
        "voteCount": 2,
        "content": "1. metadata\n2. cognitive search"
      },
      {
        "date": "2023-06-10T01:43:00.000Z",
        "voteCount": 3,
        "content": "This question was in today's exam on 10-June-2023"
      },
      {
        "date": "2023-02-28T14:08:00.000Z",
        "voteCount": 3,
        "content": "On my exam 2023-02-25"
      },
      {
        "date": "2023-02-28T05:46:00.000Z",
        "voteCount": 2,
        "content": "This question was on the 24/02/2023"
      },
      {
        "date": "2023-02-17T14:24:00.000Z",
        "voteCount": 3,
        "content": "This question was on exam on 17/02/23."
      },
      {
        "date": "2023-01-19T23:55:00.000Z",
        "voteCount": 4,
        "content": "Given answers are correct \nAzure blob index tags\nCognitive serach\nhttps://learn.microsoft.com/en-us/azure/search/search-blob-storage-integration"
      },
      {
        "date": "2022-12-23T09:01:00.000Z",
        "voteCount": 3,
        "content": "Did my exam on 17th December 2022. This question was on it."
      },
      {
        "date": "2022-12-25T08:18:00.000Z",
        "voteCount": 2,
        "content": "examtopic questions are enough to pass ?"
      },
      {
        "date": "2023-09-29T01:02:00.000Z",
        "voteCount": 2,
        "content": "Also follow some course on Udemy (or Pluralsight), just to see actions, and read all the discussions here on ExamTopics. Then, if you have time/energy, study Microsoft docs."
      },
      {
        "date": "2022-12-31T06:15:00.000Z",
        "voteCount": 4,
        "content": "No - you need a lot of other resources in order to get a better chance. The Microsoft exams are no joke."
      },
      {
        "date": "2022-12-10T05:54:00.000Z",
        "voteCount": 2,
        "content": "1. index tag\n2. cognitive search"
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 30,
    "url": "https://www.examtopics.com/discussions/microsoft/view/79433-exam-az-204-topic-3-question-30-discussion/",
    "body": "HOTSPOT -<br>You are developing a web application by using the Azure SDK. The web application accesses data in a zone-redundant BlockBlobStorage storage account.<br>The application must determine whether the data has changed since the application last read the data. Update operations must use the latest data changes when writing data to the storage account.<br>You need to implement the update operations.<br>Which values should you use? To answer, select the appropriate option in the answer area.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04273/0026600001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04273/0026700001.png\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: Last Modified -<br>The Last-Modified response HTTP header contains a date and time when the origin server believes the resource was last modified. It is used as a validator to determine if the resource is the same as the previously stored one. Less accurate than an ETag header, it is a fallback mechanism.<br><br>Box 2: If-Modified-Since -<br>Conditional Header If-Modified-Since:<br>A DateTime value. Specify this header to perform the operation only if the resource has been modified since the specified time.<br>Incorrect:<br><br>Not ETag/If-Match -<br>Conditional Header If-Match:<br>An ETag value. Specify this header to perform the operation only if the resource's ETag matches the value specified. For versions 2011-08-18 and newer, the<br>ETag can be specified in quotes.<br>Reference:<br>https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Last-Modified https://docs.microsoft.com/en-us/rest/api/storageservices/specifying-conditional-headers-for-blob-service-operations",
    "votes": [],
    "comments": [
      {
        "date": "2022-09-06T05:01:00.000Z",
        "voteCount": 42,
        "content": "I think it should be:\n- ETag - server returns this tag for a resource to ensure we operate on the same version of the resource in subsequent API calls\n- If-Match - update is processed by the server only if the ETag provided matches the latest resource version ETag \n\nThe reason for that is we want to make sure we update the latest version of a resource:\n\"Update operations must use the latest data changes when writing\" \nSo, when using Last-Modified with If-Modified-Since, the operation executes only when another client modifies the resource between our READ and WRITE operations.\nIf we wanted to use Last-Modified instead, we would need If-Unmodified-Since instead."
      },
      {
        "date": "2024-07-25T06:35:00.000Z",
        "voteCount": 1,
        "content": "i agree , good explanation."
      },
      {
        "date": "2022-09-10T13:12:00.000Z",
        "voteCount": 4,
        "content": "I agree with you. (ETag + If-Match)\nhttps://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/If-Match"
      },
      {
        "date": "2022-09-30T00:34:00.000Z",
        "voteCount": 20,
        "content": "I referred to the documentation also and I cannot convince my mind I care enough to even understand this because there is no chance I will ever have to know these options in details unless I have to use it. Who reads and understands all these information when this is available as documentation and with Microsoft documentation it is all about trial and error and hoping for the best"
      },
      {
        "date": "2024-09-22T07:08:00.000Z",
        "voteCount": 1,
        "content": "Based on the scenario where you need to implement update operations for a web application accessing data in a zone-redundant BlockBlobStorage storage account, the application must ensure it uses the latest data by checking whether the data has changed since it was last read. Here are the appropriate choices:\n\n1. HTTP Header value:\nETag\nReason: The ETag (Entity Tag) is a unique identifier assigned to a specific version of a resource. It is used to determine if the data has changed since the last request. When you read the data, you get the ETag, and when performing update operations, you can compare the ETag to ensure you are working with the latest version of the data.\n\n2. Conditional header:\nIf-Match\nReason: The If-Match header is used to perform operations only if the ETag of the resource matches the one specified in the request. This ensures that updates happen only if the resource hasn't been modified since it was last read, preventing overwrites of more recent updates."
      },
      {
        "date": "2023-09-28T07:46:00.000Z",
        "voteCount": 4,
        "content": "Got examn 28/09/23"
      },
      {
        "date": "2023-09-22T05:10:00.000Z",
        "voteCount": 2,
        "content": "both are wrong in given solution. \nCorrect anser - etag and If-match"
      },
      {
        "date": "2023-08-17T02:26:00.000Z",
        "voteCount": 2,
        "content": "It's ETag and If-Match.\n\nThe ETag (Entity Tag) is an HTTP header that represents a unique identifier for a version of the resource. When sending an update request, you can include the If-Match header with the ETag value of the data you previously read. If the current ETag of the resource matches the provided ETag, it means the data hasn't changed."
      },
      {
        "date": "2023-07-13T04:18:00.000Z",
        "voteCount": 1,
        "content": "Correct answer"
      },
      {
        "date": "2023-05-07T17:30:00.000Z",
        "voteCount": 2,
        "content": "It is Etag and If-Match\n\ncheck this page https://learn.microsoft.com/en-us/rest/api/storageservices/specifying-conditional-headers-for-blob-service-operations for conditional header \"If-Match\" - We can specify ETag value. Specify this header to perform the operation only if the resource's ETag matches the value specified."
      },
      {
        "date": "2023-03-31T20:01:00.000Z",
        "voteCount": 1,
        "content": "Etag and if-match  ChatGPT"
      },
      {
        "date": "2023-02-23T03:45:00.000Z",
        "voteCount": 1,
        "content": "Since we also need the update to work which is a PUT operation the correct answer is ETag/If-Match"
      },
      {
        "date": "2023-02-16T14:54:00.000Z",
        "voteCount": 2,
        "content": "ETag\nIf-Match\n\nThere are 2 possible options to validate an update against unwanted changes:\n - ETag + If-Match\n - Last-Modified + If-Unmodified-Since\n\nThe second option is not available here, so it must be the first one. Besides, even if it was available, it would still be better to check ETag, because Last-Modified is weaker (it has only 1-second resolution, so it does not detect 2 changes within 1 second, so you cannot ensure you have the latest version) and I guess the zone-redundancy may also play some role in how Last-Modified is handled."
      },
      {
        "date": "2023-02-16T01:41:00.000Z",
        "voteCount": 5,
        "content": "For those who have taken AZ-204 test, should I trust ExamTopics answers or the Community's answers?"
      },
      {
        "date": "2023-04-06T20:02:00.000Z",
        "voteCount": 7,
        "content": "You should trust the discussions and other users experiencies. The default answers in the questions might be right or wrong."
      },
      {
        "date": "2023-01-23T02:17:00.000Z",
        "voteCount": 4,
        "content": "Etag, If-Match are correct answers as per MS docs\nOptimistic concurrency: An application performing an update will, as part of its update, determine whether the data has changed since the application last read that data. For example, if two users viewing a wiki page make an update to that page, then the wiki platform must ensure that the second update does not overwrite the first update. It must also ensure that both users understand whether their update was successful. This strategy is most often used in web applications.\nhttps://learn.microsoft.com/en-us/azure/storage/blobs/concurrency-manage?tabs=dotnet"
      },
      {
        "date": "2023-01-15T05:49:00.000Z",
        "voteCount": 1,
        "content": "I think it should be E-tag and if-none-match.\nSee the following source on how e-tag works: https://en.wikipedia.org/wiki/HTTP_ETag"
      },
      {
        "date": "2023-01-08T14:07:00.000Z",
        "voteCount": 2,
        "content": "I think the answer is correct. The question is asking explicitly if \"data changed since the application last read the data\", so we must evaluate against the date, hence If-Modified-Since."
      },
      {
        "date": "2022-12-28T01:30:00.000Z",
        "voteCount": 7,
        "content": "Answer is correct - in my opinion.\n\n- ETag - The ETag (or entity tag) HTTP response header is an identifier for a specific version of a resource. (Version!)\n- Last-Modified - The Last-Modified response HTTP header contains a date and time when the origin server believes the resource was last modified. (Date and Time!)\n(Source: https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers)\n\nIn Question: The application must determine whether the data has changed since the application last read the data. \nMy understanding: We are working on dates, not versions! So, Last-Modified and If-Modified-Since are better options.\n\nPS: I honestly have no idea why I need to know this for Azure Certification Exam :(("
      },
      {
        "date": "2022-11-29T09:25:00.000Z",
        "voteCount": 1,
        "content": "Got this question in the exam 27/11/2022, anyone, please mention the correct answer and explain"
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 31,
    "url": "https://www.examtopics.com/discussions/microsoft/view/79435-exam-az-204-topic-3-question-31-discussion/",
    "body": "HOTSPOT -<br>An organization deploys a blob storage account. Users take multiple snapshots of the blob storage account over time.<br>You need to delete all snapshots of the blob storage account. You must not delete the blob storage account itself.<br>How should you complete the code segment? To answer, select the appropriate options in the answer area.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04273/0026800001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04273/0026900001.jpg\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: DeleteSnapshotsOption -<br>Sample code in powershell:<br>//dont forget to add the include snapshots :)<br>await batchClient.DeleteBlobsAsync(listofURIforBlobs,<br>Azure.Storage.Blobs.Models.DeleteSnapshotsOption.IncludeSnapshots);<br>Sample code in .Net:<br>// Create a batch with three deletes<br>BlobBatchClient batchClient = service.GetBlobBatchClient();<br>BlobBatch batch = batchClient.CreateBatch();<br>batch.DeleteBlob(foo.Uri, DeleteSnapshotsOption.IncludeSnapshots); batch.DeleteBlob(bar.Uri, DeleteSnapshotsOption.OnlySnapshots); batch.DeleteBlob(baz.Uri);<br>// Submit the batch<br>batchClient.SubmitBatch(batch);<br><br>Box 2: OnlySnapshots -<br>Reference:<br>https://docs.microsoft.com/en-us/dotnet/api/overview/azure/storage.blobs.batch-readme https://stackoverflow.com/questions/39471212/programmatically-delete-azure-blob-storage-objects-in-bulks",
    "votes": [],
    "comments": [
      {
        "date": "2022-10-10T01:09:00.000Z",
        "voteCount": 19,
        "content": "it is DeleteSnapshotsOption.OnlySnapshots but the explanation in the answer is bogus as usual.\nsee https://learn.microsoft.com/en-us/dotnet/api/azure.storage.blobs.models.deletesnapshotsoption?view=azure-dotnet"
      },
      {
        "date": "2022-11-11T18:26:00.000Z",
        "voteCount": 3,
        "content": "Yeah, we can ignore the explanation on this one,\nWe can use OnlySnapshots"
      },
      {
        "date": "2023-02-13T06:03:00.000Z",
        "voteCount": 7,
        "content": "It was there in 13 Feb 2023 exam"
      },
      {
        "date": "2024-03-13T00:44:00.000Z",
        "voteCount": 2,
        "content": "Is correct, https://learn.microsoft.com/en-us/azure/storage/blobs/storage-blob-delete\n\npublic static async Task DeleteBlobSnapshotsAsync(BlobClient blob)\n{\n    // Delete a blob and all of its snapshots\n    await blob.DeleteAsync(snapshotsOption: DeleteSnapshotsOption.IncludeSnapshots);\n\n    // Delete only the blob's snapshots\n    //await blob.DeleteAsync(snapshotsOption: DeleteSnapshotsOption.OnlySnapshots);\n}"
      },
      {
        "date": "2023-11-08T23:35:00.000Z",
        "voteCount": 2,
        "content": "On exam 9 Nov 2023, went with given answer, socre 865. Case Study: Farmers and Distributors"
      },
      {
        "date": "2024-01-09T08:39:00.000Z",
        "voteCount": 1,
        "content": "Where can I find the case studies on this site."
      },
      {
        "date": "2024-01-20T10:55:00.000Z",
        "voteCount": 1,
        "content": "Now is present."
      },
      {
        "date": "2023-10-23T19:22:00.000Z",
        "voteCount": 1,
        "content": "correct."
      },
      {
        "date": "2023-06-10T01:44:00.000Z",
        "voteCount": 2,
        "content": "This question was in today's exam on 10-June-2023"
      },
      {
        "date": "2023-04-04T21:03:00.000Z",
        "voteCount": 4,
        "content": "Got this in exam today (5 April 2023)"
      },
      {
        "date": "2023-01-20T05:16:00.000Z",
        "voteCount": 1,
        "content": "Given options are correct\nhttps://learn.microsoft.com/en-us/dotnet/api/azure.storage.blobs.models.deletesnapshotsoption?view=azure-dotnet"
      },
      {
        "date": "2022-12-13T03:49:00.000Z",
        "voteCount": 4,
        "content": "DeleteSnapshotsOption.OnlySnapshots"
      },
      {
        "date": "2022-09-02T07:45:00.000Z",
        "voteCount": 5,
        "content": "Correct!!"
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 32,
    "url": "https://www.examtopics.com/discussions/microsoft/view/82038-exam-az-204-topic-3-question-32-discussion/",
    "body": "HOTSPOT -<br>An organization deploys a blob storage account. Users take multiple snapshots of the blob storage account over time.<br>You need to delete all snapshots of the blob storage account. You must not delete the blob storage account itself.<br>How should you complete the code segment? To answer, select the appropriate options in the answer area.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04273/0027000001.jpg\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04273/0027000002.jpg\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: delete_snapshots -<br># Delete only the snapshot (blob itself is retained)<br>blob_client.delete_blob(delete_snapshots=\"only\")<br><br>Box 2: only -<br>Reference:<br>https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/storage/azure-storage-blob/samples/blob_samples_common.py",
    "votes": [],
    "comments": [
      {
        "date": "2022-09-30T00:38:00.000Z",
        "voteCount": 36,
        "content": "So, according to Microsoft a developer has to remember how the Microsoft guy chose to write in the .Net library and also how the python person thought and the unfortunate inconsistencies they built into these APIs?"
      },
      {
        "date": "2023-11-03T04:13:00.000Z",
        "voteCount": 3,
        "content": "I've read somewhere that before starting an exam you select in which language you are programming. Based on that you will get customize language questions/answers."
      },
      {
        "date": "2022-12-24T06:06:00.000Z",
        "voteCount": 4,
        "content": "or you can retake the exam?"
      },
      {
        "date": "2022-12-27T14:52:00.000Z",
        "voteCount": 1,
        "content": "haha I think you are right"
      },
      {
        "date": "2022-09-25T02:56:00.000Z",
        "voteCount": 16,
        "content": "The answer looks correct and the link proves it:\nLink to exact line with comment:\nhttps://github.com/Azure/azure-sdk-for-python/blob/main/sdk/storage/azure-storage-blob/samples/blob_samples_common.py#L65"
      },
      {
        "date": "2023-12-23T16:04:00.000Z",
        "voteCount": 1,
        "content": "I think given answer is correct."
      },
      {
        "date": "2023-10-23T19:28:00.000Z",
        "voteCount": 1,
        "content": "given answers are correct."
      },
      {
        "date": "2023-01-20T05:23:00.000Z",
        "voteCount": 1,
        "content": "Given answers are correct\nhttps://github.com/Azure/azure-sdk-for-python/blob/main/sdk/storage/azure-storage-blob/samples/blob_samples_common.py"
      },
      {
        "date": "2022-12-30T07:40:00.000Z",
        "voteCount": 4,
        "content": "Ah yes my favorite thing as developer - to remember what is something doing instead of google it.. lmao nice \"exam\" micro$oft"
      },
      {
        "date": "2022-09-23T03:20:00.000Z",
        "voteCount": 4,
        "content": "Correct\nRequired if the blob has associated snapshots. Values include:\n\n\"only\": Deletes only the blobs snapshots.\n\n\"include\": Deletes the blob along with all snapshots.\nhttps://learn.microsoft.com/en-us/azure/developer/python/sdk/storage/azure-storage-blob/azure.storage.blob.containerclient?view=storage-py-v12"
      },
      {
        "date": "2022-09-14T03:55:00.000Z",
        "voteCount": 5,
        "content": "Weird comments. When there is only 1 or 2 comments, everyone is saying examtopics is correct..."
      },
      {
        "date": "2022-09-13T10:08:00.000Z",
        "voteCount": 2,
        "content": "Correct!"
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 33,
    "url": "https://www.examtopics.com/discussions/microsoft/view/94493-exam-az-204-topic-3-question-33-discussion/",
    "body": "HOTSPOT<br> -<br><br>You are developing an application that monitors data added to an Azure Blob storage account.<br><br>You need to process each change made to the storage account.<br><br>How should you complete the code segment? To answer, select the appropriate options in the answer area.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/az-204/image389.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/az-204/image390.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2023-01-11T11:58:00.000Z",
        "voteCount": 77,
        "content": "I've tried the code in VS. Here's some thoughts:\n1. box:\n - GetChanges() - wrong - var c in the foreach would be BlobChangeFeedEvent which doesn't contain Values property used in ProcessChanges(c.Values) line below\n- GetChangesAsync - wrong - code won't compile because it would require await foreach loop instead\n- GetChanges(x).AsPages() - correct - it's the only option to make this code even compile\n- GetChanges(x).GetEnumerator() - wrong - you cannot use IEnumerator type as foreach source\n2. box:\n- x = c.ContinuationToken - right - variable x was used as continuationToken parameter in changeFeedClient.GetChanges(x).AsPages() above\n- c.GetRawResponse().ReasonPhrase - wrong - that does not make sense to use this value as continuation token\n- x = c.Values.Min - wrong - continuation token is a number not date\n- x = c.Values.Max - wrong - as above\n\nSo to sum up\n1. changeFeedClient.GetChanges(x).AsPages()\n2. x = c.ContinuationToken;\n\nYou can find more about Continuation Token here:\nhttps://jessehouwing.net/azure-devops-accessing-apis-with-large-volumes-of-data/"
      },
      {
        "date": "2023-07-30T07:27:00.000Z",
        "voteCount": 3,
        "content": "got this question today, go with this answer - 7/30/2023, score 895/1000"
      },
      {
        "date": "2023-09-23T06:39:00.000Z",
        "voteCount": 2,
        "content": "Does all questions came from exam topics ?"
      },
      {
        "date": "2023-10-17T05:08:00.000Z",
        "voteCount": 1,
        "content": "The majority of the questions"
      },
      {
        "date": "2023-01-21T02:55:00.000Z",
        "voteCount": 4,
        "content": "Agree.\n\nBox 1. GetChanges(x).AsPages()\nBox 2. ContinuationToken"
      },
      {
        "date": "2023-01-27T10:18:00.000Z",
        "voteCount": 4,
        "content": "you are right... \n1. changeFeedClient.GetChanges(x).AsPages() -&gt; returns an IEnumerable&lt;Page&lt;BlobChangeFeedEvent&gt;&gt; ... when you loop through these pages \"Page&lt;BlobChangeFeedEvent&gt;\" you will get the options \"page.ContinuationToken\" and page.Values which are used in this example\n100% Correct...\nfound the code here\nhttps://github.com/Azure/azure-sdk-for-net/tree/main/sdk/storage/Azure.Storage.Blobs.ChangeFeed#resume-with-continuationtoken"
      },
      {
        "date": "2023-02-26T09:33:00.000Z",
        "voteCount": 3,
        "content": "var x = default(string);\nso, x is string\nContinuationToken is not string"
      },
      {
        "date": "2024-08-22T05:00:00.000Z",
        "voteCount": 1,
        "content": "The Answer is correct!!\nvar changeFeedClient = new BlobServiceClient(\"..\").GetChangeFeedClient();\nvar continuationToken = default(string);\n\nwhile (true)\n{\n    var changeFeed = changeFeedClient.GetChanges(continuationToken);\n    foreach (var change in changeFeed)\n    {\n        continuationToken = change.ContinuationToken;\n        ProcessChanges(change.Values);\n    }\n}\nhttps://learn.microsoft.com/en-us/dotnet/api/azure.storage.blobs.changefeed.blobchangefeedclient.getchanges?view=azure-dotnet-preview#azure-storage-blobs-changefeed-blobchangefeedclient-getchanges"
      },
      {
        "date": "2024-08-05T14:40:00.000Z",
        "voteCount": 1,
        "content": "The answer is incorrect, continuationToken points to the position of the last processed change event, changeFeedClient.Getchanges(x).AsPages retrieves changes in chunks or pages so it's more efficient Handling."
      },
      {
        "date": "2024-05-30T06:09:00.000Z",
        "voteCount": 1,
        "content": "For those who are wondering of the answer see this link by following the methods you see its using above above.\n\n1. GetChanges(x).AsPages()\n2. ContinuationToken\n\nis the correct answer"
      },
      {
        "date": "2024-05-30T06:09:00.000Z",
        "voteCount": 1,
        "content": "https://learn.microsoft.com/en-us/dotnet/api/azure.storage.blobs.changefeed.blobchangefeedclient.getchanges?view=azure-dotnet-preview#azure-storage-blobs-changefeed-blobchangefeedclient-getchanges"
      },
      {
        "date": "2024-04-28T00:55:00.000Z",
        "voteCount": 3,
        "content": "Got it on 20 April 2024...Marks &gt; 900...All questions from examtopics 400 questions...\n- GetChanges(x).AsPages()\nContinuationToken;"
      },
      {
        "date": "2024-01-21T09:38:00.000Z",
        "voteCount": 2,
        "content": "Jan-21-2024 - This was in my exam  - Score 740, just border :) Didnt purchased contributor access.\nContosso case study [Couldnt find here]"
      },
      {
        "date": "2024-01-10T00:20:00.000Z",
        "voteCount": 2,
        "content": "This question was on exam. 09/01/2024. Passed 872."
      },
      {
        "date": "2023-09-25T09:17:00.000Z",
        "voteCount": 2,
        "content": "Got this quesiton in examn - 2023.09.25. Got Case Study Contoso"
      },
      {
        "date": "2023-12-15T05:22:00.000Z",
        "voteCount": 1,
        "content": "What answer you selected?"
      },
      {
        "date": "2023-07-25T20:43:00.000Z",
        "voteCount": 1,
        "content": "Had this question in today's exam: 2023-07-26"
      },
      {
        "date": "2023-02-28T14:09:00.000Z",
        "voteCount": 2,
        "content": "On my exam 2023-02-25"
      },
      {
        "date": "2023-02-17T14:25:00.000Z",
        "voteCount": 1,
        "content": "This question was on exam on 17/02/23."
      },
      {
        "date": "2023-02-20T21:42:00.000Z",
        "voteCount": 1,
        "content": "what answer do you put ?"
      },
      {
        "date": "2023-01-20T05:38:00.000Z",
        "voteCount": 2,
        "content": "As per Microsoft docs:\nGetchangesAsync(), contiuationtoken are correct\n\nhttps://learn.microsoft.com/en-us/azure/storage/blobs/storage-blob-change-feed-how-to"
      },
      {
        "date": "2023-01-24T13:43:00.000Z",
        "voteCount": 3,
        "content": "for GetchangesAsync you need the async await approach"
      },
      {
        "date": "2023-02-13T04:41:00.000Z",
        "voteCount": 5,
        "content": "Async option can be ignore, it requires 'await', which is not there in this situation"
      },
      {
        "date": "2023-01-10T08:17:00.000Z",
        "voteCount": 1,
        "content": "I believe it should be await... getchangesasync.... then getrawresponse, as x is a string. I don't see the connection to cancellationtoken."
      },
      {
        "date": "2023-01-08T13:40:00.000Z",
        "voteCount": 3,
        "content": "i think the fisrt box must be : getChangesAsync()\nthe second one is correct\nsource : https://learn.microsoft.com/en-us/azure/storage/blobs/storage-blob-change-feed-how-to"
      },
      {
        "date": "2023-04-08T12:40:00.000Z",
        "voteCount": 2,
        "content": "I don't agree. There is no await statement before the method"
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 34,
    "url": "https://www.examtopics.com/discussions/microsoft/view/94727-exam-az-204-topic-3-question-34-discussion/",
    "body": "HOTSPOT<br> -<br><br>You develop an application that sells AI generated images based on user input. You recently started a marketing campaign that displays unique ads every second day.<br><br>Sales data is stored in Azure Cosmos DB with the date of each sale being stored in a property named \u2018whenFinished\u2019.<br><br>The marketing department requires a view that shows the number of sales for each unique ad.<br>You need to implement the query for the view.<br><br>How should you complete the query? To answer, select the appropriate options in the answer area.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/az-204/image391.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/az-204/image392.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2023-01-12T10:18:00.000Z",
        "voteCount": 24,
        "content": "Correct!\nCan't be DateTimePart as it takes two args only, see https://learn.microsoft.com/en-us/azure/cosmos-db/nosql/query/date-time-functions"
      },
      {
        "date": "2023-01-15T06:01:00.000Z",
        "voteCount": 2,
        "content": "You are right good sir I stand corrected."
      },
      {
        "date": "2023-06-10T01:44:00.000Z",
        "voteCount": 6,
        "content": "This question was in today's exam on 10-June-2023"
      },
      {
        "date": "2024-06-14T01:51:00.000Z",
        "voteCount": 1,
        "content": "\"The marketing department requires a view that shows the number of sales for each unique ad.\"  - where is the ad in the query?"
      },
      {
        "date": "2024-02-13T03:14:00.000Z",
        "voteCount": 4,
        "content": "On exam 2024, went with given answer, score 872 or something. Case Study: Farmers and Distributors"
      },
      {
        "date": "2023-11-08T23:36:00.000Z",
        "voteCount": 4,
        "content": "On exam 9 Nov 2023, went with given answer, socre 865. Case Study: Farmers and Distributors"
      },
      {
        "date": "2023-11-21T10:41:00.000Z",
        "voteCount": 1,
        "content": "This question was inside that Case Study?"
      },
      {
        "date": "2023-09-28T07:48:00.000Z",
        "voteCount": 1,
        "content": "got today in 28-09-23"
      },
      {
        "date": "2023-04-26T01:03:00.000Z",
        "voteCount": 2,
        "content": "why count and not sum?"
      },
      {
        "date": "2023-05-24T08:33:00.000Z",
        "voteCount": 1,
        "content": "[...]The marketing department requires a view that shows the \"number of sales\"[...]"
      },
      {
        "date": "2023-09-20T07:28:00.000Z",
        "voteCount": 1,
        "content": "the field is a date, not a number, so you cannot sum it."
      },
      {
        "date": "2023-01-23T20:00:00.000Z",
        "voteCount": 4,
        "content": "Given answers Count, DateTimeBin are correct answers as per MS docs\nDateTimebin takes 3 and 4 parameters but DateTimepart takes only 2 args\n\n https://learn.microsoft.com/en-us/azure/cosmos-db/nosql/query/date-time-functions"
      },
      {
        "date": "2023-01-21T05:42:00.000Z",
        "voteCount": 1,
        "content": "Correct!"
      },
      {
        "date": "2023-01-15T06:02:00.000Z",
        "voteCount": 2,
        "content": "Anyone have an idea as to why it says day and not hour?"
      },
      {
        "date": "2023-05-16T11:52:00.000Z",
        "voteCount": 1,
        "content": "It says every second day, so 12 hours would be twice a day. It might work if hours was 48"
      },
      {
        "date": "2023-01-12T07:28:00.000Z",
        "voteCount": 1,
        "content": "Pretty sure it has to be DateTimePart(...day) option.\nhttps://learn.microsoft.com/en-us/azure/cosmos-db/nosql/query/datetimepart"
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 35,
    "url": "https://www.examtopics.com/discussions/microsoft/view/94589-exam-az-204-topic-3-question-35-discussion/",
    "body": "HOTSPOT<br> -<br><br>You implement an Azure solution to include Azure Cosmos DB, the latest Azure Cosmos DB SDK, and the Core (SQL) API. You also implement a change feed processor on a new container instance by using the Azure Functions trigger for Azure Cosmos DB.<br><br>A large batch of documents continues to fail when reading one of the documents in the batch. The same batch of documents is continuously retried by the triggered function and a new batch of documents must be read.<br><br>You need to implement the change feed processor to read the documents.<br><br>Which feature should you implement? To answer, select the appropriate features in the answer area.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/az-204/image393.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/az-204/image394.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2023-03-19T13:10:00.000Z",
        "voteCount": 13,
        "content": "Got this on 16/03/23. Went with proposed solution. Make sure to prepare for case study. I got city and lights case study. No Kubernetes, Search, Logic Apps questions for me."
      },
      {
        "date": "2023-08-21T10:46:00.000Z",
        "voteCount": 5,
        "content": "Agreed. \nThis was on the exam (08/20/2023). Scored 925\nChange feed estimator\nDead-letter queue"
      },
      {
        "date": "2024-02-22T08:38:00.000Z",
        "voteCount": 1,
        "content": "For case study's though dont they block by contributor access now? How did you prepare for those?"
      },
      {
        "date": "2023-01-09T07:18:00.000Z",
        "voteCount": 10,
        "content": "I agree with the answer!\n1. Change feed estimators monitor change feed processors' progress\n2. Dead-letter queues handle errors and are able to monitor failed attempts, require failed attempts and even trigger a follow-up action (remediation or response)"
      },
      {
        "date": "2024-05-25T04:57:00.000Z",
        "voteCount": 1,
        "content": "Why feed estimator ? It has nothing to do with 'keeping track of failing batch'. Failing batch should be sent to dead-letter queue to keep track of it..."
      },
      {
        "date": "2024-04-08T05:38:00.000Z",
        "voteCount": 2,
        "content": "Got this on 04/07/2024, Went with highly voted answer, score:820"
      },
      {
        "date": "2024-02-19T00:46:00.000Z",
        "voteCount": 3,
        "content": "The correct answer seems to me:\n- Change feed estimator\n- Life cycle notifications\n\nYou also can use the change feed estimator to monitor the progress of your change feed processor instances as they read the change feed, or you can use life cycle notifications to detect underlying failures.\n\nLife cycle notitications literally says:\nRegister a handler for WithErrorNotification to be notified when the current host encounters an exception during processing. You need to be able to distinguish whether the source is the user delegate (an unhandled exception) or an error that the processor encounters when it tries to access the monitored container (for example, networking issues)."
      },
      {
        "date": "2024-02-19T01:26:00.000Z",
        "voteCount": 3,
        "content": "Correction, change feed estimator does nothing in this question. I do not know why people pick this answer and I blindly followed. Change feed estimator only tracks changes between read operations.\nLife cycle notificaitons tracks everything. and you can use a dead letter queue to process the failed documents."
      },
      {
        "date": "2024-02-07T07:24:00.000Z",
        "voteCount": 1,
        "content": "Got on 07/02/2024"
      },
      {
        "date": "2023-11-21T10:44:00.000Z",
        "voteCount": 3,
        "content": "The answers should be reversed."
      },
      {
        "date": "2023-11-03T07:49:00.000Z",
        "voteCount": 2,
        "content": "On exam 3-Nov-2023. Went with proposed answer - 932/1000.\n1) change feed estimator\n2) dead-letter queue"
      },
      {
        "date": "2023-09-13T00:36:00.000Z",
        "voteCount": 2,
        "content": "1/ \"Change feed estimator\" solely estimates the rate of changes, number of shards, and distrubution of the feed, but not read or process documents.\nThere's a error because by confusing with \"Change feed processor\".\n2/ Dead-letter queue"
      },
      {
        "date": "2023-07-13T14:11:00.000Z",
        "voteCount": 4,
        "content": "should be vice versa"
      },
      {
        "date": "2023-07-06T02:45:00.000Z",
        "voteCount": 2,
        "content": "This was on the exam (July 2023). Unsure about solution...."
      },
      {
        "date": "2023-05-13T13:49:00.000Z",
        "voteCount": 2,
        "content": "Got this on 2023may12.\n\nmy cases also:\ncase: You need to configure authorization.\ncase: You need to ensure the app does not time out and processes the blob data\ncase study: VanArsdel Inc Canada"
      },
      {
        "date": "2023-03-07T11:10:00.000Z",
        "voteCount": 2,
        "content": "From: https://learn.microsoft.com/en-us/azure/cosmos-db/nosql/change-feed-processor?tabs=dotnet#error-handling\n\n\"To prevent your change feed processor from getting \"stuck\" continuously retrying the same batch of changes, you should add logic in your delegate code to write documents, upon exception, to an errored-message queue. This design ensures that you can keep track of unprocessed changes while still being able to continue to process future changes. The errored-message queue might be another Azure Cosmos DB container. The exact data store does not matter, simply that the unprocessed changes are persisted.\n\nIn addition, you can use the change feed estimator to monitor the progress of your change feed processor instances as they read the change feed or use the life cycle notifications to detect underlying failures.\"\n\nAs the questions says 'keeping track' I'd go for feed estimator."
      },
      {
        "date": "2023-02-28T14:09:00.000Z",
        "voteCount": 2,
        "content": "On my exam 2023-02-25"
      },
      {
        "date": "2023-02-27T07:00:00.000Z",
        "voteCount": 3,
        "content": "Was on the exam 27.02.2023\nWent for Lifecycle notifications and dead letter queue.\nScore 870"
      },
      {
        "date": "2023-02-02T10:03:00.000Z",
        "voteCount": 3,
        "content": "was on exam 02/2023"
      },
      {
        "date": "2023-01-28T03:10:00.000Z",
        "voteCount": 4,
        "content": "1. Life-cycle notifications\nhttps://learn.microsoft.com/en-us/azure/cosmos-db/nosql/change-feed-processor?tabs=dotnet#life-cycle-notifications\nRegister a handler for WithErrorNotification to be notified when the current host encounters an exception during processing\n\n2. Dead-letter queue\nhttps://learn.microsoft.com/en-us/azure/cosmos-db/nosql/change-feed-processor?tabs=dotnet#error-handling\nTo prevent your change feed processor from getting \"stuck\" continuously retrying the same batch of changes, you should add logic in your delegate code to write documents, upon exception, to an errored-message queue."
      },
      {
        "date": "2023-02-26T10:25:00.000Z",
        "voteCount": 2,
        "content": "Correct\nhttps://learn.microsoft.com/en-us/azure/cosmos-db/nosql/change-feed-processor?tabs=dotnet#error-handling:~:text=use%20the%20life%20cycle%20notifications%20to%20detect%20underlying%20failures."
      },
      {
        "date": "2023-02-26T10:33:00.000Z",
        "voteCount": 4,
        "content": "but \n1. (about the stuck) - Dead-letter and 2. (about error handling) - notifications"
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 36,
    "url": "https://www.examtopics.com/discussions/microsoft/view/94432-exam-az-204-topic-3-question-36-discussion/",
    "body": "You are developing an application to store business-critical data in Azure Blob storage.<br><br>The application must meet the following requirements:<br><br>\u2022\tData must not be modified or deleted for a user-specified interval.<br>\u2022\tData must be protected from overwrites and deletes.<br>\u2022\tData must be written once and allowed to be read many times.<br><br>You need to protect the data in the Azure Blob storage account.<br><br>Which two actions should you perform? Each correct answer presents part of the solution.<br><br>NOTE: Each correct selection is worth one point.",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure a time-based retention policy for the storage account.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate an account shared-access signature (SAS).",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEnable the blob change feed for the storage account.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEnable version-level immutability support for the storage account.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEnable point-in-time restore for containers in the storage account.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"F\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tF.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a service shared-access signature (SAS)."
    ],
    "answer": "AD",
    "answerDescription": "",
    "votes": [
      {
        "answer": "AD",
        "count": 11,
        "isMostVoted": true
      },
      {
        "answer": "AF",
        "count": 1,
        "isMostVoted": false
      },
      {
        "answer": "AC",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2023-01-08T07:24:00.000Z",
        "voteCount": 36,
        "content": "I think the answer should be AD\nA. Configure a time-based retention policy for the storage account\n\t- A time-based retention policy stores blob data in a Write-Once, Read-Many (WORM) format for a specified interval. When a time-based retention policy is set, clients can create and read blobs, but can't modify or delete them. After the retention interval has expired, blobs can be deleted but not overwritten.\n\thttps://learn.microsoft.com/en-us/azure/storage/blobs/immutable-time-based-retention-policy-overview\nD. Before you can apply a time-based retention policy to a blob version, you must enable support for version-level immutability.\n\thttps://learn.microsoft.com/en-us/azure/storage/blobs/immutable-policy-configure-version-scope?tabs=azure-portal"
      },
      {
        "date": "2023-01-23T20:09:00.000Z",
        "voteCount": 3,
        "content": "I Agree with you A and D are correct answers"
      },
      {
        "date": "2023-04-17T03:38:00.000Z",
        "voteCount": 5,
        "content": "received 2023-04-17 went with above answer, score 926"
      },
      {
        "date": "2024-10-05T00:20:00.000Z",
        "voteCount": 1,
        "content": "a: Time-based retention policies: With a time-based retention policy, users can set policies to store data for a specified interval. When a time-based retention policy is set, objects can be created and read, but not modified or deleted. After the retention period has expired, objects can be deleted but not overwritten.\n\nd: Specify whether to enable version-level immutability for this container. Version-level immutability can be applied to specific blobs (any or all) in the container. For blobs with version-level immutability set, blob overwrites will still be allowed, but Azure will maintain immutable versions of each blob. Once enabled, this setting cannot be removed. Versioning is required for this feature, and cannot be disabled on a storage account while version-level policies are in place\n\nNot sure why D is needed, because with A you already cannot add or change the data."
      },
      {
        "date": "2024-08-05T15:03:00.000Z",
        "voteCount": 1,
        "content": "The answer is A and D: retention can prevent modification and deletion during a period, and version level immutability can prevent each version from being overwritten and deleted. For some frequently changed data, the user cannot apply a retention policy, the user can only set version-level immutability."
      },
      {
        "date": "2023-10-23T19:44:00.000Z",
        "voteCount": 1,
        "content": "correct answer is AD"
      },
      {
        "date": "2023-08-14T23:01:00.000Z",
        "voteCount": 1,
        "content": "A and D are the correct answers"
      },
      {
        "date": "2023-07-20T08:53:00.000Z",
        "voteCount": 1,
        "content": "A is clearly a correct answer and this documentation confirms https://learn.microsoft.com/en-us/azure/storage/blobs/immutable-policy-configure-version-scope?tabs=azure-portal that D is also required."
      },
      {
        "date": "2023-05-22T21:28:00.000Z",
        "voteCount": 1,
        "content": "Feels correct"
      },
      {
        "date": "2023-05-12T12:12:00.000Z",
        "voteCount": 2,
        "content": "Got this type 2023-05-12.\n\nMy case:\ncase: You need to configure authorization.\ncase: You need to ensure the app does not time out and processes the blob data\ncase study: VanArsdel Inc Canada"
      },
      {
        "date": "2023-03-31T20:34:00.000Z",
        "voteCount": 2,
        "content": "A,D chatgpt"
      },
      {
        "date": "2023-03-30T01:41:00.000Z",
        "voteCount": 1,
        "content": "Question was in Exam 2023-03-30"
      },
      {
        "date": "2023-03-19T13:12:00.000Z",
        "voteCount": 2,
        "content": "Got this on 16/03/23. Went with AD Make sure to prepare for case study. I got city and lights case study. No Kubernetes, Search, Logic Apps questions for me."
      },
      {
        "date": "2023-02-27T07:01:00.000Z",
        "voteCount": 2,
        "content": "Was on the exam 27.02.2023\nWent for A and D.\nScore 870"
      },
      {
        "date": "2023-02-28T08:32:00.000Z",
        "voteCount": 2,
        "content": "Which resources did you use to study?"
      },
      {
        "date": "2023-02-19T19:00:00.000Z",
        "voteCount": 1,
        "content": "100% A and D, other options don't fit into this question (i.e., don't solve it)"
      },
      {
        "date": "2023-02-02T10:04:00.000Z",
        "voteCount": 1,
        "content": "on exam 02/2023"
      },
      {
        "date": "2023-01-24T10:25:00.000Z",
        "voteCount": 1,
        "content": "A. Configuring a time-based retention policy for the storage account would ensure that the data in the storage account cannot be modified or deleted for a user-specified interval. This would meet the requirement that data must not be modified or deleted for a user-specified interval.\n\nD. Enabling version-level immutability support for the storage account would ensure that the data in the storage account is protected from overwrites and deletes. This would meet the requirement that data must be protected from overwrites and deletes, and written once and allowed to be read many times."
      },
      {
        "date": "2023-01-21T06:10:00.000Z",
        "voteCount": 2,
        "content": "Should be A and D"
      },
      {
        "date": "2023-01-16T22:48:00.000Z",
        "voteCount": 2,
        "content": "Should be A and D"
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 37,
    "url": "https://www.examtopics.com/discussions/microsoft/view/94594-exam-az-204-topic-3-question-37-discussion/",
    "body": "You are updating an application that stores data on Azure and uses Azure Cosmos DB for storage. The application stores data in multiple documents associated with a single username.<br><br>The application requires the ability to update multiple documents for a username in a single ACID operation.<br><br>You need to configure Azure Cosmos DB.<br><br>Which two actions should you perform? Each correct answer presents part of the solution.<br><br>NOTE: Each correct selection is worth one point.",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a collection sharded on username to store documents.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure Azure Cosmos DB to use the Gremlin API.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate an unsharded collection to store documents.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure Azure Cosmos DB to use the MongoDB API.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "CD",
    "answerDescription": "",
    "votes": [
      {
        "answer": "CD",
        "count": 30,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-01-09T07:39:00.000Z",
        "voteCount": 23,
        "content": "Agreed!\nTo update multiple documents for a username in a single ACID operation in Azure Cosmos DB, you need to ensure that the documents are stored in the same logical partition.\n\nTo do this, you should perform the following actions:\n\nCreate an unsharded collection to store documents. This will ensure that all documents are stored in the same logical partition.\nConfigure Azure Cosmos DB to use the MongoDB API. The MongoDB API supports multi-document ACID transactions, which allow you to update multiple documents in a single atomic operation."
      },
      {
        "date": "2023-01-12T07:56:00.000Z",
        "voteCount": 3,
        "content": "How do you know that the documents should be stored in the same logical partition. Is this a requirement for MongoDB API?"
      },
      {
        "date": "2023-04-15T23:07:00.000Z",
        "voteCount": 1,
        "content": "all operations like executing stored procedures or udf are effecting only items within single partition regardless of used API"
      },
      {
        "date": "2023-04-04T21:04:00.000Z",
        "voteCount": 5,
        "content": "Got this in exam today (5 April 2023)"
      },
      {
        "date": "2024-01-23T03:22:00.000Z",
        "voteCount": 2,
        "content": "Forget previous comment, not correct"
      },
      {
        "date": "2024-01-23T03:06:00.000Z",
        "voteCount": 1,
        "content": "I think it is AD because you need to shard across partitions on username to be able to process all documents with that user name in one transactional batch. You have to create a shard key for this in the cosmos db container based on the username."
      },
      {
        "date": "2023-07-13T13:43:00.000Z",
        "voteCount": 3,
        "content": "Correct answer is AD"
      },
      {
        "date": "2023-05-06T23:04:00.000Z",
        "voteCount": 4,
        "content": "To update multiple documents for a username in a single ACID operation in Azure Cosmos DB, you should perform the following actions:\n\nC. Create an unsharded collection to store documents, since sharded collections do not support multi-document transactions.\nD. Configure Azure Cosmos DB to use the MongoDB API, since it is the only API that supports multi-document transactions.\nTherefore, the correct actions are C and D."
      },
      {
        "date": "2023-04-28T14:39:00.000Z",
        "voteCount": 1,
        "content": "Agreed!"
      },
      {
        "date": "2023-02-13T06:04:00.000Z",
        "voteCount": 3,
        "content": "It was there in 13 Feb 2023 exam"
      },
      {
        "date": "2023-01-23T20:18:00.000Z",
        "voteCount": 3,
        "content": "CD are correct\nupdate multiple documents for a username in a single ACID operation."
      },
      {
        "date": "2023-01-23T20:19:00.000Z",
        "voteCount": 5,
        "content": "https://learn.microsoft.com/en-us/azure/cosmos-db/mongodb/use-multi-document-transactions#requirements"
      },
      {
        "date": "2023-01-13T10:56:00.000Z",
        "voteCount": 3,
        "content": "multi-document transaction is only supported within unsharded collection.\nhttps://learn.microsoft.com/en-us/azure/cosmos-db/mongodb/use-multi-document-transactions#requirements"
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 38,
    "url": "https://www.examtopics.com/discussions/microsoft/view/94299-exam-az-204-topic-3-question-38-discussion/",
    "body": "You develop Azure solutions.<br><br>You must connect to a No-SQL globally-distributed database by using the .NET API.<br><br>You need to create an object to configure and execute requests in the database.<br><br>Which code segment should you use?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tdatabase_name = 'MyDatabase'<br>database = client.create_database_if_not_exists(id=database_name)",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tclient = CosmosClient(endpoint, key)\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tcontainer_name = 'MyContainer'<br>container = database.create_container_if_not_exists(<br>id=container_name, partition_key=PartitionKey(path=\"/lastName\"), offer_throughput=400 )"
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 27,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-01-09T07:49:00.000Z",
        "voteCount": 16,
        "content": "CosmosClient has to be created before you can do option A and C to create databases and execute requests.\n\nclient = CosmosClient(endpoint, key)\ndatabase_name = 'MyDatabase'\ndatabase = client.create_database_if_not_exists(id=database_name)\ncontainer_name = 'MyContainer'\ncontainer = database.create_container_if_not_exists(\nid=container_name, partition_key=PartitionKey(path=\"/lastName\"), offer_throughput=400 )"
      },
      {
        "date": "2023-07-13T13:48:00.000Z",
        "voteCount": 9,
        "content": "It doesn't matter. Question is asking about .NET API. A and C are not .NET code"
      },
      {
        "date": "2024-09-19T00:18:00.000Z",
        "voteCount": 1,
        "content": "I found that this question has the following answer options:\nA. new Container(EndpointUri, PrimaryKey);\nB. new Database(EndpointUri, PrimaryKey);\nC. new CosmosClient(EndpointUri, PrimaryKey);\n\nand the correct answer is: new CosmosClient(...)"
      },
      {
        "date": "2023-08-30T17:00:00.000Z",
        "voteCount": 3,
        "content": "I think its B, but its missing new keyword.\n\nCosmosClient cosmosClient = new CosmosClient(\n            \"connection-string-from-portal\", \n            new CosmosClientOptions()\n            {\n                ApplicationRegion = Regions.EastUS2,\n            });"
      },
      {
        "date": "2023-07-13T13:47:00.000Z",
        "voteCount": 3,
        "content": "B is only one .NET code here. So, B is a correct answer"
      },
      {
        "date": "2023-06-09T01:11:00.000Z",
        "voteCount": 4,
        "content": "You need to create the client before anything else"
      },
      {
        "date": "2023-05-22T21:33:00.000Z",
        "voteCount": 1,
        "content": "correct"
      },
      {
        "date": "2023-02-20T03:32:00.000Z",
        "voteCount": 4,
        "content": "The correct code segment to configure and execute requests in the No-SQL globally-distributed database by using the .NET API would be option B:\nclient = CosmosClient(endpoint, key)\nThis code initializes the CosmosClient class and connects to the database with the specified endpoint and key parameters. This is the first step in creating a client to communicate with the Azure Cosmos DB.\n\nOption A shows how to create a database, and option C shows how to create a container inside a database, but they do not create the client object that is needed to communicate with the database. Therefore, they are not correct options for this scenario."
      },
      {
        "date": "2023-02-19T19:03:00.000Z",
        "voteCount": 2,
        "content": "Has to be B - How could you do either A or C before B?"
      },
      {
        "date": "2023-02-17T16:39:00.000Z",
        "voteCount": 2,
        "content": "A\nYou need to\" create an object\" to configure and execute requests in the \"database\".\nNot B\nSure B must be done before A, but A is the actual database Object\nNot C\nC is the container and not the database object"
      },
      {
        "date": "2023-01-24T02:53:00.000Z",
        "voteCount": 2,
        "content": "B as \u201cby using the .NET API\u201d"
      },
      {
        "date": "2023-01-23T23:39:00.000Z",
        "voteCount": 1,
        "content": "B is the correct answer\nhttps://learn.microsoft.com/en-us/python/api/azure-cosmos/azure.cosmos.cosmosclient?view=azure-python"
      },
      {
        "date": "2023-01-17T01:32:00.000Z",
        "voteCount": 2,
        "content": "CosmosClient has to be created first"
      },
      {
        "date": "2023-01-09T01:39:00.000Z",
        "voteCount": 1,
        "content": "I believe Cosmos client type object can be used to configure and execute requests in the Azure Cosmos DB database service.\nhttps://learn.microsoft.com/en-us/dotnet/api/microsoft.azure.cosmos.cosmosclient?view=azure-dotnet"
      },
      {
        "date": "2023-01-08T14:27:00.000Z",
        "voteCount": 3,
        "content": "I vote for CosmosClient, which can connect to No-SQL database"
      },
      {
        "date": "2023-01-07T06:22:00.000Z",
        "voteCount": 2,
        "content": "i think answer B"
      },
      {
        "date": "2023-01-08T14:04:00.000Z",
        "voteCount": 1,
        "content": "i don't think so, in my point of view, cosmos client can be used to create your datababe, but not to manipulate it.\nto do that, you have to create a container from this database, and use this object to do some requests !"
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 39,
    "url": "https://www.examtopics.com/discussions/microsoft/view/106561-exam-az-204-topic-3-question-39-discussion/",
    "body": "You develop a web application that provides access to legal documents that are stored on Azure Blob Storage with version-level immutability policies. Documents are protected with both time-based policies and legal hold policies. All time-based retention policies have the AllowProtectedAppendWrites property enabled.<br><br>You have a requirement to prevent the user from attempting to perform operations that would fail only when a legal hold is in effect and when all other policies are expired.<br><br>You need to meet the requirement.<br><br>Which two operations should you prevent? Each correct answer presents a complete solution.<br><br>NOTE: Each correct selection is worth one point.",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tadding data to documents",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tdeleting documents\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tcreating documents",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\toverwriting existing documents\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "BD",
    "answerDescription": "",
    "votes": [
      {
        "answer": "BD",
        "count": 5,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-04-18T08:27:00.000Z",
        "voteCount": 13,
        "content": "The legal hold policies prevent the deletion of the legal documents that are stored on Azure Blob Storage, but they do not prevent other types of operations such as read, write, or update. Therefore, you need to prevent the following two operations that would fail only when a legal hold is in effect and when all other policies are expired:\n\nDelete operation: When a legal hold is in effect and all other policies are expired, attempting to delete the document will fail. Therefore, you should prevent the user from attempting to delete a document.\n\nOverwrite operation: When a legal hold is in effect and all other policies are expired, attempting to overwrite the document with a new version will fail. Therefore, you should prevent the user from attempting to overwrite a document with a new version.\n\nBy preventing these two operations, you can ensure that the legal documents are not accidentally deleted or overwritten when they are protected by legal hold policies.\nCHatgpt answer. Is this correct?"
      },
      {
        "date": "2023-08-30T02:10:00.000Z",
        "voteCount": 3,
        "content": "Got it in exam 28/08/23. Went with this answer. Scored 912"
      },
      {
        "date": "2023-06-22T00:33:00.000Z",
        "voteCount": 1,
        "content": "ty for the comment made it much clearer"
      },
      {
        "date": "2023-07-06T02:45:00.000Z",
        "voteCount": 7,
        "content": "This was on the exam (July 2023). Went with BD. Scored 917"
      },
      {
        "date": "2023-07-10T05:36:00.000Z",
        "voteCount": 1,
        "content": "What was your casestudy?"
      },
      {
        "date": "2023-08-21T01:23:00.000Z",
        "voteCount": 1,
        "content": "What does it mean casestudy?"
      },
      {
        "date": "2024-05-05T18:08:00.000Z",
        "voteCount": 4,
        "content": "What's confusing is ' adding data to documents' sure sounds like Updating documents..."
      },
      {
        "date": "2024-03-22T13:46:00.000Z",
        "voteCount": 1,
        "content": "When a legal hold is applied to a container, all existing blobs move into an immutable WORM state in less than 30 seconds. All new blobs that are uploaded to that policy-protected container will also move into an immutable state. Once all blobs are in an immutable state, overwrite or delete operations in the immutable container aren't allowed."
      },
      {
        "date": "2024-02-07T07:34:00.000Z",
        "voteCount": 1,
        "content": "Got on 07/02/2024"
      },
      {
        "date": "2023-11-03T07:51:00.000Z",
        "voteCount": 4,
        "content": "On exam 3-Nov-2023. Wend with proposed answer - 932/1000.\nB &amp; D"
      },
      {
        "date": "2024-01-02T05:06:00.000Z",
        "voteCount": 1,
        "content": "How do you remember all questions?"
      },
      {
        "date": "2023-09-23T17:34:00.000Z",
        "voteCount": 1,
        "content": "legal hold policies: prevents delete and overwrite actions.\nthe question said that \"legal hold\" is in effect an the others expired, we should prevent other operations from user. so the answer should not be: A and C ?\nB and D are already prevented with the legal hold policies, right?"
      },
      {
        "date": "2023-07-13T13:56:00.000Z",
        "voteCount": 5,
        "content": "I don't really understand this question"
      },
      {
        "date": "2024-08-08T05:14:00.000Z",
        "voteCount": 1,
        "content": "is the way is written , it happen with most of them"
      },
      {
        "date": "2023-04-18T05:32:00.000Z",
        "voteCount": 3,
        "content": "b,d IS CORRECT"
      },
      {
        "date": "2023-04-18T04:07:00.000Z",
        "voteCount": 4,
        "content": "BD. Ref: https://learn.microsoft.com/en-us/azure/storage/blobs/immutable-legal-hold-overview"
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 40,
    "url": "https://www.examtopics.com/discussions/microsoft/view/106572-exam-az-204-topic-3-question-40-discussion/",
    "body": "HOTSPOT<br> -<br><br>You provisioned an Azure Cosmos DB for NoSQL account named account1 with the default consistency level.<br><br>You plan to configure the consistency level on a per request basis. The level needs to be set for consistent prefix for read and write operations to account1.<br><br>You need to identify the resulting consistency level for read and write operations.<br><br>Which levels should you configure? To answer, select the appropriate options in the answer area.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/az-204/image424.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/az-204/image425.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2023-04-25T19:45:00.000Z",
        "voteCount": 30,
        "content": "Just passed the exam 26/04/2023. All the questions were from Exam topics. Got 970 marks!"
      },
      {
        "date": "2024-07-25T07:05:00.000Z",
        "voteCount": 1,
        "content": "congrats i got 984 in AZ-900 but i don't think i will get similar score in AZ-204"
      },
      {
        "date": "2023-07-13T14:01:00.000Z",
        "voteCount": 17,
        "content": "useless comment"
      },
      {
        "date": "2023-07-16T07:55:00.000Z",
        "voteCount": 38,
        "content": "Still more useful than yours :)"
      },
      {
        "date": "2023-05-20T05:05:00.000Z",
        "voteCount": 5,
        "content": "Bro you had the contributor access?"
      },
      {
        "date": "2024-07-25T07:05:00.000Z",
        "voteCount": 1,
        "content": "you can't get 970 only with the 100 firts questions."
      },
      {
        "date": "2023-09-01T03:23:00.000Z",
        "voteCount": 1,
        "content": "of course"
      },
      {
        "date": "2023-11-10T09:21:00.000Z",
        "voteCount": 4,
        "content": "Never seen a score so high."
      },
      {
        "date": "2023-04-18T05:48:00.000Z",
        "voteCount": 17,
        "content": "both should be consistent prefix"
      },
      {
        "date": "2023-07-10T05:39:00.000Z",
        "voteCount": 2,
        "content": "could you explain why?"
      },
      {
        "date": "2023-07-19T22:39:00.000Z",
        "voteCount": 15,
        "content": "Wrong. The Given answer is correct. Only Read Consistency can be set by client. Write stays at server setting which is session by default.\nhttps://learn.microsoft.com/en-us/azure/cosmos-db/nosql/how-to-manage-consistency?tabs=portal%2Cdotnetv2%2Capi-async#override-the-default-consistency-level"
      },
      {
        "date": "2023-08-23T04:08:00.000Z",
        "voteCount": 1,
        "content": "You are right, the given answer is correct.\nMicrosoft documentation states:\nOverriding the default consistency level only applies to &lt;b&gt;reads&lt;/b&gt; within the SDK client. &lt;b&gt;An account configured for strong consistency by default will still write and replicate data synchronously to every region in the account.&lt;/b&gt; When the SDK client instance or request overrides this with Session or weaker consistency, reads will be performed using a single replica."
      },
      {
        "date": "2024-07-03T05:06:00.000Z",
        "voteCount": 1,
        "content": "Still very confusing explanation. The other thing you must consider is that the level can only be relaxed. In conclusion I guess you have to configur prefix for write because it cannot be change while you can configure strong for read because it can be relaxed on a per SDK request basis."
      },
      {
        "date": "2024-10-03T06:41:00.000Z",
        "voteCount": 1,
        "content": "Read operations will result in consistent prefix. Write operations will remain session because of the settings of the storage account."
      },
      {
        "date": "2024-08-16T10:43:00.000Z",
        "voteCount": 1,
        "content": "For Azure Cosmos DB, when you provision an account with a default consistency level, you can override this setting on a per-request basis. Here's how you should configure the consistency levels for read and write operations to achieve a consistent prefix:\n\nRead operations: Consistent Prefix\nWrite operations: Consistent Prefix\nBy setting both read and write operations to the Consistent Prefix level, you ensure that the data is read and written in the order in which it was updated, without requiring a strong consistency level, which can be more resource-intensive. This guarantees that reads never see out-of-order writes."
      },
      {
        "date": "2024-07-29T07:09:00.000Z",
        "voteCount": 1,
        "content": "Both are consistent prefix ."
      },
      {
        "date": "2024-07-03T05:10:00.000Z",
        "voteCount": 1,
        "content": "My answer would be that the resulting levels are both consisten prefix because it is written that they are set like that at account level and it is only possible to relax them via SDK (and only for read), so it would exclude strong and session as resulting levels for read or any other for write"
      },
      {
        "date": "2024-01-10T00:20:00.000Z",
        "voteCount": 4,
        "content": "This question was on exam. 09/01/2024. Passed 872."
      },
      {
        "date": "2023-12-11T06:39:00.000Z",
        "voteCount": 7,
        "content": "I got this question on my exam, 2023Dec, go with what I remember was the most voted answer. Score 902, most of the questions were here, slightly different on wording because the Azure Ad &lt;-&gt; Entra Id change. Case was City Power &amp; Light. Good luck!\nImportant tip, you  have access to microsoft learn during the exam!"
      },
      {
        "date": "2023-12-17T01:18:00.000Z",
        "voteCount": 1,
        "content": "Hi, does all question were from exam topic? Did you bought contributor access? And what does it mean by case study city power and light. In free version I haven't came across thus term/ farmer case study"
      },
      {
        "date": "2023-09-28T07:52:00.000Z",
        "voteCount": 1,
        "content": "got in 28/09/2023"
      },
      {
        "date": "2023-08-20T19:27:00.000Z",
        "voteCount": 6,
        "content": "Sorry, my first cmmt is error\nI think should be :\nread: consistent prefix, \nwrite: session\n\n1. default level is session\n2. override only work for read\n3. To move from weaker to stronger consistency, update the default consistency for the Azure Cosmos DB account\n\nstrong &gt; boundary &gt; session &gt; consistent prefix &gt; eventually\n\nhttps://learn.microsoft.com/en-us/azure/cosmos-db/nosql/how-to-manage-consistency?tabs=portal%2Cdotnetv2%2Capi-async#override-the-default-consistency-level"
      },
      {
        "date": "2023-08-20T19:21:00.000Z",
        "voteCount": 1,
        "content": "I think should be session, session\n1. default level is session\n2. override only work for read\n3. To move from weaker to stronger consistency, update the default consistency for the Azure Cosmos DB account\n\nhttps://learn.microsoft.com/en-us/azure/cosmos-db/nosql/how-to-manage-consistency?tabs=portal%2Cdotnetv2%2Capi-async#override-the-default-consistency-level"
      },
      {
        "date": "2023-07-14T01:38:00.000Z",
        "voteCount": 6,
        "content": "answer is here: https://learn.microsoft.com/en-us/azure/cosmos-db/nosql/how-to-manage-consistency?tabs=portal%2Cdotnetv2%2Capi-async#override-the-default-consistency-level \nOverriding the default consistency level only applies to reads within the SDK client.\ndefaut consistency is session"
      },
      {
        "date": "2023-07-15T05:06:00.000Z",
        "voteCount": 2,
        "content": "Now I get it! Appreciated."
      },
      {
        "date": "2023-06-21T01:05:00.000Z",
        "voteCount": 3,
        "content": "stupid question xD"
      },
      {
        "date": "2023-04-27T03:28:00.000Z",
        "voteCount": 2,
        "content": "Any explanation? \nFor read operations with the requirement of consistent prefix, the resulting consistency level option is C. Consistent prefix.\nFollowing is what ChatGPT said, but I am not convinced.\nFor write operations, there is no consistency level option called \"Consistent prefix\". The available options are Strong, Bounded staleness, Session, and Eventual. If you want to ensure consistency prefix for write operations, you should choose Strong consistency level."
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 41,
    "url": "https://www.examtopics.com/discussions/microsoft/view/106564-exam-az-204-topic-3-question-41-discussion/",
    "body": "DRAG DROP<br> -<br><br>You are developing an application to store millions of images in Azure blob storage. The images are uploaded to an Azure blob storage container named companyimages contained in an Azure blob storage account named companymedia. The stored images are uploaded with multiple blob index tags across multiple blobs in the container.<br><br>You must find all blobs whose tags match a search expression in the container. The search expression must evaluate an index tag named status with a value of final.<br><br>You need to construct the GET method request URI.<br><br>How should you complete the URI? To answer, drag the appropriate parameters to the correct request URI targets. Each parameter may be used once, more than once, or not at all. You may need to drag the split bar between panes or scroll to view content.<br><br><img src=\"https://img.examtopics.com/az-204/image426.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/az-204/image427.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2023-04-18T05:37:00.000Z",
        "voteCount": 23,
        "content": "Answer is correct!"
      },
      {
        "date": "2023-06-16T03:26:00.000Z",
        "voteCount": 6,
        "content": "Just for information: I just had this question on my AZ204 exam - 16-jun-2023.\nI barely made it (with only 767 points) so I can't inform anyony if this answer is correct or not, just stating that this is an actual exam question."
      },
      {
        "date": "2023-07-14T05:20:00.000Z",
        "voteCount": 1,
        "content": "Do you have contributor access? what other websites did you study from?"
      },
      {
        "date": "2024-08-12T10:53:00.000Z",
        "voteCount": 1,
        "content": "Brother you won't see this question without contributor access now."
      },
      {
        "date": "2024-09-06T18:26:00.000Z",
        "voteCount": 1,
        "content": "previously around 200 questions were free. but now only 100 questions are free."
      },
      {
        "date": "2024-01-13T07:54:00.000Z",
        "voteCount": 1,
        "content": "no its not"
      },
      {
        "date": "2023-09-26T18:37:00.000Z",
        "voteCount": 2,
        "content": "It was on my exam today (2023-09-26) I went with the examtopics answer - score 850"
      },
      {
        "date": "2023-07-13T01:31:00.000Z",
        "voteCount": 2,
        "content": "Correct"
      },
      {
        "date": "2023-05-31T22:58:00.000Z",
        "voteCount": 3,
        "content": "Got this question on the exam at 2023/05/31"
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 42,
    "url": "https://www.examtopics.com/discussions/microsoft/view/114548-exam-az-204-topic-3-question-42-discussion/",
    "body": "HOTSPOT<br> -<br><br>You develop two Python scripts to process data.<br><br>The Python scripts must be deployed to two, separate Linux containers running in an Azure Container Instance container group. The containers must access external data by using the Server Message Block (SMB) protocol. Containers in the container group must run only once.<br><br>You need to configure the Azure Container Instance.<br><br>Which configuration value should you use? To answer, select the appropriate options in the answer area.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/az-204/image447.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/az-204/image448.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2023-07-08T21:49:00.000Z",
        "voteCount": 16,
        "content": "I believe the answer is correct.\n\nAzure file share: https://learn.microsoft.com/en-us/azure/storage/files/files-smb-protocol?tabs=azure-portal"
      },
      {
        "date": "2023-08-13T06:32:00.000Z",
        "voteCount": 10,
        "content": "Azure File Share is the only option that supports SMB"
      },
      {
        "date": "2023-08-23T04:49:00.000Z",
        "voteCount": 1,
        "content": "You are right"
      },
      {
        "date": "2024-06-03T19:54:00.000Z",
        "voteCount": 1,
        "content": "https://learn.microsoft.com/en-us/azure/container-instances/container-instances-restart-policy\nContainer restart policy : Never\nContainers in the container group are never restarted. The containers run at most once."
      },
      {
        "date": "2023-12-23T16:14:00.000Z",
        "voteCount": 1,
        "content": "I think given answer is correct."
      },
      {
        "date": "2023-07-25T00:51:00.000Z",
        "voteCount": 4,
        "content": "Answer is correct."
      },
      {
        "date": "2023-07-23T11:34:00.000Z",
        "voteCount": 1,
        "content": "Incorrect\nCorrect Answer: Empty Directory, Never"
      },
      {
        "date": "2023-11-25T06:59:00.000Z",
        "voteCount": 1,
        "content": "this guy is wrong"
      },
      {
        "date": "2023-11-09T08:54:00.000Z",
        "voteCount": 2,
        "content": "Is not Empty Directory, but Azure File Share."
      },
      {
        "date": "2023-08-02T08:42:00.000Z",
        "voteCount": 2,
        "content": "why Empty Directory ?"
      },
      {
        "date": "2023-11-02T02:49:00.000Z",
        "voteCount": 2,
        "content": "Whyyyy???????????????"
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 43,
    "url": "https://www.examtopics.com/discussions/microsoft/view/114267-exam-az-204-topic-3-question-43-discussion/",
    "body": "HOTSPOT<br> -<br><br>You are developing a static website hosted on Azure Blob Storage. You create a storage account and enable static website hosting.<br><br>The website must support the following requirements:<br><br>\u2022\tCustom domain name<br>\u2022\tCustom header values for all responses<br>\u2022\tCustom SSL certificate<br><br>You need to implement the static website.<br><br>What should you configure? To answer, select the appropriate values in the answer area.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/az-204/image449.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/az-204/image450.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2023-07-06T06:30:00.000Z",
        "voteCount": 18,
        "content": "Answer seems correct.\n\"Static websites have some limitations. For example, If you want to configure headers, you'll have to use Azure Content Delivery Network (Azure CDN)\"  and  \" To enable HTTPS, you'll have to use Azure CDN because Azure Storage doesn't yet natively support HTTPS with custom domains\"\n\nhttps://learn.microsoft.com/en-us/azure/storage/blobs/storage-blob-static-website"
      },
      {
        "date": "2024-04-28T00:56:00.000Z",
        "voteCount": 5,
        "content": "Got it on 20 April 2024...Marks &gt; 900...All questions from examtopics 400 questions...\nanswer is correct..."
      },
      {
        "date": "2023-11-08T23:36:00.000Z",
        "voteCount": 5,
        "content": "On exam 9 Nov 2023, went with given answer, socre 865. Case Study: Farmers and Distributors"
      },
      {
        "date": "2023-11-09T08:56:00.000Z",
        "voteCount": 4,
        "content": "\"Farmers and Distribuor\" is a new one (not present here on ExamTopics)."
      },
      {
        "date": "2024-01-18T08:58:00.000Z",
        "voteCount": 3,
        "content": "it's in there : Munson's Pickles and preserves farms Topic 4, Q69, T5 ..., T6...,"
      },
      {
        "date": "2024-01-04T13:39:00.000Z",
        "voteCount": 2,
        "content": "I am also looking for this case study."
      },
      {
        "date": "2023-09-04T12:34:00.000Z",
        "voteCount": 2,
        "content": "Using Azure CDN to Specify Custom HTTP Headers for an Azure Static Website Hosted SPA: https://medium.com/datadigest/using-azure-cdn-to-specify-custom-http-headers-for-an-azure-static-website-hosted-spa-41a9b9ec1674"
      },
      {
        "date": "2023-08-23T05:04:00.000Z",
        "voteCount": 3,
        "content": "The answers are correct.\nThe most appropriate answer is Azure CDN, as it can fulfill all three requirements: custom domain name, custom header values, and a custom SSL certificate."
      },
      {
        "date": "2023-08-10T21:08:00.000Z",
        "voteCount": 3,
        "content": "1. Custom Domain Name:\n   - Configuration: Azure Content Delivery Network (CDN)\nAzure CDN can be configured to map your custom domain name (e.g., www.yourdomain.com) to the Azure Blob Storage static website endpoint. This allows you to access your static website using your custom domain.\n2. Custom Header Values for All Responses:\n   - Configuration: Blob index tag\nYou can use blob index tags to set custom header values for all responses from your static website. Blob index tags allow you to define metadata at the container or blob level that can be used as headers for the website content.\n3. Custom SSL Certificate:\n   - Configuration: Azure Content Delivery Network (CDN)\nTo use a custom SSL certificate for your custom domain, you can configure Azure CDN to use the custom SSL certificate. This will enable secure communication between the user's browser and the CDN endpoint serving your static website content."
      },
      {
        "date": "2023-07-25T20:44:00.000Z",
        "voteCount": 2,
        "content": "Had this question in today's exam: 2023-07-26"
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 44,
    "url": "https://www.examtopics.com/discussions/microsoft/view/114418-exam-az-204-topic-3-question-44-discussion/",
    "body": "You are developing an inventory tracking solution. The solution includes an Azure Function app containing multiple functions triggered by Azure Cosmos DB. You plan to deploy the solution to multiple Azure regions.<br><br>The solution must meet the following requirements:<br><br>\u2022\tItem results from Azure Cosmos DS must return the most recent committed version of an item.<br>\u2022\tItems written to Azure Cosmos DB must provide ordering guarantees.<br><br>You need to configure the consistency level for the Azure Cosmos DB deployments.<br><br>Which consistency level should you use?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tconsistent prefix",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\teventual",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tbounded staleness",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tstrong\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tsession"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 18,
        "isMostVoted": true
      },
      {
        "answer": "C",
        "count": 4,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2023-07-16T07:18:00.000Z",
        "voteCount": 11,
        "content": "I believe its C 'bounded staleness'\nBecause strong consistency is not supported for multiple regions"
      },
      {
        "date": "2024-01-11T03:11:00.000Z",
        "voteCount": 4,
        "content": "Yes, the Strong consistency level is supported in Azure Cosmos DB for multiple regions. When you configure Azure Cosmos DB with multiple regions, you have the option to choose the consistency level that fits your application's requirements. The Strong consistency level ensures that, regardless of the region being accessed, each read operation returns the most recent committed version of an item and maintains ordering guarantees. This is achieved by synchronously replicating writes across all regions before acknowledging the write operation."
      },
      {
        "date": "2023-07-24T22:59:00.000Z",
        "voteCount": 6,
        "content": "Azure Cosmos DB accounts configured with multiple write regions can't be configured for strong consistency as it isn't possible for a distributed system to provide an RPO of zero and an RTO of zero\n\nhttps://learn.microsoft.com/en-us/azure/cosmos-db/consistency-levels"
      },
      {
        "date": "2024-06-03T23:38:00.000Z",
        "voteCount": 2,
        "content": "...strong consistency completes an operation only after ensuring that it has been committed to all regions within an account.\nhttps://learn.microsoft.com/en-us/azure/cosmos-db/consistency-levels#write-latency-and-strong-consistency"
      },
      {
        "date": "2024-03-06T09:13:00.000Z",
        "voteCount": 4,
        "content": "That is true but there is no mention of \"multiple write regions\" mentioned in the question. \nYou can have strong consistency and multiple regions (notice it is not multiple write regions): https://learn.microsoft.com/en-us/azure/cosmos-db/consistency-levels#write-latency-and-strong-consistency"
      },
      {
        "date": "2023-07-07T07:15:00.000Z",
        "voteCount": 11,
        "content": "Strong consistency offers a linearizability guarantee. Linearizability refers to serving requests concurrently. The reads are guaranteed to return the most recent committed version of an item. A client never sees an uncommitted or partial write. Users are always guaranteed to read the latest committed write.\nSource: https://learn.microsoft.com/en-us/azure/cosmos-db/consistency-levels"
      },
      {
        "date": "2024-08-13T01:31:00.000Z",
        "voteCount": 1,
        "content": "There is a trick here - the SOLUTION is deployed to multiple regions. That only contains the function app. Nowhere does it say that the COSMOS db is in multiple regions. Therefore, Strong is perfectly acceptable."
      },
      {
        "date": "2024-07-25T07:25:00.000Z",
        "voteCount": 1,
        "content": "D is correct .According to the requirements that item results from Azure Cosmos DB must return the most recent committed version of an item and items written to Azure Cosmos DB must provide ordering guarantees, the Strong consistency level should be used.\nStrong consistency offers linearizability, which is the highest consistency level available. It guarantees that once an operation completes, the result will be immediately visible to all subsequent operations. This ensures that the most recent committed version of an item is always returned and also provides ordering guarantees, but this comes with a trade-off as strong consistency may introduce higher latencies and reduced availability compared to other consistency levels."
      },
      {
        "date": "2024-07-04T03:07:00.000Z",
        "voteCount": 1,
        "content": "\"Most recent\""
      },
      {
        "date": "2024-03-25T15:35:00.000Z",
        "voteCount": 3,
        "content": "The problem doesn't specify any condition (versions or time lag) which may allow bounded staleness. \nOnly Strong consistency guarantees the reading the more recent commit."
      },
      {
        "date": "2024-02-20T01:52:00.000Z",
        "voteCount": 1,
        "content": "Item results from Azure Cosmos DB must return the most recent committed version of an item: Strong consistency ensures that once a write operation is acknowledged, all subsequent read operations will return the most recent committed version of the data. This means that any read operation will see the effects of the latest write operation.\nItems written to Azure Cosmos DB must provide ordering guarantees: Strong consistency also ensures ordering guarantees. It means that if one write operation is acknowledged before another, then the order of these operations is preserved for all subsequent read operations."
      },
      {
        "date": "2023-12-05T10:16:00.000Z",
        "voteCount": 3,
        "content": "Strong - doesnt mention multi-region writes - the multi-region functions are triggered hence reads"
      },
      {
        "date": "2023-12-01T10:20:00.000Z",
        "voteCount": 2,
        "content": "The key is the multiple regions"
      },
      {
        "date": "2023-11-03T05:15:00.000Z",
        "voteCount": 1,
        "content": "Azure Cosmos DB accounts configured with multiple write regions can't be configured for strong consistency as it isn't possible for a distributed system to provide an RPO of zero and an RTO of zero. Additionally, there are no write latency benefits on using strong consistency with multiple write regions because a write to any region must be replicated and committed to all configured regions within the account. This scenario results in the same write latency as a single write region account.\n\nhttps://learn.microsoft.com/en-us/azure/cosmos-db/consistency-levels#strong-consistency-and-multiple-write-regions"
      },
      {
        "date": "2023-11-06T01:18:00.000Z",
        "voteCount": 3,
        "content": "but the question didn't mention that there will be multiple WRITE regions ?"
      },
      {
        "date": "2023-10-01T21:26:00.000Z",
        "voteCount": 3,
        "content": "strong is correct ans.:\nStrong consistency: Strong consistency offers a linearizability guarantee. Linearizability refers to serving requests concurrently. The reads are guaranteed to return the most recent committed version of an item. A client never sees an uncommitted or partial write. Users are always guaranteed to read the latest committed write.\n\nBounded staleness consistency:\nWith Bounded Staleness consistency, reads issued against a non-primary region may not necessarily return the most recent version of the data globally, but are guaranteed to return the most recent version of the data in that region, which will be within the maximum staleness boundary globally.\n\nhttps://learn.microsoft.com/en-us/azure/cosmos-db/consistency-levels"
      },
      {
        "date": "2023-09-12T18:44:00.000Z",
        "voteCount": 2,
        "content": "I think it's D. \nStrong consistency is not supported for multiple WRITE regions, and I don't see any such requirements in the question. https://learn.microsoft.com/en-us/azure/cosmos-db/high-availability#multiple-write-regions"
      },
      {
        "date": "2023-10-01T21:16:00.000Z",
        "voteCount": 1,
        "content": "as per Que.: You plan to deploy the solution to multiple Azure regions."
      },
      {
        "date": "2023-08-23T05:29:00.000Z",
        "voteCount": 1,
        "content": "I think it's Bounded Staleness because it's not mentioned that read is executed right after write operation so I think it's acceptable to have small latency between write and read operations. I would go with this!"
      },
      {
        "date": "2023-08-14T09:43:00.000Z",
        "voteCount": 3,
        "content": "But for Strong consistency, it also says Bounded Staleness in a multi-write account is an anti-pattern. So I really don't understand what the correct answer is. \n\nBounded Staleness or Strong?"
      },
      {
        "date": "2023-08-02T10:07:00.000Z",
        "voteCount": 3,
        "content": "C. bounded staleness\nItem results return the most recent committed version of an item: Bounded staleness ensures that reads are served from a version of the data that is within a specified lag from the current write operation. This means that you can read the most recent committed version of an item while still providing a level of consistency.\n\nItems written to Azure Cosmos DB must provide ordering guarantees: Bounded staleness guarantees that writes are ordered and committed before being read.\n\nWhile other consistency levels like \"Strong\" and \"Consistent prefix\" also provide strong consistency, \"Bounded staleness\" offers a balance between consistency and availability, which is suitable for scenarios where the most recent data is needed with some level of delay."
      },
      {
        "date": "2023-08-13T07:03:00.000Z",
        "voteCount": 1,
        "content": "\"Reads when using Bounded Staleness returns the latest data available in that region by reading from two available replicas in that region.\"\n\nWith bounded staleness there is a certain amount of lag, so it does not return the most recently committed write"
      },
      {
        "date": "2023-07-31T09:16:00.000Z",
        "voteCount": 3,
        "content": "Correct answer is C 'bounded staleness'\n\nQuestion mentions deployment to multiple regions, and strong consistency is not supported for that."
      },
      {
        "date": "2023-07-11T08:47:00.000Z",
        "voteCount": 3,
        "content": "I believe `Strong` consistency is correct."
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 45,
    "url": "https://www.examtopics.com/discussions/microsoft/view/114647-exam-az-204-topic-3-question-45-discussion/",
    "body": "HOTSPOT<br> -<br><br>You are developing an application that runs in several customer Azure Kubernetes Service clusters. Within each cluster, a pod runs that collects performance data to be analyzed later. A large amount of data is collected so saving latency must be minimized.<br><br>The performance data must be stored so that pod restarts do not impact the stored data. Write latency should be minimized.<br><br>You need to configure blob storage.<br><br>How should you complete the YAML configuration? To answer, select the appropriate options in the answer area.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/az-204/image451.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/az-204/image452.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2023-09-28T07:57:00.000Z",
        "voteCount": 8,
        "content": "got in 28/09/23 , totally out of scope"
      },
      {
        "date": "2023-08-16T23:59:00.000Z",
        "voteCount": 8,
        "content": "Sadly got this question 08/17/23 in the exam"
      },
      {
        "date": "2023-09-04T07:38:00.000Z",
        "voteCount": 15,
        "content": "Thanks for mentioning, so this question is definitely not out of scope! In fact, I don't even believe \"scope\" is in Microsoft's dictionary"
      },
      {
        "date": "2024-05-31T03:13:00.000Z",
        "voteCount": 1,
        "content": "Isn't Kubernetes a whole other Certification?"
      },
      {
        "date": "2024-08-05T19:29:00.000Z",
        "voteCount": 1,
        "content": "kind should be PersistentVolume and PersistentVolumeClaim to ensure data persistence.\nprovisioner should be kubernetes.io/azure-disk for Azure Disk.\nskuName is set to Premium_LRS for low latency.\nreclaimPolicy is set to Retain to ensure data is not deleted when the pod is restarted."
      },
      {
        "date": "2024-08-14T06:38:00.000Z",
        "voteCount": 1,
        "content": "in Kubernetes manifest you don't set the provisioner in a PV or PVC , you do in storageClass"
      },
      {
        "date": "2024-02-13T03:24:00.000Z",
        "voteCount": 4,
        "content": "On exam 2024, went with given answer, score 872 or something. Case Study: Farmers and Distributors. I don't understand the question. The question states \"configure blob\", and then there is no option for blob configuration, but instead you configure Azure Files or Azure Disks?\n\nAnd the worse of all, the configuration given is so obsolete that:\n*it was already removed from Kubernetes, as stated here: https://kubernetes.io/docs/concepts/storage/storage-classes/#azure-disk\n\n*it is only available in an example outside MS Learn (so unavailable during the exam)\n\nAnyway, I'm still not sure what the right answer would be, but I went with azure-disk because it supports retentionPolicy, maybe it should be azure-files like some are saying, but its examples don't use retentionPolicy."
      },
      {
        "date": "2023-12-05T10:27:00.000Z",
        "voteCount": 3,
        "content": "StorageClass / azure-file / retain"
      },
      {
        "date": "2023-08-12T05:07:00.000Z",
        "voteCount": 4,
        "content": "Out of scope. Suggested answer seems correct. Ref:\nhttps://learn.microsoft.com/en-us/azure/aks/azure-csi-disk-storage-provision\nhttps://kubernetes.io/docs/concepts/storage/storage-classes/#azure-disk\n\nRef azure-file\nhttps://learn.microsoft.com/en-us/azure/aks/azure-csi-files-storage-provision#create-a-storage-class\n(Create a storage class)\n\nhttps://kubernetes.io/docs/concepts/storage/storage-classes/#azure-file\n\nRef PodStorage / Persistent Volume / PersistentVolumeClaim\nhttps://kubernetes.io/docs/tasks/configure-pod-container/configure-persistent-volume-storage/\n\nRef portworx-volume \nhttps://docs.portworx.com/portworx-enterprise/operations/operate-kubernetes/storage-operations/kubernetes-storage-101/volumes\n\nRef Reclaim Policy\nhttps://kubernetes.io/docs/concepts/storage/storage-classes/#reclaim-policy"
      },
      {
        "date": "2023-08-21T01:55:00.000Z",
        "voteCount": 4,
        "content": "As someone mentioned to received this question recently, it is not out of scope. Actually, I am no longer care if it is out of scope because Microsoft doesn't give a f about it!"
      },
      {
        "date": "2023-08-03T06:10:00.000Z",
        "voteCount": 4,
        "content": "Crazy that people are getting out-of-scope questions in the official exam. Perhaps its not counted in the final score. We wont know"
      },
      {
        "date": "2023-08-21T01:56:00.000Z",
        "voteCount": 5,
        "content": "Or maybe, \"out-of-scope\" is not within Microsoft dictionary!"
      },
      {
        "date": "2023-07-28T21:30:00.000Z",
        "voteCount": 4,
        "content": "Got this question 29/06/2023"
      },
      {
        "date": "2023-07-09T23:37:00.000Z",
        "voteCount": 3,
        "content": "Out of scope! Nevertheless, seems to be correct."
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 46,
    "url": "https://www.examtopics.com/discussions/microsoft/view/117537-exam-az-204-topic-3-question-46-discussion/",
    "body": "HOTSPOT<br> -<br><br><br>Case study<br> -<br><br>This is a case study. Case studies are not timed separately. You can use as much exam time as you would like to complete each case. However, there may be additional case studies and sections on this exam. You must manage your time to ensure that you are able to complete all questions included on this exam in the time provided.<br><br>To answer the questions included in a case study, you will need to reference information that is provided in the case study. Case studies might contain exhibits and other resources that provide more information about the scenario that is described in the case study. Each question is independent of the other questions in this case study.<br><br>At the end of this case study, a review screen will appear. This screen allows you to review your answers and to make changes before you move to the next section of the exam. After you begin a new section, you cannot return to this section.<br><br><br>To start the case study<br> -<br>To display the first question in this case study, click the Next button. Use the buttons in the left pane to explore the content of the case study before you answer the questions. Clicking these buttons displays information such as business requirements, existing environment, and problem statements. When you are ready to answer a question, click the Question button to return to the question.<br><br><br>Background<br> -<br><br>VanArsdel, Ltd. is a global office supply company. The company is based in Canada and has retail store locations across the world. The company is developing several cloud-based solutions to support their stores, distributors, suppliers, and delivery services.<br><br><br>Current environment<br> -<br><br><br>Corporate website<br> -<br><br>The company provides a public website located at http://www.vanarsdelltd.com. The website consists of a React JavaScript user interface, HTML, CSS, image assets, and several APIs hosted in Azure Functions.<br><br><br>Retail Store Locations<br> -<br><br>The company supports thousands of store locations globally. Store locations send data every hour to an Azure Blob storage account to support inventory, purchasing and delivery services. Each record includes a location identifier and sales transaction information.<br><br><br>Requirements<br> -<br><br>The application components must meet the following requirements:<br><br><br>Corporate website<br> -<br><br>\u2022\tSecure the website by using SSL.<br>\u2022\tMinimize costs for data storage and hosting.<br>\u2022\tImplement native GitHub workflows for continuous integration and continuous deployment (CI/CD).<br>\u2022\tDistribute the website content globally for local use.<br>\u2022\tImplement monitoring by using Application Insights and availability web tests including SSL certificate validity and custom header value verification.<br>\u2022\tThe website must have 99.95 percent uptime.<br><br><br>Retail store locations<br> -<br><br>\u2022\tAzure Functions must process data immediately when data is uploaded to Blob storage. Azure Functions must update Azure Cosmos DB by using native SQL language queries.<br>\u2022\tAudit store sale transaction information nightly to validate data, process sales financials, and reconcile inventory.<br><br><br>Delivery services<br> -<br><br>\u2022\tStore service telemetry data in Azure Cosmos DB by using an Azure Function. Data must include an item id, the delivery vehicle license plate, vehicle package capacity, and current vehicle location coordinates.<br>\u2022\tStore delivery driver profile information in Azure Active Directory (Azure AD) by using an Azure Function called from the corporate website.<br><br><br>Inventory services<br> -<br><br>The company has contracted a third-party to develop an API for inventory processing that requires access to a specific blob within the retail store storage account for three months to<br> include read-only access to the data.<br><br><br>Security<br> -<br><br>\u2022\tAll Azure Functions must centralize management and distribution of configuration data for different environments and geographies, encrypted by using a company-provided RSA-HSM key.<br>\u2022\tAuthentication and authorization must use Azure AD and services must use managed identities where possible.<br><br><br>Issues<br> -<br><br><br>Retail Store Locations<br> -<br><br>\u2022\tYou must perform a point-in-time restoration of the retail store location data due to an unexpected and accidental deletion of data.<br>\u2022\tAzure Cosmos DB queries from the Azure Function exhibit high Request Unit (RU) usage and contain multiple, complex queries that exhibit high point read latency for large items as the function app is scaling.<br><br><br>You need to implement the delivery service telemetry data.<br><br>How should you configure the solution? To answer, select the appropriate options in the answer area.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/az-204/image461.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/az-204/image462.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2023-08-14T01:53:00.000Z",
        "voteCount": 26,
        "content": "API: \"Core (SQL)\"\nPartition Key: \"Item id\"\n\nSee: https://learn.microsoft.com/en-us/azure/cosmos-db/partitioning-overview#use-item-id-as-the-partition-key"
      },
      {
        "date": "2024-06-27T20:20:00.000Z",
        "voteCount": 1,
        "content": "Great explanation ! Thanks for the link."
      },
      {
        "date": "2023-08-14T11:04:00.000Z",
        "voteCount": 1,
        "content": "That makes a lot more sense, thanks for the link"
      },
      {
        "date": "2023-11-03T07:59:00.000Z",
        "voteCount": 15,
        "content": "On exam 3-Nov-2023. Went with most-voted answer - 932/1000:\n1) Core SQL\n2) Item Id\n\nNote: all 11 Qs from VanArsdel case study were on Exam."
      },
      {
        "date": "2024-02-29T06:44:00.000Z",
        "voteCount": 2,
        "content": "Why can I see only 1 question here\nis it because I dont have contributors access?"
      },
      {
        "date": "2024-04-07T08:19:00.000Z",
        "voteCount": 1,
        "content": "I have this access, but I still see only one question..."
      },
      {
        "date": "2024-03-06T14:27:00.000Z",
        "voteCount": 1,
        "content": "yeah, even i just see 1 question, cases study has usually 10 questions"
      },
      {
        "date": "2023-11-14T02:28:00.000Z",
        "voteCount": 1,
        "content": "Why its not License plate?"
      },
      {
        "date": "2023-08-22T03:27:00.000Z",
        "voteCount": 3,
        "content": "This should be Core(SQL) and Partition Key (item.id) i belive ?"
      },
      {
        "date": "2023-08-07T09:31:00.000Z",
        "voteCount": 9,
        "content": "Why item.id is not used for Partition Key?"
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 47,
    "url": "https://www.examtopics.com/discussions/microsoft/view/116813-exam-az-204-topic-3-question-47-discussion/",
    "body": "You create and publish a new Azure App Service web app.<br><br>User authentication and authorization must use Azure Active Directory (Azure AD).<br><br>You need to configure authentication and authorization.<br><br>What should you do first?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAdd an identity provider.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tMap an existing custom DNS name.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate and configure a new app setting.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAdd a private certificate.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate and configure a managed identity."
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 17,
        "isMostVoted": true
      },
      {
        "answer": "E",
        "count": 2,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2023-07-30T18:51:00.000Z",
        "voteCount": 12,
        "content": "A- Add an identity provide is correct\nhttps://learn.microsoft.com/en-us/azure/app-service/scenario-secure-app-authentication-app-service#3-configure-authentication-and-authorization"
      },
      {
        "date": "2023-08-23T05:49:00.000Z",
        "voteCount": 1,
        "content": "Correct - step 3"
      },
      {
        "date": "2024-07-04T03:10:00.000Z",
        "voteCount": 1,
        "content": "https://learn.microsoft.com/en-us/azure/app-service/scenario-secure-app-authentication-app-service#3-configure-authentication-and-authorization"
      },
      {
        "date": "2024-02-27T09:10:00.000Z",
        "voteCount": 1,
        "content": "Select Answer : E"
      },
      {
        "date": "2023-10-11T06:16:00.000Z",
        "voteCount": 2,
        "content": "I think E is right"
      },
      {
        "date": "2023-09-21T03:35:00.000Z",
        "voteCount": 2,
        "content": "Why not E. Create and configure a managed identity??"
      },
      {
        "date": "2023-10-12T01:20:00.000Z",
        "voteCount": 8,
        "content": "I think it is because you need to implement user authentication and authorization. Managed identity is used to authenticate Azure resources"
      },
      {
        "date": "2023-07-30T12:31:00.000Z",
        "voteCount": 4,
        "content": "Answer seems correct based on https://learn.microsoft.com/en-us/azure/app-service/configure-authentication-provider-aad?tabs=workforce-tenant"
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 48,
    "url": "https://www.examtopics.com/discussions/microsoft/view/116610-exam-az-204-topic-3-question-48-discussion/",
    "body": "DRAG DROP<br> -<br><br>You have an Azure Cosmos DB for NoSQL account.<br><br>You plan to develop two apps named App1 and App2 that will use the change feed functionality to track changes to containers. App1 will use the pull model and App2 will use the push model.<br><br>You need to choose the method to track the most recently processed change in App1 and App2.<br><br>Which component should you use? To answer, drag the appropriate components to the correct apps. Each component may be used once, more than once, or not at all. You may need to drag the split bar between panes or scroll to view content.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/az-204/image465.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/az-204/image466.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2023-08-12T05:20:00.000Z",
        "voteCount": 9,
        "content": "Seems correct. \n\nApp2 Push Model - Lease container\n\"When reading from the Azure Cosmos DB change feed, we usually recommend using a push model because you won't need to worry about: ... Storing state for the last processed change. If you are reading from the change feed processor, state is automatically stored in a lease container.\nRef: \nhttps://learn.microsoft.com/en-us/azure/cosmos-db/nosql/read-change-feed#reading-change-feed-with-a-push-model\""
      },
      {
        "date": "2023-10-05T15:13:00.000Z",
        "voteCount": 6,
        "content": "Correct!\nThe change feed pull model allows you to consume the change feed at your own pace. Changes must be requested by the client and there's no automatic polling for changes. If you want to permanently \"bookmark\" the last processed change (similar to the push model's lease container), you'll need to save a continuation token.\n\nhttps://learn.microsoft.com/en-us/azure/cosmos-db/nosql/read-change-feed"
      },
      {
        "date": "2024-01-17T00:47:00.000Z",
        "voteCount": 6,
        "content": "Correct.\nApp1 (Pull Model): This model involves explicitly querying the change feed and managing the state of what has been read.\nBest Component: Continuation Token. The pull model typically relies on continuation tokens to keep track of where the last read operation ended and to resume from that point.\nApp2 (Push Model): In this model, the change feed processor pushes changes to the application, and the application logic processes these changes.\nBest Component: Lease Container. The push model, especially when using the change feed processor, leverages a lease container to maintain state and ensure reliable processing."
      },
      {
        "date": "2023-09-28T17:25:00.000Z",
        "voteCount": 1,
        "content": "Correct"
      },
      {
        "date": "2023-07-27T09:30:00.000Z",
        "voteCount": 4,
        "content": "The answer is correct. Link: https://learn.microsoft.com/en-us/azure/cosmos-db/nosql/change-feed-pull-model?tabs=dotnet#compare-to-the-change-feed-processor"
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 49,
    "url": "https://www.examtopics.com/discussions/microsoft/view/125276-exam-az-204-topic-3-question-49-discussion/",
    "body": "You have a Linux container-based console application that uploads image files from customer sites all over the world. A back-end system that runs on Azure virtual machines processes the images by using the Azure Blobs API.<br><br>You are not permitted to make changes to the application.<br><br>Some customer sites only have phone-based internet connections.<br><br>You need to configure the console application to access the images.<br><br>What should you use?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure BlobFuse\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure Disks",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure Storage Network File System (NFS) 3.0 support",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure Files"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 16,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-12-17T22:45:00.000Z",
        "voteCount": 8,
        "content": "The correct answer is:\n\nA. Azure BlobFuse\n\nAzure BlobFuse allows you to access Azure Blob Storage from Linux and Azure services as if it were a local file system, without changing the application. This is particularly useful for your scenario where you can't modify the application and need to process images stored in Azure Blob Storage. BlobFuse provides the necessary interface between the application and Azure Blob Storage."
      },
      {
        "date": "2024-02-29T01:49:00.000Z",
        "voteCount": 3,
        "content": "That's a chatGPT answer?"
      },
      {
        "date": "2024-08-29T23:14:00.000Z",
        "voteCount": 1,
        "content": "Azure BlobFuse is an open-source virtual file system driver for Azure Blob storage. It allows you to mount a Blob storage container as a file system on Linux.\nAdvantages:\nSeamless Integration: Since BlobFuse allows you to mount Blob storage as a file system, your application can interact with the Blob storage as if it were a local file system. This means no changes are needed in your application code.\nPerformance: BlobFuse is optimized for performance and can handle large files and high throughput.\nCompatibility: It works well with Linux-based systems and containerized applications.\nNetwork Efficiency: It can handle intermittent connectivity and optimize data transfer over limited bandwidth connections, which is beneficial for sites with phone-based internet connections."
      },
      {
        "date": "2024-02-19T03:56:00.000Z",
        "voteCount": 1,
        "content": "Azure files is the selected answers according to google bbard and chatgpt."
      },
      {
        "date": "2024-01-13T07:55:00.000Z",
        "voteCount": 2,
        "content": "Linuxis unbased. we should ff"
      },
      {
        "date": "2023-12-02T22:13:00.000Z",
        "voteCount": 4,
        "content": "https://learn.microsoft.com/en-us/azure/storage/blobs/blobfuse2-what-is"
      },
      {
        "date": "2023-11-16T04:24:00.000Z",
        "voteCount": 4,
        "content": "Is this still a valid question for AZ-204? I don't see those resources in study guide."
      },
      {
        "date": "2024-03-12T04:28:00.000Z",
        "voteCount": 2,
        "content": "Microsoft is just crazy"
      },
      {
        "date": "2023-11-13T09:19:00.000Z",
        "voteCount": 4,
        "content": "Azure BlobFuse, as\nAzure Disks are block storage devices that are not designed to be accessed directly by applications.\nAzure Storage NFS 3.0 support is still in preview and is not yet available for all accounts.\nAzure Files is a managed file share service that is not designed to be used with slow and unreliable internet connections."
      },
      {
        "date": "2023-11-04T07:32:00.000Z",
        "voteCount": 1,
        "content": "not completly clear on what \"access the images\" really means,but seeing that the application in VM uses blob API, stands to reason that the console application will interact with blob storage, not files. given that the console application is uploading images, it reasonably means that uploads via blobfuse, as this is a virtual file system driver for azure blob storage"
      },
      {
        "date": "2023-11-03T10:22:00.000Z",
        "voteCount": 3,
        "content": "Azure BlobFuse is the correct answer in this scenario."
      },
      {
        "date": "2023-11-03T05:46:00.000Z",
        "voteCount": 1,
        "content": "Hi what is this?"
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 50,
    "url": "https://www.examtopics.com/discussions/microsoft/view/125277-exam-az-204-topic-3-question-50-discussion/",
    "body": "DRAG DROP<br> -<br><br>You are developing several microservices named serviceA, serviceB, and serviceC. You deploy the microservices to a new Azure Container Apps environment.<br><br>You have the following requirements:<br><br>\u2022\tThe microservices must persist data to storage.<br>\u2022\tserviceA must persist data only visible to the current container and the storage must be restricted to the amount of disk space available in the container.<br>\u2022\tserviceB must persist data for the lifetime of the replica and allow multiple containers in the replica to mount the same storage location.<br>\u2022\tserviceC must persist data beyond the lifetime of the replica while allowing multiple containers to access the storage and enable per object permissions.<br><br>You need to configure storage for each microservice.<br><br>Which storage type should you use? To answer, drag the appropriate storage types to the correct microservices. Each storage type may be used once, more than once, or not at all. You may need to drag the split bar between panes or scroll to view content.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/az-204/image484.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/az-204/image485.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2023-12-17T22:46:00.000Z",
        "voteCount": 7,
        "content": "Given these options, the storage types for each microservice should be:\n\nserviceA: Container file system The container file system is local to the container and is only visible to the current container. It is restricted to the amount of disk space available in the container.\n\nserviceB: Ephemeral Storage Ephemeral Storage is temporary storage that persists for the lifetime of the replica. It allows multiple containers in the replica to mount the same storage location.\n\nserviceC: Azure Blob Storage Azure Blob Storage is a highly scalable and durable object storage service that persists data beyond the lifetime of the replica. It allows multiple containers to access the storage and supports per-object permissions."
      },
      {
        "date": "2024-07-26T02:53:00.000Z",
        "voteCount": 2,
        "content": "A ----&gt; container file system.\nB ----&gt; Ephemeral Storage.\nC : While Azure Blob Storage is a valid option for persisting data beyond the lifetime of a replica and allows access from multiple containers, it lacks a key feature mentioned in the requirement: it does not provide it does not provide BUILT-IN  funcionality for mounting the blob storage AS FILE SYSTEM ACCESSIBLE to the containers , Azure Files does offer , so C -----&gt; Azure Files"
      },
      {
        "date": "2024-06-11T01:43:00.000Z",
        "voteCount": 1,
        "content": "Given answer is correct. https://learn.microsoft.com/en-us/azure/container-apps/storage-mounts?tabs=smb&amp;pivots=azure-cli"
      },
      {
        "date": "2024-03-26T04:17:00.000Z",
        "voteCount": 2,
        "content": "The options are tricky. Container File System is essentially an Ephemeral Storage. \nEphemeral Storage has both the options Container Scoped and Replica Scoped. :)\n\nThe given answer is the most appropriate choice."
      },
      {
        "date": "2023-11-03T05:53:00.000Z",
        "voteCount": 4,
        "content": "Anwser looks correct."
      },
      {
        "date": "2023-11-03T05:59:00.000Z",
        "voteCount": 5,
        "content": "Sorry. I'm mean:\nServiceA: Container file system\nServiceB: Ephemeral volumes (it lives as long as replica lives)\nServiceC: Azure Blob Storage (it lives outside of replica. So it's beyond the lifetime. And we want to have blob instead of file)"
      },
      {
        "date": "2023-11-04T07:40:00.000Z",
        "voteCount": 6,
        "content": "ACA does not mount to blob storage(https://learn.microsoft.com/en-us/azure/container-apps/storage-mounts), AKS i belive it does. so original answer is right"
      },
      {
        "date": "2023-11-20T00:43:00.000Z",
        "voteCount": 4,
        "content": "C: Azure Files storage\nAzure Blob Storage don't allow: per object permissions"
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 51,
    "url": "https://www.examtopics.com/discussions/microsoft/view/131298-exam-az-204-topic-3-question-51-discussion/",
    "body": "DRAG DROP<br> -<br><br>You are developing a web service that will run on Azure virtual machines that use Azure Storage. You configure all virtual machines to use managed identities.<br><br>You have the following requirements:<br><br>\u2022\tSecret-based authentication mechanisms are not permitted for accessing an Azure Storage account.<br>\u2022\tMust use only Azure Instance Metadata Service endpoints.<br><br>You need to write code to retrieve an access token to access Azure Storage. To answer, drag the appropriate code segments to the correct locations. Each code segment may be used once or not at all. You may need to drag the split bar between panes or scroll to view content.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/az-204/image504.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/az-204/image505.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-02-26T04:08:00.000Z",
        "voteCount": 3,
        "content": "I asked Google AI tool the following question: How do I retrieve an access token using Azure Instance Metadata Service endpoints ?\nI think the given answer here is correct!"
      },
      {
        "date": "2024-01-16T04:34:00.000Z",
        "voteCount": 3,
        "content": "Not relevant question and answer!"
      },
      {
        "date": "2024-08-04T00:01:00.000Z",
        "voteCount": 1,
        "content": "It is part of the exam, you can check Microsoft website."
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 52,
    "url": "https://www.examtopics.com/discussions/microsoft/view/130467-exam-az-204-topic-3-question-52-discussion/",
    "body": "HOTSPOT<br> -<br><br>You are developing an Azure Function app.<br><br>The Azure Function app must enable a WebHook to read an image from Azure Blob Storage and create a new Azure Cosmos DB document.<br><br>You need to implement the Azure Function app.<br><br>Which configuration should you use? To answer, select the appropriate options in the answer area.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/az-204/image506.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/az-204/image507.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-01-08T06:38:00.000Z",
        "voteCount": 5,
        "content": "Given Answer is Correct: \n\nA- HTTP Trigger for webhook\nB- Input binding for blob storage to read image\nC- Output binding to output a document to Cosmos DB\n\nhttps://learn.microsoft.com/en-us/azure/azure-functions/functions-bindings-storage-blob-input?tabs=python-v2%2Cisolated-process%2Cnodejs-v4&amp;pivots=programming-language-csharp\n\nhttps://learn.microsoft.com/en-us/azure/azure-functions/functions-bindings-cosmosdb-v2-output?tabs=python-v2%2Cisolated-process%2Cnodejs-v4%2Cextensionv4&amp;pivots=programming-language-csharp"
      },
      {
        "date": "2024-01-14T07:01:00.000Z",
        "voteCount": 4,
        "content": "provided answer is correct: https://learn.microsoft.com/en-us/azure/azure-functions/functions-bindings-http-webhook-trigger?tabs=python-v2%2Cisolated-process%2Cnodejs-v4%2Cfunctionsv2&amp;pivots=programming-language-csharp"
      },
      {
        "date": "2024-01-11T05:42:00.000Z",
        "voteCount": 2,
        "content": "Answer is correct because you can route storage events to webhook\nhttps://learn.microsoft.com/en-us/azure/storage/blobs/storage-blob-event-quickstart?toc=%2Fazure%2Fevent-grid%2Ftoc.json"
      },
      {
        "date": "2024-01-06T08:44:00.000Z",
        "voteCount": 3,
        "content": "Given answer is false:\nBlob storage, Blob storage, Azure Cosmos DB"
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 53,
    "url": "https://www.examtopics.com/discussions/microsoft/view/130460-exam-az-204-topic-3-question-53-discussion/",
    "body": "You create an Azure Cosmos DB for NoSQL database.<br><br>You plan to use the Azure Cosmos DB .NET SDK v3 API for NoSQL to upload the following files:<br><br><img src=\"https://img.examtopics.com/az-204/image508.png\"><br><br>You receive the following error message when uploading the files: \u201c413 Entity too large\u201d.<br><br>You need to determine which files you can upload to the Azure Cosmos DB for NoSQL database.<br><br>Which files can you upload?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tFile1, File2, File3, File4, and File5",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tFile1 and File2 only\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tFile1, File2, and File3 only",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tFile1, File2, File3, and File4 only",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tFile1 only"
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 19,
        "isMostVoted": true
      },
      {
        "answer": "E",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2024-01-06T05:54:00.000Z",
        "voteCount": 9,
        "content": "Correct  - 2MB limit -https://learn.microsoft.com/en-us/azure/cosmos-db/concepts-limits#per-item-limits"
      },
      {
        "date": "2024-03-26T07:39:00.000Z",
        "voteCount": 5,
        "content": "2 GB it is. \nMaximum size of an item = 2 MB (UTF-8 length of JSON representation) \u00b9\n\u00b9 Large document sizes up to 16 MB are supported with Azure Cosmos DB for MongoDB only."
      },
      {
        "date": "2024-08-14T06:21:00.000Z",
        "voteCount": 1,
        "content": "Select B.\n\"Azure Cosmos DB limits single request's size to 2MB.\"\nhttps://learn.microsoft.com/en-us/azure/data-factory/connector-azure-cosmos-db?tabs=data-factory#sink-transformation"
      },
      {
        "date": "2024-02-11T09:59:00.000Z",
        "voteCount": 3,
        "content": "Option B is correct. Each file has a maximum size of 2 MB. So File 1, File 2 Only can be uploaded."
      },
      {
        "date": "2024-03-15T01:04:00.000Z",
        "voteCount": 1,
        "content": "this correct: https://learn.microsoft.com/en-us/answers/questions/692455/actual-document-size-limit-for-azure-cosmos-db-s-a\n\nWhile it is possible to store more than 2MB"
      },
      {
        "date": "2024-01-16T09:20:00.000Z",
        "voteCount": 1,
        "content": "B is correct"
      },
      {
        "date": "2024-01-16T04:57:00.000Z",
        "voteCount": 1,
        "content": "E, because the total of files in the batch will exceed 2 MB"
      },
      {
        "date": "2024-01-14T07:05:00.000Z",
        "voteCount": 2,
        "content": "Correct Answer is E: Azure Cosmos DB limits single request's size to 2MB. The formula is Request Size = Single Document Size * Write Batch Size. If you hit error saying \"Request size is too large.\", reduce the writeBatchSize value in copy sink configuration\n\nhttps://learn.microsoft.com/en-us/azure/data-factory/connector-azure-cosmos-db?tabs=data-factory"
      },
      {
        "date": "2024-01-10T03:56:00.000Z",
        "voteCount": 1,
        "content": "I think the correct answer is E not B because the total size for File1 and File2 will be 3 MB"
      },
      {
        "date": "2024-02-19T02:18:00.000Z",
        "voteCount": 2,
        "content": "The requirements do not specify that they MUST be uploaded in one batch"
      },
      {
        "date": "2024-07-03T17:12:00.000Z",
        "voteCount": 1,
        "content": "I'll go with the agreed answer but it also did not say the files are uploaded individually. \nSo the answer E has some merit."
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 54,
    "url": "https://www.examtopics.com/discussions/microsoft/view/149596-exam-az-204-topic-3-question-54-discussion/",
    "body": "You are developing an app to store globally distributed data in several Azure Blob Storage containers. Each container hosts multiple blobs where each instance of the app will store the data. You enable versioning and soft delete for the blobs.<br><br>App testing and incorrect code have frequently corrupted data. Development of the app must allow data to be restored to a previous day for testing.<br><br>You need to configure the storage account to support point-in-time restore.<br><br>What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEnable the change feed on the storage account to begin capturing and recording changes.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure object replication and specify replication rules.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a snapshot of the blob in the hot tier.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure an immutability policy that is scoped to a blob version."
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-10-18T06:33:00.000Z",
        "voteCount": 1,
        "content": "Looks like the answer is correct.\n\nhttps://learn.microsoft.com/en-us/azure/storage/blobs/point-in-time-restore-manage?tabs=portal#enable-and-configure-point-in-time-restore"
      },
      {
        "date": "2024-10-18T06:34:00.000Z",
        "voteCount": 1,
        "content": "From the link above:\n\nEnable and configure point-in-time restore\nBefore you enable and configure point-in-time restore, enable its prerequisites for the storage account: soft delete, change feed, and blob versioning. For more information about enabling each of these features, see these articles:\n\nEnable soft delete for blobs\nEnable and disable the change feed\nEnable and manage blob versioning"
      },
      {
        "date": "2024-10-16T01:13:00.000Z",
        "voteCount": 1,
        "content": "Given the need for point-in-time restore and the capabilities of the options:\n\nCorrect Answer: C. Create a snapshot of the blob in the hot tier.\n\nReasoning: Creating a snapshot allows you to capture the current state of the blob and restore it later, which meets the requirement of restoring to a previous day for testing."
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 55,
    "url": "https://www.examtopics.com/discussions/microsoft/view/149601-exam-az-204-topic-3-question-56-discussion/",
    "body": "HOTSPOT<br> -<br><br>You have the following data lifecycle management policy:<br><br><img src=\"https://img.examtopics.com/az-204/image530.png\"><br><br>You plan to implement an Azure Blob Storage account and apply to it Policy1. The solution should maximize resiliency and performance.<br><br>You need to configure the account to support the policy.<br><br>Which redundancy option and storage account type should you use? To answer, select the appropriate options in the answer area.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/az-204/image531.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/az-204/image532.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-10-18T08:26:00.000Z",
        "voteCount": 1,
        "content": "Second answer incorrect. Should be General-purpose V2\n\nhttps://learn.microsoft.com/en-us/azure/storage/common/storage-redundancy#supported-storage-account-types"
      },
      {
        "date": "2024-10-16T03:29:00.000Z",
        "voteCount": 1,
        "content": "\"Microsoft recommends using GZRS for applications requiring maximum consistency, durability, and availability, excellent performance, and resilience for disaster recovery.\"\nOnly Standard general-purpose v2 (StorageV2)1 can handle GRS/RA-GRS\n\n\nhttps://learn.microsoft.com/en-us/azure/storage/common/storage-redundancy\nSo, i would say RA-GRS with general purpose v2"
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 56,
    "url": "https://www.examtopics.com/discussions/microsoft/view/149602-exam-az-204-topic-3-question-57-discussion/",
    "body": "HOTSPOT<br> -<br><br>You have an Azure Cosmos DB for NoSQL API account named account1. Multiple instances of an on-premises application named app1 read data from account1.<br><br>You plan to implement integrated cache for connections from the instances of app to account1.<br><br>You need to set the connection mode and maximum consistency level of app1.<br><br>Which values should you use for the configuration settings? To answer, select the appropriate options in the answer area.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/az-204/image533.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/az-204/image534.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-10-16T03:55:00.000Z",
        "voteCount": 1,
        "content": "Okay, so gateway mode using dedicated gateway has to be correct. \n\"The integrated cache uses the dedicated gateway within your Azure Cosmos DB account. \" (https://learn.microsoft.com/en-us/azure/cosmos-db/integrated-cache)\n\nThe second one I'm not sure about. \"The integrated cache supports read requests with session and eventual consistency only.\" (https://learn.microsoft.com/en-us/azure/cosmos-db/integrated-cache). In my mind there are two correct answers here, but please correct me if I'm wrong. On that page they do talk a lot about session consistency and that leads me to believe that session is the correct answer"
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 57,
    "url": "https://www.examtopics.com/discussions/microsoft/view/149600-exam-az-204-topic-3-question-58-discussion/",
    "body": "You are developing a Cosmos DB solution that will be deployed to multiple Azure regions.<br><br>Your solution must meet the following requirements:<br><br>\u2022\tRead operations will never receive write operations that are out of order.<br>\u2022\tMaximize concurrency of read operations in all regions.<br><br>You need to choose the consistency level for the solution.<br><br>Which consistency level should you use?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tsession",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\teventual",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tbounded staleness",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tconsistent prefix"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2024-10-16T02:31:00.000Z",
        "voteCount": 1,
        "content": "Why not C?"
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 58,
    "url": "https://www.examtopics.com/discussions/microsoft/view/149599-exam-az-204-topic-3-question-59-discussion/",
    "body": "You have an Azure Queue Storage named queue1.<br><br>You plan to develop code that will process messages in queue1.<br><br>You need to implement a queue operation to set the visibility timeout value of individual messages in queue1.<br><br>Which two operations can you use? Each correct answer presents a complete solution.<br><br>NOTE: Each correct selection is worth one point.",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tPeek at a message in the queue.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDelete a message in the queue.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAdd a message to the queue.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUpdate a message in the queue.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tReceive a message from the queue."
    ],
    "answer": "CD",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-10-16T02:07:00.000Z",
        "voteCount": 2,
        "content": "To set the visibility timeout of individual messages in Azure Queue Storage, you can use the following operations:\n\nD. Update a message in the queue\n\nExplanation: The Update operation allows you to modify a message\u2019s content and its visibility timeout. You can use this operation to update the visibility timeout for a message that has already been retrieved from the queue.\nE. Receive a message from the queue\n\nExplanation: When you retrieve (or \"receive\") a message from the queue, you can specify the visibility timeout at that point. This is useful when you want to process the message but delay its visibility to other consumers."
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 59,
    "url": "https://www.examtopics.com/discussions/microsoft/view/149597-exam-az-204-topic-3-question-60-discussion/",
    "body": "HOTSPOT<br> -<br><br><br>Case study<br> -<br><br>This is a case study. Case studies are not timed separately. You can use as much exam time as you would like to complete each case. However, there may be additional case studies and sections on this exam. You must manage your time to ensure that you are able to complete all questions included on this exam in the time provided.<br><br>To answer the questions included in a case study, you will need to reference information that is provided in the case study. Case studies might contain exhibits and other resources that provide more information about the scenario that is described in the case study. Each question is independent of the other questions in this case study.<br><br>At the end of this case study, a review screen will appear. This screen allows you to review your answers and to make changes before you move to the next section of the exam. After you begin a new section, you cannot return to this section.<br><br><br>To start the case study<br> -<br>To display the first question in this case study, click the Next button. Use the buttons in the left pane to explore the content of the case study before you answer the questions. Clicking these buttons displays information such as business requirements, existing environment, and problem statements. When you are ready to answer a question, click the Question button to return to the question.<br><br><br>Background<br> -<br><br>Fourth Coffee is a global coffeehouse chain and coffee company recognized as one of the world\u2019s most influential coffee brands. The company is renowned for its specialty coffee beverages, including a wide range of espresso-based drinks, teas, and other beverages. Fourth Coffee operates thousands of stores worldwide.<br><br><br>Current environment<br> -<br><br>The company is developing cloud-native applications hosted in Azure.<br><br><br>Corporate website<br> -<br>The company hosts a public website located at http://www.fourthcoffee.com/. The website is used to place orders as well as view and update inventory items.<br><br><br>Inventory items<br> -<br>In addition to its core coffee offerings, Fourth Coffee recently expanded its menu to include inventory items such as lunch items, snacks, and merchandise. Corporate team members constantly update inventory. Users can customize items. Corporate team members configure inventory items and associated images on the website.<br><br><br>Orders<br> -<br>Associates in the store serve customized beverages and items to customers. Orders are placed on the website for pickup.<br><br>The application components process data as follows:<br><br>1. Azure Traffic Manager routes a user order request to the corporate website hosted in Azure App Service.<br>2. Azure Content Delivery Network serves static images and content to the user.<br>3. The user signs in to the application through a Microsoft Entra ID for customers tenant.<br>4. Users search for items and place an order on the website as item images are pulled from Azure Blob Storage.<br>5. Item customizations are placed in an Azure Service Bus queue message.<br>6. Azure Functions processes item customizations and saves the customized items to Azure Cosmos DB.<br>7. The website saves order details to Azure SQL Database.<br>8. SQL Database query results are cached in Azure Cache for Redis to improve performance.<br><br>The application consists of the following Azure services:<br><br><img src=\"https://img.examtopics.com/az-204/image535.png\"><br><br><br>Requirements<br> -<br><br>The application components must meet the following requirements:<br><br>\u2022\tAzure Cosmos DB development must use a native API that receives the latest updates and stores data in a document format.<br>\u2022\tCosts must be minimized for all Azure services.<br>\u2022\tDevelopers must test Azure Blob Storage integrations locally before deployment to Azure. Testing must support the latest versions of the Azure Storage APIs.<br><br><br>Corporate website<br> -<br>\u2022\tUser authentication and authorization must allow one-time passcode sign-in methods and social identity providers (Google or Facebook).<br>\u2022\tStatic web content must be stored closest to end users to reduce network latency.<br><br><br>Inventory items<br> -<br>\u2022\tCustomized items read from Azure Cosmos DB must maximize throughput while ensuring data is accurate for the current user on the website.<br>\u2022\tProcessing of inventory item updates must automatically scale and enable updates across an entire Azure Cosmos DB container.<br>\u2022\tInventory items must be processed in the order they were placed in the queue.<br>\u2022\tInventory item images must be stored as JPEG files in their native format to include exchangeable image file format (data) stored with the blob data upon upload of the image file.<br>\u2022\tThe Inventory Items API must securely access the Azure Cosmos DB data.<br><br><br>Orders<br> -<br>\u2022\tOrders must receive inventory item changes automatically after inventory items are updated or saved.<br><br><br>Issues<br> -<br><br>\u2022\tDevelopers are storing the Azure Cosmos DB credentials in an insecure clear text manner within the Inventory Items API code.<br>\u2022\tProduction Azure Cache for Redis maintenance has negatively affected application performance.<br><br><br>You need to save customized items to Azure Cosmos DB.<br><br>Which Azure Cosmos DB configuration should you use? To answer, select the appropriate options in the answer area.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/az-204/image536.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/az-204/image537.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-10-16T02:01:00.000Z",
        "voteCount": 1,
        "content": "1. API:\nNoSQL\nReasoning: Since the development must use a native API that stores data in a document format, the NoSQL API is the correct choice. Azure Cosmos DB's NoSQL API stores data in JSON documents and is the most commonly used API for document-based use cases, which aligns with the storage of customized items in the scenario.\n2. Consistency Level:\nSession\nReasoning: The scenario requires that customized items maximize throughput while ensuring that the data is accurate for the current user. Session consistency provides the best balance between performance and data accuracy for scenarios where multiple reads and writes are performed by the same user session. It ensures that a user reads their own writes, which is important for ensuring that customized items are accurate for the current user.\nFinal Answer:\nAPI: NoSQL\nConsistency level: Session"
      }
    ],
    "examNameCode": "az-204",
    "topicNumber": "3"
  }
]