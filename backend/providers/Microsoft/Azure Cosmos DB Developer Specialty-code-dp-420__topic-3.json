[
  {
    "topic": 3,
    "index": 1,
    "url": "https://www.examtopics.com/discussions/microsoft/view/77531-exam-dp-420-topic-3-question-1-discussion/",
    "body": "You have an Azure Cosmos DB Core (SQL) API account that uses a custom conflict resolution policy. The account has a registered merge procedure that throws a runtime exception.<br>The runtime exception prevents conflicts from being resolved.<br>You need to use an Azure function to resolve the conflicts.<br>What should you use?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ta function that pulls items from the conflicts feed and is triggered by a timer trigger\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ta function that receives items pushed from the change feed and is triggered by an Azure Cosmos DB trigger",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ta function that pulls items from the change feed and is triggered by a timer trigger",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ta function that receives items pushed from the conflicts feed and is triggered by an Azure Cosmos DB trigger"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 19,
        "isMostVoted": true
      },
      {
        "answer": "B",
        "count": 2,
        "isMostVoted": false
      },
      {
        "answer": "D",
        "count": 1,
        "isMostVoted": false
      },
      {
        "answer": "C",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2022-08-15T05:22:00.000Z",
        "voteCount": 15,
        "content": "Correct answer should be \"A\" - we need to resolve conflicts, hence we definitely need to read the conflicts feed, hence answers B and C are immediately eliminated as they are pull from the changes feed, answer D mentions an Azure Cosmos DB trigger, but this is only for the change feed, not for the conflicts feed, hence A is the correct answer since there is no trigger mechanism for the conflict feed in Cosmos DB"
      },
      {
        "date": "2023-12-29T01:41:00.000Z",
        "voteCount": 1,
        "content": "Conflict feed and CosmosDB trigger"
      },
      {
        "date": "2023-10-01T01:29:00.000Z",
        "voteCount": 1,
        "content": "Answer is A:\n\nhttps://learn.microsoft.com/en-us/azure/cosmos-db/conflict-resolution-policies#conflict-resolution-policies\n\nIf you configure your container with the custom resolution option, and you fail to register a merge procedure on the container or the merge procedure throws an exception at runtime, the conflicts are written to the conflicts feed. Your application then needs to manually resolve the conflicts in the conflicts feed. To learn more, see examples of how to use the custom resolution policy and how to use the conflicts feed."
      },
      {
        "date": "2023-03-02T01:21:00.000Z",
        "voteCount": 1,
        "content": "Correct answer is A"
      },
      {
        "date": "2022-09-25T23:24:00.000Z",
        "voteCount": 1,
        "content": "Correct answer is A"
      },
      {
        "date": "2022-09-05T09:38:00.000Z",
        "voteCount": 2,
        "content": "Correct answer is A: all conflicts related data is stored in the conflicts feed, you have to orchestrate the function using a timer"
      },
      {
        "date": "2022-08-22T01:28:00.000Z",
        "voteCount": 1,
        "content": "Answer A"
      },
      {
        "date": "2022-08-15T05:14:00.000Z",
        "voteCount": 1,
        "content": "As grada explained very well, the answer should be C"
      },
      {
        "date": "2022-08-15T05:20:00.000Z",
        "voteCount": 1,
        "content": "Actually, ignore this answer - C is retrieving from the change feed not the conflicts feed"
      },
      {
        "date": "2022-08-15T05:26:00.000Z",
        "voteCount": 1,
        "content": "Correct answer is A"
      },
      {
        "date": "2022-07-24T14:13:00.000Z",
        "voteCount": 2,
        "content": "The Azure Cosmos DB Trigger uses the Azure Cosmos DB Change Feed to listen for inserts and updates across partitions. The change feed publishes inserts and updates, not deletions."
      },
      {
        "date": "2022-07-22T02:13:00.000Z",
        "voteCount": 4,
        "content": "Answer should be A. Need to read from conflict feed but there is no trigger mechanism for the conflict feed in Cosmos DB."
      },
      {
        "date": "2022-07-15T07:11:00.000Z",
        "voteCount": 2,
        "content": "The correct answer is C, only change feed triggers are available, and conflict feed needs to be manually queried from a timer-triggered function.\n\nSource: https://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-cosmosdb-v2-trigger?tabs=in-process%2Cextensionv4&amp;pivots=programming-language-csharp#attributes\n\nNothing conflict-feed-related there, only change-feed-related. Conflict feed needs to be manually triggered like this: https://docs.microsoft.com/en-us/azure/cosmos-db/sql/how-to-manage-conflicts?tabs=dotnetv3%2Capi-async%2Casync#read-from-conflict-feed"
      },
      {
        "date": "2024-01-03T06:25:00.000Z",
        "voteCount": 1,
        "content": "You can use a timer trigger as well."
      }
    ],
    "examNameCode": "dp-420",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 2,
    "url": "https://www.examtopics.com/discussions/microsoft/view/77532-exam-dp-420-topic-3-question-2-discussion/",
    "body": "The following is a sample of a document in orders.<br><img src=\"/assets/media/exam-media/04276/0007300001.png\" class=\"in-exam-image\"><br>The orders container uses customerId as the partition key.<br>You need to provide a report of the total items ordered per month by item type. The solution must meet the following requirements:<br>\u2711 Ensure that the report can run as quickly as possible.<br>\u2711 Minimize the consumption of request units (RUs).<br>What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure the report to query orders by using a SQL query.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure the report to query a new aggregate container. Populate the aggregates by using the change feed.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure the report to query orders by using a SQL query through a dedicated gateway.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure the report to query a new aggregate container. Populate the aggregates by using SQL queries that run daily."
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 18,
        "isMostVoted": true
      },
      {
        "answer": "D",
        "count": 7,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2022-07-15T07:56:00.000Z",
        "voteCount": 10,
        "content": "After processing items in the change feed, you can build a materialized view and persist aggregated values back in Azure Cosmos DB. If you're using Azure Cosmos DB to build a game, you can, for example, use change feed to implement real-time leaderboards based on scores from completed games.\n\nhttps://docs.microsoft.com/en-us/azure/cosmos-db/sql/change-feed-design-patterns#high-availability"
      },
      {
        "date": "2023-12-29T01:43:00.000Z",
        "voteCount": 1,
        "content": "B is correct, no additional SQL queries necessary"
      },
      {
        "date": "2023-08-27T01:56:00.000Z",
        "voteCount": 1,
        "content": "The answer is D"
      },
      {
        "date": "2023-06-11T12:59:00.000Z",
        "voteCount": 2,
        "content": "Selected Answer: B"
      },
      {
        "date": "2023-04-27T06:28:00.000Z",
        "voteCount": 3,
        "content": "Option D suggests populating the aggregates by using SQL queries that run daily. While this may reduce the RU consumption during querying, it may not necessarily minimize RU consumption overall. Additionally, this approach may result in stale data since the aggregates are only updated once a day.\n\nThe best approach to minimize RU consumption and ensure the report runs as quickly as possible is to use the change feed to populate the aggregates in real-time, as suggested in option B. This way, the aggregates are always up-to-date, and the report can be generated quickly and with minimal RU consumption."
      },
      {
        "date": "2023-01-28T01:03:00.000Z",
        "voteCount": 2,
        "content": "B Is Correct"
      },
      {
        "date": "2022-09-29T11:01:00.000Z",
        "voteCount": 4,
        "content": "I would go with D, we need to minimize RU, so we run the job daily which should be fine for these types of reports (using monthly data). Using the change feed costs much more RU."
      },
      {
        "date": "2022-08-22T01:37:00.000Z",
        "voteCount": 2,
        "content": "B Is Correct"
      },
      {
        "date": "2022-08-05T12:05:00.000Z",
        "voteCount": 2,
        "content": "I would go with D, as we need to reduce RU. An additional container writes costs RU and the change-feed will be updated every time a new item appears."
      }
    ],
    "examNameCode": "dp-420",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 3,
    "url": "https://www.examtopics.com/discussions/microsoft/view/101329-exam-dp-420-topic-3-question-3-discussion/",
    "body": "HOTSPOT -<br>You have three containers in an Azure Cosmos DB Core (SQL) API account as shown in the following table.<br><img src=\"/assets/media/exam-media/04276/0007400001.png\" class=\"in-exam-image\"><br>You have the following Azure functions:<br>\u2711 A function named Fn1 that reads the change feed of cn1<br>\u2711 A function named Fn2 that reads the change feed of cn2<br>\u2711 A function named Fn3 that reads the change feed of cn3<br>You perform the following actions:<br>\u2711 Delete an item named item1 from cn1.<br>\u2711 Update an item named item2 in cn2.<br>\u2711 For an item named item3 in cn3, update the item time to live to 3,600 seconds.<br>For each of the following statements, select Yes if the statement is true. Otherwise, select No.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04276/0007500001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04276/0007500002.jpg\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: No -<br>Azure Cosmos DB's change feed is a great choice as a central data store in event sourcing architectures where all data ingestion is modeled as writes (no updates or deletes).<br>Note: The change feed does not capture deletes. If you delete an item from your container, it is also removed from the change feed. The most common method of handling this is adding a soft marker on the items that are being deleted. You can add a property called \"deleted\" and set it to \"true\" at the time of deletion. This document update will show up in the change feed. You can set a TTL on this item so that it can be automatically deleted later.<br><br>Box 2: No -<br>The _etag format is internal and you should not take dependency on it, because it can change anytime.<br><br>Box 3: Yes -<br>Change feed support in Azure Cosmos DB works by listening to an Azure Cosmos container for any changes.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/cosmos-db/sql/change-feed-design-patterns https://docs.microsoft.com/en-us/azure/cosmos-db/change-feed",
    "votes": [],
    "comments": [
      {
        "date": "2023-03-02T00:20:00.000Z",
        "voteCount": 7,
        "content": "Correct - \nN - https://learn.microsoft.com/en-us/azure/cosmos-db/change-feed#features-of-change-feed \nN - https://stackoverflow.com/questions/68409298/how-to-tell-the-difference-between-insert-and-update-in-cosmos-db-change-feed \nY - https://docs.microsoft.com/en-us/azure/cosmos-db/sql/change-feed-design-patterns https://docs.microsoft.com/en-us/azure/cosmos-db/change-feed"
      },
      {
        "date": "2023-06-11T13:11:00.000Z",
        "voteCount": 1,
        "content": "The correct answer is NYY.\n\nExplanation:\n\nFn1 will receive item1 from the change feed: No (The item was deleted from cn1, so it will not be received by Fn1.)\n\nFn2 checks the _etag of item2 to see whether the item is an update or an insert: Yes (Fn2 will be able to determine whether item2 is an update or an insert based on its _etag value.)\n\nFn3 will receive item3 from the change feed: Yes (The update of the time to live (TTL) for item3 in cn3 will trigger a change event in the change feed, and Fn3 will receive it.)\n\nTherefore, the correct answer is NYY."
      },
      {
        "date": "2023-06-11T13:13:00.000Z",
        "voteCount": 6,
        "content": "My Mistake\n\nAnswer is NNY"
      }
    ],
    "examNameCode": "dp-420",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 4,
    "url": "https://www.examtopics.com/discussions/microsoft/view/120890-exam-dp-420-topic-3-question-4-discussion/",
    "body": "HOTSPOT -<br>You configure Azure Cognitive Search to index a container in an Azure Cosmos DB Core (SQL) API account as shown in the following exhibit.<br><img src=\"/assets/media/exam-media/04276/0007600001.jpg\" class=\"in-exam-image\"><br>Use the drop-down menus to select the answer choice that completes each statement based on the information presented in the graphic.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04276/0007700001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04276/0007700002.jpg\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: country -<br>The country field is filterable.<br>Note: filterable: Indicates whether to enable the field to be referenced in $filter queries. Filterable differs from searchable in how strings are handled. Fields of type<br>Edm.String or Collection(Edm.String) that are filterable do not undergo lexical analysis, so comparisons are for exact matches only.<br><br>Box 2: name -<br>The name field is not Retrievable.<br>Retrievable: Indicates whether the field can be returned in a search result. Set this attribute to false if you want to use a field (for example, margin) as a filter, sorting, or scoring mechanism but do not want the field to be visible to the end user.<br>Note: searchable: Indicates whether the field is full-text searchable and can be referenced in search queries.<br>Reference:<br>https://docs.microsoft.com/en-us/rest/api/searchservice/create-index",
    "votes": [],
    "comments": [
      {
        "date": "2023-10-08T07:09:00.000Z",
        "voteCount": 2,
        "content": "https://learn.microsoft.com/en-us/azure/search/search-what-is-an-index#field-attributes\n\n\"filterable\" - Referenced in $filter queries. Filterable fields of type Edm.String or Collection(Edm.String) don't undergo word-breaking, so comparisons are for exact matches only. For example, if you set such a field f to \"sunny day\", $filter=f eq 'sunny' finds no matches, but $filter=f eq 'sunny day' will.\n\n\"retrievable\" -\tDetermines whether the field can be returned in a search result. This is useful when you want to use a field (such as profit margin) as a filter, sorting, or scoring mechanism, but don't want the field to be visible to the end user. This attribute must be true for key fields.\n\nYes County and I believe Id would be more correct as a key field."
      },
      {
        "date": "2023-09-17T23:44:00.000Z",
        "voteCount": 4,
        "content": "Yes, correct, Country &amp; Name"
      }
    ],
    "examNameCode": "dp-420",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 5,
    "url": "https://www.examtopics.com/discussions/microsoft/view/112437-exam-dp-420-topic-3-question-5-discussion/",
    "body": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.<br>After you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.<br>You have a container named container1 in an Azure Cosmos DB Core (SQL) API account.<br>You need to make the contents of container1 available as reference data for an Azure Stream Analytics job.<br>Solution: You create an Azure Synapse pipeline that uses Azure Cosmos DB Core (SQL) API as the input and Azure Blob Storage as the output.<br>Does this meet the goal?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tYes\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tNo"
    ],
    "answer": "B",
    "answerDescription": "Instead create an Azure function that uses Azure Cosmos DB Core (SQL) API change feed as a trigger and Azure event hub as the output.<br>The Azure Cosmos DB change feed is a mechanism to get a continuous and incremental feed of records from an Azure Cosmos container as those records are being created or modified. Change feed support works by listening to container for any changes. It then outputs the sorted list of documents that were changed in the order in which they were modified.<br>The following diagram represents the data flow and components involved in the solution:<br><img src=\"/assets/media/exam-media/04276/0007900001.jpg\" class=\"in-exam-image\"><br>Reference:<br>https://docs.microsoft.com/en-us/azure/cosmos-db/sql/changefeed-ecommerce-solution",
    "votes": [
      {
        "answer": "A",
        "count": 2,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-05-07T01:33:00.000Z",
        "voteCount": 2,
        "content": "This is a series of questions with multiple scenarios. Correct options are:\n1. You create an Azure Synapse pipeline that uses Azure Cosmos DB Core (SQL) API as the input and Azure Blob Storage as the output.\n2. You create an Azure Data Factory pipeline that uses Azure Cosmos DB Core (SQL) API as the input and Azure Blob Storage as the output.\nAll other options are incorrect."
      },
      {
        "date": "2024-03-14T04:48:00.000Z",
        "voteCount": 2,
        "content": "https://learn.microsoft.com/en-us/azure/stream-analytics/stream-analytics-use-reference-data#example\nStream Analytics supports Azure Blob Storage, Azure Data Lake Storage Gen2, and Azure SQL Database as the storage layer for reference data.\nI think the solution of outputting to Azure Blob Storage is yes, and the rest is no."
      },
      {
        "date": "2023-07-03T03:35:00.000Z",
        "voteCount": 2,
        "content": "According to https://learn.microsoft.com/en-us/azure/stream-analytics/stream-analytics-quick-create-portal, can the answer be YES."
      },
      {
        "date": "2023-11-13T21:06:00.000Z",
        "voteCount": 2,
        "content": "Probably not as I do not see CosmosDB as an input for stream analytics job\n\nhttps://learn.microsoft.com/en-us/azure/stream-analytics/stream-analytics-add-inputs"
      },
      {
        "date": "2023-06-17T04:24:00.000Z",
        "voteCount": 4,
        "content": "Given answer is correct"
      }
    ],
    "examNameCode": "dp-420",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 6,
    "url": "https://www.examtopics.com/discussions/microsoft/view/126023-exam-dp-420-topic-3-question-6-discussion/",
    "body": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.<br>After you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.<br>You have a container named container1 in an Azure Cosmos DB Core (SQL) API account.<br>You need to make the contents of container1 available as reference data for an Azure Stream Analytics job.<br>Solution: You create an Azure Data Factory pipeline that uses Azure Cosmos DB Core (SQL) API as the input and Azure Blob Storage as the output.<br>Does this meet the goal?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tYes\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tNo"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 5,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-05-07T01:33:00.000Z",
        "voteCount": 1,
        "content": "This is a series of questions with multiple scenarios. Correct options are:\n1. You create an Azure Synapse pipeline that uses Azure Cosmos DB Core (SQL) API as the input and Azure Blob Storage as the output.\n2. You create an Azure Data Factory pipeline that uses Azure Cosmos DB Core (SQL) API as the input and Azure Blob Storage as the output.\nAll other options are incorrect."
      },
      {
        "date": "2024-03-14T04:47:00.000Z",
        "voteCount": 1,
        "content": "https://learn.microsoft.com/en-us/azure/stream-analytics/stream-analytics-use-reference-data#example\nStream Analytics supports Azure Blob Storage, Azure Data Lake Storage Gen2, and Azure SQL Database as the storage layer for reference data.\nI think the solution of outputting to Azure Blob Storage is yes, and the rest is no."
      },
      {
        "date": "2023-11-13T21:10:00.000Z",
        "voteCount": 4,
        "content": "https://learn.microsoft.com/en-us/azure/data-factory/concepts-pipelines-activities?tabs=data-factory#data-movement-activities\n\nAzure Data Factory supports CosmosDB as a source and Blob storage as the sink."
      }
    ],
    "examNameCode": "dp-420",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 7,
    "url": "https://www.examtopics.com/discussions/microsoft/view/84080-exam-dp-420-topic-3-question-7-discussion/",
    "body": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.<br>After you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.<br>You have a container named container1 in an Azure Cosmos DB Core (SQL) API account.<br>You need to make the contents of container1 available as reference data for an Azure Stream Analytics job.<br>Solution: You create an Azure function that uses Azure Cosmos DB Core (SQL) API change feed as a trigger and Azure event hub as the output.<br>Does this meet the goal?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tYes",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tNo\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "A",
    "answerDescription": "The Azure Cosmos DB change feed is a mechanism to get a continuous and incremental feed of records from an Azure Cosmos container as those records are being created or modified. Change feed support works by listening to container for any changes. It then outputs the sorted list of documents that were changed in the order in which they were modified.<br>The following diagram represents the data flow and components involved in the solution:<br><img src=\"/assets/media/exam-media/04276/0008100001.jpg\" class=\"in-exam-image\"><br>Reference:<br>https://docs.microsoft.com/en-us/azure/cosmos-db/sql/changefeed-ecommerce-solution",
    "votes": [
      {
        "answer": "B",
        "count": 1,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2022-09-29T23:27:00.000Z",
        "voteCount": 7,
        "content": "I don't thing that Y is correct. While event hub would be a great input source for Stream Analytics *Streaming* Data, it is not supported as input for Stream Analytics *Reference* Data. https://learn.microsoft.com/en-us/azure/stream-analytics/stream-analytics-add-inputs. \n\nUsing Data Factory is the recommended solution for reference data in the Microsoft docs: https://learn.microsoft.com/en-us/azure/stream-analytics/stream-analytics-use-reference-data"
      },
      {
        "date": "2023-07-03T03:27:00.000Z",
        "voteCount": 1,
        "content": "So, why question #6 is no? The question before this one."
      },
      {
        "date": "2024-01-03T06:43:00.000Z",
        "voteCount": 1,
        "content": "Question #6 is wrong. For real-time data, you use an Event Hub. For reference data, you use Data Factory"
      },
      {
        "date": "2023-07-01T13:33:00.000Z",
        "voteCount": 1,
        "content": "Answer"
      }
    ],
    "examNameCode": "dp-420",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 8,
    "url": "https://www.examtopics.com/discussions/microsoft/view/82559-exam-dp-420-topic-3-question-8-discussion/",
    "body": "You have an Azure Cosmos DB Core (SQL) API account.<br>The change feed is enabled on a container named invoice.<br>You create an Azure function that has a trigger on the change feed.<br>What is received by the Azure function?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tonly the changed properties and the system-defined properties of the updated items",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tonly the partition key and the changed properties of the updated items",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tall the properties of the original items and the updated items",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tall the properties of the updated items\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 15,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2022-09-17T11:47:00.000Z",
        "voteCount": 6,
        "content": "Answer is D as all properties are sent to the change feed.  This is testable by creating an Azure Function with CosmosDB input trigger."
      },
      {
        "date": "2023-09-27T13:20:00.000Z",
        "voteCount": 1,
        "content": "When you create an Azure function with a trigger on the change feed of an Azure Cosmos DB Core (SQL) API container, the Azure function receives the following:\n\nB. only the partition key and the changed properties of the updated items.\n\nThe change feed provides information about changes made to the items in the container. Specifically, it includes the partition key and the properties of the updated items. This allows the Azure function to process the changes, including the partition key and the specific properties that were modified, without needing to retrieve all properties of the original items.\n\nThis selective information is beneficial for efficiently processing changes and reacting to updates in real-time without the need to access the entire original item, which can help minimize processing overhead and improve performance."
      },
      {
        "date": "2024-01-03T06:58:00.000Z",
        "voteCount": 1,
        "content": "Answer is D - all properties are retrieved using the change feed\n\nChange feed in Azure Cosmos DB is a persistent record of changes to a container in the order they occur. Change feed support in Azure Cosmos DB works by listening to an Azure Cosmos DB container for any changes. It then outputs the sorted list of documents that were changed in the order in which they were modified. \n\nhttps://learn.microsoft.com/en-us/azure/cosmos-db/change-feed"
      },
      {
        "date": "2023-08-19T21:18:00.000Z",
        "voteCount": 2,
        "content": "It is D"
      },
      {
        "date": "2023-07-29T12:22:00.000Z",
        "voteCount": 1,
        "content": "It should be D only."
      },
      {
        "date": "2023-03-30T10:03:00.000Z",
        "voteCount": 1,
        "content": "D is correct"
      },
      {
        "date": "2022-12-21T05:28:00.000Z",
        "voteCount": 3,
        "content": "D is the correct answer"
      },
      {
        "date": "2022-09-30T06:32:00.000Z",
        "voteCount": 4,
        "content": "It should be D"
      },
      {
        "date": "2022-09-29T11:05:00.000Z",
        "voteCount": 4,
        "content": "Wrong. D is correct, entire doc is passed"
      }
    ],
    "examNameCode": "dp-420",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 9,
    "url": "https://www.examtopics.com/discussions/microsoft/view/113273-exam-dp-420-topic-3-question-9-discussion/",
    "body": "DRAG DROP -<br>You have an Azure Synapse Analytics workspace named workspace1 that contains a serverless SQL pool.<br>You have an Azure Table Storage account that stores operational data.<br>You need to replace the Table storage account with Azure Cosmos DB Core (SQL) API. The solution must meet the following requirements:<br>\u2711 Support queries from the serverless SQL pool.<br>\u2711 Only pay for analytical compute when running queries.<br>\u2711 Ensure that analytical processes do NOT affect operational processes.<br>Which three actions should you perform in sequence? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.<br>Select and Place:<br><img src=\"/assets/media/exam-media/04276/0008200004.jpg\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04276/0008200005.jpg\" class=\"in-exam-image\">",
    "answerDescription": "Step 1: Create an Azure Cosmos DB core (SQL) API account<br>Step 2: Enable Azure Synapse Link<br>Synapse Link creates a tight seamless integration between Azure Cosmos DB and Azure Synapse Analytics.<br>Serverless SQL pool allows you to query and analyze data in your Azure Cosmos DB containers that are enabled with Azure Synapse Link. You can analyze data in near real-time without impacting the performance of your transactional workloads.<br>Step 3: Create a database and a container that has Analytical store enabled<br>Create an analytical store enabled container<br>Reference:<br>https://docs.microsoft.com/en-us/azure/cosmos-db/configure-synapse-link",
    "votes": [],
    "comments": [
      {
        "date": "2023-06-25T12:53:00.000Z",
        "voteCount": 5,
        "content": "Therefore, the correct sequence of actions is as follows:\n\n1. Create an Azure Cosmos DB Core (SQL) API account.\n2. Enable Azure Synapse Link.\n3. Create a database and a container that has Analytical store enabled."
      }
    ],
    "examNameCode": "dp-420",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 10,
    "url": "https://www.examtopics.com/discussions/microsoft/view/80399-exam-dp-420-topic-3-question-10-discussion/",
    "body": "You have a database named db1 in an Azure Cosmos DB Core (SQL) API account named account1.<br>You need to write JSON data to db1 by using Azure Stream Analytics. The solution must minimize costs.<br>Which should you do before you can use db1 as an output of Stream Analytics?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tIn account1, add a private endpoint",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tIn db1, create containers that have a custom indexing policy and analytical store disabled\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tIn db1, create containers that have an automatic indexing policy and analytical store enabled",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tIn account1, enable a dedicated gateway"
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 10,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2022-09-05T11:31:00.000Z",
        "voteCount": 7,
        "content": "Answer is B\nStream Analytics doesn't create containers in your database. Instead, it requires you to create them up front. You can then control the billing costs of Azure Cosmos DB containers, and u dont need to use Analytical Store becosue we dont have ColumnStore"
      },
      {
        "date": "2023-07-12T02:53:00.000Z",
        "voteCount": 1,
        "content": "But a Document databases can use analytical store."
      },
      {
        "date": "2023-12-29T01:47:00.000Z",
        "voteCount": 1,
        "content": "Strange and most likely incomplete or wrong question"
      },
      {
        "date": "2023-09-27T14:48:00.000Z",
        "voteCount": 1,
        "content": "To use an Azure Cosmos DB Core (SQL) API database (db1) as an output for Azure Stream Analytics while minimizing costs, you should follow these steps:\n\nB. In db1, create containers that have a custom indexing policy and analytical store disabled.\n\nHere's why this is the correct option:\n\nCustom Indexing Policy: Creating containers with a custom indexing policy allows you to optimize the indexing behavior based on your specific requirements. You can choose to exclude specific properties from indexing if they are not needed for querying. This can help reduce indexing costs.\n\nAnalytical Store Disabled: The analytical store is used for historical data analysis, and enabling it can add extra cost. If you're primarily using Stream Analytics for real-time data ingestion and processing, you may not need the analytical store. Disabling it can help minimize costs."
      },
      {
        "date": "2023-03-02T22:27:00.000Z",
        "voteCount": 4,
        "content": "\"Stream Analytics doesn't create containers in your database. Instead, it requires you to create them beforehand. You can then control the billing costs of Azure Cosmos DB containers. You can also tune the performance, consistency, and capacity of your containers directly by using the Azure Cosmos DB APIs.\"\nhttps://learn.microsoft.com/en-us/azure/stream-analytics/stream-analytics-documentdb-output#basics-of-azure-cosmos-db-as-an-output-target"
      },
      {
        "date": "2022-10-13T08:17:00.000Z",
        "voteCount": 2,
        "content": "I Think that B is the correct answer because you don't need the Analytical Store."
      },
      {
        "date": "2022-09-29T07:34:00.000Z",
        "voteCount": 2,
        "content": "sure it's not A, but usure about B"
      },
      {
        "date": "2022-09-14T08:55:00.000Z",
        "voteCount": 2,
        "content": "Definitely not A"
      }
    ],
    "examNameCode": "dp-420",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 11,
    "url": "https://www.examtopics.com/discussions/microsoft/view/107689-exam-dp-420-topic-3-question-11-discussion/",
    "body": "You have a database named db1 in an Azure Cosmos DB Core (SQL) API account.<br>You have a third-party application that is exposed through a REST API.<br>You need to migrate data from the application to a container in db1 on a weekly basis.<br>What should you use?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure Migrate",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure Data Factory\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDatabase Migration Assistant"
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 9,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-04-27T06:45:00.000Z",
        "voteCount": 5,
        "content": "Correct Answer is B. \nAzure Migrate is a service designed for migrating on-premises virtual machines and database Migration Assistant is a tool that helps you assess and migrate databases to Azure, but it is not designed for migrating data from a third-party application exposed through a REST API"
      },
      {
        "date": "2023-06-30T12:09:00.000Z",
        "voteCount": 4,
        "content": "With Azure Data Factory, you can create a pipeline that connects to the third-party application's REST API as a data source and configures the destination to be the container in db1. By scheduling the pipeline to run weekly, you can migrate the data from the application to the specified container in db1 on a recurring basis."
      }
    ],
    "examNameCode": "dp-420",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 12,
    "url": "https://www.examtopics.com/discussions/microsoft/view/86682-exam-dp-420-topic-3-question-12-discussion/",
    "body": "HOTSPOT -<br>You have an Apache Spark pool in Azure Synapse Analytics that runs the following Python code in a notebook.<br><img src=\"/assets/media/exam-media/04276/0008600001.jpg\" class=\"in-exam-image\"><br>For each of the following statements. select Yes if the statement is true. Otherwise. select No.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04276/0008700001.jpg\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04276/0008700002.jpg\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: No -<br>Streaming \u05d2\u20ac\" Append Output Mode is an outputMode in which only the new rows in the streaming DataFrame/Dataset will be written to the sink.<br>This is the default mode. Use append as output mode outputMode(\"append\") when you want to output only new rows to the output sink.<br>Note:<br>Streaming \u05d2\u20ac\" Complete Output Mode is an OutputMode in which all the rows in the streaming DataFrame/Dataset will be written to the sink every time there are some updates.<br>Streaming \u05d2\u20ac\" Update Output Mode is an outputMode in which only the rows that were updated in the streaming DataFrame/Dataset will be written to the sink every time there are some updates.<br><br>Box 2: No -<br>Structured Streaming is a scalable and fault-tolerant stream processing engine built on the Spark SQL engine. You can express your streaming computation the same way you would express a batch computation on static data. The Spark SQL engine will take care of running it incrementally and continuously and updating the final result as streaming data continues to arrive.<br><br>Box 3: Yes -<br>Synapse Apache Spark also allows you to ingest data into Azure Cosmos DB. It is important to note that data is always ingested into Azure Cosmos DB containers through the transactional store. When Synapse Link is enabled, any new inserts, updates, and deletes are then automatically synced to the analytical store.<br>Reference:<br>https://sparkbyexamples.com/spark/spark-streaming-outputmode/ https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html https://docs.microsoft.com/en-us/azure/synapse-analytics/synapse-link/how-to-query-analytical-store-spark",
    "votes": [],
    "comments": [
      {
        "date": "2023-08-10T09:58:00.000Z",
        "voteCount": 6,
        "content": "Answer \nN: Append mode activate, updates won't be recorded.\nN: Streaming\nN: It doesn't need"
      },
      {
        "date": "2022-10-30T11:51:00.000Z",
        "voteCount": 5,
        "content": "And Question 1 is \"Yes\" - as this is reading from the change feed and so gets all the inserts and updates."
      },
      {
        "date": "2023-01-17T14:48:00.000Z",
        "voteCount": 4,
        "content": "Since the append mode is enabled, updates will not be recorded, only new records are added so your answer is partially right/wrong.  I would go with 'No' for Question 1."
      },
      {
        "date": "2024-01-03T07:12:00.000Z",
        "voteCount": 2,
        "content": "Correct, but this is not what the bullet point is asking. \nIt says that updates and inserts are added to orders, which is FALSE. \n\nThe stream is reading inserts and updates for contoso-app. \nIt only adds the inserts for contoso-erp, due to mode Append. \nReading data from a stream does not guarantee it will processed in any way, shape or form."
      },
      {
        "date": "2023-09-27T19:35:00.000Z",
        "voteCount": 1,
        "content": "Yes - New and updated orders will be added to contoso-erp.orders - The format is cosmos.oltp.changeFeed which will process all inserts and updates.\n\nNo - The code performs bulk data ingestion from contoso-app - It is not bulk data ingestion rather it is change feed.\n\nNo - Both contoso-app and contoso-erp have Analytical store enabled - The format is cosmos.oltp which will write into the original container (not into the lease container) so it is not required to enable Analytical store on the container"
      },
      {
        "date": "2023-09-27T14:57:00.000Z",
        "voteCount": 1,
        "content": "Please update the answer. Right answer is below\nAnswer\nN: Append mode activate, updates won't be recorded.\nN: Streaming\nN: It doesn't need"
      },
      {
        "date": "2023-06-17T11:10:00.000Z",
        "voteCount": 5,
        "content": "Answer YNN"
      },
      {
        "date": "2022-10-30T11:35:00.000Z",
        "voteCount": 3,
        "content": "This is linked to this documentation:\nhttps://learn.microsoft.com/en-us/azure/synapse-analytics/synapse-link/how-to-query-analytical-store-spark-3#load-streaming-dataframe-from-azure-cosmos-db-container\n\nAnd so doesn't need the analytical store to be enabled, so \"No\" for the third question."
      },
      {
        "date": "2023-01-17T14:49:00.000Z",
        "voteCount": 2,
        "content": "I agree.  For the third question, it should be a \"No\""
      }
    ],
    "examNameCode": "dp-420",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 13,
    "url": "https://www.examtopics.com/discussions/microsoft/view/113774-exam-dp-420-topic-3-question-13-discussion/",
    "body": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.<br>After you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.<br>You have a container named container1 in an Azure Cosmos DB Core (SQL) API account.<br>You need to make the contents of container1 available as reference data for an Azure Stream Analytics job.<br>Solution: You create an Azure function to copy data to another Azure Cosmos DB Core (SQL) API container.<br>Does this meet the goal?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tYes",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tNo\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 6,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-06-30T12:10:00.000Z",
        "voteCount": 6,
        "content": "Creating an Azure function to copy data to another Azure Cosmos DB Core (SQL) API container does not directly make the contents of container1 available as reference data for Azure Stream Analytics.\n\nTo make the contents of container1 available as reference data for an Azure Stream Analytics job, you should use Azure Stream Analytics' built-in support for Azure Cosmos DB Core (SQL) API as an input source. Azure Stream Analytics allows you to directly query the container and use its contents as reference data within the job."
      }
    ],
    "examNameCode": "dp-420",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 14,
    "url": "https://www.examtopics.com/discussions/microsoft/view/113775-exam-dp-420-topic-3-question-14-discussion/",
    "body": "You develop an application that uses Azure Cosmos DB Core (SQL) API.<br><br>You create an Azure pipeline to build and deploy the application.<br><br>You need to change the pipeline to run integration tests that you wrote for the application. The solution must execute entirely in the pipeline.<br><br>What should you add to the pipeline?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ta deployment group named Cosmos DB testing",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tan Azure Cosmos DB Emulator task",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ta NuGet service connection that uses an Azure Cosmos DB API key",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ta secret variable that has a connection string to an Azure Cosmos DB database\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 9,
        "isMostVoted": true
      },
      {
        "answer": "B",
        "count": 2,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2023-08-06T01:48:00.000Z",
        "voteCount": 5,
        "content": "the pipeline needs a connection string to execute"
      },
      {
        "date": "2024-01-03T07:16:00.000Z",
        "voteCount": 1,
        "content": "Emulators should be used for LOCAL development only. \nThis means that even if the Emulator would work in a pipeline, it's really a BAD decision. \nWhy ? Because integration tests need to have the same infrastructure as prod and the emulator does not work exactly the same."
      },
      {
        "date": "2023-10-26T05:40:00.000Z",
        "voteCount": 1,
        "content": "What \"The solution must execute entirely in the pipeline\" even means? Does it implies that connection to actual CosmosDB instance in the cloud should be made? Than, yes it should be Emulator. But, the emulator currently has limitations and IMHO shouldn't be used in integration tests. So secret connection string to a real CosmosDB instance dedicated for tests purposes could more accurate."
      },
      {
        "date": "2023-10-03T08:18:00.000Z",
        "voteCount": 2,
        "content": "The Azure Cosmos DB Emulator is a local, downloadable tool that emulates the Azure Cosmos DB service."
      },
      {
        "date": "2023-09-27T15:06:00.000Z",
        "voteCount": 1,
        "content": "Answer: B\nTo run integration tests for an application that uses Azure Cosmos DB Core (SQL) API within an Azure pipeline, you should add the following to the pipeline:\n\nB. an Azure Cosmos DB Emulator task.\n\nHere's why this is the correct option:\n\nAzure Cosmos DB Emulator: The Azure Cosmos DB Emulator is a local, downloadable tool that emulates the Azure Cosmos DB service. It allows you to test and develop applications locally without connecting to the actual Azure Cosmos DB service in the cloud. You can run integration tests against the emulator to ensure your application works as expected with Cosmos DB.\n\nPipeline Execution: By adding an Azure Cosmos DB Emulator task to your pipeline, you can start the emulator as part of the pipeline execution before running your integration tests. This ensures that your tests can interact with the emulated Cosmos DB service.\n\nOption D (a secret variable with a connection string to an Azure Cosmos DB database) is useful for securely storing connection strings, but it doesn't provide the emulator needed for running integration tests in the pipeline."
      },
      {
        "date": "2024-01-03T07:20:00.000Z",
        "voteCount": 1,
        "content": "Using the emulator is possible, but it's not the best decision because it does not replicate exactly the features of an actual Cosmos DB. For automated pipelines, you should always prefer a dedicated cosmos db instance over an emulator."
      },
      {
        "date": "2023-06-30T12:25:00.000Z",
        "voteCount": 4,
        "content": "D. a secret variable that has a connection string to an Azure Cosmos DB database."
      }
    ],
    "examNameCode": "dp-420",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 15,
    "url": "https://www.examtopics.com/discussions/microsoft/view/113776-exam-dp-420-topic-3-question-15-discussion/",
    "body": "You plan to create an operational system that will store data in an Azure Cosmos DB Core (SQL) API account.<br><br>You need to configure the account to meet the following requirements:<br><br>\u2022\tSupport Spark queries.<br>\u2022\tSupport the analysis of data from the last six months.<br>\u2022\tOnly pay for analytical compute when running queries.<br><br>Which three actions should you perform? Each correct answer presents part of the solution.<br><br>NOTE: Each correct selection is worth one point.",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEnable Azure Synapse Link for the account.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a container and set the analyticalTTL property to six months.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate an Azure Databricks notebook.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate an Azure Synapse linked service.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a container and set the time to live to six months.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"F\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tF.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate an Azure Synapse pipeline."
    ],
    "answer": "ABC",
    "answerDescription": "",
    "votes": [
      {
        "answer": "ABC",
        "count": 3,
        "isMostVoted": true
      },
      {
        "answer": "ABD",
        "count": 2,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2024-04-23T01:37:00.000Z",
        "voteCount": 2,
        "content": "Enable Azure Synapse Link for the account (Option A)\nCreate a container and set the analyticalTTL property to six months (Option B)\nCreate an Azure Synapse linked service (Option D)"
      },
      {
        "date": "2024-05-07T01:16:00.000Z",
        "voteCount": 1,
        "content": "Edit: Option D is wrong, Answers are A B and C"
      },
      {
        "date": "2023-06-30T12:27:00.000Z",
        "voteCount": 3,
        "content": "A. Enable Azure Synapse Link for the account.\nB. Create a container and set the analyticalTTL property to six months.\nC. Create an Azure Databricks notebook."
      }
    ],
    "examNameCode": "dp-420",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 16,
    "url": "https://www.examtopics.com/discussions/microsoft/view/114109-exam-dp-420-topic-3-question-16-discussion/",
    "body": "You have an Azure Cosmos DB account named account1.<br><br>You need to access account1 from an on-premises environment by using a Site-to-Site VPN.<br><br>What should you use?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ta private endpoint\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ta dedicated gateway",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure Synapse Link"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 9,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-07-04T13:00:00.000Z",
        "voteCount": 5,
        "content": "In the context of Azure Cosmos DB, there is no specific feature or service called \"dedicated gateway\" for accessing the database from an on-premises environment via a Site-to-Site VPN. Therefore, option B is not the correct answer.\n\nTo access an Azure Cosmos DB account from an on-premises environment via a Site-to-Site VPN, you would typically use:\n\nA. a private endpoint.\n\nA private endpoint allows you to access Azure services, including Azure Cosmos DB, privately from within an Azure virtual network. By configuring a private endpoint for the Azure Cosmos DB account, you can connect to the account using private IP addresses and ensure that the data transfer occurs securely over the Site-to-Site VPN between the on-premises network and the Azure virtual network.\n\nWith a private endpoint, the data traffic from the on-premises environment to Azure Cosmos DB remains within the private network and does not traverse the public internet, enhancing security and isolation."
      },
      {
        "date": "2023-08-06T01:51:00.000Z",
        "voteCount": 4,
        "content": "Site to site, from On-Prem to a cloud service securely, is almost always a private end-point"
      }
    ],
    "examNameCode": "dp-420",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 17,
    "url": "https://www.examtopics.com/discussions/microsoft/view/136009-exam-dp-420-topic-3-question-17-discussion/",
    "body": "HOTSPOT<br> -<br><br>You plan to create an Azure Cosmos DB database named db1 that will contain two containers. One of the containers will contain blog posts, and the other will contain users. Each item in the blog post container will include:<br><br>\u2022\tA single blog post<br>\u2022\tAll the comments associated to the blog post<br>\u2022\tThe names of the users who created the blog post and added the comments<br><br>You need to design a solution to update usernames in the user container without causing data integrity issues. The solution must minimize administrative and development effort.<br><br>What should you include in the solution? To answer, select the appropriate options in the answer area.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/dp-420/image147.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/dp-420/image148.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-03-14T05:31:00.000Z",
        "voteCount": 2,
        "content": "The change feed processor/A stored procedure\nhttps://learn.microsoft.com/en-us/azure/cosmos-db/nosql/model-partition-example#denormalizing-usernames\nIn our example, we use the change feed of the users container to react whenever users update their usernames. When that happens, we propagate the change by calling another stored procedure on the posts container."
      }
    ],
    "examNameCode": "dp-420",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 18,
    "url": "https://www.examtopics.com/discussions/microsoft/view/140119-exam-dp-420-topic-3-question-20-discussion/",
    "body": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.<br><br>After you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.<br><br>You have a container named container1 in an Azure Cosmos DB Core (SQL) API account.<br><br>You need to make the contents of container1 available as reference data for an Azure Stream Analytics job.<br><br>Solution: You create an Azure function that uses Azure Cosmos DB for NoSQL change feed as a trigger and Azure event hub as the output.<br><br>Does this meet the goal?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tYes",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tNo\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 1,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-09-24T21:34:00.000Z",
        "voteCount": 1,
        "content": "No, this solution does not meet the goal. \n\nTo use Azure Cosmos DB as reference data for an **Azure Stream Analytics job**, you would typically use Cosmos DB as a direct input or reference data source for the Stream Analytics job. Azure Stream Analytics supports Cosmos DB Core (SQL) API directly as a reference data source.\n\nThe provided solution involves using **Azure Functions** with Cosmos DB change feed as a trigger and outputting to **Azure Event Hub**, which is more suitable for real-time event-driven scenarios, but it doesn't directly provide Cosmos DB data as reference data to Stream Analytics.\n\nTo meet the goal, you should configure Cosmos DB as a reference data source in the Stream Analytics job instead of using the change feed and event hub combination."
      },
      {
        "date": "2024-05-07T01:36:00.000Z",
        "voteCount": 1,
        "content": "This is a series of questions with multiple scenarios. Correct options are:\n1. You create an Azure Synapse pipeline that uses Azure Cosmos DB Core (SQL) API as the input and Azure Blob Storage as the output.\n2. You create an Azure Data Factory pipeline that uses Azure Cosmos DB Core (SQL) API as the input and Azure Blob Storage as the output.\nAll other options are incorrect."
      }
    ],
    "examNameCode": "dp-420",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 19,
    "url": "https://www.examtopics.com/discussions/microsoft/view/139405-exam-dp-420-topic-3-question-23-discussion/",
    "body": "You plan to create an Azure Cosmos DB for NoSQL database named db1 that will contain two containers. One of the containers will contain blog posts, and the other will contain users. Each item in the blog post container will include:<br><br>\u2022\tA single blog post<br>\u2022\tThe top 10 comments associated to the blog post<br>\u2022\tThe names of the users who created the blog post and the associated comments<br><br>You need to automatically update the usernames in the blog post container whenever a username in the user container changes.<br><br>What should you implement for the user container?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ta stored procedure",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ta change feed processor\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ta post-trigger",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ta user-defined function (UDF)"
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 1,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-04-23T02:55:00.000Z",
        "voteCount": 1,
        "content": "Change feed is correct"
      }
    ],
    "examNameCode": "dp-420",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 20,
    "url": "https://www.examtopics.com/discussions/microsoft/view/140120-exam-dp-420-topic-3-question-25-discussion/",
    "body": "HOTSPOT<br> -<br><br>You have two Azure Cosmos for NoSQL containers named Container1 and Container2.<br><br>You plan to process the change feed for each container by using the following:<br><br>\u2022\tContainer1: Pull model<br>\u2022\tContainer2: Change feed processor<br><br>You need to track the current processing point for each change feed.<br><br>What should you use for each container? To answer, select the appropriate options in the answer area.<br><br><img src=\"https://img.examtopics.com/dp-420/image175.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/dp-420/image176.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-05-07T01:39:00.000Z",
        "voteCount": 1,
        "content": "Provided answer is correct."
      }
    ],
    "examNameCode": "dp-420",
    "topicNumber": "3"
  }
]