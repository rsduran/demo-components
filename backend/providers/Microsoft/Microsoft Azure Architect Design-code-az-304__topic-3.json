[
  {
    "topic": 3,
    "index": 1,
    "url": "https://www.examtopics.com/discussions/microsoft/view/63329-exam-az-304-topic-3-question-1-discussion/",
    "body": "HOTSPOT -<br>You manage a database environment for a Microsoft Volume Licensing customer named Contoso, Ltd. Contoso uses License Mobility through Software<br>Assurance.<br>You need to deploy 50 databases. The solution must meet the following requirements:<br>\u2711 Support automatic scaling.<br>\u2711 Minimize Microsoft SQL Server licensing costs.<br>What should you include in the solution? To answer, select the appropriate options in the answer area.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04027/0013600003.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04027/0013700001.png\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: vCore -<br>Virtual core (vCore)-based purchasing model (recommended). This purchasing model provides a choice between a provisioned compute tier and a serverless compute tier. With the provisioned compute tier, you choose the exact amount of compute resources that are always provisioned for your workload. With the serverless compute tier, you specify the autoscaling of the compute resources over a configurable compute range<br>Box 2: An Azure SQL Database Elastic pool<br>Azure SQL Database provides the following deployment options for a database:<br>\u2711 Single database represents a fully managed, isolated database.<br>\u2711 Elastic pool is a collection of single databases with a shared set of resources, such as CPU or memory. Single databases can be moved into and out of an elastic pool.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/azure-sql/database/purchasing-models",
    "votes": [],
    "comments": [
      {
        "date": "2021-10-07T16:20:00.000Z",
        "voteCount": 37,
        "content": "R1: Support automatic scaling\nThis is definitely Elastic Pool. Both DTU and vCore support exlastic pool. \n\n\nR2: Minimize Microsoft SQL Server licensing costs\nBut question mentioned License with software assurance. Therefore you can use Azure Hybrid Benefit for your Azure SQL database. In the provisioned compute tier of the vCore-based purchasing model, you can exchange your existing licenses for discounted rates on Azure SQL Database and Azure SQL Managed Instance by using Azure Hybrid Benefit. So purchase mode should be vCore.\n\nvCore &amp; Elastic pool"
      },
      {
        "date": "2021-12-01T09:51:00.000Z",
        "voteCount": 3,
        "content": "thanks for explanation"
      },
      {
        "date": "2021-12-01T09:54:00.000Z",
        "voteCount": 3,
        "content": "And can confirm with microsoft documentation:\n\nhttps://docs.microsoft.com/en-us/azure/azure-sql/azure-hybrid-benefit?tabs=azure-powershell"
      },
      {
        "date": "2022-03-02T23:05:00.000Z",
        "voteCount": 4,
        "content": "Correct.\n\nEnable Azure Hybrid Benefit\nAzure SQL Database\nYou can choose or change your licensing model for Azure SQL Database using the Azure portal or the API of your choice.\n\nYou can only apply the Azure Hybrid licensing model when you choose a vCore-based purchasing model and the provisioned compute tier for your Azure SQL Database. Azure Hybrid Benefit isn't available for service tiers under the DTU-based purchasing model or for the serverless compute tier.\nhttps://docs.microsoft.com/en-us/azure/azure-sql/azure-hybrid-benefit?tabs=azure-powershell"
      },
      {
        "date": "2021-10-03T08:32:00.000Z",
        "voteCount": 9,
        "content": "DTU is cheaper but you need vCore model to apply hybrid benefits.\n\nWhat is Azure Hybrid Benefit for SQL Server, and am I eligible for it?\nhttps://azure.microsoft.com/en-us/pricing/details/azure-sql-database/elastic/"
      },
      {
        "date": "2022-11-14T16:19:00.000Z",
        "voteCount": 1,
        "content": "Answer is correct"
      },
      {
        "date": "2022-08-11T01:39:00.000Z",
        "voteCount": 1,
        "content": "Thsi option \"Minimize Microsoft SQL Server licensing costs.\" pretty much threw me off thinking as I thought this alone force the choice to be a full SQL Server on a VM. I guess I didn't understand. I think they should have said SQL License to avoid confusion but I will not make the mistake again. \n\nThank you for the explanation."
      },
      {
        "date": "2022-03-29T02:46:00.000Z",
        "voteCount": 1,
        "content": "For Azure SQL Database, Azure Hybrid Benefit is only available when using the provisioned compute tier of the vCore-based purchasing model. Azure Hybrid Benefit doesn't apply to DTU-based purchasing models or the serverless compute tier."
      },
      {
        "date": "2021-10-08T10:41:00.000Z",
        "voteCount": 1,
        "content": "Given answers are correct."
      },
      {
        "date": "2021-10-07T04:16:00.000Z",
        "voteCount": 2,
        "content": "https://docs.microsoft.com/en-us/azure/azure-sql/database/purchasing-models\n\nVirtual core (vCore)-based purchasing model (recommended). This purchasing model provides a choice between a provisioned compute tier and a serverless compute tier. With the provisioned compute tier, you choose the exact amount of compute resources that are always provisioned for your workload. With the serverless compute tier, you specify the autoscaling of the compute resources over a configurable compute range\n\nvCore as purchasing model\n\n\"deploy 50 databases\"\n\nelastic pool for deployment"
      },
      {
        "date": "2021-09-30T16:54:00.000Z",
        "voteCount": 2,
        "content": "I think the answer might be DTU or vCore and sql elastic pool\n\nrefer these \nhttps://docs.microsoft.com/ko-kr/azure/azure-sql/database/elastic-pool-overview#how-do-i-choose-the-correct-pool-size"
      },
      {
        "date": "2021-10-02T16:26:00.000Z",
        "voteCount": 1,
        "content": "In the provisioned compute tier of the vCore-based purchasing model, you can exchange your existing licenses for discounted rates on Azure SQL Database and Azure SQL Managed Instance by using Azure Hybrid Benefit\n\nhttps://docs.microsoft.com/en-us/azure/azure-sql/azure-hybrid-benefit?tabs=azure-powershell"
      },
      {
        "date": "2021-09-30T10:19:00.000Z",
        "voteCount": 1,
        "content": "Answer is correct."
      },
      {
        "date": "2021-09-30T02:03:00.000Z",
        "voteCount": 2,
        "content": "Deployment option should be : SQL Managed Instance :\n\nSQL Managed Instance uses vCores mode and enables you to define maximum CPU cores and maximum of storage allocated to your instance. All databases within the managed instance will share the resources allocated to the instance.\n\nhttps://docs.microsoft.com/en-us/azure/azure-sql/database/scale-resources"
      },
      {
        "date": "2021-10-03T04:31:00.000Z",
        "voteCount": 1,
        "content": "In this question , it is not mentioned whether migration is happening . So Definitely SQL managed instance is not the answer"
      },
      {
        "date": "2021-09-30T10:19:00.000Z",
        "voteCount": 2,
        "content": "Disagree. Deployment option should be elastic pool, which supports vCore-based purchasing model too. \nhttps://docs.microsoft.com/en-us/azure/azure-sql/database/elastic-pool-overview#:~:text=%20Creating%20a%20new%20SQL%20Database%20elastic%20pool,pool%20to%20create%20a%20pool%20directly...%20More%20"
      },
      {
        "date": "2021-10-01T03:25:00.000Z",
        "voteCount": 2,
        "content": "You are right  with elastic pool we save some money which required in this question"
      },
      {
        "date": "2021-11-15T06:35:00.000Z",
        "voteCount": 1,
        "content": "Managed instance is the answer when you need near 100% compatibility with an existing on-prem deployment of SQL.\nThe question does not mention migration of a solution so managed instance is not the solution."
      }
    ],
    "examNameCode": "az-304",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 2,
    "url": "https://www.examtopics.com/discussions/microsoft/view/63381-exam-az-304-topic-3-question-2-discussion/",
    "body": "DRAG DROP -<br>You plan to import data from your on-premises environment into Azure. The data is shown in the following table.<br><img src=\"/assets/media/exam-media/04027/0013800001.png\" class=\"in-exam-image\"><br>What should you recommend using to migrate the data? To answer, drag the appropriate tools to the correct data sources. Each tool may be used once, more than once, or not at all. You may need to drag the split bar between panes or scroll to view content.<br>NOTE: Each correct selection is worth one point.<br>Select and Place:<br><img src=\"/assets/media/exam-media/04027/0013800002.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04027/0013900001.png\" class=\"in-exam-image\">",
    "answerDescription": "Reference:<br>https://docs.microsoft.com/en-us/azure/dms/tutorial-sql-server-to-azure-sql https://docs.microsoft.com/en-us/azure/cosmos-db/import-data",
    "votes": [],
    "comments": [
      {
        "date": "2021-10-19T02:38:00.000Z",
        "voteCount": 17,
        "content": "Given answers are correct\nchoose the same\ncleared with 900 on 17th October 2021"
      },
      {
        "date": "2022-03-09T22:33:00.000Z",
        "voteCount": 2,
        "content": "correct answer"
      },
      {
        "date": "2021-12-24T03:41:00.000Z",
        "voteCount": 4,
        "content": "On exam 24.12.2021"
      },
      {
        "date": "2021-11-21T12:38:00.000Z",
        "voteCount": 4,
        "content": "Given answers are correct\n\nThe Data Migration Assistant (DMA) migrates SQL sources to SQL destinations.\nhttps://docs.microsoft.com/en-us/sql/dma/dma-overview?view=sql-server-ver15#supported-source-and-target-versions\n\nAzure Cosmos DB Data Migration tool is to migrate different sources including SQL to Azure Cosmo DB\nYou can import from JSON files, CSV files, SQL, MongoDB, Azure Table storage, Amazon DynamoDB, and even Azure Cosmos DB SQL API collections. You migrate that data to collections and tables for use with Azure Cosmos DB.\nhttps://docs.microsoft.com/en-us/azure/cosmos-db/import-data"
      },
      {
        "date": "2021-10-08T10:41:00.000Z",
        "voteCount": 2,
        "content": "Given answers are correct."
      },
      {
        "date": "2021-10-07T04:21:00.000Z",
        "voteCount": 2,
        "content": "provided links support answer given"
      },
      {
        "date": "2021-10-07T03:37:00.000Z",
        "voteCount": 2,
        "content": "It's correct wihtout any further doubt"
      },
      {
        "date": "2021-10-06T14:07:00.000Z",
        "voteCount": 2,
        "content": "Answers are correct for both boxes."
      },
      {
        "date": "2021-09-30T17:05:00.000Z",
        "voteCount": 2,
        "content": "i think it might be correct\n\nrefer these\n1 : https://docs.microsoft.com/ko-kr/sql/dma/dma-overview?view=sql-server-ver15#supported-source-and-target-versions\n\n2 : https://docs.microsoft.com/ko-kr/azure/cosmos-db/import-data#import-from-sql-server"
      }
    ],
    "examNameCode": "az-304",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 3,
    "url": "https://www.examtopics.com/discussions/microsoft/view/30779-exam-az-304-topic-3-question-3-discussion/",
    "body": "You have an Azure virtual machine named VM1 that runs Windows Server 2019 and contains 500 GB of data files.<br>You are designing a solution that will use Azure Data Factory to transform the data files, and then load the files to Azure Data Lake Storage.<br>What should you deploy on VM1 to support the design?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tthe Azure Pipelines agent",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tthe Azure File Sync agent",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tthe On-premises data gateway",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tthe self-hosted integration runtime\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 3,
        "isMostVoted": true
      },
      {
        "answer": "A",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2020-11-19T10:20:00.000Z",
        "voteCount": 37,
        "content": "answer is correct:\nhttps://docs.microsoft.com/en-us/azure/data-factory/connector-file-system\n\n\"\nIf your data store is located inside an on-premises network, an Azure virtual network, or Amazon Virtual Private Cloud, you need to configure a self-hosted integration runtime to connect to it.\n\""
      },
      {
        "date": "2022-03-29T00:39:00.000Z",
        "voteCount": 1,
        "content": "Use the self-hosted integration runtime even if the data store is in the cloud on an Azure Infrastructure as a Service (IaaS) virtual machine."
      },
      {
        "date": "2020-09-07T04:56:00.000Z",
        "voteCount": 17,
        "content": "The integration runtime (IR) is the compute infrastructure that Azure Data Factory uses to provide data-integration capabilities across different network environments. For details about IR, see Integration runtime overview.\n\nA self-hosted integration runtime can run copy activities between a cloud data store and a data store in a private network. It also can dispatch transform activities against compute resources in an on-premises network or an Azure virtual network. The installation of a self-hosted integration runtime needs an on-premises machine or a virtual machine inside a private network.\n\nThis article describes how you can create and configure a self-hosted IR."
      },
      {
        "date": "2021-04-10T05:01:00.000Z",
        "voteCount": 19,
        "content": "Great example of cut and paste from the original answer"
      },
      {
        "date": "2021-09-06T15:50:00.000Z",
        "voteCount": 1,
        "content": "so what, summarize here"
      },
      {
        "date": "2021-05-20T15:13:00.000Z",
        "voteCount": 4,
        "content": "\ud83d\ude00 \ud83d\ude02 \ud83d\ude02\ud83d\ude02"
      },
      {
        "date": "2022-08-11T02:18:00.000Z",
        "voteCount": 1,
        "content": "Of all the 4 options that has to be the answer. Although it is not the only option"
      },
      {
        "date": "2022-06-08T05:38:00.000Z",
        "voteCount": 1,
        "content": "When you use the Azure Data Factory to move the data, the solution that you will need to install on the VM would be Self Hosted Integrated Runtime only. I have never seen anyone using any other solution on the VM with ADF"
      },
      {
        "date": "2022-04-09T04:26:00.000Z",
        "voteCount": 2,
        "content": "In AZ-305 exam, 9 april 22"
      },
      {
        "date": "2022-03-03T21:34:00.000Z",
        "voteCount": 1,
        "content": "D. the self-hosted integration runtime\n\nSimilar question in Az-303 Module 8 Review Questions:\nYour organization has an Azure VM named OEM_VM3 that runs on Windows Server 2019 and contains 1 TB of data files.\nYou are asked to design a solution using Azure Data Factory to transform the data files and then load them into Azure Data Lake Storage.\nWhat should you deploy on OEM_VM3 to support your design?\n\nCorrect answer (provided by MS): A self-hosted integration runtime. A self-hosted integration runtime can run copy activities between a cloud data store and a data store in a private network."
      },
      {
        "date": "2022-02-26T09:47:00.000Z",
        "voteCount": 1,
        "content": "SHIR is needed for connecting the on-prem data store"
      },
      {
        "date": "2022-02-11T05:31:00.000Z",
        "voteCount": 2,
        "content": "Answer: D"
      },
      {
        "date": "2022-02-10T11:42:00.000Z",
        "voteCount": 1,
        "content": "test wrong vote. \nAnswer: D"
      },
      {
        "date": "2021-12-23T03:34:00.000Z",
        "voteCount": 3,
        "content": "Appere on exam 23-dec-2021"
      },
      {
        "date": "2021-10-01T01:11:00.000Z",
        "voteCount": 9,
        "content": "Was in exam today 1-10-2021.  I passed with score 896.  I chose D"
      },
      {
        "date": "2021-09-28T22:58:00.000Z",
        "voteCount": 1,
        "content": "\"solution that will use Azure Data Factory to transform the data files\"\n\nThis is D for sure; self-hosted integration runtime"
      },
      {
        "date": "2021-07-20T19:31:00.000Z",
        "voteCount": 3,
        "content": "To me answer seems D.Self hosted IR because it is mentioned  in below link that \"Use the self-hosted integration runtime even if the data store is in the cloud on an Azure Infrastructure as a Service (IaaS) virtual machine.\" https://docs.microsoft.com/en-us/azure/data-factory/create-self-hosted-integration-runtime"
      },
      {
        "date": "2021-06-27T10:57:00.000Z",
        "voteCount": 3,
        "content": "After careful review of the question I have to agree with some comments regarding where this all takes place. In the question, there is absolutely no mention of on-prem. This seems to take place in Azure. If that is the case then \"the self-hosted integration runtime\" is not necessarily the answer. According to Microsoft \"A self-hosted integration runtime can run copy activities between a cloud data store and a data store in a private network. It also can dispatch transform activities against compute resources in an on-premises network or an Azure virtual network.\""
      },
      {
        "date": "2021-07-31T16:22:00.000Z",
        "voteCount": 2,
        "content": "You're absolutely correct, there is no mention of on-prem. Regardless, the other answers really don't fit at all."
      },
      {
        "date": "2021-08-13T23:13:00.000Z",
        "voteCount": 3,
        "content": "They can also be deployed onto Azure VMs:\n\nhttps://azure.microsoft.com/en-gb/resources/templates/vms-with-selfhost-integration-runtime/"
      },
      {
        "date": "2021-05-31T19:44:00.000Z",
        "voteCount": 2,
        "content": "Anyway I think that Azure File Sync should do the work. Since Azure Data Lake Storage is in the end a Storage account."
      },
      {
        "date": "2021-06-13T01:05:00.000Z",
        "voteCount": 4,
        "content": "I have worked with Azure Data Factory for a long time and given answer is correct."
      },
      {
        "date": "2021-03-24T09:57:00.000Z",
        "voteCount": 1,
        "content": "Correct. \nUse the self-hosted integration runtime even if the data store is in the cloud on an Azure Infrastructure as a Service (IaaS) virtual machine.\nhttps://docs.microsoft.com/en-us/azure/data-factory/create-self-hosted-integration-runtime"
      },
      {
        "date": "2021-03-01T20:13:00.000Z",
        "voteCount": 3,
        "content": "read the question again. it says both data and Data Lake are in Azure, so Azure pipeline is the answer not the self hosted IR."
      },
      {
        "date": "2021-03-15T18:56:00.000Z",
        "voteCount": 2,
        "content": "self host IR is for private network"
      },
      {
        "date": "2021-05-28T22:29:00.000Z",
        "voteCount": 1,
        "content": "The installation of a self-hosted integration runtime needs an on-premises machine or a virtual machine inside a private network."
      },
      {
        "date": "2021-05-26T06:19:00.000Z",
        "voteCount": 2,
        "content": "It is a virtual machine sitting in azure. A private network. \nA self-hosted integration runtime can run copy activities between a cloud data store and a data store in a private network. It also can dispatch transform activities against compute resources in an on-premises network or an Azure virtual network."
      }
    ],
    "examNameCode": "az-304",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 4,
    "url": "https://www.examtopics.com/discussions/microsoft/view/33705-exam-az-304-topic-3-question-4-discussion/",
    "body": "HOTSPOT -<br>Your company is designing a multi-tenant application that will use elastic pools and Azure SQL databases. The application will be used by 30 customers.<br>You need to design a storage solution for the application. The solution must meet the following requirements:<br>\u2711 Operational costs must be minimized.<br>\u2711 All customers must have their own database.<br>\u2711 The customer databases will be in one of the following three Azure regions: East US, North Europe, or South Africa North.<br>What is the minimum number of elastic pools and Azure SQL Database servers required? To answer, select the appropriate options in the answer area.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04027/0014100001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04027/0014200001.png\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: 3 -<br>The server, its pools &amp; databases must be in the same Azure region under the same subscription.<br><br>Box 2: 3 -<br>A server can have up to 5000 databases associated to it.<br>Reference:<br>https://vincentlauzon.com/2016/12/18/azure-sql-elastic-pool-overview/",
    "votes": [],
    "comments": [
      {
        "date": "2021-01-14T03:03:00.000Z",
        "voteCount": 37,
        "content": "If they mentioned,\nThe customer databases will be in the following three Azure regions; Then, that means it is ok to have the databases in all three regions.\n\nBUT,\nThey mentioned,\nThe customer databases will be in ONE OF THE following three Azure regions, which means all the databases must be in ONLY ONE region, and it can be East US, North Europe, or South Africa North.\n\nA server can have up to 5000 databases associated to it.\n\nSo the answer should be 1 Azure SQL database server and 1 Elastic pool."
      },
      {
        "date": "2022-12-25T20:59:00.000Z",
        "voteCount": 1,
        "content": "This is not a logic test, what if several customer dbs fall into different regions, then will 1 server and 1 pool still fit the purpose? I think it should be 3 servers, 3 pools."
      },
      {
        "date": "2021-10-08T01:07:00.000Z",
        "voteCount": 6,
        "content": "Customer DB will be in one of the 3 regions. So they should have that option which can only be achieved by having an elastic pool in each region. It is ok to have to have it all in one region, but that wouldn't meet the requirement ."
      },
      {
        "date": "2023-09-09T23:31:00.000Z",
        "voteCount": 1,
        "content": "It's not DB, it's DB's. So all three will be in any one region."
      },
      {
        "date": "2021-11-06T07:02:00.000Z",
        "voteCount": 19,
        "content": "I think what the question meant was \"the customer databases will be across three regions\". They're not testing grammar or logic."
      },
      {
        "date": "2022-03-26T04:42:00.000Z",
        "voteCount": 3,
        "content": "And how do you know what the question meant? Did you set it? If you interpret the question as is, then @RasiR is correct"
      },
      {
        "date": "2020-10-05T10:29:00.000Z",
        "voteCount": 28,
        "content": "Correct"
      },
      {
        "date": "2022-06-09T05:16:00.000Z",
        "voteCount": 3,
        "content": "The customers only need their on DB, not their own server. And the fact that the customer databases will be in ONE OF THE following three Azure regions, means it will be 1 &amp; 1."
      },
      {
        "date": "2022-04-05T01:07:00.000Z",
        "voteCount": 2,
        "content": "I mean the key here is the multi tenant application that is a cross region architecture for possible customers from different regions. So I suppose the mentioned 3 regions should contains the infrastructure.\n3/3"
      },
      {
        "date": "2022-04-01T18:29:00.000Z",
        "voteCount": 2,
        "content": "All the customer databases will be in one of the three regions or the database can spread across 3 regions? \n\nThe question is not clear. \n\nIf the database can spread across 3 regions then the answer is correct. If not, 1 DB server and 1 Elastic pool."
      },
      {
        "date": "2022-03-23T20:52:00.000Z",
        "voteCount": 1,
        "content": "Answer --&gt; 3, 3\nCustomer can belong to any of the 3 regions given. So, we need 3 DB servers at the very least.  One elastic pool per DB server, therefore 3 Elastic Pool."
      },
      {
        "date": "2022-02-23T09:47:00.000Z",
        "voteCount": 3,
        "content": "It's pretty obvious to me that \"a multi-tenant app with 30 customers\" might need 3 regions BECUASE those disparate customers could have varying legal requirements that require them store corporate data in a specific geography.    This scenario is much more likely than \"hey, let's spin a wheel and decide where our 1 central DB is...one of these 3 is good!\".   So back to the answer, I'd go with 3 and 3."
      },
      {
        "date": "2022-02-06T10:27:00.000Z",
        "voteCount": 1,
        "content": "One SQL server to hold one elastic pool in each of the 3 regions mentioned, so answer is 3 pools, 3 servers."
      },
      {
        "date": "2021-12-24T03:41:00.000Z",
        "voteCount": 4,
        "content": "On exam 24.12.2021"
      },
      {
        "date": "2021-12-09T17:37:00.000Z",
        "voteCount": 5,
        "content": "Elastic Pool can only stretch across a single region so it should be 3 3."
      },
      {
        "date": "2021-10-19T02:39:00.000Z",
        "voteCount": 14,
        "content": "i choose 3 &amp; 3\ncleared with 900 on 17th October 2021"
      },
      {
        "date": "2021-10-08T10:42:00.000Z",
        "voteCount": 1,
        "content": "Given answers are correct."
      },
      {
        "date": "2021-10-03T17:10:00.000Z",
        "voteCount": 3,
        "content": "If the customers can be in one of the three Azure Regions, this means that it will probably have customers in all regions, these are the regions where the customers will be, so you will need 3 elastic pools, one for each region and one sql server for each region."
      },
      {
        "date": "2022-01-29T01:50:00.000Z",
        "voteCount": 1,
        "content": "yeah, that's the key. Customers can be in one of the three azure regions, but you have 30 customers, and they are not saying that \"all customers are in the same region\", so you have to cover the three regions =&gt; 3 elastic pools with 3 servers"
      },
      {
        "date": "2021-10-01T01:12:00.000Z",
        "voteCount": 5,
        "content": "Was in exam today 1-10-2021.  I passed with score 896.  I chose 3 and 3"
      },
      {
        "date": "2020-11-30T02:26:00.000Z",
        "voteCount": 3,
        "content": "The customer databases will be in one of the following three Azure regions - this is ambiguous. Does it mean ALL databases must be in one region - or each customer database can be in one of 3 regions?  I think it must be the latter so 3/3. But there is doubt."
      },
      {
        "date": "2020-11-23T21:17:00.000Z",
        "voteCount": 2,
        "content": "how did we arrive at 3 for the number of DB servers? why not 1 since 5000 DBs can be hosted on a server? Moreover, the question said the databases would be hosted in ONE of the 3 regions mentioned."
      },
      {
        "date": "2020-11-26T11:07:00.000Z",
        "voteCount": 4,
        "content": "This is a bit of a trick question. My first thought was 3 databases and 3 elastic pools. Given that you will use 3 separate regions. But it could be that they actually mean that the databases should be in ONE of the three regions. I that case you need 1 db and elastic pool."
      },
      {
        "date": "2020-11-29T09:12:00.000Z",
        "voteCount": 3,
        "content": "\u2711 All customers must have their own database.\n\u2711 The customer databases will be in one of the following three Azure regions: East US, North Europe, or South Africa North.\nThis means that we'll have many dbs, part on region 1, part on region 2 and part on region 3. So we'll need 3 servers and 3 pools."
      },
      {
        "date": "2021-11-15T06:48:00.000Z",
        "voteCount": 2,
        "content": "Microsoft don't do trick questions. You were correct with 3 and 3."
      },
      {
        "date": "2020-11-20T03:33:00.000Z",
        "voteCount": 2,
        "content": "correct"
      }
    ],
    "examNameCode": "az-304",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 5,
    "url": "https://www.examtopics.com/discussions/microsoft/view/38657-exam-az-304-topic-3-question-5-discussion/",
    "body": "You are reviewing an Azure architecture as shown in the Architecture exhibit. (Click the Architecture tab.)<br><img src=\"/assets/media/exam-media/04027/0014300001.jpg\" class=\"in-exam-image\"><br>The estimated monthly costs for the architecture are shown in the Costs exhibit. (Click the Costs tab.)<br><img src=\"/assets/media/exam-media/04027/0014300002.png\" class=\"in-exam-image\"><br>The log files are generated by user activity to Apache web servers. The log files are in a consistent format. Approximately 1 GB of logs are generated per day.<br>Microsoft Power BI is used to display weekly reports of the user activity.<br>You need to recommend a solution to minimize costs while maintaining the functionality of the architecture.<br>What should you recommend?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tReplace Azure Synapse Analytics and Azure Analysis Services with SQL Server on an Azure virtual machine.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tReplace Azure Synapse Analytics with Azure SQL Database Hyperscale.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tReplace Azure Data Factory with CRON jobs that use AzCopy.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tReplace Azure Databricks with Azure Machine Learning."
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 4,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2020-12-12T05:50:00.000Z",
        "voteCount": 71,
        "content": "The question states that \"The log files are in a consistent format.\" So, no ETL is required. The files can be copied directly using the AzCopy command."
      },
      {
        "date": "2021-02-17T19:25:00.000Z",
        "voteCount": 22,
        "content": "The answer is C. In the real world, I'd be asking some hard questions about why ADF was costing so much with that traffic volume ..."
      },
      {
        "date": "2021-10-14T15:32:00.000Z",
        "voteCount": 2,
        "content": "I made a mistake once and kept ADF running for 2 days. The pipeline was pretty basic - to copy logs to SQL Database. The bill for those 2 days was over 100$."
      },
      {
        "date": "2023-09-09T23:52:00.000Z",
        "voteCount": 1,
        "content": "I left Dedicated SQL Pool running for 2 days and it costed 500$ \ud83e\udd72"
      },
      {
        "date": "2022-10-09T23:56:00.000Z",
        "voteCount": 1,
        "content": "Even though C is the right answer, its like recommending - don't use cloud."
      },
      {
        "date": "2022-08-20T11:05:00.000Z",
        "voteCount": 1,
        "content": "\"Replace Azure Data Factory with CRON jobs that use AzCopy.\"  but where are the Cron jobs using AzCopy running?"
      },
      {
        "date": "2023-09-09T23:55:00.000Z",
        "voteCount": 1,
        "content": "Majority Apache Servers on Linux, so CRON can be used."
      },
      {
        "date": "2022-08-11T02:36:00.000Z",
        "voteCount": 2,
        "content": "The fact that they are using ADF &amp; Synapse Analysis is a huge alert. They both pretty much do the same in most case. A good place to start to look. And if you are just copying log files to ADL, of course Azure Data Factory with CRON jobs has to be the answer"
      },
      {
        "date": "2022-03-14T22:30:00.000Z",
        "voteCount": 1,
        "content": "Answer is c"
      },
      {
        "date": "2022-03-09T22:40:00.000Z",
        "voteCount": 1,
        "content": "AZCopy"
      },
      {
        "date": "2021-12-28T09:15:00.000Z",
        "voteCount": 1,
        "content": "If not ADF which service is going to be used to orchestrate this data pipeline ?"
      },
      {
        "date": "2021-12-23T03:35:00.000Z",
        "voteCount": 3,
        "content": "Appere on exam 23-dec-2021"
      },
      {
        "date": "2021-10-03T17:14:00.000Z",
        "voteCount": 4,
        "content": "I'd take C for 2 reasons\n\n1) Data Factory is the most expensive service used so it should be replaced\n2) Log files in consistent format so just use AzCopy will do"
      },
      {
        "date": "2021-10-01T01:13:00.000Z",
        "voteCount": 3,
        "content": "Was in exam today 1-10-2021.  I passed with score 896.  I chose C"
      },
      {
        "date": "2021-09-09T05:10:00.000Z",
        "voteCount": 2,
        "content": "Correct. Also appears in the practice questions for AZ304"
      },
      {
        "date": "2021-08-29T23:02:00.000Z",
        "voteCount": 1,
        "content": "Correct"
      },
      {
        "date": "2021-08-24T02:34:00.000Z",
        "voteCount": 1,
        "content": "Have used a similar arch in one of our use case. ADF doesn't cost this much, anyways, with this bill probably the given ans is correct."
      },
      {
        "date": "2021-08-18T19:34:00.000Z",
        "voteCount": 3,
        "content": "Since, ADF is being used for trivial task of just copying the log files already in consistent format. Hence, it need to go to save the cost."
      },
      {
        "date": "2021-07-01T21:15:00.000Z",
        "voteCount": 4,
        "content": "if we notice in the diagram Azure Data Factory is where the most money is spent, and the solution is to minimize costs hence we need to look for a solution that deals with data factory and makes sense so I would say C is the right answer."
      },
      {
        "date": "2021-02-25T18:46:00.000Z",
        "voteCount": 2,
        "content": "https://medium.com/@nimishrao/moving-a-file-in-seconds-to-your-azure-data-lake-generation-2-using-azcopy-6dde114258"
      }
    ],
    "examNameCode": "az-304",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 6,
    "url": "https://www.examtopics.com/discussions/microsoft/view/39772-exam-az-304-topic-3-question-6-discussion/",
    "body": "You deploy Azure App Service Web Apps that connect to on-premises Microsoft SQL Server instances by using Azure ExpressRoute. You plan to migrate the<br>SQL Server instances to Azure.<br>Migration of the SQL Server instances to Azure must:<br>\u2711 Support automatic patching and version updates to SQL Server.<br>\u2711 Provide automatic backup services.<br>\u2711 Allow for high-availability of the instances.<br>\u2711 Provide a native VNET with private IP addressing.<br>\u2711 Encrypt all data in transit.<br>\u2711 Be in a single-tenant environment with dedicated underlying infrastructure (compute, storage).<br>You need to migrate the SQL Server instances to Azure.<br>Which Azure service should you use?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSQL Server in a Docker container running on Azure Container Instances (ACI)",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSQL Server in Docker containers running on Azure Kubernetes Service (AKS)",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSQL Server Infrastructure-as-a-Service (IaaS) virtual machine (VM)",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure SQL Database Managed Instance\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure SQL Database with elastic pools"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 3,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2020-12-13T08:34:00.000Z",
        "voteCount": 46,
        "content": "Correct answer"
      },
      {
        "date": "2021-05-08T08:36:00.000Z",
        "voteCount": 1,
        "content": "No, it should be E. SQLMI doesn't support private IP address"
      },
      {
        "date": "2021-07-28T04:01:00.000Z",
        "voteCount": 9,
        "content": "wrong: \"SQL Managed Instance has private IP addresses in its own virtual network\", ref\nhttps://docs.microsoft.com/en-us/azure/azure-sql/managed-instance/connect-application-instance#connect-inside-a-different-vnet"
      },
      {
        "date": "2021-09-22T15:56:00.000Z",
        "voteCount": 9,
        "content": "At a high level, SQL Managed Instance is a set of service components. These components are hosted on a dedicated set of isolated virtual machines that run inside the customer's virtual network subnet. These machines form a virtual cluster.\n\nhttps://docs.microsoft.com/en-us/azure/azure-sql/managed-instance/connectivity-architecture-overview"
      },
      {
        "date": "2021-06-13T19:52:00.000Z",
        "voteCount": 14,
        "content": "the given answer is correct. Cannot have Azure SQL because it does not support VNET integration. SQL MI supports it."
      },
      {
        "date": "2022-02-02T09:44:00.000Z",
        "voteCount": 1,
        "content": "Azure SQL Database can leverage private endpoint to support VNET integration\nhttps://docs.microsoft.com/en-us/azure/virtual-network/vnet-integration-for-azure-services#private-link-and-private-endpoints"
      },
      {
        "date": "2022-02-18T05:33:00.000Z",
        "voteCount": 1,
        "content": "Correct answer"
      },
      {
        "date": "2022-02-06T06:06:00.000Z",
        "voteCount": 1,
        "content": "The correct answer is D as one of the features related to Azure SQL Managed Instance is native Vnet integration - a native virtual network (VNet) implementation that addresses common security concerns\n\nhttps://docs.microsoft.com/en-us/azure/azure-sql/managed-instance/sql-managed-instance-paas-overview"
      },
      {
        "date": "2022-01-28T14:14:00.000Z",
        "voteCount": 1,
        "content": "E - Azure SQL Database with elastic pools would be correct as well since it can have a private endpoint in the VNET"
      },
      {
        "date": "2022-05-18T09:18:00.000Z",
        "voteCount": 1,
        "content": "But its not native VNET Integration as with Azure SQL Managed Instance"
      },
      {
        "date": "2021-12-22T05:19:00.000Z",
        "voteCount": 2,
        "content": "Correct answer"
      },
      {
        "date": "2021-09-29T06:25:00.000Z",
        "voteCount": 5,
        "content": "\"Support automatic patching and version updates\"\n\nAnswer is D for sure"
      },
      {
        "date": "2021-09-18T15:39:00.000Z",
        "voteCount": 1,
        "content": "I think it's a trick question. I have been studying for the exam and I don't remember reading from Azure SQL Database MI, but I have read from Azure SQL MI, and only the above three options (A, B and C) indicate SQL Server, and the question is about the options for migrate SQL Server instances. The most reasonable option (following the observation if it is DB or Server) is C (IaaS), but this does not support automatic updates and patches. I'll see if this question will be in my close exam."
      },
      {
        "date": "2021-09-02T05:19:00.000Z",
        "voteCount": 1,
        "content": "C.  SQL Server Infrastructure-as-a-Service (IaaS) virtual machine (VM)\n\nRequirement - Provide a native VNET with private IP addressing.\nThis cannot be achieved on Azure SQL. With VNET integration you can restrict only the services within that VNET can reach DB, but still they have to reach the public endpoint of the DB (xx.database.windows.net) and not to a private IP."
      },
      {
        "date": "2021-12-28T09:02:00.000Z",
        "voteCount": 1,
        "content": "This doesnt support automatic patching and version updates to SQL Server though does it?"
      },
      {
        "date": "2022-01-17T13:29:00.000Z",
        "voteCount": 2,
        "content": "Azure supports automated backup and automated patching for an Azure VM with SQL Server installed. It must be either SQL Server 2014 or 2016+, and with the SQL IaaS Agent extension in full management mode. A pair of VMs with AGs can support the multiple SQL instances required. Not strictly mentioned in the question, but reasonable implication is existing on-premises SQL licensing. With Software Assurance in a migration scenario both on-premises and cloud VMs are covered for 180 days. An Azure VM as the SQL AG failover server would not require a license if used purely for business continuity. Using SQL on an Azure VM with multiple instances could be the best solution.\nhttps://docs.microsoft.com/en-us/azure/azure-sql/virtual-machines/windows/automated-backup\nhttps://docs.microsoft.com/en-us/azure/azure-sql/virtual-machines/windows/automated-patching\nhttps://docs.microsoft.com/en-us/azure/azure-sql/virtual-machines/windows/sql-server-iaas-agent-extension-automate-management\nI think my answer will be C."
      },
      {
        "date": "2021-08-14T22:17:00.000Z",
        "voteCount": 2,
        "content": "D is the correct answer.\n\nEverything is in this section https://docs.microsoft.com/en-us/azure/azure-sql/managed-instance/sql-managed-instance-paas-overview#key-features-and-capabilities"
      },
      {
        "date": "2021-07-16T17:32:00.000Z",
        "voteCount": 2,
        "content": "Answer is D , refer the link and check in that 'Key features and capabilities\" , all the requirements are meet. \nhttps://docs.microsoft.com/en-us/azure/azure-sql/managed-instance/sql-managed-instance-paas-overview"
      },
      {
        "date": "2021-05-13T08:03:00.000Z",
        "voteCount": 4,
        "content": "Managed Instance(Be in a single-tenant environment with dedicated underlying infrastructure (compute, storage))\n\nread \n\nhttps://docs.microsoft.com/en-us/azure/azure-sql/managed-instance/sql-managed-instance-paas-overview"
      },
      {
        "date": "2021-12-16T10:46:00.000Z",
        "voteCount": 1,
        "content": "1. Single-tenant with dedicated underlying infrastructure (compute, storage).  2. Automatic patch"
      },
      {
        "date": "2021-05-24T03:27:00.000Z",
        "voteCount": 2,
        "content": "Exactly, on that link you mention it appears as capabilities this:\nIsolated environment (VNet integration, single tenant service, dedicated compute and storage)\n\nSo the right answer is Managed Instance."
      },
      {
        "date": "2021-05-08T08:35:00.000Z",
        "voteCount": 1,
        "content": "it should be E."
      },
      {
        "date": "2021-04-12T17:11:00.000Z",
        "voteCount": 4,
        "content": "You guys seem to have missed the most important part of the question \" Be in a single-tenant environment with dedicated underlying infrastructure (compute, storage)\"  Managed instances runs on shared infrastructure. Only IAAS can allow you to choose reserved instances"
      },
      {
        "date": "2021-04-19T01:03:00.000Z",
        "voteCount": 7,
        "content": "read better\n\nhttps://docs.microsoft.com/en-us/azure/azure-sql/managed-instance/sql-managed-instance-paas-overview\n\nKey features and capabilities"
      },
      {
        "date": "2021-05-26T06:30:00.000Z",
        "voteCount": 2,
        "content": "reserved instances doesn't equate to dedicated or isolated"
      },
      {
        "date": "2021-02-27T16:14:00.000Z",
        "voteCount": 3,
        "content": "why isn't \"E. Azure SQL Database with elastic pools\" a valid option then?"
      },
      {
        "date": "2021-03-26T06:48:00.000Z",
        "voteCount": 2,
        "content": "because of \"native Vnet with private addressing\".\nSQL Managed Instance can be injected in customer's VNet. \nhttps://docs.microsoft.com/en-us/azure/azure-sql/database/features-comparison"
      },
      {
        "date": "2021-01-25T08:05:00.000Z",
        "voteCount": 3,
        "content": "D. Azure SQL Database Managed Instance"
      },
      {
        "date": "2021-01-23T05:43:00.000Z",
        "voteCount": 3,
        "content": "Right ans."
      }
    ],
    "examNameCode": "az-304",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 7,
    "url": "https://www.examtopics.com/discussions/microsoft/view/39154-exam-az-304-topic-3-question-7-discussion/",
    "body": "You plan to store data in Azure Blob storage for many years. The stored data will be accessed rarely.<br>You need to ensure that the data in Blob storage is always available for immediate access. The solution must minimize storage costs.<br>Which storage tier should you use?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCool\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tArchive",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tHot"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 5,
        "isMostVoted": true
      },
      {
        "answer": "B",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2020-12-07T14:24:00.000Z",
        "voteCount": 42,
        "content": "Cool tier is correct answer.. hot tier will be costlier and accessing data from archive tier takes time."
      },
      {
        "date": "2021-02-16T12:59:00.000Z",
        "voteCount": 21,
        "content": "Coolio"
      },
      {
        "date": "2021-02-28T12:39:00.000Z",
        "voteCount": 10,
        "content": "I'll see you when you get there..."
      },
      {
        "date": "2022-02-12T03:26:00.000Z",
        "voteCount": 6,
        "content": "As I walk through the valley of the shadow of death\nI take a look at my life, and realize there's nothin' left"
      },
      {
        "date": "2022-03-29T11:12:00.000Z",
        "voteCount": 1,
        "content": "archive is not immediately accessible, so it's cool"
      },
      {
        "date": "2022-03-28T20:33:00.000Z",
        "voteCount": 1,
        "content": "A is correct"
      },
      {
        "date": "2022-03-25T15:49:00.000Z",
        "voteCount": 1,
        "content": "Both Cool and Hot are online so for sure Cool."
      },
      {
        "date": "2022-03-14T22:32:00.000Z",
        "voteCount": 2,
        "content": "Sorry, I will go with A. Cool."
      },
      {
        "date": "2022-03-14T22:31:00.000Z",
        "voteCount": 1,
        "content": "I will go with B"
      },
      {
        "date": "2022-03-14T22:32:00.000Z",
        "voteCount": 2,
        "content": "Forget this. My mistake."
      },
      {
        "date": "2022-02-15T07:36:00.000Z",
        "voteCount": 1,
        "content": "A is correct."
      },
      {
        "date": "2021-12-29T19:36:00.000Z",
        "voteCount": 1,
        "content": "Cool ----&gt; correct answerr"
      },
      {
        "date": "2021-10-05T05:46:00.000Z",
        "voteCount": 4,
        "content": "\"always available for immediate access\" yet \"minimize storage costs\"\n\nAnswer is A"
      },
      {
        "date": "2021-09-20T04:21:00.000Z",
        "voteCount": 3,
        "content": "came in exam on 20-sep-21, I passed, i choose given answer"
      },
      {
        "date": "2021-09-07T11:02:00.000Z",
        "voteCount": 1,
        "content": "Hot because the data in Blob storage is always available for immediate access"
      },
      {
        "date": "2021-09-24T12:00:00.000Z",
        "voteCount": 1,
        "content": "In cool tier you also have immediate access, just little bit slower than in hot tier. In archive tier you don't have an access and you need request it first."
      },
      {
        "date": "2021-10-03T04:40:00.000Z",
        "voteCount": 1,
        "content": "Read the question carefully . It was mentioned that files will be accessed RARELY . So COOL is the correct answer"
      },
      {
        "date": "2021-07-27T11:24:00.000Z",
        "voteCount": 3,
        "content": "was in exam today, answer is correct"
      },
      {
        "date": "2021-06-06T04:29:00.000Z",
        "voteCount": 4,
        "content": "Wow, a fundamentals question!"
      },
      {
        "date": "2021-01-25T08:07:00.000Z",
        "voteCount": 3,
        "content": "A. Cool"
      }
    ],
    "examNameCode": "az-304",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 8,
    "url": "https://www.examtopics.com/discussions/microsoft/view/38186-exam-az-304-topic-3-question-8-discussion/",
    "body": "DRAG DROP -<br>You are designing a virtual machine that will run Microsoft SQL Server and will contain two data disks. The first data disk will store log files, and the second data disk will store data. Both disks are P40 managed disks.<br>You need to recommend a caching policy for each disk. The policy must provide the best overall performance for the virtual machine while preserving integrity of the SQL data and logs.<br>Which caching policy should you recommend for each disk? To answer, drag the appropriate policies to the correct disks. Each policy may be used once, more than once, or not at all. You may need to drag the split bar between panes or scroll to view content.<br>Select and Place:<br><img src=\"/assets/media/exam-media/04027/0014600001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04027/0014700001.png\" class=\"in-exam-image\">",
    "answerDescription": "Reference:<br>https://docs.microsoft.com/en-us/azure/virtual-machines/windows/sql/virtual-machines-windows-sql-performance",
    "votes": [],
    "comments": [
      {
        "date": "2020-11-30T20:26:00.000Z",
        "voteCount": 96,
        "content": "The answers provided are correct, here is the explanation and supporting websites:\nLog: None\u2014Log files have primarily write-heavy operations. Therefore, they do not benefit from the ReadOnly cache.\nhttps://docs.microsoft.com/en-us/azure/virtual-machines/windows/premium-storage-performance#disk-caching\n\nData: readonly\u2014If you have separate storage pools for the log and data files, enable read caching only on the storage pool for the data files.\nhttps://docs.microsoft.com/en-us/azure/azure-sql/virtual-machines/windows/performance-guidelines-best-practices"
      },
      {
        "date": "2021-09-29T04:21:00.000Z",
        "voteCount": 4,
        "content": "Good find there!"
      },
      {
        "date": "2022-08-11T02:59:00.000Z",
        "voteCount": 1,
        "content": "Thank you"
      },
      {
        "date": "2021-01-25T08:20:00.000Z",
        "voteCount": 7,
        "content": "Log: None\u2014\nData: readonly\u2014"
      },
      {
        "date": "2022-03-23T21:51:00.000Z",
        "voteCount": 2,
        "content": "Set host caching to read-only for data file disks.\nSet host caching to none for log file disks."
      },
      {
        "date": "2021-12-22T10:26:00.000Z",
        "voteCount": 1,
        "content": "https://docs.microsoft.com/en-us/azure/azure-sql/virtual-machines/windows/performance-guidelines-best-practices-storage\n\nCorrect"
      },
      {
        "date": "2021-02-08T11:03:00.000Z",
        "voteCount": 4,
        "content": "correct."
      },
      {
        "date": "2020-12-26T16:13:00.000Z",
        "voteCount": 4,
        "content": "correct\n- Use premium SSDs for the best price/performance advantages. Configure Read only cache for data files and no cache for the log file."
      },
      {
        "date": "2020-12-06T20:43:00.000Z",
        "voteCount": 3,
        "content": "Following are the recommended disk cache settings for data disks,\n\nTABLE 9\nDisk caching setting\trecommendation on when to use this setting\nNone\tConfigure host-cache as None for write-only and write-heavy disks.\nReadOnly\tConfigure host-cache as ReadOnly for read-only and read-write disks.\nReadWrite\tConfigure host-cache as ReadWrite only if your application properly handles writing cached data to persistent disks when needed.\n\nhttps://docs.microsoft.com/en-us/azure/virtual-machines/premium-storage-performance#disk-caching"
      },
      {
        "date": "2020-12-04T07:41:00.000Z",
        "voteCount": 3,
        "content": "Correct\nhttps://docs.microsoft.com/en-us/azure/azure-sql/virtual-machines/windows/performance-guidelines-best-practices#disks-guidance\n\nIf you are using separate disks for data and log files, enable read caching on the data disks hosting your data files and TempDB data files. This can result in a significant performance benefit. Do not enable caching on the disk holding the log file as this causes a minor decrease in performance."
      },
      {
        "date": "2022-01-17T13:36:00.000Z",
        "voteCount": 2,
        "content": "Indeed \nhttps://docs.microsoft.com/en-us/azure/azure-sql/virtual-machines/windows/performance-guidelines-best-practices-storage#data-file-caching-policies\nata disk\tEnable Read-only caching for the disks hosting SQL Server data files.\nReads from cache will be faster than the uncached reads from the data disk.\nUncached IOPS and throughput plus Cached IOPS and throughput will yield the total possible performance available from the virtual machine within the VMs limits, but actual performance will vary based on the workload's ability to use the cache (cache hit ratio).\nTransaction log disk\tSet the caching policy to None for disks hosting the transaction log. There is no performance benefit to enabling caching for the Transaction log disk, and in fact having either Read-only or Read/Write caching enabled on the log drive can degrade performance of the writes against the drive and decrease the amount of cache available for reads on the data drive."
      }
    ],
    "examNameCode": "az-304",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 9,
    "url": "https://www.examtopics.com/discussions/microsoft/view/38810-exam-az-304-topic-3-question-9-discussion/",
    "body": "You are designing a SQL database solution. The solution will include 20 databases that will be 20 GB each and have varying usage patterns.<br>You need to recommend a database platform to host the databases. The solution must meet the following requirements:<br>\u2711 The compute resources allocated to the databases must scale dynamically.<br>\u2711 The solution must meet an SLA of 99.99% uptime.<br>\u2711 The solution must have reserved capacity.<br>\u2711 Compute charges must be minimized.<br>What should you include in the recommendation?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t20 databases on a Microsoft SQL server that runs on an Azure virtual machine in an availability set",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t20 instances of Azure SQL Database serverless",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t20 databases on a Microsoft SQL server that runs on an Azure virtual machine",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tan elastic pool that contains 20 Azure SQL databases\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 7,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2020-12-04T07:42:00.000Z",
        "voteCount": 35,
        "content": "Correct"
      },
      {
        "date": "2021-10-04T04:17:00.000Z",
        "voteCount": 7,
        "content": "Answer is D\n\nhttps://docs.microsoft.com/en-us/azure/azure-sql/database/elastic-pool-overview\n\nAzure SQL Database elastic pools are a simple, cost-effective solution for managing and scaling multiple databases that have varying and unpredictable usage demands. The databases in an elastic pool are on a single server and share a set number of resources at a set price. Elastic pools in Azure SQL Database enable SaaS developers to optimize the price performance for a group of databases within a prescribed budget while delivering performance elasticity for each database."
      },
      {
        "date": "2022-05-31T07:54:00.000Z",
        "voteCount": 1,
        "content": "Correct answer is D"
      },
      {
        "date": "2022-03-14T22:34:00.000Z",
        "voteCount": 1,
        "content": "D is correct"
      },
      {
        "date": "2022-02-12T03:57:00.000Z",
        "voteCount": 1,
        "content": "D for the win"
      },
      {
        "date": "2022-01-13T16:33:00.000Z",
        "voteCount": 1,
        "content": "D. is the correct answer."
      },
      {
        "date": "2021-12-23T05:23:00.000Z",
        "voteCount": 4,
        "content": "Correct answer"
      },
      {
        "date": "2021-11-16T06:31:00.000Z",
        "voteCount": 2,
        "content": "For me, due:\nhttps://docs.microsoft.com/en-us/azure/azure-sql/database/serverless-tier-overview#scenarios-well-suited-for-serverless-compute\nand\nhttps://docs.microsoft.com/en-us/azure/azure-sql/database/serverless-tier-overview#scenarios-well-suited-for-provisioned-compute\nanswer is D"
      },
      {
        "date": "2021-10-29T20:28:00.000Z",
        "voteCount": 2,
        "content": "D\n---\nI think Elastic Pools with reserved capacity will be cheaper than server less."
      },
      {
        "date": "2021-09-20T04:22:00.000Z",
        "voteCount": 2,
        "content": "came in exam on 20-sep-21, I passed, i choose A"
      },
      {
        "date": "2021-09-23T09:43:00.000Z",
        "voteCount": 7,
        "content": "\u201cA\u201d cant be correct. AVSets dont have 99.99% SLA"
      },
      {
        "date": "2021-10-04T23:12:00.000Z",
        "voteCount": 3,
        "content": "That's correct. AVSet is 99.95% while AVZone is 99.99%.\nhttps://www.azure.cn/en-us/support/sla/virtual-machines/"
      },
      {
        "date": "2021-05-09T05:44:00.000Z",
        "voteCount": 2,
        "content": "Azure SQL databases can also do Reserved Capacity https://docs.microsoft.com/en-us/azure/azure-sql/database/reserved-capacity-overview"
      },
      {
        "date": "2021-04-10T09:11:00.000Z",
        "voteCount": 2,
        "content": "Curious, why not B?"
      },
      {
        "date": "2021-04-18T19:25:00.000Z",
        "voteCount": 8,
        "content": "key is: databases that will be 20 GB each and have varying usage patterns. hence elastic pools"
      },
      {
        "date": "2021-06-06T22:40:00.000Z",
        "voteCount": 1,
        "content": "so what? why won't serverless fulfill these two requirements?"
      },
      {
        "date": "2021-08-30T22:25:00.000Z",
        "voteCount": 1,
        "content": "It says 99.99% uptime required. Surely serverless is not suitable because of the warmup time as HDZ78 already mentioned?\n\nhttps://docs.microsoft.com/en-us/azure/azure-sql/database/serverless-tier-overview#scenarios\n\nServerless is price-performance optimized for single databases with intermittent, unpredictable usage patterns that can afford some delay in compute warm-up after idle usage periods. In contrast, the provisioned compute tier is price-performance optimized for single databases or multiple databases in elastic pools with higher average usage that cannot afford any delay in compute warm-up"
      },
      {
        "date": "2021-06-06T22:41:00.000Z",
        "voteCount": 7,
        "content": "rather, the reason can't be serverless is due to reserved capacity which is not supported in server tier"
      },
      {
        "date": "2021-06-16T05:31:00.000Z",
        "voteCount": 3,
        "content": "That is right, B is out of question because it does not allow reserved capacity.\n\"Azure Hybrid Benefit (AHB) and reserved capacity discounts do not apply to the serverless compute tier.\"\n\nREF: https://docs.microsoft.com/en-us/azure/azure-sql/database/serverless-tier-overview#billing"
      },
      {
        "date": "2021-06-26T20:33:00.000Z",
        "voteCount": 2,
        "content": "This think people are not understanding reserved capacity.  This is about pre-committing database servers. Essentially paying ahead. Azure SQL Services for Managed instances and Azure SQL Database can both be have it. I agree with Moota.  With elastic pools you are sharing resources. \n\n https://docs.microsoft.com/en-us/azure/azure-sql/database/reserved-capacity-overview\nI think the answer is B."
      },
      {
        "date": "2021-07-04T04:51:00.000Z",
        "voteCount": 1,
        "content": "It depends on how you interpret reserved capacity. The GA blogpost way back clearly states that warm-up times after a period of inactivity are the trade off for serverless: https://techcommunity.microsoft.com/t5/azure-sql/optimize-price-performance-with-compute-auto-scaling-in-azure/ba-p/966149\n\nTo me that would make it D."
      },
      {
        "date": "2021-03-28T00:34:00.000Z",
        "voteCount": 2,
        "content": "D is Correct"
      },
      {
        "date": "2021-02-28T06:00:00.000Z",
        "voteCount": 3,
        "content": "HMMMM i read \" The compute resources allocated to the databases must scale dynamically.\" to mean that it must autoscale and therefore went for B as that is the only option that autoscales, question is do they mean autoscale when they say \"scale dynamically\"?"
      },
      {
        "date": "2021-04-18T01:16:00.000Z",
        "voteCount": 1,
        "content": "I would understand scale dynamically is equivalent to autoscale, otherwise we can Azure VM without autoscale included is also scale dynamically."
      },
      {
        "date": "2021-04-18T02:07:00.000Z",
        "voteCount": 2,
        "content": "Sorry, above is incorrect after I found below statement in MS website. \n\nDynamic scalability is different from autoscale. Autoscale is when a service scales automatically based on criteria, whereas dynamic scalability allows for manual scaling with a minimal downtime.\n\nSo the correct answer is B"
      },
      {
        "date": "2021-04-25T20:13:00.000Z",
        "voteCount": 1,
        "content": "Hello Leon, Was the article from where you fetched this Dynamic vs Auto scale in context to Azure SQL?\nBoth B and D sounds correct but in terms of terminologies, it cold be a different service"
      },
      {
        "date": "2021-01-25T08:24:00.000Z",
        "voteCount": 3,
        "content": "D. an elastic pool that contains 20 Azure SQL databases"
      },
      {
        "date": "2021-01-01T08:49:00.000Z",
        "voteCount": 2,
        "content": "99.95%.?? Requirement is to have 99.99%.. Is this a typo.."
      },
      {
        "date": "2021-01-04T11:51:00.000Z",
        "voteCount": 2,
        "content": "Not a typo.  The article linked and the explanation say 99.995%, which is even greater that 99.99% (which is 99.990%), so it's all correct."
      },
      {
        "date": "2021-01-03T02:06:00.000Z",
        "voteCount": 4,
        "content": "- Azure SQL Database Business Critical or Premium tiers configured as Zone Redundant Deployments have an availability guarantee of at least 99.995%.\n\n- Azure SQL Database Business Critical or Premium tiers not configured for Zone Redundant Deployments, General Purpose, Standard, or Basic tiers, or Hyperscale tier with two or more replicas have an availability guarantee of at least 99.99%.\n\nhttps://azure.microsoft.com/en-us/support/legal/sla/sql-database/v1_5/"
      }
    ],
    "examNameCode": "az-304",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 10,
    "url": "https://www.examtopics.com/discussions/microsoft/view/38811-exam-az-304-topic-3-question-10-discussion/",
    "body": "You have an app named App1 that uses two on-premises Microsoft SQL Server databases named DB1 and DB2.<br>You plan to migrate DB1 and DB2 to Azure.<br>You need to recommend an Azure solution to host DB1 and DB2. The solution must meet the following requirements:<br>\u2711 Support server-side transactions across DB1 and DB2.<br>\u2711 Minimize administrative effort to update the solution.<br>What should you recommend?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ttwo Azure SQL databases in an elastic pool",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ttwo Azure SQL databases on different Azure SQL Database servers",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ttwo Azure SQL databases on the same Azure SQL Database managed instance\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ttwo SQL Server databases on an Azure virtual machine"
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 3,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2020-12-04T07:45:00.000Z",
        "voteCount": 43,
        "content": "Correct\nhttps://docs.microsoft.com/en-us/azure/azure-sql/managed-instance/sql-managed-instance-paas-overview#azure-active-directory-integration"
      },
      {
        "date": "2021-05-31T08:00:00.000Z",
        "voteCount": 25,
        "content": "https://www.examtopics.com/exams/microsoft/az-303/view/2/\nYou need to implement Azure services to host DB1 and DB2. The solution must support server-side transactions across DB1 and DB2.\nSolution: You deploy DB1 and DB2 to SQL Server on an Azure virtual machine.\nReference: https://docs.particular.net/nservicebus/azure/understanding-transactionality-in-azure"
      },
      {
        "date": "2022-01-14T08:59:00.000Z",
        "voteCount": 2,
        "content": "https://docs.microsoft.com/en-us/azure/azure-sql/database/elastic-transactions-overview\nIn Important block:\nDistributed transactions for Azure SQL Managed Instance are now generally available. \n\nI believe correct answer is: C"
      },
      {
        "date": "2021-12-28T09:24:00.000Z",
        "voteCount": 7,
        "content": "Wrong, this doesnt minimize administrative effort compared with Managed Instance"
      },
      {
        "date": "2022-06-04T07:49:00.000Z",
        "voteCount": 1,
        "content": "Nonsense.\n\nhttps://docs.microsoft.com/en-us/azure/azure-sql/managed-instance/sql-managed-instance-paas-overview?view=azuresql#azure-active-directory-integration\n. Azure AD server principals (logins) enable you to specify users and groups from your Azure AD tenant as true instance-scoped principals, capable of performing any instance-level operation, including cross-database queries within the same managed instance."
      },
      {
        "date": "2022-04-09T04:27:00.000Z",
        "voteCount": 1,
        "content": "In AZ-305 exam, 9 april 22"
      },
      {
        "date": "2022-03-14T22:35:00.000Z",
        "voteCount": 1,
        "content": "I think C is correct"
      },
      {
        "date": "2022-01-03T07:49:00.000Z",
        "voteCount": 2,
        "content": "Distributed transactions for Azure SQL Managed Instance are now generally available. Elastic Database Transactions for Azure SQL Database are in preview.  https://docs.microsoft.com/en-us/azure/azure-sql/database/elastic-transactions-overview"
      },
      {
        "date": "2021-12-16T00:59:00.000Z",
        "voteCount": 3,
        "content": "This is C\nDistributed transactions for Azure SQL Managed Instance are now generally available. Dec 2021\nhttps://docs.microsoft.com/en-us/azure/azure-sql/database/elastic-transactions-overview#transact-sql-development-experience"
      },
      {
        "date": "2021-11-16T11:58:00.000Z",
        "voteCount": 2,
        "content": "According to this: https://docs.microsoft.com/en-us/azure/azure-sql/database/elastic-transactions-overview#transactions-for-sql-managed-instance for me Answer is C"
      },
      {
        "date": "2021-10-04T04:20:00.000Z",
        "voteCount": 6,
        "content": "\"Minimize administrative effort to update \"\n\nThis is C; Managed Instance"
      },
      {
        "date": "2021-10-03T08:52:00.000Z",
        "voteCount": 2,
        "content": "Depends. If we assume Preview answers are allowed, then C, if not then D."
      },
      {
        "date": "2021-09-20T04:22:00.000Z",
        "voteCount": 3,
        "content": "came in exam on 20-sep-21, I passed, i choose C"
      },
      {
        "date": "2021-09-19T13:54:00.000Z",
        "voteCount": 1,
        "content": "Answer is D....as other options are still under Preview."
      },
      {
        "date": "2021-08-14T22:20:00.000Z",
        "voteCount": 5,
        "content": "Managed instance already supported server-side tractions https://docs.microsoft.com/en-us/azure/azure-sql/database/elastic-transactions-overview#transact-sql-development-experience"
      },
      {
        "date": "2021-08-01T08:49:00.000Z",
        "voteCount": 8,
        "content": "Both C and D support server-side transactions but C has a less administrative effort"
      },
      {
        "date": "2021-05-14T06:53:00.000Z",
        "voteCount": 1,
        "content": "Actually this should be a series of questions ... multiple answers are correct. \nSee https://docs.microsoft.com/en-us/azure/azure-sql/database/elastic-transactions-overview"
      },
      {
        "date": "2021-05-11T20:40:00.000Z",
        "voteCount": 4,
        "content": "Answer is D"
      },
      {
        "date": "2021-05-13T11:16:00.000Z",
        "voteCount": 12,
        "content": "Why you confuse others? \n\nMinimize administrative effort to update the solution. --&gt; You use an Azure virtual machine for minimize administrative effort??\n\nThe right ans is C"
      },
      {
        "date": "2021-05-09T10:17:00.000Z",
        "voteCount": 14,
        "content": "Answer is C: Managed Instances\n\nhttps://docs.microsoft.com/en-us/azure/azure-sql/database/elastic-transactions-overview\nTransact-SQL development experience\n\"A server-side distributed transactions using Transact-SQL are available only for Azure SQL Managed Instance. Distributed transaction can be executed only between Managed Instances that belong to the same Server trust group. In this scenario, Managed Instances need to use linked server to reference each other.\"\n\nDon't confuse this with the AZ-303 questions like I did.  The correct answer is managed instrances."
      },
      {
        "date": "2021-04-14T20:45:00.000Z",
        "voteCount": 9,
        "content": "303 question, an the answer is D. \"instead use virtual machine instance\""
      }
    ],
    "examNameCode": "az-304",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 11,
    "url": "https://www.examtopics.com/discussions/microsoft/view/47152-exam-az-304-topic-3-question-11-discussion/",
    "body": "You have an Azure subscription that contains the resources shown in the following table.<br><img src=\"/assets/media/exam-media/04027/0014900001.png\" class=\"in-exam-image\"><br>You need to archive the diagnostic data for VNET1 for 365 days. The solution must minimize costs.<br>Where should you archive the data?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tWorkspace1",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tstorage1\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tstorage2"
    ],
    "answer": "B",
    "answerDescription": "Incorrect Answers:<br>A: When you create a new workspace, it automatically creates several Azure resources that are used by the workspace:<br>\u2711 Azure Storage account: Is used as the default datastore for the workspace.<br>Note: The workspace is the top-level resource for Azure Machine Learning, providing a centralized place to work with all the artifacts you create when you use<br>Azure Machine Learning.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/machine-learning/concept-workspace",
    "votes": [
      {
        "answer": "B",
        "count": 2,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-06-16T05:53:00.000Z",
        "voteCount": 47,
        "content": "Answer is correct. Here is microsoft recomendation:\n\n\"Archiving logs and metrics to an Azure storage account is useful for audit, static analysis, or backup. Compared to Azure Monitor Logs and a Log Analytics workspace, Azure storage is less expensive and logs can be kept there indefinitely.\"\n\n\"The storage account needs to be in the same region as the resource being monitored if the resource is regional.\"\n\nREF: https://docs.microsoft.com/en-us/azure/azure-monitor/essentials/diagnostic-settings?tabs=CMD"
      },
      {
        "date": "2021-11-19T02:39:00.000Z",
        "voteCount": 3,
        "content": "thanks for explanation and for the documentation attached"
      },
      {
        "date": "2021-03-15T02:03:00.000Z",
        "voteCount": 15,
        "content": "Probably storage1, since it's in the same region. Otherwise you pay for data transfer.\nHas nothing to do with machine learning."
      },
      {
        "date": "2022-02-17T03:04:00.000Z",
        "voteCount": 1,
        "content": "It's a bit more than that.\nYou can't Diagnostic settings to Archive to a storage account that is not in the same region as the resource itself."
      },
      {
        "date": "2022-03-14T22:35:00.000Z",
        "voteCount": 1,
        "content": "B is correct"
      },
      {
        "date": "2022-02-12T04:12:00.000Z",
        "voteCount": 1,
        "content": "vote b"
      },
      {
        "date": "2022-01-13T16:36:00.000Z",
        "voteCount": 1,
        "content": "B. is the correct answer\nStorage1 is the same region and cheaper than the log analytics workspace"
      },
      {
        "date": "2021-10-04T06:09:00.000Z",
        "voteCount": 5,
        "content": "The storage account needs to be in the same region as the resource being monitored. it will incur additional egress charges to transfer data so answer is B"
      },
      {
        "date": "2021-06-08T00:13:00.000Z",
        "voteCount": 6,
        "content": "B (storage 1) is correct as it is cost effective and can store data for longer periods whereas  in Azure Log Analytics workspace, every GB of data ingested into your Azure Monitor Log Analytics workspace can be retained at no charge for up to first 31 days. Data retained beyond first 31 days will be charged per the data retention prices listed below."
      },
      {
        "date": "2021-04-19T05:42:00.000Z",
        "voteCount": 2,
        "content": "if I pay for Log analytics why not send to workspace?"
      },
      {
        "date": "2022-02-12T04:11:00.000Z",
        "voteCount": 1,
        "content": "it is what it is"
      },
      {
        "date": "2021-04-24T07:52:00.000Z",
        "voteCount": 2,
        "content": "Clever remark ! It there a trick here finally ?\nNo sure anyway, we don't use analytics for archive retention usually.\nI'll pick Storage 1 anyway!"
      },
      {
        "date": "2021-05-01T05:23:00.000Z",
        "voteCount": 4,
        "content": "The question is asking to archive the data, so a storage account would be more cost effective."
      },
      {
        "date": "2022-02-10T02:44:00.000Z",
        "voteCount": 2,
        "content": "A bit late to answer you but here is why you choose Azure Storage here instead of Log analytics workspace : the question is asking to retain the data for 365 days while log analytics workspace only keep them 90 days (thought you can expand to 730 days in some situations). So, normally, if you want to keep your logs more than 90 days, you send them to a storage.\nA ref among others : \nhttps://docs.microsoft.com/en-us/azure/azure-monitor/essentials/activity-log#send-to-azure-storage"
      },
      {
        "date": "2022-10-10T13:21:00.000Z",
        "voteCount": 1,
        "content": "\"while log analytics workspace only keep them 90 days\" - this is not correct.\nLog analytics workspace can keep logs up to 730 days.\n\"90\" is free days that you can keep logs with.\nLAW is not for archiving, is for interactive query.\nSo the correct answer is storage1."
      },
      {
        "date": "2021-03-28T00:38:00.000Z",
        "voteCount": 6,
        "content": "The answer is correct. This is Storage 1"
      }
    ],
    "examNameCode": "az-304",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 12,
    "url": "https://www.examtopics.com/discussions/microsoft/view/47153-exam-az-304-topic-3-question-12-discussion/",
    "body": "You plan to create an Azure Cosmos DB account that uses the SQL API. The account will contain data added by a web application. The web application will send data daily.<br>You need to recommend a notification solution that meets the following requirements:<br>\u2711 Sends email notifications when data is received from the web application<br>\u2711 Minimizes compute cost<br>What should you include in the recommendation?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDeploy an Azure logic app that has a SendGrid connector configured to use an Azure Cosmos DB action.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDeploy a function app that is configured to use the Consumption plan and an Azure Event Hubs binding.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDeploy a function app that is configured to use the Consumption plan and a SendGrid binding.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDeploy an Azure logic app that has a webhook configured to use a SendGrid action."
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 3,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-03-15T02:12:00.000Z",
        "voteCount": 31,
        "content": "Function apps support triggers for CosmosDB, logic apps do not.\nhttps://docs.microsoft.com/nl-nl/azure/azure-functions/functions-bindings-cosmosdb-v2-trigger?tabs=csharp\n\nCosmosDB actions makes no sense: we don't want to modify the CosmosDB data."
      },
      {
        "date": "2021-07-11T05:45:00.000Z",
        "voteCount": 7,
        "content": "Correct answer\nAzure functions can be directly tied to the change feed of Cosmos DB.\nhttps://docs.microsoft.com/en-us/azure/cosmos-db/change-feed-functions"
      },
      {
        "date": "2021-07-11T05:49:00.000Z",
        "voteCount": 9,
        "content": "Note: Send Grid ==&gt; send Email"
      },
      {
        "date": "2021-09-20T04:22:00.000Z",
        "voteCount": 9,
        "content": "came in exam on 20-sep-21, I passed, i choose C"
      },
      {
        "date": "2023-09-02T11:37:00.000Z",
        "voteCount": 1,
        "content": "You can send email by using SendGrid bindings in Azure Functions\nAzure functions can be directly tied to the change feed of Cosmos DB"
      },
      {
        "date": "2022-03-14T22:36:00.000Z",
        "voteCount": 1,
        "content": "I would choose C here"
      },
      {
        "date": "2022-01-14T15:32:00.000Z",
        "voteCount": 1,
        "content": "Azure Functions consumption plan is billed based on per-second resource consumption and executions. Consumption plan pricing includes a monthly free grant of 1 million requests and 400,000 GB-s of resource consumption per month per subscription in pay-as-you-go pricing across all function apps in that subscription. Azure Functions Premium plan provides enhanced performance and is billed on a per second basis based on the number of vCPU-s and GB-s your Premium Functions consume. Customers can also run Functions within their App Service plan at regular App Service plan rates."
      },
      {
        "date": "2021-12-23T05:24:00.000Z",
        "voteCount": 2,
        "content": "Correct answer"
      },
      {
        "date": "2021-12-23T03:36:00.000Z",
        "voteCount": 3,
        "content": "Appere on exam 23-dec-2021"
      },
      {
        "date": "2021-10-04T06:13:00.000Z",
        "voteCount": 4,
        "content": "A and D are out since \"minimize compute cost\"\n\nhttps://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-cosmosdb-v2-trigger?tabs=csharp\nhttps://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-sendgrid?tabs=csharp\nhttps://docs.sendgrid.com/ui/sending-email/how-to-send-email-with-marketing-campaigns\n\nC is the answer"
      },
      {
        "date": "2021-10-01T01:15:00.000Z",
        "voteCount": 6,
        "content": "Was in exam today 1-10-2021.  I passed with score 896.  I chose C"
      },
      {
        "date": "2021-08-27T23:15:00.000Z",
        "voteCount": 4,
        "content": "This seems to be the only question in both AZ-303 and AZ-304 that includes a 3rd party solution (SendGrid) in the suggestion solution."
      },
      {
        "date": "2021-08-18T19:54:00.000Z",
        "voteCount": 1,
        "content": "correct:\nconsumption plan: (min computer cost) Scale automatically and only pay for compute resources when your functions are running"
      },
      {
        "date": "2021-08-16T19:43:00.000Z",
        "voteCount": 1,
        "content": "D is correct. \nTo save cost LogicApp and work on top of webhook tirgger"
      },
      {
        "date": "2021-07-05T14:12:00.000Z",
        "voteCount": 3,
        "content": "Answer seems D.\n\nWe have to save compute costs, Use Azure Logic Apps instead of Azure Functions. As the web application will send a notification via a web trigger to the Azure Logic App, then use an Azure Logic App that has a webhook trigger and the SendGrid action can be used to send a notification."
      },
      {
        "date": "2021-08-01T18:43:00.000Z",
        "voteCount": 4,
        "content": "Both C &amp; D can satisfy the requirement. However, C did mentioned \"Consumption plan\" but not Logic App. So C would be more precise in low costing aspect"
      },
      {
        "date": "2021-06-16T06:23:00.000Z",
        "voteCount": 5,
        "content": "Answer seams right. Function supports trigger with CosmosDB with SQL API is used and the text mentions it. There is also a text explaining how to do it below. That with sendgrid to send the email is all that is needed. So I will go with answer C\n\nhttps://docs.microsoft.com/en-us/azure/azure-functions/functions-create-cosmos-db-triggered-function"
      },
      {
        "date": "2021-06-15T15:42:00.000Z",
        "voteCount": 1,
        "content": "Correct Answer is D.\nHere since we need to save the compute cost so Logic App needs to be used instead of Function App. \n2. Since the application are sending via webtrigger so SendGrind Action would be required."
      },
      {
        "date": "2021-09-28T06:22:00.000Z",
        "voteCount": 1,
        "content": "pls explain on how a logic app to trigger a function of SendGrid?"
      },
      {
        "date": "2022-01-21T08:41:00.000Z",
        "voteCount": 1,
        "content": "https://docs.microsoft.com/en-us/azure/connectors/connectors-create-api-sendgrid"
      },
      {
        "date": "2021-05-05T14:55:00.000Z",
        "voteCount": 3,
        "content": "Correct Answer - C. Deploy a function app that is configured to use the Consumption plan and a SendGrid binding. \nhttps://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-sendgrid?tabs=csharp#example"
      },
      {
        "date": "2021-05-04T17:49:00.000Z",
        "voteCount": 2,
        "content": "So what is the right answer?"
      }
    ],
    "examNameCode": "az-304",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 13,
    "url": "https://www.examtopics.com/discussions/microsoft/view/47249-exam-az-304-topic-3-question-13-discussion/",
    "body": "HOTSPOT -<br>You on-premises network contains a file server named Server1 that stores 500 GB of data.<br>You need to use Azure Data Factory to copy the data from Server1 to Azure Storage.<br>You add a new data factory.<br>What should you do next? To answer, select the appropriate options in the answer area.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04027/0015100001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04027/0015200001.png\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: Install a self-hosted integration runtime<br>The Integration Runtime is a customer-managed data integration infrastructure used by Azure Data Factory to provide data integration capabilities across different network environments.<br><br>Box 2: Create a pipeline -<br>With ADF, existing data processing services can be composed into data pipelines that are highly available and managed in the cloud. These data pipelines can be scheduled to ingest, prepare, transform, analyze, and publish data, and ADF manages and orchestrates the complex data and processing dependencies<br>Reference:<br>https://docs.microsoft.com/en-us/azure/machine-learning/team-data-science-process/move-sql-azure-adf",
    "votes": [],
    "comments": [
      {
        "date": "2021-03-26T08:39:00.000Z",
        "voteCount": 30,
        "content": "correct / https://docs.microsoft.com/pl-pl/azure/data-factory/tutorial-hybrid-copy-data-tool"
      },
      {
        "date": "2021-03-15T15:12:00.000Z",
        "voteCount": 14,
        "content": "I still don't get why we should use ADF to move files to Azure haha"
      },
      {
        "date": "2021-05-01T05:26:00.000Z",
        "voteCount": 4,
        "content": "Most likely to transform the data somehow during the process."
      },
      {
        "date": "2021-05-12T14:13:00.000Z",
        "voteCount": 1,
        "content": "Yep ETL"
      },
      {
        "date": "2021-08-31T02:38:00.000Z",
        "voteCount": 80,
        "content": "So that you can later save 4993.14 USD per month by replacing ADF with AZCOPY, see topic 3 question 3 ;)\n\nhttps://www.examtopics.com/discussions/microsoft/view/38657-exam-az-304-topic-3-question-3-discussion/"
      },
      {
        "date": "2021-12-16T23:56:00.000Z",
        "voteCount": 1,
        "content": "the question just comes for getting the knowledge :)))"
      },
      {
        "date": "2021-10-03T08:57:00.000Z",
        "voteCount": 3,
        "content": "Lmao, good one!"
      },
      {
        "date": "2022-12-30T03:41:00.000Z",
        "voteCount": 1,
        "content": "Right on, and it's a huge strategic cost-saving item in your department in future!"
      },
      {
        "date": "2021-12-15T07:45:00.000Z",
        "voteCount": 5,
        "content": "Nicely played, pentium75 :)"
      },
      {
        "date": "2021-09-28T23:39:00.000Z",
        "voteCount": 4,
        "content": "https://docs.microsoft.com/en-us/azure/data-factory/create-self-hosted-integration-runtime?tabs=data-factory\n\n\"A self-hosted integration runtime can run copy activities between a cloud data store and a data store in a private network\"\n\nhttps://docs.microsoft.com/en-us/azure/data-factory/introduction\n\n\"With Data Factory, you can use the Copy Activity in a data pipeline to move data from both on-premises and cloud source data stores to a centralization data store in the cloud for further analysis\"\n\nAnswer is correct"
      },
      {
        "date": "2021-08-31T02:34:00.000Z",
        "voteCount": 2,
        "content": "In second box, there is an option \"Provision Azure-SQL Server SSIS runtime,\" which is obviously wrong as we need a self-hosted (not an Azure-SQL) runtime. But still, don't we have to provision the self-hosted SSIS runtime in Azure Data Factory before we deploy it to the on-premise server?"
      },
      {
        "date": "2021-06-22T09:42:00.000Z",
        "voteCount": 2,
        "content": "2nnd is create an import export job"
      },
      {
        "date": "2021-06-12T10:59:00.000Z",
        "voteCount": 3,
        "content": "It seems to be correct for me, as there is no \"copy data tool\" option in the data factory bombo box, the most approximated one is \"create a pipeline\" as described in the following references (the last one hits the nail for me).\nReferences: \nhttps://docs.microsoft.com/en-us/azure/data-factory/copy-activity-overview\nhttps://docs.microsoft.com/en-us/azure/data-factory/quickstart-create-data-factory-copy-data-tool"
      },
      {
        "date": "2021-06-06T05:29:00.000Z",
        "voteCount": 1,
        "content": "1. StorageV2\nOnly storage type with storage tiers. The Central Europe region is no Azure region. In that geographic region, only Germany West Central has storage accounts with storage tiers. By the way, France Central is not situated in Central Europe geographically.\n2. ZRS\nProtection against single datacenter failure.\nhttps://en.wikipedia.org/wiki/Central_Europe\nhttps://docs.microsoft.com/en-us/azure/storage/common/storage-redundancy#redundancy-in-the-primary-region"
      },
      {
        "date": "2021-12-14T16:15:00.000Z",
        "voteCount": 3,
        "content": "Hey watch where your comment. your comment should be in the next question. lmao"
      },
      {
        "date": "2021-03-27T14:23:00.000Z",
        "voteCount": 2,
        "content": "It should mention :data to be migrated is from a SQL Server database..."
      },
      {
        "date": "2021-09-29T00:26:00.000Z",
        "voteCount": 1,
        "content": "nope, because it is not a SQL Server DB, then box2 select the first one;\nif it is a SQL Server DB, the better way is to use the 3rd one for box2;"
      },
      {
        "date": "2021-03-22T09:20:00.000Z",
        "voteCount": 3,
        "content": "the link provided has no relation to the question asked... Not sure if this question makes sense?"
      },
      {
        "date": "2021-03-18T18:27:00.000Z",
        "voteCount": 2,
        "content": "Correct..."
      }
    ],
    "examNameCode": "az-304",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 14,
    "url": "https://www.examtopics.com/discussions/microsoft/view/46509-exam-az-304-topic-3-question-14-discussion/",
    "body": "HOTSPOT -<br>You have an on-premises file server that stores 2 TB of data files.<br>You plan to move the data files to Azure Blob storage in the Central Europe region.<br>You need to recommend a storage account type to store the data files and a replication solution for the storage account. The solution must meet the following requirements:<br>\u2711 Be available if a single Azure datacenter fails.<br>\u2711 Support storage tiers.<br>\u2711 Minimize cost.<br>What should you recommend? To answer, select the appropriate options in the answer area.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04027/0015400001.jpg\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04027/0015500001.jpg\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: Blob storage -<br>Blob storage supports storage tiers<br>Note: Azure offers three storage tiers to store data in blob storage: Hot Access tier, Cool Access tier, and Archive tier. These tiers target data at different stages of its lifecycle and offer cost-effective storage options for different use cases.<br>Box 2: Zone-redundant storage (ZRS)<br>Data in an Azure Storage account is always replicated three times in the primary region. Azure Storage offers two options for how your data is replicated in the primary region:<br>\u2711 Zone-redundant storage (ZRS) copies your data synchronously across three Azure availability zones in the primary region.<br>\u2711 Locally redundant storage (LRS) copies your data synchronously three times within a single physical location in the primary region. LRS is the least expensive replication option, but is not recommended for applications requiring high availability.<br>Reference:<br>https://cloud.netapp.com/blog/storage-tiers-in-azure-blob-storage-find-the-best-for-your-data https://docs.microsoft.com/en-us/azure/storage/common/storage-redundancy",
    "votes": [],
    "comments": [
      {
        "date": "2021-03-11T11:02:00.000Z",
        "voteCount": 141,
        "content": "Answer is\nAccount Type: StorageV2\nReplication solution: Zone-redundant storage (ZRS)\n\nThe blobstorage and StorageV1 doesn't support ZRS replication."
      },
      {
        "date": "2021-03-12T04:27:00.000Z",
        "voteCount": 1,
        "content": "That is correct"
      },
      {
        "date": "2021-03-12T00:21:00.000Z",
        "voteCount": 4,
        "content": "Yes Correct blobstorage doesn't support ZRS"
      },
      {
        "date": "2021-03-22T09:45:00.000Z",
        "voteCount": 5,
        "content": "also only v2 supports access tier (hot and cold)"
      },
      {
        "date": "2021-04-14T21:07:00.000Z",
        "voteCount": 5,
        "content": "excelent argument, thank you for your contribution"
      },
      {
        "date": "2021-03-18T07:53:00.000Z",
        "voteCount": 14,
        "content": "Account Type: StorageV2\nReplication solution: Zone-redundant storage (ZRS)"
      },
      {
        "date": "2023-06-02T21:25:00.000Z",
        "voteCount": 1,
        "content": "AZ 305 3 June 2023"
      },
      {
        "date": "2022-08-22T22:31:00.000Z",
        "voteCount": 2,
        "content": "i am fine with V2, but second one should be GRS because of single data center fails. one region could have 2 or more DC, if only one fails, your data is still safe if it is GRS. considering min cost...."
      },
      {
        "date": "2022-08-11T05:19:00.000Z",
        "voteCount": 1,
        "content": "I was pretty sure iti hate when they get something so simple wrong. Answer is StorageV2(GP V2) &amp; ZRS"
      },
      {
        "date": "2022-06-27T07:57:00.000Z",
        "voteCount": 1,
        "content": "To minimise cost use standard not premium.\nGPv2 is recommended as a default by MS\nZRS is cheapest option that supports a data centre failure"
      },
      {
        "date": "2022-04-09T04:28:00.000Z",
        "voteCount": 5,
        "content": "In AZ-305 exam, 9 april 22"
      },
      {
        "date": "2022-03-09T22:54:00.000Z",
        "voteCount": 1,
        "content": "answer is V2 &amp; ZRS"
      },
      {
        "date": "2022-02-10T03:11:00.000Z",
        "voteCount": 2,
        "content": "Answer : \nStorage V2 and ZRS.\nZRS is pretty obvious.\nBut why you should choose Storage V2 rather than Blob storage ? Because if you deploy a storage account and want only Blod, then you need to select a premium storage. Premium Blobs are more expansive than the Blobs you have in your Storage V2. Question says : minimize the cost. So you can't choose Blob Storage (premium) or worse (legacy blob storage......). You can't choose Storage V1 since they don't support access tiers."
      },
      {
        "date": "2022-01-31T18:20:00.000Z",
        "voteCount": 1,
        "content": "Supported storage account types\nThe following table shows which redundancy options are supported by each type of storage account. For information for storage account types, see Storage account overview.\n\nSUPPORTED STORAGE ACCOUNT TYPES\nLRS\tZRS\tGRS/RA-GRS\tGZRS/RA-GZRS\nGeneral-purpose v21\nGeneral-purpose v1\nPremium block blob1\nLegacy blob\nPremium file shares\tGeneral-purpose v21\nPremium block blobs1\nPremium file shares\tGeneral-purpose v21\nGeneral-purpose v1\nLegacy blob\tGeneral-purpose v21"
      },
      {
        "date": "2022-01-10T22:13:00.000Z",
        "voteCount": 1,
        "content": "I think storage V2 is the correct answer as I think that is what Microsoft is pushing us to use in the future. I heard the other storage types will be phased out eventually."
      },
      {
        "date": "2022-01-03T08:03:00.000Z",
        "voteCount": 1,
        "content": "the blob storage support ZRS https://docs.microsoft.com/en-us/azure/storage/common/storage-redundancy#supported-azure-storage-services \nthe General-purpose v1 not support ZRS"
      },
      {
        "date": "2021-12-29T02:43:00.000Z",
        "voteCount": 1,
        "content": "Its should be \nBox1: Storage V2 and \nBpx2: ZRS"
      },
      {
        "date": "2021-12-28T09:46:00.000Z",
        "voteCount": 1,
        "content": "\"What should you recommend?\"\n\nI assume by \"Blob\" the option is actually Standard Blob storage (legacy), which should never be recommended. In any case, it doesnt support LRS.\n\nDescribed as \"legacy blob\" in the table here:\n\nhttps://docs.microsoft.com/en-us/azure/storage/common/storage-redundancy"
      },
      {
        "date": "2021-12-23T03:36:00.000Z",
        "voteCount": 2,
        "content": "Appere on exam 23-dec-2021"
      },
      {
        "date": "2021-10-14T23:47:00.000Z",
        "voteCount": 1,
        "content": "Hi Guys, look at the question itself: \"You plan to move the data files to Azure Blob storage in the Central Europe region\", it has highlighted that data will move to BLOB Storage, so the question here is narrowed to that is the Storage V2 under BLOB Storage?"
      },
      {
        "date": "2021-10-06T07:51:00.000Z",
        "voteCount": 6,
        "content": "This question was in AZ-303, and the Correct Answer is - StorageV2 &amp; ZRS"
      }
    ],
    "examNameCode": "az-304",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 15,
    "url": "https://www.examtopics.com/discussions/microsoft/view/51313-exam-az-304-topic-3-question-15-discussion/",
    "body": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.<br>After you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.<br>You are designing an Azure solution for a company that has four departments. Each department will deploy several Azure app services and Azure SQL databases.<br>You need to recommend a solution to report the costs for each department to deploy the app services and the databases. The solution must provide a consolidated view for cost reporting that displays cost broken down by department.<br>Solution: Create a resource group for each resource type. Assign tags to each resource group.<br>Does this meet the goal?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tYes",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tNo\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 20,
        "isMostVoted": true
      },
      {
        "answer": "A",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2021-05-01T05:39:00.000Z",
        "voteCount": 53,
        "content": "No since each department will deploy several app services and DBs.  If we group like resources in resource groups we will not be able to get a break down by department."
      },
      {
        "date": "2021-06-03T08:50:00.000Z",
        "voteCount": 2,
        "content": "Agree hundred percent with you"
      },
      {
        "date": "2021-06-07T06:57:00.000Z",
        "voteCount": 3,
        "content": "why not ? You are not able to filter by tags? If you have 4 dept a 1 resources group for lets say storage account and you tag every SA with name of department, then you can filter tags and see departments resources and see price.. I would say answer is YES in here"
      },
      {
        "date": "2021-06-20T10:52:00.000Z",
        "voteCount": 13,
        "content": "The questions say tag resource group and not resources, so how can you get which resource belongs to which department?."
      },
      {
        "date": "2021-10-04T23:46:00.000Z",
        "voteCount": 2,
        "content": "Answer is almost correct, just tag on the resources instead of resource group as what said in explanation."
      },
      {
        "date": "2021-06-17T09:47:00.000Z",
        "voteCount": 3,
        "content": "there are no words they will use resources from other department so we can assume they will use only their own resources - the answer is YES"
      },
      {
        "date": "2021-08-14T00:57:00.000Z",
        "voteCount": 14,
        "content": "Look at the wording. It says create a resource group for each resource type. It should be create a resource group for each department. \n\n\"Create a resource group for each resource type. Assign tags to each resource group.\"\n\nIt also states each department will deploy web apps and SQL. Therefore the solution doesn't work."
      },
      {
        "date": "2021-06-26T23:30:00.000Z",
        "voteCount": 13,
        "content": "No.\nYou have to assign a tag like Department1 or Department2 or Department3 or Department4 on each resource so you can filter for instance all resources relative to the first department by selecting the tag Department1.\nThe option is wrong because if we put let me say all the storage accounts in RG1 and we assign a tag to it as the option says for instance StAcs we don't have any possibility to filter the storage accounts belonging to the first department."
      },
      {
        "date": "2021-06-26T23:41:00.000Z",
        "voteCount": 1,
        "content": "Of course another option would be to create 4 RGs one for each department and to assign a tag to each one like Department1 or Department2 or Department3 or Department4. Then we put inside the RG tagged Department1 all the resources belonging to the first department and so on. In this case though we do not have the RGs divided by resource type as the option requires."
      },
      {
        "date": "2022-10-10T02:31:00.000Z",
        "voteCount": 1,
        "content": "Ans is NO. RG will have resources from all depts, so no use of its tag."
      },
      {
        "date": "2022-08-11T05:28:00.000Z",
        "voteCount": 1,
        "content": "this is so unfair. By assigning tags to the RG, you can still get to your resource after you assign a policy to inherit the tags from the RG. So technically, at this stage, how it is presented, this answer is not entirely false. \n\nI would have to go with Yes on this one."
      },
      {
        "date": "2022-09-21T13:23:00.000Z",
        "voteCount": 1,
        "content": "They key point here is that they created the RGs for each resource type... not for each department."
      },
      {
        "date": "2022-05-31T08:00:00.000Z",
        "voteCount": 2,
        "content": "Link is correct. However , it's false to the question statements."
      },
      {
        "date": "2022-08-11T05:29:00.000Z",
        "voteCount": 1,
        "content": "Yes, the question is badly stated."
      },
      {
        "date": "2022-05-30T22:16:00.000Z",
        "voteCount": 1,
        "content": "Given Ans: Create a resource group for each resource type. Assign tags to each resource group.\nCorrect Ans : NO\n\nIt should be 1 or 4 resource groups and each resource will have tag as per department, i.e. Department#1, Department2  3... 4..\nAlso there is no mention that different department will use each others resources, even if they use, Cost would still be on resource owner."
      },
      {
        "date": "2022-03-21T10:59:00.000Z",
        "voteCount": 1,
        "content": "It's B"
      },
      {
        "date": "2022-03-10T09:59:00.000Z",
        "voteCount": 2,
        "content": "It is definitely NO as tagging the resources is not available for the costs:\nMost Azure resources support tagging. However, some tags aren't available in Cost Management and billing. Additionally, resource group tags aren't supported. \nhttps://docs.microsoft.com/en-us/azure/cost-management-billing/costs/quick-acm-cost-analysis#group-costs"
      },
      {
        "date": "2022-03-09T22:58:00.000Z",
        "voteCount": 2,
        "content": "ANSWER is NO"
      },
      {
        "date": "2022-02-16T07:35:00.000Z",
        "voteCount": 1,
        "content": "You can create 4 RGs one for each department and to assign a tag to each one like Department1 or Department2 or Department3 or Department4. Then we put inside the RG tagged Department1 all the resources belonging to the first department and so on. Tags are inheritable, but you can use a policy to make sure a tag is copied from a RG to its resources."
      },
      {
        "date": "2022-02-04T13:10:00.000Z",
        "voteCount": 3,
        "content": "No, tags are not inhereted from Resource Groups to resources"
      },
      {
        "date": "2022-02-04T13:07:00.000Z",
        "voteCount": 1,
        "content": "No, tags are not inhereted from Resource Group to the resources."
      },
      {
        "date": "2022-02-01T22:56:00.000Z",
        "voteCount": 1,
        "content": "This is certainly no as once you club all the resources of different department in one RG tagging the RG won't be of any help while getting cost for each dept"
      },
      {
        "date": "2022-01-02T00:06:00.000Z",
        "voteCount": 1,
        "content": "It Says \"Create a resource group for each resource type\" hence we can tag individual RGs i.e. each SQL DB will be in its own RG.   Hence Answer is CORRECT."
      },
      {
        "date": "2021-12-28T20:16:00.000Z",
        "voteCount": 3,
        "content": "either tag individual resources or place resources owned by a department into their own tagged resource groups"
      },
      {
        "date": "2021-12-20T03:07:00.000Z",
        "voteCount": 4,
        "content": "should tag individual resources rather than rg"
      },
      {
        "date": "2021-12-17T03:34:00.000Z",
        "voteCount": 3,
        "content": "Answer: no. With the proposed solution, the tags will allow you to distinguish by resource type, not by department, which is what is needed"
      }
    ],
    "examNameCode": "az-304",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 16,
    "url": "https://www.examtopics.com/discussions/microsoft/view/51314-exam-az-304-topic-3-question-16-discussion/",
    "body": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.<br>After you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.<br>You are designing an Azure solution for a company that has four departments. Each department will deploy several Azure app services and Azure SQL databases.<br>You need to recommend a solution to report the costs for each department to deploy the app services and the databases. The solution must provide a consolidated view for cost reporting that displays cost broken down by department.<br>Solution: Create a new subscription for each department.<br>Does this meet the goal?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tYes\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tNo"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 7,
        "isMostVoted": true
      },
      {
        "answer": "B",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2021-04-30T15:19:00.000Z",
        "voteCount": 39,
        "content": "it should be yes, with sub. for each dept. we can get the spending for each spending. RG for resource group will not fix it, RG for each dept. will."
      },
      {
        "date": "2021-09-11T12:22:00.000Z",
        "voteCount": 2,
        "content": "Yes. We can create a consolidated report for all subscriptions under MG scope. Filters allows to see breakdown of resources under each subscription."
      },
      {
        "date": "2021-09-11T12:27:00.000Z",
        "voteCount": 1,
        "content": "https://docs.microsoft.com/en-us/azure/cost-management-billing/costs/group-filter"
      },
      {
        "date": "2021-05-06T15:20:00.000Z",
        "voteCount": 18,
        "content": "Answer is correct. You need a CONSOLIDATED report, of all departments\nDep 1  50\nDep 2  35\nDep 3  80\nDep 4  55\n\nBy subscription yo only get \nSubcription 1 50"
      },
      {
        "date": "2021-05-10T10:37:00.000Z",
        "voteCount": 16,
        "content": "You can use management group as the scope and use \"grouped by subscription\". So the answer is yes."
      },
      {
        "date": "2021-05-22T08:32:00.000Z",
        "voteCount": 4,
        "content": "agreed should be yes. It's under the same tenant."
      },
      {
        "date": "2022-03-08T19:17:00.000Z",
        "voteCount": 1,
        "content": "You have a subscription for each department...therefor the subscription report will show the costs for that department only and a report from the MG level will consolidate all 4 Subs into 1 report"
      },
      {
        "date": "2024-08-20T18:49:00.000Z",
        "voteCount": 1,
        "content": "I think it should be NO because having cost management at subscription level would include cost of other resources/resource groups created in that subsciption. The aim is to report on the costs for each department to deploy the \"app services and the databases\"."
      },
      {
        "date": "2023-09-02T10:48:00.000Z",
        "voteCount": 1,
        "content": "You have a subscription for each department...therefor the subscription report will show the costs for that department only and a report from the MG level will consolidate all 4 Subs into 1 report"
      },
      {
        "date": "2022-10-10T02:37:00.000Z",
        "voteCount": 1,
        "content": "The question says -  \"The solution must provide a consolidated view for cost reporting that displays cost broken down by department.\", so ans is No"
      },
      {
        "date": "2022-08-13T21:44:00.000Z",
        "voteCount": 3,
        "content": "The correct answer as per the MS practice test is \"NO\"."
      },
      {
        "date": "2022-08-13T04:03:00.000Z",
        "voteCount": 1,
        "content": "The goal is to break down cost in the entire subscription by department so separate subscriptions is not the answer. Correct answer is B."
      },
      {
        "date": "2022-08-24T04:22:00.000Z",
        "voteCount": 1,
        "content": "to break down cost in the entire SOLUTION by department. Subscriptions are not mentioned in the text.\n'A' works well here."
      },
      {
        "date": "2022-08-11T05:33:00.000Z",
        "voteCount": 1,
        "content": "This question could better formulated. Here also you can get your answer. You just have to consider admin effort. \n\nClick each of the option can still lead you to the solution. I guess they want to emphasis on tag here?"
      },
      {
        "date": "2022-08-10T07:34:00.000Z",
        "voteCount": 1,
        "content": "Each subscriptoin is one department. So generating a report based on the subscription will give us the spending of each department."
      },
      {
        "date": "2022-04-01T19:07:00.000Z",
        "voteCount": 1,
        "content": "Yes but not a good solution but should answer the question/"
      },
      {
        "date": "2022-04-01T19:10:00.000Z",
        "voteCount": 2,
        "content": "meant to say not a very bad solution. Another option is one subscription, RG for each department and tagging enforced for each resource."
      },
      {
        "date": "2021-12-21T05:38:00.000Z",
        "voteCount": 6,
        "content": "Should be YES"
      },
      {
        "date": "2021-11-13T02:27:00.000Z",
        "voteCount": 3,
        "content": "Should be YES:\nCost managment / Cost analysis / Scope: Account / Group by: Subscription"
      },
      {
        "date": "2021-10-04T23:25:00.000Z",
        "voteCount": 2,
        "content": "I would take No as the answer\n\n\"consolidated view for cost reporting\" would mean it falls under a single subscription"
      },
      {
        "date": "2021-09-25T11:03:00.000Z",
        "voteCount": 2,
        "content": "Azure portal -&gt; subscription -&gt; cost management - &gt; cost analysis.\nSo \"yes\""
      },
      {
        "date": "2021-09-18T21:27:00.000Z",
        "voteCount": 1,
        "content": "YES : Subscription has a view of costs of resources used by department and convenient way."
      },
      {
        "date": "2021-06-06T05:45:00.000Z",
        "voteCount": 3,
        "content": "Answer is Yes.\nThis solution is the most convenient, costs are split per department without any effort."
      },
      {
        "date": "2021-05-04T23:57:00.000Z",
        "voteCount": 3,
        "content": "should be A-yes. That gives us consolidated and even detailed view on resources per dept without any effort"
      }
    ],
    "examNameCode": "az-304",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 17,
    "url": "https://www.examtopics.com/discussions/microsoft/view/46640-exam-az-304-topic-3-question-17-discussion/",
    "body": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.<br>After you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.<br>You are designing an Azure solution for a company that has four departments. Each department will deploy several Azure app services and Azure SQL databases.<br>You need to recommend a solution to report the costs for each department to deploy the app services and the databases. The solution must provide a consolidated view for cost reporting that displays cost broken down by department.<br>Solution: Place all resources in the same resource group. Assign tags to each resource.<br>Does the solution meet the goal?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tYes\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tNo"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 9,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-03-12T00:29:00.000Z",
        "voteCount": 78,
        "content": "Answer is yes , tag will be the department and value the department name"
      },
      {
        "date": "2021-04-14T21:19:00.000Z",
        "voteCount": 6,
        "content": "Works, but is not recomended has single resource group for all resources, its necesary organice resource according a clasification."
      },
      {
        "date": "2021-06-06T10:36:00.000Z",
        "voteCount": 5,
        "content": "https://docs.microsoft.com/en-us/azure/azure-resource-manager/management/tag-resources?tabs=json#tags-and-billing the documentation says it's fine"
      },
      {
        "date": "2021-03-15T02:40:00.000Z",
        "voteCount": 1,
        "content": "Consolidated view is required, so costs per departments in one view I assume. Changing filter all the time is not suffice."
      },
      {
        "date": "2021-03-15T02:45:00.000Z",
        "voteCount": 4,
        "content": "Correction: you can set the 'Group By' to a specific tag, so would work indeed."
      },
      {
        "date": "2021-03-23T22:42:00.000Z",
        "voteCount": 17,
        "content": "Again please see the explanation - same question was in AZ-303, here it is actually correct in saying it is not recommended to put all resources in the same RG, but it is a YES as it will still work. The perfect answer is in the explanation - Instead, create a resources group for each resource type. Assign tags to each ***resource***"
      },
      {
        "date": "2023-01-04T09:17:00.000Z",
        "voteCount": 1,
        "content": "nothing is mentioned about tags on question.. quite tricky one to choose"
      },
      {
        "date": "2022-08-11T05:34:00.000Z",
        "voteCount": 1,
        "content": "This would work. But considering the state of the question, we don't have enough information to tell if this is bad practice. This question was poorly formulated."
      },
      {
        "date": "2022-04-01T19:09:00.000Z",
        "voteCount": 1,
        "content": "Yes this should solve the problem."
      },
      {
        "date": "2022-02-11T09:31:00.000Z",
        "voteCount": 2,
        "content": "Answer is Yes."
      },
      {
        "date": "2022-01-03T08:16:00.000Z",
        "voteCount": 2,
        "content": "this is answer for the MOC:\nCreate an individual resource group for each department and place the separate resources for each department in their individual groups.\nCost Management can track by Resource Group. Allows you to report by resource group."
      },
      {
        "date": "2021-12-23T05:28:00.000Z",
        "voteCount": 3,
        "content": "Answer is Yes."
      },
      {
        "date": "2021-12-17T05:29:00.000Z",
        "voteCount": 3,
        "content": "Answer is Yes. Indeed not a good solution but works"
      },
      {
        "date": "2021-10-04T23:30:00.000Z",
        "voteCount": 1,
        "content": "This will work so Yes"
      },
      {
        "date": "2021-09-29T03:24:00.000Z",
        "voteCount": 1,
        "content": "\"recommend a solution to report the costs for each department to deploy the app services and the databases\" it will work but your recommendation should be accurate. I think \"No\" is the right"
      },
      {
        "date": "2021-09-18T21:30:00.000Z",
        "voteCount": 1,
        "content": "YES : Resource Tags are used for the reason to classify resources in common RG"
      },
      {
        "date": "2021-06-25T22:55:00.000Z",
        "voteCount": 3,
        "content": "The answer should be yes because you can create tags for each department for the resources. However, not a good practice to put everything under one resource group."
      },
      {
        "date": "2021-06-22T04:16:00.000Z",
        "voteCount": 1,
        "content": "Answer should be Yes. Though this is not best the practice but it will work since you easily differentiate the cost of each department in the bill by segregating the tags."
      },
      {
        "date": "2021-06-16T06:57:00.000Z",
        "voteCount": 2,
        "content": "Answer should be YES.\n\nIt will definitely works as expected !"
      },
      {
        "date": "2021-06-13T20:05:00.000Z",
        "voteCount": 3,
        "content": "not a best practice but it would work."
      },
      {
        "date": "2021-06-07T06:55:00.000Z",
        "voteCount": 1,
        "content": "answer is Yes. The question provides only 2 resource types web app and SQL database. And the cost of each department can be calculated based on the tags applied on each resource"
      }
    ],
    "examNameCode": "az-304",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 18,
    "url": "https://www.examtopics.com/discussions/microsoft/view/47203-exam-az-304-topic-3-question-18-discussion/",
    "body": "HOTSPOT -<br>You have an Azure SQL database named DB1.<br>You need to recommend a data security solution for DB1. The solution must meet the following requirements:<br>\u2711 When helpdesk supervisors query DB1, they must see the full number of each credit card.<br>\u2711 When helpdesk operators query DB1, they must see only the last four digits of each credit card number.<br>\u2711 A column named Credit Rating must never appear in plain text within the database system, and only client applications must be able to decrypt the Credit<br>Rating column.<br>What should you include in the recommendation? To answer, select the appropriate options in the answer area.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04027/0015900001.jpg\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04027/0016000001.jpg\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: Dynamic data masking -<br>Dynamic data masking helps prevent unauthorized access to sensitive data by enabling customers to designate how much of the sensitive data to reveal with minimal impact on the application layer. It's a policy-based security feature that hides the sensitive data in the result set of a query over designated database fields, while the data in the database is not changed.<br><br>Box 2: Always encrypted -<br>Data stored in the database is protected even if the entire machine is compromised, for example by malware. Always Encrypted leverages client-side encryption: a database driver inside an application transparently encrypts data, before sending the data to the database. Similarly, the driver decrypts encrypted data retrieved in query results.<br>Reference:<br>https://azure.microsoft.com/en-us/blog/transparent-data-encryption-or-always-encrypted/",
    "votes": [],
    "comments": [
      {
        "date": "2021-03-15T09:03:00.000Z",
        "voteCount": 32,
        "content": "Correct!!"
      },
      {
        "date": "2021-06-17T10:32:00.000Z",
        "voteCount": 8,
        "content": "For Second Answer 'Always Encrypt' explanations is here\n\nhttps://docs.microsoft.com/en-us/sql/relational-databases/security/encryption/always-encrypted-database-engine?view=sql-server-ver15"
      },
      {
        "date": "2021-12-23T03:36:00.000Z",
        "voteCount": 3,
        "content": "Appere on exam 23-dec-2021"
      },
      {
        "date": "2021-10-01T22:56:00.000Z",
        "voteCount": 6,
        "content": "\"see only the last four digits\" -&gt; This implies data masking\n\n\"must never appear in plain text\" and \"only client applications must be able to decrypt\" -&gt; Always Encrypted\n\nAnswer is correct"
      },
      {
        "date": "2021-06-17T09:52:00.000Z",
        "voteCount": 2,
        "content": "Correct"
      },
      {
        "date": "2021-05-19T10:52:00.000Z",
        "voteCount": 2,
        "content": "Correct. dynamic data masking explained here:\nhttps://docs.microsoft.com/en-us/sql/relational-databases/security/dynamic-data-masking?view=sql-server-ver15"
      },
      {
        "date": "2021-04-15T14:17:00.000Z",
        "voteCount": 2,
        "content": "Answers are correct!"
      },
      {
        "date": "2021-03-28T04:13:00.000Z",
        "voteCount": 3,
        "content": "The answer is correct"
      }
    ],
    "examNameCode": "az-304",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 19,
    "url": "https://www.examtopics.com/discussions/microsoft/view/51415-exam-az-304-topic-3-question-19-discussion/",
    "body": "You are designing a data protection strategy for Azure virtual machines. All the virtual machines use managed disks.<br>You need to recommend a solution that meets the following requirements:<br>\u2711 The use of encryption keys is audited.<br>\u2711 All the data is encrypted at rest always.<br>\u2711 You manage the encryption keys, not Microsoft.<br>What should you include in the recommendation?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tclient-side encryption",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure Storage Service Encryption",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure Disk Encryption\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEncrypting File System (EFS)"
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 5,
        "isMostVoted": true
      },
      {
        "answer": "B",
        "count": 4,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2021-05-25T15:39:00.000Z",
        "voteCount": 20,
        "content": "Since it says \"All of the Data\", the answer is C.\n\nhttps://docs.microsoft.com/en-us/azure/virtual-machines/windows/disk-encryption-faq#how-is-azure-disk-encryption-different-from-storage-server-side-encryption-with-customer-managed-key-and-when-should-i-use-each-solution"
      },
      {
        "date": "2021-08-18T21:05:00.000Z",
        "voteCount": 10,
        "content": "This link says us: \n\"- If your requirements include encrypting all of the above and end-to-end encryption, use Azure Disk Encryption.\n-If your requirements include encrypting only data at rest with customer-managed key, then use Server-side encryption with customer-managed keys. You cannot encrypt a disk with both Azure Disk Encryption and Storage server-side encryption with customer managed keys\"\nSo the answer is B"
      },
      {
        "date": "2021-12-06T05:55:00.000Z",
        "voteCount": 2,
        "content": "Absolutely agree with you.\n\"Azure Storage encryption automatically encrypts your data stored on Azure managed disks (OS and data disks) at rest by default when persisting it to the cloud\"\n\n\"Full control of your keys\nYou must grant access to managed disks in your Key Vault to use your keys for encrypting and decrypting the DEK. This allows you full control of your data and keys. You can disable your keys or revoke access to managed disks at any time. You can also audit the encryption key usage with Azure Key Vault monitoring to ensure that only managed disks or other trusted Azure services are accessing your keys.\"\n\nhttps://docs.microsoft.com/en-us/azure/virtual-machines/disk-encryption\nhttps://docs.microsoft.com/en-us/azure/virtual-machines/disk-encryption-overview"
      },
      {
        "date": "2023-09-02T10:59:00.000Z",
        "voteCount": 1,
        "content": "Since it says \"All of the Data\"\nAzure Disk Encryption provides end-to-end encryption for the OS disk, data disks, and the temporary disk with a customer-managed key.\nIf your requirements include encrypting all of the above and end-to-end encryption, use Azure Disk Encryption.\nif your requirements include encrypting only data at rest with customer-managed key, then use Server-side encryption with customer-managed keys. You can't encrypt a disk with both Azure Disk Encryption and Storage server-side encryption with customer managed keys."
      },
      {
        "date": "2022-04-13T01:04:00.000Z",
        "voteCount": 1,
        "content": "Here: https://docs.microsoft.com/en-us/azure/virtual-machines/disk-encryption#restrictions-1 \n\nSupports ephemeral OS disks but only with platform-managed keys.\n\nHowever I find it creazy that so many answers are unclear ... Maybe the documentation of Azure is not clear enough"
      },
      {
        "date": "2022-04-13T01:06:00.000Z",
        "voteCount": 1,
        "content": "Sorry C, https://docs.microsoft.com/en-us/azure/virtual-machines/disk-encryption#server-side-encryption-versus-azure-disk-encryption"
      },
      {
        "date": "2022-03-08T11:16:00.000Z",
        "voteCount": 1,
        "content": "please refer below links and explanation, it has answers for all given requirements. \n\nhttps://docs.microsoft.com/en-us/azure/virtual-machines/disk-encryption#full-control-of-your-keys\n- You can audit the encryption key usage with Azure Key Vault monitoring to ensure that only managed disks or other trusted Azure services are accessing your keys\n\nhttps://docs.microsoft.com/en-us/azure/virtual-machines/disk-encryption#customer-managed-keys\n- You can choose to manage encryption at the level of each managed disk, with your own custom keys\n\nhttps://docs.microsoft.com/en-us/azure/virtual-machines/disk-encryption\n- Most Azure managed disks are encrypted with Azure Storage encryption, which uses server-side encryption (SSE) to protect your data and to help you meet your organizational security and compliance commitments"
      },
      {
        "date": "2022-02-20T17:36:00.000Z",
        "voteCount": 2,
        "content": "the key here is not whether SSE or ADE can encrypt or do it using CMK, it is about \"The use of encryption keys is audited\", with SSE+CMK audit is \"Unhealthy, not applicable if exempt\" and with ADE it is \"Healthy\" ..."
      },
      {
        "date": "2022-02-11T09:38:00.000Z",
        "voteCount": 1,
        "content": "Answer is C."
      },
      {
        "date": "2022-01-29T10:03:00.000Z",
        "voteCount": 4,
        "content": "Azure storage Server-Side Encryption  can be answer but the options say 'Azure Storage Services Encryption' and that is different.\nAzure Storage Service Encryption\nData at rest in Azure Blob storage and Azure file shares can be encrypted in both server-side and client-side scenarios.\n\nAzure Storage Service Encryption (SSE) can automatically encrypt data before it is stored, and it automatically decrypts the data when you retrieve it. The process is completely transparent to users. Storage Service Encryption uses 256-bit Advanced Encryption Standard (AES) encryption, which is one of the strongest block ciphers available. AES handles encryption, decryption, and key management transparently. Please see the link below\nhttps://docs.microsoft.com/en-us/azure/security/fundamentals/encryption-overview"
      },
      {
        "date": "2022-01-23T19:39:00.000Z",
        "voteCount": 1,
        "content": "The link is self-explanatory"
      },
      {
        "date": "2022-01-21T01:07:00.000Z",
        "voteCount": 1,
        "content": "https://docs.microsoft.com/en-us/azure/storage/common/storage-service-encryption?toc=/azure/storage/blobs/toc.json"
      },
      {
        "date": "2022-01-04T09:25:00.000Z",
        "voteCount": 1,
        "content": "if you follow the link and look \"Encryption at Rest\" section you will see the following :\n\"Any customer using Azure Infrastructure as a Service (IaaS) features can achieve encryption at rest for their IaaS VMs and disks through Azure Disk Encryption\"\n\nhttps://docs.microsoft.com/en-us/azure/security/fundamentals/encryption-atrest#azure-disk-encryption"
      },
      {
        "date": "2021-12-28T10:11:00.000Z",
        "voteCount": 2,
        "content": "I'd go for C \n\nhttps://docs.microsoft.com/en-us/azure/virtual-machines/disk-encryption-overview#comparison"
      },
      {
        "date": "2022-01-17T17:07:00.000Z",
        "voteCount": 1,
        "content": "I agree, Azure Disk Encryption with VolumeType = All to encrypt the temporary disk - as Defender for Cloud can audit encryption state health for Azure Disk Encryption \nThe other way to encrypt the temporary disk is using server-side encryption with encryption at host but Defender for Cloud cannot audit disk encryption health state for encryption at host, according to the comparison table linked to."
      },
      {
        "date": "2021-12-24T17:45:00.000Z",
        "voteCount": 1,
        "content": "read the link it is self explanatory"
      },
      {
        "date": "2021-10-29T21:10:00.000Z",
        "voteCount": 3,
        "content": "C. Azure Disk Encryption \n---\nhttps://docs.microsoft.com/en-us/azure/virtual-machines/windows/disk-encryption-faq#how-is-azure-disk-encryption-different-from-storage-server-side-encryption-with-customer-managed-key-and-when-should-i-use-each-solution-"
      },
      {
        "date": "2021-10-12T04:47:00.000Z",
        "voteCount": 1,
        "content": "I will go for B, because question says \"encryption at rest\"\n\nNote: ASSE is majorly for encryption at rest."
      },
      {
        "date": "2021-10-04T23:32:00.000Z",
        "voteCount": 2,
        "content": "https://docs.microsoft.com/en-us/azure/virtual-machines/disk-encryption#full-control-of-your-keys\n\nC is correct"
      },
      {
        "date": "2021-09-22T18:30:00.000Z",
        "voteCount": 1,
        "content": "I think B\nStorage server-side encryption encrypts Azure managed disks in Azure Storage. Managed disks are encrypted by default with Server-side encryption with a platform-managed key (as of June 10, 2017). You can manage encryption of managed disks with your own keys by specifying a customer-managed key."
      },
      {
        "date": "2021-09-19T17:29:00.000Z",
        "voteCount": 2,
        "content": "Answer is correct\n\nBoth Azure Disk Encrypt and Azure Server Side Encryption(Customer Managed Key) can meet all 3 requirements. For given answers, C is correct"
      }
    ],
    "examNameCode": "az-304",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 20,
    "url": "https://www.examtopics.com/discussions/microsoft/view/51579-exam-az-304-topic-3-question-20-discussion/",
    "body": "You have an on-premises application named App1 that uses an Oracle database.<br>You plan to use Azure Databricks to transform and load data from App1 to an Azure Synapse Analytics instance.<br>You need to ensure that the App1 data is available to Databricks.<br>Which two Azure services should you include in the solution? Each correct answer presents part of the solution.<br>NOTE: Each correct selection is worth one point.<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure Data Box Gateway",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure Data Lake Storage\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure Import/Export service",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure Data Factory\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure Data Box Edge"
    ],
    "answer": "BD",
    "answerDescription": "",
    "votes": [
      {
        "answer": "BD",
        "count": 9,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-05-21T14:25:00.000Z",
        "voteCount": 18,
        "content": "Correct answer. Azure Data factory with Self Hosted Integration Runtime (installed on premise) can move the data to data lake storage"
      },
      {
        "date": "2021-07-10T23:45:00.000Z",
        "voteCount": 1,
        "content": "why to ADLS? why not directly to Synapse?"
      },
      {
        "date": "2022-01-05T10:10:00.000Z",
        "voteCount": 2,
        "content": "Yes, we could even ask \"why ADF ?\" :\n\nOK Data Factory is made for ETL and Data Lake for storage, but...\n\nWhat is the link with Databricks and Synapse as mentioned in the question ??\nIt is said that we want to perform the ETL job with Databricks and to store data into Synapse, so why would we use two more resources when Databrick can directly connect to Oracle and to Synapse ?\nIt is just a matter of what script we use\n\nIt works, but ADLS is useless, and if we use ADF we should not use Databricks, and vice versa\n\nAnswer is correct but stupid"
      },
      {
        "date": "2021-12-18T02:40:00.000Z",
        "voteCount": 7,
        "content": "Correct. App1 data -&gt; ADF -&gt; A Storage Lake -&gt; Azure Databricks , Synapse Analytics"
      },
      {
        "date": "2022-10-07T00:46:00.000Z",
        "voteCount": 1,
        "content": "https://learn.microsoft.com/en-us/azure/synapse-analytics/sql-data-warehouse/sql-data-warehouse-overview-what-is\n\nhttps://azure.microsoft.com/en-in/solutions/architecture/modern-data-warehouse/\n\nhttps://learn.microsoft.com/en-us/azure/architecture/solution-ideas/media/enterprise-data-warehouse.png\n\nAzure Databricks is placed after 2, as this grants the ability to provide on-click streamlined workflows to prepare and train data.\n\nAzure Data Factory is used for data integration that allows you to create, schedule and orchestrate extract, transform and load (ELT) workloads.\n\nFor storing the data, you can use Azure Data Lake as this is a highly scalable and cost-effective data lake (storage) solution for big data analytics."
      },
      {
        "date": "2022-08-11T05:48:00.000Z",
        "voteCount": 1,
        "content": "Why this can be confusing. To create Azure Synapse analytics, you first must create an ADLS. So at this point, I am assuming that because we have already got an ADLS, there's got to be another option. \n\nI guess the key here is to know that the other options are absolutely a no."
      },
      {
        "date": "2022-03-14T22:39:00.000Z",
        "voteCount": 1,
        "content": "Correct"
      },
      {
        "date": "2022-03-14T00:18:00.000Z",
        "voteCount": 1,
        "content": "Correct answer"
      },
      {
        "date": "2022-02-01T21:15:00.000Z",
        "voteCount": 1,
        "content": "Data Box Edge also provides a computing platform via IoT Edge, which lets you deploy Azure services and custom code and applications to the edge. This means that you can analyze, filter, or transform your data right at the edge as part of your workflow. \nData Box Edge acts as a storage gateway, creating a link between your site and Azure storage. This makes moving data into and out of Azure storage as easy as working with a local network share.\n\nCan this be Azure Data Box Edge &amp; ADLS?"
      },
      {
        "date": "2022-01-02T00:20:00.000Z",
        "voteCount": 1,
        "content": "Answer is CORRECT"
      },
      {
        "date": "2021-12-23T03:37:00.000Z",
        "voteCount": 3,
        "content": "Appere on exam 23-dec-2021"
      },
      {
        "date": "2021-10-04T23:34:00.000Z",
        "voteCount": 4,
        "content": "This is correct\n\nData Lake to store the data and Data Factory for the ETL process"
      },
      {
        "date": "2021-08-29T23:19:00.000Z",
        "voteCount": 2,
        "content": "Correct"
      },
      {
        "date": "2021-07-14T03:50:00.000Z",
        "voteCount": 1,
        "content": "Azure Synapse uses Azure Data Lake Storage Gen2 as a data warehouse and a consistent data model that incorporates administration, monitoring and metadata management sections."
      },
      {
        "date": "2021-05-03T08:15:00.000Z",
        "voteCount": 3,
        "content": "Correct answer"
      },
      {
        "date": "2021-05-02T11:07:00.000Z",
        "voteCount": 3,
        "content": "Answer is correct"
      }
    ],
    "examNameCode": "az-304",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 21,
    "url": "https://www.examtopics.com/discussions/microsoft/view/48352-exam-az-304-topic-3-question-21-discussion/",
    "body": "You have 100 devices that write performance data to Azure Blob storage.<br>You plan to store and analyze the performance data in an Azure SQL database.<br>You need to recommend a solution to move the performance data to the SQL database.<br>What should you include in the recommendation?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure Database Migration Service",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure Data Factory\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure Data Box",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tData Migration Assistant"
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 7,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-04-02T04:52:00.000Z",
        "voteCount": 90,
        "content": "A. Azure Database Migration Service - migrates the database from on-prem to Azure\n    B. Azure Data Factory - the remaining correct answer\n    C. Azure Data Box - physically move the data, has no business here\n    D. Data Migration Assistant -- migrates the database from on-prem to Azure (helper)"
      },
      {
        "date": "2021-11-19T07:42:00.000Z",
        "voteCount": 2,
        "content": "thanks for the explanation"
      },
      {
        "date": "2021-03-28T04:22:00.000Z",
        "voteCount": 6,
        "content": "The answer is correct"
      },
      {
        "date": "2022-04-09T04:29:00.000Z",
        "voteCount": 2,
        "content": "In AZ-305 exam, 9 april 22"
      },
      {
        "date": "2022-03-14T22:40:00.000Z",
        "voteCount": 5,
        "content": "Always Data Factory \ud83d\ude02"
      },
      {
        "date": "2022-03-14T00:21:00.000Z",
        "voteCount": 1,
        "content": "Correct answer"
      },
      {
        "date": "2021-12-24T03:42:00.000Z",
        "voteCount": 3,
        "content": "On exam 24.12.2021"
      },
      {
        "date": "2021-12-20T01:44:00.000Z",
        "voteCount": 1,
        "content": "Correct answer"
      },
      {
        "date": "2021-10-04T23:36:00.000Z",
        "voteCount": 2,
        "content": "This is B for sure"
      },
      {
        "date": "2021-08-29T23:20:00.000Z",
        "voteCount": 2,
        "content": "correct"
      },
      {
        "date": "2021-06-03T09:01:00.000Z",
        "voteCount": 4,
        "content": "Seems correct"
      },
      {
        "date": "2022-02-12T14:02:00.000Z",
        "voteCount": 1,
        "content": "seems legit"
      }
    ],
    "examNameCode": "az-304",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 22,
    "url": "https://www.examtopics.com/discussions/microsoft/view/47213-exam-az-304-topic-3-question-22-discussion/",
    "body": "HOTSPOT -<br>You have a web application that uses a MongoDB database. You plan to migrate the web application to Azure.<br>You must migrate to Cosmos DB while minimizing code and configuration changes.<br>You need to design the Cosmos DB configuration.<br>What should you recommend? To answer, select the appropriate values in the answer area.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04027/0016400001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04027/0016500001.png\" class=\"in-exam-image\">",
    "answerDescription": "MongoDB compatibility: API -<br><br>API: MongoDB API -<br>Azure Cosmos DB comes with multiple APIs:<br>\u2711 SQL API, a JSON document database service that supports SQL queries. This is compatible with the former Azure DocumentDB.<br>\u2711 MongoDB API, compatible with existing Mongo DB libraries, drivers, tools and applications.<br>\u2711 Cassandra API, compatible with existing Apache Cassandra libraries, drivers, tools, and applications.<br>\u2711 Azure Table API, a key-value database service compatible with existing Azure Table Storage.<br>\u2711 Gremlin (graph) API, a graph database service supporting Apache Tinkerpop's graph traversal language, Gremlin.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/cosmos-db/create-mongodb-dotnet",
    "votes": [],
    "comments": [
      {
        "date": "2021-03-18T08:04:00.000Z",
        "voteCount": 55,
        "content": "Account\nMongoDB API"
      },
      {
        "date": "2021-05-01T19:31:00.000Z",
        "voteCount": 3,
        "content": "Hello all, I think answer could be Database or API for Part 1 and MongoDB API for Part 2.\nHow Account could be an answer. Could you share documentation or on what basis it can be Account. Please, I would like to get documentation to refer, thanks !"
      },
      {
        "date": "2021-05-22T08:57:00.000Z",
        "voteCount": 1,
        "content": "Account and MongoDB API.\nGet started with an account https://docs.microsoft.com/en-us/azure/cosmos-db/create-mongodb-dotnet#create-a-database-account"
      },
      {
        "date": "2021-05-17T00:12:00.000Z",
        "voteCount": 1,
        "content": "Agreed: I guess this is account as the MongoDB version compatibility is set when you create the CosmosDB account and attached to the account (as well as the MongoDB API btw)."
      },
      {
        "date": "2021-07-28T04:53:00.000Z",
        "voteCount": 12,
        "content": "first should be API. The question is not what to do first, but to ensure compatibility. According to docs, that's done through the API. See ref: \nhttps://docs.microsoft.com/en-us/azure/cosmos-db/mongodb-introduction#how-the-api-works"
      },
      {
        "date": "2021-11-19T08:12:00.000Z",
        "voteCount": 3,
        "content": "Yes, I think you're right and the question is a little misleading. Trying to translate the meaning of the question we can say it states what are the step you have to do in order to CONFIGURE a Cosmos DB Account. So you have a cosmos db account and you need to do some configuration to guarantee compatibility with a Mongo DB database. So the first thing you have to choose for this configuration is the API. The second is which API specifically. Maybe a bit demented but this is only explanation i can find."
      },
      {
        "date": "2021-05-29T03:57:00.000Z",
        "voteCount": 6,
        "content": "Account\nMongoDB API \nare the correct answers.\n\nhttps://docs.microsoft.com/en-us/azure/cosmos-db/create-mongodb-nodejs#create-an-azure-cosmos-db-account\n\naz cosmosdb create --name &lt;cosmosdb-name&gt; --resource-group myResourceGroup --kind MongoDB\n\nThe --kind MongoDB parameter enables MongoDB client connections."
      },
      {
        "date": "2021-06-13T21:44:00.000Z",
        "voteCount": 22,
        "content": "This question is bit confusing. Second option is very obvious but first one is very strange. Azure CosmosDB, in fact, does not host any database engine for MongoDB therefore 'Database' and/or 'Collection' would not be correct selection.\n\nSo it is either 'API' or 'Account'. Account because we specify MongoDB Server version we want to use for the account. But it is my understanding that CosmosDB uses wire protocol, meaning that MongoDB compatibility (i.e. Server version) is equivalent to API version. This is why we do not have create new Account to upgrade or downgrade MongoDB API. In addition, development team needs to know MongoDB Server (i.e. API) version to connect to it (or using SDK). \n\nSo if this question comes up and even if I get a wrong mark, I would go with\n\n- API\n- MongoDB API\n\nThat's because when we investigate compatibility to migrate, I would assess MongoDB server and API version we use currently, and configure 'version' field when creating CosmosDB account."
      },
      {
        "date": "2022-07-02T09:13:00.000Z",
        "voteCount": 2,
        "content": "Here's a handy little tutorial. Given answers are correct.\n\nhttps://docs.microsoft.com/en-us/azure/cosmos-db/mongodb/tutorial-mongotools-cosmos-db"
      },
      {
        "date": "2022-05-31T07:05:00.000Z",
        "voteCount": 1,
        "content": "1- API  \nFirst thing you have to choose for this configuration is the API. \n2- MongoDB API\nThe second is which API specifically."
      },
      {
        "date": "2022-04-25T17:52:00.000Z",
        "voteCount": 1,
        "content": "Just tested. When you go to the portal and select Create Cosmos DB, the first selection is --- Which API best suits your workload? So the provided answer is correct."
      },
      {
        "date": "2022-03-09T23:50:00.000Z",
        "voteCount": 1,
        "content": "API\nMongoDB AP"
      },
      {
        "date": "2022-02-12T14:10:00.000Z",
        "voteCount": 1,
        "content": "api/mongo api"
      },
      {
        "date": "2022-01-21T20:18:00.000Z",
        "voteCount": 2,
        "content": "It should be API / MongoDB API.\nFor the first one, if you create a CosmosDB via the Portal, you can see that it clearly prompts \"Select API option &gt; Which API best suits your workload?\" as the first step of setting up an account.\nThe question specifically asks about \"MongoDB COMPATIBILITY\". It is the API you select that make it compatible. not the account. As the account is only a logical container."
      },
      {
        "date": "2021-12-23T03:38:00.000Z",
        "voteCount": 3,
        "content": "Appere on exam 23-dec-2021"
      },
      {
        "date": "2021-11-13T03:02:00.000Z",
        "voteCount": 1,
        "content": "Account - version compatibility is selected at the account level during the creation\nMongoDB API -"
      },
      {
        "date": "2021-11-13T03:03:00.000Z",
        "voteCount": 3,
        "content": "I have reviewed the question again:\n\"MongoDB compatibility\" -&gt; it is at API level\nSo answer should be:\nAPI\nMongoDB API"
      },
      {
        "date": "2021-10-30T01:45:00.000Z",
        "voteCount": 2,
        "content": "API\nMongoDB API"
      },
      {
        "date": "2021-10-08T10:43:00.000Z",
        "voteCount": 1,
        "content": "API and MongoDB API."
      },
      {
        "date": "2021-10-04T23:45:00.000Z",
        "voteCount": 3,
        "content": "https://docs.microsoft.com/en-us/azure/cosmos-db/mongodb/create-mongodb-nodejs#create-an-azure-cosmos-db-account\n\nCreate an account for CosmosDB first so compatibility is Account\n\nAPI is definitely Mongo"
      },
      {
        "date": "2021-09-25T11:55:00.000Z",
        "voteCount": 4,
        "content": "API and MongoDB API\nfor 1) Azure Cosmos DB API for MongoDB implements the wire protocol for MongoDB. This implementation allows transparent compatibility with native MongoDB client SDKs, drivers, and tools. Azure Cosmos DB does not host the MongoDB database engine. Any MongoDB client driver compatible with the API version you are using should be able to connect, with no special configuration.\nhttps://docs.microsoft.com/en-us/azure/cosmos-db/mongodb/mongodb-introduction#how-the-api-works"
      },
      {
        "date": "2021-09-17T18:09:00.000Z",
        "voteCount": 2,
        "content": "about API, the 2nd question is about it, no idea about question 1, I would go for Collection."
      },
      {
        "date": "2021-08-19T22:04:00.000Z",
        "voteCount": 1,
        "content": "Maybe question 1 is not referring to any Azure setting at all, but just 'on which level will this solution be MongoDB compatible', and that would be 'API'?"
      },
      {
        "date": "2021-07-08T06:47:00.000Z",
        "voteCount": 4,
        "content": "The answer is correct, First box you choose API then in the second box it asks, but which API, then you choose, MongoDB API. This is a straight forward question. Too many answers here."
      }
    ],
    "examNameCode": "az-304",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 23,
    "url": "https://www.examtopics.com/discussions/microsoft/view/30000-exam-az-304-topic-3-question-23-discussion/",
    "body": "You have 100 servers that run Windows Server 2012 R2 and host Microsoft SQL Server 2014 instances. The instances host databases that have the following characteristics:<br>\u2711 The largest database is currently 3 TB. None of the databases will ever exceed 4 TB.<br>\u2711 Stored procedures are implemented by using CLR.<br>You plan to move all the data from SQL Server to Azure.<br>You need to recommend an Azure service to host the databases. The solution must meet the following requirements:<br>\u2711 Whenever possible, minimize management overhead for the migrated databases.<br>\u2711 Minimize the number of database changes required to facilitate the migration.<br>\u2711 Ensure that users can authenticate by using their Active Directory credentials.<br>What should you include in the recommendation?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure SQL Database elastic pools",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure SQL Database Managed Instance\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure SQL Database single databases",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSQL Server 2016 on Azure virtual machines"
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 8,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2020-08-29T06:02:00.000Z",
        "voteCount": 39,
        "content": "B is the correct answer. Azure SQL DB does not support CLR stored procedure:\n\nref: https://docs.microsoft.com/en-gb/azure/azure-sql/database/transact-sql-tsql-differences-sql-server#transact-sql-syntax-not-supported-in-azure-sql-database\nref: https://docs.microsoft.com/en-us/azure/azure-sql/managed-instance/transact-sql-tsql-differences-sql-server#clr"
      },
      {
        "date": "2022-03-08T09:58:00.000Z",
        "voteCount": 1,
        "content": "D. SQL Server 2016 in VM Azure vs B.Azure SQL Managed Instance\nCLR Integration - Enabling for both.\nhttps://docs.microsoft.com/en-us/sql/relational-databases/clr-integration/clr-integration-enabling?view=sql-server-ver15\nSo the issue here is: who supports Active Directory authentication?\n- Directly it would be \"D\".\n- Through Azure AD Connect it would be \"B\". (doesn't mention Azure AD)\nCorrect answer is D"
      },
      {
        "date": "2021-11-22T04:19:00.000Z",
        "voteCount": 4,
        "content": "Correct\n\n SQL Managed Instance enables you to move your on-premises applications to Azure with minimal application or database changes. \n\nhttps://docs.microsoft.com/en-us/azure/azure-sql/migration-guides/managed-instance/sql-server-to-managed-instance-overview#overview"
      },
      {
        "date": "2020-11-07T13:13:00.000Z",
        "voteCount": 21,
        "content": "Correct:\n\nSQL Managed Instance allows existing SQL Server customers to lift and shift their on-premises applications to the cloud with minimal application and database changes. At the same time, SQL Managed Instance preserves all PaaS capabilities (automatic patching and version updates, automated backups, high availability) that drastically reduce management overhead and TCO."
      },
      {
        "date": "2021-03-21T13:31:00.000Z",
        "voteCount": 4,
        "content": "why not D?"
      },
      {
        "date": "2021-05-20T01:33:00.000Z",
        "voteCount": 9,
        "content": "Logically, even we don't know about the answer or explanation, but we know that Microsoft will promote their native product, D is not, B is.\nFundamental of guessing :)"
      },
      {
        "date": "2021-03-30T22:39:00.000Z",
        "voteCount": 5,
        "content": "Because of \"Whenever possible, minimize management overhead for the migrated databases\". Managed instance does not require for you to do VM and SQL updates, this is done by Microsoft."
      },
      {
        "date": "2021-05-16T06:30:00.000Z",
        "voteCount": 2,
        "content": "same applies for Azure SQL so what's your point here"
      },
      {
        "date": "2021-06-16T07:32:00.000Z",
        "voteCount": 2,
        "content": "Azure SQL is PaaS, all service is mantained by Microsoft. VM with SQL is IaaS, so you need to maintain updates, OS, patches etc. So this is the reason D is not an option here."
      },
      {
        "date": "2021-08-14T02:08:00.000Z",
        "voteCount": 1,
        "content": "No, it explicitly states they need to login using Active Directory credentials. Azure SQL and MI are both out since they only support Azure AD. It's carefully worded as \"Wherever possible\" rather than an explicit requirement. Therefore D is the only option that works."
      },
      {
        "date": "2022-03-08T09:58:00.000Z",
        "voteCount": 1,
        "content": "D. SQL Server 2016 in VM Azure vs B.Azure SQL Managed Instance\nCLR Integration - Enabling for both.\nhttps://docs.microsoft.com/en-us/sql/relational-databases/clr-integration/clr-integration-enabling?view=sql-server-ver15\nSo the issue here is: who supports Active Directory authentication?\n- Directly it would be \"D\".\n- Through Azure AD Connect it would be \"B\". (doesn't mention Azure AD)\nCorrect answer is D"
      },
      {
        "date": "2023-07-09T21:47:00.000Z",
        "voteCount": 1,
        "content": "With the Common Language Runtime (CLR) hosted in Microsoft SQL Server (called CLR integration), you can author stored procedures, triggers, user-defined functions, user-defined types, and user-defined aggregates in managed code. CLR is also available in Azure SQL Database Managed Instance.\n\nhttps://learn.microsoft.com/en-us/shows/data-exposed/its-just-sql-clr-in-azure-sql-database-managed-instance"
      },
      {
        "date": "2023-02-12T10:53:00.000Z",
        "voteCount": 1,
        "content": "Answer is correct;\nLet me explain;\n1\n\"Azure SQL Managed Instance is ideal for customers interested in instance-scoped features, such as SQL Server Agent, Common language runtime (CLR), Database Mail, Distributed transactions, and Machine Learning Services.\"\n2\nYou can use SQL Managed Instance to do lift-and-shift migrations to Azure without having to redesign your applications.\n\nLink\nhttps://learn.microsoft.com/en-us/training/modules/design-data-storage-solution-for-relational-data/3-design-for-azure-sql-managed-instance#:~:text=You%20can%20use,Machine%20Learning%20Services."
      },
      {
        "date": "2022-06-14T04:40:00.000Z",
        "voteCount": 1,
        "content": "Though the clr enabled configuration option is enabled in Azure SQL Database, developing CLR user functions are not supported in Azure SQL Database.\nB"
      },
      {
        "date": "2022-03-14T00:29:00.000Z",
        "voteCount": 1,
        "content": "Correct answer"
      },
      {
        "date": "2022-03-09T23:52:00.000Z",
        "voteCount": 1,
        "content": "Azure SQL Database Managed Instance"
      },
      {
        "date": "2022-01-29T08:22:00.000Z",
        "voteCount": 6,
        "content": "A. Azure SQL Database elastic pools - Doesn't support CLR\nB. Azure SQL Database Managed Instance - Correct answer\nC. Azure SQL Database single databases - Doesn't support CLR\nD. SQL Server 2016 on Azure virtual machines - Doesn't minimize cost."
      },
      {
        "date": "2021-12-11T08:47:00.000Z",
        "voteCount": 2,
        "content": "Can anyone suggest me How we are ruling out the option. A - with Elastic pool. Manage Instance and Elastic pool - both will serve the purpose , i believe , But Elastic pool is cheaper . In Microsoft ESI portal Mock Test , Similar Question is answered with Elastic Pool . So i am little confused here with Option B - Managed Instance which is bit more expensive than the elastic Pool."
      },
      {
        "date": "2021-11-18T06:27:00.000Z",
        "voteCount": 1,
        "content": "The Correct Answer is the D we are not talking about hybrid environment so to use AD for authentication the correct answer is the D"
      },
      {
        "date": "2022-01-21T10:16:00.000Z",
        "voteCount": 1,
        "content": "How do you plan to use AD for authentication on an Azure VM if you don't have a hybrid domain?"
      },
      {
        "date": "2021-10-05T05:53:00.000Z",
        "voteCount": 1,
        "content": "\"minimize management overhead\"\n\nI would go for B"
      },
      {
        "date": "2022-03-08T09:56:00.000Z",
        "voteCount": 1,
        "content": "if you migrate to sql server in VM you are minimizing the changes. since it is the same platform. Answer is D."
      },
      {
        "date": "2021-08-29T23:21:00.000Z",
        "voteCount": 1,
        "content": "correct"
      },
      {
        "date": "2021-06-13T20:30:00.000Z",
        "voteCount": 7,
        "content": "there are 3 key requirements that we need to consider.\n1. CLR\n2. Active Directory (and I believe this is not Azure AD).\n3. Minimum Changes\n\nWith Azure SQL Server, and MI, even with Azure AD is integrated with Admin operation. And I do not believe Window Authentication is supported for both of option. \n\nEven with CLR, there are few functions that are not support. Access to File System. We do not know what CLR does and we cannot predict changes that the limitation would cause. \n\nIn addition, client does not seem mind managing the server by themselves. It seems like there are willing to manage patching and upgrade as they are more concerns around changes/impact/risks comes with migration.\n\nBased upon above, SQL using VM should be recommended."
      },
      {
        "date": "2021-06-17T18:40:00.000Z",
        "voteCount": 4,
        "content": "plus they mention db size won't excide 4Gb"
      },
      {
        "date": "2021-08-01T10:57:00.000Z",
        "voteCount": 2,
        "content": "You are right, it shuld be D. Azure SQL MI does to support AD on-premises logons. As we move our DM from on-premises, the:\n\"by using their Active Directory credentials\"\nmeans that Windows Logon type must be supported."
      },
      {
        "date": "2021-08-19T22:48:00.000Z",
        "voteCount": 2,
        "content": "Per the link below, Azure SQL MI does support AD auth with on-premise credentials if you use SSO ... \n\nhttps://docs.microsoft.com/en-us/azure/azure-sql/database/authentication-aad-configure?tabs=azure-powershell"
      },
      {
        "date": "2021-08-22T07:09:00.000Z",
        "voteCount": 2,
        "content": "Yes, I would agree with you if  SSO is used. But is not. \nMore about the workaround mentioned by you is here:\nhttps://docs.microsoft.com/en-us/azure/azure-sql/database/authentication-mfa-ssms-overview"
      },
      {
        "date": "2021-08-19T22:47:00.000Z",
        "voteCount": 2,
        "content": "Tricky. SQL Server on VM (D) \"is the only way to use Windows authentication to SQL Server.\" On the other hand, SQL Managed Instance supports \"Active Directory integrated authentication ... Use this method if you are logged into Windows using your Azure Active Directory credentials from a federated domain, or a managed domain that is configured for seamless single sign-on for pass-through and password hash authentication.\"\n\nSince they are asking what to INCLUDE in the solution (not for the COMPLETE solution), we could include SQL Managed Instance AND AD Connect with SSO in the solution. Then B would work."
      },
      {
        "date": "2022-03-08T09:54:00.000Z",
        "voteCount": 1,
        "content": "D. SQL Server 2016 in VM Azure  vs  B.Azure SQL Managed Instance \nCLR Integration - Enabling for both.\nhttps://docs.microsoft.com/en-us/sql/relational-databases/clr-integration/clr-integration-enabling?view=sql-server-ver15\nSo the issue here is: who supports Active Directory authentication?\n- Directly it would be \"D\".\n- Through Azure AD Connect it would be \"B\". (doesn't mention Azure AD)\nCorrect answer is D"
      },
      {
        "date": "2021-03-26T15:54:00.000Z",
        "voteCount": 3,
        "content": "Shouldnt the answer be D as it requires Windows AD authentication? Azure SQL MI doesnt support Windows Authentication"
      },
      {
        "date": "2021-03-27T23:44:00.000Z",
        "voteCount": 1,
        "content": "Azure Active Directory (Azure AD) authentication - Azure SQL: Yes. Azure AD users only.\tSQL Managed Instance: Yes. Including server-level Azure AD logins."
      },
      {
        "date": "2022-03-08T09:54:00.000Z",
        "voteCount": 1,
        "content": "D. SQL Server 2016 in VM Azure  vs  B.Azure SQL Managed Instance \nCLR Integration - Enabling for both.\nhttps://docs.microsoft.com/en-us/sql/relational-databases/clr-integration/clr-integration-enabling?view=sql-server-ver15\nSo the issue here is: who supports Active Directory authentication?\n- Directly it would be \"D\".\n- Through Azure AD Connect it would be \"B\". (doesn't mention Azure AD)\nCorrect answer is D"
      },
      {
        "date": "2021-01-24T17:55:00.000Z",
        "voteCount": 3,
        "content": "B. Azure SQL Database Managed Instance"
      },
      {
        "date": "2021-01-21T14:17:00.000Z",
        "voteCount": 9,
        "content": "CLR is support by SQL Managed instance only. Ans is correct."
      },
      {
        "date": "2021-11-15T08:11:00.000Z",
        "voteCount": 1,
        "content": "CLR also works on SQL on VM.\nI believe the answer should be D, SQL VM, as AD login not supported on MI."
      },
      {
        "date": "2022-03-08T09:53:00.000Z",
        "voteCount": 1,
        "content": "correct.\nD. SQL Server 2016 in VM Azure  vs  B.Azure SQL Managed Instance \nCLR Integration - Enabling for both.\nhttps://docs.microsoft.com/en-us/sql/relational-databases/clr-integration/clr-integration-enabling?view=sql-server-ver15\nSo the issue here is: who supports Active Directory authentication?\n- Directly it would be \"D\".\n- Through Azure AD Connect it would be \"B\". (doesn't mention Azure AD)\nCorrect answer is D"
      },
      {
        "date": "2020-12-12T15:00:00.000Z",
        "voteCount": 2,
        "content": "in exam this week"
      }
    ],
    "examNameCode": "az-304",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 24,
    "url": "https://www.examtopics.com/discussions/microsoft/view/48791-exam-az-304-topic-3-question-24-discussion/",
    "body": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.<br>After you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.<br>You have an Azure Storage account that contains two 1-GB data files named File1 and File2. The data files are set to use the archive access tier.<br>You need to ensure that File1 is accessible immediately when a retrieval request is initiated.<br>Solution: For File1, you set Access tier to Hot.<br>Does this meet the goal?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tYes\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tNo"
    ],
    "answer": "A",
    "answerDescription": "The hot access tier has higher storage costs than cool and archive tiers, but the lowest access costs. Example usage scenarios for the hot access tier include:<br>\u2711 Data that's in active use or expected to be accessed (read from and written to) frequently.<br>\u2711 Data that's staged for processing and eventual migration to the cool access tier.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blob-storage-tiers",
    "votes": [
      {
        "answer": "A",
        "count": 1,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-04-15T00:07:00.000Z",
        "voteCount": 25,
        "content": "The Answer is correct and to clear up the confusion.\nFile != File Share\nIn this case the File should be called a blob\nArchive Tier is only available for Blob Storage and Blob Containers\nIn a Blob Container you can set the Access-Tier per blob"
      },
      {
        "date": "2022-01-21T20:31:00.000Z",
        "voteCount": 7,
        "content": "never had this confusion... but thanks anyway :)"
      },
      {
        "date": "2021-09-20T04:24:00.000Z",
        "voteCount": 8,
        "content": "came in exam on 20-sep-21, I passed, i choose given answer"
      },
      {
        "date": "2022-08-11T06:09:00.000Z",
        "voteCount": 1,
        "content": "While the answwer is correct, the question is bad. Because they start with saying that both files are set to use Archive tier. This is enough to confuse."
      },
      {
        "date": "2022-03-14T22:41:00.000Z",
        "voteCount": 1,
        "content": "I think it is correct"
      },
      {
        "date": "2022-03-04T11:03:00.000Z",
        "voteCount": 4,
        "content": "\"You need to ensure that File1 is accessible immediately when ***a retrieval request is initiated***.\" If it is in archive, even changing to Hot is impossible to be immediately available, isn\u00b4t it?"
      },
      {
        "date": "2021-06-17T18:46:00.000Z",
        "voteCount": 1,
        "content": "Why Hot but not Cool?"
      },
      {
        "date": "2021-06-22T07:37:00.000Z",
        "voteCount": 9,
        "content": "This is a series of question, each one will provide different solutions and we have to check if the solution will meet the goal or not. Both hot and cool are correct. Maybe on next question, the solution that will be provide is \"Hot\""
      },
      {
        "date": "2021-04-02T05:21:00.000Z",
        "voteCount": 2,
        "content": "This is really confusing. YES - you set the Hot tier but NO - you can't set it for file, you set it for the whole storage.\n\nI guess the expected answer here is still A (Yes) but the question itself is incorrect"
      },
      {
        "date": "2021-04-02T06:03:00.000Z",
        "voteCount": 6,
        "content": "Disregard that. It's possible to set the tier per file. The answer Yes is correct"
      },
      {
        "date": "2022-01-10T23:48:00.000Z",
        "voteCount": 1,
        "content": "You're right:\n\"Storage accounts have a default access tier setting that indicates the online tier in which a new blob is created. The default access tier setting can be set to either Hot or Cool. Users can override the default setting for an individual blob when uploading the blob or changing its tier\".\nhttps://docs.microsoft.com/en-us/azure/storage/blobs/access-tiers-overview"
      }
    ],
    "examNameCode": "az-304",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 25,
    "url": "https://www.examtopics.com/discussions/microsoft/view/49709-exam-az-304-topic-3-question-25-discussion/",
    "body": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.<br>After you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.<br>You have an Azure Storage account that contains two 1-GB data files named File1 and File2. The data files are set to use the archive access tier.<br>You need to ensure that File1 is accessible immediately when a retrieval request is initiated.<br>Solution: You add a new file share to the storage account.<br>Does this meet the goal?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tYes",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tNo\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 4,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-04-09T05:43:00.000Z",
        "voteCount": 13,
        "content": "correct"
      },
      {
        "date": "2022-03-14T22:42:00.000Z",
        "voteCount": 2,
        "content": "Correct"
      },
      {
        "date": "2022-03-14T22:42:00.000Z",
        "voteCount": 1,
        "content": "Correct"
      },
      {
        "date": "2022-03-14T00:31:00.000Z",
        "voteCount": 1,
        "content": "Correct"
      },
      {
        "date": "2022-03-05T04:03:00.000Z",
        "voteCount": 1,
        "content": "Correct answer given"
      },
      {
        "date": "2021-10-03T17:16:00.000Z",
        "voteCount": 3,
        "content": "Answer is No\n\nIt's the access tier you need to change"
      },
      {
        "date": "2021-09-20T04:24:00.000Z",
        "voteCount": 3,
        "content": "came in exam on 20-sep-21, I passed, i choose given answer"
      },
      {
        "date": "2021-08-13T13:21:00.000Z",
        "voteCount": 1,
        "content": "Correct.  But this is not a good question.\n\nAs other have pointed out, Azure file share does NOT have an archive tier (https://docs.microsoft.com/en-us/azure/storage/files/storage-how-to-create-file-share?tabs=azure-portal) .  Only 3 tiers are available, Transaction optimized, Hot, Cool.\n\nPerhaps creating an Azure file share is the first step in rehydrating the data.  Moving data to Cool / hot tier is rehydrating.  However, the question stops short in just stating creating a file share, which does nothing to the original data."
      },
      {
        "date": "2021-08-02T05:14:00.000Z",
        "voteCount": 1,
        "content": "What a crap question, if it is intended to check the knowledge on the access tier  should be NO, otherwise YES"
      },
      {
        "date": "2021-07-15T06:24:00.000Z",
        "voteCount": 2,
        "content": "archive tier, should be No?"
      },
      {
        "date": "2021-07-10T21:32:00.000Z",
        "voteCount": 2,
        "content": "If files stored in File Share are not accessible immediately, then how long will take when user access the file? \n\nAnswer is A"
      },
      {
        "date": "2021-06-24T09:00:00.000Z",
        "voteCount": 2,
        "content": "question without foot or head....\nThis question is about the TIER, not the storage type."
      },
      {
        "date": "2021-06-08T04:27:00.000Z",
        "voteCount": 2,
        "content": "I think the answer is A.\nFile share of Azure storage account provides immediate access."
      },
      {
        "date": "2021-08-19T22:51:00.000Z",
        "voteCount": 1,
        "content": "Not if it's in the archive tier: \"Data in the archive tier can take several hours to retrieve depending on the specified rehydration priority.\"\n\nhttps://github.com/MicrosoftDocs/azure-docs/blob/master/articles/storage/blobs/storage-blob-storage-tiers.md"
      },
      {
        "date": "2022-04-16T08:25:00.000Z",
        "voteCount": 1,
        "content": "slow and high reterival cost"
      }
    ],
    "examNameCode": "az-304",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 26,
    "url": "https://www.examtopics.com/discussions/microsoft/view/49808-exam-az-304-topic-3-question-26-discussion/",
    "body": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.<br>After you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.<br>You have an Azure Storage account that contains two 1-GB data files named File1 and File2. The data files are set to use the archive access tier.<br>You need to ensure that File1 is accessible immediately when a retrieval request is initiated.<br>Solution: You move File1 to a new storage account. For File1, you set Access tier to Archive.<br>Does this meet the goal?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tYes",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tNo\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "B",
    "answerDescription": "Instead use the hot access tier.<br>The hot access tier has higher storage costs than cool and archive tiers, but the lowest access costs. Example usage scenarios for the hot access tier include:<br>Data that's in active use or expected to be accessed (read from and written to) frequently.<br><img src=\"/assets/media/exam-media/04027/0016800001.png\" class=\"in-exam-image\"><br>\u2711 Data that's staged for processing and eventual migration to the cool access tier.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blob-storage-tiers",
    "votes": [
      {
        "answer": "B",
        "count": 2,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-04-10T08:08:00.000Z",
        "voteCount": 20,
        "content": "Correct"
      },
      {
        "date": "2021-09-27T06:09:00.000Z",
        "voteCount": 5,
        "content": "https://docs.microsoft.com/en-us/azure/storage/blobs/archive-rehydrate-overview?tabs=azure-portal\n\nWhile a blob is in the archive access tier, it's considered to be offline and can't be read or modified. In order to read or modify data in an archived blob, you must first rehydrate the blob to an online tier, either the hot or cool tier. There are two options for rehydrating a blob that is stored in the archive tier:\n\nCopy an archived blob to an online tier: You can rehydrate an archived blob by copying it to a new blob in the hot or cool tier with the Copy Blob or Copy Blob from URL operation. Microsoft recommends this option for most scenarios.\n\nChange a blob's access tier to an online tier: You can rehydrate an archived blob to hot or cool by changing its tier using the Set Blob Tier operation.\n\nAnswer is No"
      },
      {
        "date": "2022-03-14T22:42:00.000Z",
        "voteCount": 1,
        "content": "Correct"
      },
      {
        "date": "2022-03-14T00:31:00.000Z",
        "voteCount": 1,
        "content": "Correct"
      },
      {
        "date": "2022-03-06T10:21:00.000Z",
        "voteCount": 1,
        "content": "It's No. \n\nBut the comment \"Instead use the hot access tier\" is wrong. At least partially.\nAs the Hot &amp; Cool access tiers will enable \"Immediate access\""
      }
    ],
    "examNameCode": "az-304",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 27,
    "url": "https://www.examtopics.com/discussions/microsoft/view/38412-exam-az-304-topic-3-question-27-discussion/",
    "body": "You are designing an order processing system in Azure that will contain the Azure resources shown in the following table.<br><img src=\"/assets/media/exam-media/04027/0016900002.png\" class=\"in-exam-image\"><br>The order processing system will have the following transaction flow:<br>\u2711 A customer will place an order by using App1.<br>\u2711 When the order is received, App1 will generate a message to check for product availability at vendor 1 and vendor 2.<br>\u2711 An integration component will process the message, and then trigger either Function1 or Function2 depending on the type of order.<br>\u2711 Once a vendor confirms the product availability, a status message for App1 will be generated by Function1 or Function2.<br>\u2711 All the steps of the transaction will be logged to storage1.<br>Which type of resource should you recommend for the integration component?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tan Azure Data Factory pipeline\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tan Azure Service Bus queue",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tan Azure Event Grid domain",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tan Azure Event Hubs capture"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 17,
        "isMostVoted": true
      },
      {
        "answer": "B",
        "count": 13,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2020-12-02T00:17:00.000Z",
        "voteCount": 101,
        "content": "B would be a more appropriate answer"
      },
      {
        "date": "2020-12-03T12:14:00.000Z",
        "voteCount": 12,
        "content": "Agreed, I believe this question is looking us to recognise that messages need be able sent from different application components. A service bus will do this. The actual orchestration via Data Factory doesn't make a lot of sense. Something like Durable (Azure) Functions would be more suited for that."
      },
      {
        "date": "2020-12-02T09:41:00.000Z",
        "voteCount": 4,
        "content": "agreed"
      },
      {
        "date": "2021-05-22T10:07:00.000Z",
        "voteCount": 8,
        "content": "\"An integration component will process the message, and then trigger either Function1 or Function2 depending on the type of order.\"  to me this describes an Event Grid"
      },
      {
        "date": "2021-05-05T07:30:00.000Z",
        "voteCount": 4,
        "content": "Agreed.  There can be a generic trigger associated with the queue and within that trigger logic can determine the order type and execute the correct AZ function.  The trigger can also do the logging.  ADF could work but seems out of place for this task IMO."
      },
      {
        "date": "2021-12-29T09:07:00.000Z",
        "voteCount": 1,
        "content": "Question states \"will process the message, and then trigger EITHER Function1 OR Function2\" (not both)"
      },
      {
        "date": "2020-12-07T06:37:00.000Z",
        "voteCount": 74,
        "content": "Look at the question carefully it states:  \nAn integration component will **process** the message, and then trigger either Function1 or Function2 depending on the type of order.\nThe keyword is process the message neither Service Bus nor Event Grid provide those functionalities. \nThere is not mentioned where you would be storing the message but Azure Data Factory can integerate with various platforms and pick messages and based on that could fire either Function1 or Function2 based on order type."
      },
      {
        "date": "2021-11-06T08:30:00.000Z",
        "voteCount": 1,
        "content": "Event grid supports filtering. Message comes in. Filter the message based on type of order. SImples."
      },
      {
        "date": "2021-07-30T18:07:00.000Z",
        "voteCount": 3,
        "content": "Plus, this \"process\" should be audited, sending data to Azure Storage Acoount. So ADF is correct."
      },
      {
        "date": "2021-04-18T09:36:00.000Z",
        "voteCount": 13,
        "content": "an ETL tool for managing a transaction... mmm smells strange.\n\nBUS has a FIFO option that is necessary for \"check availability\""
      },
      {
        "date": "2020-12-22T22:11:00.000Z",
        "voteCount": 11,
        "content": "Microsoft Azure Service Bus is a fully managed enterprise message broker with message queues and public-subscribe topics. Service Bus is used to decouple applications and services from each other, providing the following benefits:\nLoad-balancing work across competing workers\nSafely routing and transferring data and control across service and application boundaries\nCoordinating transactional work that requires a high-degree of reliability\nIn the question\nWhen the order is received, App1 will generate a message to check for product availability at vendor 1 and vendor 2.\n\nWith Topics the Publisher sends a message to a topic and one or more subscribers receive a copy of the message, depending on filter rules set on these subscriptions.\n\nhttps://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-queues-topics-subscriptions#topics-and-subscriptions"
      },
      {
        "date": "2023-09-02T10:26:00.000Z",
        "voteCount": 1,
        "content": "the problem is that in the answers options you haven't a topic but only the queue service. So ASB can't process to different functions.\nLeaves only A, Azure Data factory"
      },
      {
        "date": "2023-01-15T12:11:00.000Z",
        "voteCount": 1,
        "content": "The requirement can be achieved with Service Bus topics/subscriptions by sending the message based on metadata to subscribers listening to a specific topic.\n\nBut since there is no such answer Factory is second best"
      },
      {
        "date": "2022-09-21T13:42:00.000Z",
        "voteCount": 1,
        "content": "This is what the Service Bus does."
      },
      {
        "date": "2022-08-25T00:58:00.000Z",
        "voteCount": 1,
        "content": "As @tteesstt said before, it's 1:M vs 1:1, it can't be SB.\nA) ADF pipeline"
      },
      {
        "date": "2022-08-11T06:23:00.000Z",
        "voteCount": 4,
        "content": "The answer is correct. I got it wrong at first but after analysis, I have come to understand the question better. \n\nThe messaging, which is probably held using Service bus Topic, is done separately. This question is about the integration component, not the messaging service. ADF will do the processing of the messages, and the trigger F1 and/or F2."
      },
      {
        "date": "2022-06-14T04:54:00.000Z",
        "voteCount": 2,
        "content": "Azure Service Bus\nFIFO\nDelivery guarantee : At-Most-Once \n It stores messages in a \"broker\" (for example, a queue) until the consuming party is ready to receive the messages. \nB"
      },
      {
        "date": "2022-05-19T23:20:00.000Z",
        "voteCount": 1,
        "content": "Where I work it's common to have the front end put messages in a service bus queue/topic to be processed by back end functions. This is critical to avoid the functions from being overwhelmed in busy times. So I'm going service bus.\n\nAlso, I don't know how the ADF which some people are proposing could be triggered to process the message from the web app, in my experience ADF is more for batch processes."
      },
      {
        "date": "2022-04-11T04:01:00.000Z",
        "voteCount": 2,
        "content": "For people who chose B, you obviously didn\u2019t setup and serverless environment with Azure before\u2026 without logging the data to storage you could do with Event Grid to determine the function app to call based on message type but when you need to manage the flow of data to storage account, you will ultimately need ADF or Logic App to handle the logic flow regardless whether you use ADF for ETL or not. \n\nAnswer is Azure Data Factory"
      },
      {
        "date": "2022-03-30T13:54:00.000Z",
        "voteCount": 4,
        "content": "The question clearly asks \u201cWhich type of resource should you recommend for the integration component?\u201d.  The integration component will \u201cprocess the message, and then trigger either Function1 or Function2 depending on the type of order.\u201d  This is not asking how to send the message; it\u2019s asking how to process the message.  I believe the answer is correct, ADF."
      },
      {
        "date": "2022-03-14T22:43:00.000Z",
        "voteCount": 1,
        "content": "I would go with B"
      },
      {
        "date": "2022-03-12T09:22:00.000Z",
        "voteCount": 3,
        "content": "As per below link 'ADF pipeline' can consume message from Web Activity and it support transform as well so it can parse/validate the incoming message and call respective function (1 or 2)..\n\nhttps://docs.microsoft.com/en-us/azure/data-factory/concepts-pipelines-activities?tabs=data-factory#control-flow-activities\n\nI use ASB queue which cannot do message validation by itself to decide which function should be called further.\n\nHowever, ASB Topic can do the expected behavior but it's not mentioned in the answer so i think 'ADF pipeline' is best suitable from the given option."
      },
      {
        "date": "2022-02-15T14:51:00.000Z",
        "voteCount": 2,
        "content": "Answer is Service Bus, no doubt. When to use: Order processing and financial transactions. \nhttps://docs.microsoft.com/en-us/azure/event-grid/compare-messaging-services#comparison-of-services"
      },
      {
        "date": "2022-02-08T18:21:00.000Z",
        "voteCount": 4,
        "content": "Multiple sources confirm it to be Datafactory."
      },
      {
        "date": "2022-02-08T09:52:00.000Z",
        "voteCount": 1,
        "content": "i think is B"
      },
      {
        "date": "2022-02-07T13:47:00.000Z",
        "voteCount": 1,
        "content": "Question asks for a resource. Pipeline is not a resource \"A data factory can have one or more pipelines. A pipeline is a logical grouping of activities that together perform a task.\"\nIf the ADF is correct, it would say A - Azure Data Factory, but it is a Pipeline that is not a resource."
      }
    ],
    "examNameCode": "az-304",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 28,
    "url": "https://www.examtopics.com/discussions/microsoft/view/39126-exam-az-304-topic-3-question-28-discussion/",
    "body": "HOTSPOT -<br>You have an existing implementation of Microsoft SQL Server Integration Services (SSIS) packages stored in an SSISDB catalog on your on-premises network.<br>The on-premises network does not have hybrid connectivity to Azure by using Site-to-Site VPN or ExpressRoute.<br>You want to migrate the packages to Azure Data Factory.<br>You need to recommend a solution that facilitates the migration while minimizing changes to the existing packages. The solution must minimize costs.<br>What should you recommend? To answer, select the appropriate options in the answer area.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04027/0017000001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04027/0017100001.png\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: Azure SQL database -<br>You can't create the SSISDB Catalog database on Azure SQL Database at this time independently of creating the Azure-SSIS Integration Runtime in Azure Data<br>Factory. The Azure-SSIS IR is the runtime environment that runs SSIS packages on Azure.<br>Box 2: Azure-SQL Server Integration Service Integration Runtime and self-hosted integration runtime<br>The Integration Runtime (IR) is the compute infrastructure used by Azure Data Factory to provide data integration capabilities across different network environments. Azure-SSIS Integration Runtime (IR) in Azure Data Factory (ADF) supports running SSIS packages.<br>Self-hosted integration runtime can be used for data movement in this scenario.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/data-factory/create-azure-integration-runtime https://docs.microsoft.com/en-us/sql/integration-services/lift-shift/ssis-azure-connect-to-catalog-database",
    "votes": [],
    "comments": [
      {
        "date": "2021-01-24T18:19:00.000Z",
        "voteCount": 51,
        "content": "Box 1: Azure SQL database -\nBox 2: Azure-SQL Server Integration Service Integration Runtime and self-hosted integration runtime"
      },
      {
        "date": "2020-12-07T06:42:00.000Z",
        "voteCount": 16,
        "content": "Why Self hosted IR?\nThis article describes how to run SQL Server Integration Services (SSIS) packages on an Azure-SSIS Integration Runtime (Azure-SSIS IR) in Azure Data Factory with a self-hosted integration runtime (self-hosted IR) configured as a proxy.\n\nWith this feature, you can access data on-premises without having to join your Azure-SSIS IR to a virtual network. The feature is useful when your corporate network has a configuration too complex or a policy too restrictive for you to inject your Azure-SSIS IR into it.\nhttps://docs.microsoft.com/en-us/azure/data-factory/self-hosted-integration-runtime-proxy-ssis\nAs Azure cloud does not connectivity to on Premise network you would need to implement self Hosted-IR as well"
      },
      {
        "date": "2020-12-27T09:17:00.000Z",
        "voteCount": 5,
        "content": "because data coming from on-prem, you need self hosted"
      },
      {
        "date": "2022-01-21T11:22:00.000Z",
        "voteCount": 1,
        "content": "It's going to an Azure SQL DB first..."
      },
      {
        "date": "2021-03-11T23:40:00.000Z",
        "voteCount": 4,
        "content": "in this case you are moving the package directly to ADF , so why you will use Asure SQL in the first box ??? As long as I'll use Azure SQL so Azure IR is enough ."
      },
      {
        "date": "2022-03-14T00:46:00.000Z",
        "voteCount": 2,
        "content": "Correct answer given"
      },
      {
        "date": "2022-01-21T11:21:00.000Z",
        "voteCount": 1,
        "content": "Provision. Before you can deploy and run SSIS packages in Azure, you have to provision the SSIS Catalog (SSISDB) and the Azure-SSIS Integration Runtime.\n\nYou don't need a self-hosted integration runtime also because the catalog is now in an Azure SQL SSIS DB."
      },
      {
        "date": "2021-10-04T06:21:00.000Z",
        "voteCount": 4,
        "content": "https://docs.microsoft.com/en-us/sql/integration-services/lift-shift/ssis-azure-lift-shift-ssis-packages-overview?view=sql-server-ver15\n\nYou can now move your SQL Server Integration Services (SSIS) projects, packages, and workloads to the Azure cloud. Deploy, run, and manage SSIS projects and packages in the SSIS Catalog (SSISDB) on Azure SQL Database or SQL Managed Instance with familiar tools such as SQL Server Management Studio (SSMS).\n\nhttps://docs.microsoft.com/en-us/azure/data-factory/self-hosted-integration-runtime-proxy-ssis\n\nWith this feature, you can access data and run tasks on premises without having to join your Azure-SSIS IR to a virtual network\n\nAnswer is correct"
      },
      {
        "date": "2022-06-14T05:11:00.000Z",
        "voteCount": 1,
        "content": "Great answer"
      },
      {
        "date": "2021-08-29T23:29:00.000Z",
        "voteCount": 2,
        "content": "Correct"
      },
      {
        "date": "2021-08-03T06:11:00.000Z",
        "voteCount": 5,
        "content": "To run SSIS packages, you need \"Azure-SQL Server Integration services Integration runtime\"  https://www.youtube.com/watch?v=weiHOeje-QA min 3:07. To connect without VPN or Express Route, you need to install a self-hosted integration runtime that acts as a proxy (as seen on video). Then the second Box is: \"Azure-SQL Server Integration services Integration runtime and self-hosted integration\". \nFor the first one, I guess Azure SQL Database."
      },
      {
        "date": "2021-06-13T04:07:00.000Z",
        "voteCount": 1,
        "content": "Select the Set up Self-Hosted Integration Runtime as a proxy for your Azure-SSIS Integration Runtime check box to choose whether you want to configure a self-hosted IR as proxy for your Azure-SSIS IR. Since we migrated completely to azure this is not needed. Box 1 is azure sql database and Box 2 is azure SSIS IR only.  (https://docs.microsoft.com/en-us/azure/data-factory/self-hosted-integration-runtime-proxy-ssis)"
      },
      {
        "date": "2021-06-13T12:18:00.000Z",
        "voteCount": 1,
        "content": "Question says you need to facilitate migtration but doesn't say you have migrated already."
      },
      {
        "date": "2021-04-25T11:05:00.000Z",
        "voteCount": 3,
        "content": "Correct answer"
      },
      {
        "date": "2021-04-17T06:59:00.000Z",
        "voteCount": 1,
        "content": "The installation of a self-hosted integration runtime needs an on-premises machine or a virtual machine inside a private network.\nI would select 2 for Box 2."
      },
      {
        "date": "2021-03-22T01:00:00.000Z",
        "voteCount": 4,
        "content": "is this even in the syllabus... id ont see any mention of this in MS learn"
      },
      {
        "date": "2021-03-01T19:57:00.000Z",
        "voteCount": 2,
        "content": "the second answer would be C only if you have a stable Site to Site connectivity or ER. without this, an SSIS IR only is the correct answer. I know the question is so misleading :)"
      },
      {
        "date": "2021-01-16T14:17:00.000Z",
        "voteCount": 6,
        "content": "In my opinion the answer is correct, as per your reference @uzairahm007, \"This article describes how to run SQL Server Integration Services (SSIS) packages on an Azure-SSIS Integration Runtime (Azure-SSIS IR) in Azure Data Factory with a self-hosted integration runtime (self-hosted IR) configured as a proxy.\n\nWith this feature, you can access data on-premises without having to join your Azure-SSIS IR to a virtual network. The feature is useful when your corporate network has a configuration too complex or a policy too restrictive for you to inject your Azure-SSIS IR into it.\" So both self hosted and Azure SSIS IR are needed for this feature to work."
      },
      {
        "date": "2021-01-13T02:22:00.000Z",
        "voteCount": 2,
        "content": "second one should be IR only.  as self-hosting is running on on-prem network. but it also mentioned 'The on-premises network does not have hybrid connectivity to Azure by using Site-to-Site VPN or ExpressRoute'"
      },
      {
        "date": "2021-01-11T06:01:00.000Z",
        "voteCount": 1,
        "content": "so whats the answer then ?"
      }
    ],
    "examNameCode": "az-304",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 29,
    "url": "https://www.examtopics.com/discussions/microsoft/view/30777-exam-az-304-topic-3-question-29-discussion/",
    "body": "You have 70 TB of files on your on-premises file server.<br>You need to recommend solution for importing data to Azure. The solution must minimize cost.<br>What Azure service should you recommend?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure StorSimple",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure Batch",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure Data Box\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure Stack Hub"
    ],
    "answer": "C",
    "answerDescription": "Microsoft has engineered an extremely powerful solution that helps customers get their data to the Azure public cloud in a cost-effective, secure, and efficient manner with powerful Azure and machine learning at play. The solution is called Data Box.<br>Data Box and is in general availability status. It is a rugged device that allows organizations to have 100 TB of capacity on which to copy their data and then send it to be transferred to Azure.<br>Incorrect Answers:<br>A: StoreSimple would not be able to handle 70 TB of data.<br>Reference:<br>https://www.vembu.com/blog/what-is-microsoft-azure-data-box-disk-edge-heavy-gateway-overview/",
    "votes": [
      {
        "answer": "C",
        "count": 1,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2020-09-07T04:53:00.000Z",
        "voteCount": 23,
        "content": "https://docs.microsoft.com/en-us/azure/databox/data-box-overview\n80TB max for Databox"
      },
      {
        "date": "2021-06-05T11:31:00.000Z",
        "voteCount": 5,
        "content": "100-TB device has 80 TB or usable capacity after RAID 5 protection"
      },
      {
        "date": "2020-11-26T10:26:00.000Z",
        "voteCount": 9,
        "content": "Storage capacity\t100 TB device has 80 TB usable capacity after RAID 5 protection"
      },
      {
        "date": "2022-03-14T22:44:00.000Z",
        "voteCount": 1,
        "content": "I think it is correct"
      },
      {
        "date": "2021-12-24T03:42:00.000Z",
        "voteCount": 2,
        "content": "On exam 24.12.2021"
      },
      {
        "date": "2021-10-19T02:40:00.000Z",
        "voteCount": 5,
        "content": "Azure Data box is correct\nchoose the same\ncleared with 900 on 17th October 2021"
      },
      {
        "date": "2021-10-04T23:55:00.000Z",
        "voteCount": 2,
        "content": "The Microsoft Azure Data Box cloud solution lets you send terabytes of data into and out of Azure in a quick, inexpensive, and reliable way. The secure data transfer is accelerated by shipping you a proprietary Data Box storage device. Each storage device has a maximum usable storage capacity of 80 TB and is transported to your datacenter through a regional carrier.\n\nAnswer is C"
      },
      {
        "date": "2021-08-29T23:29:00.000Z",
        "voteCount": 1,
        "content": "correct"
      },
      {
        "date": "2021-07-19T05:08:00.000Z",
        "voteCount": 6,
        "content": "on exam (7-19-2021). cleared 304 exam."
      },
      {
        "date": "2021-06-16T09:25:00.000Z",
        "voteCount": 1,
        "content": "StorSimple would fit only 15 TB or up to 38 TB. So answer is correct.\n\nREF: https://docs.microsoft.com/en-us/azure/storsimple/storsimple-8000-technical-specifications-and-compliance"
      },
      {
        "date": "2021-08-22T05:10:00.000Z",
        "voteCount": 1,
        "content": "Could also use more than one device, but it would surely not 'minimize cost'."
      },
      {
        "date": "2021-05-01T08:42:00.000Z",
        "voteCount": 2,
        "content": "Correct"
      },
      {
        "date": "2021-01-24T18:23:00.000Z",
        "voteCount": 4,
        "content": "C. Azure Data Box"
      },
      {
        "date": "2021-01-21T14:31:00.000Z",
        "voteCount": 3,
        "content": "Right ans."
      },
      {
        "date": "2021-01-16T04:48:00.000Z",
        "voteCount": 3,
        "content": "Correct"
      },
      {
        "date": "2020-11-24T22:40:00.000Z",
        "voteCount": 4,
        "content": "correct"
      }
    ],
    "examNameCode": "az-304",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 30,
    "url": "https://www.examtopics.com/discussions/microsoft/view/51312-exam-az-304-topic-3-question-30-discussion/",
    "body": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.<br>After you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.<br>You are designing an Azure solution for a company that has four departments. Each department will deploy several Azure app services and Azure SQL databases.<br>You need to recommend a solution to report the costs for each department to deploy the app services and the databases. The solution must provide a consolidated view for cost reporting that displays cost broken down by department.<br>Solution: Create a separate resource group for each department. Place the resources for each department in its respective resource group.<br>Does this meet the goal?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tYes\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tNo"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 12,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-05-18T11:21:00.000Z",
        "voteCount": 58,
        "content": "Correct Answer is yes, below are the simple steps to fetch consolidated cost report for each Resource Group (department in this case).\n1. Open Azure portal and navigate to subscription and then cost analysis (under cost management).\n2. A consolidated view will appear with a nice main diagram and multiple pie charts and one of them is showing costs for each resource group.\n3. You may also select \"Resource Group Name\" under option \"Group by\" on the main chart. This will bring also bring a consolidated view for each resource group!"
      },
      {
        "date": "2024-03-01T17:15:00.000Z",
        "voteCount": 1,
        "content": "The key point is \"Assign tags to each resource\" , as tags are not inherited which means if you assign a tag to a RG &gt;&gt; it will not propagated/inherited to the underneath resources , so you MUST assign tags to each individual resource."
      },
      {
        "date": "2023-02-28T03:52:00.000Z",
        "voteCount": 1,
        "content": "Ive tested this and its true"
      },
      {
        "date": "2021-05-09T03:41:00.000Z",
        "voteCount": 21,
        "content": "Resource Groups are used to delegate administration, not for cost allocation. Tags should be used for this purpose!"
      },
      {
        "date": "2021-08-28T15:12:00.000Z",
        "voteCount": 3,
        "content": "But in this question, it says \"You need to recommend a solution to ...\". The solution can solve the problem, but is not the recommended solution by administrator. So \"No\" is right."
      },
      {
        "date": "2021-09-25T08:03:00.000Z",
        "voteCount": 8,
        "content": "But in the end, it says \"Does it meet the goal\". It does meet the goal."
      },
      {
        "date": "2022-01-01T07:13:00.000Z",
        "voteCount": 2,
        "content": "Exactly. \"Does this meet the goal?\""
      },
      {
        "date": "2021-05-15T21:19:00.000Z",
        "voteCount": 16,
        "content": "That's true, but it doesn't mean the given answer is correct.\nCost management can breakdown costs per RG, so the answer is A. Yes."
      },
      {
        "date": "2023-09-10T02:39:00.000Z",
        "voteCount": 1,
        "content": "It's simple, we can use separate RG's to achieve the goal."
      },
      {
        "date": "2023-09-02T09:49:00.000Z",
        "voteCount": 1,
        "content": "cost analysis \nA consolidated view will appear\nYou may also select \"Resource Group Name\" under option \"Group by\""
      },
      {
        "date": "2022-11-18T15:51:00.000Z",
        "voteCount": 1,
        "content": "Even though resource group creation suffice the purpose but it is not recommended. Create tags instead"
      },
      {
        "date": "2022-08-11T06:42:00.000Z",
        "voteCount": 3,
        "content": "I guess this question was designed to raise awareness of tags. It just needs a better formulation. At the exam, yes to all that have tag on it I supposej, smiling."
      },
      {
        "date": "2022-03-24T23:49:00.000Z",
        "voteCount": 1,
        "content": "for sure a better solution with tag, no doubt, but mind question : \" Does it meet the goal?\"\nYes"
      },
      {
        "date": "2022-02-12T05:14:00.000Z",
        "voteCount": 1,
        "content": "VOTE A"
      },
      {
        "date": "2022-02-01T20:33:00.000Z",
        "voteCount": 1,
        "content": "Answer is A"
      },
      {
        "date": "2022-01-03T08:35:00.000Z",
        "voteCount": 1,
        "content": "Cost Management can track by Resource Group. Allows you to report by resource group."
      },
      {
        "date": "2021-12-21T06:57:00.000Z",
        "voteCount": 3,
        "content": "Answer is YES"
      },
      {
        "date": "2021-12-18T02:59:00.000Z",
        "voteCount": 5,
        "content": "Answer should be Yes, tags will help to find data if combined to multiple resources group. In this case ask is department based and resource group is set to department. Yes is right"
      },
      {
        "date": "2021-11-27T03:05:00.000Z",
        "voteCount": 1,
        "content": "I would go for yes, eventhough this is not recommended because sometime isolation is more a requirement than cost. So the goal is met. so \"Yes\"."
      },
      {
        "date": "2021-10-04T23:29:00.000Z",
        "voteCount": 7,
        "content": "You can filter by resource group so answer is Yes\n\nhttps://docs.microsoft.com/en-us/azure/cost-management-billing/costs/group-filter"
      },
      {
        "date": "2021-09-07T06:35:00.000Z",
        "voteCount": 6,
        "content": "Same question in www.skillpipe.com that provided by training course, answer is Yes."
      },
      {
        "date": "2021-08-22T05:14:00.000Z",
        "voteCount": 2,
        "content": "That would probably meet the goal of getting cost report per department, but would it be feasible in general? Having one RG per department is not a Best Practice and would cause other implications (like difficult permission management etc.). Would they consider a solution 'meeting the goal' in that case?"
      },
      {
        "date": "2021-07-23T11:32:00.000Z",
        "voteCount": 3,
        "content": "Answer is YES"
      }
    ],
    "examNameCode": "az-304",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 31,
    "url": "https://www.examtopics.com/discussions/microsoft/view/30778-exam-az-304-topic-3-question-31-discussion/",
    "body": "You have an Azure subscription that contains 100 virtual machines.<br>You plan to design a data protection strategy to encrypt the virtual disks.<br>You need to recommend a solution to encrypt the disks by using Azure Disk Encryption. The solution must provide the ability to encrypt operating system disks and data disks.<br>What should you include in the recommendation?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ta certificate",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ta key\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ta passphrase",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ta secret"
    ],
    "answer": "B",
    "answerDescription": "For enhanced virtual machine (VM) security and compliance, virtual disks in Azure can be encrypted. Disks are encrypted by using cryptographic keys that are secured in an Azure Key Vault. You control these cryptographic keys and can audit their use.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/virtual-machines/windows/encrypt-disks",
    "votes": [
      {
        "answer": "B",
        "count": 2,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2020-09-07T04:55:00.000Z",
        "voteCount": 28,
        "content": "Azure Disk Encryption requires an Azure Key Vault to control and manage disk encryption keys and secrets. Your key vault and VMs must reside in the same Azure region and subscription."
      },
      {
        "date": "2020-11-20T03:27:00.000Z",
        "voteCount": 15,
        "content": "B is correct"
      },
      {
        "date": "2022-05-20T12:39:00.000Z",
        "voteCount": 1,
        "content": "I created a VM and key vault, and encrypted the os disk following the steps in https://docs.microsoft.com/en-us/azure/virtual-machines/windows/disk-encryption-cli-quickstart\n\nAfterwards my key vault contained no keys, 1 secret"
      },
      {
        "date": "2022-03-14T22:45:00.000Z",
        "voteCount": 1,
        "content": "A key is correct"
      },
      {
        "date": "2022-02-13T01:15:00.000Z",
        "voteCount": 1,
        "content": "vote b"
      },
      {
        "date": "2021-12-23T03:39:00.000Z",
        "voteCount": 1,
        "content": "Appere on exam 23-dec-2021"
      },
      {
        "date": "2021-10-19T02:41:00.000Z",
        "voteCount": 7,
        "content": "Key is correct\nchoose the same\ncleared with 900 on 17th October 2021"
      },
      {
        "date": "2021-09-29T06:26:00.000Z",
        "voteCount": 1,
        "content": "https://docs.microsoft.com/en-us/azure/virtual-machines/linux/disk-encryption-key-vault\n\nB for sure"
      },
      {
        "date": "2021-08-29T23:30:00.000Z",
        "voteCount": 1,
        "content": "correct"
      },
      {
        "date": "2021-07-19T05:09:00.000Z",
        "voteCount": 5,
        "content": "this on exam (7-19-2021) . passed 304"
      },
      {
        "date": "2021-06-13T12:33:00.000Z",
        "voteCount": 2,
        "content": "B is the only answer here, keys could be customer or Azure assiged in AKV."
      },
      {
        "date": "2021-05-28T23:47:00.000Z",
        "voteCount": 2,
        "content": "It requires key to be created in AKV.\nhttps://docs.microsoft.com/en-us/azure/virtual-machines/windows/disk-encryption-key-vault"
      },
      {
        "date": "2021-01-25T06:57:00.000Z",
        "voteCount": 4,
        "content": "B. a key"
      },
      {
        "date": "2020-09-28T14:59:00.000Z",
        "voteCount": 1,
        "content": "Why not a secret that configures the key as the secret?"
      },
      {
        "date": "2020-10-08T06:56:00.000Z",
        "voteCount": 14,
        "content": "Eventually, you are configuring a key only. B is correct."
      },
      {
        "date": "2021-01-16T14:04:00.000Z",
        "voteCount": 1,
        "content": "with data disk secret may not work"
      },
      {
        "date": "2021-08-22T05:19:00.000Z",
        "voteCount": 1,
        "content": "I too was wondering if a key isn't considered a secret, but no, KV manages \"secrets and keys\" per MS documentation. Thus a key is not considered a \"secret.\""
      }
    ],
    "examNameCode": "az-304",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 32,
    "url": "https://www.examtopics.com/discussions/microsoft/view/30557-exam-az-304-topic-3-question-32-discussion/",
    "body": "You have data files in Azure Blob storage.<br>You plan to transform the files and move them to Azure Data Lake Storage.<br>You need to transform the data by using mapping data flow.<br>Which Azure service should you use?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure Data Box Gateway",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure Storage Sync",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure Data Factory\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure Databricks"
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 3,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2020-09-04T02:44:00.000Z",
        "voteCount": 34,
        "content": "C is correct.\nhttps://docs.microsoft.com/en-us/azure/data-factory/concepts-data-flow-overview#:~:text=Mapping%20data%20flows%20are%20visually%20designed%20data%20transformations,Factory%20pipelines%20that%20use%20scaled-out%20Apache%20Spark%20clusters."
      },
      {
        "date": "2021-06-05T11:32:00.000Z",
        "voteCount": 28,
        "content": "Seems like Azure Data Factory is the new favorite for a lot of answers."
      },
      {
        "date": "2021-09-05T00:49:00.000Z",
        "voteCount": 7,
        "content": "Perhaps it is the most costly :-)"
      },
      {
        "date": "2022-01-01T07:20:00.000Z",
        "voteCount": 2,
        "content": "ADF is cheap generally speaking."
      },
      {
        "date": "2022-03-14T22:46:00.000Z",
        "voteCount": 3,
        "content": "Always Data Factory \ud83d\ude02"
      },
      {
        "date": "2021-10-04T23:56:00.000Z",
        "voteCount": 3,
        "content": "C is the answer for sure"
      },
      {
        "date": "2021-08-29T23:31:00.000Z",
        "voteCount": 2,
        "content": "Correct"
      },
      {
        "date": "2021-01-25T06:59:00.000Z",
        "voteCount": 5,
        "content": "C. Azure Data Factory"
      },
      {
        "date": "2020-12-26T14:14:00.000Z",
        "voteCount": 9,
        "content": "Data flow = Azure Data Factory"
      },
      {
        "date": "2020-10-20T04:47:00.000Z",
        "voteCount": 17,
        "content": "Mapping data flows are visually designed data transformations in Azure Data Factory. Data flows allow data engineers to develop data transformation logic without writing code. Data flow activities can be operationalized using existing Azure Data Factory scheduling, control, flow, and monitoring capabilities."
      },
      {
        "date": "2020-09-07T04:55:00.000Z",
        "voteCount": 3,
        "content": "For Copy activity, with this connector you can:\n\nCopy data from/to Azure Data Lake Storage Gen2 by using account key, service principal, or managed identities for Azure resources authentications.\nCopy files as-is or parse or generate files with supported file formats and compression codecs.\nPreserve file metadata during copy.\nPreserve ACLs when copying from Azure Data Lake Storage Gen1/Gen2."
      }
    ],
    "examNameCode": "az-304",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 33,
    "url": "https://www.examtopics.com/discussions/microsoft/view/53924-exam-az-304-topic-3-question-33-discussion/",
    "body": "HOTSPOT -<br>You plan to develop a new app that will store business critical data. The app must meet the following requirements:<br>\u2711 Prevent new data from being modified for one year.<br>\u2711 Minimize read latency.<br>\u2711 Maximize data resiliency.<br>You need to recommend a storage solution for the app.<br>What should you recommend? To answer, select the appropriate options in the answer area.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04027/0017500001.jpg\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04027/0017500002.jpg\" class=\"in-exam-image\">",
    "answerDescription": "Box 1:<br><br>BlockBlobStorage -<br>Storage accounts with premium performance characteristics for block blobs and append blobs.<br>Box 2:<br>Reference:<br>https://docs.microsoft.com/en-us/azure/storage/common/storage-account-overview https://docs.microsoft.com/en-us/azure/storage/common/storage-redundancy?toc=/azure/storage/blobs/toc.json",
    "votes": [],
    "comments": [
      {
        "date": "2021-06-04T05:39:00.000Z",
        "voteCount": 70,
        "content": "premium blockblobs has the best read latency (https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blobs-latency)\nMaximize data resiliency; for blockbobs are only LRS or ZRS available. (https://docs.microsoft.com/en-us/azure/storage/common/storage-account-overview)\nSo I think the right answer is Blockblob storage and ZRS."
      },
      {
        "date": "2021-12-09T21:44:00.000Z",
        "voteCount": 2,
        "content": "If you create a premium SA, you can only select LRS."
      },
      {
        "date": "2022-09-21T14:06:00.000Z",
        "voteCount": 2,
        "content": "That is not true. Premium files and premium block blob support ZRS. Only premium page blob does not."
      },
      {
        "date": "2021-07-07T15:48:00.000Z",
        "voteCount": 4,
        "content": "do you even know difference between ZRS and RA GRS? Man there are big minds in this forum"
      },
      {
        "date": "2022-01-21T11:52:00.000Z",
        "voteCount": 3,
        "content": "It's because you have humans in here that are engineers and then you have humans with a mile long string of certs by their name that can't do a mf thing in the real world."
      },
      {
        "date": "2021-11-06T09:19:00.000Z",
        "voteCount": 11,
        "content": "This is a childish and unhelpful comment. Why not just correct whatever incorrect information you have seen at least?"
      },
      {
        "date": "2021-06-07T11:24:00.000Z",
        "voteCount": 3,
        "content": "excellent explanation, just on the storage type, according to https://docs.microsoft.com/en-us/azure/storage/common/storage-account-overview#types-of-storage-accounts , a premium block blob is supported under a \"blob storage\""
      },
      {
        "date": "2021-10-10T07:34:00.000Z",
        "voteCount": 9,
        "content": "Blockblob storage and ZRS is the correct answer. \n\nKeyword here is data resiliency, not redundancy. \n\nPrem. Block blob Storage are only LRS and ZRS"
      },
      {
        "date": "2021-05-31T05:49:00.000Z",
        "voteCount": 69,
        "content": "1st: StorageV2. Reason: Generally recommended by Microsoft, also for immutable storage: \nhttps://docs.microsoft.com/en-us/azure/storage/blobs/storage-blob-immutable-storage\n\n2nd: RA-GRS. Reason: \"Maximize data resiliency\" requirement. RA-GRA provides six copies total, including three in the primary region and three in the secondary region"
      },
      {
        "date": "2021-07-07T15:51:00.000Z",
        "voteCount": 4,
        "content": "100% correct as mmutable storage is available for general-purpose v1, general-purpose v2, premium block blob, and legacy blob accounts in all Azure regions. So the key here is what does it at low cost which is General purpose V2.  I go with you protofx."
      },
      {
        "date": "2021-09-25T08:37:00.000Z",
        "voteCount": 9,
        "content": "Cost is not a factor here."
      },
      {
        "date": "2022-01-06T07:22:00.000Z",
        "voteCount": 6,
        "content": "Yes, the factor is read latency, that is why BlockBlob fits the best\nAnd the higher resiliency for this storage is ZRS"
      },
      {
        "date": "2022-06-25T00:56:00.000Z",
        "voteCount": 2,
        "content": "This does not meet the requirements of minimal read latency"
      },
      {
        "date": "2021-06-20T12:58:00.000Z",
        "voteCount": 12,
        "content": "Immutable storage is available for Premium BlockBlob storage\n\"Immutable storage for Azure Blob storage enables users to store business-critical data objects in a WORM (Write Once, Read Many) state. This state makes the data non-erasable and non-modifiable for a user-specified interval. For the duration of the retention interval, blobs can be created and read, but cannot be modified or deleted. Immutable storage is available for general-purpose v1, general-purpose v2, premium block blob, and legacy blob accounts in all Azure regions.\"\nhttps://docs.microsoft.com/en-us/azure/storage/blobs/storage-blob-immutable-storage"
      },
      {
        "date": "2022-06-25T00:55:00.000Z",
        "voteCount": 10,
        "content": "Entirely wrong - this does not meet the requirements.\nBlock Blob Storage to meet Minimize read latency and time-based immutable retention policies\nZRS as highest level of resiliency available for Block Blob Storage"
      },
      {
        "date": "2022-07-02T13:33:00.000Z",
        "voteCount": 1,
        "content": "I was all set to disagree with you, but I think you're right. The Block BLOB and ZRS does seem to match up. Although, I can't find a resource that lists the read latency for the different storage types.\n\nI was going with V2 and RA-GZRS, but RA-GZRS is only available in certain regions. ZRS is allowed in all regions."
      },
      {
        "date": "2023-02-28T04:06:00.000Z",
        "voteCount": 2,
        "content": "when creating a storage account, the premium option says - recommended for scenarios that require low latency"
      },
      {
        "date": "2023-09-02T10:16:00.000Z",
        "voteCount": 2,
        "content": "Based on the order\n   Prevent new data from being modified for one year. (WORM - all type blobs have it, v2,v1,prem)\n\u2711 Minimize read latency. premium blockblob\n\u2711 Maximize data resiliency. zrs because that is the max resiliency of a prem blockblob"
      },
      {
        "date": "2022-11-18T15:57:00.000Z",
        "voteCount": 1,
        "content": "Block Blob and ZRS is answer"
      },
      {
        "date": "2022-10-17T17:40:00.000Z",
        "voteCount": 1,
        "content": "BlockBlob storage, ZRS. Cost isnt a factor here, RAGRS not available for blockblob. Simples!"
      },
      {
        "date": "2022-09-21T14:08:00.000Z",
        "voteCount": 2,
        "content": "You're ether going with:\n\nBlockBlobStorage + ZRS -- to minimize read latency\nor\nStandard v2 + RA-GRS to maximize data resiliency \n\nIt depends entirely on which way you prioritize them."
      },
      {
        "date": "2022-09-27T11:55:00.000Z",
        "voteCount": 1,
        "content": "make sense!"
      },
      {
        "date": "2022-08-11T06:57:00.000Z",
        "voteCount": 4,
        "content": "(this replaces my previous post)\n\nThe answer is BlockBlob, ZRS. \n\n\nBlockBlob is a premium service and there's no (RA)GRS option with premium, only ZRS. This has changed over the years and we are also comparing legacy resources with current resources rules and regulations. \n\nBut there you have it. Answer from the 305 dump."
      },
      {
        "date": "2022-08-11T06:51:00.000Z",
        "voteCount": 3,
        "content": "The answer is BlockBlob, ZRS. \n\nBlockBlob is a premium service and there's no (RA)GRS option with premium, only ZRS. This has changed over the years and we are also compare legacy with current resources. \n\nBut there you have it. Answer from the 305 dump."
      },
      {
        "date": "2022-06-11T05:54:00.000Z",
        "voteCount": 1,
        "content": "The key here is data resiliency which means system needs to recover quickly and continue operating when there has been failure. \nHence Storage v2 is better options as it has better resiliency options like RA-GRS and RA-GZRS. The block blob options are - LRS, ZRS and hence less resiliency."
      },
      {
        "date": "2022-05-18T07:19:00.000Z",
        "voteCount": 1,
        "content": "RA-GRS doesn't meet the minimum latency"
      },
      {
        "date": "2022-03-10T00:15:00.000Z",
        "voteCount": 7,
        "content": "BlockBlob\nZRS"
      },
      {
        "date": "2022-01-25T17:29:00.000Z",
        "voteCount": 1,
        "content": "Legacy blob is supported by GRS/RA-GRS.  See \"https://docs.microsoft.com/en-us/azure/storage/common/storage-redundancy#supported-storage-account-types\" .  I would go with BlobStorage and RA-GRS."
      },
      {
        "date": "2022-01-04T21:07:00.000Z",
        "voteCount": 2,
        "content": "BlockBlob and ZRS seems to be the right answer"
      },
      {
        "date": "2022-01-02T03:51:00.000Z",
        "voteCount": 2,
        "content": "It should be StorageV2 and RA-GRS.  since BlockBlog does not support RA-GRS.\nAlso here it says BlockBlob NOT PREMIUM BLockBlob.\nhttps://docs.microsoft.com/en-us/azure/storage/common/storage-account-overview"
      },
      {
        "date": "2022-02-23T13:43:00.000Z",
        "voteCount": 1,
        "content": "If you create a Premium storage account, and select Block blob as the type, and then go back and check the \"Account Kind\" attribute, you will see it is BlockBlobStorage.    If you create a non premium account, the \"Account Kind\" attribute is StorageV2 (general purpose v2).   So BlockBlobStorage implies premium.   I would go with BlockBlobStorage / ZRS."
      },
      {
        "date": "2021-12-29T19:31:00.000Z",
        "voteCount": 1,
        "content": "Hi...I believe that the correct answer is \nBox1: BlockBlobStorage\nBox2: ZRS"
      },
      {
        "date": "2021-12-23T03:39:00.000Z",
        "voteCount": 3,
        "content": "Appere on exam 23-dec-2021"
      },
      {
        "date": "2021-12-17T04:51:00.000Z",
        "voteCount": 2,
        "content": "Its V2 Storage and RA GRS for resiliency."
      }
    ],
    "examNameCode": "az-304",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 34,
    "url": "https://www.examtopics.com/discussions/microsoft/view/53915-exam-az-304-topic-3-question-34-discussion/",
    "body": "You have an application named App1. App1 generates log files that must be archived for five years. The log files must be readable by App1 but must not be modified.<br>Which storage solution should you recommend for archiving?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tIngest the log files into an Azure Log Analytics workspace",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse an Azure Blob storage account and a time-based retention policy\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse an Azure Blob storage account configured to use the Archive access tier",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse an Azure file share that has access control enabled"
    ],
    "answer": "B",
    "answerDescription": "Immutable storage for Azure Blob storage enables users to store business-critical data objects in a WORM (Write Once, Read Many) state.<br>Immutable storage supports:<br>Time-based retention policy support: Users can set policies to store data for a specified interval. When a time-based retention policy is set, blobs can be created and read, but not modified or deleted. After the retention period has expired, blobs can be deleted but not overwritten.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blob-immutable-storage",
    "votes": [
      {
        "answer": "B",
        "count": 2,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-05-31T05:54:00.000Z",
        "voteCount": 17,
        "content": "Correct"
      },
      {
        "date": "2021-10-19T02:42:00.000Z",
        "voteCount": 9,
        "content": "Answer is correct\nchoose the same\ncleared with 900 on 17th October 2021"
      },
      {
        "date": "2022-03-15T08:48:00.000Z",
        "voteCount": 1,
        "content": "I would choose B"
      },
      {
        "date": "2021-12-29T03:56:00.000Z",
        "voteCount": 1,
        "content": "B + Lock policy needed not to modify it"
      },
      {
        "date": "2021-12-29T03:58:00.000Z",
        "voteCount": 2,
        "content": "sorry &amp; correction: Time-based retention covers the no modification"
      },
      {
        "date": "2021-10-04T23:57:00.000Z",
        "voteCount": 2,
        "content": "\"must not be modified\"\n\nAnswer is B"
      },
      {
        "date": "2021-09-20T04:25:00.000Z",
        "voteCount": 6,
        "content": "came in exam on 20-sep-21, I passed, i choose given answer"
      },
      {
        "date": "2021-08-03T10:42:00.000Z",
        "voteCount": 1,
        "content": "Correct See&gt; https://www.examtopics.com/discussions/microsoft/view/21805-exam-az-301-topic-17-question-42-discussion/"
      },
      {
        "date": "2021-06-05T18:09:00.000Z",
        "voteCount": 1,
        "content": "What would be the explanation for not using the Archive access tier?"
      },
      {
        "date": "2021-09-25T08:58:00.000Z",
        "voteCount": 1,
        "content": "While a blob is in archive storage, the blob data is offline and can't be read or modified. To read or download a blob in archive, you must first rehydrate it to an online tier.\nhttps://docs.microsoft.com/en-us/azure/storage/blobs/storage-blob-storage-tiers#archive-access-tier"
      },
      {
        "date": "2021-06-20T10:40:00.000Z",
        "voteCount": 3,
        "content": "Archive tier is \"offline\" copies if data. You need to hydrate it first before it can be accessible."
      },
      {
        "date": "2021-07-07T15:52:00.000Z",
        "voteCount": 1,
        "content": "correct"
      },
      {
        "date": "2021-08-22T07:25:00.000Z",
        "voteCount": 1,
        "content": "And Archive tier alone does not protect data from deletion."
      },
      {
        "date": "2021-06-07T11:39:00.000Z",
        "voteCount": 5,
        "content": "thought the same but I guess if it needs to be accessible by an app, there is an immediacy requirement. Also when you have a blob in archive, you rehydrate a copy of it in hot and you can then edit it I guess. So suggested answer is the safest one"
      },
      {
        "date": "2021-05-31T05:36:00.000Z",
        "voteCount": 2,
        "content": "I agree"
      },
      {
        "date": "2021-05-31T04:34:00.000Z",
        "voteCount": 3,
        "content": "On exam 30 may"
      }
    ],
    "examNameCode": "az-304",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 35,
    "url": "https://www.examtopics.com/discussions/microsoft/view/56558-exam-az-304-topic-3-question-35-discussion/",
    "body": "You have 100 Microsoft SQL Server Integration Services (SSIS) packages that are configured to use 10 on-premises SQL Server databases as their destinations.<br>You plan to migrate the 10 on-premises databases to Azure SQL Database.<br>You need to recommend a solution to host the SSIS packages in Azure. The solution must ensure that the packages can target the SQL Database instances as their destinations.<br>What should you include in the recommendation?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSQL Server Migration Assistant (SSMA)",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tData Migration Assistant",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure Data Catalog",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure Data Factory\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 57,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2022-02-13T01:31:00.000Z",
        "voteCount": 42,
        "content": "i am a simple guy, I see \"ADF\" in aswers and I select it"
      },
      {
        "date": "2021-06-30T18:28:00.000Z",
        "voteCount": 34,
        "content": "Incorrect. D is the answer based on this https://docs.microsoft.com/en-us/azure/data-factory/how-to-migrate-ssis-job-ssms"
      },
      {
        "date": "2022-09-17T06:08:00.000Z",
        "voteCount": 1,
        "content": "I believe the answer is correct. If we read the question carefully he is not asking to migrate the SSIS packages infact he is asking for \"The solution must ensure that the packages can target the SQL Database instances as their destinations.\". In order to find the fitment analysis we need to run DMA irrepspective of how you deploy the packages in Azure. please refer to below link\nhttps://learn.microsoft.com/en-us/sql/dma/dma-assess-ssis?view=sql-server-ver16"
      },
      {
        "date": "2022-07-26T20:19:00.000Z",
        "voteCount": 1,
        "content": "Check this link for SSIS vs ADF\nhttps://www.mssqltips.com/sqlservertip/7094/azure-data-factory-vs-ssis-similarities-differences/"
      },
      {
        "date": "2022-06-26T09:43:00.000Z",
        "voteCount": 2,
        "content": "The question is about hosting SSIS packages as is in Azure, Hence the answer here is Data Migration Assistant. ADF will be used if you are creating custom pipelines for your business requirements."
      },
      {
        "date": "2022-04-09T04:30:00.000Z",
        "voteCount": 4,
        "content": "In AZ-305 exam, 9 april 22"
      },
      {
        "date": "2022-03-10T00:18:00.000Z",
        "voteCount": 1,
        "content": "DATA FACTORY"
      },
      {
        "date": "2022-02-19T00:50:00.000Z",
        "voteCount": 3,
        "content": "Correct Answer is B\nhttps://docs.microsoft.com/en-us/azure/dms/how-to-migrate-ssis-packages-managed-instance"
      },
      {
        "date": "2022-05-12T18:16:00.000Z",
        "voteCount": 1,
        "content": "Wrong - Azure Database Migration Service (DMS) currently does not support Azure SQL Database as a target migration destination. To redeploy SSIS projects/packages to Azure SQL Database, see the article Redeploy SQL Server Integration Services packages to Azure SQL Database. ..In this caso, SHOULD fo to Azure."
      },
      {
        "date": "2022-01-16T07:49:00.000Z",
        "voteCount": 2,
        "content": "Correct one is D"
      },
      {
        "date": "2022-01-10T03:00:00.000Z",
        "voteCount": 1,
        "content": "D Answer"
      },
      {
        "date": "2022-01-01T07:34:00.000Z",
        "voteCount": 2,
        "content": "Data factory makes most sense based on this. https://docs.microsoft.com/en-us/azure/data-factory/how-to-migrate-ssis-job-ssms"
      },
      {
        "date": "2021-12-28T22:04:00.000Z",
        "voteCount": 2,
        "content": "D Data Factory, seems right to me"
      },
      {
        "date": "2021-12-21T05:04:00.000Z",
        "voteCount": 2,
        "content": "See https://docs.microsoft.com/en-us/azure/data-factory/how-to-migrate-ssis-job-ssms"
      },
      {
        "date": "2021-12-18T03:47:00.000Z",
        "voteCount": 1,
        "content": "Consider #28 question, it's SSIS + ADF doing the migration targeting right package goes to it's respective SQL database."
      },
      {
        "date": "2021-12-04T15:44:00.000Z",
        "voteCount": 1,
        "content": "thanks i chose D too, so was confused to see it lists B"
      },
      {
        "date": "2021-12-01T12:53:00.000Z",
        "voteCount": 4,
        "content": "https://docs.microsoft.com/en-us/azure/data-factory/how-to-migrate-ssis-job-ssms"
      },
      {
        "date": "2021-09-29T00:34:00.000Z",
        "voteCount": 1,
        "content": "https://docs.microsoft.com/en-us/azure/data-factory/create-azure-ssis-integration-runtime\n\nAnswer is D; Data Factory"
      }
    ],
    "examNameCode": "az-304",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 36,
    "url": "https://www.examtopics.com/discussions/microsoft/view/56560-exam-az-304-topic-3-question-36-discussion/",
    "body": "HOTSPOT -<br>You are planning an Azure Storage solution for sensitive data. The data will be accessed daily. The data set is less than 10 GB.<br>You need to recommend a storage solution that meets the following requirements:<br>\u2711 All the data written to storage must be retained for five years.<br>\u2711 Once the data is written, the data can only be read. Modifications and deletion must be prevented.<br>\u2711 After five years, the data can be deleted, but never modified.<br>\u2711 Data access charges must be minimized.<br>What should you recommend? To answer, select the appropriate options in the answer area.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04027/0017800001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04027/0017800002.png\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: General purpose v2 with Archive acce3ss tier for blobs<br>Archive - Optimized for storing data that is rarely accessed and stored for at least 180 days with flexible latency requirements, on the order of hours.<br>Cool - Optimized for storing data that is infrequently accessed and stored for at least 30 days.<br>Hot - Optimized for storing data that is accessed frequently.<br>Box 2: Storage account resource lock<br>As an administrator, you can lock a subscription, resource group, or resource to prevent other users in your organization from accidentally deleting or modifying critical resources. The lock overrides any permissions the user might have.<br>Note: You can set the lock level to CanNotDelete or ReadOnly. In the portal, the locks are called Delete and Read-only respectively.<br>\u2711 CanNotDelete means authorized users can still read and modify a resource, but they can't delete the resource.<br>\u2711 ReadOnly means authorized users can read a resource, but they can't delete or update the resource. Applying this lock is similar to restricting all authorized users to the permissions granted by the Reader role.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blob-storage-tiers",
    "votes": [],
    "comments": [
      {
        "date": "2021-07-04T10:37:00.000Z",
        "voteCount": 64,
        "content": "\"The data will be accessed daily.\" &amp; \"Data access charges must be minimized.\" =&gt; Hot Tier.\n\"Once the data is written, the data can only be read.\", WORM \"Immutable storage for Azure Blob storage supports two types of WORM or immutable policies: time-based retention and legal holds.\" =&gt; Container Level Policy\nhttps://docs.microsoft.com/en-us/azure/storage/blobs/storage-blob-immutable-storage#how-it-works"
      },
      {
        "date": "2021-07-08T03:47:00.000Z",
        "voteCount": 51,
        "content": "There is no such thing as \"Container Level Policy\"\nJust to be clear:\n1st box: Hot tier\n2nd box: Container access policy"
      },
      {
        "date": "2021-08-07T17:30:00.000Z",
        "voteCount": 9,
        "content": "Yes there is:\nhttps://docs.microsoft.com/en-us/azure/storage/blobs/immutable-time-based-retention-policy-overview#container-level-policy-scope"
      },
      {
        "date": "2021-06-30T17:32:00.000Z",
        "voteCount": 20,
        "content": "I think, we should have cool access tier  instead of archive as the data will be accessed daily and access charges should be minimized."
      },
      {
        "date": "2021-07-08T01:50:00.000Z",
        "voteCount": 3,
        "content": "Reducing access charges is reducing latency not the storage cost."
      },
      {
        "date": "2022-02-02T13:59:00.000Z",
        "voteCount": 2,
        "content": "Wrong: hot and cool tiers have same latency (milliseconds). They differ in SLA and cost.\nhttps://docs.microsoft.com/en-us/azure/storage/blobs/access-tiers-overview#summary-of-access-tier-options"
      },
      {
        "date": "2021-08-22T07:38:00.000Z",
        "voteCount": 4,
        "content": "What? \"Charges\" refer to cost obviously. Access tier with lowest data access charges is Hot."
      },
      {
        "date": "2021-07-18T06:36:00.000Z",
        "voteCount": 4,
        "content": "Hot storage is much cheaper in this scenario, thus 1:hot must be correct"
      },
      {
        "date": "2021-08-03T14:23:00.000Z",
        "voteCount": 1,
        "content": "Agree with @juandmi see https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blob-storage-tiers : \"Data access costs: Data access charges increase as the tier gets cooler. For data in the cool and archive access tier, you're charged a per-gigabyte data access charge for reads\""
      },
      {
        "date": "2022-04-11T06:02:00.000Z",
        "voteCount": 2,
        "content": "To access ur data on a daily basis on cool access tier will cost more than hot access tier so its definitely storage account V2 with Blob on hot tier for sure"
      },
      {
        "date": "2022-03-11T22:58:00.000Z",
        "voteCount": 2,
        "content": "Hot Tier - access daily\nContainer access policy"
      },
      {
        "date": "2022-03-05T21:02:00.000Z",
        "voteCount": 2,
        "content": "1. Cool Access \n2. Container access policy"
      },
      {
        "date": "2022-01-03T01:23:00.000Z",
        "voteCount": 3,
        "content": "Hot Tier.\nContainer access policy"
      },
      {
        "date": "2021-12-29T16:19:00.000Z",
        "voteCount": 2,
        "content": "1st box: Hot tier\n2nd box: Container access policy"
      },
      {
        "date": "2021-12-24T03:43:00.000Z",
        "voteCount": 3,
        "content": "On exam 24.12.2021"
      },
      {
        "date": "2021-12-23T03:40:00.000Z",
        "voteCount": 3,
        "content": "Appere on exam 23-dec-2021"
      },
      {
        "date": "2021-12-08T08:58:00.000Z",
        "voteCount": 2,
        "content": "Going to do the exam soon, but I do not agree with the answers, for me they are:\n1- Hot tier: It is the cheapest for access charges.\n2- Storage account resouce lock: https://docs.microsoft.com/en-us/azure/azure-resource-manager/management/lock-resources?tabs=json\n\nWhy the correct answer for 1 is Archive? Why some people say the 2nd is container access policy?"
      },
      {
        "date": "2021-11-15T09:23:00.000Z",
        "voteCount": 3,
        "content": "With such a small data set storage and write charges are insignificant, access charges will be much more important.\n\nWhilst daily access just about allows for the ~15hr retrieval time, the access charges for Archive tier will be extremely expensive so it cannot be the solution.\n\nHot tier read cost is roughly half that of cool so is the correct solution here."
      },
      {
        "date": "2022-01-31T03:42:00.000Z",
        "voteCount": 1,
        "content": "I agree your opinion"
      },
      {
        "date": "2021-10-30T03:31:00.000Z",
        "voteCount": 4,
        "content": "Box 1: Hot tier\nBox 2: Container access policy"
      },
      {
        "date": "2021-10-19T02:45:00.000Z",
        "voteCount": 4,
        "content": "i choose archive tier and container access policy\ncleared with 900 on 17th October 2021"
      },
      {
        "date": "2021-11-12T10:13:00.000Z",
        "voteCount": 4,
        "content": "So, tell us..why archive and not hot? Also, you scored a 900, impressive, isn't that a \"perfect\" score? Something tells me you're full of BS. Who knows, maybe you're a genius."
      },
      {
        "date": "2021-12-15T01:46:00.000Z",
        "voteCount": 2,
        "content": "saw this same comment on many questions. i agree unless one has got 1000 / 1000 on the exam how can one be sure which one they got wrong. instead of score one should suggest an explanation."
      },
      {
        "date": "2021-11-05T06:20:00.000Z",
        "voteCount": 2,
        "content": "I highly doubt that..."
      },
      {
        "date": "2021-10-10T07:52:00.000Z",
        "voteCount": 4,
        "content": "Hot storage tier is optimized for storing data that is accessed frequently. Hot storage has higher storage costs than Cool and Archive storage, but the lowest access costs.\n\nCool storage tier is for infrequently accessed data that needs to be stored for a minimum of 30 days. The storage cost for cold tier is lower than that of hot storage tier but the data access charges are high when compared to Hot tier.\n\nThe Azure Archive tier is offline and offers the lowest storage costs but also the highest access costs. This tier is meant for data that remains in archival storage for a minimum of 180 days."
      },
      {
        "date": "2021-10-04T04:27:00.000Z",
        "voteCount": 2,
        "content": "There is no requirement for minimizing storage costs but \"minimizing access charges\" so account type is Hot Tier\n\nPrevent modifications and deletes would be container access policy\n\nhttps://docs.microsoft.com/en-us/azure/storage/blobs/immutable-storage-overview\n\nImmutability policies can be scoped to a blob version (preview) or to a container. How an object behaves under an immutability policy depends on the scope of the policy"
      },
      {
        "date": "2021-09-18T22:50:00.000Z",
        "voteCount": 4,
        "content": "1st box: Hot tier\n2nd box: Container access policy"
      },
      {
        "date": "2021-08-24T07:33:00.000Z",
        "voteCount": 5,
        "content": "1st box: Hot tier\n2nd box: Container access policy\n\nA read-only lock on a storage account doesn't prevent data within that account from being deleted or modified. This type of lock only protects the storage account itself from being deleted or modified, and doesn't protect blob, queue, table, or file data within that storage account.\n\nhttps://docs.microsoft.com/en-us/azure/azure-resource-manager/management/lock-resources?tabs=json"
      }
    ],
    "examNameCode": "az-304",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 37,
    "url": "https://www.examtopics.com/discussions/microsoft/view/56749-exam-az-304-topic-3-question-37-discussion/",
    "body": "You have an Azure subscription. The subscription contains an app that is hosted in the East US, Central Europe, and East Asia regions.<br>You need to recommend a data-tier solution for the app. The solution must meet the following requirements:<br>\u2711 Support multiple consistency levels.<br>\u2711 Be able to store at least 1 TB of data.<br>\u2711 Be able to perform read and write operations in the Azure region that is local to the app instance.<br>What should you include in the recommendation?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tan Azure Cosmos DB database\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ta Microsoft SQL Server Always On availability group on Azure virtual machines",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tan Azure SQL database in an elastic pool",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure Table storage that uses geo-redundant storage (GRS) replication"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 4,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-07-01T04:42:00.000Z",
        "voteCount": 19,
        "content": "Cosmos DB is correct"
      },
      {
        "date": "2021-09-27T06:54:00.000Z",
        "voteCount": 9,
        "content": "\"Support multiple consistency levels\"\n\nThis is 101% A Cosmos DB"
      },
      {
        "date": "2022-07-26T20:25:00.000Z",
        "voteCount": 1,
        "content": "Cosmos DB is the only Azure DB that supports multi-master"
      },
      {
        "date": "2022-03-15T08:50:00.000Z",
        "voteCount": 1,
        "content": "I think it is correct"
      },
      {
        "date": "2021-12-23T03:41:00.000Z",
        "voteCount": 2,
        "content": "Appere on exam 23-dec-2021"
      },
      {
        "date": "2021-12-21T05:08:00.000Z",
        "voteCount": 3,
        "content": "Correct"
      },
      {
        "date": "2021-07-29T20:08:00.000Z",
        "voteCount": 3,
        "content": "Correct Answer: A\nClue: Support multiple consistency levels."
      },
      {
        "date": "2021-07-02T16:37:00.000Z",
        "voteCount": 3,
        "content": "Yes, I agree."
      }
    ],
    "examNameCode": "az-304",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 38,
    "url": "https://www.examtopics.com/discussions/microsoft/view/61168-exam-az-304-topic-3-question-38-discussion/",
    "body": "You have an Azure subscription.<br>Your on-premises network contains a file server named Server1. Server1 stores 5 TB of company files that are accessed rarely.<br>You plan to copy the files to Azure Storage.<br>You need to implement a storage solution for the files that meets the following requirements:<br>\u2711 The files must be available within 24 hours of being requested.<br>\u2711 Storage costs must be minimized.<br>Which two possible storage solutions achieve this goal? Each correct answer presents a complete solution.<br>NOTE: Each correct selection is worth one point.<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a general-purpose v1 storage account. Create a blob container and copy the files to the blob container.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a general-purpose v2 storage account that is configured for the Hot default access tier. Create a blob container, copy the files to the blob container, and set each file to the Archive access tier.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a general-purpose v1 storage account. Create a file share in the storage account and copy the files to the file share.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a general-purpose v2 storage account that is configured for the Cool default access tier. Create a file share in the storage account and copy the files to the file share.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate an Azure Blob storage account that is configured for the Cool default access tier. Create a blob container, copy the files to the blob container, and set each file to the Archive access tier.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "BE",
    "answerDescription": "",
    "votes": [
      {
        "answer": "BE",
        "count": 9,
        "isMostVoted": true
      },
      {
        "answer": "DE",
        "count": 2,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2021-08-31T06:17:00.000Z",
        "voteCount": 35,
        "content": "Answer should be B and E (Archive Tier). Though under \"incorrect answers\", the explanation states:\n\n\"The Archive tier is optimized for storing data that is rarely accessed and stored for at least 180 days with flexible latency requirements (on the order of hours).\"\n\nAnd that is exactly what is asked here. The files \"are accessed rarely.\" They must be \"available within 24 hours of being requested.\" And \"Storage costs must be minimized.\""
      },
      {
        "date": "2021-09-24T11:11:00.000Z",
        "voteCount": 1,
        "content": "E is not correct. \". Create a blob container, copy the files to the blob container, and set each file to the Archive access tier.\" \n\nYou will never set each file to be archive. you would set the container."
      },
      {
        "date": "2021-10-06T22:14:00.000Z",
        "voteCount": 6,
        "content": "We can set at the object level according to following URL , that means we can set at each file level.\nhttps://docs.microsoft.com/en-us/azure/storage/blobs/manage-access-tier?tabs=portal"
      },
      {
        "date": "2021-10-05T23:20:00.000Z",
        "voteCount": 3,
        "content": "How can Option B minimize storage cost? Can you please help us enlighten?  It has storage costs for Hot default access tier at the account level+ the copy of files in the Archive access tier! It cannot have optimized storage costs better than Options D&amp;E."
      },
      {
        "date": "2021-10-15T16:42:00.000Z",
        "voteCount": 9,
        "content": "Access tier on file overrides default account access tier."
      },
      {
        "date": "2021-10-05T23:27:00.000Z",
        "voteCount": 9,
        "content": "A. General-purpose v1 accounts do not provide access to Cool or Archive storage and has high storage prices. So this option is ruled out.\nB. Owing to default Hot Access Tier at account level, all savings derived out of Archive storage tier will be nullified.\nC. GPv1 option is ruled out.\nD. Yes. One of the cheaper storage cost options\nE. Yes. Cheapest amongst all options."
      },
      {
        "date": "2022-01-18T12:36:00.000Z",
        "voteCount": 2,
        "content": "It's certainly B) and E) as the cost for Archive access tier storage by size is vastly cheaper than Cool or Hot. If Read costs are to be neglected (\"rarely\"), and Write costs are more or less equal (a separate discussion, but as they are), then the storage volumetric cost is the overriding cost and a very rough rule of thumb is something like, if Hot=$100, then Cool=$75 and Archive=$5 (billed on the daily average qty).\n(The write cost of Hot is half of Cool and Archive ; writes are zero cost per GB but cost per operation; in the worst case 2x operations to write hot then change to Archive depending on blob size)."
      },
      {
        "date": "2022-06-17T00:06:00.000Z",
        "voteCount": 1,
        "content": "The problem with E \"Azure Blob storage account\" is that it must be premium, and premium doesn't support archive tiers. So I think only B is correct!\nhttps://docs.microsoft.com/en-us/azure/storage/blobs/storage-feature-support-in-storage-accounts"
      },
      {
        "date": "2022-06-04T11:04:00.000Z",
        "voteCount": 1,
        "content": ". Blobs in the account inherit this access tier unless you explicitly override the setting for an individual blob."
      },
      {
        "date": "2022-03-12T15:40:00.000Z",
        "voteCount": 2,
        "content": "B and E is the 100% Correct Answer !!!!!!!\n\nHere are the pricing details\nHOT Blob : $0.022 GB/month for First 50 TB\nCOOL Blob : $0.01 GB/month for First 50 TB\nARCHIVE Blob : $0.00099 GB/month for First 50 TB\nFILE : $0.06 GB/month\nClearly Archive Access Tier has the least storage cost.\nand Archive Access Tier provides Standard rehydration in 15 Hours as well as Premium rehydration in 1 hours option (and since cost of access in not part of requirement) !"
      },
      {
        "date": "2022-03-10T00:25:00.000Z",
        "voteCount": 2,
        "content": "B and E - Archive Tier. \nMin storage cost"
      },
      {
        "date": "2022-02-21T11:02:00.000Z",
        "voteCount": 1,
        "content": "I agree with C and D"
      },
      {
        "date": "2022-02-11T12:15:00.000Z",
        "voteCount": 1,
        "content": "Answer should be B and E"
      },
      {
        "date": "2022-01-05T12:18:00.000Z",
        "voteCount": 1,
        "content": "It cannot be general-purpose v1, as it does not support access tiers. It cannot be file share as archive tier will be lower cost compared to file share. Then I would choose Cool as default to minimize cost, hence my options of D and E."
      },
      {
        "date": "2022-01-03T08:51:00.000Z",
        "voteCount": 1,
        "content": "the correct answer"
      },
      {
        "date": "2021-12-20T05:16:00.000Z",
        "voteCount": 5,
        "content": "Correct answer"
      },
      {
        "date": "2021-12-18T04:09:00.000Z",
        "voteCount": 1,
        "content": "Cool and Archiv tier are right answers.\nOthers can be omitted"
      },
      {
        "date": "2022-01-08T10:15:00.000Z",
        "voteCount": 1,
        "content": "B &amp; E is correct."
      },
      {
        "date": "2021-11-13T05:03:00.000Z",
        "voteCount": 1,
        "content": "Everything that includes Archived should be ruled-out.\n- The files must be available within 24 hours of being requested. -&gt; although the time required to get files is up to 15h\n- Storage costs must be minimized -&gt; you will pay for the remaining time (180 - days the file was stored)"
      },
      {
        "date": "2022-01-06T09:45:00.000Z",
        "voteCount": 1,
        "content": "Agree if thee is no \"The files must be available within 24 hours of being requested\"; as you know, this only applies to archived. Containers and File Shares have immediate access."
      },
      {
        "date": "2022-06-24T05:16:00.000Z",
        "voteCount": 1,
        "content": "Why? \"While a blob is in the Archive tier, it can't be read or modified. To read or download a blob in the Archive tier, you must first rehydrate it to an online tier, either Hot or Cool. Data in the Archive tier can take up to 15 hours to rehydrate, depending on the priority you specify for the rehydration operation\" from https://docs.microsoft.com/en-us/azure/storage/blobs/access-tiers-overview, which means it will meet the 24 hour requirment"
      },
      {
        "date": "2021-11-05T08:33:00.000Z",
        "voteCount": 3,
        "content": "Outdated question. Only available options are B and D the rest is legacy."
      },
      {
        "date": "2022-01-18T21:45:00.000Z",
        "voteCount": 1,
        "content": "yes only B and D are the available options from azure portal as at today 19/Jan/2022."
      },
      {
        "date": "2022-06-24T05:18:00.000Z",
        "voteCount": 1,
        "content": "I'm not sure what you are referring to"
      },
      {
        "date": "2021-11-01T18:48:00.000Z",
        "voteCount": 1,
        "content": "B,E\n---"
      },
      {
        "date": "2021-10-15T16:43:00.000Z",
        "voteCount": 1,
        "content": "B &amp; E."
      },
      {
        "date": "2021-10-04T17:31:00.000Z",
        "voteCount": 3,
        "content": "Object storage data tiering between hot, cool, and archive is only supported in Blob storage and General Purpose v2 (GPv2) accounts. General Purpose v1 (GPv1) accounts don't support tiering. Blob storage and GPv2 accounts expose the Access Tier attribute at the account level. This attribute allows you to specify the default access tier for any blob that doesn't have it explicit set at the object level. For objects with the tier set at the object level, the account tier won't apply. The archive tier can be applied only at the object level. You can switch between these access tiers at any time.\n\nI would take B and E"
      },
      {
        "date": "2022-03-29T07:02:00.000Z",
        "voteCount": 1,
        "content": "great explanation."
      }
    ],
    "examNameCode": "az-304",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 39,
    "url": "https://www.examtopics.com/discussions/microsoft/view/61573-exam-az-304-topic-3-question-39-discussion/",
    "body": "You use Azure Application Insights.<br>You plan to use continuous export.<br>You need to store Application Insights data for five years.<br>Which Azure service should you use?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure SQL Database",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure Monitor Logs",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure Backup",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure Storage\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "Create a Continuous Export.<br>1. In the Application Insights resource for your app under configure on the left, open Continuous Export and choose Add:<br>2. Choose the telemetry data types you want to export.<br>3. Create or select an Azure storage account where you want to store the data. Click Add, Export Destination, Storage account, and then either create a new store or choose an existing store.<br>4. Create or select a container in the storage.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/azure-monitor/app/export-telemetry#continuous-export-advanced-storage-configuration",
    "votes": [
      {
        "answer": "D",
        "count": 1,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-10-19T02:46:00.000Z",
        "voteCount": 12,
        "content": "Azure storage is what i choose\ncleared with 900 on 17th October 2021"
      },
      {
        "date": "2021-09-27T16:54:00.000Z",
        "voteCount": 6,
        "content": "Store for five years -&gt; Azure Storage is correct\n\nAnswer is D"
      },
      {
        "date": "2022-06-14T05:42:00.000Z",
        "voteCount": 1,
        "content": "Continuous export is only supported for classic Application Insights resources. Workspace-based Application Insights resources must instead use diagnostic settings (recommended new way of handling telemetry export).\nD"
      },
      {
        "date": "2022-01-30T03:09:00.000Z",
        "voteCount": 1,
        "content": "Answer is D."
      },
      {
        "date": "2021-10-07T15:52:00.000Z",
        "voteCount": 5,
        "content": "Answer is \"D.\"   \"The events you see in the Application Insights portal can be exported to storage in Microsoft Azure in JSON format. From there, you can download your data and write whatever code you need to process it.\"\nhttps://docs.microsoft.com/en-us/azure/azure-monitor/app/export-telemetry"
      },
      {
        "date": "2021-09-12T21:14:00.000Z",
        "voteCount": 2,
        "content": "The answer D is correct. https://docs.microsoft.com/en-us/azure/azure-monitor/app/data-retention-privacy; https://docs.microsoft.com/en-us/azure/azure-monitor/app/export-telemetry"
      },
      {
        "date": "2021-09-12T06:28:00.000Z",
        "voteCount": 1,
        "content": "If this question is still valid, then Azure Storage is correct, to archive the logs in Azure storage account using diagnostic settings. Otherwise send it to Log Analytics workspace for analyzing the data."
      },
      {
        "date": "2021-09-05T08:23:00.000Z",
        "voteCount": 3,
        "content": "\"Continuous export has been deprecated. Migrate to a workspace-based Application Insights resource to use diagnostic settings for exporting telemetry.\"\nhttps://docs.microsoft.com/en-us/azure/azure-monitor/app/export-telemetry"
      },
      {
        "date": "2021-09-09T21:58:00.000Z",
        "voteCount": 1,
        "content": "so what's the answer?"
      },
      {
        "date": "2021-11-17T01:10:00.000Z",
        "voteCount": 2,
        "content": "Still D :)"
      }
    ],
    "examNameCode": "az-304",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 40,
    "url": "https://www.examtopics.com/discussions/microsoft/view/61171-exam-az-304-topic-3-question-40-discussion/",
    "body": "You have an Azure subscription that contains an Azure SQL database.<br>You are evaluating whether to use Azure reservations on the Azure SQL database.<br>Which tool should you use to estimate the potential savings?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tThe Purchase reservations blade in the Azure portal\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tThe Advisor blade in the Azure portal",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tThe SQL database blade in the Azure portal"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 4,
        "isMostVoted": true
      },
      {
        "answer": "B",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2021-09-02T14:58:00.000Z",
        "voteCount": 17,
        "content": "Purchase reservation blade in Azure portal shows percentage of estimated savings."
      },
      {
        "date": "2021-08-31T06:24:00.000Z",
        "voteCount": 7,
        "content": "Correct answer is B (Advisor). Suggested solution (A) is how to purchase the reservation, not how \"to estimate the potential savings.\""
      },
      {
        "date": "2021-08-31T06:27:00.000Z",
        "voteCount": 3,
        "content": "Actually not sure anymore. This can be done in Advisor, but it's in Preview. So maybe A is really correct."
      },
      {
        "date": "2022-03-19T22:38:00.000Z",
        "voteCount": 1,
        "content": "Agreed. Should be Advisor. \nhttps://docs.microsoft.com/en-us/azure/cost-management-billing/costs/tutorial-acm-opt-recommendations"
      },
      {
        "date": "2022-07-03T07:37:00.000Z",
        "voteCount": 1,
        "content": "I would like an example of why you think that. The purchase reservations clearly gives you an estimation of savings, where the Advisor advises you on how to tighten up your tenant."
      },
      {
        "date": "2022-08-23T05:51:00.000Z",
        "voteCount": 1,
        "content": "Azure advisor also shows potential saving"
      },
      {
        "date": "2022-03-19T22:38:00.000Z",
        "voteCount": 1,
        "content": "https://docs.microsoft.com/en-us/azure/cost-management-billing/costs/tutorial-acm-opt-recommendations"
      },
      {
        "date": "2022-03-15T08:51:00.000Z",
        "voteCount": 1,
        "content": "A seems correct"
      },
      {
        "date": "2022-02-10T04:39:00.000Z",
        "voteCount": 1,
        "content": "Yes A is right, but be aware the this feature is not available in a subscription paid in CSP. This should be done with your Solution Aggregator platform."
      },
      {
        "date": "2022-02-10T04:38:00.000Z",
        "voteCount": 1,
        "content": "Yes A is right, but be aware that this feature is not available in CSP and should be done through youhttps://www.examtopics.com/exams/microsoft/az-304/view/25/#r Solution Aggregator."
      },
      {
        "date": "2022-01-30T03:12:00.000Z",
        "voteCount": 1,
        "content": "A is correct."
      },
      {
        "date": "2021-12-26T10:27:00.000Z",
        "voteCount": 2,
        "content": "1000% A CORRECT"
      },
      {
        "date": "2022-02-13T01:50:00.000Z",
        "voteCount": 2,
        "content": "1000000000000000000000000000%"
      },
      {
        "date": "2021-10-07T15:57:00.000Z",
        "voteCount": 1,
        "content": "For arguments sake...lets go with \"A.\""
      },
      {
        "date": "2021-10-03T17:21:00.000Z",
        "voteCount": 2,
        "content": "https://docs.microsoft.com/en-us/azure/azure-sql/database/reserved-capacity-overview\nhttps://docs.microsoft.com/en-us/azure/cost-management-billing/reservations/save-compute-costs-reservations\n\nAnswer is A"
      },
      {
        "date": "2021-10-01T19:50:00.000Z",
        "voteCount": 1,
        "content": "Correct"
      },
      {
        "date": "2021-09-12T21:32:00.000Z",
        "voteCount": 3,
        "content": "A is correct answer. https://docs.microsoft.com/en-us/azure/cost-management-billing/reservations/save-compute-costs-reservations"
      }
    ],
    "examNameCode": "az-304",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 41,
    "url": "https://www.examtopics.com/discussions/microsoft/view/61400-exam-az-304-topic-3-question-41-discussion/",
    "body": "HOTSPOT -<br>You have an Azure subscription that contains the storage accounts shown in the following table.<br><img src=\"/assets/media/exam-media/04027/0018400001.png\" class=\"in-exam-image\"><br>You plan to implement two new apps that have the requirements shown in the following table.<br><img src=\"/assets/media/exam-media/04027/0018400002.png\" class=\"in-exam-image\"><br>Which storage accounts should you recommend using for each app? To answer, select the appropriate options in the answer area.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04027/0018500001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04027/0018600001.png\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: Storage1, storage2, and storage3 only<br>Azure Blob Storage lifecycle management offers a rich, rule-based policy for GPv2 and blob storage accounts. Use the policy to transition your data to the appropriate access tiers or expire at the end of the data's lifecycle.<br>Box 2: Storage1, storage2, and storage4 only<br>General purpose version 2 (GPv2) storage accounts: GPv2 storage accounts allow you to deploy Azure file shares on standard/hard disk-based (HDD-based) hardware.<br>FileStorage storage accounts: FileStorage storage accounts allow you to deploy Azure file shares on premium/solid-state disk-based (SSD-based) hardware.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/storage/blobs/storage-lifecycle-management-concepts",
    "votes": [],
    "comments": [
      {
        "date": "2021-09-24T10:12:00.000Z",
        "voteCount": 29,
        "content": "Box 1 - Storage 1 and 3\nBox 2 - Storage 1, 2 and 4"
      },
      {
        "date": "2022-06-04T11:17:00.000Z",
        "voteCount": 1,
        "content": "I was so confused ... you are the G.O.A.T"
      },
      {
        "date": "2021-12-02T09:44:00.000Z",
        "voteCount": 55,
        "content": "Hey guys, the problem here is a question based on an old version of Azure Storage Account service.\nCurrently there is no GPv2 Premium storage account but only standard performance tier. In addition we have Premium Block Blobs, Premium File Shares and Premium Page Blobs services:\n\nhttps://docs.microsoft.com/en-us/azure/storage/common/storage-account-overview\n\nUnfortunately microsoft exams are full of questions about this old version of the storage account so I decided to deepen reconstructing its history. It would appear in fact that the current composition of the service is a 2019 update. I refer you in particular to the following article that explains everything very well and at the bottom has a summary table that contains just what we need.\n\nhttps://www.skylinesacademy.com/blog/2019/6/28/azure-storage-options-explained\n\nAlso for more insights you can read these:\n\nhttps://www.edureka.co/community/40011/different-storage-accounts-there-major-difference-between\n\nhttps://insidemstech.com/tag/general-purpose-v2/\n\nIn conclusion the correct answers are: \nBox1 --&gt; 1 and 3\nBox2 --&gt; 1 and 4"
      },
      {
        "date": "2021-12-30T07:00:00.000Z",
        "voteCount": 1,
        "content": "Correct!\n\nBox1:\nhttps://docs.microsoft.com/en-us/azure/storage/blobs/access-tiers-overview#feature-support\n\nBox2:\n\"Azure Files supports two storage tiers: premium and standard. Standard file shares are created in general purpose (GPv1 or GPv2) storage accounts and premium file shares are created in FileStorage storage accounts. Learn more about how to create standard file shares and premium file shares.\""
      },
      {
        "date": "2022-02-01T21:20:00.000Z",
        "voteCount": 1,
        "content": "i support this"
      },
      {
        "date": "2022-07-03T07:49:00.000Z",
        "voteCount": 1,
        "content": "Admittedly this one threw me. When you pointed out the V2 Premium/Standard part I realized I was very wrong and you are very right. Thanks for this post."
      },
      {
        "date": "2021-10-30T04:03:00.000Z",
        "voteCount": 22,
        "content": "Box 1 - Storage 1 and 3\nBox 2 - Storage 1 and 4"
      },
      {
        "date": "2021-11-17T01:36:00.000Z",
        "voteCount": 4,
        "content": "Box 2: You are right. https://docs.microsoft.com/en-us/azure/storage/files/storage-how-to-create-file-share?tabs=azure-portal#basics"
      },
      {
        "date": "2022-04-09T04:31:00.000Z",
        "voteCount": 4,
        "content": "In AZ-305 exam, 9 april 22"
      },
      {
        "date": "2022-03-22T23:20:00.000Z",
        "voteCount": 1,
        "content": "Answer is correct. See : \nhttps://docs.microsoft.com/en-us/azure/storage/blobs/lifecycle-management-overview"
      },
      {
        "date": "2022-03-10T00:30:00.000Z",
        "voteCount": 2,
        "content": "Box 1 - Storage 1 and 3\nBox 2 - Storage 1 and 4"
      },
      {
        "date": "2021-10-18T23:56:00.000Z",
        "voteCount": 6,
        "content": "For who concern about premium doesn't support tiering\nhttps://docs.microsoft.com/en-us/azure/storage/blobs/access-tiers-overview\nData stored in a premium block blob storage account cannot be tiered to hot, cool, or archive using Set Blob Tier or using Azure Blob Storage lifecycle management"
      },
      {
        "date": "2021-10-08T10:45:00.000Z",
        "voteCount": 6,
        "content": "Box 1 - Storage 1 and 3\nBox 2 - Storage 1 and 4"
      },
      {
        "date": "2021-10-07T05:43:00.000Z",
        "voteCount": 5,
        "content": "Box 1 - Storage 1 and 3\nBox 2 - Storage 1 and 4"
      },
      {
        "date": "2021-10-05T03:18:00.000Z",
        "voteCount": 6,
        "content": "https://docs.microsoft.com/en-us/azure/storage/blobs/lifecycle-management-overview\n\nLifecycle management policies are supported for block blobs and append blobs in general-purpose v2, premium block blob, and Blob Storage accounts\n\nhttps://docs.microsoft.com/en-us/azure/storage/blobs/storage-blob-performance-tiers#blob-lifecycle-management\n\nBlob storage lifecycle management offers a rich, rule-based policy:\n\nPremium: Expire data at the end of its lifecycle.\n\nStorage 1, 2 and 3 for lifecycle\n\nStorage 1,2 and 4 for file share for sure"
      },
      {
        "date": "2021-10-06T04:04:00.000Z",
        "voteCount": 1,
        "content": "storage 2 does not support access tiers being premium V2"
      },
      {
        "date": "2021-10-06T04:28:00.000Z",
        "voteCount": 1,
        "content": "https://azure.microsoft.com/en-us/blog/azure-premium-block-blob-storage-is-now-generally-available/#:~:text=At%20present%2C%20data%20stored%20in,v10%2C%20which%20supports%20this%20API."
      },
      {
        "date": "2021-10-15T02:13:00.000Z",
        "voteCount": 1,
        "content": "Provided link is dated in 2019, see the below latest link from MS Doc.\nhttps://docs.microsoft.com/en-us/azure/storage/blobs/lifecycle-management-overview#:~:text=Lifecycle%20management%20policies%20are%20supported%20for%20block%20blobs%20and%20append%20blobs%20in%20general-purpose%20v2%2C%20premium%20block%20blob%2C%20and%20Blob%20Storage%20accounts.%20Lifecycle%20management%20does%20not%20affect%20system%20containers%20such%20as%20the%20%24logs%20or%20%24web%20containers."
      },
      {
        "date": "2021-10-06T05:15:00.000Z",
        "voteCount": 2,
        "content": "Box 1 - Storage 1 and 3\nBox 2 - Storage 1, 2 and 4"
      },
      {
        "date": "2021-10-06T06:21:00.000Z",
        "voteCount": 2,
        "content": "Sorry for 2nd option its 1 &amp; 4 only...not 2...as V2 with Premium Tier don't support file."
      },
      {
        "date": "2022-01-01T08:42:00.000Z",
        "voteCount": 1,
        "content": "As far as I can tell, V2 with premium tier doesnt exist (anymore)"
      },
      {
        "date": "2021-09-16T11:13:00.000Z",
        "voteCount": 2,
        "content": "Storage2 is a premium storage account wich does not support tiering. So anwser 1 is storage 1 and 3."
      },
      {
        "date": "2021-09-11T21:49:00.000Z",
        "voteCount": 3,
        "content": "I think the answer should be\nApp1: 1,2,3,4. Since Azure file share also has different Tier\nApp2: 1,2,4 is correct"
      },
      {
        "date": "2021-09-20T19:24:00.000Z",
        "voteCount": 2,
        "content": "Please read the question before commenting.. Premium storage doesn't support tiers."
      },
      {
        "date": "2021-10-05T23:42:00.000Z",
        "voteCount": 4,
        "content": "Don't just copy others' comments, please share the link where saying Premium storage doesn't support tiering."
      },
      {
        "date": "2021-12-29T08:31:00.000Z",
        "voteCount": 1,
        "content": "Vincent, as of 12/29/21, Premium storage does not support hot/cold/archive tiers.  It is mentioned in this feature table and also in another section in the same article\n\nhttps://docs.microsoft.com/en-us/azure/storage/blobs/access-tiers-overview#feature-support"
      },
      {
        "date": "2021-09-08T19:17:00.000Z",
        "voteCount": 15,
        "content": "Correct\nApp1: 1, 2, 3\nhttps://docs.microsoft.com/en-us/azure/storage/blobs/storage-blob-storage-tiers#storage-accounts-that-support-tiering\n\nApp2: 1, 2, 4\nhttps://docs.microsoft.com/ja-jp/azure/storage/common/storage-account-overview#types-of-storage-accounts"
      },
      {
        "date": "2021-11-01T01:53:00.000Z",
        "voteCount": 4,
        "content": "premium storage cannot move between tiers, because it have only one tier \napp1: should 1 and 3"
      },
      {
        "date": "2021-09-05T08:37:00.000Z",
        "voteCount": 1,
        "content": "jamess...you said \"so app1 needs to be storage1, storage2 and storage4.\" For app 1 there is NO answer for: storage 1, storage 2, and storage 4. Also, for app 2...there is no such answer for \"app2 should be storage1, storage2, storage3\"  So did you get the boxes mixed up? Im just asking."
      },
      {
        "date": "2021-09-04T05:47:00.000Z",
        "voteCount": 1,
        "content": "az_architect that is incorrect. gpv2 and blob support access tiers. https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blob-storage-tiers\ngpv1 does not support access tiers.\nso it says 'app 2 application data' which possibly means logs or database/table data. which can't go into 'file storage'. it has to be gpv1, gpv2 or blob to store in tables. so app1 needs to be storage1, storage2 and storage4. app2 should be storage1, storage2, storage3"
      },
      {
        "date": "2021-09-02T10:27:00.000Z",
        "voteCount": 6,
        "content": "storage 2 does not support access tiers. Hence storage 1&amp; storage 3 for first application. Storage 1 and 4 for the second application."
      }
    ],
    "examNameCode": "az-304",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 42,
    "url": "https://www.examtopics.com/discussions/microsoft/view/61311-exam-az-304-topic-3-question-42-discussion/",
    "body": "You have an Azure subscription that contains an Azure SQL database.<br>You plan to use Azure reservations on the Azure SQL database.<br>To which resource type will the reservation discount be applied?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tvCore compute\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDTU compute",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tStorage",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tLicense"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 8,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-09-01T12:47:00.000Z",
        "voteCount": 9,
        "content": "Correct"
      },
      {
        "date": "2021-10-04T04:33:00.000Z",
        "voteCount": 5,
        "content": "C and D are out for sure\n\nhttps://docs.microsoft.com/en-us/azure/azure-sql/database/reserved-capacity-overview#limitation\n\nYou cannot reserve DTU-based (basic, standard, or premium) databases in SQL Database. Reserved capacity pricing is only supported for features and products that are in General Availability state.\n\nAnswer is A"
      },
      {
        "date": "2022-03-26T08:02:00.000Z",
        "voteCount": 1,
        "content": "For Azure SQL Database, Azure Hybrid Benefit is only available when using the provisioned compute tier of the vCore-based purchasing model. Azure Hybrid Benefit doesn't apply to DTU-based purchasing models or the serverless compute tier.\n\nhttps://docs.microsoft.com/en-us/azure/azure-sql/azure-hybrid-benefit?tabs=azure-portal"
      },
      {
        "date": "2022-06-04T11:21:00.000Z",
        "voteCount": 1,
        "content": "Wrong reasons. Who said anything about Hybrid Benefit ?\nReserved instances is a separate topic"
      },
      {
        "date": "2022-03-15T13:07:00.000Z",
        "voteCount": 1,
        "content": "Correct"
      },
      {
        "date": "2021-12-01T17:23:00.000Z",
        "voteCount": 4,
        "content": "A seems correct"
      },
      {
        "date": "2021-11-26T15:08:00.000Z",
        "voteCount": 3,
        "content": "correct"
      },
      {
        "date": "2021-09-08T19:23:00.000Z",
        "voteCount": 4,
        "content": "correct: \nhttps://docs.microsoft.com/ja-jp/azure/cost-management-billing/reservations/save-compute-costs-reservations#charges-covered-by-reservation"
      }
    ],
    "examNameCode": "az-304",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 43,
    "url": "https://www.examtopics.com/discussions/microsoft/view/61731-exam-az-304-topic-3-question-43-discussion/",
    "body": "You are designing an Azure Cosmos DB solution that will host multiple writable replicas in multiple Azure regions.<br>You need to recommend the strongest database consistency level for the design. The solution must meet the following requirements:<br>\u2711 Provide a latency-based Service Level Agreement (SLA) for writes.<br>\u2711 Support multiple regions.<br>Which consistency level should you recommend?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tbounded staleness\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tstrong",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tsession",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tconsistent prefix"
    ],
    "answer": "A",
    "answerDescription": "Each level provides availability and performance tradeoffs. The following image shows the different consistency levels as a spectrum.<br><img src=\"/assets/media/exam-media/04027/0018800001.jpg\" class=\"in-exam-image\"><br>Note: The service offers comprehensive 99.99% SLAs which covers the guarantees for throughput, consistency, availability and latency for the Azure Cosmos DB<br>Database Accounts scoped to a single Azure region configured with any of the five Consistency Levels or Database Accounts spanning multiple Azure regions, configured with any of the four relaxed Consistency Levels.<br>Incorrect Answers:<br>B: Strong consistency for accounts with regions spanning more than 5000 miles (8000 kilometers) is blocked by default due to high write latency. To enable this capability please contact support.<br>Reference:<br>https://azure.microsoft.com/en-us/support/legal/sla/cosmos-db/v1_3/ https://docs.microsoft.com/en-us/azure/cosmos-db/consistency-levels#consistency-levels-and-latency",
    "votes": [
      {
        "answer": "A",
        "count": 1,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-09-08T18:42:00.000Z",
        "voteCount": 18,
        "content": "Bounded staleness\nhttps://docs.microsoft.com/en-us/azure/cosmos-db/consistency-levels\nBounded staleness is frequently chosen by globally distributed applications that expect low write latencies but require total global order guarantee. Bounded staleness is great for applications featuring group collaboration and sharing, stock ticker, publish-subscribe/queueing etc."
      },
      {
        "date": "2021-09-08T20:41:00.000Z",
        "voteCount": 5,
        "content": "B: Strong ?    \nhttps://docs.microsoft.com/ja-jp/azure/cosmos-db/consistency-levels"
      },
      {
        "date": "2021-11-09T15:09:00.000Z",
        "voteCount": 1,
        "content": "Not if the regions span more than 5000 miles"
      },
      {
        "date": "2022-03-15T08:52:00.000Z",
        "voteCount": 1,
        "content": "Seems correct"
      },
      {
        "date": "2022-01-01T08:56:00.000Z",
        "voteCount": 1,
        "content": "\"Provide a latency-based Service Level Agreement (SLA) for writes.\" is actually the key here I think.\n\nFor Azure Cosmos accounts configured with strong consistency with more than one region, the write latency is equal to two times round-trip time (RTT) between any of the two farthest regions, plus 10 milliseconds at the 99th percentile. High network RTT between the regions will translate to higher latency for Cosmos DB requests since strong consistency completes an operation only after ensuring that it has been committed to all regions within an account.\n\nThe exact RTT latency is a function of speed-of-light distance and the Azure networking topology. Azure networking doesn't provide any latency SLAs for the RTT between any two Azure regions, however it does publish Azure network round-trip latency statistics.\n\nhttps://docs.microsoft.com/en-us/azure/cosmos-db/consistency-levels"
      },
      {
        "date": "2022-01-01T08:59:00.000Z",
        "voteCount": 2,
        "content": "See also here for Bounded Staleness write latency SLA \n\nhttps://azure.microsoft.com/en-gb/support/legal/sla/cosmos-db/v1_3/"
      },
      {
        "date": "2021-10-04T06:28:00.000Z",
        "voteCount": 3,
        "content": "Strong consistency for accounts with regions spanning more than 5000 miles (8000 kilometers) is blocked by default due to high write latency. To enable this capability please contact support.\n\nIn session consistency, within a single client session reads are guaranteed to honor the consistent-prefix, monotonic reads, monotonic writes, read-your-writes, and write-follows-reads guarantees.\n\nIn consistent prefix option, updates that are returned contain some prefix of all the updates, with no gaps. Consistent prefix consistency level guarantees that reads never see out-of-order writes.\n\nAnswer is A"
      },
      {
        "date": "2021-09-27T07:34:00.000Z",
        "voteCount": 2,
        "content": "A bounded stateless due to - https://docs.microsoft.com/en-us/azure/cosmos-db/consistency-levels#write-latency-and-strong-consistency this paragrpah \"For Azure Cosmos accounts configured with strong consistency with more than one region, the write latency is equal to two times round-trip time (RTT) between any of the two farthest regions, plus 10 milliseconds at the 99th percentile. High network RTT between the regions will translate to higher latency for Cosmos DB requests since strong consistency completes an operation only after ensuring that it has been committed to all regions within an account.\nThe exact RTT latency is a function of speed-of-light distance and the Azure networking topology. Azure networking doesn't provide any latency SLAs for the RTT between any two Azure regions, however it does publish Azure network round-trip latency statistics.\""
      }
    ],
    "examNameCode": "az-304",
    "topicNumber": "3"
  }
]