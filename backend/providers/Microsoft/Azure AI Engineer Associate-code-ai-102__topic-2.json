[
  {
    "topic": 2,
    "index": 1,
    "url": "https://www.examtopics.com/discussions/microsoft/view/54796-exam-ai-102-topic-2-question-1-discussion/",
    "body": "HOTSPOT -<br>You are developing an application that will use the Computer Vision client library. The application has the following code.<br><img src=\"/assets/media/exam-media/04271/0008000001.png\" class=\"in-exam-image\"><br>For each of the following statements, select Yes if the statement is true. Otherwise, select No.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04271/0008100001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04271/0008100002.png\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: No -<br><br>Box 2: Yes -<br>The ComputerVision.analyzeImageInStreamAsync operation extracts a rich set of visual features based on the image content.<br><br>Box 3: No -<br>Images will be read from a stream.<br>Reference:<br>https://docs.microsoft.com/en-us/java/api/com.microsoft.azure.cognitiveservices.vision.computervision.computervision.analyzeimageinstreamasync",
    "votes": [],
    "comments": [
      {
        "date": "2021-06-07T05:15:00.000Z",
        "voteCount": 86,
        "content": "Box 3 is Yes, the stream will be generated from a local image!"
      },
      {
        "date": "2024-08-12T03:00:00.000Z",
        "voteCount": 2,
        "content": "Agree with this man"
      },
      {
        "date": "2021-07-04T05:38:00.000Z",
        "voteCount": 36,
        "content": "Box 3 should be Yes, a stream is only a pathway for data. and in this case the data actually comes from a local file. The correct answer would be No, Yes, Yes."
      },
      {
        "date": "2024-09-01T09:27:00.000Z",
        "voteCount": 1,
        "content": "1. **The code will perform face recognition.**  \n   **Answer:** No  \n   The code uses the `ComputerVisionClient` to analyze an image for visual features such as `Description` and `Tags`, not for face recognition.\n\n2. **The code will list tags and their associated confidence.**  \n   **Answer:** Yes  \n   The code retrieves tags and their confidence scores from the `results.Tags` property and outputs them.\n\n3. **The code will read a file from the local file system.**  \n   **Answer:** Yes  \n   The code uses `File.OpenRead(localImage)` to read an image file from the local file system."
      },
      {
        "date": "2024-06-29T23:28:00.000Z",
        "voteCount": 1,
        "content": "N - Y - Y"
      },
      {
        "date": "2024-06-15T05:55:00.000Z",
        "voteCount": 7,
        "content": "The code will perform face recognition --&gt; No\nThe code will list tags and their associated confidence --&gt; Yes\nThe code will read a file from the local file system --&gt; Yes"
      },
      {
        "date": "2024-06-06T08:11:00.000Z",
        "voteCount": 3,
        "content": "The code will perform face recognition.\nNo. The code is set to analyze image descriptions and tags (VisualFeatureTypes.Description, VisualFeatureTypes.Tags), but it does not include face recognition.\n\n\nThe code will list tags and their associated confidence.\nYes. The code includes a loop that iterates through results.Tags and prints each tag's name and confidence.\n\nThe code will read a file from the local file system.\nYes. The code uses File.OpenRead(localImage) to open and read an image file from the local file system.\n\nSo, the answers are:\n\nThe code will perform face recognition. No\nThe code will list tags and their associated confidence. Yes\nThe code will read a file from the local file system. Yes"
      },
      {
        "date": "2024-06-06T05:02:00.000Z",
        "voteCount": 1,
        "content": "https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/quickstarts-sdk/image-analysis-client-library?tabs=windows%2Cvisual-studio&amp;pivots=programming-language-csharp#analyze-image"
      },
      {
        "date": "2024-05-28T06:53:00.000Z",
        "voteCount": 2,
        "content": "No\nYes\nYes"
      },
      {
        "date": "2024-05-01T05:04:00.000Z",
        "voteCount": 3,
        "content": "No Yes Yes\nImage analysis\nReturn the category and confident score\nRead local video streaming or streaming source"
      },
      {
        "date": "2024-04-11T21:58:00.000Z",
        "voteCount": 1,
        "content": "The fact that the parameter is named 'local', might be misleading - it could be anything. \nHOWEVER, I'm not a C# expert, but File.OpenRead tells us that the file is on a filesystem to which the device has access. \nSO my vote is NYY"
      },
      {
        "date": "2024-03-25T03:21:00.000Z",
        "voteCount": 1,
        "content": "Final Answer:\nN Y Y"
      },
      {
        "date": "2023-11-02T14:12:00.000Z",
        "voteCount": 3,
        "content": "To me correct answers are NYY. localImage parameter is a string, that's a file path"
      },
      {
        "date": "2023-07-01T01:28:00.000Z",
        "voteCount": 11,
        "content": "NYY is the answer.\n\nhttps://learn.microsoft.com/en-us/java/api/com.microsoft.azure.cognitiveservices.vision.computervision.computervision?view=azure-java-legacy#com-microsoft-azure-cognitiveservices-vision-computervision-computervision-analyzeimageinstreamasync(byte-()-analyzeimageinstreamoptionalparameter)\nhis operation extracts a rich set of visual features based on the image content. Two input methods are supported (1) Uploading an image or (2) specifying an image URL."
      },
      {
        "date": "2023-10-21T09:31:00.000Z",
        "voteCount": 1,
        "content": "NYN\nBox 3: No.... because the image (whether uploaded or a URL), the CODE will read it as a An image STEAM. Please continue reading the same URL you shared."
      },
      {
        "date": "2023-10-22T11:09:00.000Z",
        "voteCount": 5,
        "content": "File.OpenRead is a System.IO method and reads file from the local storage path provided as a parameter hence last one is Y as it reads file from local storage\n\nhttps://learn.microsoft.com/en-us/dotnet/api/system.io.file.openread?view=net-7.0"
      },
      {
        "date": "2022-08-12T07:30:00.000Z",
        "voteCount": 6,
        "content": "Box 1: No.  The code generates description and tags. See line 3,4\nBox 2: Yes. The code displays tag.Name and tag.Confidence\nBox 3: Yes.  File.OpenRead reads a local file. See https://docs.microsoft.com/en-us/dotnet/api/system.io.file.openread?view=net-6.0"
      },
      {
        "date": "2022-07-15T22:43:00.000Z",
        "voteCount": 2,
        "content": "No\nYes\nYes"
      },
      {
        "date": "2022-06-25T07:43:00.000Z",
        "voteCount": 3,
        "content": "Answer is NYY"
      },
      {
        "date": "2022-04-23T16:36:00.000Z",
        "voteCount": 1,
        "content": "https://docs.microsoft.com/en-us/java/api/com.microsoft.azure.cognitiveservices.vision.computervision.computervision.analyzeimageinstreamasync?view=azure-java-legacy"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 2,
    "url": "https://www.examtopics.com/discussions/microsoft/view/74739-exam-ai-102-topic-2-question-2-discussion/",
    "body": "You are developing a method that uses the Computer Vision client library. The method will perform optical character recognition (OCR) in images. The method has the following code.<br><img src=\"/assets/media/exam-media/04271/0008200001.jpg\" class=\"in-exam-image\"><br>During testing, you discover that the call to the GetReadResultAsync method occurs before the read operation is complete.<br>You need to prevent the GetReadResultAsync method from proceeding until the read operation is complete.<br>Which two actions should you perform? Each correct answer presents part of the solution.<br>NOTE: Each correct selection is worth one point.<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRemove the Guid.Parse(operationId) parameter.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAdd code to verify the results.Status value.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAdd code to verify the status of the txtHeaders.Status value.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tWrap the call to GetReadResultAsync within a loop that contains a delay.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "BD",
    "answerDescription": "",
    "votes": [
      {
        "answer": "BD",
        "count": 17,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2022-06-21T23:03:00.000Z",
        "voteCount": 13,
        "content": "as per link in solution"
      },
      {
        "date": "2022-06-21T23:09:00.000Z",
        "voteCount": 5,
        "content": "and looking at what getReadAsync and getReadResultAsync methods return. \ngetReadResultAsync returns Observable&lt;ReadOperationResult&gt; object which contains as status() method."
      },
      {
        "date": "2022-06-21T23:11:00.000Z",
        "voteCount": 4,
        "content": "getReadAsync doesn't have status method. Answer is B and D\nhttps://docs.microsoft.com/en-us/dotnet/api/system.io.stream.readasync?view=net-6.0"
      },
      {
        "date": "2023-06-27T23:17:00.000Z",
        "voteCount": 6,
        "content": "this appeared in the exam 28/06"
      },
      {
        "date": "2024-05-25T07:15:00.000Z",
        "voteCount": 1,
        "content": "results.Status\nGetReadResultAsync"
      },
      {
        "date": "2023-11-02T14:22:00.000Z",
        "voteCount": 3,
        "content": "provided answer seems correct. The attached documentation demonstrate it"
      },
      {
        "date": "2022-06-07T05:27:00.000Z",
        "voteCount": 3,
        "content": "was on exam 7 Jun 2022"
      },
      {
        "date": "2022-04-28T01:44:00.000Z",
        "voteCount": 3,
        "content": "C and D are the correct answers."
      },
      {
        "date": "2022-07-07T03:50:00.000Z",
        "voteCount": 1,
        "content": "I don't think C is one of the answer based on https://github.com/Azure-Samples/cognitive-services-quickstart-code/blob/master/dotnet/ComputerVision/ComputerVisionQuickstart.cs.\n\nIt seems results.Status is part of the while condition, hence I agree with dokmak's B and D"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 3,
    "url": "https://www.examtopics.com/discussions/microsoft/view/60330-exam-ai-102-topic-2-question-3-discussion/",
    "body": "HOTSPOT -<br>You have a Computer Vision resource named contoso1 that is hosted in the West US Azure region.<br>You need to use contoso1 to make a different size of a product photo by using the smart cropping feature.<br>How should you complete the API URL? To answer, select the appropriate options in the answer area.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04271/0008300001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04271/0008400001.png\" class=\"in-exam-image\">",
    "answerDescription": "Reference:<br>https://westus.dev.cognitive.microsoft.com/docs/services/computer-vision-v3-2/operations/56f91f2e778daf14a499f21b https://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/concept-generating-thumbnails#examples",
    "votes": [],
    "comments": [
      {
        "date": "2021-08-24T10:33:00.000Z",
        "voteCount": 57,
        "content": "The second one should be generate Thumbnail imho."
      },
      {
        "date": "2021-09-02T23:44:00.000Z",
        "voteCount": 13,
        "content": "yes, the question is exactly the sample here \nhttps://docs.microsoft.com/en-us/rest/api/computervision/3.1/generate-thumbnail/generate-thumbnail#examples"
      },
      {
        "date": "2023-11-02T14:34:00.000Z",
        "voteCount": 1,
        "content": "agree with you"
      },
      {
        "date": "2023-11-02T14:40:00.000Z",
        "voteCount": 1,
        "content": "however, I don't understand how I do using the generic endpoint to meet the requirement, \"You need to use contoso1 to make a different size of a product photo\". I'm not so sure to use the generic endpoint."
      },
      {
        "date": "2023-11-02T14:46:00.000Z",
        "voteCount": 8,
        "content": "Clarified. If you go on the API documentation https://westus.dev.cognitive.microsoft.com/docs/services/computer-vision-v3-2/operations/56f91f2e778daf14a499f20c/console (here is the version 3.2 but it's the same) you can verify that both type of endpoint are supported. If you choose a custom endpoint named contos1 you'll get the following url request:\nhttps://westus.dev.cognitive.microsoft.com/docs/services/computer-vision-v3-2/operations/56f91f2e778daf14a499f20c/console.\n\nSo correct answers are \nhttps://contoso1.cognitiveservices.azure.com/\ngenerateThumbnail"
      },
      {
        "date": "2023-11-02T14:48:00.000Z",
        "voteCount": 1,
        "content": "sorry i pasted twice the same url in the message before:\nwith the custom endpoint the url of the service is:\nhttps://contoso1.cognitiveservices.azure.com/vision/v3.2/generateThumbnail?width=300&amp;height=200&amp;smartCropping=true&amp;model-version=latest"
      },
      {
        "date": "2021-10-26T10:38:00.000Z",
        "voteCount": 46,
        "content": "Both answers are incorrect.\n\nThe correct answers are:\nhttps://contoso1.cognitiveservices.azure.com/\nAND\ngenerateThumbnail\n\nwestus.dev.cognitive.microsoft.com wouldn't be a correct Computer Vision endpoint if the resource name is contoso1.\n\nAlso, per the documentation, areaOfInterest \"returns a bounding box around the most important area of the image\", it doesn't return a different size photo (https://docs.microsoft.com/en-us/rest/api/computervision/3.1/get-area-of-interest)."
      },
      {
        "date": "2022-07-14T04:15:00.000Z",
        "voteCount": 8,
        "content": "I agree with generateThumbnail, however first answer provided by ET should be correct https://westus.api.cognitive.microsoft.com as shown in https://docs.microsoft.com/en-us/rest/api/computervision/3.1/generate-thumbnail/generate-thumbnail?tabs=HTTP#examples"
      },
      {
        "date": "2023-04-06T06:42:00.000Z",
        "voteCount": 3,
        "content": "contoso1 is a Computer Vision resource, so you would not specify /vision in the URL.  Therefore I think the correct answer must be westus.api.cognitive.microsoft.com"
      },
      {
        "date": "2023-02-11T16:56:00.000Z",
        "voteCount": 1,
        "content": "I agree with both answers here. The example https://westus.api.cognitive.microsoft.com is just an example and it needs to be changed to use the source in real which is contoso1."
      },
      {
        "date": "2023-07-22T00:59:00.000Z",
        "voteCount": 11,
        "content": "Today (july 2023), both regional and resource endpoints are supported. So both are correct : \nhttps://contoso1.cognitiveservices.azure.com/ \nAND \nhttps://westus.api.cognitive.microsoft.com\n\nDoc : https://learn.microsoft.com/en-us/azure/ai-services/cognitive-services-custom-subdomains#what-if-an-sdk-asks-me-for-the-region-for-a-resource\n\"Regional endpoints and custom subdomain names are both supported and can be used interchangeably.\"\n\nI tested it by creating a custom vision resource and used it with both endpoints."
      },
      {
        "date": "2024-03-21T18:17:00.000Z",
        "voteCount": 1,
        "content": "Yes, I think the key thing is that the key is specified."
      },
      {
        "date": "2024-06-22T04:52:00.000Z",
        "voteCount": 1,
        "content": "POST https://westus.api.cognitive.microsoft.com/vision/v3.2/generateThumbnail?width=500&amp;height=500&amp;smartCropping=True\n\n\n{\n  \"url\": \"{url}\"\n}"
      },
      {
        "date": "2024-05-28T06:51:00.000Z",
        "voteCount": 2,
        "content": "1. contoso1\n2. gererateThumbnail"
      },
      {
        "date": "2024-03-27T19:40:00.000Z",
        "voteCount": 3,
        "content": "Final Answer:\n1. https://contoso1.cognitiveservices.azure.com/\n2. generateThumbnail"
      },
      {
        "date": "2024-03-16T08:36:00.000Z",
        "voteCount": 2,
        "content": "API URL:\nThe base URL for the Analyze Image 4.0 API is typically:\nhttps://&lt;region&gt;.api.cognitive.microsoft.com/vision/v4.0/analyze\n\nReplace &lt;region&gt; with the appropriate Azure region (in this case, West US)."
      },
      {
        "date": "2023-08-25T04:49:00.000Z",
        "voteCount": 1,
        "content": "\"You need to use contoso1 to make a different size of a product photo by using the smart cropping feature.\" -&gt; You need to use contoso1 to make....  that is hosted in the west us...."
      },
      {
        "date": "2023-07-01T01:22:00.000Z",
        "voteCount": 12,
        "content": "1. https://contoso1.cognitiveservices.azure.com\n2. generateThumbnail\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/computer-vision/concept-generating-thumbnails\nA thumbnail is a reduced-size representation of an image. Thumbnails are used to represent images and other data in a more economical, layout-friendly way. The Computer Vision API uses smart cropping to create intuitive image thumbnails that include the most important regions of an image with priority given to any detected faces.\n\nThe Computer Vision thumbnail generation algorithm works as follows:\n- Remove distracting elements from the image and identify the area of interest\u2014the area of the image in which the main object(s) appears.\n- Crop the image based on the identified area of interest.\n- Change the aspect ratio to fit the target thumbnail dimensions."
      },
      {
        "date": "2023-06-27T23:19:00.000Z",
        "voteCount": 4,
        "content": "was on exam 28/06/2023"
      },
      {
        "date": "2023-06-04T11:21:00.000Z",
        "voteCount": 3,
        "content": "I simulated this in Azure Portal:\n1. endpoint is https://contoso1.cognitiveservices.azure.com/\n2. thumbnail"
      },
      {
        "date": "2023-04-09T19:49:00.000Z",
        "voteCount": 5,
        "content": "https://contoso1.cognitiveservices.azure.com/ is correct.\n\nContext from ChatGPT:\nwestus.api.cognitive.microsoft.com is also a valid endpoint for the Cognitive Services APIs, including the Computer Vision API. However, it is important to note that this endpoint is deprecated and will be retired on October 31, 2024.\n\nTherefore, it is recommended to use the newer endpoint format https://&lt;resource-name&gt;.cognitiveservices.azure.com/ for any new development work. This endpoint format follows a more standard Azure resource URL pattern and is also more flexible in terms of geographic distribution and availability.\n\nHope it helps."
      },
      {
        "date": "2023-02-23T11:20:00.000Z",
        "voteCount": 1,
        "content": "The first is https://contoso1.cognitiveservices.azure.com the second is generateThumbnail\nPOST https://*.cognitiveservices.azure.com/vision/v3.2/generateThumbnail?width=100&amp;height=100&amp;smartCropping=true&amp;model-version=latest HTTP/1.1\nHost: *.cognitiveservices.azure.com\nContent-Type: application/json\n\n{\"url\":\"http://example.com/images/test.jpg\"}"
      },
      {
        "date": "2023-01-16T18:15:00.000Z",
        "voteCount": 3,
        "content": "on my exam (2023-01-16 Passed)\n\nMy Answer:\nhttps://westus.api.cognitive.microsoft.com\nBut I think this is wrong.Because Question request use contoso1!\nSo correct answer is :\nhttps://contoso1.cognitiveservices.azure.com/"
      },
      {
        "date": "2023-01-17T11:47:00.000Z",
        "voteCount": 1,
        "content": "Hello.. I have exam tomorrow. Can you suggest if ET questions were on exam?"
      },
      {
        "date": "2022-07-25T03:00:00.000Z",
        "voteCount": 4,
        "content": "Westus\ngenerateThumbnail\n\nhttps://docs.microsoft.com/en-gb/azure/cognitive-services/computer-vision/how-to/generate-thumbnail#call-the-generate-thumbnail-api\n\ncurl -H \"Ocp-Apim-Subscription-Key: &lt;subscriptionKey&gt;\" -o &lt;thumbnailFile&gt; -H \"Content-Type: application/json\" \"https://westus.api.cognitive.microsoft.com/vision/v3.2/generateThumbnail?width=100&amp;height=100&amp;smartCropping=true\" -d \"{\\\"url\\\":\\\"https://upload.wikimedia.org/wikipedia/commons/thumb/5/56/Shorkie_Poo_Puppy.jpg/1280px-Shorkie_Poo_Puppy.jpg\\\"}\""
      },
      {
        "date": "2022-07-24T06:34:00.000Z",
        "voteCount": 1,
        "content": "First one is contoso.cognitive services. Just checked my own script and cognitiive services uses ur rg name in the endpoint URI."
      },
      {
        "date": "2022-07-24T06:34:00.000Z",
        "voteCount": 1,
        "content": "Second one is obv. generateThumbnail"
      },
      {
        "date": "2022-07-18T23:29:00.000Z",
        "voteCount": 1,
        "content": "For first dropdown, 3rd option works with cognitive service key and computer vision key as well. whereas 2nd option works with only computer vision key. so answer 3rd works in both situation. therefor i'll go with https://westus.api.cognitive.microsoft.com/vision/v3.1/generateThumbnail?width=500&amp;height=500&amp;smartCropping=True"
      },
      {
        "date": "2022-07-15T22:46:00.000Z",
        "voteCount": 1,
        "content": "Contoso1\nGeneratethumbnail"
      },
      {
        "date": "2022-07-25T02:58:00.000Z",
        "voteCount": 4,
        "content": "Correction: New resources created after July 1, 2019, will use custom subdomain names, therefore:\nwestus and generateThumbnail are correct answers. \n\nExact copy here from MS docs: \ncurl -H \"Ocp-Apim-Subscription-Key: &lt;subscriptionKey&gt;\" -o &lt;thumbnailFile&gt; -H \"Content-Type: application/json\" \"https://westus.api.cognitive.microsoft.com/vision/v3.2/generateThumbnail?width=100&amp;height=100&amp;smartCropping=true\" -d \"{\\\"url\\\":\\\"https://upload.wikimedia.org/wikipedia/commons/thumb/5/56/Shorkie_Poo_Puppy.jpg/1280px-Shorkie_Poo_Puppy.jpg\\\"}\"\n\n\nhttps://docs.microsoft.com/en-gb/azure/cognitive-services/computer-vision/how-to/generate-thumbnail#call-the-generate-thumbnail-api"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 4,
    "url": "https://www.examtopics.com/discussions/microsoft/view/77130-exam-ai-102-topic-2-question-4-discussion/",
    "body": "DRAG DROP -<br>You are developing a webpage that will use the Azure Video Analyzer for Media (previously Video Indexer) service to display videos of internal company meetings.<br>You embed the Player widget and the Cognitive Insights widget into the page.<br>You need to configure the widgets to meet the following requirements:<br>\u2711 Ensure that users can search for keywords.<br>\u2711 Display the names and faces of people in the video.<br>\u2711 Show captions in the video in English (United States).<br>How should you complete the URL for each widget? To answer, drag the appropriate values to the correct targets. Each value may be used once, more than once, or not at all. You may need to drag the split bar between panes or scroll to view content.<br>NOTE: Each correct selection is worth one point.<br>Select and Place:<br><img src=\"/assets/media/exam-media/04271/0008500001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04271/0008500002.png\" class=\"in-exam-image\">",
    "answerDescription": "Reference:<br>https://docs.microsoft.com/en-us/azure/azure-video-analyzer/video-analyzer-for-media-docs/video-indexer-embed-widgets",
    "votes": [],
    "comments": [
      {
        "date": "2023-07-01T01:18:00.000Z",
        "voteCount": 22,
        "content": "1. people, keywords / search\n2. true / en-US\n\nhttps://learn.microsoft.com/en-us/azure/azure-video-indexer/video-indexer-embed-widgets#cognitive-insights-widget\n- widgets\nAllows you to control the insights that you want to render.\n- controls\nAllows you to control the controls that you want to render.\n\nhttps://learn.microsoft.com/en-us/azure/azure-video-indexer/video-indexer-embed-widgets#player-widget\n- showCaptions\nMakes the player load with the captions already enabled.\n- captions\nFetches the caption in the specified language during the widget loading to be available on the Captions menu"
      },
      {
        "date": "2023-11-03T09:14:00.000Z",
        "voteCount": 1,
        "content": "thanks for explanation"
      },
      {
        "date": "2022-07-25T03:04:00.000Z",
        "voteCount": 9,
        "content": "Answer is correct. \n\nhttps://docs.microsoft.com/en-us/azure/azure-video-indexer/video-indexer-embed-widgets"
      },
      {
        "date": "2024-06-21T08:58:00.000Z",
        "voteCount": 1,
        "content": "1. widgets is people,keywords\n2. controls is search\n3. showcaptions is true\n4. captions is en-US"
      },
      {
        "date": "2024-05-28T06:41:00.000Z",
        "voteCount": 1,
        "content": "widgets: people,keywords\ncontrols: search\nshowcaptions: true\ncaptions: en-US"
      },
      {
        "date": "2024-05-25T06:59:00.000Z",
        "voteCount": 1,
        "content": "widgets=people,keywords\ncontrols=search\nshowcaptions=true\ncaptions=en-US"
      },
      {
        "date": "2024-05-20T08:15:00.000Z",
        "voteCount": 1,
        "content": "widgets=people,keywords; controls=search; showcaptions=true; captions=en-US"
      },
      {
        "date": "2022-06-27T20:16:00.000Z",
        "voteCount": 1,
        "content": "https://docs.microsoft.com/en-us/azure/azure-video-indexer/video-indexer-embed-widgets"
      },
      {
        "date": "2022-06-27T20:15:00.000Z",
        "voteCount": 2,
        "content": "Cognitive Insights widget - answer is correct\nPlayer widget - answer is correct"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 5,
    "url": "https://www.examtopics.com/discussions/microsoft/view/60335-exam-ai-102-topic-2-question-5-discussion/",
    "body": "DRAG DROP -<br>You train a Custom Vision model to identify a company's products by using the Retail domain.<br>You plan to deploy the model as part of an app for Android phones.<br>You need to prepare the model for deployment.<br>Which three actions should you perform in sequence? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.<br>Select and Place:<br><img src=\"/assets/media/exam-media/04271/0008600001.jpg\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/ai-102/image166.png\">",
    "answerDescription": "Reference:<br>https://docs.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/export-your-model",
    "votes": [],
    "comments": [
      {
        "date": "2021-08-24T10:42:00.000Z",
        "voteCount": 41,
        "content": "Actually the model should be retrained prior to publishing:\n\n\"From the top of the page, select Train to retrain using the new domain.\"\n\nSo it should be:\n1. Change the model domain\n2. Retrain\n3. Publish"
      },
      {
        "date": "2022-05-22T06:28:00.000Z",
        "voteCount": 2,
        "content": "Where is the Test step before publishing? After retraining you must test it before publishing it"
      },
      {
        "date": "2021-09-09T19:44:00.000Z",
        "voteCount": 5,
        "content": "Yep, Change the model to Retail (Compact). Exporting the Model is an optional step."
      },
      {
        "date": "2022-08-12T07:55:00.000Z",
        "voteCount": 4,
        "content": "Agreed. see reference https://docs.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/export-your-model"
      },
      {
        "date": "2021-09-09T19:52:00.000Z",
        "voteCount": 15,
        "content": "Actually all four steps required in the sequence Change, Retrain, Test and Export. Export is also must as model has to be deployed on Android App. If I have to choose three options, I may drop \"Test\" as that is not mandatory to proceed, but good to have as part of process."
      },
      {
        "date": "2024-03-03T23:25:00.000Z",
        "voteCount": 1,
        "content": "The question states: 'Which three actions should you perform in sequence?'"
      },
      {
        "date": "2023-11-03T09:24:00.000Z",
        "voteCount": 1,
        "content": "agree with you"
      },
      {
        "date": "2022-03-05T01:53:00.000Z",
        "voteCount": 14,
        "content": "Change the model domain {Retail(compact)}\nRetrain the model\nExport the model\n\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/export-your-model"
      },
      {
        "date": "2024-10-10T18:08:00.000Z",
        "voteCount": 1,
        "content": "There is no mention of whether or not they will actually deploy it, although they plan to deploy it.\nIf they only plan to deploy it, isn't the current answer correct?\n\n1. Change the model domain.\n2. Retrain the model.\n3. Test the model."
      },
      {
        "date": "2024-07-21T02:07:00.000Z",
        "voteCount": 1,
        "content": "Change the model domain Retail(compact)\nRetrain the model\nExport the model"
      },
      {
        "date": "2024-07-02T08:51:00.000Z",
        "voteCount": 1,
        "content": "But why they ask 3 and answer is 4.\nBtw...\n1. Change the model domain\n2. Retrain\n3. Publish"
      },
      {
        "date": "2024-08-09T07:12:00.000Z",
        "voteCount": 1,
        "content": "That's my exact question too."
      },
      {
        "date": "2024-06-07T03:22:00.000Z",
        "voteCount": 1,
        "content": "You train a Custom Vision model to identify a company's products by using the Retail domain.\n\nYou are already using the retail domain, so you technically don't need to change the domain. You are only preparing it for deployment on a mobile app. \n\nSo ...\n\nTo prepare the Custom Vision model for deployment as part of an app for Android phones, you should perform the following three actions in sequence:\n\nRetrain the model. - Ensure the model is trained on the latest data to improve accuracy.\nTest the model. - Validate the model's performance to ensure it meets the required standards.\nExport the model. - Export the trained and tested model for integration into the Android app"
      },
      {
        "date": "2024-09-30T11:22:00.000Z",
        "voteCount": 1,
        "content": "change model to Retail(compact) for mobile apps"
      },
      {
        "date": "2024-05-28T08:28:00.000Z",
        "voteCount": 2,
        "content": "Change the model domain\nRetrain the model\nExport the model"
      },
      {
        "date": "2024-05-28T06:50:00.000Z",
        "voteCount": 2,
        "content": "1. Change the model domain\n2. Retrain\n3. Export"
      },
      {
        "date": "2024-05-25T07:22:00.000Z",
        "voteCount": 1,
        "content": "1. Change the model domain\n2. Retrain\n3. Export"
      },
      {
        "date": "2024-05-17T13:20:00.000Z",
        "voteCount": 3,
        "content": "The Android App has Internet Connectivity, so there is no need for the Compact Version and also no need (and not even the option) for an Export. Therefore.\n1. Change the Model\n2. Retrain the Model\n3. Test the Model."
      },
      {
        "date": "2024-03-25T03:43:00.000Z",
        "voteCount": 2,
        "content": "Final Answer:\nChange the model domain {Retail(compact)}\nRetrain the model\nExport the model"
      },
      {
        "date": "2023-07-01T01:17:00.000Z",
        "voteCount": 1,
        "content": "1. Change model domain\n2. Retrain model\n3. Test model\n4. Export model\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/export-your-model"
      },
      {
        "date": "2023-07-20T10:17:00.000Z",
        "voteCount": 6,
        "content": "Only three actions are requested. Test is optionnal imo"
      },
      {
        "date": "2023-06-27T23:20:00.000Z",
        "voteCount": 3,
        "content": "was on exam 28/06"
      },
      {
        "date": "2023-03-15T02:53:00.000Z",
        "voteCount": 6,
        "content": "Change the model domain: Since you trained the model using the Retail domain, you need to switch the domain to one that is optimized for mobile devices such as the General (compact) domain.\n\nRetrain the model: After changing the domain, you need to retrain the model using the new domain settings.\n\nExport the model: Once the model is retrained, you can export it in the format that is compatible with your Android app. The model can be exported as a TensorFlow or Core ML model for deployment on Android."
      },
      {
        "date": "2023-02-12T02:04:00.000Z",
        "voteCount": 1,
        "content": "The model was trained, we must to test it, chage the model domain and export it.\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/test-your-model (How-to guides) the first is test, second change domain in Export models finaly export model"
      },
      {
        "date": "2023-01-16T18:17:00.000Z",
        "voteCount": 5,
        "content": "on my exam (2023-01-16 Passed)\n\nMy Answer:\n1. Change the model domain\n2. Retrain\n3. Publish"
      },
      {
        "date": "2022-11-04T01:33:00.000Z",
        "voteCount": 1,
        "content": "Export the Model must be excluded as it is asking for only three steps not four."
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 6,
    "url": "https://www.examtopics.com/discussions/microsoft/view/82128-exam-ai-102-topic-2-question-6-discussion/",
    "body": "HOTSPOT -<br>You are developing an application to recognize employees' faces by using the Face Recognition API. Images of the faces will be accessible from a URI endpoint.<br>The application has the following code.<br><img src=\"/assets/media/exam-media/04271/0008700001.png\" class=\"in-exam-image\"><br>For each of the following statements, select Yes if the statement is true. Otherwise, select No.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04271/0008700002.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04271/0008800001.png\" class=\"in-exam-image\">",
    "answerDescription": "Reference:<br>https://docs.microsoft.com/en-us/azure/cognitive-services/face/face-api-how-to-topics/use-persondirectory",
    "votes": [],
    "comments": [
      {
        "date": "2022-09-14T04:31:00.000Z",
        "voteCount": 15,
        "content": "Based on the subscription, I think, it could also be\nYes\nYes\nYes\n\n\"Free-tier subscription quota: 1,000 person groups. Each holds up to 1,000 persons.\nS0-tier subscription quota: 1,000,000 person groups. Each holds up to 10,000 persons.\"\n\nhttps://docs.microsoft.com/en-us/rest/api/faceapi/person-group/create?tabs=HTTP"
      },
      {
        "date": "2024-07-27T11:00:00.000Z",
        "voteCount": 2,
        "content": "Just posting the correct link =&gt; https://learn.microsoft.com/en-us/rest/api/face/person-group-operations/create-person-group?view=rest-face-v1.1-preview.1&amp;tabs=HTTP. It will be Yes, Yes and Yes"
      },
      {
        "date": "2024-06-18T05:56:00.000Z",
        "voteCount": 1,
        "content": "404 on the source"
      },
      {
        "date": "2023-08-18T16:11:00.000Z",
        "voteCount": 2,
        "content": "person groups, not persons. 2 choose No."
      },
      {
        "date": "2023-02-11T18:14:00.000Z",
        "voteCount": 11,
        "content": "The second box should be No. The given answers are correct. The second box states that the code will work for up to 10,000 people. While this is true for S0 tier, it is false for free-tier. Since the price tier is not given, we will have to say that it is not always true, and that means it is false"
      },
      {
        "date": "2024-08-22T14:32:00.000Z",
        "voteCount": 1,
        "content": "The question isn't really about the SKU,  but asking if the \"code will work\" for that many. The code will."
      },
      {
        "date": "2023-02-13T02:58:00.000Z",
        "voteCount": 4,
        "content": "Hi, have you passed the exam? Did you simulation questions?"
      },
      {
        "date": "2023-02-14T15:09:00.000Z",
        "voteCount": 1,
        "content": "Following"
      },
      {
        "date": "2023-06-08T16:50:00.000Z",
        "voteCount": 12,
        "content": "Yes\nNo \nYes\n\n\"Free-tier subscription quota: 1,000 person groups. Each holds up to 1,000 persons. So in the code you can have 1000 person groups and 1000 persons each giving you 1,000,000 people"
      },
      {
        "date": "2024-09-18T22:05:00.000Z",
        "voteCount": 1,
        "content": "ChatGPT Response:\n\n1. The code will add a face image to a person object in a person group:\nYes: In the Face API, adding a face to a person object in a person group is a typical operation. You use the add_face method (or similar method depending on the SDK or API) to associate a face with a person object within a specific person group.\n2. The code will work for up to 10,000 people:\nYes: Azure Face API can typically support up to 10,000 people in a person group. This is a documented limit for the Face API's person groups, so the code can handle this number of people.\n3. add_face can be called multiple times to add multiple face images to a person object:\nYes: You can call the add_face method multiple times to associate multiple face images with a single person object. This helps improve the accuracy of face recognition by allowing the system to recognize the same person from different angles or lighting conditions."
      },
      {
        "date": "2024-09-02T00:36:00.000Z",
        "voteCount": 1,
        "content": "Another of those ambigous guessing game from the dysfunctional microsoft. I will answer the second one No. Just assuming the question creator is asking whether one person group can have 10K persons. Otherwise I hope he/she would have given the plan. \nI do not understand the point of all these questions and remembering these useless facts."
      },
      {
        "date": "2024-09-02T00:37:00.000Z",
        "voteCount": 1,
        "content": "Changed, I will go for yes, and assuming standard plan."
      },
      {
        "date": "2024-07-27T10:59:00.000Z",
        "voteCount": 1,
        "content": "Second should be yes .Link =&gt; https://learn.microsoft.com/en-us/rest/api/face/person-group-operations/create-person-group?view=rest-face-v1.1-preview.1&amp;tabs=HTTP.. It will be supported by Free tier subscription quota."
      },
      {
        "date": "2024-07-15T11:20:00.000Z",
        "voteCount": 1,
        "content": "Yes\nNo\nYes"
      },
      {
        "date": "2024-05-28T08:23:00.000Z",
        "voteCount": 2,
        "content": "The correct sequence for this problem solution is Yes No Yes."
      },
      {
        "date": "2024-05-25T06:54:00.000Z",
        "voteCount": 2,
        "content": "Yes\nNo\nYes"
      },
      {
        "date": "2024-05-20T08:10:00.000Z",
        "voteCount": 1,
        "content": "Yes No Yes"
      },
      {
        "date": "2024-03-29T03:54:00.000Z",
        "voteCount": 1,
        "content": "The code you\u2019ve provided is intended to add a face image to a person object in a person group using the Azure Face API, so:\n\nYes, the code will add a face image to a person object in a person group, provided the code is corrected for syntax errors and proper API usage.\nYes, the code can work for up to 10,000 people, as long as the Azure Face API limits are adhered to and the appropriate subscription tier is used.\nYes, the add_face function can be called multiple times to add multiple face images to a person object, subject to the limits imposed by the Azure Face API."
      },
      {
        "date": "2024-03-21T19:38:00.000Z",
        "voteCount": 1,
        "content": "Images sent to the service are not stored after analysis.\n\nhttps://learn.microsoft.com/en-us/legal/cognitive-services/face/data-privacy-security"
      },
      {
        "date": "2024-02-24T10:59:00.000Z",
        "voteCount": 1,
        "content": "Is this a trick question?\nFrom here: https://westus.dev.cognitive.microsoft.com/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f3039523b\nNo image will be stored. Only the extracted face feature(s) will be stored on server until PersonGroup PersonFace - Delete, PersonGroup Person - Delete or PersonGroup - Delete is called."
      },
      {
        "date": "2024-01-08T08:41:00.000Z",
        "voteCount": 2,
        "content": "Yes\nNo - As the code will keep working in other groups (for instance), and as AzureJobsTillRetire says, a statement that's not generally true is false\nNo - As the image is not really 'added', just their features\n\n\"No image will be stored. Only the extracted face feature will be stored on server until PersonGroup PersonFace - Delete, PersonGroup Person - Delete or PersonGroup - Delete is called.\" --see: https://learn.microsoft.com/en-us/rest/api/faceapi/person-group/create?view=rest-faceapi-v1.0&amp;tabs=HTTP\n\nThe way it works, you have to update a face https://learn.microsoft.com/en-us/rest/api/faceapi/person-group-person/update-face?view=rest-faceapi-v1.0&amp;tabs=HTTP. If you register a new pic for an existing user it will just create a new one and return a new persistedFaceId."
      },
      {
        "date": "2024-03-21T19:41:00.000Z",
        "voteCount": 1,
        "content": "If that's your reasoning, then you can't select Yes for the first one. They use the same verbiage in both."
      },
      {
        "date": "2023-10-21T10:07:00.000Z",
        "voteCount": 1,
        "content": "You can vary the person group id and the person id while making the call, so even with the free tier is still way above  the mention 10,000 people limitation. The only limitation that is defined for this API is this Response 403\nPersisted face number reached limit, maximum is 248 per person.\nLink here: https://westus.dev.cognitive.microsoft.com/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f3039523b"
      },
      {
        "date": "2023-10-21T10:11:00.000Z",
        "voteCount": 1,
        "content": "The 10,000 lomitation would make more sense if they are asking about this API: POST {Endpoint}/face/v1.0/persongroups/{personGroupId}/persons"
      },
      {
        "date": "2022-09-14T07:37:00.000Z",
        "voteCount": 4,
        "content": "Once you have the Person ID from the Create Person call, you can add up to 248 face images to a Person per recognition model. \nThey are all true, the limit is 75 milion persons per group"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 7,
    "url": "https://www.examtopics.com/discussions/microsoft/view/62223-exam-ai-102-topic-2-question-7-discussion/",
    "body": "DRAG DROP -<br>You have a Custom Vision resource named acvdev in a development environment.<br>You have a Custom Vision resource named acvprod in a production environment.<br>In acvdev, you build an object detection model named obj1 in a project named proj1.<br>You need to move obj1 to acvprod.<br>Which three actions should you perform in sequence? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.<br>Select and Place:<br><img src=\"/assets/media/exam-media/04271/0008900001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04271/0008900002.png\" class=\"in-exam-image\">",
    "answerDescription": "Reference:<br>https://docs.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/copy-move-projects",
    "votes": [],
    "comments": [
      {
        "date": "2021-12-13T10:34:00.000Z",
        "voteCount": 35,
        "content": "1. GetProjects on acvDEV\n2. ExportProjects on acvDEV\n3. ImportProjects on avcPROD"
      },
      {
        "date": "2023-07-01T01:13:00.000Z",
        "voteCount": 15,
        "content": "1. Use GetProjects endpoint on acvDEV\n2. Use ExportProjects endpoint on acvDEV\n3. Use ImportProjects endpoint on avcPROD\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/copy-move-projects#get-the-project-id\nFirst call GetProjects to see a list of your existing Custom Vision projects and their IDs. Use the training key and endpoint of your source account.\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/copy-move-projects#export-the-project\nCall ExportProject using the project ID and your source training key and endpoint.\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/copy-move-projects#import-the-project\nCall ImportProject using your target training key and endpoint, along with the reference token. You can also give your project a name in its new account."
      },
      {
        "date": "2023-07-01T01:13:00.000Z",
        "voteCount": 4,
        "content": "https://learn.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/copy-move-projects#process-overview\nThe process for copying a project consists of the following steps:\n- First, you get the ID of the project in your source account you want to copy.\n- Then you call the ExportProject API using the project ID and the training key of your source account. You'll get a temporary token string.\n- Then you call the ImportProject API using the token string and the training key of your target account. The project will then be listed under your target account."
      },
      {
        "date": "2024-08-14T20:04:00.000Z",
        "voteCount": 1,
        "content": "1. GetProjects on acvDEV\n2. ExportProjects on acvDEV\n3. ImportProjects on avcPROD"
      },
      {
        "date": "2024-05-28T06:50:00.000Z",
        "voteCount": 1,
        "content": "1. Use GetProjects endpoint on acvDEV\n2. Use ExportProjects endpoint on acvDEV\n3. Use ImportProjects endpoint on avcPROD"
      },
      {
        "date": "2024-03-25T03:45:00.000Z",
        "voteCount": 2,
        "content": "Final Answer:\n1. GetProjects on acvDEV\n2. ExportProjects on acvDEV\n3. ImportProjects on avcPROD"
      },
      {
        "date": "2023-11-03T13:54:00.000Z",
        "voteCount": 1,
        "content": "correct answer as the documentation provided demonstrates"
      },
      {
        "date": "2022-07-17T21:48:00.000Z",
        "voteCount": 1,
        "content": "Get on Dev\nExport on Dev\nImport on Prod"
      },
      {
        "date": "2022-07-09T17:59:00.000Z",
        "voteCount": 3,
        "content": "1. GetProjects on acvDEV\n2. ExportProjects on acvDEV\n3. ImportProjects on avcPROD\n\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/copy-move-projects"
      },
      {
        "date": "2022-01-04T09:40:00.000Z",
        "voteCount": 2,
        "content": "Was on exam 02/01/2022"
      },
      {
        "date": "2021-11-27T18:28:00.000Z",
        "voteCount": 3,
        "content": "Was on exam 27/11/2021"
      },
      {
        "date": "2021-09-16T09:45:00.000Z",
        "voteCount": 3,
        "content": "Given link proves this is correct."
      },
      {
        "date": "2021-09-25T09:05:00.000Z",
        "voteCount": 2,
        "content": "Here in this document it is clearly mentioned how can you move your resource from dev. to prod. : https://docs.microsoft.com/en-us/azure/cognitive-services/luis/luis-tutorial-pattern#what-did-this-tutorial-accomplish"
      },
      {
        "date": "2021-10-19T06:21:00.000Z",
        "voteCount": 2,
        "content": "Provided link is for LUIS. Incorrect Link."
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 8,
    "url": "https://www.examtopics.com/discussions/microsoft/view/74355-exam-ai-102-topic-2-question-8-discussion/",
    "body": "DRAG DROP -<br>You are developing an application that will recognize faults in components produced on a factory production line. The components are specific to your business.<br>You need to use the Custom Vision API to help detect common faults.<br>Which three actions should you perform in sequence? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.<br>Select and Place:<br><img src=\"/assets/media/exam-media/04271/0009000001.jpg\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04271/0009100001.jpg\" class=\"in-exam-image\">",
    "answerDescription": "Step 1: Create a project -<br>Create a new project.<br>Step 2: Upload and tag the images<br>Choose training images. Then upload and tag the images.<br>Step 3: Train the classifier model.<br><br>Train the classifier -<br>Reference:<br>https://docs.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/getting-started-build-a-classifier",
    "votes": [],
    "comments": [
      {
        "date": "2023-02-12T03:00:00.000Z",
        "voteCount": 19,
        "content": "The anwser is correct\nCreate a project\nUpload and tag images\nTrain a classifier model\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/quickstarts/image-classification?tabs=visual-studio&amp;pivots=programming-language-csharp\nFor Type of model \nhttps://azure.microsoft.com/en-us/use-cases/defect-detection-with-image-analysis/"
      },
      {
        "date": "2023-11-03T14:11:00.000Z",
        "voteCount": 12,
        "content": "The choice between Object Detection and Classification depends on the nature of your defect detection problem in the production line components. Here are some considerations:\nClassification: You use classification when your goal is to determine whether a component is defective or non-defective. In this case, the Custom Vision model will be trained to classify the entire image as \"good\" or \"defective.\" Classification is suitable if you want a binary answer.\nObject Detection: You use object detection when you want to identify and locate specific defects or objects within an image. This is useful if you have multiple defect classes or if you want to identify the exact location of defects within a component.\nSo, if you only need to distinguish between good and defective components, classification may suffice. However, if you need to identify and locate specific defects within components, you should opt for object detection. The choice depends on the complexity of your use case and the level of detail you want to extract from the images. (Chat GPT)\n\nHonestly I think Classifier is more appropriate in this case"
      },
      {
        "date": "2024-10-14T04:23:00.000Z",
        "voteCount": 1,
        "content": "Got a similar one in Oct 2024, some wording change from memory."
      },
      {
        "date": "2024-10-01T04:32:00.000Z",
        "voteCount": 1,
        "content": "Answer is correct, it is a classifier since custom vision only builds an image classifier, detection is part of normal vision."
      },
      {
        "date": "2024-06-24T17:03:00.000Z",
        "voteCount": 1,
        "content": "Got this in the exam, Jun 2024."
      },
      {
        "date": "2024-05-28T06:48:00.000Z",
        "voteCount": 3,
        "content": "1. Create a project\n2. Upload and tag images\n3. Train a classifier model"
      },
      {
        "date": "2024-05-25T07:16:00.000Z",
        "voteCount": 3,
        "content": "1. Create a project\n2. Upload and tag images\n3. Train a classifier model"
      },
      {
        "date": "2024-03-25T03:46:00.000Z",
        "voteCount": 1,
        "content": "Final Answer:\n\nCreate a project\nUpload and tag images\nTrain a classifier model"
      },
      {
        "date": "2024-03-21T21:58:00.000Z",
        "voteCount": 1,
        "content": "I think the key is recognizing it's a production line. That means the same component is coming down the line.\n\nThen there are other lines producing other components.\n\nClassification would be best suited for that scenario.  If we were looking at an image that might have many different components in one image and want to find the location of different faults, then object would be more appropriate."
      },
      {
        "date": "2024-01-25T05:19:00.000Z",
        "voteCount": 1,
        "content": "It's a classifier model because it's not detecting whether they objects are there or not, it's classifying them as faulty or not"
      },
      {
        "date": "2023-10-08T21:21:00.000Z",
        "voteCount": 1,
        "content": "I would pick object detection. Custom Vision functionality can be divided into two features. Image classification applies one or more labels to an entire image. Object detection is similar, but it returns the coordinates in the image where the applied label(s) can be found. If I were the users, I would certainly want know where the faults are located to make sure and have a second look and it\u2019s quite useless by just telling me there are something wrong but can\u2019t tell you where they are as I need to do extra work to find them!"
      },
      {
        "date": "2023-02-12T02:49:00.000Z",
        "voteCount": 3,
        "content": "Yes the anwser is correct\nCreate a project\nUpload and tags images\nTrain the classifier model\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/quickstarts/image-classification?tabs=visual-studio&amp;pivots=programming-language-csharp\nand for type of model\nhttps://azure.microsoft.com/en-us/use-cases/defect-detection-with-image-analysis/"
      },
      {
        "date": "2022-12-27T23:49:00.000Z",
        "voteCount": 2,
        "content": "Correct answer should be:\nCreate\nUpload &amp; Tag\nTrain the object detection model\n\nThe question was to help \"detect\" common faults. Detection means where the fault actually is in the image."
      },
      {
        "date": "2023-01-04T07:03:00.000Z",
        "voteCount": 5,
        "content": "Nope, answer should be \nCreate, Upload &amp; Tag, and Train classifier (not a detection mode)\nBcz classifier has to classify whether the given component is faulty or not..."
      },
      {
        "date": "2022-07-17T21:50:00.000Z",
        "voteCount": 3,
        "content": "Create\nUpload\nTrain the classifier"
      },
      {
        "date": "2022-07-14T04:23:00.000Z",
        "voteCount": 2,
        "content": "Quite confusing on the questions, since Object Detection technically can be correct IMO"
      },
      {
        "date": "2022-09-14T07:42:00.000Z",
        "voteCount": 1,
        "content": "You don't tag the detection images so by exclusion you could direct the answer to classification"
      },
      {
        "date": "2022-04-24T11:14:00.000Z",
        "voteCount": 4,
        "content": "Correct"
      },
      {
        "date": "2022-06-21T23:43:00.000Z",
        "voteCount": 4,
        "content": "Agreed. Train the classifier, not object detection model because they make no mention of need to know the location of the detections, but they do mention detecting common faults. So can either classify as faulty, not faulty, or also classify different fault types.. not clear on that one but the answer is correct."
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 9,
    "url": "https://www.examtopics.com/discussions/microsoft/view/74741-exam-ai-102-topic-2-question-9-discussion/",
    "body": "HOTSPOT -<br>You are building a model that will be used in an iOS app.<br>You have images of cats and dogs. Each image contains either a cat or a dog.<br>You need to use the Custom Vision service to detect whether the images is of a cat or a dog.<br>How should you configure the project in the Custom Vision portal? To answer, select the appropriate options in the answer area.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04271/0009300001.jpg\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04271/0009400001.jpg\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: Classification -<br>Incorrect Answers:<br>An object detection project is for detecting which objects, if any, from a set of candidates are present in an image.<br><br>Box 2: Multiclass -<br>A multiclass classification project is for classifying images into a set of tags, or target labels. An image can be assigned to one tag only.<br>Incorrect Answers:<br>A multilabel classification project is similar, but each image can have multiple tags assigned to it.<br><br>Box 3: General -<br>General: Optimized for a broad range of image classification tasks. If none of the other specific domains are appropriate, or if you're unsure of which domain to choose, select one of the General domains.<br>Reference:<br>https://cran.r-project.org/web/packages/AzureVision/vignettes/customvision.html",
    "votes": [],
    "comments": [
      {
        "date": "2022-05-05T22:23:00.000Z",
        "voteCount": 42,
        "content": "The third choice should be General compact, in other that the model can be exported to be used in iOS device"
      },
      {
        "date": "2022-05-16T07:35:00.000Z",
        "voteCount": 4,
        "content": "it seems the general compact is for edge device not ios.\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/select-domain#image-classification"
      },
      {
        "date": "2022-06-19T00:34:00.000Z",
        "voteCount": 13,
        "content": "So general compact is correct since ios device is an edge device."
      },
      {
        "date": "2023-09-11T05:29:00.000Z",
        "voteCount": 3,
        "content": "How about this article? https://learn.microsoft.com/en-us/azure/ai-services/custom-vision-service/export-your-model"
      },
      {
        "date": "2023-11-03T14:16:00.000Z",
        "voteCount": 1,
        "content": "thanks for sharing the documentation."
      },
      {
        "date": "2023-11-03T14:17:00.000Z",
        "voteCount": 1,
        "content": "agree with you"
      },
      {
        "date": "2022-07-22T02:46:00.000Z",
        "voteCount": 15,
        "content": "Classification\nMulticlass\nGeneral (compact)"
      },
      {
        "date": "2024-07-16T03:08:00.000Z",
        "voteCount": 1,
        "content": "Classification\nMulticlass\nGeneral (compact)"
      },
      {
        "date": "2024-06-23T02:42:00.000Z",
        "voteCount": 1,
        "content": "classification\nmulticlass\nGeneral (compact): Since the model will be used in an iOS app, a compact model is preferred for performance and size reasons. The \"General (compact)\" domain is suitable for a wide range of image classification tasks and is optimized for mobile and edge devices."
      },
      {
        "date": "2024-05-28T08:26:00.000Z",
        "voteCount": 2,
        "content": "1. Classification\n2. Multiclass\n3. General (compact)"
      },
      {
        "date": "2024-05-28T06:48:00.000Z",
        "voteCount": 1,
        "content": "1. Classification\n2. Multiclass\n3. General (compact)"
      },
      {
        "date": "2024-05-25T07:13:00.000Z",
        "voteCount": 2,
        "content": "1. Classification\n2. Multiclass\n3. General (compact)"
      },
      {
        "date": "2024-04-12T22:33:00.000Z",
        "voteCount": 1,
        "content": "1 - Classification\n2 - Multiclass (single tag per image)\n3 - General (compact)\n\n\n\nCustom Vision Service only exports projects with compact domains. \n\nThe models generated by compact domains are optimized for the constraints of real-time classification on mobile devices. \nClassifiers built with a compact domain may be slightly less accurate than a standard domain with the same amount of training data."
      },
      {
        "date": "2024-03-25T03:47:00.000Z",
        "voteCount": 1,
        "content": "Final Answer:\nClassification\nMulticlass\nGeneral (compact)"
      },
      {
        "date": "2023-07-01T01:06:00.000Z",
        "voteCount": 4,
        "content": "1. Classification\n2. Multiclass\n3. General (compact)\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/getting-started-build-a-classifier\n- Select Classification under Project Types. Then, under Classification Types, choose either Multilabel or Multiclass, depending on your use case. Multilabel classification applies any number of your tags to an image (zero or more), while multiclass classification sorts images into single categories (every image you submit will be sorted into the most likely tag). You'll be able to change the classification type later if you want to."
      },
      {
        "date": "2023-07-01T01:06:00.000Z",
        "voteCount": 1,
        "content": "- Next, select one of the available domains. Each domain optimizes the model for specific types of images, as described in the following table. You can change the domain later if you wish.\n-- Generic\nOptimized for a broad range of image classification tasks. If none of the other domains are appropriate, or you're unsure of which domain to choose, select the Generic domain.\n-- Compact domains\nOptimized for the constraints of real-time classification on mobile devices. The models generated by compact domains can be exported to run locally."
      },
      {
        "date": "2022-07-14T22:14:00.000Z",
        "voteCount": 3,
        "content": "I also think that General(compact) https://docs.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/export-your-model \n1. It can be running offline\n2. Real time locally"
      },
      {
        "date": "2022-04-28T01:53:00.000Z",
        "voteCount": 1,
        "content": "Correct"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 10,
    "url": "https://www.examtopics.com/discussions/microsoft/view/75691-exam-ai-102-topic-2-question-10-discussion/",
    "body": "You have an Azure Video Analyzer for Media (previously Video Indexer) service that is used to provide a search interface over company videos on your company's website.<br>You need to be able to search for videos based on who is present in the video.<br>What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a person model and associate the model to the videos.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate person objects and provide face images for each object.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tInvite the entire staff of the company to Video Indexer.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEdit the faces in the videos.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUpload names to a language model."
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 17,
        "isMostVoted": true
      },
      {
        "answer": "B",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2023-11-03T14:30:00.000Z",
        "voteCount": 5,
        "content": "A seems the correct answer\nhttps://learn.microsoft.com/en-us/azure/azure-video-indexer/customize-person-model-overview"
      },
      {
        "date": "2024-06-22T00:17:00.000Z",
        "voteCount": 1,
        "content": "I say this answer is A."
      },
      {
        "date": "2024-05-25T07:10:00.000Z",
        "voteCount": 2,
        "content": "A is right."
      },
      {
        "date": "2023-10-20T16:56:00.000Z",
        "voteCount": 3,
        "content": "You can use a Person model to index your new video by assigning the Person model during the upload of the video.\n\nYou can use a Person model to index your new video by assigning the Person model during the upload of the video.\n\nhttps://learn.microsoft.com/en-us/azure/azure-video-indexer/customize-person-model-with-website"
      },
      {
        "date": "2023-10-08T22:11:00.000Z",
        "voteCount": 1,
        "content": "Customers can build custom Person models and enable Azure AI Video Indexer to recognize faces that aren't recognized by default. Customers can build these Person models by pairing a person's name with image files of the person's face. You can use the default model if you like but the point is to add persons and their associated image files to the model : https://learn.microsoft.com/en-us/azure/azure-video-indexer/customize-person-model-with-website."
      },
      {
        "date": "2023-10-08T22:18:00.000Z",
        "voteCount": 1,
        "content": "Azure AI Video Indexer can detect occurrences of this person in the future videos that you index and the current videos that you had already indexed, using the Person model to which you added this new face - you need to tell it what it should be comparing to when looking for a given face."
      },
      {
        "date": "2023-10-08T22:36:00.000Z",
        "voteCount": 1,
        "content": "Also If you don't need the multiple Person model support, don't assign a Person model ID to your video when uploading/indexing or reindexing. In this case, Azure AI Video Indexer will use the default Person model in your account. one more reason not to choose A."
      },
      {
        "date": "2023-06-28T05:47:00.000Z",
        "voteCount": 1,
        "content": "Same as Question 1.\nhttps://www.examtopics.com/discussions/microsoft/view/55438-exam-ai-102-topic-2-question-1-discussion"
      },
      {
        "date": "2023-06-28T05:42:00.000Z",
        "voteCount": 2,
        "content": "A is the answer.\n\nhttps://learn.microsoft.com/en-us/azure/azure-video-indexer/customize-person-model-overview\nAzure Video Indexer supports celebrity recognition in your videos. The celebrity recognition feature covers approximately one million faces based on commonly requested data source such as IMDB, Wikipedia, and top LinkedIn influencers. Faces that are not recognized by Azure Video Indexer are still detected but are left unnamed. Customers can build custom Person models and enable Azure Video Indexer to recognize faces that are not recognized by default. Customers can build these Person models by pairing a person's name with image files of the person's face."
      },
      {
        "date": "2022-08-26T17:58:00.000Z",
        "voteCount": 4,
        "content": "Should be A"
      },
      {
        "date": "2022-05-16T07:39:00.000Z",
        "voteCount": 1,
        "content": "seems right\nhttps://docs.microsoft.com/en-us/azure/azure-video-indexer/customize-person-model-with-website"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 11,
    "url": "https://www.examtopics.com/discussions/microsoft/view/75223-exam-ai-102-topic-2-question-11-discussion/",
    "body": "You use the Custom Vision service to build a classifier.<br>After training is complete, you need to evaluate the classifier.<br>Which two metrics are available for review? Each correct answer presents a complete solution.<br>NOTE: Each correct selection is worth one point.<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\trecall\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tF-score",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tweighted accuracy",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tprecision\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tarea under the curve (AUC)"
    ],
    "answer": "AD",
    "answerDescription": "",
    "votes": [
      {
        "answer": "AD",
        "count": 16,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-06-22T00:17:00.000Z",
        "voteCount": 1,
        "content": "I say this answer is A and D."
      },
      {
        "date": "2024-06-12T10:35:00.000Z",
        "voteCount": 1,
        "content": "Chat GPT and me: A + D"
      },
      {
        "date": "2024-05-28T06:44:00.000Z",
        "voteCount": 1,
        "content": "A and D are right answer."
      },
      {
        "date": "2024-02-16T15:29:00.000Z",
        "voteCount": 2,
        "content": "Zellck provided an excellent answer with precise documentation and interpretation of precision and recall metrics. Precision refers to the positive predictive value - the proportion of true positive results among all positively identified outcomes. Meanwhile, recall represents sensitivity - the proportion of actual positive cases that are correctly identified as such.\n\nPrecision and recall form a fundamental pair of performance indicators that entail an inherent trade-off. As one metric is optimized, the other typically suffers as a consequence. Specifically, as the precision rate increases, the recall rate often correspondingly decreases. The optimal balance between precision and recall depends on the business context and specific needs of the use case. By clearly explaining the definitions and relationship between these two metrics, Zellck thoroughly addressed the concepts with clarity and accuracy."
      },
      {
        "date": "2023-11-03T14:34:00.000Z",
        "voteCount": 1,
        "content": "Answer is correct\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/getting-started-build-a-classifier#evaluate-the-classifier"
      },
      {
        "date": "2023-10-28T21:08:00.000Z",
        "voteCount": 3,
        "content": "Appeared on Oct/29/2023."
      },
      {
        "date": "2023-06-28T05:46:00.000Z",
        "voteCount": 1,
        "content": "Same as Question 2.\nhttps://www.examtopics.com/discussions/microsoft/view/55211-exam-ai-102-topic-2-question-2-discussion"
      },
      {
        "date": "2023-06-28T05:38:00.000Z",
        "voteCount": 4,
        "content": "AD is the answer.\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/getting-started-build-a-classifier#evaluate-the-classifier\nAfter training has completed, the model's performance is estimated and displayed. The Custom Vision Service uses the images that you submitted for training to calculate precision and recall. Precision and recall are two different measurements of the effectiveness of a classifier:\n- Precision indicates the fraction of identified classifications that were correct. For example, if the model identified 100 images as dogs, and 99 of them were actually of dogs, then the precision would be 99%.\n- Recall indicates the fraction of actual classifications that were correctly identified. For example, if there were actually 100 images of apples, and the model identified 80 as apples, the recall would be 80%."
      },
      {
        "date": "2022-12-12T02:14:00.000Z",
        "voteCount": 1,
        "content": "Precision and Recall:  https://learn.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/getting-started-build-a-classifier#evaluate-the-classifier"
      },
      {
        "date": "2022-07-18T05:34:00.000Z",
        "voteCount": 2,
        "content": "A and D are correct answers - as per PHD_CHENG\nhttps://docs.microsoft.com/en-us/learn/modules/cv-classify-bird-species/4-understand-results-test"
      },
      {
        "date": "2022-06-07T05:28:00.000Z",
        "voteCount": 1,
        "content": "Was on exam 7 Jun 2022"
      },
      {
        "date": "2022-05-05T21:19:00.000Z",
        "voteCount": 4,
        "content": "Answer is correct.  You can find the metrics from Microsoft link https://docs.microsoft.com/en-us/learn/modules/cv-classify-bird-species/4-understand-results-test"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 12,
    "url": "https://www.examtopics.com/discussions/microsoft/view/55440-exam-ai-102-topic-2-question-12-discussion/",
    "body": "DRAG DROP -<br>You are developing a call to the Face API. The call must find similar faces from an existing list named employeefaces. The employeefaces list contains 60,000 images.<br>How should you complete the body of the HTTP request? To answer, drag the appropriate values to the correct targets. Each value may be used once, more than once, or not at all. You may need to drag the split bar between panes or scroll to view content.<br>NOTE: Each correct selection is worth one point.<br>Select and Place:<br><img src=\"/assets/media/exam-media/04271/0009700001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04271/0009700002.png\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: LargeFaceListID -<br>LargeFaceList: Add a face to a specified large face list, up to 1,000,000 faces.<br>Note: Given query face's faceId, to search the similar-looking faces from a faceId array, a face list or a large face list. A \"faceListId\" is created by FaceList - Create containing persistedFaceIds that will not expire. And a \"largeFaceListId\" is created by LargeFaceList - Create containing persistedFaceIds that will also not expire.<br>Incorrect Answers:<br>Not \"faceListId\": Add a face to a specified face list, up to 1,000 faces.<br><br>Box 2: matchFace -<br>Find similar has two working modes, \"matchPerson\" and \"matchFace\". \"matchPerson\" is the default mode that it tries to find faces of the same person as possible by using internal same-person thresholds. It is useful to find a known person's other photos. Note that an empty list will be returned if no faces pass the internal thresholds. \"matchFace\" mode ignores same-person thresholds and returns ranked similar faces anyway, even the similarity is low. It can be used in the cases like searching celebrity-looking faces.<br>Reference:<br>https://docs.microsoft.com/en-us/rest/api/faceapi/face/findsimilar",
    "votes": [],
    "comments": [
      {
        "date": "2021-06-16T06:35:00.000Z",
        "voteCount": 19,
        "content": "Correct."
      },
      {
        "date": "2022-05-05T21:33:00.000Z",
        "voteCount": 12,
        "content": "Facelist ID up to 1,000 faces; LargeFaceListId up to 1,000,000 faces\nhttps://docs.microsoft.com/en-us/rest/api/faceapi/large-face-list"
      },
      {
        "date": "2024-09-05T07:31:00.000Z",
        "voteCount": 1,
        "content": "Another of the detective style finding answers from hidden clues in the english language usage. Microsoft is a truly remarkable org. \n\nSimilar face, must find and employes. Similar face and Must find might point to matchFace, but for employees it should be matchPerson (we need the person not similar looking). Now, what will you choose? Very hard. Remarkable piece of hmm sweetness."
      },
      {
        "date": "2024-09-05T07:33:00.000Z",
        "voteCount": 1,
        "content": "And the fact that this remarkable org created a largeFaceList and a faceList and expects one to remember that piece of bad design. The size of the facelist should not be in the client calls, but at the server. Now if the facelist increases in size the clients need to change. What kind of org creates these kind of things and shamelessly ask that in certification exam. Microsoft is the answer."
      },
      {
        "date": "2024-09-05T07:38:00.000Z",
        "voteCount": 1,
        "content": "I will go for matchFace considering the other clue \"similar face\" instead of person. Man, this question should be taken to court and microsoft should be whipped"
      },
      {
        "date": "2024-06-23T02:47:00.000Z",
        "voteCount": 2,
        "content": "LargeFaceIdList\nmatchFace - reason why not matchPerson - becomes matchPerson compares agains larger person group and not one to one, here we are doing matchFace to find similar faces based on one to one analysis."
      },
      {
        "date": "2024-06-21T08:54:00.000Z",
        "voteCount": 1,
        "content": "1. LargeFaceListId\n2. matchFace"
      },
      {
        "date": "2024-05-25T07:25:00.000Z",
        "voteCount": 1,
        "content": "1. LargeFaceListId\n2. matchFace"
      },
      {
        "date": "2024-03-25T05:01:00.000Z",
        "voteCount": 4,
        "content": "Final Answer:\n1. LargeFaceListId \n2. matchFace ( matchPerson could return an empty list, but matchFace will not.)"
      },
      {
        "date": "2024-03-21T22:25:00.000Z",
        "voteCount": 1,
        "content": "The key is \"must find\". matchPerson could return an empty list, but matchFace will not."
      },
      {
        "date": "2023-11-03T14:38:00.000Z",
        "voteCount": 1,
        "content": "correct answer:\nhttps://learn.microsoft.com/en-us/rest/api/faceapi/face-list?view=rest-faceapi-v1.0"
      },
      {
        "date": "2023-11-12T04:01:00.000Z",
        "voteCount": 1,
        "content": "Sorry but I have to laugh off my previous answer:\n\"matchPerson\" is the default mode that it tries to find faces of the same person as possible by using internal same-person thresholds. It is useful to find a known person's other photos. Note that an empty list will be returned if no faces pass the internal thresholds. \"matchFace\" mode ignores same-person thresholds and returns ranked similar faces anyway, even the similarity is low. It can be used in the cases like searching celebrity-looking faces\"\n\nhttps://learn.microsoft.com/en-us/rest/api/faceapi/face/find-similar?view=rest-faceapi-v1.0&amp;tabs=HTTP"
      },
      {
        "date": "2023-11-12T04:01:00.000Z",
        "voteCount": 2,
        "content": "in this case we are talking about finding the faces of people who are employees of an organization. We are not talking about famous people. So the recognition will have to be done by an internal set of images of the faces whose faces are to be matched in the corporate photo gallery. Also set maxNumOfCandidatesReturned = 1. Which means that it is also acceptable not to find matches. Which is not the case with matchFace because it also tolerates a low confidence coefficient. Considering what is reported in the article I think the second answer to the question is more correct matchParson."
      },
      {
        "date": "2023-11-12T04:29:00.000Z",
        "voteCount": 1,
        "content": "Sorry, but after further investigation I am not sure that this is the case. Frankly, the Microsoft documentation in this case doesn't seem to be very satisfactory."
      },
      {
        "date": "2024-09-05T07:36:00.000Z",
        "voteCount": 1,
        "content": "Although Microsoft is known for bad products,  confusing naming conventions, no-alignment across products, confusing documentation and useless certification questions, this is a case of wrong question."
      },
      {
        "date": "2022-07-18T06:04:00.000Z",
        "voteCount": 7,
        "content": "I'm leaning towards: largeFaceListId and matchedPerson\n\nhttps://docs.microsoft.com/en-us/rest/api/faceapi/face/find-similar?tabs=HTTP#find-similar-results-example\n\n\"matchPerson\" is the default mode that it tries to find faces of the same person as possible by using internal same-person thresholds. It is useful to find a known person's other photos. Note that an empty list will be returned if no faces pass the internal thresholds. \n\n\"matchFace\" mode ignores same-person thresholds and returns ranked similar faces anyway, even the similarity is low. It can be used in the cases like searching celebrity-looking faces."
      },
      {
        "date": "2023-08-16T06:50:00.000Z",
        "voteCount": 1,
        "content": "it says \"The call must find similar faces from an existing list named employeefaces\", similar  being the keyword here so matchFace i think is correct."
      },
      {
        "date": "2023-12-27T07:20:00.000Z",
        "voteCount": 2,
        "content": "Agree since code also has \"maxNumOfCandidatesReturned\", which would be ignored by \"matchFace\"... both \"matchFace\" and \"matchPerson\" find similars but only \"matchPerson\" will use internal thresholds."
      },
      {
        "date": "2022-06-07T05:28:00.000Z",
        "voteCount": 3,
        "content": "Was on exam 7 Jun 2022"
      },
      {
        "date": "2022-05-29T10:50:00.000Z",
        "voteCount": 5,
        "content": "it's should be largeFaceListId not LargeFaceListId (Capitalized). It's wouldn't work in a http request..."
      },
      {
        "date": "2022-04-23T15:55:00.000Z",
        "voteCount": 1,
        "content": "The 1000 face parameter is for the faceIds and not the faceListId.So, it could be faceListId as well."
      },
      {
        "date": "2022-04-23T15:53:00.000Z",
        "voteCount": 1,
        "content": "Why not faceListId? Nothing specific mentioned on MS docs."
      },
      {
        "date": "2022-02-01T16:55:00.000Z",
        "voteCount": 2,
        "content": "\"matchPerson\"\n\nFind similar results example\nSample Request\nHTTP\nPOST {Endpoint}/face/v1.0/findsimilars\nOcp-Apim-Subscription-Key: {API key}\nRequest Body\nJSON\n{\n  \"faceId\": \"c5c24a82-6845-4031-9d5d-978df9175426\",\n  \"largeFaceListId\": \"sample_list\",\n  \"maxNumOfCandidatesReturned\": 1,\n  \"mode\": \"matchPerson\"\n}\n\nhttps://docs.microsoft.com/en-us/rest/api/faceapi/face/find-similar"
      },
      {
        "date": "2022-01-04T16:13:00.000Z",
        "voteCount": 5,
        "content": "In Question it's given we have to find similar faces - So we have to use \"matchFace\" and because there are large list , so we have to use LargeFaceListID"
      },
      {
        "date": "2021-11-06T04:18:00.000Z",
        "voteCount": 2,
        "content": "Seems Correct"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 13,
    "url": "https://www.examtopics.com/discussions/microsoft/view/54793-exam-ai-102-topic-2-question-13-discussion/",
    "body": "DRAG DROP -<br>You are developing a photo application that will find photos of a person based on a sample image by using the Face API.<br>You need to create a POST request to find the photos.<br>How should you complete the request? To answer, drag the appropriate values to the correct targets. Each value may be used once, more than once, or not at all.<br>You may need to drag the split bar between panes or scroll to view content.<br>NOTE: Each correct selection is worth one point.<br>Select and Place:<br><img src=\"/assets/media/exam-media/04271/0009800001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04271/0009900001.png\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: detect -<br>Face - Detect With Url: Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes.<br>POST {Endpoint}/face/v1.0/detect<br><br>Box 2: matchPerson -<br>Find similar has two working modes, \"matchPerson\" and \"matchFace\". \"matchPerson\" is the default mode that it tries to find faces of the same person as possible by using internal same-person thresholds. It is useful to find a known person's other photos. Note that an empty list will be returned if no faces pass the internal thresholds. \"matchFace\" mode ignores same-person thresholds and returns ranked similar faces anyway, even the similarity is low. It can be used in the cases like searching celebrity-looking faces.<br>Reference:<br>https://docs.microsoft.com/en-us/rest/api/faceapi/face/detectwithurl https://docs.microsoft.com/en-us/rest/api/faceapi/face/findsimilar",
    "votes": [],
    "comments": [
      {
        "date": "2021-06-07T05:03:00.000Z",
        "voteCount": 74,
        "content": "Box 1 is \"findsimilars\", others do not match the given request body and make no sense anyway. https://docs.microsoft.com/en-us/rest/api/faceapi/face/find-similar"
      },
      {
        "date": "2021-06-13T21:41:00.000Z",
        "voteCount": 2,
        "content": "cool. correct answer!"
      },
      {
        "date": "2021-07-02T11:34:00.000Z",
        "voteCount": 4,
        "content": "definitely find-similar, as it is the only one whose body parameters correspond"
      },
      {
        "date": "2022-07-18T06:06:00.000Z",
        "voteCount": 12,
        "content": "findsimilars and matchPerson\n\nhttps://docs.microsoft.com/en-us/rest/api/faceapi/face/find-similar?tabs=HTTP#find-similar-results-example\n\n\"matchPerson\" is the default mode that it tries to find faces of the same person as possible by using internal same-person thresholds. It is useful to find a known person's other photos. Note that an empty list will be returned if no faces pass the internal thresholds. \n\n\"matchFace\" mode ignores same-person thresholds and returns ranked similar faces anyway, even the similarity is low. It can be used in the cases like searching celebrity-looking faces."
      },
      {
        "date": "2024-09-02T04:57:00.000Z",
        "voteCount": 2,
        "content": "find similar and matchperson\nmatchperson because it is identifying a specific person, not finding similar faces"
      },
      {
        "date": "2024-07-15T11:24:00.000Z",
        "voteCount": 1,
        "content": "1. findsimilars\n2. matchPerson"
      },
      {
        "date": "2024-06-21T08:55:00.000Z",
        "voteCount": 1,
        "content": "1. findsimilars\n2. matchPerson"
      },
      {
        "date": "2024-05-28T06:54:00.000Z",
        "voteCount": 1,
        "content": "1. findsimilars\n2. matchPerson"
      },
      {
        "date": "2024-05-25T07:31:00.000Z",
        "voteCount": 1,
        "content": "1. findsimilars\n2. matchPerson"
      },
      {
        "date": "2024-03-25T04:51:00.000Z",
        "voteCount": 1,
        "content": "Final Answer:\nfindsimilars and matchPerson"
      },
      {
        "date": "2023-11-03T14:54:00.000Z",
        "voteCount": 2,
        "content": "Box 1 is findsimilars. Box 2 is matchPerson and the provided explanation is correct"
      },
      {
        "date": "2023-07-01T00:49:00.000Z",
        "voteCount": 10,
        "content": "1. findsimilars\n2. matchPerson\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/computer-vision/how-to/find-similar-faces?tabs=rest#find-and-print-matches\nThe Find Similar operation does face matching between a target face and a set of candidate faces, finding a smaller set of faces that look similar to the target face. This is useful for doing a face search by image."
      },
      {
        "date": "2022-03-04T00:09:00.000Z",
        "voteCount": 5,
        "content": "Box 1: findsimilars\nBox 2: matchPerson\n\nhttps://dev.cognitive.azure.cn/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395237"
      },
      {
        "date": "2022-02-09T15:02:00.000Z",
        "voteCount": 2,
        "content": "FIRST BOX IDEBTIFY SECOND BOX NOTHING\nPOST {Endpoint}/face/v1.0/identify\nOcp-Apim-Subscription-Key: {API key}\n{\n  \"largePersonGroupId\": \"sample_group\",\n  \"faceIds\": [\n    \"c5c24a82-6845-4031-9d5d-978df9175426\",\n    \"65d083d4-9447-47d1-af30-b626144bf0fb\"\n  ],\n  \"maxNumOfCandidatesReturned\": 1,\n  \"confidenceThreshold\": 0.5\n}"
      },
      {
        "date": "2022-01-04T16:32:00.000Z",
        "voteCount": 1,
        "content": "Box 1 - FindSimilar\nBox 2 - matchPerson (We have to find based on a sample photo)"
      },
      {
        "date": "2021-11-06T04:19:00.000Z",
        "voteCount": 1,
        "content": "Seems FIND SIMILAR AND MATCHPERSON"
      },
      {
        "date": "2021-10-18T07:46:00.000Z",
        "voteCount": 2,
        "content": "Looking at the ENTIRE document the answer has to be findsimilar: You cannot send the properties like faceListID and largeFaceListId to /detect"
      },
      {
        "date": "2021-09-03T06:52:00.000Z",
        "voteCount": 4,
        "content": "The Answer is correct. The question asks to \"find photos of a person based on a sample image\". Key is \"based on a sample image\". Only detect does this : https://docs.microsoft.com/en-us/rest/api/faceapi/face/detect-with-url.  Find Similars is used to search the similar-looking faces from a faceId array, a face list or a large face list"
      },
      {
        "date": "2021-10-18T09:51:00.000Z",
        "voteCount": 1,
        "content": "detect does not take faceid. Cannot be detect !"
      },
      {
        "date": "2021-08-23T00:34:00.000Z",
        "voteCount": 2,
        "content": "https://docs.microsoft.com/en-us/rest/api/faceapi/face/find-similar"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 14,
    "url": "https://www.examtopics.com/discussions/microsoft/view/84342-exam-ai-102-topic-2-question-14-discussion/",
    "body": "HOTSPOT -<br>You develop a test method to verify the results retrieved from a call to the Computer Vision API. The call is used to analyze the existence of company logos in images. The call returns a collection of brands named brands.<br>You have the following code segment.<br><img src=\"/assets/media/exam-media/04271/0010000001.png\" class=\"in-exam-image\"><br>For each of the following statements, select Yes if the statement is true. Otherwise, select No.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04271/0010000002.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04271/0010100001.png\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: Yes -<br><br>Box 2: Yes -<br>Coordinates of a rectangle in the API refer to the top left corner.<br><br>Box 3: No -<br>Reference:<br>https://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/concept-brand-detection",
    "votes": [],
    "comments": [
      {
        "date": "2022-11-13T06:02:00.000Z",
        "voteCount": 13,
        "content": "Maybe I take it too literally, but I think the third one is \"NO\": the response returns Width and Height, which can be used to calculate the coordinates of bottom right corner, but it does not include them directly."
      },
      {
        "date": "2023-08-31T03:58:00.000Z",
        "voteCount": 11,
        "content": "Y, Y, N\nhttps://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/shelf-analyze#bounding-box-api-model\nx\tLeft-coordinate of the top left point of the area, in pixels.\ny\tTop-coordinate of the top left point of the area, in pixels.\nw\tWidth measured from the top-left point of the area, in pixels.\nh\tHeight measured from the top-left point of the area, in pixels."
      },
      {
        "date": "2023-11-04T02:38:00.000Z",
        "voteCount": 2,
        "content": "thanks for posting the documentation"
      },
      {
        "date": "2024-09-10T00:47:00.000Z",
        "voteCount": 1,
        "content": "yes yes no"
      },
      {
        "date": "2024-07-21T00:35:00.000Z",
        "voteCount": 1,
        "content": "I cant see anythig related to corner position in the api. \nThen its Y, Y, Y"
      },
      {
        "date": "2024-07-21T00:40:00.000Z",
        "voteCount": 2,
        "content": "Nop , based on documentation its top left - so its Y Y N"
      },
      {
        "date": "2024-05-28T08:21:00.000Z",
        "voteCount": 3,
        "content": "The correct sequence is Yes Yes No."
      },
      {
        "date": "2024-05-25T06:55:00.000Z",
        "voteCount": 2,
        "content": "This is the same question as Topic2 #29."
      },
      {
        "date": "2024-05-20T08:07:00.000Z",
        "voteCount": 3,
        "content": "Yes Yes No"
      },
      {
        "date": "2024-05-20T08:06:00.000Z",
        "voteCount": 2,
        "content": "Yes Yes No"
      },
      {
        "date": "2024-04-30T01:05:00.000Z",
        "voteCount": 2,
        "content": "The brand_confidence variable is not declared in the snippet. Perhaps they meant brand.confidence? Same with rectangle_x . As it stands, the answers should be N,N,N."
      },
      {
        "date": "2024-04-13T00:27:00.000Z",
        "voteCount": 1,
        "content": "The Python syntax for working with Python dictionaries is wrong. Remember we are calling the API which returns a JSON object. \n\nbrand.rectangle_x - WRONG - it should be brand.rectangle.x\nbrand_confidence - WRONG - should be brand.confidence\n\nSo the answer should be N for all!"
      },
      {
        "date": "2024-03-25T04:53:00.000Z",
        "voteCount": 2,
        "content": "Final Answer:\nYes\nYes\nNo"
      },
      {
        "date": "2023-03-15T03:22:00.000Z",
        "voteCount": 2,
        "content": "The code will return the name of each detected brand with a confidence equal to or higher than 75 percent.\nYes, the code will return the name of each detected brand with a confidence equal to or higher than 75 percent.\n\n2. The code will return coordinates for the top-left corner of the rectangle that contains the brand logo of the displayed brands.\nYes, the code will return the coordinates for the top-left corner of the rectangle that contains the brand logo of the displayed brands.\n\n3. The code will return coordinates for the bottom-right corner of the rectangle that contains the brand logo of the displayed brands.\nNo, the code will not return coordinates for the bottom-right corner of the rectangle that contains the brand logo of the displayed brands. The code is printing the width and height of the rectangle instead."
      },
      {
        "date": "2023-01-09T09:48:00.000Z",
        "voteCount": 2,
        "content": "it could be a trap : so yes, no (it is rectangle.x and not _x) , no (should be x + w as the service returns the width and top left corner : \n\nConsole.WriteLine(\"Brands:\");\nforeach (var brand in results.Brands)\n{\n    Console.WriteLine($\"Logo of {brand.Name} with confidence {brand.Confidence} at location {brand.Rectangle.X}, \" +\n      $\"{brand.Rectangle.X + brand.Rectangle.W}, {brand.Rectangle.Y}, {brand.Rectangle.Y + brand.Rectangle.H}\");\n}\nConsole.WriteLine();\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/computer-vision/how-to/call-analyze-image?tabs=csharp"
      },
      {
        "date": "2024-05-20T00:47:00.000Z",
        "voteCount": 1,
        "content": "hope it is a typo. explanation is spot on"
      },
      {
        "date": "2024-03-01T00:55:00.000Z",
        "voteCount": 1,
        "content": "it is true, it is a trick.\nYes,No,No"
      },
      {
        "date": "2022-12-13T07:31:00.000Z",
        "voteCount": 3,
        "content": "its' yes\nyes\nno\nThe coordinates are always regarding the top left point of the rectangle"
      },
      {
        "date": "2022-10-13T07:21:00.000Z",
        "voteCount": 1,
        "content": "Y\nY\nY\nthe code will return the coordinates for any position"
      },
      {
        "date": "2022-10-04T06:09:00.000Z",
        "voteCount": 1,
        "content": "yes\nyes\nyes"
      },
      {
        "date": "2022-10-04T20:08:00.000Z",
        "voteCount": 2,
        "content": "What makes the third one \"yes\"?"
      },
      {
        "date": "2022-10-08T10:44:00.000Z",
        "voteCount": 2,
        "content": "According to the microsoft Documetn, Ithought so. What makes yu think it is No ?"
      },
      {
        "date": "2022-10-27T07:07:00.000Z",
        "voteCount": 2,
        "content": "if you look at the code it is _x and not .x"
      },
      {
        "date": "2023-02-11T20:24:00.000Z",
        "voteCount": 2,
        "content": "I think that is a typo"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 15,
    "url": "https://www.examtopics.com/discussions/microsoft/view/54794-exam-ai-102-topic-2-question-15-discussion/",
    "body": "HOTSPOT -<br>You develop an application that uses the Face API.<br>You need to add multiple images to a person group.<br>How should you complete the code? To answer, select the appropriate options in the answer area.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04271/0010200001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04271/0010300001.png\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: Stream -<br>The File.OpenRead(String) method opens an existing file for reading.<br>Example:  Open the stream and read it back.<br>using (FileStream fs = File.OpenRead(path))<br><br>Box 2: CreateAsync -<br>Create the persons for the PersonGroup. Persons are created concurrently.<br>Example:<br>await faceClient.PersonGroupPerson.CreateAsync(personGroupId, personName);<br>Reference:<br>https://docs.microsoft.com/en-us/azure/cognitive-services/face/face-api-how-to-topics/how-to-add-faces",
    "votes": [],
    "comments": [
      {
        "date": "2021-06-13T22:16:00.000Z",
        "voteCount": 69,
        "content": "AddFaceFromStreamAsync. Step 5 on https://docs.microsoft.com/en-us/azure/cognitive-services/face/face-api-how-to-topics/how-to-add-faces"
      },
      {
        "date": "2023-11-04T02:42:00.000Z",
        "voteCount": 3,
        "content": "thanks for the provided document. Clearly wrong the second answer. It should be AddFaceFromStreamAsync"
      },
      {
        "date": "2021-06-30T08:11:00.000Z",
        "voteCount": 50,
        "content": "Wrong!\nA - Stream (this is correct)\nB - AddFaceFromStreamAsync\n(literally the same code from Step 5 at https://docs.microsoft.com/en-us/azure/cognitive-services/face/face-api-how-to-topics/how-to-add-faces)"
      },
      {
        "date": "2024-06-06T06:36:00.000Z",
        "voteCount": 2,
        "content": "1. Stream\n2. AddFaceFromStreamAsync"
      },
      {
        "date": "2024-05-28T06:53:00.000Z",
        "voteCount": 1,
        "content": "1. Stream\n2. AddFaceFromStreamAsync"
      },
      {
        "date": "2024-05-25T07:29:00.000Z",
        "voteCount": 1,
        "content": "1. Stream\n2. AddFaceFromStreamAsync"
      },
      {
        "date": "2024-05-24T07:58:00.000Z",
        "voteCount": 1,
        "content": "Stream and CreateAsync"
      },
      {
        "date": "2024-03-25T04:54:00.000Z",
        "voteCount": 2,
        "content": "Final Answer:\nA - Stream (this is correct)\nB - AddFaceFromStreamAsync"
      },
      {
        "date": "2023-10-26T04:45:00.000Z",
        "voteCount": 2,
        "content": "1. Stream\n2. AddFaceFromStreamAsync\nhttps://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/add-faces#step-5-add-faces-to-the-persons"
      },
      {
        "date": "2023-07-01T00:41:00.000Z",
        "voteCount": 5,
        "content": "1. Stream\n2. AddFaceFromStreamAsync\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/computer-vision/how-to/add-faces#step-5-add-faces-to-the-persons"
      },
      {
        "date": "2023-05-29T09:09:00.000Z",
        "voteCount": 1,
        "content": "Stream\nAddFaceFromStreamAsync"
      },
      {
        "date": "2023-05-02T05:15:00.000Z",
        "voteCount": 1,
        "content": "Stream\nAddFaceFromStreamAsync"
      },
      {
        "date": "2022-08-12T10:44:00.000Z",
        "voteCount": 3,
        "content": "Box 1: Stream\nBox 2: AddFaceFromStreamAsync\n\nFile.OpenRead() returns a Stream object. \n\n using (Stream stream = File.OpenRead(imagePath))\n        {\n            await faceClient.PersonGroupPerson.AddFaceFromStreamAsync(personGroupId, personId, stream);\n        }\nref: https://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/how-to/add-faces#step-5-add-faces-to-the-persons"
      },
      {
        "date": "2022-07-18T06:25:00.000Z",
        "voteCount": 3,
        "content": "Stream and AddFaceFromStreamAsync are correct answers. \n\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/how-to/add-faces#step-5-add-faces-to-the-persons"
      },
      {
        "date": "2022-02-11T22:50:00.000Z",
        "voteCount": 2,
        "content": "Parallel.For(0, PersonCount, async i =&gt;\n{\n    Guid personId = persons[i].PersonId;\n    string personImageDir = @\"/path/to/person/i/images\";\n\n    foreach (string imagePath in Directory.GetFiles(personImageDir, \"*.jpg\"))\n    {\n        await WaitCallLimitPerSecondAsync();\n\n        using (Stream stream = File.OpenRead(imagePath))\n        {\n            await faceClient.PersonGroupPerson.AddFaceFromStreamAsync(personGroupId, personId, stream);\n        }\n    }\n});"
      },
      {
        "date": "2022-01-04T17:36:00.000Z",
        "voteCount": 3,
        "content": "Stream and AddFaceFromStreamAsync"
      },
      {
        "date": "2021-09-20T12:25:00.000Z",
        "voteCount": 3,
        "content": "Parallel.For(0, PersonCount, async i =&gt;\n{\n    Guid personId = persons[i].PersonId;\n    string personImageDir = @\"/path/to/person/i/images\";\n\n    foreach (string imagePath in Directory.GetFiles(personImageDir, \"*.jpg\"))\n    {\n        await WaitCallLimitPerSecondAsync();\n\n        using (Stream stream = File.OpenRead(imagePath))\n        {\n            await faceClient.PersonGroupPerson.AddFaceFromStreamAsync(personGroupId, personId, stream);\n        }\n    }\n});\n\n\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/face/face-api-how-to-topics/how-to-add-faces"
      },
      {
        "date": "2021-09-20T12:23:00.000Z",
        "voteCount": 2,
        "content": "Parallel.For(0, PersonCount, async i =&gt;\n{\n    Guid personId = persons[i].PersonId;\n    string personImageDir = @\"/path/to/person/i/images\";\n\n    foreach (string imagePath in Directory.GetFiles(personImageDir, \"*.jpg\"))\n    {\n        await WaitCallLimitPerSecondAsync();\n\n        using (Stream stream = File.OpenRead(imagePath))\n        {\n            await faceClient.PersonGroupPerson.AddFaceFromStreamAsync(personGroupId, personId, stream);\n        }\n    }\n});\n\n\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/face/face-api-how-to-topics/how-to-add-faces"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 16,
    "url": "https://www.examtopics.com/discussions/microsoft/view/77610-exam-ai-102-topic-2-question-16-discussion/",
    "body": "Your company uses an Azure Cognitive Services solution to detect faces in uploaded images. The method to detect the faces uses the following code.<br><img src=\"/assets/media/exam-media/04271/0010400001.png\" class=\"in-exam-image\"><br>You discover that the solution frequently fails to detect faces in blurred images and in images that contain sideways faces.<br>You need to increase the likelihood that the solution can detect faces in blurred images and images that contain sideways faces.<br>What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse a different version of the Face API.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse the Computer Vision service instead of the Face service.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse the Identify method instead of the Detect method.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tChange the detection model.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 21,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2022-07-18T06:30:00.000Z",
        "voteCount": 12,
        "content": "D is correct answer : change the detection model.\n\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/how-to/specify-detection-model#evaluate-different-models"
      },
      {
        "date": "2024-06-22T00:16:00.000Z",
        "voteCount": 1,
        "content": "I say this answer is D."
      },
      {
        "date": "2024-05-20T08:14:00.000Z",
        "voteCount": 1,
        "content": "I use detection_02 or detection_03."
      },
      {
        "date": "2024-02-16T15:36:00.000Z",
        "voteCount": 1,
        "content": "it contains sideway faces, so change face API detection model 03"
      },
      {
        "date": "2023-11-04T02:53:00.000Z",
        "voteCount": 2,
        "content": "answer is correct"
      },
      {
        "date": "2023-06-28T05:36:00.000Z",
        "voteCount": 4,
        "content": "D is the answer.\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/computer-vision/how-to/specify-detection-model#evaluate-different-models\nThe different face detection models are optimized for different tasks.\n- detection_02\nImproved accuracy on small, side-view, and blurry faces."
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 17,
    "url": "https://www.examtopics.com/discussions/microsoft/view/81643-exam-ai-102-topic-2-question-17-discussion/",
    "body": "You have the following Python function for creating Azure Cognitive Services resources programmatically. def create_resource (resource_name, kind, account_tier, location) : parameters = CognitiveServicesAccount(sku=Sku(name=account_tier), kind=kind, location=location, properties={}) result = client.accounts.create(resource_group_name, resource_name, parameters)<br>You need to call the function to create a free Azure resource in the West US Azure region. The resource will be used to generate captions of images automatically.<br>Which code should you use?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tcreate_resource(\"res1\", \"ComputerVision\", \"F0\", \"westus\")\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tcreate_resource(\"res1\", \"CustomVision.Prediction\", \"F0\", \"westus\")",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tcreate_resource(\"res1\", \"ComputerVision\", \"S0\", \"westus\")",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tcreate_resource(\"res1\", \"CustomVision.Prediction\", \"S0\", \"westus\")"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 58,
        "isMostVoted": true
      },
      {
        "answer": "B",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2022-11-06T05:41:00.000Z",
        "voteCount": 43,
        "content": "Computer vision provide automatic vision solutions including captions. The key-phrase is \"automatic\". Therefore this answer should be obvious to everyone. I would expect more professionalism from people who request money for services like this one. Many questions here have incorrect and even contradictory answers... Shame!"
      },
      {
        "date": "2023-05-08T06:42:00.000Z",
        "voteCount": 3,
        "content": "I agree.\nTo me it looks like many answers are being deliberately set to incorrect answers. Not sure why, though."
      },
      {
        "date": "2024-05-25T06:57:00.000Z",
        "voteCount": 2,
        "content": "ComputerVision and F0."
      },
      {
        "date": "2024-04-27T17:26:00.000Z",
        "voteCount": 1,
        "content": "duplicate question"
      },
      {
        "date": "2024-07-23T06:06:00.000Z",
        "voteCount": 1,
        "content": "Set 1 question 9."
      },
      {
        "date": "2023-11-25T02:42:00.000Z",
        "voteCount": 1,
        "content": "The answer is A"
      },
      {
        "date": "2023-11-04T02:59:00.000Z",
        "voteCount": 3,
        "content": "Seems to be duplicated question. Anyway to me the correct answer is A.\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/computer-vision/concept-describing-images"
      },
      {
        "date": "2023-10-28T21:08:00.000Z",
        "voteCount": 2,
        "content": "Appeared on Oct/29/2023."
      },
      {
        "date": "2023-10-01T21:25:00.000Z",
        "voteCount": 1,
        "content": "Very confusion, Does Computer Vision provide captions in Free? I think Custom Vision Do:\nComputer Vision Free tire:\nInstance | Features | Price\nFree - Web/Container 20 transactions per minute |  - |5,000 transactions free per month\n\nCustom Vision Free Tire:\nInstance\t| Transactions Per Second (TPS) | Features | Price\nFree\t | 2 TPS | Upload, training and prediction transactions, Up to 2 projects, Up to 1 hour training per month | 5,000 training images free per project, 10,000 predictions per month"
      },
      {
        "date": "2023-06-28T05:33:00.000Z",
        "voteCount": 3,
        "content": "Same as Topic 1 Question 9.\nhttps://www.examtopics.com/discussions/microsoft/view/57153-exam-ai-102-topic-1-question-9-discussion"
      },
      {
        "date": "2023-06-28T05:32:00.000Z",
        "voteCount": 2,
        "content": "A is the answer.\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/cognitive-services-apis-create-account-client-library?pivots=programming-language-python#create-a-cognitive-services-resource-python\nTo create and subscribe to a new Cognitive Services resource, use the Create function. This function adds a new billable resource to the resource group you pass in. When you create your new resource, you'll need to know the \"kind\" of service you want to use, along with its pricing tier (or SKU) and an Azure location. The following function takes all of these arguments and creates a resource."
      },
      {
        "date": "2023-07-07T18:01:00.000Z",
        "voteCount": 2,
        "content": "Gotten this in Jul 2023 exam."
      },
      {
        "date": "2023-06-27T23:23:00.000Z",
        "voteCount": 2,
        "content": "This was on exam 28/06"
      },
      {
        "date": "2023-06-27T16:23:00.000Z",
        "voteCount": 2,
        "content": "Asked in 28/06/2023 exam"
      },
      {
        "date": "2023-06-11T06:44:00.000Z",
        "voteCount": 2,
        "content": "computer vision can generate captions for images"
      },
      {
        "date": "2023-01-18T09:22:00.000Z",
        "voteCount": 1,
        "content": "Computer Vision has generate captions feature"
      },
      {
        "date": "2022-12-11T09:18:00.000Z",
        "voteCount": 1,
        "content": "This question was asked for free azure service. Do we have the generate caption feature supports this with free tier? \nReference -  https://azure.microsoft.com/en-us/pricing/details/cognitive-services/computer-vision/"
      },
      {
        "date": "2022-09-22T02:46:00.000Z",
        "voteCount": 4,
        "content": "Should be A."
      },
      {
        "date": "2022-09-21T12:30:00.000Z",
        "voteCount": 2,
        "content": "A because computer vision provides tags"
      },
      {
        "date": "2022-09-11T04:30:00.000Z",
        "voteCount": 2,
        "content": "Answer Should be A."
      },
      {
        "date": "2022-09-11T04:31:00.000Z",
        "voteCount": 3,
        "content": "one of the feature of Computer vision: The Image Analysis service extracts many visual features from images, such as objects, faces, adult content, and auto-generated text descriptions. Follow the Image Analysis quickstart to get started.\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/overview"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 18,
    "url": "https://www.examtopics.com/discussions/microsoft/view/81861-exam-ai-102-topic-2-question-18-discussion/",
    "body": "You are developing a method that uses the Computer Vision client library. The method will perform optical character recognition (OCR) in images. The method has the following code.<br><img src=\"/assets/media/exam-media/04271/0010700001.png\" class=\"in-exam-image\"><br>During testing, you discover that the call to the GetReadResultAsync method occurs before the read operation is complete.<br>You need to prevent the GetReadResultAsync method from proceeding until the read operation is complete.<br>Which two actions should you perform? Each correct answer presents part of the solution.<br>NOTE: Each correct selection is worth one point.<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRemove the operation_id parameter.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAdd code to verify the read_results.status value.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAdd code to verify the status of the read_operation_location value.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tWrap the call to get_read_result within a loop that contains a delay.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "BD",
    "answerDescription": "",
    "votes": [
      {
        "answer": "BD",
        "count": 16,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-03-15T03:39:00.000Z",
        "voteCount": 5,
        "content": "B. Add code to verify the read_results.status value.\nD. Wrap the call to get_read_result within a loop that contains a delay.\n\nExplanation:\n\nIn order to prevent the GetReadResultAsync method from proceeding until the read operation is complete, we need to check the status of the read operation and wait until it's completed. To do this, we can add code to verify the status of the read_results.status value. If the status is not \"succeeded\", we can add a delay and then retry the operation until it's complete. This can be achieved by wrapping the call to get_read_result within a loop that contains a delay.\n\nRemoving the operation_id parameter or adding code to verify the status of the read_operation_location value will not solve the issue of waiting for the read operation to complete before proceeding with the GetReadResultAsync method."
      },
      {
        "date": "2024-05-28T06:40:00.000Z",
        "voteCount": 1,
        "content": "B and D are right answer."
      },
      {
        "date": "2024-05-20T08:11:00.000Z",
        "voteCount": 2,
        "content": "memorize \"read_results\" words. So B and D."
      },
      {
        "date": "2024-05-20T08:10:00.000Z",
        "voteCount": 1,
        "content": "B and D."
      },
      {
        "date": "2024-04-13T02:18:00.000Z",
        "voteCount": 2,
        "content": "The code snippet does not match the question. There is NO GetReadResultAsync call."
      },
      {
        "date": "2024-01-30T00:06:00.000Z",
        "voteCount": 3,
        "content": "where's GetReadResultAsync  in the code? looks like C# method not python code"
      },
      {
        "date": "2023-11-04T03:06:00.000Z",
        "voteCount": 3,
        "content": "duplicated question"
      },
      {
        "date": "2023-06-28T05:45:00.000Z",
        "voteCount": 2,
        "content": "Same as Question 2.\nhttps://www.examtopics.com/discussions/microsoft/view/74739-exam-ai-102-topic-2-question-2-discussion"
      },
      {
        "date": "2023-06-27T23:24:00.000Z",
        "voteCount": 3,
        "content": "This was on exam 28/06"
      },
      {
        "date": "2022-11-13T06:34:00.000Z",
        "voteCount": 1,
        "content": "Duplicated with Topic 2, Question 2."
      },
      {
        "date": "2022-09-12T11:44:00.000Z",
        "voteCount": 1,
        "content": "Correct"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 19,
    "url": "https://www.examtopics.com/discussions/microsoft/view/83146-exam-ai-102-topic-2-question-19-discussion/",
    "body": "HOTSPOT -<br>You are building an app that will enable users to upload images. The solution must meet the following requirements:<br>* Automatically suggest alt text for the images.<br>* Detect inappropriate images and block them.<br>* Minimize development effort.<br>You need to recommend a computer vision endpoint for each requirement.<br>What should you recommend? To answer, select the appropriate options in the answer area.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04271/0010800001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04271/0010900001.png\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: https://westus.api.cognitive.microsoft.com/customvision/v3.1/prediction/projectid/classify/iterations/publishName/image<br>Box 2: https://westus.api.cognitive.microsoft.com/vision/v3.2/analyze/?visualFeatures=Adult,Description<br>Computer Vision can detect adult material in images so that developers can restrict the display of these images in their software. Content flags are applied with a score between zero and one so developers can interpret the results according to their own preferences.<br>You can detect adult content with the Analyze Image API. When you add the value of Adult to the visualFeatures query parameter<br>Incorrect:<br>Use the Image Moderation API in Azure Content Moderator to scan image content. The moderation job scans your content for profanity, and compares it against custom and shared blocklists.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/concept-detecting-adult-content https://docs.microsoft.com/en-us/azure/cognitive-services/content-moderator/try-image-api https://docs.microsoft.com/en-us/legal/cognitive-services/custom-vision/custom-vision-cvs-transparency-note",
    "votes": [],
    "comments": [
      {
        "date": "2022-11-26T17:11:00.000Z",
        "voteCount": 31,
        "content": "I think it is vision/v3.2/analyze/?visualFeatures=Adult,Description for both"
      },
      {
        "date": "2023-07-01T00:37:00.000Z",
        "voteCount": 12,
        "content": "1. https://westus.api.cognitive.microsoft.com/vision/v3.2/analyze/?visualFeatures=Adult,Description\n2. https://westus.api.cognitive.microsoft.com/vision/v3.2/analyze/?visualFeatures=Adult,Description\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/computer-vision/concept-describing-images\nComputer Vision can analyze an image and generate a human-readable phrase that describes its contents. The algorithm returns several descriptions based on different visual features, and each description is given a confidence score. The final output is a list of descriptions ordered from highest to lowest confidence."
      },
      {
        "date": "2024-01-18T12:26:00.000Z",
        "voteCount": 3,
        "content": "The first one says \"descnption\" , so I guess that's not the correct answer. \n\nDoes anybody know the correct one?"
      },
      {
        "date": "2023-07-07T18:01:00.000Z",
        "voteCount": 4,
        "content": "Gotten this in Jul 2023 exam."
      },
      {
        "date": "2023-07-10T12:29:00.000Z",
        "voteCount": 3,
        "content": "zelleck, do you say this on every question?"
      },
      {
        "date": "2023-07-23T21:26:00.000Z",
        "voteCount": 6,
        "content": "He does not, he doesn't say that in the next question Topic 2 Q20"
      },
      {
        "date": "2023-08-21T02:20:00.000Z",
        "voteCount": 2,
        "content": "Thank you for confirming that it a active/valid question, and it might appare in the exam"
      },
      {
        "date": "2023-07-01T00:37:00.000Z",
        "voteCount": 2,
        "content": "https://learn.microsoft.com/en-us/azure/cognitive-services/computer-vision/concept-detecting-adult-content\nComputer Vision can detect adult material in images so that developers can restrict the display of these images in their software. Content flags are applied with a score between zero and one so developers can interpret the results according to their own preferences.\n\nYou can detect adult content with the Analyze Image 3.2 API. When you add the value of Adult to the visualFeatures query parameter, the API returns three boolean properties\u2014isAdultContent, isRacyContent, and isGoryContent\u2014in its JSON response. The method also returns corresponding properties\u2014adultScore, racyScore, and goreScore\u2014which represent confidence scores between zero and one for each respective category."
      },
      {
        "date": "2023-08-31T06:59:00.000Z",
        "voteCount": 1,
        "content": "https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/use-case-alt-text?source=recommendations\nAlt text, or alternative text, is an HTML attribute added to the\u202f&lt;img&gt;\u202ftag that displays images on an application or web page.\nAlt text enables website owners to describe an image in plain text. These image descriptions improve accessibility by enabling screen readers such as Microsoft Narrator, JAWS, and NVDA to accurately communicate image content to their visually impaired and blind users.\nAlt text is also vital for image search engine optimization (SEO). It helps search engines understand the visual content in your images. The search engine is then better able to include and rank your website in search results when users search for the content in your website.\nAuto-generate alt text with Image Analysis: Image Analysis offers image captioning models that generate one-sentence descriptions of image visual content.\nThank you @zellck!"
      },
      {
        "date": "2024-06-06T06:35:00.000Z",
        "voteCount": 1,
        "content": "Adult Video"
      },
      {
        "date": "2024-05-28T08:22:00.000Z",
        "voteCount": 2,
        "content": "Both will contain Adult,Description."
      },
      {
        "date": "2024-05-20T08:09:00.000Z",
        "voteCount": 2,
        "content": "Generate alt text should be \"v3.2/analyze\". Detect inappropriate content should be \"v3.2/analyze\"."
      },
      {
        "date": "2024-02-16T15:37:00.000Z",
        "voteCount": 2,
        "content": "description ==&gt;Alt text"
      },
      {
        "date": "2023-10-21T10:33:00.000Z",
        "voteCount": 2,
        "content": "Both are https://westus.api.cognitive.microsoft.com/vision/v3.2/analyze/?visualFeatures=Adult,Description\n\nA string indicating what visual feature types to return. Multiple values should be comma-separated.\nValid visual feature types include:\n\nAdult - detects if the image is pornographic in nature (depicts nudity or a sex act), or is gory (depicts extreme violence or blood). Sexually suggestive content (aka racy content) is also detected.\nDescription - describes the image content with a complete sentence in supported languages.\n\nhttps://westus.dev.cognitive.microsoft.com/docs/services/computer-vision-v3-2/operations/56f91f2e778daf14a499f21b"
      },
      {
        "date": "2022-10-03T03:39:00.000Z",
        "voteCount": 4,
        "content": "I think it is two times /analyze/?visualFeatures=Adult,Description"
      },
      {
        "date": "2022-10-04T06:23:00.000Z",
        "voteCount": 1,
        "content": "Shouldn't it be option 2 in the first column ?  \"iteratio\""
      },
      {
        "date": "2022-09-21T16:24:00.000Z",
        "voteCount": 2,
        "content": "Generate alt text can use either analyze or describe. From the given option, I think it should be the analyze url too.\nhttps://westcentralus.dev.cognitive.microsoft.com/docs/services/computer-vision-v3-2/operations/56f91f2e778daf14a499f21f"
      },
      {
        "date": "2023-05-05T20:59:00.000Z",
        "voteCount": 1,
        "content": "Agreed, analyze in both answers"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 20,
    "url": "https://www.examtopics.com/discussions/microsoft/view/91092-exam-ai-102-topic-2-question-20-discussion/",
    "body": "You need to build a solution that will use optical character recognition (OCR) to scan sensitive documents by using the Computer Vision API. The solution must<br>NOT be deployed to the public cloud.<br>What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tBuild an on-premises web app to query the Computer Vision endpoint.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tHost the Computer Vision endpoint in a container on an on-premises server.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tHost an exported Open Neural Network Exchange (ONNX) model on an on-premises server.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tBuild an Azure web app to query the Computer Vision endpoint."
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 19,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-06-22T00:15:00.000Z",
        "voteCount": 2,
        "content": "I say this answer is B. Please hurry up and transport the meat."
      },
      {
        "date": "2024-05-28T08:20:00.000Z",
        "voteCount": 3,
        "content": "B is the correct answer."
      },
      {
        "date": "2024-05-20T08:06:00.000Z",
        "voteCount": 3,
        "content": "B is right answer."
      },
      {
        "date": "2024-02-16T15:38:00.000Z",
        "voteCount": 1,
        "content": "model is hosted on-premise but the billing information has to be provided to the on-premise container to report the usage"
      },
      {
        "date": "2023-11-04T03:21:00.000Z",
        "voteCount": 2,
        "content": "correct answer\nhttps://learn.microsoft.com/en-us/azure/ai-services/cognitive-services-container-support"
      },
      {
        "date": "2023-06-28T05:26:00.000Z",
        "voteCount": 4,
        "content": "B is the answer.\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/computer-vision/deploy-computer-vision-on-premises\nOne option to manage your Computer Vision containers on-premises is to use Kubernetes and Helm. Using Kubernetes and Helm to define a Computer Vision container image, we'll create a Kubernetes package. This package will be deployed to a Kubernetes cluster on-premises."
      },
      {
        "date": "2023-03-15T03:53:00.000Z",
        "voteCount": 2,
        "content": "B. Host the Computer Vision endpoint in a container on an on-premises server.\n\nSince the solution should not be deployed to the public cloud, option B is the correct answer. By hosting the Computer Vision endpoint in a container on an on-premises server, the solution can still leverage the capabilities of the Computer Vision API while keeping the processing and data within the on-premises environment. Option A and D both involve using a web app, which would likely require hosting in the public cloud. Option C involves hosting an exported ONNX model, which may not have the same capabilities as the Computer Vision API."
      },
      {
        "date": "2022-12-11T17:51:00.000Z",
        "voteCount": 2,
        "content": "Answer is correct."
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 21,
    "url": "https://www.examtopics.com/discussions/microsoft/view/102684-exam-ai-102-topic-2-question-21-discussion/",
    "body": "You have an Azure Cognitive Search solution and a collection of handwritten letters stored as JPEG files.<br><br>You plan to index the collection. The solution must ensure that queries can be performed on the contents of the letters.<br><br>You need to create an indexer that has a skillset.<br><br>Which skill should you include?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\timage analysis",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\toptical character recognition (OCR)\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tkey phrase extraction",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tdocument extraction"
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 19,
        "isMostVoted": true
      },
      {
        "answer": "A",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2023-03-15T03:57:00.000Z",
        "voteCount": 13,
        "content": "To ensure that queries can be performed on the contents of the letters, the skill that should be included in the indexer is optical character recognition (OCR).\n\nOption B, optical character recognition (OCR), is a technology that can recognize text within an image and convert it into machine-readable text. This skill will enable the search engine to read the handwritten letters and convert them into searchable text that can be indexed by Azure Cognitive Search.\n\nOption A, image analysis, is a useful skill for analyzing images to extract metadata, but it does not directly enable text recognition.\n\nOption C, key phrase extraction, extracts important phrases and concepts from text, but it requires the text to be already recognized and extracted by OCR or other text extraction techniques.\n\nOption D, document extraction, is a skill that extracts specific pieces of information from documents, but it does not address the challenge of recognizing and extracting text from handwritten letters."
      },
      {
        "date": "2024-09-26T03:12:00.000Z",
        "voteCount": 1,
        "content": "Image Analysis includes OCR capabilities inside. \nhttps://learn.microsoft.com/en-us/azure/ai-services/computer-vision/overview-image-analysis?tabs=4-0#analyze-image"
      },
      {
        "date": "2024-06-22T00:15:00.000Z",
        "voteCount": 1,
        "content": "I say this answer is B. Please hurry up and transport the meat."
      },
      {
        "date": "2024-05-28T08:19:00.000Z",
        "voteCount": 1,
        "content": "OCR is the correct answer."
      },
      {
        "date": "2024-05-20T08:01:00.000Z",
        "voteCount": 1,
        "content": "Why OCR?"
      },
      {
        "date": "2024-06-03T17:36:00.000Z",
        "voteCount": 1,
        "content": "Handwritten is the keyword"
      },
      {
        "date": "2024-02-16T15:39:00.000Z",
        "voteCount": 2,
        "content": "OCR to extract the text and then create an indexer on the text extracted"
      },
      {
        "date": "2023-11-04T03:26:00.000Z",
        "voteCount": 1,
        "content": "provided answer is correct. OCR to scan handwritten documents"
      },
      {
        "date": "2023-06-28T05:23:00.000Z",
        "voteCount": 1,
        "content": "B is the answer.\n\nhttps://learn.microsoft.com/en-us/azure/search/cognitive-search-skill-ocr\nThe Optical character recognition (OCR) skill recognizes printed and handwritten text in image files."
      },
      {
        "date": "2023-06-27T01:16:00.000Z",
        "voteCount": 1,
        "content": "Therefore, option B, optical character recognition (OCR), is the most suitable skill to include in the indexer for indexing the contents of handwritten letters and making them searchable."
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 22,
    "url": "https://www.examtopics.com/discussions/microsoft/view/102936-exam-ai-102-topic-2-question-22-discussion/",
    "body": "HOTSPOT<br> -<br><br>You have a library that contains thousands of images. <br><br>You need to tag the images as photographs, drawings, or clipart. <br><br>Which service endpoint and response property should you use? To answer, select the appropriate options in the answer area. <br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/ai-102/image3.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/ai-102/image4.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2023-03-17T06:05:00.000Z",
        "voteCount": 51,
        "content": "I think that the answers are wrong. They should be:\n1 - Computer Vision analyze image\n2 - imageType\n\nAccording to https://learn.microsoft.com/en-us/azure/cognitive-services/computer-vision/concept-detecting-image-types Computer Vision can analyze the content type of images, indicating whether an image is clip art or a line drawing"
      },
      {
        "date": "2024-05-20T01:26:00.000Z",
        "voteCount": 1,
        "content": "out of box option this is the best bet if not custom vision and train the model for object detection - more work"
      },
      {
        "date": "2023-05-31T00:21:00.000Z",
        "voteCount": 2,
        "content": "Agree, see json example at: https://westcentralus.dev.cognitive.microsoft.com/docs/services/computer-vision-v3-2/operations/56f91f2e778daf14a499f21b"
      },
      {
        "date": "2024-05-31T18:19:00.000Z",
        "voteCount": 1,
        "content": "This link no longer works"
      },
      {
        "date": "2023-11-04T03:31:00.000Z",
        "voteCount": 1,
        "content": "agree and thanks for posting the related documentation"
      },
      {
        "date": "2023-07-01T00:28:00.000Z",
        "voteCount": 13,
        "content": "1. Computer Vision analyze images\n2. imageType\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/computer-vision/concept-detecting-image-types\nWith the Analyze Image API, Computer Vision can analyze the content type of images, indicating whether an image is clip art or a line drawing."
      },
      {
        "date": "2023-07-07T18:02:00.000Z",
        "voteCount": 6,
        "content": "Gotten this in Jul 2023 exam."
      },
      {
        "date": "2024-09-17T01:59:00.000Z",
        "voteCount": 1,
        "content": "first is - Computer Vision analyze images\n2nd -  imageType\n\ninfo here - https://learn.microsoft.com/en-us/azure/cognitive-services/computer-vision/concept-detecting-image-types"
      },
      {
        "date": "2024-07-15T11:26:00.000Z",
        "voteCount": 1,
        "content": "1. Computer Vision analyze images\n2. imageType"
      },
      {
        "date": "2024-06-06T06:34:00.000Z",
        "voteCount": 1,
        "content": "1. Computer Vision analyze images\n2. imageType"
      },
      {
        "date": "2024-05-28T08:17:00.000Z",
        "voteCount": 1,
        "content": "The following aligned answer is correct.\n1. Computer Vision analyze images\n2. imageType"
      },
      {
        "date": "2024-05-25T06:02:00.000Z",
        "voteCount": 1,
        "content": "1. Computer Vision analyze images\n2. imageType"
      },
      {
        "date": "2024-05-20T08:04:00.000Z",
        "voteCount": 1,
        "content": "Service endpoint should be \"Computer Vision analyze images\". Property should be \"imageType\"."
      },
      {
        "date": "2024-05-20T08:04:00.000Z",
        "voteCount": 1,
        "content": "Service endpoint shoud be \"Computer Vision analyze images\". Property should be \"imageType\"."
      },
      {
        "date": "2023-10-28T21:07:00.000Z",
        "voteCount": 5,
        "content": "Appeared on Oct/29/2023."
      },
      {
        "date": "2023-10-09T22:40:00.000Z",
        "voteCount": 2,
        "content": "I would say the answers are correct. Image type can only indicate whether an image is clip art or a line drawing. It can\u2019t tell you if it\u2019s a photograph or not - you can\u2019t just assume that if the image isn\u2019t a clip art or a line drawing will automatically be categorized as a photograph. It\u2019s a very sloppy solution IMO. Besides you have thousands of images and it\u2019s a good reason to create your own model."
      },
      {
        "date": "2024-05-31T18:41:00.000Z",
        "voteCount": 1,
        "content": "The example at https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/concept-detecting-image-types\n\nimplies that if the  \"imageType\": {\n        \"clipArtType\": 0,\n        \"lineDrawingType\": 0\n    },\nthen we have an image."
      },
      {
        "date": "2023-06-16T02:32:00.000Z",
        "voteCount": 5,
        "content": "To tag images as photographs, drawings, or clipart, you should use the following service endpoint and response property:\n\nService endpoint: Computer Vision image classification\nProperty: imageType\n\nThe Computer Vision image classification endpoint allows you to classify images into different categories, and the imageType property specifically provides information about the type of image, such as whether it is a photograph, drawing, or clipart."
      },
      {
        "date": "2023-05-08T07:37:00.000Z",
        "voteCount": 2,
        "content": "ChatGPT:\nYou can use the Microsoft Azure Computer Vision API to tag the images as photographs, drawings, or clipart.\n\nYou can call the \"Describe Image\" API endpoint and use the \"imageType\" property of the response to determine if the image is a photograph, a drawing, or clipart. The \"imageType\" property can have the following values:\n\n\"Clipart\": Indicates that the image is a clipart.\n\"LineDrawing\": Indicates that the image is a line drawing.\n\"Photograph\": Indicates that the image is a photograph.\nYou can send an HTTP POST request to the API endpoint with the image file as the request body and specify the \"imageType\" in the \"visualFeatures\" parameter. The API will return a JSON response containing the \"imageType\" property along with other properties such as \"tags\", \"description\", and \"categories\"."
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 23,
    "url": "https://www.examtopics.com/discussions/microsoft/view/102569-exam-ai-102-topic-2-question-23-discussion/",
    "body": "You have an app that captures live video of exam candidates.<br><br>You need to use the Face service to validate that the subjects of the videos are real people.<br><br>What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCall the face detection API and retrieve the face rectangle by using the FaceRectangle attribute.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCall the face detection API repeatedly and check for changes to the FaceAttributes.HeadPose attribute.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCall the face detection API and use the FaceLandmarks attribute to calculate the distance between pupils.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCall the face detection API repeatedly and check for changes to the FaceAttributes.Accessories attribute."
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 30,
        "isMostVoted": true
      },
      {
        "answer": "A",
        "count": 4,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2023-06-28T05:22:00.000Z",
        "voteCount": 18,
        "content": "B is the answer.\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/computer-vision/how-to/use-headpose#detect-head-gestures\nYou can detect head gestures like nodding and head shaking by tracking HeadPose changes in real time. You can use this feature as a custom liveness detector.\n\nLiveness detection is the task of determining that a subject is a real person and not an image or video representation. A head gesture detector could serve as one way to help verify liveness, especially as opposed to an image representation of a person."
      },
      {
        "date": "2023-11-12T04:49:00.000Z",
        "voteCount": 2,
        "content": "thanks for explanation"
      },
      {
        "date": "2024-06-22T00:14:00.000Z",
        "voteCount": 1,
        "content": "I say this answer is B. Please hurry up and transport the meat."
      },
      {
        "date": "2024-05-20T08:02:00.000Z",
        "voteCount": 2,
        "content": "FaceAttributes.HeadPose is used this solution."
      },
      {
        "date": "2024-04-11T17:50:00.000Z",
        "voteCount": 2,
        "content": "\"You need to use the Face service to validate that the subjects of the videos are real people.\" Never think too much into these questions. A can detect if it's real or not. Not asking anything else. It's A."
      },
      {
        "date": "2023-11-12T04:49:00.000Z",
        "voteCount": 1,
        "content": "https://learn.microsoft.com/en-us/azure/cognitive-services/computer-vision/how-to/use-headpose#detect-head-gestures"
      },
      {
        "date": "2023-10-10T11:49:00.000Z",
        "voteCount": 1,
        "content": "It can\u2019t be A. If you only try to detect the faces without tracking their position over time, the system can be easily fooled in this very specific scenario."
      },
      {
        "date": "2023-06-27T23:31:00.000Z",
        "voteCount": 2,
        "content": "Option A is more appropriate for validating the presence of real people in the live video. By calling the face detection API and retrieving the face rectangle using the FaceRectangle attribute, you can detect and locate faces within the video frames. This helps in confirming the presence of actual human faces in the captured video.\n\nOption B, on the other hand, suggests repeatedly calling the face detection API and checking for changes to the FaceAttributes.HeadPose attribute. While head pose analysis can provide information about the orientation of detected faces, it may not be the most reliable approach for validating the authenticity of the subjects as real people. Checking for changes in head pose alone may not be sufficient to differentiate between real people and other forms of visual representations."
      },
      {
        "date": "2023-06-11T06:47:00.000Z",
        "voteCount": 2,
        "content": "B: https://learn.microsoft.com/en-us/azure/cognitive-services/computer-vision/how-to/use-headpose#detect-head-gestures"
      },
      {
        "date": "2023-06-09T19:55:00.000Z",
        "voteCount": 1,
        "content": "B: https://learn.microsoft.com/en-us/azure/cognitive-services/computer-vision/how-to/use-headpose#detect-head-gestures"
      },
      {
        "date": "2023-05-05T21:12:00.000Z",
        "voteCount": 3,
        "content": "B https://learn.microsoft.com/en-us/azure/cognitive-services/computer-vision/how-to/use-headpose#detect-head-gestures\n\"Liveness detection is the task of determining that a subject is a real person and not an image or video representation\""
      },
      {
        "date": "2023-04-16T21:50:00.000Z",
        "voteCount": 3,
        "content": "The Answer is B. A could be a still picture"
      },
      {
        "date": "2023-03-14T04:17:00.000Z",
        "voteCount": 2,
        "content": "The answer is B\nDetect head gestures\nYou can detect head gestures like nodding and head shaking by tracking HeadPose changes in real time. You can use this feature as a custom liveness detector.\nReference https://learn.microsoft.com/en-us/azure/cognitive-services/computer-vision/how-to/use-headpose"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 24,
    "url": "https://www.examtopics.com/discussions/microsoft/view/102686-exam-ai-102-topic-2-question-24-discussion/",
    "body": "HOTSPOT<br> -<br><br>You make an API request and receive the results shown in the following exhibits. <br><br><img src=\"https://img.examtopics.com/ai-102/image5.png\"><br><br><img src=\"https://img.examtopics.com/ai-102/image6.png\"><br><br>Use the drop-down menus to select the answer choice that completes each statement based on the information presented in the graphic. <br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/ai-102/image7.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/ai-102/image8.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2023-07-01T00:17:00.000Z",
        "voteCount": 13,
        "content": "1. detects\n2. 797, 201\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/computer-vision/concept-face-detection#face-rectangle\nEach detected face corresponds to a faceRectangle field in the response. This is a set of pixel coordinates for the left, top, width, and height of the detected face. Using these coordinates, you can get the location and size of the face. In the API response, faces are listed in size order from largest to smallest.\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/computer-vision/concept-face-detection#attributes\n- QualityForRecognition\nThe overall image quality regarding whether the image being used in the detection is of sufficient quality to attempt face recognition on. The value is an informal rating of low, medium, or high. Only \"high\" quality images are recommended for person enrollment, and quality at or above \"medium\" is recommended for identification scenarios."
      },
      {
        "date": "2023-09-11T06:29:00.000Z",
        "voteCount": 6,
        "content": "To answer the first question see the endpoint .../face/v1.0/detect?....\nTo answer the second question see the first object from the response \"faceRectangle\": {\"TOP\":201, \"LEFT:\"797....}"
      },
      {
        "date": "2023-11-04T03:40:00.000Z",
        "voteCount": 1,
        "content": "exactly. Answer is correct"
      },
      {
        "date": "2024-05-28T08:19:00.000Z",
        "voteCount": 1,
        "content": "By feeling paizuri, you can see that the answers are \u2018detect\u2019 and \u2018797,201\u2019."
      },
      {
        "date": "2024-05-28T08:18:00.000Z",
        "voteCount": 1,
        "content": "By feeling the paisley, you can see that the answers are \u2018detect\u2019 and \u2018797,201\u2019."
      },
      {
        "date": "2024-05-20T07:59:00.000Z",
        "voteCount": 2,
        "content": "memorize. detects and 797, 201."
      },
      {
        "date": "2024-03-25T21:15:00.000Z",
        "voteCount": 1,
        "content": "Final Answer:\n1. detects\n2. 797, 201"
      },
      {
        "date": "2023-03-15T04:36:00.000Z",
        "voteCount": 4,
        "content": "The API detects faces.\n\nA face that can be used in person enrollment is at position 797, 201 within the photo.\n\nThis question provides information about an API request made to a face detection service. The request is sent to the endpoint \"https://facetesting.cognitiveservices.azure.com/face/v1.0/detect\" with the content of an image in the JSON format. The response from the API includes an array of detected faces, each with a unique faceId, faceRectangle, and faceAttributes.\n\nThe first statement asks what the API does with faces. The correct answer is \"detects\" because the endpoint used in the request is \"/detect,\" which implies that the API is used for face detection.\n\nThe second statement asks about the position of a face that can be used for person enrollment. The face's position is specified in the \"faceRectangle\" field of the JSON response. The correct answer is \"118, 754\" because that is the \"left\" and \"top\" position of the face rectangle for the fourth face in the response, which has a high enough quality for recognition to be used in person enrollment."
      },
      {
        "date": "2023-04-13T10:44:00.000Z",
        "voteCount": 1,
        "content": "\"118, 754\" has low quality, isn't it?"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 25,
    "url": "https://www.examtopics.com/discussions/microsoft/view/108276-exam-ai-102-topic-2-question-25-discussion/",
    "body": "You have an Azure subscription that contains an AI enrichment pipeline in Azure Cognitive Search and an Azure Storage account that has 10 GB of scanned documents and images.<br><br>You need to index the documents and images in the storage account. The solution must minimize how long it takes to build the index.<br><br>What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tFrom the Azure portal, configure parallel indexing.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tFrom the Azure portal, configure scheduled indexing.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure field mappings by using the REST API.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a text-based indexer by using the REST API."
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 14,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-06-28T05:18:00.000Z",
        "voteCount": 8,
        "content": "A is the answer.\n\nhttps://learn.microsoft.com/en-us/azure/search/search-howto-large-index#run-indexers-in-parallel\nIf you partition your data, you can create multiple indexer-data-source combinations that pull from each data source and write to the same search index. Because each indexer is distinct, you can run them at the same time, populating a search index more quickly than if you ran them sequentially."
      },
      {
        "date": "2023-11-04T03:43:00.000Z",
        "voteCount": 1,
        "content": "thanks for explanation"
      },
      {
        "date": "2024-05-29T08:52:00.000Z",
        "voteCount": 1,
        "content": "A is correct."
      },
      {
        "date": "2024-05-28T08:16:00.000Z",
        "voteCount": 1,
        "content": "The answer to this question is A."
      },
      {
        "date": "2024-05-20T07:54:00.000Z",
        "voteCount": 1,
        "content": "A is right answer."
      },
      {
        "date": "2023-11-04T03:43:00.000Z",
        "voteCount": 1,
        "content": "answer is correct"
      },
      {
        "date": "2023-06-16T06:55:00.000Z",
        "voteCount": 2,
        "content": "To minimize the time it takes to build the index for the documents and images in the Azure Storage account, the best approach would be to use parallel indexing.\nTherefore, the correct option is:\nA. From the Azure portal, configure parallel indexing.\n\nConfiguring parallel indexing allows you to process multiple documents or images simultaneously"
      },
      {
        "date": "2023-05-08T07:53:00.000Z",
        "voteCount": 1,
        "content": "https://learn.microsoft.com/en-us/azure/search/search-howto-large-index"
      },
      {
        "date": "2023-05-02T08:29:00.000Z",
        "voteCount": 1,
        "content": "seems logical"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 26,
    "url": "https://www.examtopics.com/discussions/microsoft/view/110625-exam-ai-102-topic-2-question-26-discussion/",
    "body": "DRAG DROP<br> -<br><br>You need to analyze video content to identify any mentions of specific company names.<br><br>Which three actions should you perform in sequence? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.<br><br><img src=\"https://img.examtopics.com/ai-102/image26.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/ai-102/image27.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2023-07-01T00:11:00.000Z",
        "voteCount": 26,
        "content": "1. Sign in to Azure Video Analyzer for Media website\n2. From Content model customization, select Brands\n3. Add specific company names to include list\n\nhttps://learn.microsoft.com/en-us/azure/azure-video-indexer/customize-brands-model-with-website"
      },
      {
        "date": "2023-07-07T18:03:00.000Z",
        "voteCount": 8,
        "content": "Gotten this in Jul 2023 exam."
      },
      {
        "date": "2024-07-16T03:10:00.000Z",
        "voteCount": 1,
        "content": "1. Sign in to Azure Video Analyzer for Media website\n2. From Content model customization, select Brands\n3. Add specific company names to include list"
      },
      {
        "date": "2024-05-28T08:07:00.000Z",
        "voteCount": 3,
        "content": "1. Sign in website ,analyzer\n2. From Brands\n3. Add include list"
      },
      {
        "date": "2024-05-20T07:47:00.000Z",
        "voteCount": 2,
        "content": "Sign in website, From Brands, Add include list.\nI memorized this line."
      },
      {
        "date": "2024-02-16T15:43:00.000Z",
        "voteCount": 3,
        "content": "login to azure video analyzer==&gt;select brands tab to customize the analyzer==&gt;add specific company names to the \"include\" list"
      },
      {
        "date": "2024-01-19T04:10:00.000Z",
        "voteCount": 1,
        "content": "Now it's call \"Azure AI Video Indexer website \""
      },
      {
        "date": "2023-11-04T03:47:00.000Z",
        "voteCount": 2,
        "content": "correct answer"
      },
      {
        "date": "2023-05-31T01:52:00.000Z",
        "voteCount": 3,
        "content": "ChatGPT agree: \nAnswer Area:\n\n    Sign in to the Azure Video Analyzer for Media website.\n    From Content model customization, select Brands.\n    Add the specific company names to the include list."
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 27,
    "url": "https://www.examtopics.com/discussions/microsoft/view/108600-exam-ai-102-topic-2-question-27-discussion/",
    "body": "You have a mobile app that manages printed forms.<br><br>You need the app to send images of the forms directly to Forms Recognizer to extract relevant information. For compliance reasons, the image files must not be stored in the cloud.<br><br>In which format should you send the images to the Form Recognizer API endpoint?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\traw image binary\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tform URL encoded",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tJSON"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 18,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-11-04T03:59:00.000Z",
        "voteCount": 7,
        "content": "To send images to the Form Recognizer API endpoint without storing them in the cloud, you should send the images in the following format:\n\nA. raw image binary\n\nSending the images as raw image binary data allows you to transmit the image directly to the Form Recognizer API without the need to store them in the cloud or convert them into other formats. This format ensures compliance with your requirements. (ChatGPT)"
      },
      {
        "date": "2023-10-28T21:04:00.000Z",
        "voteCount": 5,
        "content": "Appeared on Oct/29/2023"
      },
      {
        "date": "2024-05-28T08:15:00.000Z",
        "voteCount": 1,
        "content": "The answer to this question is A."
      },
      {
        "date": "2024-05-25T05:54:00.000Z",
        "voteCount": 1,
        "content": "A is right."
      },
      {
        "date": "2024-05-20T07:53:00.000Z",
        "voteCount": 1,
        "content": "A is right answer."
      },
      {
        "date": "2023-12-29T10:47:00.000Z",
        "voteCount": 2,
        "content": "its correct"
      },
      {
        "date": "2023-08-31T10:36:00.000Z",
        "voteCount": 3,
        "content": "A. raw image binary\nhttps://westus.dev.cognitive.microsoft.com/docs/services/form-recognizer-api-v2-1/operations/AnalyzeReceiptAsync\nRequest body: Document containing the receipt image(s) to be analyzed. The POST body should be the raw image binary, or the image URL in JSON.\n\nhttps://ittichaicham.com/2020/03/call-azure-form-recognizer-api-on-sharepoint-document-image-url-in-power-automate/\nPower Automate (formerly Microsoft Flow) can call Azure Form Recognizer via the connector. Since Power Automate is a cloud solution, the natural choice is to use the image URL. This should work fine if the URL is accessible to the public or requires no authentication. Unfortunately, the company\u2019s SharePoint URL, most of the time, is not.\nTo solve this, we can add another flow step to move the SharePoint file to where it is accessible, or, better, instead of using file URL, we can pass binary content in the Form Recognizer API."
      },
      {
        "date": "2023-06-28T05:13:00.000Z",
        "voteCount": 3,
        "content": "A is the answer.\n\nhttps://learn.microsoft.com/en-us/azure/applied-ai-services/form-recognizer/faq?view=form-recog-3.0.0#does-form-recognizer-store-my-data-\nFor all features, Form Recognizer temporarily stores data and results in Azure storage in the same region as the request. Your data is then deleted within 24 hours from the time an analyze request was submitted."
      },
      {
        "date": "2023-11-04T03:59:00.000Z",
        "voteCount": 2,
        "content": "thanks for the provided document"
      },
      {
        "date": "2023-06-05T02:09:00.000Z",
        "voteCount": 1,
        "content": "Should be A. When you send images to the endpoint, the images don't get stored anywhere."
      },
      {
        "date": "2023-05-15T00:06:00.000Z",
        "voteCount": 3,
        "content": "chat gpt \"To send images directly to Forms Recognizer and extract relevant information without storing the image files in the cloud, you should use the raw image binary format.\""
      },
      {
        "date": "2023-05-05T21:29:00.000Z",
        "voteCount": 1,
        "content": "Looks like URL (not sure about the \"encoded\" part though!)\nhttps://learn.microsoft.com/en-us/azure/applied-ai-services/form-recognizer/v3-migration-guide?view=form-recog-3.0.0#analyze-request-body"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 28,
    "url": "https://www.examtopics.com/discussions/microsoft/view/107293-exam-ai-102-topic-2-question-28-discussion/",
    "body": "You plan to build an app that will generate a list of tags for uploaded images. The app must meet the following requirements:<br><br>\u2022\tGenerate tags in a user's preferred language.<br>\u2022\tSupport English, French, and Spanish.<br>\u2022\tMinimize development effort.<br><br>You need to build a function that will generate the tags for the app.<br><br>Which Azure service endpoint should you use?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tContent Moderator Image Moderation",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCustom Vision image classification",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tComputer Vision Image Analysis\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCustom Translator"
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 33,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-04-24T04:20:00.000Z",
        "voteCount": 17,
        "content": "I think the answer should be C, because of the minimized developement effort. Since the prebuilt model of C also fits the other two requirements, so there is no need to train a custom model.\n\nsource: https://learn.microsoft.com/en-us/azure/cognitive-services/computer-vision/how-to/call-analyze-image?tabs=rest"
      },
      {
        "date": "2023-11-04T04:02:00.000Z",
        "voteCount": 2,
        "content": "agree with you"
      },
      {
        "date": "2024-01-26T18:03:00.000Z",
        "voteCount": 6,
        "content": "Here's why:\n\nMultilingual Tag Generation: Azure's Computer Vision Image Analysis service can analyze images and provide a list of tags describing the content of the images. It also has the capability to return these tags in various languages, including English, French, and Spanish, which aligns with your requirement.\n\nMinimizing Development Effort: This service offers a pre-built model, which means there is no need for you to collect data and train your own model. This significantly reduces the development effort and time. You simply need to call the API with your images, and it will return the tags."
      },
      {
        "date": "2024-06-22T04:51:00.000Z",
        "voteCount": 1,
        "content": "C is the answer."
      },
      {
        "date": "2024-06-22T00:13:00.000Z",
        "voteCount": 1,
        "content": "Why C?"
      },
      {
        "date": "2024-05-29T08:52:00.000Z",
        "voteCount": 1,
        "content": "C is correct."
      },
      {
        "date": "2024-05-25T05:57:00.000Z",
        "voteCount": 1,
        "content": "C is right."
      },
      {
        "date": "2024-05-20T07:58:00.000Z",
        "voteCount": 1,
        "content": "C. Computer Vision Image Analysis"
      },
      {
        "date": "2024-02-16T15:45:00.000Z",
        "voteCount": 3,
        "content": "generate tags as per image is an Image Analysis operation rather than an image classification operation"
      },
      {
        "date": "2023-12-29T10:49:00.000Z",
        "voteCount": 2,
        "content": "Verified with google bard"
      },
      {
        "date": "2024-02-03T22:58:00.000Z",
        "voteCount": 1,
        "content": "C, verified with Copilot too"
      },
      {
        "date": "2023-12-25T02:31:00.000Z",
        "voteCount": 2,
        "content": "Selected Answer: B \nFrench is not supported by computer vision"
      },
      {
        "date": "2024-03-06T23:10:00.000Z",
        "voteCount": 1,
        "content": "French is supported, I just tested it in Azure. See also this link (the table 'Analyze image':\nhttps://learn.microsoft.com/en-us/azure/ai-services/computer-vision/language-support#image-analysis"
      },
      {
        "date": "2024-01-19T04:18:00.000Z",
        "voteCount": 1,
        "content": "True.\n\nURL parameter\tValue\tDescription\nlanguage\ten\tEnglish\nlanguage\tes\tSpanish\nlanguage\tja\tJapanese\nlanguage\tpt\tPortuguese\nlanguage\tzh\tSimplified Chinese\n\nSource: https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/call-analyze-image?tabs=rest"
      },
      {
        "date": "2023-11-04T04:02:00.000Z",
        "voteCount": 1,
        "content": "C to minimize the effort:\nhttps://learn.microsoft.com/en-us/azure/ai-services/computer-vision/overview-image-analysis?tabs=4-0"
      },
      {
        "date": "2023-06-28T05:05:00.000Z",
        "voteCount": 3,
        "content": "C is the answer.\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/computer-vision/concept-tagging-images\nImage Analysis can return content tags for thousands of recognizable objects, living beings, scenery, and actions that appear in images. Tags are not organized as a taxonomy and do not have inheritance hierarchies. A collection of content tags forms the foundation for an image description displayed as human readable language formatted in complete sentences. When tags are ambiguous or not common knowledge, the API response provides hints to clarify the meaning of the tag in context of a known setting."
      },
      {
        "date": "2023-06-28T05:07:00.000Z",
        "voteCount": 4,
        "content": "https://learn.microsoft.com/en-us/azure/cognitive-services/computer-vision/language-support#image-analysis\nSome features of the Analyze - Image API can return results in other languages, specified with the language query parameter. Other actions return results in English regardless of what language is specified, and others throw an exception for unsupported languages. Actions are specified with the visualFeatures and details query parameters; see the Overview for a list of all the actions you can do with image analysis. Languages for tagging are only available in API version 3.2 or later."
      },
      {
        "date": "2023-11-12T06:00:00.000Z",
        "voteCount": 1,
        "content": "thanks for explanation"
      },
      {
        "date": "2023-06-27T16:24:00.000Z",
        "voteCount": 4,
        "content": "Asked in 28/06/2023 exam"
      },
      {
        "date": "2023-06-08T17:19:00.000Z",
        "voteCount": 1,
        "content": "C: https://learn.microsoft.com/en-us/azure/cognitive-services/computer-vision/concept-tagging-images"
      },
      {
        "date": "2023-05-15T00:08:00.000Z",
        "voteCount": 1,
        "content": "chat gpt \"To generate a list of tags for uploaded images in multiple languages, you should use the Computer Vision Image Analysis service endpoint in Azure.\n\nComputer Vision provides a pre-built model that can generate image tags based on a given image. It also supports multiple languages, including English, French, and Spanish, which meets the requirements of the app. Additionally, the service provides a REST API, which can be easily integrated into your app without requiring significant development effort.\""
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 29,
    "url": "https://www.examtopics.com/discussions/microsoft/view/108601-exam-ai-102-topic-2-question-29-discussion/",
    "body": "HOTSPOT<br> -<br><br>You develop a test method to verify the results retrieved from a call to the Computer Vision API. The call is used to analyze the existence of company logos in images. The call returns a collection of brands named brands.<br><br>You have the following code segment.<br><br><img src=\"https://img.examtopics.com/ai-102/image28.png\"><br><br>For each of the following statements, select Yes if the statement is true. Otherwise, select No.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/ai-102/image29.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/ai-102/image30.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2023-07-01T00:05:00.000Z",
        "voteCount": 12,
        "content": "YYN is the answer.\n\nhttps://learn.microsoft.com/en-us/rest/api/computervision/3.1/detect-objects/detect-objects?tabs=HTTP#boundingrect\nA bounding box for an area inside an image.\n- x\nX-coordinate of the top left point of the area, in pixels.\n- y\nY-coordinate of the top left point of the area, in pixels.\n- h\nHeight measured from the top-left point of the area, in pixels.\n- w\nWidth measured from the top-left point of the area, in pixels."
      },
      {
        "date": "2024-07-15T11:27:00.000Z",
        "voteCount": 1,
        "content": "YYN is the answer."
      },
      {
        "date": "2024-05-28T08:15:00.000Z",
        "voteCount": 1,
        "content": "The answer is YYN."
      },
      {
        "date": "2024-05-20T07:52:00.000Z",
        "voteCount": 1,
        "content": "Yes Yes No"
      },
      {
        "date": "2024-01-26T18:05:00.000Z",
        "voteCount": 2,
        "content": "answer is correct: Y Y N\nresponse only display the top left corner and width and height from this origin"
      },
      {
        "date": "2023-11-04T04:05:00.000Z",
        "voteCount": 3,
        "content": "YYN: correct answer and duplicated question"
      },
      {
        "date": "2023-09-12T15:36:00.000Z",
        "voteCount": 1,
        "content": "YYY - the last one is Y because all coordinates together give you top left and bottom right."
      },
      {
        "date": "2023-09-21T01:02:00.000Z",
        "voteCount": 3,
        "content": "YYN. not the bottom right"
      },
      {
        "date": "2023-11-04T04:05:00.000Z",
        "voteCount": 1,
        "content": "no, you can calculate the bottom right corner coordinates but they aren't displyed in the code provided"
      },
      {
        "date": "2023-09-11T22:16:00.000Z",
        "voteCount": 1,
        "content": "Answer is correct"
      },
      {
        "date": "2023-07-01T00:43:00.000Z",
        "voteCount": 4,
        "content": "Same as Question 14.\nhttps://www.examtopics.com/discussions/microsoft/view/55050-exam-ai-102-topic-2-question-14-discussion"
      },
      {
        "date": "2023-05-05T21:51:00.000Z",
        "voteCount": 1,
        "content": "Correct YYN. The last one is width and height."
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 30,
    "url": "https://www.examtopics.com/discussions/microsoft/view/108602-exam-ai-102-topic-2-question-30-discussion/",
    "body": "DRAG DROP<br> -<br><br>You have a factory that produces cardboard packaging for food products. The factory has intermittent internet connectivity.<br><br>The packages are required to include four samples of each product.<br><br>You need to build a Custom Vision model that will identify defects in packaging and provide the location of the defects to an operator. The model must ensure that each package contains the four products.<br><br>Which project type and domain should you use? To answer, drag the appropriate options to the correct targets. Each option may be used once, more than once, or not at all. You may need to drag the split bar between panes or scroll to view content.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/ai-102/image31.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/ai-102/image32.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2023-06-30T23:55:00.000Z",
        "voteCount": 21,
        "content": "1. Object detection\n2. General (compact)\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/get-started-build-detector\n- Select Object Detection under Project Types.\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/select-domain#compact-domains\nThe models generated by compact domains can be exported to run locally."
      },
      {
        "date": "2023-07-20T22:35:00.000Z",
        "voteCount": 3,
        "content": "1. I was about to say Classification, but they say \"and provide the location of the defects\" so it is definitively Object Detection.\n2. General (compact)"
      },
      {
        "date": "2023-11-04T04:09:00.000Z",
        "voteCount": 2,
        "content": "agree with you"
      },
      {
        "date": "2023-06-25T03:26:00.000Z",
        "voteCount": 7,
        "content": "This was on my exam"
      },
      {
        "date": "2024-09-17T02:15:00.000Z",
        "voteCount": 1,
        "content": "project - object detection because it needs to detect errors.\nDomain - compact as it needs to be run on a container offline"
      },
      {
        "date": "2024-07-15T11:28:00.000Z",
        "voteCount": 1,
        "content": "1. Object detection\n2. General (compact)"
      },
      {
        "date": "2024-06-21T08:55:00.000Z",
        "voteCount": 1,
        "content": "1. Object detection\n2. General(compact)"
      },
      {
        "date": "2024-05-28T08:13:00.000Z",
        "voteCount": 1,
        "content": "This answer is as follows.\n1. Object detection\n2. General (compact)"
      },
      {
        "date": "2024-05-25T05:42:00.000Z",
        "voteCount": 1,
        "content": "1. Object detection\n2. General(compact)"
      },
      {
        "date": "2024-05-20T07:51:00.000Z",
        "voteCount": 1,
        "content": "Project type is Object detection. Domain is General(compact)."
      },
      {
        "date": "2024-02-16T15:46:00.000Z",
        "voteCount": 2,
        "content": "lcoally==&gt;mean general(compact)\ndetect =&gt;object detection"
      },
      {
        "date": "2024-01-26T18:07:00.000Z",
        "voteCount": 4,
        "content": "The factory has intermittent internet connectivity:====&gt; this merans an edge deployment of the model without internet connectivity is needed and then edge model using General(compact) domain suits the demands"
      },
      {
        "date": "2023-09-11T22:19:00.000Z",
        "voteCount": 1,
        "content": "The answer is correct!"
      },
      {
        "date": "2023-06-27T16:25:00.000Z",
        "voteCount": 5,
        "content": "Asked in 28/06/2023 exam"
      },
      {
        "date": "2023-05-05T21:55:00.000Z",
        "voteCount": 3,
        "content": "Correct - https://learn.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/select-domain#compact-domains"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 31,
    "url": "https://www.examtopics.com/discussions/microsoft/view/112135-exam-ai-102-topic-2-question-31-discussion/",
    "body": "HOTSPOT<br> -<br><br>You are building a model to detect objects in images.<br><br>The performance of the model based on training data is shown in the following exhibit.<br><br><img src=\"https://img.examtopics.com/ai-102/image49.png\"><br><br>Use the drop-down menus to select the answer choice that completes each statement based on the information presented in the graphic.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/ai-102/image50.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/ai-102/image51.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2023-06-30T23:47:00.000Z",
        "voteCount": 20,
        "content": "1. 0\n2. 25\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/language-service/custom-text-classification/concepts/evaluation-metrics\n\n- Precision: Measures how precise/accurate your model is. It's the ratio between the correctly identified positives (true positives) and all identified positives. The precision metric reveals how many of the predicted classes are correctly labeled.\nPrecision = #True_Positive / (#True_Positive + #False_Positive)\n\n- Recall: Measures the model's ability to predict actual positive classes. It's the ratio between the predicted true positives and what was actually tagged. The recall metric reveals how many of the predicted classes are correct.\nRecall = #True_Positive / (#True_Positive + #False_Negatives)"
      },
      {
        "date": "2023-11-04T04:24:00.000Z",
        "voteCount": 2,
        "content": "thanks for explanation"
      },
      {
        "date": "2023-06-27T16:26:00.000Z",
        "voteCount": 5,
        "content": "Asked in 28/06/2023 exam"
      },
      {
        "date": "2024-10-14T04:33:00.000Z",
        "voteCount": 1,
        "content": "got this in Oct 2024 exam"
      },
      {
        "date": "2024-09-17T02:16:00.000Z",
        "voteCount": 1,
        "content": "0 &amp; 25"
      },
      {
        "date": "2024-06-06T06:33:00.000Z",
        "voteCount": 1,
        "content": "1. 0\n2. 25"
      },
      {
        "date": "2024-05-25T05:34:00.000Z",
        "voteCount": 1,
        "content": "1. 0\n2. 25"
      },
      {
        "date": "2023-06-15T23:08:00.000Z",
        "voteCount": 1,
        "content": "The answer is correct. \nSee https://learn.microsoft.com/en-us/azure/cognitive-services/Custom-Vision-Service/get-started-build-detector"
      },
      {
        "date": "2023-06-14T00:54:00.000Z",
        "voteCount": 1,
        "content": "It is true.\n#1:Precision = 100%\n#2:recall = 25%"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 32,
    "url": "https://www.examtopics.com/discussions/microsoft/view/122477-exam-ai-102-topic-2-question-32-discussion/",
    "body": "You are building an app that will include one million scanned magazine articles. Each article will be stored as an image file.<br><br>You need to configure the app to extract text from the images. The solution must minimize development effort.<br><br>What should you include in the solution?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tComputer Vision Image Analysis",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tthe Read API in Computer Vision\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tForm Recognizer",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure Cognitive Service for Language"
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 21,
        "isMostVoted": true
      },
      {
        "answer": "C",
        "count": 3,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2023-11-04T04:32:00.000Z",
        "voteCount": 10,
        "content": "To me the correct answer is B. With the new Image Analysis API 4.0 (in preview) you could use OCR feature too, but as i said, it is in preview. And i don't think it is considered in the exam. \n\nhttps://learn.microsoft.com/en-us/azure/ai-services/computer-vision/overview-image-analysis?tabs=4-0\n\nInstead the Read API is particularly adapted for text-heavy documents and it seems this is the case\n\nhttps://learn.microsoft.com/en-us/rest/api/computervision/read/read?view=rest-computervision-v3.1&amp;tabs=HTTP"
      },
      {
        "date": "2023-10-04T18:28:00.000Z",
        "voteCount": 8,
        "content": "All answers should have a reference to prove the answer is true"
      },
      {
        "date": "2024-09-25T20:46:00.000Z",
        "voteCount": 1,
        "content": "Answer is C\nForm Recognizer\n\nThere is note in below microsoft doc mentioning about document images for text extraction\n\nOCR for images (version 4.0)\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/computer-vision/concept-ocr\n\nPlease refer important section to Select the Read edition that best fits your requirements.\nhttps://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/call-read-api"
      },
      {
        "date": "2024-09-17T02:20:00.000Z",
        "voteCount": 1,
        "content": "Azure AI Document Intelligence is a more sophisticated solution. For example, it can identify key/value pairs, tables, and context-specific fields. If you want to deploy a complete document analysis solution for both extracting AND understanding text, Azure AI Document Intelligence is a good solution. In this case, Document Intelligence is a too advanced solution as the question doesn't provide any information about what to do with the extracted text, the focus here is on text extraction alone. So the answer is B"
      },
      {
        "date": "2024-09-17T02:20:00.000Z",
        "voteCount": 1,
        "content": "so answer is B"
      },
      {
        "date": "2024-07-15T06:07:00.000Z",
        "voteCount": 2,
        "content": "A. Computer vision does not have read model. Read model is document intelligence (formregnize) model"
      },
      {
        "date": "2024-07-12T08:24:00.000Z",
        "voteCount": 1,
        "content": "Selected Answer: B"
      },
      {
        "date": "2024-06-22T00:12:00.000Z",
        "voteCount": 1,
        "content": "see if you can spot this one B."
      },
      {
        "date": "2024-06-16T05:15:00.000Z",
        "voteCount": 2,
        "content": "This is a good explanation from chat GPT why B is the correct fit and A is not:\n\nA - Computer Vision Image Analysis: This is a service provided by Azure that can extract a wide variety of visual features from your images. It can determine whether an image contains adult content, find specific brands or objects, or find human faces. However, while it does have OCR capabilities, it is not specifically designed for large-scale text extraction from images.\n\nB - Read API in Computer Vision: This is a part of the Azure Computer Vision service that is designed to extract printed and handwritten text from images. It uses state-of-the-art Optical Character Recognition (OCR) algorithms optimized for text-heavy documents2. This could be a good fit for your needs as it is designed to handle large amounts of text in images.\n\nthe key here is  option A it is not specifically designed for large-scale text extraction from images."
      },
      {
        "date": "2024-05-25T05:33:00.000Z",
        "voteCount": 2,
        "content": "the Read API in Computer Vision is right."
      },
      {
        "date": "2024-04-19T03:16:00.000Z",
        "voteCount": 1,
        "content": "Concordo com o @jangotango sobre as refer\u00eancias. Tem que evidenciar."
      },
      {
        "date": "2024-04-07T08:24:00.000Z",
        "voteCount": 2,
        "content": "Read API is particularly adapted for text-heavy documents and it seems this is the case"
      },
      {
        "date": "2024-03-24T00:42:00.000Z",
        "voteCount": 3,
        "content": "Document Intelligence(Previously Form Recognizer) reads small to large volume of text from images and PDF documents. For example: receipts, articles, and invoices"
      },
      {
        "date": "2024-03-26T20:40:00.000Z",
        "voteCount": 1,
        "content": "No I don't think so. Azure AI Document Intelligence is a more sophisticated solution. For example, it can identify key/value pairs, tables, and context-specific fields. If you want to deploy a complete document analysis solution for both extracting AND understanding text, Azure AI Document Intelligence is a good solution. In this case, Document Intelligence is a too advanced solution as the question doesn't provide any information about what to do with the extracted text, the focus here is on text extraction alone. So the answer is B."
      },
      {
        "date": "2023-10-28T16:58:00.000Z",
        "voteCount": 2,
        "content": "i think it should be B \nbased on ChatGpt \nusing Azure Read API if:\n\nYour primary focus is on text extraction from documents, forms, or images with printed text.\nYou have a batch processing requirement, and you need to process a large number of documents or images at once.\nYou need highly accurate text extraction with structured output."
      },
      {
        "date": "2023-10-05T23:27:00.000Z",
        "voteCount": 5,
        "content": "i also think its B\n\nUse this interface to get the result of a Read operation, employing the state-of-the-art Optical Character Recognition (OCR) algorithms optimized for text-heavy documents.\n\nhttps://learn.microsoft.com/en-us/rest/api/computervision/3.2preview2/read/read?tabs=HTTP"
      },
      {
        "date": "2023-10-04T18:25:00.000Z",
        "voteCount": 1,
        "content": "Why not B?"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 33,
    "url": "https://www.examtopics.com/discussions/microsoft/view/122636-exam-ai-102-topic-2-question-33-discussion/",
    "body": "You have a 20-GB video file named File1.avi that is stored on a local drive.<br><br>You need to index File1.avi by using the Azure Video Indexer website.<br><br>What should you do first?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUpload File1.avi to an Azure Storage queue.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUpload File1.avi to the Azure Video Indexer website.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUpload File1.avi to Microsoft OneDrive.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUpload File1.avi to the www.youtube.com webpage."
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 25,
        "isMostVoted": true
      },
      {
        "answer": "B",
        "count": 6,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2023-10-06T00:03:00.000Z",
        "voteCount": 18,
        "content": "This question is part of free assessment given by Microsoft and the answer in that was C."
      },
      {
        "date": "2024-04-13T03:30:00.000Z",
        "voteCount": 1,
        "content": "I saw it there too :)"
      },
      {
        "date": "2023-10-06T08:47:00.000Z",
        "voteCount": 2,
        "content": "because that is the correct option"
      },
      {
        "date": "2024-10-14T04:34:00.000Z",
        "voteCount": 2,
        "content": "got this in Oct 2024 exam"
      },
      {
        "date": "2024-10-17T01:27:00.000Z",
        "voteCount": 1,
        "content": "did you get any labs/simulations?"
      },
      {
        "date": "2024-09-17T02:22:00.000Z",
        "voteCount": 2,
        "content": "max size for direct upload is 2GB so tou have to have it uploaded somewhere else."
      },
      {
        "date": "2024-09-12T19:44:00.000Z",
        "voteCount": 1,
        "content": "ChatGPT says, \"The correct option is B. Upload File1.avi to the Azure Video Indexer website. This is the appropriate first step to index your video file using Azure Video Indexer.\""
      },
      {
        "date": "2024-08-30T08:15:00.000Z",
        "voteCount": 1,
        "content": "Answer C: For large files, Azure Video Indexer supports uploading through a linked storage service like OneDrive."
      },
      {
        "date": "2024-06-22T00:12:00.000Z",
        "voteCount": 1,
        "content": "see if you can spot this one C."
      },
      {
        "date": "2024-05-25T05:31:00.000Z",
        "voteCount": 1,
        "content": "C is right answer."
      },
      {
        "date": "2024-05-20T01:57:00.000Z",
        "voteCount": 4,
        "content": "Max file size for direct upload is 2 GB . 30 GB is through url.so answer C"
      },
      {
        "date": "2024-04-26T15:34:00.000Z",
        "voteCount": 1,
        "content": "B. Upload File1.avi to the Azure Video Indexer website.\n\nExplanation:\n\nThe Azure Video Indexer website is specifically designed to analyze and index video files, extracting insights such as keywords, faces, sentiments, and more.\nUploading File1.avi directly to the Azure Video Indexer website allows the platform to process the video file and generate the necessary metadata and insights.\nOptions A, C, and D are not relevant for indexing File1.avi using the Azure Video Indexer website. Uploading to Azure Storage queue (option A) is not appropriate for indexing videos. Microsoft OneDrive (option C) is a cloud storage service and doesn't provide video indexing capabilities like the Azure Video Indexer. Uploading to YouTube (option D) is also not relevant as the task is to index the video using the Azure Video Indexer website. Therefore, option B is the correct choice."
      },
      {
        "date": "2024-04-13T03:30:00.000Z",
        "voteCount": 1,
        "content": "Yep, uploading to OneDrive and creating a download link (if I recall) was the answer on the MS free assessment."
      },
      {
        "date": "2024-04-07T08:26:00.000Z",
        "voteCount": 2,
        "content": "C is correct"
      },
      {
        "date": "2024-03-26T20:48:00.000Z",
        "voteCount": 4,
        "content": "Upload file size and video duration\nIf uploading a file from your device, the file size limit is 2 GB.\nIf the video is uploaded from a URL, the file size limit is 30 GB. The URL must lead to an online media file with a media file extension (for example myvideo.MP4) and not a webpage such as https://www.youtube.com.\n\nThe file duration limit is 4 hours.\n\nhttps://learn.microsoft.com/en-us/azure/azure-video-indexer/avi-support-matrix"
      },
      {
        "date": "2024-03-26T00:56:00.000Z",
        "voteCount": 1,
        "content": "Final Answer:\nC"
      },
      {
        "date": "2024-02-19T16:52:00.000Z",
        "voteCount": 2,
        "content": "Looks like C is correct due to the large size of the file being 20GB in the question.  See article here: https://learn.microsoft.com/en-us/azure/azure-video-indexer/odrv-download"
      },
      {
        "date": "2024-02-16T15:51:00.000Z",
        "voteCount": 1,
        "content": "B is correct and B"
      },
      {
        "date": "2024-01-25T06:23:00.000Z",
        "voteCount": 2,
        "content": "C: There is a max byte array of 2gb when uploading direct to the indexer so it has to be via a url"
      },
      {
        "date": "2023-12-09T07:41:00.000Z",
        "voteCount": 1,
        "content": "https://learn.microsoft.com/en-us/azure/azure-video-indexer/considerations-when-use-at-scale"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 34,
    "url": "https://www.examtopics.com/discussions/microsoft/view/134929-exam-ai-102-topic-2-question-34-discussion/",
    "body": "HOTSPOT<br> -<br><br>You are building an app that will share user images.<br><br>You need to configure the app to meet the following requirements:<br><br>\u2022\tUploaded images must be scanned and any text must be extracted from the images.<br>\u2022\tExtracted text must be analyzed for the presence of profane language.<br>\u2022\tThe solution must minimize development effort.<br><br>What should you use for each requirement? To answer, select the appropriate options in the answer area.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/ai-102/image95.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/ai-102/image96.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-03-29T14:02:00.000Z",
        "voteCount": 8,
        "content": "Text Extraction from Images: You can use an Optical Character Recognition (OCR) service to scan and extract text from the uploaded images. Computer Vision API are examples of services that provide OCR capabilities.\nProfanity Check: Once the text is extracted, you can use a text analytics service to analyze the presence of profane language. Services Content Moderator API can help identify and filter out inappropriate content."
      },
      {
        "date": "2024-10-13T18:55:00.000Z",
        "voteCount": 1,
        "content": "Agree with this answer. Take a look at this small blurb on this portion of the Microsoft docs:\nhttps://learn.microsoft.com/en-us/azure/ai-services/computer-vision/concept-ocr?view=doc-intel-4.0.0\n\"If you want to extract text from PDFs, Office files, or HTML documents and document images, use the Document Intelligence Read OCR model. It's optimized for text-heavy digital and scanned documents...\"\nThere's nowhere in this question that states these images will be \"document images\". Despite the fact that document intelligence CAN accept images, I've received no indication that we should assume these images will be documents."
      },
      {
        "date": "2024-08-01T20:29:00.000Z",
        "voteCount": 3,
        "content": "Text extraction: Azure AI Document Intelligence\nProfane language detection: Content Moderator (now Azure AI Content Safety)"
      },
      {
        "date": "2024-06-22T23:30:00.000Z",
        "voteCount": 2,
        "content": "Azure AI Computer Vision has ReadApi for OCR feature to extract text from images, and content moderator for removing anything profane"
      },
      {
        "date": "2024-06-22T23:32:00.000Z",
        "voteCount": 1,
        "content": "Azure AI Document Intelligence (formerly Form Recognizer):\nPurpose: Specialized document analysis.\nCapabilities:\nAdvanced OCR to extract text, key-value pairs, and table data from documents.\nCustomizable models to extract structured data from forms and invoices.\nTailored for processing documents such as forms, receipts, invoices, business cards, and other structured documents.\nHere we are dealing with scanned images"
      },
      {
        "date": "2024-06-08T14:59:00.000Z",
        "voteCount": 4,
        "content": "Azure AI vision for me. Both Document Intelligence and AI vision have OCR, but document inte is more for structure and semi-structure files, like pdf doc, w-2, forms, etc. AI vision is easier to extract simple text from general images."
      },
      {
        "date": "2024-06-06T06:33:00.000Z",
        "voteCount": 1,
        "content": "1. Azure AI Document Intelligence\n2. Content Moderator"
      },
      {
        "date": "2024-07-08T10:43:00.000Z",
        "voteCount": 1,
        "content": "We're looking at Images, not documents. And if the images contained documents, we don't know that from the question. Answer is correct"
      },
      {
        "date": "2024-09-17T02:26:00.000Z",
        "voteCount": 1,
        "content": "agree, they have not said if the images will be images of documents or not. it could be images of anything that we need to extract from"
      },
      {
        "date": "2024-05-25T05:31:00.000Z",
        "voteCount": 1,
        "content": "1. Azure AI Document Intelligence\n2. Content Moderator"
      },
      {
        "date": "2024-05-24T03:35:00.000Z",
        "voteCount": 1,
        "content": "on exam but with AI Content Safety instead of content moderator. For the first, I chose Azure AI Document Intelligence"
      },
      {
        "date": "2024-04-29T09:21:00.000Z",
        "voteCount": 2,
        "content": "Why not Azure AI Document Intelligence for the first option?"
      },
      {
        "date": "2024-04-29T09:24:00.000Z",
        "voteCount": 1,
        "content": "Should be Azure AI Document Intelligence. Document Intelligence Read Optical Character Recognition (OCR) model runs at a higher resolution than Azure AI Vision Read and extracts print and handwritten text from PDF documents and scanned images.\nhttps://learn.microsoft.com/en-us/answers/questions/1512283/vision-studio-vs-document-intelligence-studio-ocr"
      },
      {
        "date": "2024-02-29T10:27:00.000Z",
        "voteCount": 4,
        "content": "I hope the Questions are revisited by Microsoft. Why would there be a question on deprecated services\nhttps://learn.microsoft.com/en-us/azure/ai-services/content-moderator/overview\nAzure Content Moderator is being deprecated in February 2024, and will be retired by February 2027. It is being replaced by Azure AI Content Safety, which offers advanced AI features and enhanced performance."
      },
      {
        "date": "2024-03-13T00:43:00.000Z",
        "voteCount": 5,
        "content": "I agree, insert profanity here to show my frustration! AND YOU CAN USE AI Content Safety to detect it :D"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 35,
    "url": "https://www.examtopics.com/discussions/microsoft/view/134935-exam-ai-102-topic-2-question-35-discussion/",
    "body": "You are building an app that will share user images.<br><br>You need to configure the app to perform the following actions when a user uploads an image:<br><br>\u2022\tCategorize the image as either a photograph or a drawing.<br>\u2022\tGenerate a caption for the image.<br><br>The solution must minimize development effort.<br><br>Which two services should you include in the solution? Each correct answer presents part of the solution.<br><br>NOTE: Each correct selection is worth one point.",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tobject detection in Azure AI Computer Vision",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tcontent tags in Azure AI Computer Vision",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\timage descriptions in Azure AI Computer Vision\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\timage type detection in Azure AI Computer Vision\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\timage classification in Azure AI Custom Vision"
    ],
    "answer": "CD",
    "answerDescription": "",
    "votes": [
      {
        "answer": "CD",
        "count": 19,
        "isMostVoted": true
      },
      {
        "answer": "CE",
        "count": 3,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2024-02-29T11:22:00.000Z",
        "voteCount": 13,
        "content": "I think Categorize the image as either a photograph or a drawing should be Image type detection\nhttps://learn.microsoft.com/en-us/azure/ai-services/computer-vision/concept-detecting-image-types\n\nImage Categorization doesn't identify image as photograph or drawing: See this: https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/concept-categorizing-images\n\nCaptions are generated using image descriptions in V3.2. However in V4.0 it is image captions\nhttps://learn.microsoft.com/en-us/azure/ai-services/computer-vision/concept-describing-images"
      },
      {
        "date": "2024-10-14T04:35:00.000Z",
        "voteCount": 1,
        "content": "this is in Oct 2024 exam"
      },
      {
        "date": "2024-06-22T00:11:00.000Z",
        "voteCount": 1,
        "content": "CD is the answer."
      },
      {
        "date": "2024-05-25T05:29:00.000Z",
        "voteCount": 1,
        "content": "image descriptions and image type detection."
      },
      {
        "date": "2024-05-19T07:44:00.000Z",
        "voteCount": 1,
        "content": "It must be C and D."
      },
      {
        "date": "2024-04-26T15:38:00.000Z",
        "voteCount": 1,
        "content": "A. Object detection in Azure AI Computer Vision\nC. Image descriptions in Azure AI Computer Vision\n\nExplanation:\n\nObject Detection (option A): This service in Azure AI Computer Vision can be used to detect objects within an image. By analyzing the content of the image, it can identify whether the image contains elements typically found in photographs (e.g., people, landscapes) or drawings (e.g., sketches, illustrations). This information can help categorize the image accordingly.\nImage Descriptions (option C): Azure AI Computer Vision can generate descriptions for images, providing textual summaries of the content. These descriptions can include details about the objects detected in the image, providing additional context that can aid in categorization and caption generation."
      },
      {
        "date": "2024-04-19T05:26:00.000Z",
        "voteCount": 1,
        "content": "C e E Sim! E para classificar como imagem e C para descrever a imagem."
      },
      {
        "date": "2024-04-04T19:00:00.000Z",
        "voteCount": 1,
        "content": "Must be C &amp; D"
      },
      {
        "date": "2024-03-27T11:21:00.000Z",
        "voteCount": 3,
        "content": "CE, Categorize instantly becomes Classification"
      },
      {
        "date": "2024-03-02T12:04:00.000Z",
        "voteCount": 1,
        "content": "CD imageType for photograph/drawing"
      },
      {
        "date": "2024-03-01T10:13:00.000Z",
        "voteCount": 1,
        "content": "Should be CD"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 36,
    "url": "https://www.examtopics.com/discussions/microsoft/view/134936-exam-ai-102-topic-2-question-36-discussion/",
    "body": "You are building an app that will use the Azure AI Video Indexer service.<br><br>You plan to train a language model to recognize industry-specific terms.<br><br>You need to upload a file that contains the industry-specific terms.<br><br>Which file format should you use?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tXML",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tTXT\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tXLS",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tPDF"
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 12,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-02-29T11:28:00.000Z",
        "voteCount": 9,
        "content": "Answer is correct:\nAs per https://learn.microsoft.com/en-us/azure/azure-video-indexer/customize-language-model-with-website\n\nThis step creates the model and gives the option to upload text files to the model."
      },
      {
        "date": "2024-05-25T05:24:00.000Z",
        "voteCount": 1,
        "content": "B is correct."
      },
      {
        "date": "2024-05-19T07:41:00.000Z",
        "voteCount": 1,
        "content": "B is right."
      },
      {
        "date": "2024-05-16T16:50:00.000Z",
        "voteCount": 1,
        "content": "I agree, B is the option"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 37,
    "url": "https://www.examtopics.com/discussions/microsoft/view/135013-exam-ai-102-topic-2-question-37-discussion/",
    "body": "DRAG DROP<br> -<br><br>You have an app that uses Azure AI and a custom trained classifier to identify products in images.<br><br>You need to add new products to the classifier. The solution must meet the following requirements:<br><br>\u2022\tMinimize how long it takes to add the products.<br>\u2022\tMinimize development effort.<br><br>Which five actions should you perform in sequence? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.<br><br><img src=\"https://img.examtopics.com/ai-102/image117.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/ai-102/image118.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-03-01T10:16:00.000Z",
        "voteCount": 24,
        "content": "First step should be Custom Vision.\nThen Upload sample images / Label / Retrain / Publish\nCustom classifiers have to go through custom vision, obviously"
      },
      {
        "date": "2024-03-01T18:32:00.000Z",
        "voteCount": 1,
        "content": "As per this https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/concept-model-customization\n\nYou can train a custom model using either the Custom Vision service or the Image Analysis 4.0 service with model customization."
      },
      {
        "date": "2024-09-12T07:56:00.000Z",
        "voteCount": 2,
        "content": "I think from now on the first step shold be Vision Studio, which if I get correctly is the new Custom Vision Studio \nhttps://learn.microsoft.com/en-us/azure/ai-services/custom-vision-service/concepts/compare-alternatives"
      },
      {
        "date": "2024-07-15T11:56:00.000Z",
        "voteCount": 2,
        "content": "From the Custom Vision portal, open the project.\nUpload sample images of the new products.\nLabel the sample images.\nRetrain the model.\nPublish the model."
      },
      {
        "date": "2024-06-12T00:52:00.000Z",
        "voteCount": 4,
        "content": "From the Custom Vision Portal, Open the Project.\nUpload Sample images of the new products.\nLabel the Sample images.\nRetrain the model.\nPublish the model."
      },
      {
        "date": "2024-05-25T05:21:00.000Z",
        "voteCount": 1,
        "content": "1. From the Custom Vision portal, open the project\n2. Label\n3. Upload\n4 .Retrain\n5. Publish"
      },
      {
        "date": "2024-10-08T06:26:00.000Z",
        "voteCount": 1,
        "content": "You must upload the images prior to labeling.\nNot Microsoft documentation but here's a pretty detailed walkthrough:\nhttps://blog.roboflow.com/how-to-label-azure-custom-vision/#:~:text=Label%20Computer%20Vision%20Data%20in%20Azure%20Custom%20Vision,...%205%20Step%20%234%3A%20Label%20an%20Image%20"
      },
      {
        "date": "2024-05-19T07:41:00.000Z",
        "voteCount": 1,
        "content": "Will this question be on the actual exam?"
      },
      {
        "date": "2024-08-29T22:29:00.000Z",
        "voteCount": 1,
        "content": "yes it was"
      },
      {
        "date": "2024-05-11T19:17:00.000Z",
        "voteCount": 3,
        "content": "So I will choice,\n1. From the Custom Vision portal, open the project\n2. Upload sample images of the new products\n3. Label the samples images\n4. Retrain the model\n5. Publish the model\n\nlabelling after uploading sample images."
      },
      {
        "date": "2024-03-29T15:07:00.000Z",
        "voteCount": 1,
        "content": "To add new products to the classifier while minimizing time and development effort, you should perform the following actions in sequence:\n\nFrom the Custom Vision portal, open the project.\nUpload sample images of the new products.\nLabel the sample images.\nRetrain the model.\nPublish the model.\nThis sequence ensures that the new product images are properly added, labeled, and incorporated into the existing model, and that the updated model is made available for use by your application."
      },
      {
        "date": "2024-03-26T03:41:00.000Z",
        "voteCount": 1,
        "content": "Final Answer: \n\n1. From the Custom Vision portal, open the project\n2. Label the samples images\n3. Upload sample images of the new products\n4 . Retrain the model\n5. Publish the model"
      },
      {
        "date": "2024-03-17T10:00:00.000Z",
        "voteCount": 2,
        "content": "4) Retrain the Model:\nTrigger the retraining process for your custom classifier. This step involves:\nUsing the labeled samples to train the model.\nFine-tuning the existing classifier with the new data.\n\n5) Publish the Model:\nOnce the retraining is complete and the model performs well on validation data, publish the updated classifier.\nThe published model will be ready for inference in your application, allowing it to identify the new products."
      },
      {
        "date": "2024-03-17T10:00:00.000Z",
        "voteCount": 2,
        "content": "Your proposed sequence of actions for adding new products to the classifier is a good start! Let\u2019s refine it a bit to ensure it aligns with best practices:\n\n1) Open the Custom Vision Project:\nBegin by accessing your project in the Custom Vision portal. This is where you\u2019ll manage your custom-trained classifier.\n\n2) Label the Sample Images:\nNext, label the sample images you\u2019ve collected for the new products. Assign appropriate tags or classes to each image based on the product category.\nProper labeling is crucial for effective training.\n\n3) Upload Sample Images:\nUpload the labeled sample images to your project. These images will serve as the training data for your classifier.\nMake sure you have a diverse set of samples to represent different variations of the new products."
      },
      {
        "date": "2024-03-05T02:48:00.000Z",
        "voteCount": 3,
        "content": "According to chat GPT, the correct sequence is the following :\n1. From the Custom Vision portal, open the project\n2. Label the samples images\n3. Upload sample images of the new products\n4 . Retrain the model\n5. Publish the model\n\nLabeling the sample images before uploading them is crucial because it helps in structuring and organizing the dataset appropriately."
      },
      {
        "date": "2024-03-26T03:43:00.000Z",
        "voteCount": 2,
        "content": "2. Label the samples images\n3. Upload sample images of the new products\nWrong, How you can label before upload so it should be Upload and then label"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 38,
    "url": "https://www.examtopics.com/discussions/microsoft/view/136424-exam-ai-102-topic-2-question-38-discussion/",
    "body": "HOTSPOT<br> -<br><br>You are developing an application that will use the Azure AI Vision client library. The application has the following code.<br><br><img src=\"https://img.examtopics.com/ai-102/image119.png\"><br><br>For each of the following statements, select Yes if the statement is true. Otherwise, select No.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/ai-102/image120.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/ai-102/image121.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-09-05T09:23:00.000Z",
        "voteCount": 3,
        "content": "What kind of a question this is!!. Asking whether it reads the local image or not. How does it become something about AI? That's all about whether you know the python syntax for reading the file. This company should get an award for being in this state"
      },
      {
        "date": "2024-09-10T04:29:00.000Z",
        "voteCount": 1,
        "content": "agree, if they want to include python or C# code they shold include modules on MS learn for it atleast"
      },
      {
        "date": "2024-08-12T20:43:00.000Z",
        "voteCount": 2,
        "content": "No Yes Yes 100%"
      },
      {
        "date": "2024-07-19T15:54:00.000Z",
        "voteCount": 1,
        "content": "No Yes Yes"
      },
      {
        "date": "2024-05-25T05:22:00.000Z",
        "voteCount": 2,
        "content": "No\nYes\nYes"
      },
      {
        "date": "2024-05-19T07:39:00.000Z",
        "voteCount": 1,
        "content": "No Yes Yes"
      },
      {
        "date": "2024-03-29T15:13:00.000Z",
        "voteCount": 2,
        "content": "Here are the answers to your questions:\n\nThe code will perform face recognition. No, the code does not include any features related to face recognition. It is only analyzing the image for tags and descriptions.\nThe code will list tags and their associated confidence. Yes, the code includes a loop that prints each tag and its associated confidence level.\nThe code will read an image file from the local file system. Yes, the code opens an image file from the local file system for analysis."
      },
      {
        "date": "2024-03-17T10:06:00.000Z",
        "voteCount": 3,
        "content": "The given answers by exam topics are CORRECT"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 39,
    "url": "https://www.examtopics.com/discussions/microsoft/view/145183-exam-ai-102-topic-2-question-39-discussion/",
    "body": "You are developing a method that uses the Azure AI Vision client library. The method will perform optical character recognition (OCR) in images. The method has the following code.<br><br><img src=\"https://img.examtopics.com/ai-102/image151.png\"><br><br>During testing, you discover that the call to the get_read_result method occurs before the read operation is complete.<br><br>You need to prevent the get_read_result method from proceeding until the read operation is complete.<br><br>Which two actions should you perform? Each correct answer presents part of the solution.<br><br>NOTE: Each correct selection is worth one point.",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRemove the operation_id parameter.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAdd code to verify the read_results.status value.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAdd code to verify the status of the read_operation_location value.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tWrap the call to get_read_result within a loop that contains a delay.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "BD",
    "answerDescription": "",
    "votes": [
      {
        "answer": "BD",
        "count": 5,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-09-10T04:30:00.000Z",
        "voteCount": 1,
        "content": "B &amp; D for sure"
      },
      {
        "date": "2024-08-12T20:44:00.000Z",
        "voteCount": 3,
        "content": "B - D, repeated many times with both python an C#"
      },
      {
        "date": "2024-08-06T14:48:00.000Z",
        "voteCount": 2,
        "content": "B and D"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 40,
    "url": "https://www.examtopics.com/discussions/microsoft/view/145640-exam-ai-102-topic-2-question-40-discussion/",
    "body": "HOTSPOT<br> -<br><br>You are developing an app that will use the Azure AI Vision API to analyze an image.<br><br>You need configure the request that will be used by the app to identify whether an image is clipart or a line drawing.<br><br>How should you complete the request? To answer, select the appropriate options in the answer area.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/ai-102/image152.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/ai-102/image153.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-09-05T06:46:00.000Z",
        "voteCount": 4,
        "content": "POST, imagetype\nhttps://learn.microsoft.com/en-us/rest/api/computervision/analyze-image/analyze-image?view=rest-computervision-v3.2&amp;tabs=HTTP"
      },
      {
        "date": "2024-08-12T20:46:00.000Z",
        "voteCount": 3,
        "content": "POST + imageType, for me and ChatGPT too"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "2"
  }
]