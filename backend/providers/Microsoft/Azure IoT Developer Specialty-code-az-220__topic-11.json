[
  {
    "topic": 11,
    "index": 1,
    "url": "https://www.examtopics.com/discussions/microsoft/view/24131-exam-az-220-topic-11-question-1-discussion/",
    "body": "You need to configure Stream Analytics to meet the POV requirements.<br>What are two ways to achieve the goal? Each correct answer presents a complete solution.<br>NOTE: Each correct selection is worth one point.<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tFrom IoT Hub, create a custom event hub endpoint, and then configure the endpoint as an input to Stream Analytics.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a Stream Analytics module, and then deploy the module to all IoT Edge devices in the fleet.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate an input in Stream Analytics that uses the built-in events endpoint of IoT Hub as the source.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRoute telemetry to an Azure Blob storage custom endpoint, and then configure the Blob storage as a reference input for Stream Analytics."
    ],
    "answer": "AC",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2020-07-04T05:30:00.000Z",
        "voteCount": 6,
        "content": "also the requirement is all about hot path analytics so agreeing to the point that blob storage comes under cold path analytics hence Option A &amp; C Correct"
      },
      {
        "date": "2020-07-24T13:24:00.000Z",
        "voteCount": 1,
        "content": "Be aware, in question 5 they mention that there is a cold path in POV phase. i think ans should be AD"
      },
      {
        "date": "2020-08-05T03:52:00.000Z",
        "voteCount": 1,
        "content": "The requirements is \"real-time\" alerts. Therefor the answer is not D. Blob storage is not real-time. A creates a realtime custom endpoint , C uses the realtime default endpoint."
      },
      {
        "date": "2021-05-18T09:31:00.000Z",
        "voteCount": 2,
        "content": "A,C\nAnswer C is not entirely correct. It shoud by as follows:\n\"Create an input in Stream Analytics that uses the created Event-Hubs-Instance as the source.\""
      },
      {
        "date": "2021-01-02T09:00:00.000Z",
        "voteCount": 1,
        "content": "I wonder if answer C can be correct.  As there's already a route defined which routes all messages to blob storage, the built-in 'events' endpoint will not receive any messages anymore."
      },
      {
        "date": "2021-01-10T05:45:00.000Z",
        "voteCount": 2,
        "content": "Once a Route is created, data stops flowing to the built-in-endpoint unless a Route is created to that endpoint."
      },
      {
        "date": "2020-06-26T02:04:00.000Z",
        "voteCount": 1,
        "content": "Why should the answer D not be correct ? It is possible to configure Routing to blob storage and also possible to choose the blob as input of the stream analytics. \nMay someone clarify it ?"
      },
      {
        "date": "2020-06-29T01:29:00.000Z",
        "voteCount": 4,
        "content": "Ans can't be D, as it adds blob as Reference Input not as Streaming input\nhttps://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-add-inputs#stream-and-reference-inputs"
      },
      {
        "date": "2020-07-24T13:16:00.000Z",
        "voteCount": 2,
        "content": "actually ans can be D, we use a blob input to make a data reference to \"compare\" it whit new data."
      }
    ],
    "examNameCode": "az-220",
    "topicNumber": "11"
  },
  {
    "topic": 11,
    "index": 2,
    "url": "https://www.examtopics.com/discussions/microsoft/view/23813-exam-az-220-topic-11-question-2-discussion/",
    "body": "DRAG DROP -<br>You need to add Time Series Insights to the solution to meet the pilot requirements.<br>Which three actions should you perform in sequence? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.<br>Select and Place:<br><img src=\"/assets/media/exam-media/04123/0010600001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04123/0010700001.png\" class=\"in-exam-image\">",
    "answerDescription": "Step 1: Provision Time Series Insights<br>Select Provision new IoT Hub to create a new IoT hub.<br>Step 2: Route telemetry from IoT Hub to a custom event.<br>Step 3: Add a data access policy to Time Series Insights for the dashboard web app<br>Scenario: Requirements. Pilot Requirements<br>During the pilot phase, devices will be deployed to 10 offices. Each office will have up to 1,000 devices.<br>During this phase, you will add Azure Time Series Insights in parallel to Stream Analytics to support real-time graphs and queries in a dashboard web app.<br>The pilot deployment must minimize operating costs.<br>Incorrect Answers:<br>No need to use an endpoint.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/time-series-insights/time-series-insights-update-create-environment",
    "votes": [],
    "comments": [
      {
        "date": "2020-06-23T04:38:00.000Z",
        "voteCount": 16,
        "content": "Ans should be:\n1.Add new consumer group to the built-in endpoint of IoT hub\n2.Provision TimeSeries Insights\n3.Add a data access policy to Time Series Insights for the dashboard web app"
      },
      {
        "date": "2020-08-05T23:00:00.000Z",
        "voteCount": 7,
        "content": "No, because the built-in endpoint will not contain any data because the custom endpoint cloud-route will route everything to the coldpath. So you first need to create a new custom endpoint that routes to the built-in endpoint. Therefor the given answer is correct."
      },
      {
        "date": "2023-07-05T13:34:00.000Z",
        "voteCount": 1,
        "content": "I would go for:\n- Add a custom event endpoint\n- Add new consumer group to the built-in endpoint of IoT hub\n- Add a data access policy\n\nStarting from this guide:\nhttps://learn.microsoft.com/en-us/azure/time-series-insights/how-to-ingest-data-iot-hub\n\"The IoT hub must have active message events being sent in\" so the first step is \"add custom event endpoint\". Then you add the new consumer group and finally, in the next steps of the guide, you can find: \"Define access policy\"\nhttps://learn.microsoft.com/en-us/azure/time-series-insights/concepts-access-policies"
      },
      {
        "date": "2021-01-02T09:04:00.000Z",
        "voteCount": 2,
        "content": "Given the fact that there's already some routing implemented and the built in events endpoint will not contain any data, I'd say the answer is:\n- add a custom event endpoint\n- route data to custom event endpoint\n- provision Timeseries Insights"
      },
      {
        "date": "2021-01-10T05:47:00.000Z",
        "voteCount": 1,
        "content": "Once a Route is created, data stops flowing to the built-in-endpoint unless a Route is created to that endpoint."
      },
      {
        "date": "2020-12-28T12:28:00.000Z",
        "voteCount": 2,
        "content": "You definitely need a dedicated consumer group for TSI ingestion."
      },
      {
        "date": "2020-11-09T08:24:00.000Z",
        "voteCount": 3,
        "content": "The tutorial says:\n1. Create an Azure Time Series Insights Gen2 environment\n2  Select Next: Event Source\n3. On the Azure Time Series Insights Gen2 page, select Data Access Policies\n\nSo in my opinion given answers are correct."
      }
    ],
    "examNameCode": "az-220",
    "topicNumber": "11"
  },
  {
    "topic": 11,
    "index": 3,
    "url": "https://www.examtopics.com/discussions/microsoft/view/24132-exam-az-220-topic-11-question-3-discussion/",
    "body": "You need to store the real-time alerts generated by Stream Analytics to meet the technical requirements.<br>Which type of Stream Analytics output should you configure?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure Blob storage",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tMicrosoft Power BI",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure Cosmos DB\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure SQL Database"
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 5,
        "isMostVoted": true
      },
      {
        "answer": "A",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2020-07-04T05:42:00.000Z",
        "voteCount": 10,
        "content": "as per the technical requirement &amp; question the real time alerts are not only to be stored but also visualize so in my opinion it should be Power-BI"
      },
      {
        "date": "2020-07-24T13:22:00.000Z",
        "voteCount": 3,
        "content": "This is correct, u can create dashboards in PBI to visualize alerts as well."
      },
      {
        "date": "2020-10-01T04:42:00.000Z",
        "voteCount": 4,
        "content": "I agree with the answer Power-BI as well since the alert needs to be visualised in real time."
      },
      {
        "date": "2021-05-18T06:44:00.000Z",
        "voteCount": 2,
        "content": "One of the techinal Requirement is - A dashboard UI must display alerts and the system status in real time and must allow device operators to make adjustments to the system - Hence PBI."
      },
      {
        "date": "2020-11-14T05:42:00.000Z",
        "voteCount": 9,
        "content": "The technical requirement says the reports must be presented weekly, monthly annually. which requires the data to be stored at some place. The brings down the answer to Storage, Cosmos, and SQL DB. Why not Power BI, of course PBI is used to visualize data but it has to connect to a source to report the data. Why Answer A, the requirement says minimize the costs. So i agree with Answer A. Blob Storage"
      },
      {
        "date": "2021-05-18T06:49:00.000Z",
        "voteCount": 1,
        "content": "One of tech requirement is - A dashboard UI must display alerts and the system status in real time and must allow device operators to make adjustments to the system. \n\nThis cannot be met using Blob Storage.\n\nIn streaming analytics, PBI is one of the option for \"Output\"...Hence Answer shall be PBI."
      },
      {
        "date": "2023-06-29T08:54:00.000Z",
        "voteCount": 1,
        "content": "The insights have hot storage included, so I gues that the question asks for the cold one which is next in line."
      },
      {
        "date": "2023-03-29T07:23:00.000Z",
        "voteCount": 1,
        "content": "The answer A is correct as per requirements, we need to generate weekly, monthly and yearly reports and also need to find a cheap option so Blog storage is good for these requirements."
      },
      {
        "date": "2022-12-05T02:49:00.000Z",
        "voteCount": 1,
        "content": "A is correct answer.\nYou do not need to care about dashboard UI which is not part of the question (yes, it is in technical requirements, but again it is not the question).\n\"Reports must be provided monthly, quarterly, and annually.\nStored data queries must be as efficient as possible.\" means Blob Partition should be used.\n\nhttps://learn.microsoft.com/en-us/azure/stream-analytics/blob-storage-azure-data-lake-gen2-output"
      },
      {
        "date": "2022-03-21T07:33:00.000Z",
        "voteCount": 1,
        "content": "Cosmos DB"
      },
      {
        "date": "2022-01-20T11:48:00.000Z",
        "voteCount": 4,
        "content": "Power BI must get data from somewhere, I would exclude that. Blob storage is for cold data not for a real time situation. SQL Database could be ok but the requirements refers to geographical redundation and about different schemas for different devices. In this case a NoSql like cosmos is better."
      },
      {
        "date": "2021-05-18T22:22:00.000Z",
        "voteCount": 2,
        "content": "A\nQuestion: You need to \"STORE\""
      },
      {
        "date": "2021-05-30T00:12:00.000Z",
        "voteCount": 2,
        "content": "C. Azure Cosmos DB\nIt states:\n- Reports must be provided monthly, quarterly, and annually.\n- Condition alerts will be sent immediately.\n- Multiple types of devices will collect telemetry that has different schemas.\n\nhttps://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-solution-patterns\nsee \"Incorporate real-time insights into your application through data stores\""
      },
      {
        "date": "2020-07-23T07:07:00.000Z",
        "voteCount": 2,
        "content": "I think answer should be SQL Database\nhttps://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-solution-patterns\nplease have a look at a topic \"Use SQL for Dashboard\", it eliminates Power BI and Blob Storage. I think Cosmos DB is used in some more advanced things and alerts are not like that much to be used up in Cosmos DB"
      },
      {
        "date": "2022-03-15T04:35:00.000Z",
        "voteCount": 1,
        "content": "we can eliminate sql as well because the technical requirements say \"telemetry that has different schemas\""
      },
      {
        "date": "2020-06-26T02:08:00.000Z",
        "voteCount": 2,
        "content": "Strange explanation why it is A. \nBlob storage is possible to choose as an output and this will store data cheap kind of cold export. \nCosmosDb would be also possible but from my perspective makes just sense in case you want to analyse those data afterwards (more expensive then blob storage)"
      }
    ],
    "examNameCode": "az-220",
    "topicNumber": "11"
  }
]