[
  {
    "topic": 3,
    "index": 1,
    "url": "https://www.examtopics.com/discussions/microsoft/view/28027-exam-dp-300-topic-3-question-1-discussion/",
    "body": "You have an Azure SQL database named sqldb1.<br>You need to minimize the possibility of Query Store transitioning to a read-only state.<br>What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDouble the value of Data Flush interval",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDecrease by half the value of Data Flush Interval\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDouble the value of Statistics Collection Interval",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDecrease by half the value of Statistics Collection interval"
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 15,
        "isMostVoted": true
      },
      {
        "answer": "C",
        "count": 11,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2020-10-04T13:14:00.000Z",
        "voteCount": 33,
        "content": "From my point of view, the correct answer is C. (Double the value of Statistics Collection Interval). To avoid Query Store transitioning to read-only state, the runtime statistics for the Last Stale Query Threshold days must fit in the defined Max Size (MB). If the Statistics Collection Interval is increased then less space will be used for the persisted runtime statistics and there will be more free space for new data. The Data Flush Interval can delay the transitioning to read-only state, but not minimize the possibility it occurs."
      },
      {
        "date": "2020-12-07T14:43:00.000Z",
        "voteCount": 3,
        "content": "Agree. This should be the correct answer. I don't see how DFI make any influence to Max Size."
      },
      {
        "date": "2021-03-17T05:00:00.000Z",
        "voteCount": 1,
        "content": "You're right - the only sensible answer is \"C\"."
      },
      {
        "date": "2021-10-28T13:48:00.000Z",
        "voteCount": 11,
        "content": "in microsoft prep test ,this question  says B. Decrease Data Flush Interval."
      },
      {
        "date": "2023-01-31T22:50:00.000Z",
        "voteCount": 1,
        "content": "B is correct.\n\nWhile Query Store collects queries, execution plans, and statistics, its size in the database grows until this limit is reached. When that happens, Query Store automatically changes the operation mode to READ_ONLY and stops collecting new data, which means that your performance analysis is no longer accurate.\n\nMAX_STORAGE_SIZE_MB limit isn't strictly enforced. Storage size is checked only when Query Store writes data to disk. This interval is set by the DATA_FLUSH_INTERVAL_SECONDS option or the Management Studio Query Store dialog option Data Flush Interval.\nhttps://learn.microsoft.com/en-us/sql/relational-databases/performance/manage-the-query-store?view=sql-server-ver16&amp;tabs=ssms"
      },
      {
        "date": "2023-11-21T14:40:00.000Z",
        "voteCount": 1,
        "content": "B is right answer"
      },
      {
        "date": "2023-09-08T19:07:00.000Z",
        "voteCount": 2,
        "content": "It's B. Decreasing Data Flush is the main way to keep the Query Store outside of read-only, prevent in-memory max size, and when it writes to disk, can delete stale data if enabled. Data Flush can be halved/doubled with ease. Statistics Collection Interval cannot be doubled as easily."
      },
      {
        "date": "2023-01-14T20:53:00.000Z",
        "voteCount": 2,
        "content": "C is correct"
      },
      {
        "date": "2023-01-14T20:57:00.000Z",
        "voteCount": 2,
        "content": "Please disregard comment"
      },
      {
        "date": "2023-01-02T14:22:00.000Z",
        "voteCount": 5,
        "content": "https://learn.microsoft.com/en-us/sql/relational-databases/performance/manage-the-query-store?view=sql-server-ver16&amp;tabs=ssms\n\nStale Query Threshold (Days): Time-based cleanup policy that controls the retention period of persisted runtime statistics and inactive queries, expressed in days. By default, Query Store is configured to keep the data for 30 days, which might be unnecessarily long for your scenario.\n\nAvoid keeping historical data that you don't plan to use. This practice reduces changes to read-only status. The size of Query Store data and the time to detect and mitigate the issue will be more predictable. Use Management Studio or the following script to configure time-based cleanup policy:\n\nSQL\n\nCopy\nALTER DATABASE [QueryStoreDB]\nSET QUERY_STORE (CLEANUP_POLICY = (STALE_QUERY_THRESHOLD_DAYS = 90));"
      },
      {
        "date": "2022-12-21T11:45:00.000Z",
        "voteCount": 1,
        "content": "B combined with SIZE_BASED_CLEANUP_MODE\n\nhttps://learn.microsoft.com/en-us/sql/relational-databases/performance/manage-the-query-store?view=sql-server-ver16&amp;tabs=ssms#query-store-maximum-size"
      },
      {
        "date": "2022-07-16T13:01:00.000Z",
        "voteCount": 3,
        "content": "C decreases the amount of collected data so less chances of reaching the limit"
      },
      {
        "date": "2022-04-29T10:38:00.000Z",
        "voteCount": 3,
        "content": "The Max Size (MB) limit isn't strictly enforced. Storage size is checked only when Query Store writes data to disk. This interval is set by the Data Flush Interval (Minutes) option. If Query Store has breached the maximum size limit between storage size checks, it transitions to read-only mode. If Size Based Cleanup Mode is enabled, the cleanup mechanism to enforce the maximum size limit is also triggered."
      },
      {
        "date": "2022-03-13T06:53:00.000Z",
        "voteCount": 3,
        "content": "C is correct"
      },
      {
        "date": "2022-01-25T06:59:00.000Z",
        "voteCount": 6,
        "content": "This clears up the confusion in MS documentation...it specifically states that Flush parameters are what controls Max DB store https://docs.microsoft.com/en-us/sql/relational-databases/performance/how-query-store-collects-data?view=sql-server-ver15#remarks"
      },
      {
        "date": "2022-03-31T14:26:00.000Z",
        "voteCount": 5,
        "content": "After reading through that, I think B."
      },
      {
        "date": "2022-01-07T00:39:00.000Z",
        "voteCount": 1,
        "content": "You can't really double or halve the Statistics Collection interval as that is a fixed value with a list of allowed values, see: sys.database_query_store_options You can't halve 15 minutes and can't double 1 hour. Flush Interval can be set to any arbitrary value above 1 minute. Makes sense to have the size checked more often. Tricky but very bad question."
      },
      {
        "date": "2021-12-29T14:02:00.000Z",
        "voteCount": 3,
        "content": "Correct answer is basically outlined in the explanation, only marked as incorrect \ud83e\udd37\u200d\u2642\ufe0f"
      },
      {
        "date": "2021-11-18T13:57:00.000Z",
        "voteCount": 2,
        "content": "Correct answer is B"
      },
      {
        "date": "2021-10-17T11:09:00.000Z",
        "voteCount": 1,
        "content": "Answer is C according to a lot of forums exponing this question...."
      },
      {
        "date": "2021-08-09T11:24:00.000Z",
        "voteCount": 1,
        "content": "C should be the correct answer"
      },
      {
        "date": "2021-08-08T13:43:00.000Z",
        "voteCount": 3,
        "content": "The correct Answer is B. Just check the Query Store - database Properties and you can find in read-only state the option B is valid. for option C , after one hour we have ONE day (cannot add the custom value) . it means, we cannot double it. it would be X 24 more."
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 2,
    "url": "https://www.examtopics.com/discussions/microsoft/view/24804-exam-dp-300-topic-3-question-2-discussion/",
    "body": "You have SQL Server 2019 on an Azure virtual machine that runs Windows Server 2019. The virtual machine has 4 vCPUs and 28 GB of memory.<br>You scale up the virtual machine to 16 vCPUSs and 64 GB of memory.<br>You need to provide the lowest latency for tempdb.<br>What is the total number of data files that tempdb should contain?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t2",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t4",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t8\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t64"
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 5,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2020-07-05T12:57:00.000Z",
        "voteCount": 38,
        "content": "Answer should be 'C. 8 TempDb Files'"
      },
      {
        "date": "2021-05-22T03:52:00.000Z",
        "voteCount": 7,
        "content": "Exact same question earlier on listed answer as 64 files. Now same question and answer is 8 . LOL ...."
      },
      {
        "date": "2021-06-29T05:56:00.000Z",
        "voteCount": 4,
        "content": "Not the same, read the explanation \"If the number of logical processors is greater than eight....\". In that case there were 16 vCPUs. Here 8 is not greater than 8"
      },
      {
        "date": "2021-12-20T08:06:00.000Z",
        "voteCount": 1,
        "content": "theb differnce between this question and the previous question\nthe previous:  qustion You scale up the virtual machine to 16 vCPUSs and 64 GB of memory.\nthis question:You scale up the virtual machine to 8 vCPUSs and 64 GB of memory."
      },
      {
        "date": "2023-01-22T09:33:00.000Z",
        "voteCount": 1,
        "content": "The number of files would be 64 according to the Microsoft documentation.\n\n\nThe number of secondary data files depends on the number of (logical) processors on the machine. As a general rule, if the number of logical processors is less than or equal to eight, use the same number of data files as logical processors. If the number of logical processors is greater than eight, use eight data files. Then if contention continues, increase the number of data files by multiples of four until the contention decreases to acceptable levels, or make changes to the workload/code."
      },
      {
        "date": "2023-03-09T00:38:00.000Z",
        "voteCount": 3,
        "content": "Where are you getting 64? 64 GB is memory is memory in the question not processors...\nAnswer c, 8 tempDb files is correct."
      },
      {
        "date": "2022-07-22T18:23:00.000Z",
        "voteCount": 2,
        "content": "Answer C, Very know 8 to 16. Not greater than vCores."
      },
      {
        "date": "2022-04-29T14:42:00.000Z",
        "voteCount": 5,
        "content": "If the number of logical processors is greater than eight (8), use eight data files. If contention continues, increase the number of data files by multiples of four (4) up to the number of logical processors until the contention is reduced to acceptable levels. Alternatively, make changes to the workload or code.\nhttps://docs.microsoft.com/en-US/troubleshoot/sql/performance/recommendations-reduce-allocation-contention"
      },
      {
        "date": "2021-05-31T19:10:00.000Z",
        "voteCount": 1,
        "content": "based on this article , answer should be 8\nhttps://docs.microsoft.com/en-US/troubleshoot/sql/performance/recommendations-reduce-allocation-contention"
      },
      {
        "date": "2021-03-02T17:04:00.000Z",
        "voteCount": 1,
        "content": "64 files as they asked for lowest latency. the situation is not about contention and not for standard setup."
      },
      {
        "date": "2021-02-26T10:13:00.000Z",
        "voteCount": 1,
        "content": "The answer should be C. 8"
      },
      {
        "date": "2021-02-08T14:29:00.000Z",
        "voteCount": 2,
        "content": "correct answer should be 8 here"
      },
      {
        "date": "2021-02-02T04:16:00.000Z",
        "voteCount": 1,
        "content": "64 is the Possibility and since need lowest latency for tempdb so 8 will be good Practice only not the Answer"
      },
      {
        "date": "2021-02-01T08:06:00.000Z",
        "voteCount": 1,
        "content": "the best solution is to have 16 tempdb files, if the contention still exists, increase the number to 20 , 24 or even 28. but I wouldn't expect to see any difference between 32 and 64 tempdf files in this case."
      },
      {
        "date": "2021-05-22T03:51:00.000Z",
        "voteCount": 2,
        "content": "That is not correct. it is multiples of 4 , not additional of 4 as you wrote. \nSo it should be 4 (since there was 4 vCPU initially), 16, 64."
      },
      {
        "date": "2021-01-17T06:54:00.000Z",
        "voteCount": 1,
        "content": "64 files is a ridiculous amount of data files for tempdb"
      },
      {
        "date": "2021-01-10T20:15:00.000Z",
        "voteCount": 1,
        "content": "start with 8 files, add multiple of 4 files every time and do not greater than number of logic cores. \nThe answer should be 'C. 8 TempDb Files'"
      },
      {
        "date": "2021-01-08T19:03:00.000Z",
        "voteCount": 1,
        "content": "Is C correct answer?"
      },
      {
        "date": "2020-12-06T15:02:00.000Z",
        "voteCount": 1,
        "content": "Makes sense to go with 8 and then add number files based on contention. so I would vote for Ans C. Check this article for better explanation https://www.sqlskills.com/blogs/paul/correctly-adding-data-files-tempdb/"
      },
      {
        "date": "2020-11-19T22:43:00.000Z",
        "voteCount": 1,
        "content": "Cannot contain more data files than the processor. So the answer would be C,8!"
      },
      {
        "date": "2020-10-27T15:56:00.000Z",
        "voteCount": 1,
        "content": "since contention is not provided as part of question, 8 sounds like the answer."
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 3,
    "url": "https://www.examtopics.com/discussions/microsoft/view/41682-exam-dp-300-topic-3-question-3-discussion/",
    "body": "HOTSPOT -<br>You have an Azure SQL database named db1.<br>You need to retrieve the resource usage of db1 from the last week.<br>How should you complete the statement? To answer, select the appropriate options in the answer area.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04275/0014800001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04275/0014900001.png\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: sys.resource_stats -<br>sys.resource_stats returns CPU usage and storage data for an Azure SQL Database. It has database_name and start_time columns.<br><br>Box 2: DateAdd -<br>The following example returns all databases that are averaging at least 80% of compute utilization over the last one week.<br>DECLARE @s datetime;<br>DECLARE @e datetime;<br>SET @s= DateAdd(d,-7,GetUTCDate());<br>SET @e= GETUTCDATE();<br>SELECT database_name, AVG(avg_cpu_percent) AS Average_Compute_Utilization<br><br>FROM sys.resource_stats -<br>WHERE start_time BETWEEN @s AND @e<br><br>GROUP BY database_name -<br>HAVING AVG(avg_cpu_percent) &gt;= 80<br>Incorrect Answers:<br>sys.dm_exec_requests:<br>sys.dm_exec_requests returns information about each request that is executing in SQL Server. It does not have a column named database_name. sys.dm_db_resource_stats: sys.dm_db_resource_stats does not have any start_time column.<br>Note: sys.dm_db_resource_stats returns CPU, I/O, and memory consumption for an Azure SQL Database database. One row exists for every 15 seconds, even if there is no activity in the database. Historical data is maintained for approximately one hour.<br>Sys.dm_user_db_resource_governance returns actual configuration and capacity settings used by resource governance mechanisms in the current database or elastic pool. It does not have any start_time column.<br>Reference:<br>https://docs.microsoft.com/en-us/sql/relational-databases/system-catalog-views/sys-resource-stats-azure-sql-database",
    "votes": [],
    "comments": [
      {
        "date": "2021-01-24T06:58:00.000Z",
        "voteCount": 34,
        "content": "sys.dm_db_resource_stats: This DMV records a snapshot of resource usage for the database every 15 seconds (kept for 1 hour). \nsys.resource_stats: This can be run in the context of the master database of the Azure SQL Database server to see resource usage for all Azure SQL Database databases associated with the server. This view is less granular and shows resource usage every 5 minutes (kept for 14 days).\n\nsys.resource_stats is the correct answer due to two reason\n1. it holds data for 14 days while the other one holds data for 1 hour only.\n2.. It has start_time column while the other one does not have it."
      },
      {
        "date": "2021-01-25T04:30:00.000Z",
        "voteCount": 20,
        "content": "Answers are correct.\n1. sys.dm_db_resource_stats can't be becuase only keep data by 1h. \nsys.resource_stats can keep by 14days.\n2.dateadd is correct"
      },
      {
        "date": "2022-04-29T16:06:00.000Z",
        "voteCount": 2,
        "content": "Answer is correct"
      },
      {
        "date": "2022-03-10T04:30:00.000Z",
        "voteCount": 1,
        "content": "sys.resource_stats\nDATEADD\n\nFor a less granular view of this data with longer retention period, use the sys.resource_stats catalog view in Azure SQL Database, or the sys.server_resource_stats catalog view in Azure SQL Managed Instance. This view captures data every 5 minutes and maintains historical data for 14 days.\n\nDECLARE @s datetime;  \nDECLARE @e datetime;  \nSET @s= DateAdd(d,-7,GetUTCDate());  \nSET @e= GETUTCDATE();  \nSELECT database_name, AVG(avg_cpu_percent) AS Average_Compute_Utilization   \nFROM sys.resource_stats   \nWHERE start_time BETWEEN @s AND @e  \nGROUP BY database_name  \nHAVING AVG(avg_cpu_percent) &gt;= 80;"
      },
      {
        "date": "2021-08-02T02:07:00.000Z",
        "voteCount": 3,
        "content": "Answer is given correct\nhttps://docs.microsoft.com/en-us/sql/relational-databases/system-catalog-views/sys-resource-stats-azure-sql-database?view=azuresqldb-current\nsee the example section yo will understand"
      },
      {
        "date": "2021-02-27T13:04:00.000Z",
        "voteCount": 1,
        "content": "the first selection is correct. sys.resource_stats returns data for longer retention period:\nys.dm_db_resource_stats returns within the last 60 minutes\nhttps://docs.microsoft.com/en-us/sql/relational-databases/system-dynamic-management-views/sys-dm-db-resource-stats-azure-sql-database?view=azuresqldb-current"
      },
      {
        "date": "2021-01-18T11:55:00.000Z",
        "voteCount": 1,
        "content": "If you query sys.dm_db_resource_stats the focus has to be in the DB. the query has DB filter applied suggestion you would be outside of DB focus and the Master focus would work fine on the query."
      },
      {
        "date": "2021-01-10T20:25:00.000Z",
        "voteCount": 3,
        "content": "Sys.dm_db_resource_stats has not got 'start time' column\nanswer is sys.resource_stats"
      },
      {
        "date": "2021-01-06T18:29:00.000Z",
        "voteCount": 2,
        "content": "To get results from sys.resource_stats the focus needs to be on the master database. It will give an error if run from a user database. Sys.dm_dm_resource_stats can be run in a user database and will give more granular information, but as noted in the given answer there is no start time column."
      },
      {
        "date": "2021-01-06T18:26:00.000Z",
        "voteCount": 1,
        "content": "Disregard my previous comment. I don't know why I can' get data back from sys.resource_stats, but Books Online agrees with the given answer."
      },
      {
        "date": "2021-01-06T18:22:00.000Z",
        "voteCount": 1,
        "content": "Answer given is wrong. Correct answer is sys.dm_db_resource_stats and DATEADD. There is no sys.resource_stats dmv."
      },
      {
        "date": "2021-09-27T07:17:00.000Z",
        "voteCount": 1,
        "content": "https://docs.microsoft.com/en-us/sql/relational-databases/system-catalog-views/sys-resource-stats-azure-sql-database?view=azuresqldb-current"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 4,
    "url": "https://www.examtopics.com/discussions/microsoft/view/47819-exam-dp-300-topic-3-question-4-discussion/",
    "body": "You have 50 Azure SQL databases.<br>You need to notify the database owner when the database settings, such as the database size and pricing tier, are modified in Azure.<br>What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a diagnostic setting for the activity log that has the Security log enabled.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tFor the database, create a diagnostic setting that has the InstanceAndAppAdvanced metric enabled.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate an alert rule that uses a Metric signal type.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate an alert rule that uses an Activity Log signal type."
    ],
    "answer": "D",
    "answerDescription": "Activity log events - An alert can trigger on every event, or, only when a certain number of events occur.<br>The activity log of a database logs the change for the SKU (Stock-keeping-Unit) change.<br>Incorrect Answers:<br>C: Metric values - The alert triggers when the value of a specified metric crosses a threshold you assign in either direction. That is, it triggers both when the condition is first met and then afterwards when that condition is no longer being met.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/azure-sql/database/alerts-insights-configure-portal",
    "votes": [],
    "comments": [
      {
        "date": "2021-06-29T06:25:00.000Z",
        "voteCount": 13,
        "content": "The answer is correct."
      },
      {
        "date": "2021-03-20T10:21:00.000Z",
        "voteCount": 7,
        "content": "Answer is correct.\nhttps://docs.microsoft.com/en-us/answers/questions/138020/auto-alert-when-compute-tier-of-azure-sql-is-chang.html"
      },
      {
        "date": "2022-12-02T14:24:00.000Z",
        "voteCount": 7,
        "content": "D is correct answer\nSignal type: The type of alert rule you're creating.\nTypes of alerts:\nMetric alerts: evaluate resource metrics at regular intervals.\nLog alerts: allow users to use a Log Analytics query to evaluate resource logs at a predefined frequency\nActivity log alerts:  Are triggered when a new activity log event occurs that matches defined conditions. Resource Health alerts and Service Health alerts are activity log alerts that report on your service and resource health.\nSmart detection alerts: \nhttps://learn.microsoft.com/en-us/azure/azure-monitor/alerts/alerts-overview#types-of-alerts"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 5,
    "url": "https://www.examtopics.com/discussions/microsoft/view/47272-exam-dp-300-topic-3-question-5-discussion/",
    "body": "You have several Azure SQL databases on the same Azure SQL Database server in a resource group named ResourceGroup1.<br>You must be alerted when CPU usage exceeds 80 percent for any database. The solution must apply to any additional databases that are created on the Azure<br>SQL server.<br>Which resource type should you use to create the alert?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tResource Groups",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSQL Servers",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSQL Databases\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSQL Virtual Machines"
    ],
    "answer": "C",
    "answerDescription": "There are resource types related to application code, compute infrastructure, networking, storage + databases.<br>You can deploy up to 800 instances of a resource type in each resource group.<br>Some resources can exist outside of a resource group. These resources are deployed to the subscription, management group, or tenant. Only specific resource types are supported at these scopes.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/azure-resource-manager/management/resource-providers-and-types",
    "votes": [
      {
        "answer": "C",
        "count": 1,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-06-28T09:41:00.000Z",
        "voteCount": 22,
        "content": "Alerts cannot be set at the resource group or Logical SQL server level, So it has to be \"SQL Database\""
      },
      {
        "date": "2023-01-08T09:18:00.000Z",
        "voteCount": 2,
        "content": "You can set an Alert on RG level, but not for \"CPU percentage\" signal or any other DB specific resource."
      },
      {
        "date": "2023-01-09T10:56:00.000Z",
        "voteCount": 2,
        "content": "https://microsoftlearning.github.io/dp-300-database-administrator/Instructions/Labs/12-create-cpu-status-alert.html"
      },
      {
        "date": "2021-09-18T19:34:00.000Z",
        "voteCount": 2,
        "content": "Where's the link to this statement?"
      },
      {
        "date": "2021-12-06T11:01:00.000Z",
        "voteCount": 5,
        "content": "https://docs.microsoft.com/en-us/azure/azure-resource-manager/management/resource-providers-and-types the answer is in this link"
      },
      {
        "date": "2021-09-28T12:30:00.000Z",
        "voteCount": 7,
        "content": "I have checked in Lab. In SQL Database we can create CPU percentage alert rule."
      },
      {
        "date": "2024-10-03T08:27:00.000Z",
        "voteCount": 1,
        "content": "B - SQL Servers - in this case, since you want to cover all current and future databases on a particular SQL Server, you would configure the alert at the SQL Server level, not at the individual SQL Database level."
      },
      {
        "date": "2024-09-19T13:41:00.000Z",
        "voteCount": 1,
        "content": "SQL Database"
      },
      {
        "date": "2024-09-08T07:08:00.000Z",
        "voteCount": 1,
        "content": "I think it should be B \nsince in a question the key is \"You must be alerted when CPU usage exceeds 80 percent for any database\""
      },
      {
        "date": "2024-09-19T13:43:00.000Z",
        "voteCount": 1,
        "content": "I Double checked myself The Correct answer is C: SQL Databses\nUnder SQL Server there is no option to Set an Alert"
      },
      {
        "date": "2023-07-15T08:09:00.000Z",
        "voteCount": 2,
        "content": "If the scope is changed in Azure Monitor to SQL managed instance, then an alert based on the log search (using KQL) of CPU utilization above 95% (might be a custom query) is supported. Otherwise, SQL VM might be the right answer as this ref https://docs.microsoft.com/en-us/azure/azure-monitor/alerts/alerts-metric-overview indicates that the rule is applied at the VM level."
      },
      {
        "date": "2023-07-15T08:01:00.000Z",
        "voteCount": 1,
        "content": "Tested on Azure SQL. CPU percentage signal returns an error -- \"alert rule that uses an Activity Log signal type\" -- when scope is specified as the SQL database from the Azure Monitor alert workflow window.  This window supports signals at the SQL server scope level, but does not cover CPU percentage, as noted by another person on this discussion. The supported signals include admin tasks at the server level -- create, delete, update SQL server."
      },
      {
        "date": "2023-02-23T01:40:00.000Z",
        "voteCount": 1,
        "content": "C. SQL Databases"
      },
      {
        "date": "2021-12-02T07:39:00.000Z",
        "voteCount": 2,
        "content": "The given answer is correct\n\nYou can specify the scope of monitoring by a single metric alert rule in one of three ways. For example, with virtual machines you can specify the scope as:\n\na list of virtual machines (in one Azure region) within a subscription\nall virtual machines (in one Azure region) in one or more resource groups in a subscription\nall virtual machines (in one Azure region) in a subscription\n Note\n\nThe scope of a multi-resource metric alert rule must contain at least one resource of the selected resource type.\n\nCreating metric alert rules that monitor multiple resources is like creating any other metric alert that monitors a single resource. Only difference is that you would select all the resources you want to monitor. You can also create these rules through Azure Resource Manager templates. You will receive individual notifications for each monitored resource.\n\n Note\n\nIn a metric alert rule that monitors multiple resources, only one condition is allowed."
      },
      {
        "date": "2021-12-02T07:43:00.000Z",
        "voteCount": 1,
        "content": "https://docs.microsoft.com/en-us/azure/azure-resource-manager/management/resource-providers-and-types"
      },
      {
        "date": "2021-09-09T04:59:00.000Z",
        "voteCount": 3,
        "content": "I think the correct answer is A, https://docs.microsoft.com/en-us/azure/azure-monitor/alerts/alerts-activity-log"
      },
      {
        "date": "2021-08-13T20:32:00.000Z",
        "voteCount": 2,
        "content": "The correct Answer is \"A\". Just make sure to review carefully, \"The solution must apply to any additional databases that are created on the Azure SQL server.\" statement! Then, RG (Resource group) would be the correct Answer."
      },
      {
        "date": "2021-08-23T00:55:00.000Z",
        "voteCount": 2,
        "content": "It is wrong given answer correct"
      },
      {
        "date": "2023-08-16T16:50:00.000Z",
        "voteCount": 1,
        "content": "https://stackoverflow.com/questions/61684053/how-can-i-be-notified-if-someone-creates-a-new-database-in-azure"
      },
      {
        "date": "2021-06-11T18:56:00.000Z",
        "voteCount": 1,
        "content": "So, what is the correct answer here?"
      },
      {
        "date": "2021-05-16T05:48:00.000Z",
        "voteCount": 1,
        "content": "It should be Azure SQL database server ."
      },
      {
        "date": "2021-03-18T15:04:00.000Z",
        "voteCount": 1,
        "content": "answer is correct. you can monitor all database on a specific resouregroup or many resourceg group for sql database type."
      },
      {
        "date": "2021-03-15T19:44:00.000Z",
        "voteCount": 3,
        "content": "Many times, you might want the same alert rule applied to many resources. Azure Monitor also supports monitoring multiple resources (of the same type) with one metric alert rule, for resources that exist in the same Azure region.\nhttps://docs.microsoft.com/en-us/azure/azure-monitor/alerts/alerts-metric-overview"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 6,
    "url": "https://www.examtopics.com/discussions/microsoft/view/46842-exam-dp-300-topic-3-question-6-discussion/",
    "body": "You have SQL Server 2019 on an Azure virtual machine that runs Windows Server 2019. The virtual machine has 4 vCPUs and 28 GB of memory.<br>You scale up the virtual machine to 8 vCPUSs and 64 GB of memory.<br>You need to provide the lowest latency for tempdb.<br>What is the total number of data files that tempdb should contain?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t2",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t4",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t8\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t64"
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 18,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-08-08T13:48:00.000Z",
        "voteCount": 18,
        "content": "16 vCPUs = 8 CPUs = 8 Tempdb data files."
      },
      {
        "date": "2021-06-13T09:36:00.000Z",
        "voteCount": 9,
        "content": "In my view, we need to focus on last sentence - \"What is the total number of data files that tempdb should contain?\" \nWhile 8 is best practice, we can reach up to 64 (in this scenario) during the course of minimizing contention. So answer is 64."
      },
      {
        "date": "2021-06-14T04:34:00.000Z",
        "voteCount": 7,
        "content": "Please ignore my above comment, confused with RAM. \nI go with 8."
      },
      {
        "date": "2024-09-19T13:46:00.000Z",
        "voteCount": 1,
        "content": "C: 8 Temp data files"
      },
      {
        "date": "2023-10-31T01:58:00.000Z",
        "voteCount": 2,
        "content": "When scaling tempdb in SQL Server, it's recommended to have a number of data files equal to or less than the number of CPU cores, but not exceeding 8 files. In your scenario, after scaling to 8 vCPUs, it would be appropriate to have 8 data files for tempdb.\nAnswer: C. 8"
      },
      {
        "date": "2022-04-22T13:31:00.000Z",
        "voteCount": 2,
        "content": "8 tempdb files is correct answer"
      },
      {
        "date": "2022-03-31T14:33:00.000Z",
        "voteCount": 4,
        "content": "General rule:\nWhen &lt; 8 CPU, use same number of tempdb files as CPU\nWhen &gt;=8 CPU, use 8 tempdb files (as first step)\nGo higher than 8 tempdb files in multiples of 4 only if contention persists"
      },
      {
        "date": "2022-01-15T07:58:00.000Z",
        "voteCount": 3,
        "content": "More than 8 vCPUs -&gt; 8 files for TemDB"
      },
      {
        "date": "2021-11-24T07:25:00.000Z",
        "voteCount": 6,
        "content": "&gt;=8 to &lt;32 = No. of Cores/2\n&gt;=32 = No. of Cores/4\n\nSo here answer is 8"
      },
      {
        "date": "2021-10-18T05:55:00.000Z",
        "voteCount": 2,
        "content": "The answer D. 64 is correct. You have 16 vCPUS. You cannot divide 8 files by 16 CPUs and get a full number. Are you going to have 0.5 tempdb-files per CPU? No, you should not. 64 files divided by 16vCPUS means 4 tempDB files per vCPU.\n\nKeep a 1:1 ratio between CPUs and tempdb files up to 8. Thereafter, add files if you continue to see allocation contention or if you\u2019re looking to push the I/O subsystem harder."
      },
      {
        "date": "2021-07-24T16:28:00.000Z",
        "voteCount": 4,
        "content": "64 Gb is the memory no the number of cpus, Cpus is 16 which number of datafiles should be 8."
      },
      {
        "date": "2021-05-31T19:09:00.000Z",
        "voteCount": 5,
        "content": "Based on this article , the answer should be 8\nhttps://docs.microsoft.com/en-US/troubleshoot/sql/performance/recommendations-reduce-allocation-contention"
      },
      {
        "date": "2021-05-27T09:17:00.000Z",
        "voteCount": 4,
        "content": "The correct answer should be C..."
      },
      {
        "date": "2021-05-21T21:25:00.000Z",
        "voteCount": 1,
        "content": "It is multiplication of 4. There was 4 first and then 16 and then 64."
      },
      {
        "date": "2021-04-07T21:26:00.000Z",
        "voteCount": 1,
        "content": "According to MOC , it should be 8 as upper."
      },
      {
        "date": "2021-03-18T13:31:00.000Z",
        "voteCount": 2,
        "content": "basically they said it was 4 and then they increased to 16, so following best practice first time when cpu increased, DBA will set  8tempdb files. if there is contention after then more files will be added. so this question refers to the first step after cpu increased. tricky"
      },
      {
        "date": "2021-05-21T21:17:00.000Z",
        "voteCount": 3,
        "content": "The number of files depends on the number of (logical) processors on the machine. As a general rule, if the number of logical processors is less than or equal to eight, use the same number of data files as logical processors. If the number of logical processors is greater than eight, use eight data files and then if contention continues, increase the number of data files by multiples of 4 until the contention is reduced to acceptable levels or make changes to the workload/code."
      },
      {
        "date": "2021-03-15T06:26:00.000Z",
        "voteCount": 1,
        "content": "i think that the correct answer is 8...."
      },
      {
        "date": "2021-03-12T23:29:00.000Z",
        "voteCount": 4,
        "content": "should be 8"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 7,
    "url": "https://www.examtopics.com/discussions/microsoft/view/33670-exam-dp-300-topic-3-question-7-discussion/",
    "body": "You have SQL Server on an Azure virtual machine that contains a database named DB1. DB1 contains a table named CustomerPII.<br>You need to record whenever users query the CustomerPII table.<br>Which two options should you enable? Each correct answer presents part of the solution.<br>NOTE: Each correct selection is worth one point.<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tserver audit specification",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSQL Server audit\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tdatabase audit specification\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ta server principal"
    ],
    "answer": "BC",
    "answerDescription": "",
    "votes": [
      {
        "answer": "BC",
        "count": 5,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2020-10-05T04:38:00.000Z",
        "voteCount": 42,
        "content": "B, C. \nOn SQL Server you need SQL Server audit and database audit specification that belongs to that SQL Server audit. Auditing in SQL Server differs from Azure SQL Server and server audit specification collects different things than database audit specifications where in Azure SQL Server Server and Database audits they are basically the same thing and only configured on the server or the database level."
      },
      {
        "date": "2020-11-07T17:16:00.000Z",
        "voteCount": 35,
        "content": "ref: https://docs.microsoft.com/en-us/sql/relational-databases/security/auditing/create-a-server-audit-and-database-audit-specification?view=sql-server-ver15 \n\nshould be B, C\n\nUSE master ;  \nGO  \n-- Create the server audit.   \nCREATE SERVER AUDIT Payrole_Security_Audit  \n    TO FILE ( FILEPATH =   \n'C:\\Program Files\\Microsoft SQL Server\\MSSQL13.MSSQLSERVER\\MSSQL\\DATA' ) ;   \nGO  \n-- Enable the server audit.   \nALTER SERVER AUDIT Payrole_Security_Audit   \nWITH (STATE = ON) ;  \n\nUSE AdventureWorks2012 ;   \nGO  \n-- Create the database audit specification.   \nCREATE DATABASE AUDIT SPECIFICATION Audit_Pay_Tables  \nFOR SERVER AUDIT Payrole_Security_Audit  \nADD (SELECT , INSERT  \n     ON HumanResources.EmployeePayHistory BY dbo )   \nWITH (STATE = ON) ;   \nGO"
      },
      {
        "date": "2024-07-07T09:11:00.000Z",
        "voteCount": 1,
        "content": "Answer is correct.\nB. SQL Server audit\nC. database audit specification"
      },
      {
        "date": "2022-07-22T18:30:00.000Z",
        "voteCount": 1,
        "content": "BC, no server audit specification on database audit specification"
      },
      {
        "date": "2022-04-27T16:02:00.000Z",
        "voteCount": 1,
        "content": "i agree with B &amp; C \nSql server Audit to see login activities \n\nC : and the DATABASE AUDIT SPECIFICATION"
      },
      {
        "date": "2022-01-17T06:46:00.000Z",
        "voteCount": 4,
        "content": "Answer Is B&amp;C"
      },
      {
        "date": "2021-06-09T02:32:00.000Z",
        "voteCount": 4,
        "content": "B, C https://solutioncenter.apexsql.com/es/auditoria-de-seguridad-de-bases-de-datos-sql-server/"
      },
      {
        "date": "2021-02-23T17:25:00.000Z",
        "voteCount": 2,
        "content": "B, C https://solutioncenter.apexsql.com/es/auditoria-de-seguridad-de-bases-de-datos-sql-server/"
      },
      {
        "date": "2021-01-09T23:51:00.000Z",
        "voteCount": 8,
        "content": "Database audit specification needs its parent component (Server Audit)\nanswer: B,C"
      },
      {
        "date": "2020-12-24T06:52:00.000Z",
        "voteCount": 2,
        "content": "You can not have a specification until you have created an audit. You cannot create a database level audit only a database level audit specification. You need to create the server level audit (B) first before you can create the specification (C)."
      },
      {
        "date": "2020-10-17T23:57:00.000Z",
        "voteCount": 4,
        "content": "B,C\n In Question clearly stating that SQL Server on Azure VM need  particular on DB level audit(capture the query record ). which can be done by Database level audit specification and that must be linked with Server audit."
      },
      {
        "date": "2020-10-13T04:57:00.000Z",
        "voteCount": 2,
        "content": "A,C\nSQL Server audit lets you create server audits, which can contain server audit specifications for server level events, and database audit"
      },
      {
        "date": "2021-02-11T22:54:00.000Z",
        "voteCount": 2,
        "content": "Then that would be B, C (not A,C)"
      },
      {
        "date": "2020-10-07T05:51:00.000Z",
        "voteCount": 7,
        "content": "The SQL Server in Question is on an Azure VM, so that makes its a regular SQL (not Azure SQL), this should be B and C"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 8,
    "url": "https://www.examtopics.com/discussions/microsoft/view/60454-exam-dp-300-topic-3-question-8-discussion/",
    "body": "You have an Azure virtual machine based on a custom image named VM1.<br>VM1 hosts an instance of Microsoft SQL Server 2019 Standard.<br>You need to automate the maintenance of VM1 to meet the following requirements:<br>\u2711 Automate the patching of SQL Server and Windows Server.<br>\u2711 Automate full database backups and transaction log backups of the databases on VM1.<br>\u2711 Minimize administrative effort.<br>What should you do first?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEnable a system-assigned managed identity for VM1",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRegister the Azure subscription to the Microsoft.Sql resource provider",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tInstall an Azure virtual machine Desired State Configuration (DSC) extension on VM1",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRegister the Azure subscription to the Microsoft.SqlVirtualMachine resource provider"
    ],
    "answer": "D",
    "answerDescription": "Automated Patching depends on the SQL Server infrastructure as a service (IaaS) Agent Extension. The SQL Server IaaS Agent Extension (SqlIaasExtension) runs on Azure virtual machines to automate administration tasks. The SQL Server IaaS extension is installed when you register your SQL Server VM with the SQL<br>Server VM resource provider.<br>To utilize the SQL IaaS Agent extension, you must first register your subscription with the Microsoft.SqlVirtualMachine provider, which gives the SQL IaaS extension the ability to create resources within that specific subscription.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/azure-sql/virtual-machines/windows/sql-server-iaas-agent-extension-automate-management https://docs.microsoft.com/en-us/azure/azure-sql/virtual-machines/windows/sql-agent-extension-manually-register-single-vm?tabs=bash%2Cazure-cli",
    "votes": [],
    "comments": [
      {
        "date": "2021-11-26T01:22:00.000Z",
        "voteCount": 7,
        "content": "Answer is D: https://docs.microsoft.com/en-us/azure/azure-sql/virtual-machines/windows/sql-server-on-azure-vm-iaas-what-is-overview"
      },
      {
        "date": "2021-08-23T23:53:00.000Z",
        "voteCount": 7,
        "content": "correct answer. the correct link is https://docs.microsoft.com/en-us/azure/azure-sql/virtual-machines/windows/sql-agent-extension-manually-register-single-vm?tabs=bash%2Cazure-cli"
      },
      {
        "date": "2023-09-12T12:46:00.000Z",
        "voteCount": 1,
        "content": "To register your SQL Server VM with the extension, you'll need:\n\nAn Azure subscription.\nAn Azure Resource Model supported Windows Server virtual machine with a supported SQL Server version deployed to the public or Azure Government cloud.\nThe client credentials used to register the virtual machine exists in any of the following Azure roles: Virtual Machine contributor, Contributor, or Owner.\nThe latest version of Azure CLI or Azure PowerShell (5.0 minimum).\nA minimum of .NET Framework 4.5.1 or later.\nTo verify that none of the limitations apply to you.\n\nhttps://learn.microsoft.com/en-us/azure/azure-sql/virtual-machines/windows/sql-agent-extension-manually-register-single-vm?view=azuresql&amp;tabs=azure-portal"
      },
      {
        "date": "2023-01-29T13:46:00.000Z",
        "voteCount": 2,
        "content": "To register your SQL Server VM with the SQL IaaS Agent extension, you must first register your subscription with the Microsoft.SqlVirtualMachine resource provider (RP)."
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 9,
    "url": "https://www.examtopics.com/discussions/microsoft/view/61893-exam-dp-300-topic-3-question-9-discussion/",
    "body": "HOTSPOT -<br>You are building an Azure Stream Analytics job to retrieve game data.<br>You need to ensure that the job returns the highest scoring record for each five-minute time interval of each game.<br>How should you complete the Stream Analytics query? To answer, select the appropriate options in the answer area.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04275/0015400001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04275/0015500001.png\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: TopOne() OVER(PARTITION BY Game ORDER BY Score Desc)<br>TopOne returns the top-rank record, where rank defines the ranking position of the event in the window according to the specified ordering. Ordering/ranking is based on event columns and can be specified in ORDER BY clause.<br>Analytic Function Syntax:<br>TopOne() OVER ([&lt;PARTITION BY clause&gt;] ORDER BY (&lt;column name&gt; [ASC |DESC])+ &lt;LIMIT DURATION clause&gt; [&lt;WHEN clause&gt;])<br>Box 2: Tumbling(minute 5)<br>Tumbling window functions are used to segment a data stream into distinct time segments and perform a function against them, such as the example below. The key differentiators of a Tumbling window are that they repeat, do not overlap, and an event cannot belong to more than one tumbling window.<br><img src=\"/assets/media/exam-media/04275/0015600001.jpg\" class=\"in-exam-image\"><br>Reference:<br>https://docs.microsoft.com/en-us/stream-analytics-query/topone-azure-stream-analytics https://github.com/MicrosoftDocs/azure-docs/blob/master/articles/stream-analytics/stream-analytics-window-functions.md",
    "votes": [],
    "comments": [
      {
        "date": "2021-09-12T06:33:00.000Z",
        "voteCount": 16,
        "content": "I got a similar question while taking a DP-203 exam. Don't think this is 100% question for DP-300"
      },
      {
        "date": "2022-04-01T04:58:00.000Z",
        "voteCount": 3,
        "content": "I believe this question is outside the scope of DP-300 and for DP-203."
      },
      {
        "date": "2022-12-20T12:04:00.000Z",
        "voteCount": 3,
        "content": "Answer is correct but it is from dp-203"
      },
      {
        "date": "2022-10-17T03:12:00.000Z",
        "voteCount": 1,
        "content": "Stream Analytics is not part of the DP-300 exam."
      },
      {
        "date": "2021-11-20T16:11:00.000Z",
        "voteCount": 4,
        "content": "The answer looks right"
      },
      {
        "date": "2022-07-30T08:18:00.000Z",
        "voteCount": 5,
        "content": "That looks like your answer to most questions!"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 10,
    "url": "https://www.examtopics.com/discussions/microsoft/view/65833-exam-dp-300-topic-3-question-10-discussion/",
    "body": "A company plans to use Apache Spark analytics to analyze intrusion detection data.<br>You need to recommend a solution to analyze network and system activity data for malicious activities and policy violations. The solution must minimize administrative efforts.<br>What should you recommend?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure Data Lake Storage",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure Databricks\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure HDInsight",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure Data Factory"
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 8,
        "isMostVoted": true
      },
      {
        "answer": "C",
        "count": 5,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2021-11-11T06:38:00.000Z",
        "voteCount": 10,
        "content": "Azure Databricks  is correct. Minimize admon effort is a key word."
      },
      {
        "date": "2022-01-17T07:46:00.000Z",
        "voteCount": 5,
        "content": "Check this out \n\n\n\nAzure HDInsight offers pre-made, monitoring dashboards in the form of solutions that can be used to monitor the workloads running on your clusters. There are solutions for Apache Spark, Hadoop, Apache Kafka, live long and process (LLAP), Apache HBase, and Apache Storm available in the Azure Marketplace. Please see our documentation to learn how to install a monitoring solution. These solutions are workload-specific, allowing you to monitor metrics like  central processing unit (CPU) time, available YARN memory, and logical disk writes across multiple clusters of a given type. Selecting a graph takes you to the query used to generate it, shown in the logs view."
      },
      {
        "date": "2022-01-17T07:45:00.000Z",
        "voteCount": 5,
        "content": "HDInsight monitoring solutions\nAzure HDInsight offers pre-made, monitoring dashboards in the form of solutions that can be used to monitor the workloads running on your clusters. There are solutions for Apache Spark, Hadoop, Apache Kafka, live long and process (LLAP), Apache HBase, and Apache Storm available in the Azure Marketplace. Please see our documentation to learn how to install a monitoring solution. These solutions are workload-specific, allowing you to monitor metrics like  central processing unit (CPU) time, available YARN memory, and logical disk writes across multiple clusters of a given type. Selecting a graph takes you to the query used to generate it, shown in the logs view."
      },
      {
        "date": "2023-09-08T19:42:00.000Z",
        "voteCount": 2,
        "content": "DP-203 question, you can skip."
      },
      {
        "date": "2022-10-28T11:30:00.000Z",
        "voteCount": 2,
        "content": "Azure DataBricks are not part of the DP-300 exam."
      },
      {
        "date": "2022-06-28T06:16:00.000Z",
        "voteCount": 2,
        "content": "Believe the answer is correct as they state that we need to analyze the already acquired Intrusion detection data and not get it"
      },
      {
        "date": "2022-04-29T20:36:00.000Z",
        "voteCount": 2,
        "content": "Intrusion detection is needed to monitor network or system activities for malicious activities or policy violations and produces electronic reports to a management station.\nIntrusion detection is needed to monitor network or system activities for malicious activities or policy violations and produces electronic reports to a management station."
      },
      {
        "date": "2022-04-01T05:00:00.000Z",
        "voteCount": 1,
        "content": "I believe this is a DP-203 question and outside the scope of DP-300"
      },
      {
        "date": "2022-03-13T04:30:00.000Z",
        "voteCount": 2,
        "content": "B. Azure Databricks\n\nThe key point is \"The solution must minimize administrative efforts.\""
      },
      {
        "date": "2022-03-13T04:29:00.000Z",
        "voteCount": 2,
        "content": "B. Azure Databricks\n\nhttps://pages.databricks.com/rs/094-YMS-629/images/FY18_AA_Databricks_e-book_FINAL_032018.pdf\n\nStep 1: Ingest Intrusion detection system Data to Notebook\nStep 2: Enrich the Data to Get Additional Insights to IDS Dataset\nStep 3: Explore IDS Data by Capturing the Type of Attacks on the Network\nStep 4: Visualization\nStep 5: Model Creation"
      },
      {
        "date": "2022-03-07T15:49:00.000Z",
        "voteCount": 2,
        "content": "Azure Databricks\n\nhttps://azure.microsoft.com/es-es/blog/three-critical-analytics-use-cases-with-microsoft-azure-databricks/"
      },
      {
        "date": "2021-11-13T14:35:00.000Z",
        "voteCount": 2,
        "content": "Is B correct?"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 11,
    "url": "https://www.examtopics.com/discussions/microsoft/view/64088-exam-dp-300-topic-3-question-11-discussion/",
    "body": "DRAG DROP -<br>Your company analyzes images from security cameras and sends alerts to security teams that respond to unusual activity. The solution uses Azure Databricks.<br>You need to send Apache Spark level events, Spark Structured Streaming metrics, and application metrics to Azure Monitor.<br>Which three actions should you perform in sequence? To answer, move the appropriate actions from the list of actions in the answer area and arrange them in the correct order.<br>Select and Place:<br><img src=\"/assets/media/exam-media/04275/0015700001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04275/0015800001.png\" class=\"in-exam-image\">",
    "answerDescription": "Send application metrics using Dropwizard.<br>Spark uses a configurable metrics system based on the Dropwizard Metrics Library.<br>To send application metrics from Azure Databricks application code to Azure Monitor, follow these steps:<br>Step 1: Configure your Azure Databricks cluster to use the Databricksmonitoring library.<br>Prerequisite: Configure your Azure Databricks cluster to use the monitoring library.<br>Step 2: Build the spark-listeners-loganalytics-1.0-SNAPSHOT.jar JAR file<br>Step 3: Create Dropwizard counters in your application code<br>Create Dropwizard gauges or counters in your application code<br>Reference:<br>https://docs.microsoft.com/en-us/azure/architecture/databricks-monitoring/application-logs",
    "votes": [],
    "comments": [
      {
        "date": "2021-10-14T07:30:00.000Z",
        "voteCount": 6,
        "content": "is his related to DP-300?"
      },
      {
        "date": "2024-06-28T10:56:00.000Z",
        "voteCount": 1,
        "content": "Its DP-203, but answers are correct"
      },
      {
        "date": "2022-04-01T05:02:00.000Z",
        "voteCount": 5,
        "content": "I believe this is outside the scope of DP-300 and belongs to DP-203"
      },
      {
        "date": "2021-11-13T14:37:00.000Z",
        "voteCount": 1,
        "content": "looks DP-300, what do you think?"
      },
      {
        "date": "2023-09-08T19:42:00.000Z",
        "voteCount": 1,
        "content": "DP-203 question, you can skip."
      },
      {
        "date": "2022-10-28T01:06:00.000Z",
        "voteCount": 1,
        "content": "Azure DataBricks are out of scope of the DP-300 exam."
      },
      {
        "date": "2022-04-30T06:30:00.000Z",
        "voteCount": 1,
        "content": "Answer is correct.\nhttps://docs.microsoft.com/en-us/azure/architecture/databricks-monitoring/application-logs"
      },
      {
        "date": "2022-03-13T04:44:00.000Z",
        "voteCount": 2,
        "content": "-&gt; Configure the Databricks cluster to use the Databricks monitoring library.\n-&gt; Build a spark-listner-lognalytics-1.0-SNAPSHOT.jar JAR file.\n-&gt; Create Dropwizard counters in the application code.\n\nhttps://docs.microsoft.com/en-us/azure/architecture/databricks-monitoring/application-logs"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 12,
    "url": "https://www.examtopics.com/discussions/microsoft/view/65976-exam-dp-300-topic-3-question-12-discussion/",
    "body": "You have an Azure data solution that contains an enterprise data warehouse in Azure Synapse Analytics named DW1.<br>Several users execute adhoc queries to DW1 concurrently.<br>You regularly perform automated data loads to DW1.<br>You need to ensure that the automated data loads have enough memory available to complete quickly and successfully when the adhoc queries run.<br>What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAssign a smaller resource class to the automated data load queries.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate sampled statistics to every column in each table of DW1.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAssign a larger resource class to the automated data load queries.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tHash distribute the large fact tables in DW1 before performing the automated data loads."
    ],
    "answer": "C",
    "answerDescription": "The performance capacity of a query is determined by the user's resource class.<br>Smaller resource classes reduce the maximum memory per query, but increase concurrency.<br>Larger resource classes increase the maximum memory per query, but reduce concurrency.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/synapse-analytics/sql-data-warehouse/resource-classes-for-workload-management",
    "votes": [],
    "comments": [
      {
        "date": "2023-09-08T19:42:00.000Z",
        "voteCount": 2,
        "content": "DP-203 question, you can skip."
      },
      {
        "date": "2022-10-17T03:22:00.000Z",
        "voteCount": 2,
        "content": "Synapse Analytics is not part of the DP-300 exam."
      },
      {
        "date": "2022-04-01T05:03:00.000Z",
        "voteCount": 2,
        "content": "I believe this is outside the scope of DP-300 and belongs to DP-203"
      },
      {
        "date": "2021-11-13T14:38:00.000Z",
        "voteCount": 3,
        "content": "Answer looks correct"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 13,
    "url": "https://www.examtopics.com/discussions/microsoft/view/65977-exam-dp-300-topic-3-question-13-discussion/",
    "body": "You are monitoring an Azure Stream Analytics job.<br>You discover that the Backlogged input Events metric is increasing slowly and is consistently non-zero.<br>You need to ensure that the job can handle all the events.<br>What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRemove any named consumer groups from the connection and use $default.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tChange the compatibility level of the Stream Analytics job.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate an additional output stream for the existing input stream.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tIncrease the number of streaming units (SUs)."
    ],
    "answer": "D",
    "answerDescription": "Backlogged Input Events: Number of input events that are backlogged. A non-zero value for this metric implies that your job isn't able to keep up with the number of incoming events. If this value is slowly increasing or consistently non-zero, you should scale out your job, by increasing the SUs.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-monitoring",
    "votes": [],
    "comments": [
      {
        "date": "2022-04-01T05:03:00.000Z",
        "voteCount": 7,
        "content": "DP-203"
      },
      {
        "date": "2023-09-08T19:42:00.000Z",
        "voteCount": 1,
        "content": "DP-203 question, you can skip."
      },
      {
        "date": "2022-11-30T08:54:00.000Z",
        "voteCount": 2,
        "content": "Azure Stream Analytics is out-of-scope of the DP-300 exam."
      },
      {
        "date": "2021-11-13T14:38:00.000Z",
        "voteCount": 3,
        "content": "looks correct"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 14,
    "url": "https://www.examtopics.com/discussions/microsoft/view/65973-exam-dp-300-topic-3-question-14-discussion/",
    "body": "You have an Azure Stream Analytics job.<br>You need to ensure that the job has enough streaming units provisioned.<br>You configure monitoring of the SU % Utilization metric.<br>Which two additional metrics should you monitor? Each correct answer presents part of the solution.<br>NOTE: Each correct selection is worth one point.<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tLate Input Events",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tOut of order Events",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tBacklogged Input Events\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tWatermark Delay\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tFunction Events"
    ],
    "answer": "CD",
    "answerDescription": "",
    "votes": [
      {
        "answer": "CD",
        "count": 9,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-12-01T09:25:00.000Z",
        "voteCount": 9,
        "content": "watermark and the number of backlogged events\nhttps://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-monitoring\nhttps://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-time-handling"
      },
      {
        "date": "2023-09-08T19:43:00.000Z",
        "voteCount": 2,
        "content": "DP-203 question, you can skip."
      },
      {
        "date": "2022-11-05T05:20:00.000Z",
        "voteCount": 1,
        "content": "Azure Stream Analytics is outside the scope of the DP-300 exam."
      },
      {
        "date": "2022-04-01T05:04:00.000Z",
        "voteCount": 4,
        "content": "DP-203"
      },
      {
        "date": "2021-11-13T14:32:00.000Z",
        "voteCount": 2,
        "content": "its ok?"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 15,
    "url": "https://www.examtopics.com/discussions/microsoft/view/65974-exam-dp-300-topic-3-question-15-discussion/",
    "body": "You have an Azure Databricks resource.<br>You need to log actions that relate to changes in compute for the Databricks resource.<br>Which Databricks services should you log?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tclusters\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tjobs",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDBFS",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSSH",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tworkspace"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 3,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-09-08T19:43:00.000Z",
        "voteCount": 1,
        "content": "DP-203 question, you can skip."
      },
      {
        "date": "2023-03-02T19:59:00.000Z",
        "voteCount": 3,
        "content": "To log actions that relate to changes in compute for an Azure Databricks resource, you should log the clusters service."
      },
      {
        "date": "2022-10-17T03:29:00.000Z",
        "voteCount": 2,
        "content": "DataBricks are outside the scope of the DP-300 exam."
      },
      {
        "date": "2022-04-01T05:04:00.000Z",
        "voteCount": 3,
        "content": "DP-203"
      },
      {
        "date": "2021-11-13T14:33:00.000Z",
        "voteCount": 2,
        "content": "Answer looks correct"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 16,
    "url": "https://www.examtopics.com/discussions/microsoft/view/65975-exam-dp-300-topic-3-question-16-discussion/",
    "body": "Your company uses Azure Stream Analytics to monitor devices.<br>The company plans to double the number of devices that are monitored.<br>You need to monitor a Stream Analytics job to ensure that there are enough processing resources to handle the additional load.<br>Which metric should you monitor?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tInput Deserialization Errors",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tLate Input Events",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEarly Input Events",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tWatermark delay"
    ],
    "answer": "D",
    "answerDescription": "The Watermark delay metric is computed as the wall clock time of the processing node minus the largest watermark it has seen so far.<br>The watermark delay metric can rise due to:<br>1. Not enough processing resources in Stream Analytics to handle the volume of input events.<br>2. Not enough throughput within the input event brokers, so they are throttled.<br>3. Output sinks are not provisioned with enough capacity, so they are throttled.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-time-handling",
    "votes": [],
    "comments": [
      {
        "date": "2023-09-08T19:43:00.000Z",
        "voteCount": 1,
        "content": "DP-203 question, you can skip."
      },
      {
        "date": "2022-10-17T03:30:00.000Z",
        "voteCount": 1,
        "content": "Stream Analytics is not part of the DP-300 exam."
      },
      {
        "date": "2022-04-01T05:04:00.000Z",
        "voteCount": 3,
        "content": "DP-203"
      },
      {
        "date": "2021-11-13T14:33:00.000Z",
        "voteCount": 1,
        "content": "looks correct"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 17,
    "url": "https://www.examtopics.com/discussions/microsoft/view/65835-exam-dp-300-topic-3-question-17-discussion/",
    "body": "You manage an enterprise data warehouse in Azure Synapse Analytics.<br>Users report slow performance when they run commonly used queries. Users do not report performance changes for infrequently used queries.<br>You need to monitor resource utilization to determine the source of the performance issues.<br>Which metric should you monitor?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tLocal tempdb percentage",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDWU percentage",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tData Warehouse Units (DWU) used",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCache hit percentage\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 4,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-09-08T19:43:00.000Z",
        "voteCount": 2,
        "content": "DP-203 question, you can skip."
      },
      {
        "date": "2022-06-23T07:49:00.000Z",
        "voteCount": 2,
        "content": "Answer: D\n\n\n// slow for frequent vs infrequent suggests issues with cache, so answer is D\n// tempdb does not care about frequent vs infrequent"
      },
      {
        "date": "2022-04-01T05:05:00.000Z",
        "voteCount": 3,
        "content": "DP-203"
      },
      {
        "date": "2022-09-17T04:32:00.000Z",
        "voteCount": 2,
        "content": "Yes, this question is for DP-203 exam."
      },
      {
        "date": "2022-03-13T02:30:00.000Z",
        "voteCount": 4,
        "content": "Could be low cache hit ratio, because infrequent queries were already slower, so they don't notice any difference, but regular queries do now.\nCould also be tempdb as suggested, but then infrequent queries would also be affected depending on the query.\nOut of the options and unknowns, I would choose cache hit ratio."
      },
      {
        "date": "2021-11-13T14:33:00.000Z",
        "voteCount": 2,
        "content": "Is D correct?"
      },
      {
        "date": "2021-11-11T06:52:00.000Z",
        "voteCount": 4,
        "content": "D is correct.\nhttps://docs.microsoft.com/da-dk/azure/synapse-analytics/sql-data-warehouse/sql-data-warehouse-how-to-monitor-cache"
      },
      {
        "date": "2021-12-06T23:48:00.000Z",
        "voteCount": 3,
        "content": "If the cache hit ratio is low, it means that new or infrequent queries last a short time in the cache and their performance would be bad, but these types of queries have no problems. Therefore answer D is not correct"
      },
      {
        "date": "2022-08-12T08:20:00.000Z",
        "voteCount": 2,
        "content": "The question does not say that \"infrequent queries\" are good or fast. It says that infrequent queries are unchanged. The issue is that the frequent queries are slower than before, meaning  there are more infrequent queries now or they are more bunched together than before and fill up the cache before the frequent queries have a chance to run. Low cache hit would show it. The solution is a bigger cache or change the run patterns"
      },
      {
        "date": "2022-03-14T05:43:00.000Z",
        "voteCount": 1,
        "content": "Frequent queries performance is also slow so D is wrong I think."
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 18,
    "url": "https://www.examtopics.com/discussions/microsoft/view/62200-exam-dp-300-topic-3-question-18-discussion/",
    "body": "You have an Azure Synapse Analytics dedicated SQL pool named Pool1 and a database named DB1. DB1 contains a fact table named Table.<br>You need to identify the extent of the data skew in Table1.<br>What should you do in Synapse Studio?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConnect to Pool1 and query sys.dm_pdw_nodes_db_partition_stats.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConnect to the built-in pool and run DBCC CHECKALLOC.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConnect to Pool1 and run DBCC CHECKALLOC.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConnect to the built-in pool and query sys.dm_pdw_nodes_db_partition_stats."
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 14,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-09-16T06:44:00.000Z",
        "voteCount": 8,
        "content": "I think the correct answer is A, not D. Don't we have to connect to the dedicated pool to query the stats. DB1 is in a dedicated pool"
      },
      {
        "date": "2021-09-22T12:00:00.000Z",
        "voteCount": 4,
        "content": "It is A."
      },
      {
        "date": "2022-01-09T14:02:00.000Z",
        "voteCount": 6,
        "content": "A is the correct answer."
      },
      {
        "date": "2023-09-08T19:43:00.000Z",
        "voteCount": 3,
        "content": "DP-203 question, you can skip."
      },
      {
        "date": "2022-11-15T06:06:00.000Z",
        "voteCount": 1,
        "content": "DP-203 question."
      },
      {
        "date": "2022-11-05T09:42:00.000Z",
        "voteCount": 1,
        "content": "This question is not part of DP-300 exam."
      },
      {
        "date": "2022-04-30T08:16:00.000Z",
        "voteCount": 2,
        "content": "Use sys.dm_pdw_nodes_db_partition_stats to analyze any skewness in the data."
      },
      {
        "date": "2022-04-01T05:05:00.000Z",
        "voteCount": 3,
        "content": "DP-203"
      },
      {
        "date": "2022-02-22T13:57:00.000Z",
        "voteCount": 2,
        "content": "The table is in Pool1 not the serverless pool"
      },
      {
        "date": "2022-01-22T23:02:00.000Z",
        "voteCount": 4,
        "content": "Option A"
      },
      {
        "date": "2021-11-14T01:17:00.000Z",
        "voteCount": 2,
        "content": "The answer is ok. tou runt the dmv over the database, no in the SQL Pool.\nTo call this from Azure Synapse Analytics or Analytics Platform System (PDW), use the name sys.dm_pdw_nodes_db_partition_stats. The partition_id in sys.dm_pdw_nodes_db_partition_stats differs from the partition_id in the sys.partitions catalog view for Azure Synapse Analytics. This syntax is not supported by serverless SQL pool in Azure Synapse\nhttps://docs.microsoft.com/en-us/sql/relational-databases/system-dynamic-management-views/sys-dm-db-partition-stats-transact-sql?view=sql-server-ver15"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 19,
    "url": "https://www.examtopics.com/discussions/microsoft/view/65916-exam-dp-300-topic-3-question-19-discussion/",
    "body": "You have an Azure Synapse Analytics dedicated SQL pool.<br>You run PDW_SHOWSPACEUSED('dbo.FactInternetSales'); and get the results shown in the following table.<br><img src=\"/assets/media/exam-media/04275/0016400001.png\" class=\"in-exam-image\"><br>Which statement accurately describes the dbo.FactInternetSales table?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tThe table contains less than 10,000 rows.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAll distributions contain data.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tThe table uses round-robin distribution",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tThe table is skewed."
    ],
    "answer": "D",
    "answerDescription": "The rows per distribution can vary up to 10% without a noticeable impact on performance. Here the distribution varies more than 10%. It is skewed.<br>Note: SHOWSPACEUSED displays the number of rows, disk space reserved, and disk space used for a specific table, or for all tables in a Azure Synapse<br>Analytics or Parallel Data Warehouse database.<br>This is a very quick and simple way to see the number of table rows that are stored in each of the 60 distributions of your database. Remember that for the most balanced performance, the rows in your distributed table should be spread evenly across all the distributions.<br>ROUND_ROBIN distributed tables should not be skewed. Data is distributed evenly across the nodes by design.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/synapse-analytics/sql-data-warehouse/sql-data-warehouse-tables-distribute https://github.com/rgl/azure-content/blob/master/articles/sql-data-warehouse/sql-data-warehouse-manage-distributed-data-skew.md",
    "votes": [],
    "comments": [
      {
        "date": "2023-09-08T19:43:00.000Z",
        "voteCount": 3,
        "content": "DP-203 question, you can skip."
      },
      {
        "date": "2022-09-17T05:08:00.000Z",
        "voteCount": 2,
        "content": "This question is for DP-203 exam (Data Engineering on Microsoft Azure)"
      },
      {
        "date": "2021-11-12T16:05:00.000Z",
        "voteCount": 4,
        "content": "looks good, what do you think?"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 20,
    "url": "https://www.examtopics.com/discussions/microsoft/view/65919-exam-dp-300-topic-3-question-20-discussion/",
    "body": "DRAG DROP -<br>You have an Azure SQL managed instance named SQLMI1 that has Resource Governor enabled and is used by two apps named App1 and App2.<br>You need to configure SQLMI1 to limit the CPU and memory resources that can be allocated to App1.<br>Which four actions should you perform in sequence? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.<br>Select and Place:<br><img src=\"/assets/media/exam-media/04275/0016500001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04275/0016600001.png\" class=\"in-exam-image\">",
    "answerDescription": "Reference:<br>https://docs.microsoft.com/en-us/sql/relational-databases/resource-governor/resource-governor?view=sql-server-ver15 https://docs.microsoft.com/en-us/sql/relational-databases/resource-governor/create-and-test-a-classifier-user-defined-function?view=sql-server-ver15",
    "votes": [],
    "comments": [
      {
        "date": "2022-03-13T02:46:00.000Z",
        "voteCount": 13,
        "content": "Correct order:\n1 The resource pool provides and limits the resources required by the application\n2 The workload group uses the resource pool it is associated with\n3 The classifier function assign the incoming session to the workload group\n4 Modify resource governor to apply configuration changes"
      },
      {
        "date": "2023-07-15T10:53:00.000Z",
        "voteCount": 2,
        "content": "https://learn.microsoft.com/en-us/sql/-databases/resource-governor/create-and-test-a-classifier-user-defined-function?view=sql-server-ver16\nCREATE RESOURCE POOL\nCREATE WORKLOAD GROUP\nCreate the classifier function\nALTER RESOURCE GOVERNOR RECONFIGURE;  \nGO"
      },
      {
        "date": "2023-07-15T10:42:00.000Z",
        "voteCount": 1,
        "content": "https://learn.microsoft.com/en-us/training/modules/configure-sql-server-resources-optimal-performance/5-control"
      },
      {
        "date": "2022-03-21T10:32:00.000Z",
        "voteCount": 2,
        "content": "The Answer is Correct: \n1. Create resource pools\n2. Create workload groups\n3. Create Classifier Function\n4. Register this classified function"
      },
      {
        "date": "2021-11-12T16:07:00.000Z",
        "voteCount": 3,
        "content": "looks good, what do you think?"
      },
      {
        "date": "2021-12-05T04:39:00.000Z",
        "voteCount": 4,
        "content": "looks good, my G."
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 21,
    "url": "https://www.examtopics.com/discussions/microsoft/view/65918-exam-dp-300-topic-3-question-21-discussion/",
    "body": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.<br>After you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.<br>You have SQL Server 2019 on an Azure virtual machine.<br>You are troubleshooting performance issues for a query in a SQL Server instance.<br>To gather more information, you query sys.dm_exec_requests and discover that the wait type is PAGELATCH_UP and the wait_resource is 2:3:905856.<br>You need to improve system performance.<br>Solution: You shrink the transaction log file.<br>Does this meet the goal?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tYes",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tNo\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 5,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2022-01-11T12:05:00.000Z",
        "voteCount": 5,
        "content": "B is correct, related to tempdb performance, see article from solution"
      },
      {
        "date": "2022-12-02T17:24:00.000Z",
        "voteCount": 1,
        "content": "B is correct\nPAGELATCH_UP: An operation is waiting for an update latch on an in-memory page. Update latches are commonly used when there\u2019s row versioning activity in tempdb, or when system allocation pages are being updated\nhttps://documentation.red-gate.com/sm4/working-with-overviews/using-performance-diagnostics/list-of-common-wait-types/pagelatch_up"
      },
      {
        "date": "2021-11-12T16:06:00.000Z",
        "voteCount": 3,
        "content": "Answer looks correct"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 22,
    "url": "https://www.examtopics.com/discussions/microsoft/view/62777-exam-dp-300-topic-3-question-22-discussion/",
    "body": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.<br>After you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.<br>You have SQL Server 2019 on an Azure virtual machine.<br>You are troubleshooting performance issues for a query in a SQL Server instance.<br>To gather more information, you query sys.dm_exec_requests and discover that the wait type is PAGELATCH_UP and the wait_resource is 2:3:905856.<br>You need to improve system performance.<br>Solution: You change the data file for the master database to autogrow by 10 percent.<br>Does this meet the goal?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tYes",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tNo"
    ],
    "answer": "B",
    "answerDescription": "You should instead reduce the use of table variables and temporary tables.<br>Or you could create additional tempdb files<br>Note: The following operations use tempdb extensively:<br>* Repetitive create-and-drop operation of temporary tables (local or global).<br>* Table variables that use tempdb for storage.<br>* Etc.<br>Reference:<br>https://docs.microsoft.com/en-US/troubleshoot/sql/performance/recommendations-reduce-allocation-contention",
    "votes": [],
    "comments": [
      {
        "date": "2021-09-27T04:21:00.000Z",
        "voteCount": 6,
        "content": "Given answer is correct."
      },
      {
        "date": "2023-09-08T19:57:00.000Z",
        "voteCount": 1,
        "content": "repeated question"
      },
      {
        "date": "2023-09-08T19:59:00.000Z",
        "voteCount": 1,
        "content": "sorry, no, actually \"solution\" part changes"
      },
      {
        "date": "2022-10-11T10:14:00.000Z",
        "voteCount": 2,
        "content": "PAGELATCH_UP is often related to tempDb contention."
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 23,
    "url": "https://www.examtopics.com/discussions/microsoft/view/65495-exam-dp-300-topic-3-question-23-discussion/",
    "body": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.<br>After you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.<br>You have SQL Server 2019 on an Azure virtual machine.<br>You are troubleshooting performance issues for a query in a SQL Server instance.<br>To gather more information, you query sys.dm_exec_requests and discover that the wait type is PAGELATCH_UP and the wait_resource is 2:3:905856.<br>You need to improve system performance.<br>Solution: You reduce the use of table variables and temporary tables.<br>Does this meet the goal?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tYes",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tNo"
    ],
    "answer": "A",
    "answerDescription": "The following operations use tempdb extensively:<br>* Repetitive create-and-drop operation of temporary tables (local or global).<br>* Table variables that use tempdb for storage.<br>* Etc.<br>Reference:<br>https://docs.microsoft.com/en-US/troubleshoot/sql/performance/recommendations-reduce-allocation-contention",
    "votes": [],
    "comments": [
      {
        "date": "2021-11-05T03:23:00.000Z",
        "voteCount": 7,
        "content": "Answer A is correct, other questions in the series have answer B - No. The case is about tempdb problem.\nhttps://docs.microsoft.com/en-us/troubleshoot/sql/performance/recommendations-reduce-allocation-contention"
      },
      {
        "date": "2022-10-22T06:51:00.000Z",
        "voteCount": 3,
        "content": "In the series of these questions there is another Solution: \n\"You create additional tempdb files.\"\nAs per my understanding there could only by one Yes and all No in the series so is this answer Yes or it is Yes for the Solution: \"you create additional tempdb files.\""
      },
      {
        "date": "2022-10-11T10:15:00.000Z",
        "voteCount": 4,
        "content": "Is for TempDb contention, and in this scenario is better reduce use of table variables and temporary tables."
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 24,
    "url": "https://www.examtopics.com/discussions/microsoft/view/60362-exam-dp-300-topic-3-question-24-discussion/",
    "body": "You have an Azure SQL database named db1 on a server named server1.<br>You need to modify the MAXDOP settings for db1.<br>What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConnect to db1 and run the sp_configure command.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConnect to the master database of server1 and run the sp_configure command.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure the extended properties of db1.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tModify the database scoped configuration of db1.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 5,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-11-03T00:41:00.000Z",
        "voteCount": 6,
        "content": "Given answer is correct: https://docs.microsoft.com/en-us/sql/t-sql/statements/alter-database-scoped-configuration-transact-sql?view=sql-server-ver15"
      },
      {
        "date": "2022-04-30T08:55:00.000Z",
        "voteCount": 3,
        "content": "In Azure SQL Database, you can change the default MAXDOP value:\n\nAt the query level, using the MAXDOP query hint.\nAt the database level, using the MAXDOP database scoped configuration.\nhttps://docs.microsoft.com/en-us/azure/azure-sql/database/configure-max-degree-of-parallelism?view=azuresql"
      },
      {
        "date": "2022-04-27T16:16:00.000Z",
        "voteCount": 2,
        "content": "https://docs.microsoft.com/en-us/sql/t-sql/statements/alter-database-scoped-configuration-transact-sql?view=sql-server-ver15"
      },
      {
        "date": "2021-08-23T03:14:00.000Z",
        "voteCount": 2,
        "content": "Answer A : Connect to db1 and run sp_configure\nhttps://docs.microsoft.com/en-us/sql/database-engine/configure-windows/configure-the-max-degree-of-parallelism-server-configuration-option?view=sql-server-ver15"
      },
      {
        "date": "2021-08-29T00:03:00.000Z",
        "voteCount": 14,
        "content": "The question is directed for Azure SQL database. Your link is applicable to SQL Server. Answer is correct."
      },
      {
        "date": "2021-11-14T01:51:00.000Z",
        "voteCount": 3,
        "content": "The answer is D. The answer b it nos posible because sp_configure is a server level, no database level.\nthe syntax for database level it the next\n\n-- Syntax for SQL Server, Azure SQL Database and Azure SQL Managed Instance\n\nALTER DATABASE SCOPED CONFIGURATION\n{\n    { [ FOR SECONDARY] SET &lt;set_options&gt;}\n}\n| CLEAR PROCEDURE_CACHE [plan_handle]\n| SET &lt; set_options &gt;\n[;]\n\n&lt; set_options &gt; ::=\n{\n    MAXDOP = { &lt;value&gt; | PRIMARY}\n    | LEGACY_CARDINALITY_ESTIMATION = { ON | OFF | PRIMARY}"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 25,
    "url": "https://www.examtopics.com/discussions/microsoft/view/65914-exam-dp-300-topic-3-question-25-discussion/",
    "body": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.<br>After you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.<br>You have SQL Server 2019 on an Azure virtual machine.<br>You are troubleshooting performance issues for a query in a SQL Server instance.<br>To gather more information, you query sys.dm_exec_requests and discover that the wait type is PAGELATCH_UP and the wait_resource is 2:3:905856.<br>You need to improve system performance.<br>Solution: You create additional tempdb files.<br>Does this meet the goal?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tYes",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tNo"
    ],
    "answer": "A",
    "answerDescription": "To improve the concurrency of tempdb, try the following methods:<br>* Increase the number of data files in tempdb to maximize disk bandwidth and reduce contention in allocation structures.<br>* Etc.<br><br>Note: Symptoms -<br>On a server that is running Microsoft SQL Server, you notice severe blocking when the server is experiencing a heavy load. Dynamic Management Views<br>[sys.dm_exec_request or sys.dm_os_waiting_tasks] indicates that these requests or tasks are waiting for tempdb resources. Additionally, the wait type is<br>PAGELATCH_UP, and the wait resource points to pages in Tempdb.<br>Reference:<br>https://docs.microsoft.com/en-US/troubleshoot/sql/performance/recommendations-reduce-allocation-contention",
    "votes": [],
    "comments": [
      {
        "date": "2021-11-12T15:36:00.000Z",
        "voteCount": 1,
        "content": "its ok?"
      },
      {
        "date": "2021-12-11T11:54:00.000Z",
        "voteCount": 8,
        "content": "Yes, adding more tempdb files decrease contention on tempdb.\nhttps://docs.microsoft.com/en-US/troubleshoot/sql/performance/recommendations-reduce-allocation-contention"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 26,
    "url": "https://www.examtopics.com/discussions/microsoft/view/65911-exam-dp-300-topic-3-question-26-discussion/",
    "body": "You have SQL Server on an Azure virtual machine.<br>You need to add a 4-TB volume that meets the following requirements:<br>\u2711 Maximizes IOPs<br>\u2711 Uses premium solid state drives (SSDs)<br>What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAttach two mirrored 4-TB SSDs.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAttach a stripe set that contains four 1-TB SSDs.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAttach a RAID-5 array that contains five 1-TB SSDs.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAttach a single 4-TB SSD."
    ],
    "answer": "B",
    "answerDescription": "For more throughput, you can add additional data disks and use disk striping.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/azure-sql/virtual-machines/windows/storage-configuration?tabs=windows2016",
    "votes": [],
    "comments": [
      {
        "date": "2022-10-11T10:30:00.000Z",
        "voteCount": 8,
        "content": "When you see \"Maximizes IOPs\" choose Striping, is the better solution."
      },
      {
        "date": "2021-12-11T12:08:00.000Z",
        "voteCount": 2,
        "content": "Out of all options, this should provide the best performance:\nhttps://docs.microsoft.com/en-us/azure/azure-sql/virtual-machines/windows/performance-guidelines-best-practices-storage"
      },
      {
        "date": "2021-12-11T12:10:00.000Z",
        "voteCount": 3,
        "content": "So the answer on striping seems correct to me."
      },
      {
        "date": "2021-11-12T14:44:00.000Z",
        "voteCount": 3,
        "content": "Answer looks correct"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 27,
    "url": "https://www.examtopics.com/discussions/microsoft/view/65912-exam-dp-300-topic-3-question-27-discussion/",
    "body": "You have an Azure SQL database named db1 on a server named server1.<br>The Intelligent Insights diagnostics log identifies that several tables are missing indexes.<br>You need to ensure that indexes are created for the tables.<br>What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRun the DBCC SQLPERF command.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRun the DBCC DBREINDEX command.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tModify the automatic tuning settings for db1.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tModify the Query Store settings for db1."
    ],
    "answer": "C",
    "answerDescription": "Automatic tuning is a fully managed intelligent performance service that uses built-in intelligence to continuously monitor queries executed on a database, and it automatically improves their performance.<br>Automatic tuning for Azure SQL Database uses the CREATE INDEX, DROP INDEX, and FORCE LAST GOOD PLAN database advisor recommendations to optimize your database performance.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/azure-sql/database/automatic-tuning-overview",
    "votes": [],
    "comments": [
      {
        "date": "2023-07-15T11:15:00.000Z",
        "voteCount": 1,
        "content": "https://learn.microsoft.com/en-us/training/modules/configure-databases-for-optimal-performance/4-describe-automatic-tuning"
      },
      {
        "date": "2022-10-11T08:48:00.000Z",
        "voteCount": 3,
        "content": "Automatic tuning is capable of seamlessly tuning hundreds of thousands of databases without affecting performance of the existing workloads. The solution has been globally available since 2016 and proven to enable performant and stable workloads while reducing resource consumption on Azure."
      },
      {
        "date": "2021-11-12T14:44:00.000Z",
        "voteCount": 3,
        "content": "Answer looks correct"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 28,
    "url": "https://www.examtopics.com/discussions/microsoft/view/65913-exam-dp-300-topic-3-question-28-discussion/",
    "body": "You have an Azure SQL managed instance named SQL1 and two Azure web apps named App1 and App2.<br>You need to limit the number of IOPs that App2 queries generate on SQL1.<br>Which two actions should you perform on SQL1? Each correct answer presents part of the solution.<br>NOTE: Each correct selection is worth one point.<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEnable query optimizer fixes.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEnable Resource Governor.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEnable parameter sniffing.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a workload group.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure In-memory OLTP.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"F\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tF.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRun the Database Engine Tuning Advisor.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"G\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tG.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tReduce the Max Degree of Parallelism value."
    ],
    "answer": "BD",
    "answerDescription": "",
    "votes": [
      {
        "answer": "BD",
        "count": 12,
        "isMostVoted": true
      },
      {
        "answer": "BC",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2022-01-21T18:16:00.000Z",
        "voteCount": 9,
        "content": "The given answer is correct."
      },
      {
        "date": "2023-06-12T13:11:00.000Z",
        "voteCount": 1,
        "content": "Per ChatGPT, BD is the correct answer."
      },
      {
        "date": "2022-04-27T16:19:00.000Z",
        "voteCount": 3,
        "content": "The given answer is correct."
      },
      {
        "date": "2022-02-03T04:12:00.000Z",
        "voteCount": 4,
        "content": "Answer is B and D from what I understood.\n\nFrom Microsoft docs:\nResource Governance\nTo enforce resource limits, Azure SQL Database uses a resource governance implementation that is based on SQL Server Resource Governor, modified and extended to run in the cloud. In SQL Database, multiple resource pools and workload groups, with resource limits set at both pool and group levels, provide a balanced\nDatabase-as-a-Service. User workload and internal workloads are classified into separate resource pools and workload groups. User workload on the primary and readable secondary replicas, including geo-replicas, is classified into the SloSharedPool1 resource pool and UserPrimaryGroup.DBId[N] workload groups, where [N] stands for the database ID value. In addition, there are multiple resource pools and workload groups for various\ninternal workloads."
      },
      {
        "date": "2022-01-02T10:15:00.000Z",
        "voteCount": 3,
        "content": "The answer is correc."
      },
      {
        "date": "2021-12-08T08:34:00.000Z",
        "voteCount": 1,
        "content": "Resource Governor + parameter sniffing"
      },
      {
        "date": "2021-12-09T07:53:00.000Z",
        "voteCount": 3,
        "content": "parameter sniffing what relation have to it ??\nit means that SP could be run w/o re-compiles"
      },
      {
        "date": "2021-11-12T14:44:00.000Z",
        "voteCount": 2,
        "content": "Answer looks correct"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 29,
    "url": "https://www.examtopics.com/discussions/microsoft/view/74978-exam-dp-300-topic-3-question-29-discussion/",
    "body": "You have an Azure SQL database named db1 on a server named server1.<br>The Intelligent Insights diagnostics log identifies queries that cause performance issues due to tempDB contention.<br>You need to resolve the performance issues.<br>What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tImplement memory-optimized tables.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRun the DBCC FLUSHPROCINDB command.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tReplace the sequential index keys with nonsequential keys.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRun the DBCC DBREINDEX command."
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 11,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2022-10-17T04:35:00.000Z",
        "voteCount": 7,
        "content": "TempDB contention -&gt; memory-optimized tables or reducing temporary tables or variables."
      },
      {
        "date": "2022-04-30T09:22:00.000Z",
        "voteCount": 4,
        "content": "TempDB contention\nThe diagnostics log outputs tempDB contention details. You can use the information as the starting point for troubleshooting. There are two things you can pursue to alleviate this kind of contention and increase the throughput of the overall workload: You can stop using the temporary tables. You also can use memory-optimized tables."
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 30,
    "url": "https://www.examtopics.com/discussions/microsoft/view/74980-exam-dp-300-topic-3-question-30-discussion/",
    "body": "HOTSPOT -<br>You have an Azure subscription that contains an Azure SQL database.<br>The database fails to respond to queries in a timely manner.<br>You need to identify whether the issue relates to resource_semaphore waits.<br>How should you complete the Transact-SQL query? To answer, select the appropriate options in the answer area.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04275/0017400001.jpg\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04275/0017500001.jpg\" class=\"in-exam-image\">",
    "answerDescription": "If your top wait type is RESOURCE_SEMAHPORE and you don't have a high CPU usage issue, you may have a memory grant waiting issue.<br>Determine if a RESOURCE_SEMAHPORE wait is a top wait<br>Use the following query to determine if a RESOURCE_SEMAHPORE wait is a top wait<br>SELECT wait_type,<br>SUM(wait_time) AS total_wait_time_ms<br>FROM sys.dm_exec_requests AS req<br>JOIN sys.dm_exec_sessions AS sess<br>ON req.session_id = sess.session_id<br><br>WHERE is_user_process = 1 -<br><br>GROUP BY wait_type -<br>ORDER BY SUM(wait_time) DESC;<br>Reference:<br>https://docs.microsoft.com/en-us/azure/azure-sql/database/monitoring-with-dmvs",
    "votes": [],
    "comments": [
      {
        "date": "2024-09-08T08:41:00.000Z",
        "voteCount": 1,
        "content": "The answer is correct!"
      },
      {
        "date": "2022-12-02T17:53:00.000Z",
        "voteCount": 2,
        "content": "Answer is correct\nIn addition, sys.query_store_query table does not have column session_id required for the join in the query"
      },
      {
        "date": "2022-11-12T05:16:00.000Z",
        "voteCount": 3,
        "content": "https://www.sqlshack.com/sql-server-performance-tuning-resource_semaphore-waits/"
      },
      {
        "date": "2022-04-30T09:29:00.000Z",
        "voteCount": 2,
        "content": "Answer is correct"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 31,
    "url": "https://www.examtopics.com/discussions/microsoft/view/85170-exam-dp-300-topic-3-question-31-discussion/",
    "body": "You have SQL Server 2019 on an Azure virtual machine that runs Windows Server 2019. The virtual machine has 4 vCPUs and 28 GB of memory.<br>You scale up the virtual machine to 8 vCPUs and 64 GB of memory.<br>You need to reduce tempdb contention without negatively affecting server performance.<br>What is the number of secondary data files that you should configure for tempdb?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t2",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t4\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t8\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t64"
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 5,
        "isMostVoted": true
      },
      {
        "answer": "B",
        "count": 4,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-10-05T08:21:00.000Z",
        "voteCount": 1,
        "content": "C is the right answer"
      },
      {
        "date": "2024-06-22T13:46:00.000Z",
        "voteCount": 2,
        "content": "C is the right answer , please refer JerryChan and Skaeakus91 comments"
      },
      {
        "date": "2024-06-22T04:14:00.000Z",
        "voteCount": 3,
        "content": "Answer is: C\n\nTo reduce tempdb contention without negatively affecting server performance, it is recommended to configure as many secondary data files as there are CPU cores up to a maximum of 8. This can help distribute the workload and reduce contention on tempdb."
      },
      {
        "date": "2024-01-14T08:39:00.000Z",
        "voteCount": 2,
        "content": "Answer should be C"
      },
      {
        "date": "2023-09-18T02:23:00.000Z",
        "voteCount": 1,
        "content": "The number of secondary data files depends on the number of (logical) processors on the machine. As a general rule, if the number of logical processors is less than or equal to eight, use the same number of data files as logical processors. If the number of logical processors is greater than eight, use eight data files. Then if contention continues, increase the number of data files by multiples of four until the contention decreases to acceptable levels, or make changes to the workload/code.\n\nSo answer should be C.8"
      },
      {
        "date": "2023-08-13T17:16:00.000Z",
        "voteCount": 1,
        "content": "Is the question being asked is total number of tempdb files or additional tempdb files to be configured?"
      },
      {
        "date": "2023-03-15T11:57:00.000Z",
        "voteCount": 4,
        "content": "I think the correct answer is B), because you should have 8 data files for 8vCPU in total, but you already have some data files and you just need to add/configure extra secondary files"
      },
      {
        "date": "2023-03-15T11:53:00.000Z",
        "voteCount": 1,
        "content": "I think the correct answer is B), because you should have 8 data files for 8vCPU in total, but you already have some data files and you just need to add/configure extra secondary files."
      },
      {
        "date": "2022-10-11T09:17:00.000Z",
        "voteCount": 2,
        "content": "There should be one TempDB data file for each thread/core/vCPU on the instance with a maximum of 8."
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 32,
    "url": "https://www.examtopics.com/discussions/microsoft/view/45610-exam-dp-300-topic-3-question-32-discussion/",
    "body": "You receive numerous alerts from Azure Monitor for an Azure SQL Database instance.<br>You need to reduce the number of alerts. You must only receive alerts if there is a significant change in usage patterns for an extended period.<br>Which two actions should you perform? Each correct answer presents part of the solution.<br>NOTE: Each correct selection is worth one point.<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSet Threshold Sensitivity to High",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSet the Alert logic threshold to Dynamic",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSet the Alert logic threshold to Static",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSet Threshold Sensitivity to Low",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSet Force Plan to On"
    ],
    "answer": "BD",
    "answerDescription": "B: Dynamic Thresholds continuously learns the data of the metric series and tries to model it using a set of algorithms and methods. It detects patterns in the data such as seasonality (Hourly / Daily / Weekly), and is able to handle noisy metrics (such as machine CPU or memory) as well as metrics with low dispersion (such as availability and error rate).<br>D: Alert threshold sensitivity is a high-level concept that controls the amount of deviation from metric behavior required to trigger an alert.<br>Low \u05d2\u20ac\" The thresholds will be loose with more distance from metric series pattern. An alert rule will only trigger on large deviations, resulting in fewer alerts.<br>Incorrect Answers:<br>A: High \u05d2\u20ac\" The thresholds will be tight and close to the metric series pattern. An alert rule will be triggered on the smallest deviation, resulting in more alerts.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/azure-monitor/platform/alerts-dynamic-thresholds",
    "votes": [],
    "comments": [
      {
        "date": "2021-03-09T05:30:00.000Z",
        "voteCount": 33,
        "content": "B and D make the most sense and will generate the least amount of alerts."
      },
      {
        "date": "2021-09-16T23:31:00.000Z",
        "voteCount": 3,
        "content": "If you are using a Static threshold, continue to define a Threshold value. The metric chart can help determine what might be a reasonable threshold.\nIf you are using a Dynamic threshold, continue to define the Threshold sensitivity. The metric chart will display the calculated thresholds based on recent data. \nhttps://docs.microsoft.com/en-us/azure/azure-monitor/alerts/alerts-metric"
      },
      {
        "date": "2021-09-16T23:21:00.000Z",
        "voteCount": 1,
        "content": "Dynamic threshold alert rules can create tailored thresholds for hundreds of metric series at a time, yet providing the same ease of defining an alert rule on a single metric. They give you fewer alerts to create and manage. You can use either Azure portal or the Azure Resource Manager API to create them. The scalable approach is especially useful when dealing with metric dimensions or when applying to multiple resources, such as to all subscription resources."
      },
      {
        "date": "2021-08-13T20:25:00.000Z",
        "voteCount": 1,
        "content": "The correct Answer is B &amp; D. simple example, try to apply \"configure signal logic\" in PAAS."
      },
      {
        "date": "2021-03-01T11:34:00.000Z",
        "voteCount": 1,
        "content": "correct answer: B and C\nWhat does 'Sensitivity' setting in Dynamic Thresholds mean?\nAlert threshold sensitivity is a high-level concept that controls the amount of deviation from metric behavior required to trigger an alert. This option doesn't require domain knowledge about the metric like static threshold. The options available are:\n\nHigh \u2013 The thresholds will be tight and close to the metric series pattern. An alert rule will be triggered on the smallest deviation, resulting in more alerts.\nMedium \u2013 Less tight and more balanced thresholds, fewer alerts than with high sensitivity (default).\nLow \u2013 The thresholds will be loose with more distance from metric series pattern. An alert rule will only trigger on large deviations, resulting in fewer alerts."
      },
      {
        "date": "2021-02-25T11:38:00.000Z",
        "voteCount": 2,
        "content": "I would go for A and B since the remaining answers does not make sense to me"
      },
      {
        "date": "2021-04-06T10:01:00.000Z",
        "voteCount": 4,
        "content": "If the sensitivity is high that will generate MORE alerts."
      },
      {
        "date": "2022-08-25T20:05:00.000Z",
        "voteCount": 1,
        "content": "I concur!"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 33,
    "url": "https://www.examtopics.com/discussions/microsoft/view/44365-exam-dp-300-topic-3-question-33-discussion/",
    "body": "You have an Azure SQL database named sqldb1.<br>You need to minimize the amount of space by the data and log files of sqldb1.<br>What should you run?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDBCC SHRINKDATABASE",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tsp_clean_db_free_space",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tsp_clean_db_file_free_space",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDBCC SHRINKFILE"
    ],
    "answer": "A",
    "answerDescription": "DBCC SHRINKDATABASE shrinks the size of the data and log files in the specified database.<br>Incorrect Answers:<br>D: To shrink one data or log file at a time for a specific database, execute the DBCC SHRINKFILE command.<br>Reference:<br>https://docs.microsoft.com/en-us/sql/t-sql/database-console-commands/dbcc-shrinkdatabase-transact-sql",
    "votes": [],
    "comments": [
      {
        "date": "2021-02-19T00:07:00.000Z",
        "voteCount": 18,
        "content": "Azure SQL database supports:\nDBCC SHRINKDATABASE (N'db1');"
      },
      {
        "date": "2024-06-28T12:11:00.000Z",
        "voteCount": 1,
        "content": "I agree on this, because SHRINKFILE provides more control, but here question asks for Data and Logs files not a single or set of files. So Better to use SHRINKDATABASE, run and prepare coffee and enjoy the wait."
      },
      {
        "date": "2021-02-09T07:44:00.000Z",
        "voteCount": 6,
        "content": "https://docs.microsoft.com/en-us/azure/azure-sql/database/file-space-manage"
      },
      {
        "date": "2023-02-21T23:16:00.000Z",
        "voteCount": 3,
        "content": "For an Azure SQL database, it's generally not recommended to use DBCC SHRINKDATABASE (option A) as it can cause performance issues and should only be used as a last resort. Instead, DBCC SHRINKFILE (option D) is the preferred option to minimize the amount of space used by the data and log files of an Azure SQL database."
      },
      {
        "date": "2023-01-29T14:22:00.000Z",
        "voteCount": 1,
        "content": "DBCC SHRINKDATABASE shrinks all data and log files in a database using a single command. The command shrinks one data file at a time, which can take a long time for larger databases. It also shrinks the log file, which is usually unnecessary because Azure SQL Database shrinks log files automatically as needed."
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 34,
    "url": "https://www.examtopics.com/discussions/microsoft/view/47415-exam-dp-300-topic-3-question-34-discussion/",
    "body": "You have an Azure SQL Database server named sqlsrv1 that hosts 10 Azure SQL databases.<br>The databases perform slower than expected.<br>You need to identify whether the performance issue relates to the use of tempdb by Azure SQL databases in sqlsrv1.<br>What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRun Query Store-based queries",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tReview information provided by SQL Server Profiler-based traces",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tReview information provided by Query Performance Insight",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRun dynamic management view-based queries\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 9,
        "isMostVoted": true
      },
      {
        "answer": "C",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2021-03-17T12:36:00.000Z",
        "voteCount": 26,
        "content": "I believe D is right based on https://docs.microsoft.com/en-us/azure/azure-sql/database/monitoring-with-dmvs#identify-tempdb-performance-issues"
      },
      {
        "date": "2021-03-20T10:05:00.000Z",
        "voteCount": 1,
        "content": "Agreed.\n\n\"Intelligent Insights\" would be the right choice for tempdb contention troubleshooting, if it were an option. However, in this question, we have \"Query Performance Insight\" as an option, which isn't suitable."
      },
      {
        "date": "2021-03-31T01:52:00.000Z",
        "voteCount": 1,
        "content": "I was wrong. Answer is \"C\"."
      },
      {
        "date": "2021-04-13T21:25:00.000Z",
        "voteCount": 8,
        "content": "Just checked my Azure Database, \"Query Performance Insight\" only provides CPU, Data IO, Log IO, Duration, and Execution count information. Answer C is not correct."
      },
      {
        "date": "2021-11-23T10:09:00.000Z",
        "voteCount": 2,
        "content": "Correct Ans is D"
      },
      {
        "date": "2021-08-23T23:30:00.000Z",
        "voteCount": 6,
        "content": "This is the trick. \"whether the performance issue relates to the use of tempdb\"!  therefore, we need to look at the trend. Option C is the right answer."
      },
      {
        "date": "2023-08-25T01:04:00.000Z",
        "voteCount": 1,
        "content": "the question is simple: identify IF tempdb is the issue.\nhttps://learn.microsoft.com/en-us/azure/azure-sql/database/intelligent-insights-troubleshoot-performance?view=azuresql - \"TempDB contention\nWhat is happening\nThis detectable performance pattern indicates a database performance condition in which a bottleneck of threads trying to access tempdb resources exists. (This condition isn't IO-related.) The typical scenario for this performance issue is hundreds of concurrent queries that all create, use, and then drop small tempdb tables. The system detected that the number of concurrent queries using the same tempdb tables increased with sufficient statistical significance to affect database performance compared to the past seven-day performance baseline.\"\nSo it it the Insight, not DMVs."
      },
      {
        "date": "2022-07-02T09:45:00.000Z",
        "voteCount": 1,
        "content": "Right answer is D as per link:  https://docs.microsoft.com/en-us/azure/azure-sql/database/monitoring-with-dmvs?view=azuresql#identify-tempdb-performance-issues"
      },
      {
        "date": "2022-04-29T06:27:00.000Z",
        "voteCount": 1,
        "content": "Troubleshoot Azure SQL Database and Azure SQL Managed Instance performance issues with Intelligent Insights"
      },
      {
        "date": "2022-04-29T06:27:00.000Z",
        "voteCount": 2,
        "content": "(1) Option C is the right answer. It is a trick. \nTroubleshoot Azure SQL Database and Azure SQL Managed Instance performance issues with Intelligent Insights\nhttps://docs.microsoft.com/en-us/azure/azure-sql/database/intelligent-insights-troubleshoot-performance?view=azuresql\n(2) D is only for identifying IO performance issues."
      },
      {
        "date": "2022-02-28T03:07:00.000Z",
        "voteCount": 1,
        "content": "Answer is correct. https://docs.microsoft.com/en-us/azure/azure-sql/database/intelligent-insights-troubleshoot-performance"
      },
      {
        "date": "2022-02-05T23:51:00.000Z",
        "voteCount": 5,
        "content": "D is right based on https://docs.microsoft.com/en-us/azure/azure-sql/database/monitoring-with-dmvs#identify-tempdb-performance-issues"
      },
      {
        "date": "2022-01-11T09:32:00.000Z",
        "voteCount": 2,
        "content": "Correct answer is D"
      },
      {
        "date": "2022-01-06T09:18:00.000Z",
        "voteCount": 2,
        "content": "use dmv for tempdb issues"
      },
      {
        "date": "2021-11-26T01:14:00.000Z",
        "voteCount": 1,
        "content": "for tempdb = D"
      },
      {
        "date": "2021-09-16T23:59:00.000Z",
        "voteCount": 1,
        "content": "C is correct."
      },
      {
        "date": "2021-08-09T19:40:00.000Z",
        "voteCount": 3,
        "content": "C is correct. If you check the link provided it reads that tempdb contention is monitored and reported through Intelligent Insights."
      },
      {
        "date": "2021-08-09T10:55:00.000Z",
        "voteCount": 1,
        "content": "For me, D is the correct answer as well."
      },
      {
        "date": "2021-06-28T09:20:00.000Z",
        "voteCount": 1,
        "content": "Answer is A: Query store can provide details on TempDB usage by queries."
      },
      {
        "date": "2021-06-18T11:03:00.000Z",
        "voteCount": 1,
        "content": "D is correct, but the links provided do not provide the actual DMV queries needed."
      },
      {
        "date": "2021-04-05T07:32:00.000Z",
        "voteCount": 1,
        "content": "I would tend to agree that \"Intelligent Insights\" would be the ideal answer, but I can certainly query the Azure SQL server using DMVs, for example\n: To further confirm tempdb contention, use sys.dm_exec_requests to confirm that the wait_resource value begins with 2:x:y where 2 is tempdb is the database ID (Microsoft Docs)"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 35,
    "url": "https://www.examtopics.com/discussions/microsoft/view/44019-exam-dp-300-topic-3-question-35-discussion/",
    "body": "DRAG DROP -<br>You are building an Azure virtual machine.<br>You allocate two 1-TiB, P30 premium storage disks to the virtual machine. Each disk provides 5,000 IOPS.<br>You plan to migrate an on-premises instance of Microsoft SQL Server to the virtual machine. The instance has a database that contains a 1.2-TiB data file. The database requires 10,000 IOPS.<br>You need to configure storage for the virtual machine to support the database.<br>Which three objects should you create in sequence? To answer, move the appropriate objects from the list of objects to the answer area and arrange them in the correct order.<br>Select and Place:<br><img src=\"/assets/media/exam-media/04275/0018000001.jpg\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04275/0018000002.jpg\" class=\"in-exam-image\">",
    "answerDescription": "Follow these same steps to create striped virtual disk:<br>\u2711 Create Log Storage Pool.<br>\u2711 Create Virtual Disk<br>\u2711 Create Volume<br><br>Box 1: a storage pool -<br>Box 2: a virtual disk that uses stripe layout<br>Disk Striping: Use multiple disks and stripe them together to get a combined higher IOPS and Throughput limit. The combined limit per VM should be higher than the combined limits of attached premium disks.<br><br>Box 3: a volume -<br>Reference:<br>https://hanu.com/hanu-how-to-striping-of-disks-for-azure-sql-server/",
    "votes": [],
    "comments": [
      {
        "date": "2021-02-10T03:31:00.000Z",
        "voteCount": 21,
        "content": "Storage Layout options Simple, Mirror Or Partity.\nCreate Virtual Disk with simple layout is correct."
      },
      {
        "date": "2021-03-27T14:27:00.000Z",
        "voteCount": 3,
        "content": "Correct.\n\nStriping would not make sense in this scenario, as there are only 2 disks, and a minimum of 3 disks is required for striping as it uses parity.\n\nThe only option that makes sense is to use the 2 disks with Simple layout which is, in effect, striping without parity.\n\nIn this scenario, one has to assume that there is external resiliency, as Simple layout does not protect against disk failure."
      },
      {
        "date": "2024-07-30T10:33:00.000Z",
        "voteCount": 1,
        "content": "Minimum number of disks for striping is 2."
      },
      {
        "date": "2021-05-21T21:04:00.000Z",
        "voteCount": 7,
        "content": "This stripe is not about creating redundancy like RAID 5. This is about combining the total IOPS of the two virtual disk into a single volume with 10,000 IOPS. Redundancy is already provided by the Azure infrastructure hosting the virtual disk. It runs at 11 9s."
      },
      {
        "date": "2021-07-05T22:04:00.000Z",
        "voteCount": 2,
        "content": "1.2TB total size is the key, guillermo is correct."
      },
      {
        "date": "2021-02-28T12:27:00.000Z",
        "voteCount": 1,
        "content": "guillermo is right"
      },
      {
        "date": "2022-03-31T14:19:00.000Z",
        "voteCount": 1,
        "content": "\"Simple\" is basically \"Stripping without Parity\", so in this case that is the better choice.\nhttps://support.microsoft.com/en-us/windows/storage-spaces-in-windows-b6c8b540-b8d8-fb8a-e7ab-4a75ba11f9f2"
      },
      {
        "date": "2021-04-08T18:59:00.000Z",
        "voteCount": 13,
        "content": "Answer given is correct. You can stripe 2 premium data disk to get 10000 IOPS.\nhttps://techcommunity.microsoft.com/t5/sql-server/optimize-oltp-performance-with-sql-server-on-azure-vm/ba-p/916794"
      },
      {
        "date": "2021-12-29T13:52:00.000Z",
        "voteCount": 1,
        "content": "I think the catch here is simple layout is actually the same as striping. When you create a virtual disk, you specify 'simple', but the technique used to be called striping in windows."
      },
      {
        "date": "2024-07-09T16:31:00.000Z",
        "voteCount": 1,
        "content": "Simple is not striping\u2026"
      },
      {
        "date": "2021-07-05T22:03:00.000Z",
        "voteCount": 1,
        "content": "How about getting 1.2TB space? that is the key here, so simple layout"
      },
      {
        "date": "2024-07-04T12:51:00.000Z",
        "voteCount": 1,
        "content": "Going with the given solution.  The simple layout option is very rarely mentioned, but striping is called out in several articles like the below.\n\nhttps://learn.microsoft.com/en-us/azure/azure-sql/virtual-machines/windows/performance-guidelines-best-practices-storage?view=azuresql"
      },
      {
        "date": "2024-07-04T13:01:00.000Z",
        "voteCount": 1,
        "content": "Furthermore, a simple volume just acts as another disk.  Seems not ideal for this situation.\n\nhttps://learn.microsoft.com/en-us/windows/win32/vds/volume-object"
      },
      {
        "date": "2023-02-14T22:25:00.000Z",
        "voteCount": 2,
        "content": "Given answer is correct.\nQuestion request 1.2T and 10,000 IOPS.\nVM has two P30 SSDs.\nSo, you need use stripe (RAID0).\n\nhttps://learn.microsoft.com/en-us/azure/virtual-machines/premium-storage-performance#disk-striping"
      },
      {
        "date": "2022-10-17T07:49:00.000Z",
        "voteCount": 1,
        "content": "Provided answer is not correct. Having only 2 disk, better choose the simple layout, not striping."
      },
      {
        "date": "2022-10-11T09:50:00.000Z",
        "voteCount": 2,
        "content": "Striping is RAID 0, and to establish a RAID 0 volume, a minimum of at least 2 hard disk drives are required."
      },
      {
        "date": "2022-04-29T06:42:00.000Z",
        "voteCount": 2,
        "content": "The answer is correct"
      },
      {
        "date": "2022-03-10T06:55:00.000Z",
        "voteCount": 2,
        "content": "Provided answer is correct \nStripe multiple Azure data disks using Storage Spaces to increase I/O bandwidth up to the target virtual machine's IOPS and throughput limits.\nhttps://docs.microsoft.com/en-us/azure/azure-sql/virtual-machines/windows/performance-guidelines-best-practices-storage"
      },
      {
        "date": "2022-03-10T03:40:00.000Z",
        "voteCount": 8,
        "content": "-&gt; a storage pool\n-&gt; a virtual disk that uses the simple layout\n-&gt; a volume\n\nThere are only three layouts while creating virtual disks on a storage pool:\n\nSimple - Data is striped across physical disks, maximizing capacity and throughput\nMirror - Data is striped across physical disks, creating two or three copies of data\nParity - Data and parity information is striped across physical disks, increasing reliability"
      },
      {
        "date": "2021-04-03T23:39:00.000Z",
        "voteCount": 5,
        "content": "Minimum 2 disks are needed for Striping, I feel given answerer is correct. \"a virtual disk that uses stripe layout\"\n\nhttps://docs.microsoft.com/en-us/troubleshoot/windows-server/backup-and-storage/establish-striped-volume-raid-0#:~:text=Disks%3A%20A%20minimum%20of%20two,very%20quickly%20without%20data%20loss."
      },
      {
        "date": "2021-02-04T15:11:00.000Z",
        "voteCount": 3,
        "content": "correct"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 36,
    "url": "https://www.examtopics.com/discussions/microsoft/view/97163-exam-dp-300-topic-3-question-36-discussion/",
    "body": "HOTSPOT<br> -<br><br>You need to use an Azure Resource Manager (ARM) template to deploy an Azure virtual machine that will host a Microsoft SQL Server instance. The solution must maximize disk I/O performance for the SQL Server database and log files.<br><br>How should you complete the template? To answer, select the appropriate options in the answer area.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/dp-300/image235.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/dp-300/image236.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2023-01-29T14:35:00.000Z",
        "voteCount": 25,
        "content": "I think it should be opposite, i.e.  Read-Only and None. \nSee https://learn.microsoft.com/en-us/azure/azure-sql/virtual-machines/windows/performance-guidelines-best-practices-storage?view=azuresql#caching\nWe need to set 'Read-Only' caching for data disks and 'None' for the log disk.  \nThere is a loop (copy) in the ARM template, it evaluates whether current disk ID is greater than sum of data disks. If yes then it's the log disk, so assign None, otherwise the value in the variable (i.e. Read-Only). \nSimilar example is here:\nhttps://learn.microsoft.com/en-us/azure/azure-sql/virtual-machines/windows/create-sql-vm-resource-manager-template"
      },
      {
        "date": "2023-03-24T14:48:00.000Z",
        "voteCount": 3,
        "content": "licna is correct"
      },
      {
        "date": "2024-10-04T04:18:00.000Z",
        "voteCount": 1,
        "content": "Select ReadOnly caching. This is because SQL Server frequently reads from the data disks but doesn't perform as many writes, so ReadOnly caching maximizes read performance while keeping write operations off the cache.\nFor log disks:\nSelect None for caching. SQL Server log writes are sequential and write-heavy. Disk caching can interfere with the efficient, sequential logging, so you should disable caching to ensure the best performance for log writes."
      },
      {
        "date": "2024-04-15T06:25:00.000Z",
        "voteCount": 2,
        "content": "Answers are the other way around as licna suggested. Look at the IF statement for the caching property in the \u201cCOPY\u201d section\u2026 it reads \u201cIf the current disk being created is of a higher index than the number of data disks count, use \u201clog cache value\u201d, otherwise default to caching variable (for data files)."
      },
      {
        "date": "2023-02-22T23:46:00.000Z",
        "voteCount": 2,
        "content": "None\nReadOnly"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 37,
    "url": "https://www.examtopics.com/discussions/microsoft/view/96760-exam-dp-300-topic-3-question-37-discussion/",
    "body": "You have an Azure SQL managed instance named MI1.<br><br>You need to implement automatic tuning for the databases of MI1.<br><br>What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse The REST API to call the patch operation and modify the AutomaticTuningServerMode property.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tFrom the Azure portal, configure automatic tuning.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse Transact-SQL to enable the FORCE_LAST_GOOD_PLAN option.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 15,
        "isMostVoted": true
      },
      {
        "answer": "B",
        "count": 7,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2023-02-14T22:50:00.000Z",
        "voteCount": 5,
        "content": "You can enable auto tuning by Azure Portal and T-SQL.\n\nTo enable automatic tuning on a single database via T-SQL, connect to the database and execute the following query:\nALTER DATABASE current SET AUTOMATIC_TUNING = AUTO | INHERIT | CUSTOM\n\nSo, option C is wrong.Answer is B:Azure Portal configuration auto tuning.\nRef:\nhttps://learn.microsoft.com/en-us/azure/azure-sql/database/automatic-tuning-enable?view=azuresql#t-sql"
      },
      {
        "date": "2023-02-14T23:57:00.000Z",
        "voteCount": 5,
        "content": "Correct the answer to C\n\nFor Azure SQL Managed Instance, the supported option FORCE_LAST_GOOD_PLAN can only be configured through T-SQL. The Azure portal based configuration and automatic index tuning options described in this article do not apply to Azure SQL Managed Instance.\n\nRef:\nhttps://learn.microsoft.com/en-us/azure/azure-sql/database/automatic-tuning-enable?view=azuresql"
      },
      {
        "date": "2024-04-22T09:24:00.000Z",
        "voteCount": 1,
        "content": "For Azure SQL Managed Instance, the supported option FORCE_LAST_GOOD_PLAN can only be configured through T-SQL. The Azure portal based configuration and automatic index tuning options described in this article do not apply to Azure SQL Managed Instance.\n\nhttps://learn.microsoft.com/en-us/azure/azure-sql/database/automatic-tuning-enable?view=azuresql-mi"
      },
      {
        "date": "2023-08-30T08:11:00.000Z",
        "voteCount": 4,
        "content": "C is the correct answer, force_last_good_plan for SQL managed instance. For Azure SQL Managed Instance, the supported option FORCE_LAST_GOOD_PLAN can only be configured through T-SQL. The Azure portal based configuration and automatic index tuning options described in this article do not apply to Azure SQL Managed Instance.\n\nhttps://learn.microsoft.com/en-us/azure/azure-sql/database/automatic-tuning-enable?view=azuresql#enable-automatic-tuning-on-an-individual-database"
      },
      {
        "date": "2023-08-28T23:38:00.000Z",
        "voteCount": 3,
        "content": "https://learn.microsoft.com/en-us/azure/azure-sql/database/automatic-tuning-overview?view=azuresql\n\"Enable automatic tuning\nAzure SQL Database: Enable automatic tuning in the Azure portal or by using the ALTER DATABASE T-SQL statement.\nAzure SQL Managed Instance: Enable automatic tuning by using the ALTER DATABASE T-SQL statement.\"\nSo FORCE_LAST_GOOD_PLAN is the correct answer, as it is provided by MS itself."
      },
      {
        "date": "2023-08-20T13:39:00.000Z",
        "voteCount": 2,
        "content": "https://learn.microsoft.com/en-us/azure/azure-sql/database/automatic-tuning-overview?view=azuresql#enable-automatic-tuning - This states that enabling via portal is only available for Azure DB not MI"
      },
      {
        "date": "2023-06-12T06:35:00.000Z",
        "voteCount": 1,
        "content": "https://learn.microsoft.com/en-us/azure/azure-sql/database/automatic-tuning-enable?view=azuresql\nFor Azure SQL Managed Instance, the supported option FORCE_LAST_GOOD_PLAN can only be configured through T-SQL. The Azure portal based configuration and automatic index tuning options described in this article do not apply to Azure SQL Managed Instance."
      },
      {
        "date": "2023-04-11T07:25:00.000Z",
        "voteCount": 2,
        "content": "C is missing the create_index and drop_index options, so answer is B, use the Azure Portal to enable AT although it could be done using T-SQL as well."
      },
      {
        "date": "2023-04-05T20:40:00.000Z",
        "voteCount": 1,
        "content": "The correct answer is B\n\n\nTo implement automatic tuning for the databases of an Azure SQL managed instance, you can configure automatic tuning from the Azure portal. In the Azure portal, navigate to your managed instance and select \u201cAutomatic tuning\u201d from the menu. From there, you can enable or disable automatic tuning options such as \u201cForce plan\u201d and \u201cCreate index\u201d. Therefore, the correct answer is B. From the Azure portal, configure automatic tuning.\n\nOption C is also incorrect because enabling the FORCE_LAST_GOOD_PLAN option is not related to automatic tuning. FORCE_LAST_GOOD_PLAN is a query hint that forces a query to use the last known good query plan in the plan cache instead of generating a new one."
      },
      {
        "date": "2023-04-15T09:43:00.000Z",
        "voteCount": 3,
        "content": "Sorry, I am wrong. C is correct."
      },
      {
        "date": "2023-03-26T00:14:00.000Z",
        "voteCount": 4,
        "content": "https://learn.microsoft.com/en-us/azure/azure-sql/database/automatic-tuning-enable?view=azuresql - read first highlighted area"
      },
      {
        "date": "2023-04-15T09:42:00.000Z",
        "voteCount": 1,
        "content": "Here you are:\n\nFor Azure SQL Managed Instance, the supported option FORCE_LAST_GOOD_PLAN can only be configured through T-SQL. The Azure portal based configuration and automatic index tuning options described in this article do not apply to Azure SQL Managed Instance."
      },
      {
        "date": "2023-02-14T23:58:00.000Z",
        "voteCount": 4,
        "content": "For Azure SQL Managed Instance, the supported option FORCE_LAST_GOOD_PLAN can only be configured through T-SQL. The Azure portal based configuration and automatic index tuning options described in this article do not apply to Azure SQL Managed Instance.\n\nRef:\nhttps://learn.microsoft.com/en-us/azure/azure-sql/database/automatic-tuning-enable?view=azuresql"
      },
      {
        "date": "2023-01-24T10:43:00.000Z",
        "voteCount": 3,
        "content": "Correct, managed instance is via alter database:\n&lt;automatic_tuning_option&gt; ::=\n{\n    AUTOMATIC_TUNING ( FORCE_LAST_GOOD_PLAN = { DEFAULT | ON | OFF } )\n}\n\nazure sql database can also be done via the portal"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 38,
    "url": "https://www.examtopics.com/discussions/microsoft/view/96761-exam-dp-300-topic-3-question-38-discussion/",
    "body": "You have an Azure subscription that contains an Azure SQL database named db1.<br><br>You need to implement SQL insights for db1.<br><br>Which two resources should you create first? Each correct answer presents part of the solution.<br><br>NOTE: Each correct selection is worth one point.",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ta storage account\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ta virtual machine",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tan Azure logic app",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tan Azure function",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ta Log Analytics workspace\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "AE",
    "answerDescription": "",
    "votes": [
      {
        "answer": "BE",
        "count": 3,
        "isMostVoted": false
      },
      {
        "answer": "AE",
        "count": 3,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-01-24T10:46:00.000Z",
        "voteCount": 18,
        "content": "correct, a VM and a Log Analytics Workspace:\nhttps://learn.microsoft.com/en-us/azure/azure-sql/database/sql-insights-enable?view=azuresql"
      },
      {
        "date": "2024-05-25T09:57:00.000Z",
        "voteCount": 1,
        "content": "its such a shame from Microsoft to create VM as shown in youtube video, wish they could have used azure storage, its hard to use SQL insights due to high cost  \nhttps://learn.microsoft.com/en-us/azure/azure-sql/database/sql-insights-enable?view=azuresql"
      },
      {
        "date": "2024-05-17T12:38:00.000Z",
        "voteCount": 2,
        "content": "BE based off this:\n\nThere's no direct cost for SQL Insights (preview). All costs are incurred by the virtual machines that gather the data, the Log Analytics workspaces that store the data, and any alert rules configured on the data.\n\nhttps://learn.microsoft.com/en-us/azure/azure-sql/database/sql-insights-overview?view=azuresql#pricing"
      },
      {
        "date": "2024-04-19T02:25:00.000Z",
        "voteCount": 1,
        "content": "The answer is correct"
      },
      {
        "date": "2024-04-17T09:18:00.000Z",
        "voteCount": 1,
        "content": "A,E are the correct answers"
      },
      {
        "date": "2024-04-17T09:24:00.000Z",
        "voteCount": 1,
        "content": "Sorry, the answer B,E is correct.\nhttps://learn.microsoft.com/en-us/azure/azure-sql/database/sql-insights-overview?view=azuresql\nSql Insight performs all monitoring remotely. Monitoring agents on dedicated virtual machines connect to your SQL resources and remotely gather Data."
      },
      {
        "date": "2024-04-15T06:56:00.000Z",
        "voteCount": 2,
        "content": "Please be aware ChatGPT can be wrong and it won\u2019t tell you it is wrong until you tell it. In other words lets stick with answers from real users please!"
      },
      {
        "date": "2024-02-22T22:59:00.000Z",
        "voteCount": 1,
        "content": "ChatGPT answer -\nA. Storage Account\nB. Log Analytics Workspace"
      },
      {
        "date": "2024-02-22T23:00:00.000Z",
        "voteCount": 1,
        "content": "*E. Log Analytics Workspace"
      },
      {
        "date": "2024-02-02T11:56:00.000Z",
        "voteCount": 2,
        "content": "A. a storage account\n    E. a Log Analytics workspace\nAzure SQL insights is a feature of Azure Monitor that collects, aggregates, and serves SQL performance metrics. It uses a Log Analytics workspace to store and provide advanced analytics on the performance data. You also need a storage account to maintain the SQL assessment data over time. These two resources are essential for setting up SQL insights. A virtual machine, an Azure logic app, and an Azure function are not necessary for this particular task."
      },
      {
        "date": "2024-04-19T02:26:00.000Z",
        "voteCount": 2,
        "content": "Your explanation says \"These two resources are essential for setting up SQL insights. A virtual machine, an Azure logic app, and an Azure function are not necessary for this particular task.\" So the correct answers are B and E"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 39,
    "url": "https://www.examtopics.com/discussions/microsoft/view/99073-exam-dp-300-topic-3-question-39-discussion/",
    "body": "You have an Azure subscription that contains the resources shown in the following table.<br><br><img src=\"https://img.examtopics.com/dp-300/image237.png\"><br><br>App1 experiences transient connection errors and timeouts when it attempts to access db1 after extended periods of inactivity.<br><br>You need to modify db1 to resolve the issues experienced by App1 as soon as possible, without considering immediate costs.<br><br>What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEnable automatic tuning for db1.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tIncrease the number of vCores allocated to db1.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDecrease the auto-pause delay for db1.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDisable auto-pause delay for db1.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 8,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-08-30T08:14:00.000Z",
        "voteCount": 1,
        "content": "yes disabling auto pause option on databases fixes the issue"
      },
      {
        "date": "2023-07-18T23:12:00.000Z",
        "voteCount": 1,
        "content": "Answer is D"
      },
      {
        "date": "2023-02-14T13:30:00.000Z",
        "voteCount": 4,
        "content": "Selected answer is correct"
      },
      {
        "date": "2023-02-14T23:04:00.000Z",
        "voteCount": 2,
        "content": "https://learn.microsoft.com/en-us/azure/azure-sql/database/serverless-tier-overview?view=azuresql#auto-pausing-and-auto-resuming"
      },
      {
        "date": "2023-02-13T07:42:00.000Z",
        "voteCount": 3,
        "content": "Answer is correct."
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 40,
    "url": "https://www.examtopics.com/discussions/microsoft/view/100349-exam-dp-300-topic-3-question-40-discussion/",
    "body": "HOTSPOT<br> -<br><br>You have an Azure SQL database named DB1 that contains a table named Table1.<br><br>You run a query to load data into Table1.<br><br>The performance metrics of Table1 during the load operation are shown in the following exhibit.<br><br><img src=\"https://img.examtopics.com/dp-300/image238.png\"><br><br>Use the drop-down menus to select the answer choice that completes each statement based on the information presented in the graphic.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/dp-300/image239.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/dp-300/image240.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2023-03-16T06:12:00.000Z",
        "voteCount": 7,
        "content": "You are loading data into Table1, which means there is some inserts going on. Note that insert statements is also considered a query. Not sure why the first answer is perform query tuning. It should be scale resource in order to reduce the time insert data into Table1."
      },
      {
        "date": "2023-05-29T05:08:00.000Z",
        "voteCount": 5,
        "content": "I was thinking the same, In my opinion also can be scale resources for the first one."
      },
      {
        "date": "2024-10-07T00:55:00.000Z",
        "voteCount": 1,
        "content": "chat also goes for scale resource"
      },
      {
        "date": "2023-04-11T08:28:00.000Z",
        "voteCount": 2,
        "content": "Query tuning is correct, make sure insert is efficient i.e. load in batches from In-Memory non durable table is faster."
      },
      {
        "date": "2023-02-22T00:13:00.000Z",
        "voteCount": 1,
        "content": "correct."
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 41,
    "url": "https://www.examtopics.com/discussions/microsoft/view/100352-exam-dp-300-topic-3-question-41-discussion/",
    "body": "DRAG DROP<br> -<br><br>You have a database named db1.<br><br>The log for db1 contains the following entry.<br><br><img src=\"https://img.examtopics.com/dp-300/image241.png\"><br><br>You need to ensure that db1 can process transactions.<br><br>Which three actions should you perform in sequence? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.<br><br><img src=\"https://img.examtopics.com/dp-300/image242.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/dp-300/image243.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2023-04-03T15:07:00.000Z",
        "voteCount": 10,
        "content": "my take would be: 1.remove db1 from ag, 2. backup t.log , 3 re-add db1 to ag . shrinking log shouldn't be necessary since log backup will reduce its size"
      },
      {
        "date": "2024-06-25T10:10:00.000Z",
        "voteCount": 1,
        "content": "Log backups wont reduce the size of the file. after a backup we need to shrink seperately, \n\nTransaction Log File Behavior:\n\nLog Truncation: After a backup (either full or transaction log), SQL Server marks the inactive portion of the transaction log as reusable. This process is known as log truncation.\n\nFile Size Management: The size of the transaction log file itself is managed separately from backups. It grows as transactions are logged and requires periodic management to maintain an appropriate size."
      },
      {
        "date": "2023-06-18T16:35:00.000Z",
        "voteCount": 2,
        "content": "Correct. You need to free the space of available transactional log capacity. Shrinking would reduce the physical size on disk, but not applicable space"
      },
      {
        "date": "2024-09-10T01:17:00.000Z",
        "voteCount": 1,
        "content": "1: backup the log, 2: remove the db from AG, 3: add the db back into the AG"
      },
      {
        "date": "2024-06-22T14:18:00.000Z",
        "voteCount": 1,
        "content": "We do not need to take a backup, because backup is not causing a logfile growth.Actual root cause is AG, so after removed the DB from AG , you can shrink the logfile, so answer is correct."
      },
      {
        "date": "2023-07-18T23:33:00.000Z",
        "voteCount": 3,
        "content": "Based on amazonalex with https://www.sqlshack.com/sql-server-transaction-log-backup-truncate-and-shrink-operations/, my answer is \nRemove db1 from the Availability Group\nBackup the Transaction Log File\nAdd db1 from the Availability Group"
      },
      {
        "date": "2023-07-10T17:06:00.000Z",
        "voteCount": 1,
        "content": "https://learn.microsoft.com/en-us/answers/questions/632536/shrink-a-database-log-file-which-is-synchronized-(\nNot seeing a need to remove from AG?"
      },
      {
        "date": "2023-07-15T12:22:00.000Z",
        "voteCount": 1,
        "content": "Got it. Avoid shrinking operation and instead back up the the log."
      },
      {
        "date": "2023-03-24T15:00:00.000Z",
        "voteCount": 1,
        "content": "kkkiet do you have link for this source? trying to learn. thx. can't find a definitive answer"
      },
      {
        "date": "2023-02-22T00:25:00.000Z",
        "voteCount": 4,
        "content": "Back up the transaction log file.\nRemove db1 from the availability group.\nShrink the transaction log file."
      },
      {
        "date": "2023-04-01T09:25:00.000Z",
        "voteCount": 4,
        "content": "First need to remove DB from AG then sometime its log file auto clean from full to 90% space  then shrink log file and readd into AG"
      },
      {
        "date": "2023-10-27T03:24:00.000Z",
        "voteCount": 1,
        "content": "Agree with your answer.\nAdd db1 back to the availability group is not necessary to create some spaces.\nhttps://learn.microsoft.com/en-us/troubleshoot/sql/database-engine/availability-groups/error-9002-transaction-log-large"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 42,
    "url": "https://www.examtopics.com/discussions/microsoft/view/97124-exam-dp-300-topic-3-question-42-discussion/",
    "body": "You have the following resources:<br><br>\u2022\t15 SQL Server on Azure Virtual Machines instances<br>\u2022\t20 Azure SQL databases<br><br>You need to recommend a solution to centrally monitor the resources for security vulnerabilities.<br><br>What should you include in the recommendation?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tdatabase audits",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tMicrosoft Defender\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSQL insights",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure SQL Auditing"
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 10,
        "isMostVoted": true
      },
      {
        "answer": "D",
        "count": 2,
        "isMostVoted": false
      },
      {
        "answer": "C",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2023-02-12T00:34:00.000Z",
        "voteCount": 8,
        "content": "In my opinion it's MS Defender. Keyword is the \"vulnerabilities\"\nhttps://learn.microsoft.com/en-us/azure/defender-for-cloud/defender-for-sql-introduction"
      },
      {
        "date": "2024-06-28T12:58:00.000Z",
        "voteCount": 1,
        "content": "Its a blinder, Defender is best in this."
      },
      {
        "date": "2023-02-14T23:17:00.000Z",
        "voteCount": 1,
        "content": "Agree."
      },
      {
        "date": "2023-02-13T07:51:00.000Z",
        "voteCount": 2,
        "content": "I agree Microsoft Defender is the correct answer to the question asked. Auditing and SQL insights primary functions are not to detect vulnerabilities. Defender will monitor both IaaS and PaaS resources."
      },
      {
        "date": "2023-10-23T17:47:00.000Z",
        "voteCount": 3,
        "content": "Security vulnerability = Microsoft Defender"
      },
      {
        "date": "2023-08-24T09:36:00.000Z",
        "voteCount": 1,
        "content": "\"You need to recommend a solution to centrally monitor the resources for security vulnerabilities.\" - auditing is meant for monitoring specific securables (say, certain users) and events (login, logout, etc). It has nothing to do with detecting vulnerabilities. So the correct answer is B."
      },
      {
        "date": "2023-04-23T23:53:00.000Z",
        "voteCount": 2,
        "content": "Azure Defender monitors for vulnerabilities"
      },
      {
        "date": "2023-04-14T00:16:00.000Z",
        "voteCount": 1,
        "content": "i think B.\nMicrosoft Defender for SQL provides a set of advanced SQL security capabilities, including SQL Vulnerability Assessment and Advanced Threat Protection."
      },
      {
        "date": "2023-04-06T18:43:00.000Z",
        "voteCount": 2,
        "content": "I think the answer is D.\n\nAzure SQL Auditing can  centrally monitor the resources for security vulnerabilities. Microsoft Defender is not specifically designed to centrally monitor SQL Server on Azure Virtual Machines instances and Azure SQL databases for security vulnerabilities. \nSQL insights is a feature that provides performance monitoring and tuning for SQL Server running on Azure Virtual Machines."
      },
      {
        "date": "2024-03-18T07:53:00.000Z",
        "voteCount": 1,
        "content": "Comparto, respuesta D"
      },
      {
        "date": "2023-04-11T18:50:00.000Z",
        "voteCount": 1,
        "content": "I am wrong. The answer should be B."
      },
      {
        "date": "2023-03-16T06:53:00.000Z",
        "voteCount": 1,
        "content": "The question is about centrally monitoring resources for security vulnerability, which includes VMs here. Azure SQL Auditing does not monitor VMs. So the answer should be Microsoft Defender."
      },
      {
        "date": "2023-01-29T18:21:00.000Z",
        "voteCount": 1,
        "content": "it shoud be SQL insight, this is for VM.\nAzure SQL is for Azure SQL Database and Azure Synapse Analytics \n\nhttps://learn.microsoft.com/en-us/azure/azure-sql/database/sql-insights-overview?view=azuresql\n\nhttps://learn.microsoft.com/en-us/azure/azure-sql/database/auditing-overview?view=azuresql"
      },
      {
        "date": "2023-01-29T22:13:00.000Z",
        "voteCount": 1,
        "content": "revised. \nSQL Insights is focused on performance optimization while Azure SQL Auditing is focused on security and compliance.\n\nit should be as Manuuzzz advised, Azure SQL auditing."
      },
      {
        "date": "2023-01-29T03:08:00.000Z",
        "voteCount": 2,
        "content": "shouldn't this be D, azure sql auditing, as sql insights gathers other metrics (performance)"
      },
      {
        "date": "2023-01-29T03:08:00.000Z",
        "voteCount": 2,
        "content": "shouldn't this be D, azure sql auditing, as sql insights gathers other metrics (performance)"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 43,
    "url": "https://www.examtopics.com/discussions/microsoft/view/96275-exam-dp-300-topic-3-question-43-discussion/",
    "body": "HOTSPOT<br> -<br><br>You have an Azure subscription that contains an instance of SQL Server on Azure Virtual Machines named SQLVM1 and a user named User1. SQLVM1 hosts a database named DB1.<br><br>You need to ensure that User1 can perform the following tasks on DB1:<br><br>\u2022\tCreate jobs.<br>\u2022\tView all jobs.<br>\u2022\tModify, delete, and disable the jobs the user created.<br><br>The solution must use the principle of least privilege.<br><br>Which built-in database role should you assign to User1, and where is the role defined? To answer, select the appropriate options in the answer area.<br><br><img src=\"https://img.examtopics.com/dp-300/image244.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/dp-300/image245.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2023-01-21T01:16:00.000Z",
        "voteCount": 18,
        "content": "Location: msdb\nRole: SQLAgentUesrRole"
      },
      {
        "date": "2024-06-28T13:07:00.000Z",
        "voteCount": 4,
        "content": "Role: SQLAgentReaderRole this is least privilege role to see all jobs\nSQLAgentUserRole can only view jobs they own."
      },
      {
        "date": "2023-02-22T06:06:00.000Z",
        "voteCount": 11,
        "content": "Location: msdb\nRole: SQLAgentOperatorRole\n\u2022 Create jobs.\n\u2022 View all jobs.\n\u2022 Modify, delete, and disable the jobs the user created."
      },
      {
        "date": "2024-10-08T06:10:00.000Z",
        "voteCount": 1,
        "content": "agree with sr18 , userrole can only view jobs whereas ReaderRole  can satisfy the requirements"
      },
      {
        "date": "2023-08-30T08:33:00.000Z",
        "voteCount": 7,
        "content": "Tested it and answer is correct, msdb, SQLAgentReaderRole, because 2nd option view all jobs is only available if account has SQLagentReaderole and higher (operator) so, with minimum privilege as requirement, Answer is msdb,  SQLagentReaderRole"
      },
      {
        "date": "2023-04-06T18:51:00.000Z",
        "voteCount": 6,
        "content": "The answer is correct.\n\nSQLAgentUesrRole can not view all jobs.\nGosan is right!"
      },
      {
        "date": "2023-03-16T07:11:00.000Z",
        "voteCount": 8,
        "content": "Based on the table here https://www.youtube.com/watch?v=rodn5MSeiuY at 0m:40s and using the principal of least privilege, the answer should be SQLAgentReaderRole. SQLAgentUserRole cannot view all jobs, it can only view own jobs. Although both SQLAgentReaderRole and SQLAgentOperatorRole can create/modify/delete own jobs, the next thing to consider here is that the user must be able to disable its own job. SQLAgentReaderRole can disable own job, where SQLAgentOperatorRole can disable all jobs. Using the principal of least privilege, the answer is SQLAgentReaderRole."
      },
      {
        "date": "2023-02-14T23:26:00.000Z",
        "voteCount": 3,
        "content": "Localtion:msdb\nRole:SQLAgentReaderRole    (Because question request \"view all jobs\". SQLAgentUserRole only view owned jobs)"
      },
      {
        "date": "2023-02-14T23:27:00.000Z",
        "voteCount": 1,
        "content": "Ref:\nhttps://learn.microsoft.com/en-us/sql/ssms/agent/sql-server-agent-fixed-database-roles?view=sql-server-ver16#sqlagentreaderrole-permissions"
      },
      {
        "date": "2023-02-21T02:31:00.000Z",
        "voteCount": 1,
        "content": "owned jobs only is for ReaderRole &amp; nor for User Role - is it right?"
      },
      {
        "date": "2023-02-21T02:33:00.000Z",
        "voteCount": 1,
        "content": "owned jobs only &gt;&gt; for ReaderRole &amp; not for UserRole - is it right? so i consider that SQLAgentUserRole is the right answer"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 44,
    "url": "https://www.examtopics.com/discussions/microsoft/view/99074-exam-dp-300-topic-3-question-44-discussion/",
    "body": "You have an Azure subscription that contains an Azure SQL managed instance named SQLMI1 and a Log Analytics workspace named Workspace1.<br><br>You need to collect performance metrics for SQLMI1 and stream the metrics to Workspace.<br><br>What should you do first?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a private endpoint connection on SQLMI1.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure Azure SQL Analytics to use Workspace1.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tModify the Compute + storage settings for SQLMI1.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tModify the diagnostic settings for SQLMI1.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 3,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-04-22T21:18:00.000Z",
        "voteCount": 1,
        "content": "D is correct,  to Modify the diagnostic settings for SQLMI1.\n\nDiagnostic settings available for databases in your Azure SQL Managed Instance include:\nlog: SQL Insights, Query Store Runtime Statistics, Query Store Wait Statistics, and Errors\ndestination details: Send to Log Analytics workspace, Archive to a storage account, Stream to an event hub, Send to partner solution\n\nhttps://learn.microsoft.com/en-us/azure/azure-sql/managed-instance/monitoring-sql-managed-instance-azure-monitor?view=azuresql#collection-and-routing"
      },
      {
        "date": "2023-03-02T20:40:00.000Z",
        "voteCount": 2,
        "content": "D. Modify the diagnostic settings for SQLMI1."
      },
      {
        "date": "2023-02-22T02:03:00.000Z",
        "voteCount": 2,
        "content": "D. Modify the diagnostic settings for SQLMI1."
      },
      {
        "date": "2023-02-13T08:09:00.000Z",
        "voteCount": 2,
        "content": "Answer is correct."
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 45,
    "url": "https://www.examtopics.com/discussions/microsoft/view/107086-exam-dp-300-topic-3-question-45-discussion/",
    "body": "HOTSPOT<br> -<br><br>You have an Azure SQL database named DB1 in the General Purpose service tier.<br><br>You need to monitor DB1 by using SQL Insights.<br><br>What should you include in the solution? To answer, select the appropriate options in the<br> answer area.<br><br><img src=\"https://img.examtopics.com/dp-300/image268.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/dp-300/image269.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2023-07-10T00:08:00.000Z",
        "voteCount": 5,
        "content": "A virtual machine and Log Analytics workspace"
      },
      {
        "date": "2024-02-29T13:00:00.000Z",
        "voteCount": 1,
        "content": "This seems like a which comes first, the chicken or the egg. The Monitoring Agent does indeed collect the data but it exists in a Virtual machine - ie. it's a virtual machine extension. I think the answer should then be Virtual machine and Log Analytics Workspace."
      },
      {
        "date": "2023-08-13T17:07:00.000Z",
        "voteCount": 3,
        "content": "SQL Insights uses dedicated monitoring virtual machines to remotely collect data from your SQL resources. Each monitoring virtual machine has the Azure Monitor agent and the Workload Insights (WLI) extension installed. The given answer is correct"
      },
      {
        "date": "2023-08-10T01:11:00.000Z",
        "voteCount": 4,
        "content": "A VM cannot collect the data, the Azure Monitor agent does.\nIndeed a poorly worded question."
      },
      {
        "date": "2023-08-24T09:57:00.000Z",
        "voteCount": 3,
        "content": "getting to the bottom of it: https://learn.microsoft.com/en-us/azure/azure-monitor/agents/agents-overview - \"Azure Monitor Agent (AMA) collects monitoring data from the guest operating system of Azure and hybrid virtual machines\". \nSo indeed the answer is Log Analytics and a VM, as this definitely is related to SQL Insights."
      },
      {
        "date": "2023-06-14T18:15:00.000Z",
        "voteCount": 3,
        "content": "The store part is correct like Pravana said. but the collect is wrong \nFrom the same link Pravana provide : \n\nYou will need to create one or more Azure virtual machines that will be used to collect data to monitor SQL."
      },
      {
        "date": "2023-06-18T17:11:00.000Z",
        "voteCount": 3,
        "content": "Correct. A virtual machine and Log Analytics workspace as in provided Pranava_GCP link"
      },
      {
        "date": "2023-04-22T21:36:00.000Z",
        "voteCount": 4,
        "content": "seem to be correct answer, \n\nSQL Insights stores its data in one or more Log Analytics workspaces.\nhttps://learn.microsoft.com/en-us/azure/azure-sql/database/sql-insights-overview?view=azuresql\nhttps://learn.microsoft.com/en-us/azure/azure-sql/database/sql-insights-enable?view=azuresql#create-log-analytics-workspace"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 46,
    "url": "https://www.examtopics.com/discussions/microsoft/view/105471-exam-dp-300-topic-3-question-46-discussion/",
    "body": "You have an Azure SQL database named DB1 in the General Purpose service tier.<br><br>The performance metrics for DB1 are shown in the following exhibit.<br><br><img src=\"https://img.examtopics.com/dp-300/image270.png\"><br><br>You need to reduce the Log IO percentage. The solution must minimize costs.<br><br>What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tChange Service tier to Business Critical.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tIncrease the number of vCores.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tPerform a checkpoint operation.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tChange Recovery model to Simple."
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 1,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-08-20T03:12:00.000Z",
        "voteCount": 1,
        "content": "I belive it's A. When you increase number of vCores, you'll get higher resource limits incl. IOPS. \nhttps://learn.microsoft.com/en-us/azure/azure-sql/database/resource-limits-vcore-single-databases?view=azuresql\nIt should be less expensive than promoting of service level."
      },
      {
        "date": "2024-05-16T14:59:00.000Z",
        "voteCount": 1,
        "content": "it seems as if  the only available option is A change service tire  which is not cost-effective"
      },
      {
        "date": "2023-08-10T02:11:00.000Z",
        "voteCount": 3,
        "content": "A. Change Service tier to Business Critical. - seems the only solution.\nB. Increase the number of vCores. - relates to MI being in the Business Critical already. it is not (https://learn.microsoft.com/en-us/answers/questions/603214/log-io-metrics-is-hitting-100)\nC. Perform a checkpoint operation. - usually for shrinking log files, not related to log performance being poor. if anything, will worsen the situation by flushing data from memory to disk. the operation has to be logged as well.\nD. Change Recovery model to Simple. - logging transactions is not related to recovery models, transaction log management is (log backups or not). irrelevant for the issue at hand."
      },
      {
        "date": "2023-07-10T11:26:00.000Z",
        "voteCount": 2,
        "content": "https://learn.microsoft.com/en-us/answers/questions/603214/log-io-metrics-is-hitting-100"
      },
      {
        "date": "2023-04-26T06:22:00.000Z",
        "voteCount": 4,
        "content": "since it is hitting max IOPS limitation and not storage space limits, upgrading to BC tier will increase max iops throughput . it won't obviously minimize the cost, but given the choices i think  it is the only option"
      },
      {
        "date": "2023-04-06T19:12:00.000Z",
        "voteCount": 2,
        "content": "Both C and D can help to reduce the MAX Log IO performance. \n\nA checkpoint operation is a cost-effective way of managing transaction log growth in an Azure SQL database. It flushes the dirty pages from memory to disk and marks the transaction log as reusable, freeing up space in the log file.\n\nChanging the recovery model to Simple reduces log space usage, as it truncates the transaction log after every checkpoint. This can help address high MAX Log IO performance, but it also means that you will lose the ability to recover the database to a specific point in time.\n\nI think C is the best answer."
      },
      {
        "date": "2023-04-11T09:28:00.000Z",
        "voteCount": 5,
        "content": "C is correct answer, Azure SQL does not support Simple recovery model."
      },
      {
        "date": "2023-04-13T17:43:00.000Z",
        "voteCount": 1,
        "content": "A good catch!"
      },
      {
        "date": "2023-04-11T19:06:00.000Z",
        "voteCount": 2,
        "content": "Correct myself.\n\n A checkpoint operation writes the current in-memory modified pages (known as dirty pages) and transaction log information from memory to disk and, also, records information about the transaction log. This operation helps reduce the recovery time in case of a crash or other failure but does not directly reduce the Log IO percentage.\n\nThe answer is D."
      },
      {
        "date": "2024-01-23T07:58:00.000Z",
        "voteCount": 2,
        "content": "are you crazy?"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 47,
    "url": "https://www.examtopics.com/discussions/microsoft/view/105473-exam-dp-300-topic-3-question-47-discussion/",
    "body": "You have an Azure SQL database named DB1 that contains a nonclustered index named index1.<br><br>End users report slow queries when they use index1.<br><br>You need to identify the operations that are being performed on the index.<br><br>Which dynamic management view should you use?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSys.dm_exec_query_plan_stats",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSys.dm_db_index_physical_stats",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSys.dm_db_index_operational_stats\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSys.dm_db_index_useage_stats"
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 3,
        "isMostVoted": true
      },
      {
        "answer": "D",
        "count": 2,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2024-09-26T06:48:00.000Z",
        "voteCount": 2,
        "content": "D. sys.dm_db_index_usage_stats is correct.\n\nhttps://learn.microsoft.com/en-us/sql/relational-databases/system-dynamic-management-views/sys-dm-db-index-usage-stats-transact-sql?view=sql-server-ver16\n\nReturns counts of different types of index operations and the time each type of operation was last performed. (This aligns more with the question than ys.dm_db_index_operational_stats)."
      },
      {
        "date": "2024-07-05T09:50:00.000Z",
        "voteCount": 1,
        "content": "C seems the better answer\n\nC details : https://learn.microsoft.com/en-us/sql/relational-databases/system-dynamic-management-views/sys-dm-db-index-operational-stats-transact-sql?view=sql-server-ver16\n\nD details : https://learn.microsoft.com/en-us/sql/relational-databases/system-dynamic-management-views/sys-dm-db-index-usage-stats-transact-sql?view=sql-server-ver16"
      },
      {
        "date": "2024-06-22T16:54:00.000Z",
        "voteCount": 1,
        "content": "To identify the operations being performed on the nonclustered index named index1 in your Azure SQL database (DB1), you should use the following dynamic management view (DMV):\n\nC. Sys.dm_db_index_operational_stats\n\nHere\u2019s why this DMV is the correct choice:\n\nSys.dm_db_index_operational_stats: This DMV provides information about the operations performed on an index since the last time SQL Server was started or statistics were cleared. It includes counts of different types of operations, such as seeks, scans, updates, and deletes, which can help you understand how the index is being used by queries.\n\nMonitoring Index Usage: By querying Sys.dm_db_index_operational_stats for index1, you can gather insights into whether the index is being utilized efficiently or if there are certain operations (such as scans instead of seeks) that could be impacting query performance."
      },
      {
        "date": "2024-05-22T03:34:00.000Z",
        "voteCount": 1,
        "content": "For diagnosing slow queries and understanding the detailed operations performed on index1, sys.dm_db_index_operational_stats is the correct choice. It gives you the specific operational details that are necessary to identify and troubleshoot performance issues effectively. While sys.dm_db_index_usage_stats is useful for understanding overall usage patterns, it lacks the detailed operational metrics needed for in-depth performance analysis."
      },
      {
        "date": "2023-11-30T08:35:00.000Z",
        "voteCount": 1,
        "content": "C is the right answer according to Bing Chat"
      },
      {
        "date": "2023-10-31T07:23:00.000Z",
        "voteCount": 1,
        "content": "The correct answer is:\nC. Sys.dm_db_index_operational_stats\nThis dynamic management view contains information about various operations performed on an index, including the number of seeks, inserts, updates, and deletes."
      },
      {
        "date": "2023-04-22T22:01:00.000Z",
        "voteCount": 2,
        "content": "D. sys.dm_db_index_usage_stats\n\nEvery individual seek, scan, lookup, or update on the specified index by one query execution is counted as a use of that index and increments the corresponding counter in this view. Information is reported both for operations caused by user-submitted queries, and for operations caused by internally generated queries, such as scans for gathering statistics.\n\nhttps://learn.microsoft.com/en-us/sql/relational-databases/system-dynamic-management-views/sys-dm-db-index-usage-stats-transact-sql?view=sql-server-ver16#remarks"
      },
      {
        "date": "2023-04-06T19:50:00.000Z",
        "voteCount": 3,
        "content": "C: dm_db_index_operational_stats provides: the information of leaf_insert_count, leaf_delete_count, leaf_update_count\nD: dm_db_index_useage_stats provides: the information of USER_SEEKS, USER_SCANS, USER_LOOKUPS, USER_UPDATES\n\nFor the performance tuning, I choose D."
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 48,
    "url": "https://www.examtopics.com/discussions/microsoft/view/105475-exam-dp-300-topic-3-question-48-discussion/",
    "body": "HOTSPOT<br> -<br><br>You have an Azure SQL managed instance named SQLMI1 that hosts multiple databases.<br><br>You need to monitor the performance of SQLMI1 and identify which database uses the most memory and the most disk I/O.<br><br>Which objects should you query? To answer, select the appropriate options in the answer area.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/dp-300/image271.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/dp-300/image272.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2023-04-06T20:12:00.000Z",
        "voteCount": 12,
        "content": "For memory is sys.dm_os_buffer_descriptors. \n\nYou can use this query to prove:\n\nSELECT \n    DB_NAME(database_id) AS database_name, \n    COUNT(*) * 8/1024.0 AS cached_MB\nFROM \n    sys.dm_os_buffer_descriptors\nGROUP BY \n    database_id\nORDER BY \n    cached_MB DESC;\n\nFor I/O, the answer is correct. \n\nSELECT \n    DB_NAME(database_id) AS database_name,\n    SUM(num_of_reads + num_of_writes) AS total_io_operations\nFROM \n    sys.dm_io_virtual_file_stats(NULL, NULL) AS virt_file_stats\nGROUP BY \n    database_id\nORDER BY \n    total_io_operations DESC;"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 49,
    "url": "https://www.examtopics.com/discussions/microsoft/view/115275-exam-dp-300-topic-3-question-49-discussion/",
    "body": "HOTSPOT<br> -<br><br>You have an Azure subscription that contains an instance of SQL Server on Azure Virtual Machines. The virtual machine hosts a database named DB1.<br><br>You need to monitor DB1 by using Extended Events. The solution must meet the following requirements:<br><br>\u2022\tCapture raw event data and store the data in Azure Storage.<br>\u2022\tMinimize the performance impact of capturing extended events.<br><br>How should you complete the Transact-SQL statement? To answer, select the appropriate options in the answer area.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/dp-300/image287.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/dp-300/image288.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-04-25T09:26:00.000Z",
        "voteCount": 2,
        "content": "Answer given is correct: event_file and ALLOW_MULTIPLE_EVENT_LOSS\n\nhttps://learn.microsoft.com/en-us/sql/relational-databases/extended-events/targets-for-extended-events-in-sql-server?view=sql-server-ver16#event_file-target\n\nhttps://learn.microsoft.com/en-us/sql/t-sql/statements/create-event-session-transact-sql?view=sql-server-ver16"
      },
      {
        "date": "2023-09-12T19:05:00.000Z",
        "voteCount": 2,
        "content": "CREATE EVENT SESSION [YourSession]\n    ON SERVER\n    ADD EVENT sqlserver.sql_statement_completed\n    (\n        ACTION(sqlserver.sql_text)\n        WHERE\n        ( [sqlserver].[like_i_sql_unicode_string]([sqlserver].[sql_text], N'%SELECT%HAVING%')\n        )\n    )\n    ADD TARGET package0.event_file\n    (SET\n        filename = N'C:\\Junk\\YourSession_Target.xel',\n        max_file_size = (2),\n        max_rollover_files = (2)\n    )\n    WITH (\n        MAX_MEMORY = 2048 KB,\n        EVENT_RETENTION_MODE = ALLOW_MULTIPLE_EVENT_LOSS,\n        MAX_DISPATCH_LATENCY = 3 SECONDS,\n        MAX_EVENT_SIZE = 0 KB,\n        MEMORY_PARTITION_MODE = NONE,\n        TRACK_CAUSALITY = OFF,\n        STARTUP_STATE = OFF\n    );\nGO\n\nhttps://learn.microsoft.com/en-us/sql/relational-databases/extended-events/quick-start-extended-events-in-sql-server?view=sql-server-ver16"
      },
      {
        "date": "2023-07-15T12:42:00.000Z",
        "voteCount": 2,
        "content": "https://learn.microsoft.com/en-us/azure/azure-sql/database/xevent-db-diff-from-svr?view=azuresql-mi\nEvent File target code for extended events in Azure SQL Database\n\nPhase 1 is PowerShell to create an Azure Storage container.\nPhase 2 is Transact-SQL that uses the Azure Storage container."
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 50,
    "url": "https://www.examtopics.com/discussions/microsoft/view/115481-exam-dp-300-topic-3-question-50-discussion/",
    "body": "You have an Azure SQL database named DB1.<br><br>You need to query the fragmentation information of data and indexes for the tables in DB1.<br><br>Which command should you run?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tsys.dm_db_index_usage_stats",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDBCC CHECKALLOC",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDBCC SHOWCONTIG",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tsts.dm_db_index_physical_stats\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 7,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-07-16T12:45:00.000Z",
        "voteCount": 7,
        "content": "it's misspelled, sys.dm_db_index_physical_stats"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 51,
    "url": "https://www.examtopics.com/discussions/microsoft/view/124494-exam-dp-300-topic-3-question-51-discussion/",
    "body": "You have an Azure SQL managed instance named SQLMI1 that has the following settings:<br><br>\u2022\tvCores: 4<br>\u2022\tService tier: General Purpose<br>\u2022\tHardware generation: Standard-series (Gen5)<br><br>You discover that memory pressure on SQLMI1 is high.<br><br>You need to reduce the memory pressure on SQLMI1. The solution must minimize costs.<br><br>What should to do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEnable the Query Store.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tChange vCores to 8.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tChange Hardware generation to Premium-series.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tChange Service tier to Business Critical."
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 2,
        "isMostVoted": true
      },
      {
        "answer": "A",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2024-10-12T08:59:00.000Z",
        "voteCount": 1,
        "content": "The asnwer doesn't make sense.\nhttps://learn.microsoft.com/en-us/azure/azure-sql/managed-instance/resource-limits?view=azuresql\nWhat we have from the Pricing Calculator: Central US GP 4 vCore Standard 533.37$, memory 4*5.1=20.4GB\nA. no comments\nB. vCores = 8, memory = 8*5.1 = 40.8 - greater, so fine, the cost 1066.74$\nC. Premium vCores = 4, memory = 4*7 = 28 - greater, so fine, the cost 630.72$\nD. BC vCores = 4, memory = 4*5.1 = 20.4 - the same, not ok.\n28GB might not reduce the pressure, though 40.8GB might not reduce either. Therefore, 2 conditions of the task: 1. increase memory, 2. the lowest price.\nSo the answer must be C."
      },
      {
        "date": "2024-08-04T07:19:00.000Z",
        "voteCount": 1,
        "content": "Why Other Options Are Less Suitable\n\n    A. Enable the Query Store:\n        Enabling the Query Store is primarily used for performance monitoring and tuning. It doesn't directly reduce memory pressure and may actually increase memory usage slightly due to additional overhead.\n\n    C. Change Hardware Generation to Premium-series:\n        Changing the hardware generation to Premium-series would increase costs significantly without a direct increase in memory allocation unless coupled with more vCores. Premium-series hardware may offer improved performance and features but doesn't specifically address memory pressure by itself.\n\n    D. Change Service Tier to Business Critical:\n        Switching to the Business Critical tier significantly increases costs and is designed to improve performance, redundancy, and availability. It provides better IOPS and latency but may not be necessary if the primary issue is memory pressure."
      },
      {
        "date": "2024-04-19T04:57:00.000Z",
        "voteCount": 2,
        "content": "https://learn.microsoft.com/en-us/azure/azure-sql/managed-instance/resource-limits?view=azuresql\nI think the answer is correct"
      },
      {
        "date": "2024-06-28T14:13:00.000Z",
        "voteCount": 1,
        "content": "I think same, cheapest option will be change to vCores to 8, then changing hardware generation then Service Tier to BC."
      },
      {
        "date": "2023-10-31T07:39:00.000Z",
        "voteCount": 1,
        "content": "The correct answer is (A).\nThe Query Store option is a cost-effective way to reduce memory pressure on a managed Azure SQL instance. The Query Store stores temporary data used by queries in the cloud, reducing the memory requirements of the managed Azure SQL instance."
      },
      {
        "date": "2023-10-25T18:44:00.000Z",
        "voteCount": 1,
        "content": "I think it should be A."
      },
      {
        "date": "2023-10-23T18:02:00.000Z",
        "voteCount": 4,
        "content": "Answer should be:\n\nC. Change Hardware generation to Premium-series.\n\nBusiness critical tier would be too expensive compared to changing the hardware type. Also, changing the number of vcores would not resolve any memory-related issues."
      },
      {
        "date": "2023-10-23T18:03:00.000Z",
        "voteCount": 1,
        "content": "Sorry forgot one last thing on hardware type: standard series comes with less memory compared to premium-series.\n\nhttps://learn.microsoft.com/en-us/azure/azure-sql/managed-instance/resource-limits?view=azuresql"
      },
      {
        "date": "2024-02-28T07:47:00.000Z",
        "voteCount": 4,
        "content": "Memory for StandardSeries(Gen5) is 5.1 GB per vCore . Doubling the cores doubles the memory too."
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 52,
    "url": "https://www.examtopics.com/discussions/microsoft/view/139586-exam-dp-300-topic-3-question-52-discussion/",
    "body": "You have five instances of SQL Server on Azure Virtual Machines.<br><br>You need to monitor Microsoft SQL Server performance for all the instances by consolidating metrics into a single graphic display. The solution must minimize administrative effort.<br><br>What should you use?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure Monitor\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tLog Analytics",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSQL Insights",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure SQL Analytics"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 7,
        "isMostVoted": true
      },
      {
        "answer": "C",
        "count": 2,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2024-04-25T09:48:00.000Z",
        "voteCount": 5,
        "content": "I think it's Azure Monitor Agent since:\n\nThe Log Analytics agent is on a deprecation path and won't be supported after August 31, 2024. Any new data centers brought online after January 1 2024 will not support the Log Analytics agent. If you use the Log Analytics agent to ingest data to Azure Monitor, migrate to the new Azure Monitor agent prior to that date.\n\nhttps://learn.microsoft.com/en-us/azure/azure-monitor/agents/log-analytics-agent"
      },
      {
        "date": "2024-10-10T01:20:00.000Z",
        "voteCount": 1,
        "content": "Its A - why not C? - because SQL Insights is primarily used for monitoring SQL Server database performance and workloads. While it can help with detailed SQL performance insights, Azure Monitor provides a broader scope for consolidating metrics across multiple SQL instances."
      },
      {
        "date": "2024-08-30T00:52:00.000Z",
        "voteCount": 1,
        "content": "SQL Insight is the best choice here"
      },
      {
        "date": "2024-08-27T04:40:00.000Z",
        "voteCount": 1,
        "content": "SQL Insights is the optimal choice for monitoring SQL Server performance across multiple instances on Azure VMs, as it provides a consolidated view with minimal administrative overhead."
      },
      {
        "date": "2024-06-07T22:04:00.000Z",
        "voteCount": 1,
        "content": "A\uff1aAzure Monitor.\nNot B"
      },
      {
        "date": "2024-06-01T04:38:00.000Z",
        "voteCount": 1,
        "content": "I think Azure Monitor is the right answer"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 53,
    "url": "https://www.examtopics.com/discussions/microsoft/view/139588-exam-dp-300-topic-3-question-53-discussion/",
    "body": "You have an instance of SQL Server on Azure Virtual Machines named SQL1.<br><br>SQL1 contains an Extended Events session named session1 that captures Microsoft SQL Server events.<br><br>You need to correlate the session events with events captured by Event Tracing for Windows (ETW).<br><br>What should you do for session1?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tModify the Set Session Event Filters settings.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAdd a target.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAdd an action.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tModify the Specify Session Data Storage settings."
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 4,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-05-07T16:34:00.000Z",
        "voteCount": 3,
        "content": "The answer is B\n\nhttps://learn.microsoft.com/en-us/sql/relational-databases/extended-events/targets-for-extended-events-in-sql-server?view=sql-server-ver16#etw_classic_sync_target-target\n\nhttps://learn.microsoft.com/en-us/sql/relational-databases/extended-events/event-tracing-for-windows-target?view=sql-server-ver16"
      },
      {
        "date": "2024-04-25T09:53:00.000Z",
        "voteCount": 1,
        "content": "Answer B seems correct."
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 54,
    "url": "https://www.examtopics.com/discussions/microsoft/view/140148-exam-dp-300-topic-3-question-54-discussion/",
    "body": "You have an Azure subscription that contains the following resources:<br><br>\u2022\t10 Azure SQL databases<br>\u2022\tFive Azure SQL managed instances<br>\u2022\tFive instances of SQL Server on Azure Virtual Machines<br><br>You need to implement a centralized monitoring solution for all the Azure SQL resources. The solution must minimize administrative effort.<br><br>What should you include in the solution?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tLog Analytics",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure SQL Analytics",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tQuery Performance Insight",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSQL Insights\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 3,
        "isMostVoted": true
      },
      {
        "answer": "B",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2024-10-10T12:52:00.000Z",
        "voteCount": 1,
        "content": "definitely D , for the stated reasons below"
      },
      {
        "date": "2024-09-19T16:41:00.000Z",
        "voteCount": 1,
        "content": "my Vote B"
      },
      {
        "date": "2024-05-07T16:41:00.000Z",
        "voteCount": 3,
        "content": "Answer is D. \n\nSQL Insights is the only option that monitors SQL Server on Azure VM, Azure SQL Database and Azure SQL Managed Instance.\n\nhttps://learn.microsoft.com/en-us/azure/azure-sql/database/sql-insights-overview?view=azuresql"
      },
      {
        "date": "2024-06-28T14:22:00.000Z",
        "voteCount": 2,
        "content": "yes you are right, VMs are not supported by SQL Analytics"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 55,
    "url": "https://www.examtopics.com/discussions/microsoft/view/139666-exam-dp-300-topic-3-question-59-discussion/",
    "body": "Case study -<br><br>This is a case study. Case studies are not timed separately. You can use as much exam time as you would like to complete each case. However, there may be additional case studies and sections on this exam. You must manage your time to ensure that you are able to complete all questions included on this exam in the time provided.<br><br>To answer the questions included in a case study, you will need to reference information that is provided in the case study. Case studies might contain exhibits and other resources that provide more information about the scenario that is described in the case study. Each question is independent of the other questions in this case study.<br><br>At the end of this case study, a review screen will appear. This screen allows you to review your answers and to make changes before you move to the next section of the exam. After you begin a new section, you cannot return to this section.<br><br><br>To start the case study -<br><br>To display the first question in this case study, click the Next button. Use the buttons in the left pane to explore the content of the case study before you answer the questions. Clicking these buttons displays information such as business requirements, existing environment, and problem statements. If the case study has an All Information tab, note that the information displayed is identical to the information displayed on the subsequent tabs. When you are ready to answer a question, click the Question button to return to the question.<br><br><br>Overview -<br><br>ADatum Corporation is a financial services company that has a main office in New York City.<br><br>Existing Environment. Licensing Agreement<br><br>ADatum has a Microsoft Volume Licensing agreement that includes Software Assurance.<br><br>Existing Environment. Network Infrastructure<br><br>ADatum has an on-premises datacenter and an Azure subscription named Sub1.<br><br>Sub1 contains a virtual network named Network1 in the East US Azure region.<br><br>The datacenter is connected to Network1 by using a Site-to-Site (S2S) VPN.<br><br>Existing Environment. Identity Environment<br><br>The on-premises network contains an Active Directory Domain Services (AD DS) forest.<br><br>The forest contains a single domain named corp.adatum.com.<br><br>The corp.adatum.com domain syncs with a Microsoft Entra tenant named adatum.com.<br><br>Existing Environment. Database Environment<br><br>The datacenter contains the servers shown in the following table.<br><br><img src=\"https://img.examtopics.com/dp-300/image306.png\"><br><br>DB1 and DB2 are used for transactional and analytical workloads by an application named App1.<br><br>App1 runs on Microsoft Entra hybrid joined servers that run Windows Server 2022. App1 uses Kerberos authentication.<br><br>DB3 stores compliance data used by two applications named App2 and App3.<br><br>DB3 performance is monitored by using Extended Events sessions, with the event_file target set to a file share on a local disk of SVR3.<br><br>Resource allocation for DB3 is managed by using Resource Governor.<br><br><br>Requirements. Planned Changes -<br><br>ADatum plans to implement the following changes:<br><br>\u2022\tDeploy an Azure SQL managed instance named Instance1 to Network1.<br>\u2022\tMigrate DB1 and DB2 to Instance1.<br>\u2022\tMigrate DB3 to Azure SQL Database.<br>\u2022\tFollowing the migration of DB1 and DB2, hand over database development to remote developers who use Microsoft Entra joined Windows 11 devices.<br>\u2022\tFollowing the migration of DB3, configure the database to be part of an auto-failover group.<br><br>Requirements. Availability Requirements<br><br>ADatum identifies the following post-migration availability requirements:<br><br>\u2022\tFor DB1 and DB2, offload analytical workloads to a read-only database replica in the same Azure region.<br>\u2022\tEnsure that if a regional disaster occurs, DB1 and DB2 can be recovered from backups.<br>\u2022\tAfter the migration, App1 must maintain access to DB1 and DB2.<br>\u2022\tFor DB3, manage potential performance issues caused by resource demand changes by App2 and App3.<br>\u2022\tEnsure that DB3 will still be accessible following a planned failover.<br>\u2022\tEnsure that DB3 can be restored if the logical server is deleted.<br>\u2022\tMinimize downtime during the migration of DB1 and DB2.<br><br>Requirements. Security Requirements<br><br>ADatum identifies the following security requirements for after the migration:<br><br>\u2022\tEnsure that only designated developers who use Microsoft Entra joined Windows 11 devices can access DB1 and DB2 remotely.<br>\u2022\tEnsure that all changes to DB3, including ones within individual transactions, are audited and recorded.<br><br>Requirements. Management Requirements<br><br>ADatum identifies the following post-migration management requirements:<br><br>\u2022\tContinue using Extended Events to monitor DB3.<br>\u2022\tIn Azure SQL Database, automate the management of DB3 by using elastic jobs that have database-scoped credentials.<br><br>Requirements. Business Requirements<br><br>ADatum identifies the following business requirements:<br><br>\u2022\tMinimize costs whenever possible, without affecting other requirements.<br>\u2022\tMinimize administrative effort.<br><br><br>You need to recommend a solution to meet the security requirements and the business requirements for DB3.<br><br>What should you recommend as the first step of the solution?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRun the sp_addarticle stored procedure.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRun the ALTER TABLE statement and specify the ENABLE CHANGE_TRACKING Clause.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRun the ALTER DATABASE statement and specify the SET CHANGE_TRACKING = ON Clause.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRun the sys.sp_cdc_enable_db stored procedure.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 3,
        "isMostVoted": true
      },
      {
        "answer": "C",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2024-10-10T14:05:00.000Z",
        "voteCount": 1,
        "content": "Chat - D - sp_addarticle is used for replication, which is not relevant for this scenario.\nChange Tracking (options B and C) is focused on tracking which rows have changed, but it does not provide a detailed audit trail of all changes within individual transactions, unlike CDC.\nTherefore, enabling Change Data Capture with the sys.sp_cdc_enable_db stored procedure aligns with the requirement to audit and record changes."
      },
      {
        "date": "2024-09-28T08:26:00.000Z",
        "voteCount": 1,
        "content": "Answer Correct  C\nAccording to implementation, DB3 should move to Azure SQL Databases.\nChange Data Capture (CDC) is enabled by default in Azure SQL Database,Azure SQL Managed Instance.\nHence, there is no need to enable it!"
      },
      {
        "date": "2024-07-29T12:50:00.000Z",
        "voteCount": 1,
        "content": "You need cdc, not cdtjavascript:void(0). Correct answer is D."
      },
      {
        "date": "2024-05-07T17:00:00.000Z",
        "voteCount": 3,
        "content": "The answer is D.\n\nBefore you can create a capture instance for individual tables, you must enable CDC for your Azure SQL Database.\n\nTo enable CDC, connect to your Azure SQL Database through Azure Data Studio or SQL Server Management Studio (SSMS). Open a new query window, then enable CDC by running the following T-SQL:\nEXEC sys.sp_cdc_enable_db;\nGO\n\nhttps://learn.microsoft.com/en-us/azure/azure-sql/database/change-data-capture-overview?view=azuresql#enable-cdc-for-azure-sql-database"
      },
      {
        "date": "2024-04-26T11:36:00.000Z",
        "voteCount": 1,
        "content": "I think it's actually D"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 56,
    "url": "https://www.examtopics.com/discussions/microsoft/view/139667-exam-dp-300-topic-3-question-60-discussion/",
    "body": "Case study -<br><br>This is a case study. Case studies are not timed separately. You can use as much exam time as you would like to complete each case. However, there may be additional case studies and sections on this exam. You must manage your time to ensure that you are able to complete all questions included on this exam in the time provided.<br><br>To answer the questions included in a case study, you will need to reference information that is provided in the case study. Case studies might contain exhibits and other resources that provide more information about the scenario that is described in the case study. Each question is independent of the other questions in this case study.<br><br>At the end of this case study, a review screen will appear. This screen allows you to review your answers and to make changes before you move to the next section of the exam. After you begin a new section, you cannot return to this section.<br><br><br>To start the case study -<br><br>To display the first question in this case study, click the Next button. Use the buttons in the left pane to explore the content of the case study before you answer the questions. Clicking these buttons displays information such as business requirements, existing environment, and problem statements. If the case study has an All Information tab, note that the information displayed is identical to the information displayed on the subsequent tabs. When you are ready to answer a question, click the Question button to return to the question.<br><br><br>Overview -<br><br>ADatum Corporation is a financial services company that has a main office in New York City.<br><br>Existing Environment. Licensing Agreement<br><br>ADatum has a Microsoft Volume Licensing agreement that includes Software Assurance.<br><br>Existing Environment. Network Infrastructure<br><br>ADatum has an on-premises datacenter and an Azure subscription named Sub1.<br><br>Sub1 contains a virtual network named Network1 in the East US Azure region.<br><br>The datacenter is connected to Network1 by using a Site-to-Site (S2S) VPN.<br><br>Existing Environment. Identity Environment<br><br>The on-premises network contains an Active Directory Domain Services (AD DS) forest.<br><br>The forest contains a single domain named corp.adatum.com.<br><br>The corp.adatum.com domain syncs with a Microsoft Entra tenant named adatum.com.<br><br>Existing Environment. Database Environment<br><br>The datacenter contains the servers shown in the following table.<br><br><img src=\"https://img.examtopics.com/dp-300/image306.png\"><br><br>DB1 and DB2 are used for transactional and analytical workloads by an application named App1.<br><br>App1 runs on Microsoft Entra hybrid joined servers that run Windows Server 2022. App1 uses Kerberos authentication.<br><br>DB3 stores compliance data used by two applications named App2 and App3.<br><br>DB3 performance is monitored by using Extended Events sessions, with the event_file target set to a file share on a local disk of SVR3.<br><br>Resource allocation for DB3 is managed by using Resource Governor.<br><br><br>Requirements. Planned Changes -<br><br>ADatum plans to implement the following changes:<br><br>\u2022\tDeploy an Azure SQL managed instance named Instance1 to Network1.<br>\u2022\tMigrate DB1 and DB2 to Instance1.<br>\u2022\tMigrate DB3 to Azure SQL Database.<br>\u2022\tFollowing the migration of DB1 and DB2, hand over database development to remote developers who use Microsoft Entra joined Windows 11 devices.<br>\u2022\tFollowing the migration of DB3, configure the database to be part of an auto-failover group.<br><br>Requirements. Availability Requirements<br><br>ADatum identifies the following post-migration availability requirements:<br><br>\u2022\tFor DB1 and DB2, offload analytical workloads to a read-only database replica in the same Azure region.<br>\u2022\tEnsure that if a regional disaster occurs, DB1 and DB2 can be recovered from backups.<br>\u2022\tAfter the migration, App1 must maintain access to DB1 and DB2.<br>\u2022\tFor DB3, manage potential performance issues caused by resource demand changes by App2 and App3.<br>\u2022\tEnsure that DB3 will still be accessible following a planned failover.<br>\u2022\tEnsure that DB3 can be restored if the logical server is deleted.<br>\u2022\tMinimize downtime during the migration of DB1 and DB2.<br><br>Requirements. Security Requirements<br><br>ADatum identifies the following security requirements for after the migration:<br><br>\u2022\tEnsure that only designated developers who use Microsoft Entra joined Windows 11 devices can access DB1 and DB2 remotely.<br>\u2022\tEnsure that all changes to DB3, including ones within individual transactions, are audited and recorded.<br><br>Requirements. Management Requirements<br><br>ADatum identifies the following post-migration management requirements:<br><br>\u2022\tContinue using Extended Events to monitor DB3.<br>\u2022\tIn Azure SQL Database, automate the management of DB3 by using elastic jobs that have database-scoped credentials.<br><br>Requirements. Business Requirements<br><br>ADatum identifies the following business requirements:<br><br>\u2022\tMinimize costs whenever possible, without affecting other requirements.<br>\u2022\tMinimize administrative effort.<br><br><br>You need to recommend a solution to ensure that the performance of DB3 is optimized after the migration to Azure SQL Database. The solution must meet availability requirements.<br><br>What should you include in the recommendation?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tvertical scaling\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ta custom resource pool",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tResource Governor",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\thorizontal scaling"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 3,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-10-10T14:09:00.000Z",
        "voteCount": 1,
        "content": "A - vertical scaling - Azure SQL Database supports vertical scaling, which allows you to adjust the compute resources (such as CPU and memory) for a database based on the workload demands. This is essential for managing performance issues, especially if App2 and App3's resource demands increase over time.\nResource Governor (Option C) is used in on-premises SQL Server to manage SQL resources and is not available in Azure SQL Database.\nHorizontal scaling (Option D) is typically used in distributed systems, but Azure SQL Database does not support native horizontal scaling in the same sense. Instead, you can scale up or down vertically.\nA custom resource pool (Option B) applies to SQL Server but is not available for Azure SQL Database."
      },
      {
        "date": "2024-05-17T12:44:00.000Z",
        "voteCount": 3,
        "content": "I stand correct option A is the best choice"
      },
      {
        "date": "2024-05-17T12:39:00.000Z",
        "voteCount": 2,
        "content": "I think the option B is correct"
      },
      {
        "date": "2024-08-04T09:48:00.000Z",
        "voteCount": 1,
        "content": "no, its A. You cannot have custom resource pool in VM"
      },
      {
        "date": "2024-06-28T14:46:00.000Z",
        "voteCount": 2,
        "content": "Consider these two also \n\u2022 Minimize costs whenever possible, without affecting other requirements.\n\u2022 Minimize administrative effort.\n\nSo overall Vertical Scaling can be more costly, but instant boost. Less admin effort. So I will go with A"
      },
      {
        "date": "2024-05-07T17:12:00.000Z",
        "voteCount": 3,
        "content": "Answer is A\nhttps://learn.microsoft.com/en-us/azure/azure-sql/database/failover-group-configure-sql-db?view=azuresql&amp;tabs=azure-portal%2Cazure-powershell-manage&amp;pivots=azure-sql-single-db#upgrading-or-downgrading-primary-database\n\nAnswer is NOT C because you cannot use resource governor with Azure SQL Database."
      },
      {
        "date": "2024-04-26T11:39:00.000Z",
        "voteCount": 1,
        "content": "Resource governor - C"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 57,
    "url": "https://www.examtopics.com/discussions/microsoft/view/139669-exam-dp-300-topic-3-question-61-discussion/",
    "body": "Case study -<br><br>This is a case study. Case studies are not timed separately. You can use as much exam time as you would like to complete each case. However, there may be additional case studies and sections on this exam. You must manage your time to ensure that you are able to complete all questions included on this exam in the time provided.<br><br>To answer the questions included in a case study, you will need to reference information that is provided in the case study. Case studies might contain exhibits and other resources that provide more information about the scenario that is described in the case study. Each question is independent of the other questions in this case study.<br><br>At the end of this case study, a review screen will appear. This screen allows you to review your answers and to make changes before you move to the next section of the exam. After you begin a new section, you cannot return to this section.<br><br><br>To start the case study -<br><br>To display the first question in this case study, click the Next button. Use the buttons in the left pane to explore the content of the case study before you answer the questions. Clicking these buttons displays information such as business requirements, existing environment, and problem statements. If the case study has an All Information tab, note that the information displayed is identical to the information displayed on the subsequent tabs. When you are ready to answer a question, click the Question button to return to the question.<br><br><br>Overview -<br><br>ADatum Corporation is a financial services company that has a main office in New York City.<br><br>Existing Environment. Licensing Agreement<br><br>ADatum has a Microsoft Volume Licensing agreement that includes Software Assurance.<br><br>Existing Environment. Network Infrastructure<br><br>ADatum has an on-premises datacenter and an Azure subscription named Sub1.<br><br>Sub1 contains a virtual network named Network1 in the East US Azure region.<br><br>The datacenter is connected to Network1 by using a Site-to-Site (S2S) VPN.<br><br>Existing Environment. Identity Environment<br><br>The on-premises network contains an Active Directory Domain Services (AD DS) forest.<br><br>The forest contains a single domain named corp.adatum.com.<br><br>The corp.adatum.com domain syncs with a Microsoft Entra tenant named adatum.com.<br><br>Existing Environment. Database Environment<br><br>The datacenter contains the servers shown in the following table.<br><br><img src=\"https://img.examtopics.com/dp-300/image306.png\"><br><br>DB1 and DB2 are used for transactional and analytical workloads by an application named App1.<br><br>App1 runs on Microsoft Entra hybrid joined servers that run Windows Server 2022. App1 uses Kerberos authentication.<br><br>DB3 stores compliance data used by two applications named App2 and App3.<br><br>DB3 performance is monitored by using Extended Events sessions, with the event_file target set to a file share on a local disk of SVR3.<br><br>Resource allocation for DB3 is managed by using Resource Governor.<br><br><br>Requirements. Planned Changes -<br><br>ADatum plans to implement the following changes:<br><br>\u2022\tDeploy an Azure SQL managed instance named Instance1 to Network1.<br>\u2022\tMigrate DB1 and DB2 to Instance1.<br>\u2022\tMigrate DB3 to Azure SQL Database.<br>\u2022\tFollowing the migration of DB1 and DB2, hand over database development to remote developers who use Microsoft Entra joined Windows 11 devices.<br>\u2022\tFollowing the migration of DB3, configure the database to be part of an auto-failover group.<br><br>Requirements. Availability Requirements<br><br>ADatum identifies the following post-migration availability requirements:<br><br>\u2022\tFor DB1 and DB2, offload analytical workloads to a read-only database replica in the same Azure region.<br>\u2022\tEnsure that if a regional disaster occurs, DB1 and DB2 can be recovered from backups.<br>\u2022\tAfter the migration, App1 must maintain access to DB1 and DB2.<br>\u2022\tFor DB3, manage potential performance issues caused by resource demand changes by App2 and App3.<br>\u2022\tEnsure that DB3 will still be accessible following a planned failover.<br>\u2022\tEnsure that DB3 can be restored if the logical server is deleted.<br>\u2022\tMinimize downtime during the migration of DB1 and DB2.<br><br>Requirements. Security Requirements<br><br>ADatum identifies the following security requirements for after the migration:<br><br>\u2022\tEnsure that only designated developers who use Microsoft Entra joined Windows 11 devices can access DB1 and DB2 remotely.<br>\u2022\tEnsure that all changes to DB3, including ones within individual transactions, are audited and recorded.<br><br>Requirements. Management Requirements<br><br>ADatum identifies the following post-migration management requirements:<br><br>\u2022\tContinue using Extended Events to monitor DB3.<br>\u2022\tIn Azure SQL Database, automate the management of DB3 by using elastic jobs that have database-scoped credentials.<br><br>Requirements. Business Requirements<br><br>ADatum identifies the following business requirements:<br><br>\u2022\tMinimize costs whenever possible, without affecting other requirements.<br>\u2022\tMinimize administrative effort.<br><br><br>You need to identify the event_file target for monitoring DB3 after the migration to Azure SQL Database. The solution must meet the management requirements.<br><br>What should you use as the event_file target?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ta SQL Server filegroup",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tan Azure SQL database",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tan Azure Files share",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tan Azure Blob Storage container\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 1,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-10-10T14:13:00.000Z",
        "voteCount": 1,
        "content": "D. an Azure Blob Storage container\n\nExplanation:\nIn Azure SQL Database, when you need to use Extended Events and store the event file target, Azure Blob Storage is the recommended option. It allows you to store the generated event data securely and access it later for analysis.\nAzure SQL Database does not support direct access to a SQL Server filegroup (Option A) or the use of a local file system like in on-premises environments, which eliminates Options B and C."
      },
      {
        "date": "2024-04-26T11:51:00.000Z",
        "voteCount": 1,
        "content": "D. an Azure Blob Storage container"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 58,
    "url": "https://www.examtopics.com/discussions/microsoft/view/149006-exam-dp-300-topic-3-question-62-discussion/",
    "body": "HOTSPOT<br> -<br><br>You have an Azure virtual machine named Server1 that has Microsoft SQL Server installed. Server1 contains a database named DB1.<br><br>You have a logical SQL server named ASVR1 that contains an Azure SQL database named ADB1.<br><br>You plan to use SQL Data Sync to migrate DB1 from Server1 to ASVR1.<br><br>You need to prepare the environment for the migration. The solution must ensure that the connection from Server1 to ADB1 does NOT use a public endpoint.<br><br>What should you do? To answer, select the appropriate options in the answer area.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/dp-300/image343.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/dp-300/image344.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-10-10T14:21:00.000Z",
        "voteCount": 1,
        "content": "agree with given answer - Azure Private Link allows private connectivity to Azure services from within a private virtual network without exposing your data to the public internet, which aligns with the requirement of avoiding public endpoints - and Snapshot Isolation helps in minimizing locking issues and ensures that the data reads during the migration are consistent without blocking operations. This isolation level is well-suited for data synchronization tasks, as it prevents long locks on tables during the sync operation, enhancing performance and concurrency"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 59,
    "url": "https://www.examtopics.com/discussions/microsoft/view/149007-exam-dp-300-topic-3-question-63-discussion/",
    "body": "HOTSPOT<br> -<br><br>You have an Azure SQL managed instance named Server1 and an Azure Blob Storage account named storage1 that contains Microsoft SQL Server database backup files.<br><br>You plan to use Log Replay Service to migrate the backup files from storage1 to Server1. The solution must use the highest level of security when connecting to storage1.<br><br>Which PowerShell cmdlet should you run, and which parameter should you specify to secure the connection? To answer, select the appropriate options in the answer area.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/dp-300/image345.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/dp-300/image346.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-10-10T14:23:00.000Z",
        "voteCount": 1,
        "content": "agree with given answer - Cmdlet:\nStart-AzSqlInstanceDatabaseLogReplay\n\nThis cmdlet is used to initiate the process of log replay and migration from Azure Blob Storage to an Azure SQL Managed Instance.\n\nParameter:\nManagedIdentity\n\nUsing Managed Identity provides the highest level of security because it eliminates the need for manual credentials (like Shared Access Signatures or Storage Account Keys). Managed Identity securely authenticates the service with Azure Blob Storage without exposing sensitive keys."
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "3"
  }
]