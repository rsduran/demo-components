[
  {
    "topic": 2,
    "index": 1,
    "url": "https://www.examtopics.com/discussions/microsoft/view/79434-exam-pl-300-topic-2-question-1-discussion/",
    "body": "You are creating a report in Power BI Desktop.<br>You load a data extract that includes a free text field named coll.<br>You need to analyze the frequency distribution of the string lengths in col1. The solution must not affect the size of the model.<br>What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tIn the report, add a DAX calculated column that calculates the length of col1",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tIn the report, add a DAX function that calculates the average length of col1",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tFrom Power Query Editor, add a column that calculates the length of col1",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tFrom Power Query Editor, change the distribution for the Column profile to group by length for col1\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 251,
        "isMostVoted": true
      },
      {
        "answer": "A",
        "count": 16,
        "isMostVoted": false
      },
      {
        "answer": "C",
        "count": 9,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2022-09-02T07:44:00.000Z",
        "voteCount": 128,
        "content": "Wrong answer, A will affect the size of the model as would C.\nB doesn't give you enough information about the distribution (just the average)\nD is the right answer."
      },
      {
        "date": "2023-05-13T15:19:00.000Z",
        "voteCount": 1,
        "content": "for D to be correct we need to calculate length of the strings in col1 beforehand so it is not correct"
      },
      {
        "date": "2023-06-09T02:13:00.000Z",
        "voteCount": 16,
        "content": "If you enable to column profile from view menu, you can actually group the distribution by text length. It is not grouping the actual column, rather just grouping the distribution."
      },
      {
        "date": "2022-09-08T09:26:00.000Z",
        "voteCount": 2,
        "content": "I agree"
      },
      {
        "date": "2022-11-21T06:00:00.000Z",
        "voteCount": 2,
        "content": "I agree completely!"
      },
      {
        "date": "2022-11-09T04:44:00.000Z",
        "voteCount": 17,
        "content": "Why do you think that aggregating in the PowerQuery size will not influence the size of the datamodel? its getting smaller isnt it?\nMeasures are the only solutions that does not influence the datamodel. They require CPU but but does not store additional data or does not reduce the data in the model"
      },
      {
        "date": "2024-03-13T03:37:00.000Z",
        "voteCount": 2,
        "content": "D is not aggregating in power query, it's viewing the column profile"
      },
      {
        "date": "2023-01-03T02:01:00.000Z",
        "voteCount": 7,
        "content": "Option B is also correct for me\nit's the only one that will not affect the size of the model"
      },
      {
        "date": "2023-01-18T02:20:00.000Z",
        "voteCount": 11,
        "content": "Yes, option B will not affect the size of the model, but it won't show us the frequency distribution, which is what we really need. Option D doesn't create any new column, it only changes how the column distribution is displayed, so it won't affect the size of the model"
      },
      {
        "date": "2023-04-29T16:05:00.000Z",
        "voteCount": 4,
        "content": "why doesn't B affect the size of the model but A does?"
      },
      {
        "date": "2022-12-26T09:22:00.000Z",
        "voteCount": 5,
        "content": "Option A is saying useing calculated column which increases the size of the model. So D is correct."
      },
      {
        "date": "2022-10-05T15:36:00.000Z",
        "voteCount": 78,
        "content": "Its D, this can easily be tested by going to Power Query Editor &gt; View &gt; Column Profile &gt; distribution graph, click the three little dots and select group by text length. This will allow you to view the distribution of text length within the column"
      },
      {
        "date": "2023-02-15T08:48:00.000Z",
        "voteCount": 7,
        "content": "The problem is this method doesn't make the distribution analyzable in the report, which I think is what the question is getting at. It will show you the distribution but you need a dax measure to place in your report to visualize that. I would go with option B as it creates a measure which you can use in the report, and it doesn't contribute to the size of the model as with A."
      },
      {
        "date": "2023-01-15T02:45:00.000Z",
        "voteCount": 2,
        "content": "D is correct and it can be tested by following step mentioned by Lukelin08"
      },
      {
        "date": "2024-01-18T07:06:00.000Z",
        "voteCount": 1,
        "content": "Thank you, just tested and it works. D has to be the answer, as it doesn't impact the model size"
      },
      {
        "date": "2023-07-21T06:38:00.000Z",
        "voteCount": 2,
        "content": "Make sure your column type is not \"variant\" ;)"
      },
      {
        "date": "2024-10-11T12:56:00.000Z",
        "voteCount": 1,
        "content": "option D is correct"
      },
      {
        "date": "2024-09-29T21:11:00.000Z",
        "voteCount": 1,
        "content": "C: Tried and tested\nTransform Data -&gt; Add Column -&gt; Extract -&gt; Length"
      },
      {
        "date": "2024-09-29T22:30:00.000Z",
        "voteCount": 1,
        "content": "As adding a Column can increase the model size, so this option does not work here."
      },
      {
        "date": "2024-09-28T02:01:00.000Z",
        "voteCount": 1,
        "content": "calculted columns will increase the size of the models so those are out and the other is finding the average leavind D as correct"
      },
      {
        "date": "2024-08-14T07:56:00.000Z",
        "voteCount": 2,
        "content": "for me is D. From Power Query Editor, change the distribution for the Column profile to group by length for col1"
      },
      {
        "date": "2024-08-20T00:53:00.000Z",
        "voteCount": 1,
        "content": "Tested it is D for sure. In power Query Editor, View check column profile. There is the possibility to group by value or text lenght. Choose text lenght and this will show the lenght of col1"
      },
      {
        "date": "2024-08-11T02:55:00.000Z",
        "voteCount": 1,
        "content": "Upon a little research it turns out that calculated columns=larger data models.\nOption A &amp; C: both introduce a new column. Will affect the size of the model.\nOption B: As muffin show and mubarakbabs stated above, it doesn't give us enough info (only avg)\n\nAns must be D.\n\n"
      },
      {
        "date": "2024-07-21T04:12:00.000Z",
        "voteCount": 1,
        "content": "correct answer"
      },
      {
        "date": "2024-05-08T05:24:00.000Z",
        "voteCount": 1,
        "content": "D for me"
      },
      {
        "date": "2024-05-05T02:11:00.000Z",
        "voteCount": 1,
        "content": "I also think D as it won't affect the data model size"
      },
      {
        "date": "2024-04-17T15:04:00.000Z",
        "voteCount": 1,
        "content": "D. It says to analyze, which means in the context of this question, look at to determine. It also states it must not affect the model size. A calculated dax column will affect size of the model. D is perfect, because with the column profile tool you able to see the exact information that are looking for."
      },
      {
        "date": "2024-03-12T05:31:00.000Z",
        "voteCount": 2,
        "content": "A is right, but B looks correct to me as well"
      },
      {
        "date": "2024-03-10T03:35:00.000Z",
        "voteCount": 1,
        "content": "D works just fine and DOES NOT affects the model size."
      },
      {
        "date": "2024-02-25T23:49:00.000Z",
        "voteCount": 2,
        "content": "I think sometimes it's better to stay grounded and read the question for what it is.\n\nrelying on facts only;\nyou create a REPORT\nyou load data\nyou need to be able to see frequency distribution of Len(col1) (supposedly on the report as you just were asked to create one, make sense?)\n\nIn the available answers you have 2 options from REPORT\nOne calculates sum, the other average.\nJust go for the sum which is answer A\n\nAs everyone knows DAX creates new info from data ALREADY in your model.\nIn Power query you need to close and apply to use your new info(=&gt; affects model)"
      },
      {
        "date": "2024-01-27T08:03:00.000Z",
        "voteCount": 1,
        "content": "Option D , doesnot allow you to see the string length of each row, just shows Min and Max"
      },
      {
        "date": "2024-01-26T15:32:00.000Z",
        "voteCount": 1,
        "content": "Why is A the right answer when 91% of the community indicates it's D? That question is for Exam Topics the company, not the community."
      },
      {
        "date": "2024-01-14T23:56:00.000Z",
        "voteCount": 1,
        "content": "I tried. D is the correct answer"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 2,
    "url": "https://www.examtopics.com/discussions/microsoft/view/80551-exam-pl-300-topic-2-question-2-discussion/",
    "body": "You have a collection of reports for the HR department of your company. The datasets use row-level security (RLS). The company has multiple sales regions.<br>Each sales region has an HR manager.<br>You need to ensure that the HR managers can interact with the data from their region only. The HR managers must be prevented from changing the layout of the reports.<br>How should you provision access to the reports for the HR managers?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tPublish the reports in an app and grant the HR managers access permission.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a new workspace, copy the datasets and reports, and add the HR managers as members of the workspace.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tPublish the reports to a different workspace other than the one hosting the datasets.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAdd the HR managers as members of the existing workspace that hosts the reports and the datasets."
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 53,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2022-09-08T09:39:00.000Z",
        "voteCount": 34,
        "content": "I would say it is correct since an app would prevent to change the layout"
      },
      {
        "date": "2024-10-03T04:29:00.000Z",
        "voteCount": 26,
        "content": "Option A (Publish the reports in an app and grant the HR managers access permission) would be the best option to provide the HR managers with access to the reports while restricting them from modifying the layout.\n\nBy publishing the reports in an app and granting the HR managers access permission, you can assign them specific roles and permissions that restrict their access to the underlying data while allowing them to view and interact with the reports. The RLS configuration can be set up to ensure that the HR managers can only see data from their own sales region."
      },
      {
        "date": "2024-08-14T08:02:00.000Z",
        "voteCount": 1,
        "content": "A is the correct answer"
      },
      {
        "date": "2024-08-20T02:01:00.000Z",
        "voteCount": 2,
        "content": "Tested, I created RLS and published to an app. Creating an app will prevent managers or final users to modify the report itself"
      },
      {
        "date": "2024-07-21T04:15:00.000Z",
        "voteCount": 1,
        "content": "correct answer"
      },
      {
        "date": "2024-05-07T08:19:00.000Z",
        "voteCount": 1,
        "content": "A is correct"
      },
      {
        "date": "2024-05-02T09:16:00.000Z",
        "voteCount": 4,
        "content": "We can rule out B &amp; D because of the below: \nRLS only restricts data access for users with Viewer permissions. It doesn't apply to Admins, Members, or Contributors.\nSeem C doesn't grant any access. So answer must be A."
      },
      {
        "date": "2024-04-16T05:05:00.000Z",
        "voteCount": 1,
        "content": "I don't think any of these options present a complete answer. you would manage what data each manager can view by using the manage role option in BI desktop and setting up a rule. this would be dependent upon having a manager dimension that contained details about which region each manager had responsibility for\n\nhttps://learn.microsoft.com/en-us/power-bi/report-server/row-level-security-report-server"
      },
      {
        "date": "2024-04-16T05:08:00.000Z",
        "voteCount": 2,
        "content": "although, if I had to choose, it would be A\n\nhttps://learn.microsoft.com/en-us/power-bi/consumer/end-user-apps"
      },
      {
        "date": "2024-03-25T02:38:00.000Z",
        "voteCount": 1,
        "content": "A is correct"
      },
      {
        "date": "2023-10-25T16:16:00.000Z",
        "voteCount": 1,
        "content": "Nice question"
      },
      {
        "date": "2023-09-04T20:17:00.000Z",
        "voteCount": 1,
        "content": "B is the correct answer. \nThis approach is correct because:\n* Isolation: By creating a new workspace, we can keep the HR manager's reports separate from others, ensuring that they only have access to their own data and reports. \n* Access Control: We can add the HR managers as members of this specific workspace, granting them access to the datasets and reports they need while maintaining control over who can make changes the layout or content of the reports.\n* No impact on Existing reports: This approach does not affect the existing workspace that may contain reports for other departments or regions. It allows us to apply RLS and access control specifically for the HR managers without affecting other users."
      },
      {
        "date": "2023-11-26T07:03:00.000Z",
        "voteCount": 3,
        "content": "Member can edit or delete B is not an option here. Correct answer should be A"
      },
      {
        "date": "2023-07-18T13:51:00.000Z",
        "voteCount": 3,
        "content": "It's annoying because I actually just did this today and got the answer wrong because I didn't think any of them were right/complete.  What you do is go to Manage Profiles and create roles where each one is filtered by region.  Then upload to the PBI server, assign roles to the respective HR managers, and provide them with viewer permissions so they can't open the reports in desktop mode."
      },
      {
        "date": "2023-09-08T09:08:00.000Z",
        "voteCount": 1,
        "content": "so A is not the correct answer?"
      },
      {
        "date": "2023-06-04T03:58:00.000Z",
        "voteCount": 1,
        "content": "Anser is A"
      },
      {
        "date": "2023-05-02T00:19:00.000Z",
        "voteCount": 11,
        "content": "Always when they say \"prevent changing layout\" select app."
      },
      {
        "date": "2023-03-20T21:37:00.000Z",
        "voteCount": 2,
        "content": "The correct answer is A since the reports is publish in an app."
      },
      {
        "date": "2023-03-15T18:49:00.000Z",
        "voteCount": 3,
        "content": "Option A (Publish the reports in an app and grant the HR managers access permission) would be the best option to provide the HR managers with access to the reports while restricting them from modifying the layout.\n\nBy publishing the reports in an app and granting the HR managers access permission, you can assign them specific roles and permissions that restrict their access to the underlying data while allowing them to view and interact with the reports. The RLS configuration can be set up to ensure that the HR managers can only see data from their own sales region."
      },
      {
        "date": "2023-03-15T05:29:00.000Z",
        "voteCount": 1,
        "content": "A is correct."
      },
      {
        "date": "2023-01-05T12:07:00.000Z",
        "voteCount": 8,
        "content": "correct ans looks as  A because in the Power BI service, members of a workspace have access to datasets in the workspace. RLS doesn't restrict this data access. and RLS is used to restrict access to data not to layout of the report. Members are allowed to change the report layout."
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 3,
    "url": "https://www.examtopics.com/discussions/microsoft/view/81241-exam-pl-300-topic-2-question-3-discussion/",
    "body": "You need to provide a user with the ability to add members to a workspace. The solution must use the principle of least privilege.<br>Which role should you assign to the user?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tViewer",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAdmin",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tContributor",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tMember\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 23,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2022-09-08T09:54:00.000Z",
        "voteCount": 20,
        "content": "Correct"
      },
      {
        "date": "2022-10-05T15:40:00.000Z",
        "voteCount": 9,
        "content": "D is correct as per example picture and principal of least privilege required"
      },
      {
        "date": "2024-10-11T13:28:00.000Z",
        "voteCount": 1,
        "content": "https://learn.microsoft.com/en-us/power-bi/collaborate-share/service-roles-new-workspaces based on that"
      },
      {
        "date": "2024-08-16T08:34:00.000Z",
        "voteCount": 1,
        "content": "Definitely correct! D.Member is the right one!"
      },
      {
        "date": "2024-06-10T10:16:00.000Z",
        "voteCount": 1,
        "content": "Correct"
      },
      {
        "date": "2024-03-10T03:36:00.000Z",
        "voteCount": 4,
        "content": "If you want to add a user with a role X you need to have at least the X role. So to add a Member you need to be a Member."
      },
      {
        "date": "2024-02-12T04:10:00.000Z",
        "voteCount": 1,
        "content": "No it doesnt, ignore my previous post!"
      },
      {
        "date": "2024-02-12T04:06:00.000Z",
        "voteCount": 1,
        "content": "This table somewhat contradicts the correct answer: https://learn.microsoft.com/en-us/power-bi/collaborate-share/service-roles-new-workspaces"
      },
      {
        "date": "2023-12-15T11:44:00.000Z",
        "voteCount": 1,
        "content": "D is correct"
      },
      {
        "date": "2023-10-16T17:34:00.000Z",
        "voteCount": 2,
        "content": "Given answer D-Member, is correct:\nhttps://learn.microsoft.com/en-us/power-bi/collaborate-share/service-roles-new-workspaces"
      },
      {
        "date": "2023-10-05T20:34:00.000Z",
        "voteCount": 1,
        "content": "Given answer D-Member, is correct:\nhttps://learn.microsoft.com/en-us/power-bi/collaborate-share/service-roles-new-workspaces"
      },
      {
        "date": "2023-10-04T11:35:00.000Z",
        "voteCount": 2,
        "content": "\"B\"- Admin is the correct. Read in between the lines....\"You need to provide a user with the ability to add members to a workspace\"\nThe user you are adding must be able \"add\" members and only and admin can do it. So you are adding another \"admin\""
      },
      {
        "date": "2023-10-25T08:34:00.000Z",
        "voteCount": 2,
        "content": "Incorrect when you said that only admins can add new members. A member can also add members, as well as other roles of lower privilege. While it is true that an admin would be able to add members, its not the correct option because the question says \"The solution must use the principle of least privilege.\" \n\nRefer to the chart here: https://learn.microsoft.com/en-us/power-bi/collaborate-share/service-roles-new-workspaces"
      },
      {
        "date": "2024-02-26T08:30:00.000Z",
        "voteCount": 1,
        "content": "Yes B - Admin is the right answer I think so because this question is in the practice assessment of Microsoft"
      },
      {
        "date": "2023-09-04T20:26:00.000Z",
        "voteCount": 1,
        "content": "C is the correct answer.\nTo provide a user with the ability to add members to a workspace while following the principle of least privilege, we should assign the contributor role to the user. The contributor role allows user to manage content within a workspace, including adding and editing datasets, reports, dashboards, and managing access to the workspace. It grants sufficient permissions for them to perform the task of adding members to the workspace without providing excessive administrative privileges as the Admin role would. The viewer role is too restrictive for this task, and the Member role does not grant the necessary permission to manage workspace members."
      },
      {
        "date": "2023-09-28T19:29:00.000Z",
        "voteCount": 1,
        "content": "https://learn.microsoft.com/en-us/power-bi/collaborate-share/service-roles-new-workspaces \nContributor is not authorized to add other member to workspace"
      },
      {
        "date": "2023-07-29T05:05:00.000Z",
        "voteCount": 1,
        "content": "MEMBER"
      },
      {
        "date": "2023-05-29T07:18:00.000Z",
        "voteCount": 4,
        "content": "I don't think it was this exact question but they had stuff like this on the exam today.\nDef need to know what roles can do what?"
      },
      {
        "date": "2023-05-02T00:21:00.000Z",
        "voteCount": 1,
        "content": "Only Admins and Members can do. because of least privilege Member is correct."
      },
      {
        "date": "2023-04-12T00:16:00.000Z",
        "voteCount": 2,
        "content": "Member\n\nhttps://community.powerbi.com/t5/image/serverpage/image-id/193423iB38878624518A351/image-size/large?v=v2&amp;px=999"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 4,
    "url": "https://www.examtopics.com/discussions/microsoft/view/80325-exam-pl-300-topic-2-question-4-discussion/",
    "body": "You have a Power BI query named Sales that imports the columns shown in the following table.<br><img src=\"/assets/media/exam-media/04331/0006900002.jpg\" class=\"in-exam-image\"><br>Users only use the date part of the Sales_Date field. Only rows with a Status of Finished are used in analysis.<br>You need to reduce the load times of the query without affecting the analysis.<br>Which two actions achieve this goal? Each correct answer presents a complete solution.<br>NOTE: Each correct selection is worth one point.<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRemove the rows in which Sales[Status] has a value of Canceled.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRemove Sales[Sales_Date].",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tChange the data type of Sale[Delivery_Time] to Integer.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSplit Sales[Sale_Date] into separate date and time columns.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRemove Sales[Canceled Date].\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "AE",
    "answerDescription": "",
    "votes": [
      {
        "answer": "AE",
        "count": 108,
        "isMostVoted": true
      },
      {
        "answer": "AD",
        "count": 41,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2022-09-19T05:22:00.000Z",
        "voteCount": 107,
        "content": "A, only records with state finished are used\nD, personally I would transform the column to a date format and not split it since only the date part is used\n\nNot E, All the cancelled rows are already deleted with A and when a order is not cancelled it will contain a null value"
      },
      {
        "date": "2024-09-10T18:25:00.000Z",
        "voteCount": 3,
        "content": "Each answer represents a complete solution.\n-&gt; D cannot be correct as it is not a complete solution.\n-&gt; A, E : Correct."
      },
      {
        "date": "2024-05-20T09:39:00.000Z",
        "voteCount": 3,
        "content": "No, option E is about delete the Canceled Date fileld not the rows"
      },
      {
        "date": "2022-12-27T16:44:00.000Z",
        "voteCount": 15,
        "content": "Splitting the column without deleting one of them isn't going to do anything for performance.\n\nAnd you're right that if step A is done then the cancelled_date column will only contain null values. But reducing the number of columns is going to improve the performance - even if that column is all null."
      },
      {
        "date": "2024-03-07T06:38:00.000Z",
        "voteCount": 9,
        "content": "AE is correct: 'Each correct answer presents a complete solution.' E presents a complete solution on its own without A."
      },
      {
        "date": "2022-11-08T13:30:00.000Z",
        "voteCount": 58,
        "content": "It says: You need to reduce the LOAD times of the query without affecting the analysis. Only answers A and E can reduce the load times. D may reduce only the time needed to process the data. Someone said that E is not the answer because: \"All the cancelled rows are already deleted with A and when a order is not cancelled it will contain a null value\". You must read again the decription cause it says \" Each answer presents a COMPLETE solutiuon\" not part of a solution."
      },
      {
        "date": "2023-07-23T10:00:00.000Z",
        "voteCount": 3,
        "content": "You focus too much on load. Answer E doesn't resolve the date part of the question.\nSplitting columns is correct, not E."
      },
      {
        "date": "2023-08-10T03:22:00.000Z",
        "voteCount": 1,
        "content": "The 'date part of the question' is not a requirement, it's not like the time is negatively impacting the users."
      },
      {
        "date": "2023-04-21T05:54:00.000Z",
        "voteCount": 5,
        "content": "\"Separate date and time, if bound together. If any of your tables have columns that combine date and time, make sure that you separate them into distinct columns before importing them into Power BI. This approach will increase compression abilities.\"\n\nSource: https://learn.microsoft.com/en-us/training/modules/get-data/8-performance-issues"
      },
      {
        "date": "2024-09-11T15:26:00.000Z",
        "voteCount": 1,
        "content": "isn't that about model / file size though? not load time?"
      },
      {
        "date": "2023-09-07T01:32:00.000Z",
        "voteCount": 5,
        "content": "I was on the Track of AD, but I think you are right.\nSplitting up [Sale_Date] alone doesn't help us with faster load times (the question is not about performance).\nAlso, analyzing the two options separately (\"Each correct answer presents a complete solution\"), deleting [Canceled_Date] for sure is a right answer."
      },
      {
        "date": "2023-11-04T22:55:00.000Z",
        "voteCount": 5,
        "content": "I agree here as well.\n\nChoosing D (splitting up [Sales_Date]) may even increase the LOAD time of the query, even though it might decrease its PROCESSING time.\n\nE (removing [Canceled_Date]) on the other hand removes an entire column to be loaded, thereby decreasing the LOAD time."
      },
      {
        "date": "2024-09-05T01:30:00.000Z",
        "voteCount": 1,
        "content": "Said AD fisrt. But I changed my mind. D  improves the analysis but doesn't change the performance, while D does."
      },
      {
        "date": "2024-09-05T01:31:00.000Z",
        "voteCount": 1,
        "content": "E I meant. So AE my answer"
      },
      {
        "date": "2024-08-14T08:06:00.000Z",
        "voteCount": 2,
        "content": "I don't agree with the community in my opinion A and D are the correct ones."
      },
      {
        "date": "2024-08-31T07:04:00.000Z",
        "voteCount": 2,
        "content": "I changed my mind. The Canceled Date is not useful in the analysis so AE is the correct for me"
      },
      {
        "date": "2024-07-21T15:37:00.000Z",
        "voteCount": 2,
        "content": "A and D. As E removing column doesn't decrease load time as query load time is dependent on the number of rows in the dataset. SInce rows will remain the same even after E, and the time taken to reach the bottom of the query is still the same. removing rows is actually where you save query load time. So A and D"
      },
      {
        "date": "2024-05-28T08:40:00.000Z",
        "voteCount": 1,
        "content": "I think it's DE. We need optimize only loading time, so A will reduces amount of rows we are loading, but Power Query must go through all dataset to delete specified values, so it takes more time than delete entire column"
      },
      {
        "date": "2024-05-21T06:36:00.000Z",
        "voteCount": 1,
        "content": "D is not correct not considering whether it affects the performance but remember question said that they wished to analyse the data with the column Sales_Date but they didn't say they not including time for analysis."
      },
      {
        "date": "2024-05-08T05:34:00.000Z",
        "voteCount": 6,
        "content": "I think AE is correct"
      },
      {
        "date": "2024-05-20T09:43:00.000Z",
        "voteCount": 1,
        "content": "I agree."
      },
      {
        "date": "2024-04-22T09:16:00.000Z",
        "voteCount": 3,
        "content": "Answer A is obvious. I choose answer E because we want to analyze the rows with Status = Finished, that implies that every record in the analysis would have the Canceled_Date = null. That column would add nothing to the report, so we could safely drop it and that would improve a little the load time."
      },
      {
        "date": "2024-04-08T07:20:00.000Z",
        "voteCount": 1,
        "content": "E will improve load time, nor D"
      },
      {
        "date": "2024-04-02T19:16:00.000Z",
        "voteCount": 3,
        "content": "i was mixing up load times and processing times. option D could potentially increase loading time, it would decrease processing time. processing time is for calculations, load time...is for loading"
      },
      {
        "date": "2024-03-12T12:02:00.000Z",
        "voteCount": 1,
        "content": "A, D and E are correct, but since we need to choose only 2, then A &amp; D"
      },
      {
        "date": "2024-03-10T03:52:00.000Z",
        "voteCount": 3,
        "content": "D does not reduce load times. Probably it increases it. If we remove rows with Status = Cancelled then Canceled Date would always be null so we better remove the column and then option E becomes better than D."
      },
      {
        "date": "2024-03-10T03:50:00.000Z",
        "voteCount": 1,
        "content": "D does not reduce anything"
      },
      {
        "date": "2024-03-08T19:19:00.000Z",
        "voteCount": 1,
        "content": "Answer: AD\n\nExplanation:\nA: Removing uninteresting rows will increase query performance.\n\nD: Splitting the Sales_Date column will make comparisons on the Sales date faster.\n\nThe Power BI Desktop data model only supports date/time, but they can be formatted as dates or times independently. Date/Time \u2013 Represents both a date and time value. Underneath the covers, the Date/Time value is stored as a Decimal Number Type. Since there's a T in the dates column before split, it's saved as a source text value. Splitting converts it to a numeric value. This reduces the size."
      },
      {
        "date": "2024-02-08T01:41:00.000Z",
        "voteCount": 2,
        "content": "Option A is obvious.\nOption D reduces the cardinality of the column which can have a huge impact in the loading time of the model."
      },
      {
        "date": "2024-01-29T08:59:00.000Z",
        "voteCount": 1,
        "content": "Keeping dateatime column as whole hurt Power BI Performance.\n\n"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 5,
    "url": "https://www.examtopics.com/discussions/microsoft/view/81242-exam-pl-300-topic-2-question-5-discussion/",
    "body": "You build a report to analyze customer transactions from a database that contains the tables shown in the following table.<br><img src=\"/assets/media/exam-media/04331/0007100001.jpg\" class=\"in-exam-image\"><br>You import the tables.<br>Which relationship should you use to link the tables?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tone-to-many from Transaction to Customer",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tone-to-one between Customer and Transaction",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tmany-to-many between Customer and Transaction",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tone-to-many from Customer to Transaction\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 58,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2022-09-14T04:38:00.000Z",
        "voteCount": 19,
        "content": "Correct"
      },
      {
        "date": "2022-09-08T10:08:00.000Z",
        "voteCount": 8,
        "content": "It is correct for me"
      },
      {
        "date": "2024-09-05T01:31:00.000Z",
        "voteCount": 1,
        "content": "No doubt here. D"
      },
      {
        "date": "2024-08-16T08:42:00.000Z",
        "voteCount": 1,
        "content": "Let's say that the ER is many to one from transaction to customer (Customer (1,N) -&gt; (1,1) Transaction). When we build the tables we need the customerId foreing key to the transaction table. In PBI there is many relationship where there is the key (from the fact to the dimension).\nSo, one to many from customer to transaction is the correct one!"
      },
      {
        "date": "2024-07-21T04:27:00.000Z",
        "voteCount": 1,
        "content": "correct answer"
      },
      {
        "date": "2024-03-12T12:06:00.000Z",
        "voteCount": 3,
        "content": "Please, MS, send questions like that in the exam... :-)"
      },
      {
        "date": "2024-03-12T02:40:00.000Z",
        "voteCount": 1,
        "content": "OBVIOUS!!"
      },
      {
        "date": "2024-03-10T03:53:00.000Z",
        "voteCount": 2,
        "content": "Per me \u00e8 la cipolla"
      },
      {
        "date": "2024-01-15T23:00:00.000Z",
        "voteCount": 1,
        "content": "Correct"
      },
      {
        "date": "2023-10-16T17:44:00.000Z",
        "voteCount": 1,
        "content": "D is the correct answer"
      },
      {
        "date": "2023-09-04T20:52:00.000Z",
        "voteCount": 5,
        "content": "D is the correct answer. Each customer can have multiple transactions (one-to-many relationship), as a customer can make multiple transactions over time."
      },
      {
        "date": "2023-07-25T23:57:00.000Z",
        "voteCount": 3,
        "content": "Correct"
      },
      {
        "date": "2023-06-08T12:47:00.000Z",
        "voteCount": 1,
        "content": "D es la ideal"
      },
      {
        "date": "2023-04-07T14:50:00.000Z",
        "voteCount": 1,
        "content": "Correto"
      },
      {
        "date": "2023-03-21T03:26:00.000Z",
        "voteCount": 4,
        "content": "D is correct because a single customer can have many transactions and this transactions have their transactions id."
      },
      {
        "date": "2023-03-20T09:02:00.000Z",
        "voteCount": 1,
        "content": "a customer is unique in the `Customer` table. However, a unique customer can possess multiple transactions in the `Transactions` table. Hence 1-MANY relationship is obvious answer. So, option D"
      },
      {
        "date": "2022-12-24T12:21:00.000Z",
        "voteCount": 5,
        "content": "It's an obvious one. Relationship always flows downstream from primary (fact) to foreign (dim)"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 6,
    "url": "https://www.examtopics.com/discussions/microsoft/view/81960-exam-pl-300-topic-2-question-6-discussion/",
    "body": "You have a custom connector that returns ID, From, To, Subject, Body, and Has Attachments for every email sent during the past year. More than 10 million records are returned.<br>You build a report analyzing the internal networks of employees based on whom they send emails to.<br>You need to prevent report recipients from reading the analyzed emails. The solution must minimize the model size.<br>What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tFrom Model view, set the Subject and Body columns to Hidden.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRemove the Subject and Body columns during the import.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tImplement row-level security (RLS) so that the report recipients can only see results based on the emails they sent."
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 73,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-04-12T00:24:00.000Z",
        "voteCount": 37,
        "content": "B is the best option to prevent report recipients from reading the analyzed emails and minimize the model size.\n\nRemoving the Subject and Body columns during the import process ensures that they are not included in the model, which prevents report recipients from being able to access the analyzed email content.\n\nA and C are not effective solutions for preventing report recipients from reading the analyzed emails.\n\nA: Hiding the Subject and Body columns in the model view may prevent report recipients from seeing the content in the report, but the data is still stored in the model and can potentially be accessed by someone with the appropriate permissions.\nC: Implementing row-level security (RLS) restricts data access based on user roles or permissions, but it does not prevent access to the analyzed email content in the model.\n\nNo confusion, and no need to discuss further"
      },
      {
        "date": "2023-06-08T12:50:00.000Z",
        "voteCount": 3,
        "content": "Gracias por tu explicaci\u00f3n :)"
      },
      {
        "date": "2022-09-14T04:42:00.000Z",
        "voteCount": 17,
        "content": "correct, \"prevent report recipients from reading the analyzed emails\""
      },
      {
        "date": "2024-08-16T08:43:00.000Z",
        "voteCount": 1,
        "content": "For exclusion B is the only one that reduce the complexity. Hide or implement RLS is not the correct way to do that.\nI totally agree with you: B. Remove the Subject and Body columns during the import."
      },
      {
        "date": "2024-07-21T04:29:00.000Z",
        "voteCount": 1,
        "content": "correct"
      },
      {
        "date": "2024-04-19T08:35:00.000Z",
        "voteCount": 3,
        "content": "This is was on the exam today. 2024-04-19"
      },
      {
        "date": "2024-03-31T14:13:00.000Z",
        "voteCount": 1,
        "content": "I think must be B because if you choose to remove Subject and Body columns you will have report based on whom they send emails , so the report and analyzed data (to whom..) of the rest part of the mails will still be visible."
      },
      {
        "date": "2024-03-20T09:52:00.000Z",
        "voteCount": 1,
        "content": "ChatGPT\nC. Implement row-level security (RLS) so that the report recipients can only see results based on the emails they sent.\n\nExplanation:\n\nRow-Level Security (RLS) allows you to control access to data at the row level based on user roles or filters. By applying RLS, you can restrict report recipients\u2019 visibility to only the data relevant to them.\nIn your scenario, you want to ensure that employees can only see results related to the emails they sent. RLS provides a fine-grained approach to achieve this without affecting the model size.\nHiding columns or removing them during import won\u2019t prevent recipients from accessing the data if they have direct access to the model."
      },
      {
        "date": "2024-09-05T01:39:00.000Z",
        "voteCount": 1,
        "content": "But it doesn't minimize the model size."
      },
      {
        "date": "2024-03-12T12:26:00.000Z",
        "voteCount": 1,
        "content": "correct"
      },
      {
        "date": "2024-03-10T03:59:00.000Z",
        "voteCount": 1,
        "content": "CLS is not available in Power Bi so we either Mask or remove the columns. Mask them though still potentially leaves chances to view the data."
      },
      {
        "date": "2024-02-19T23:44:00.000Z",
        "voteCount": 1,
        "content": "dissect the question and only keep key elements:\ncustom connector : ID, From, To, Subject, Body, and Has Attachments\n-build a report analyzing send emails to.\n-prevent report from reading emails.\n-minimize the model size.\nWhat should you do?\n\nPretty obvious you only need to keep : [ID, From, To], right ?"
      },
      {
        "date": "2024-01-15T23:05:00.000Z",
        "voteCount": 1,
        "content": "Correct"
      },
      {
        "date": "2023-09-04T21:02:00.000Z",
        "voteCount": 2,
        "content": "C is the correct answer.\nIn this scenario, we want to prevent report recipients from reading the analyzed emails while still allowing them to analyze internal networks based on whom employees send emails to. To achieve this this goal while minimizing the model size, implementing row-level security (RLS) is the most appropriate solution. \nOption A doesn't prevent access to the underlying data. Option B might limit our ability to perform analysis based on the content of emails."
      },
      {
        "date": "2023-10-02T00:10:00.000Z",
        "voteCount": 1,
        "content": "C doesnt minimize the size , B does"
      },
      {
        "date": "2023-06-08T12:51:00.000Z",
        "voteCount": 1,
        "content": "B es correcta"
      },
      {
        "date": "2023-04-03T03:42:00.000Z",
        "voteCount": 3,
        "content": "B is the best option to prevent report recipients from reading the analyzed emails and minimize the model size.\n\nRemoving the Subject and Body columns during the import process ensures that they are not included in the model, which prevents report recipients from being able to access the analyzed email content.\n\nA and C are not effective solutions for preventing report recipients from reading the analyzed emails.\n\nA: Hiding the Subject and Body columns in the model view may prevent report recipients from seeing the content in the report, but the data is still stored in the model and can potentially be accessed by someone with the appropriate permissions.\nC: Implementing row-level security (RLS) restricts data access based on user roles or permissions, but it does not prevent access to the analyzed email content in the model.\n\nNo confusion, and no need to discuss further"
      },
      {
        "date": "2022-11-23T23:58:00.000Z",
        "voteCount": 3,
        "content": "Remove the sensitive info at the very beginning"
      },
      {
        "date": "2022-11-22T13:15:00.000Z",
        "voteCount": 1,
        "content": "B is correct for me"
      },
      {
        "date": "2022-11-02T10:28:00.000Z",
        "voteCount": 3,
        "content": "B is correct"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 7,
    "url": "https://www.examtopics.com/discussions/microsoft/view/81789-exam-pl-300-topic-2-question-7-discussion/",
    "body": "HOTSPOT -<br>You create a Power BI dataset that contains the table shown in the following exhibit.<br><img src=\"/assets/media/exam-media/04331/0007300001.jpg\" class=\"in-exam-image\"><br>You need to make the table available as an organizational data type in Microsoft Excel.<br>How should you configure the properties of the table? To answer, select the appropriate options in the answer area.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04331/0007400001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04331/0007500001.png\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: Cost Center -<br>The Row label field value is used in Excel so users can easily identify the row. It appears as the cell value for a linked cell, in the Data Selector pane, and in the<br>Information card.<br><img src=\"/assets/media/exam-media/04331/0007600001.jpg\" class=\"in-exam-image\"><br><br>Box 2: ID -<br>The Key column field value provides the unique ID for the row. This value enables Excel to link a cell to a specific row in the table.<br><br>Box 3: Yes -<br>In the Data Types Gallery in Excel, your users can find data from featured tables in your Power BI datasets.<br>Reference:<br>https://docs.microsoft.com/en-us/power-bi/collaborate-share/service-create-excel-featured-tables",
    "votes": [],
    "comments": [
      {
        "date": "2022-09-21T05:38:00.000Z",
        "voteCount": 121,
        "content": "Row label: Name\nKey column: ID\nIs featured table: Yes"
      },
      {
        "date": "2022-09-28T06:14:00.000Z",
        "voteCount": 1,
        "content": "why you said is  ?"
      },
      {
        "date": "2023-07-05T03:13:00.000Z",
        "voteCount": 2,
        "content": "Yes right you can also see in example given in the solution it mentioned companyname rather than cost centre"
      },
      {
        "date": "2022-10-26T05:33:00.000Z",
        "voteCount": 10,
        "content": "The Row label field value is used in Excel so users can easily identify the row. It appears as the cell value for a linked cell, in the Data Selector pane, and in the Information card.\nThe Key column field value provides the unique ID for the row. This value enables Excel to link a cell to a specific row in the table.\nSource: https://learn.microsoft.com/en-us/power-bi/collaborate-share/service-create-excel-featured-tables"
      },
      {
        "date": "2022-09-18T16:46:00.000Z",
        "voteCount": 24,
        "content": "Maybe a Row label must be a Name."
      },
      {
        "date": "2022-09-19T01:46:00.000Z",
        "voteCount": 10,
        "content": "Yeah, Name of the Business Unit should be a Row Label"
      },
      {
        "date": "2024-10-12T02:05:00.000Z",
        "voteCount": 1,
        "content": "Surely Cost Center is wrong and the name identifies the business to users??"
      },
      {
        "date": "2024-10-02T20:15:00.000Z",
        "voteCount": 1,
        "content": "correct answer is Name, ID and Yes"
      },
      {
        "date": "2024-08-16T09:04:00.000Z",
        "voteCount": 1,
        "content": "Row Label: Name\nKey column: ID\nIs featured Table: Yes"
      },
      {
        "date": "2024-01-13T14:37:00.000Z",
        "voteCount": 8,
        "content": "Shouldn't this be an Excel question rather than power bi?"
      },
      {
        "date": "2024-10-02T20:14:00.000Z",
        "voteCount": 1,
        "content": "Its need to be done in power bi before its brought into excel."
      },
      {
        "date": "2023-12-30T05:07:00.000Z",
        "voteCount": 9,
        "content": "this youtube video speaks the correct answer on its own! \n\nRow label: Name\nKey column: ID\nIs featured table: Yes"
      },
      {
        "date": "2023-12-27T14:21:00.000Z",
        "voteCount": 5,
        "content": "may I ask why we need a feature table here?"
      },
      {
        "date": "2023-12-19T17:35:00.000Z",
        "voteCount": 5,
        "content": "Row label: Name\nKey column: ID\nIs featured table: Yes\n\nThe reason for \"Row label\" as Name is that the \"Name\" of a Business Unit would be more descriptive and recognizable to users than a numeric ID or a Cost Center code, making it easier to identify the Business Unit in Excel."
      },
      {
        "date": "2023-11-08T05:35:00.000Z",
        "voteCount": 6,
        "content": "Name, ID, Yes. Name it will be a Business Unit Name."
      },
      {
        "date": "2023-11-05T13:55:00.000Z",
        "voteCount": 2,
        "content": "Do experienced users of Power BI use this feature at all?"
      },
      {
        "date": "2023-09-04T21:16:00.000Z",
        "voteCount": 1,
        "content": "\"Name\", \"Headcount\" and \"Yes\" are correct answers. It is because in row label, we should choose the \"Name\" column as the row label because it is typically the primary identifier or name associated with the data in an organization data type. In column we should choose the \"Headcount\" column as the column because it represents a numeric value (presumably the headcount) associated with the organization data. Is featured table, we should select \"Yes\" to indicate that this table should be recognized as an organization data type in Excel."
      },
      {
        "date": "2023-09-21T01:00:00.000Z",
        "voteCount": 1,
        "content": "As key column i would say ID, why headcount?"
      },
      {
        "date": "2023-08-24T00:30:00.000Z",
        "voteCount": 6,
        "content": "This has not been shown in any of the path on the microsoft sites suggested for the pl-300..."
      },
      {
        "date": "2024-03-19T08:23:00.000Z",
        "voteCount": 1,
        "content": "IKR! I'm like, I literally don't know any of this thing lmao"
      },
      {
        "date": "2023-08-05T07:39:00.000Z",
        "voteCount": 2,
        "content": "For me Name doesn't mean much. In a report in the corp level I've only ever used Cost Center, oddly enough i've never been asked the name of the cost center.. (weird probably yeah) and we have one but still"
      },
      {
        "date": "2023-06-05T03:37:00.000Z",
        "voteCount": 2,
        "content": "There could be more than one business units under a cost centre so I think Business Unit Name should be the correct choice for Row label."
      },
      {
        "date": "2023-05-09T16:38:00.000Z",
        "voteCount": 10,
        "content": "Correct answer \nCost Center\nID\nYes\nwith this explanation\n\nIn a table or matrix visualization in Power BI, the row labels are typically the fields that define the categories or groups along the rows of the table or matrix. In the case of the given fields, \"Cost Center\" and \"Headcount\" can be considered as row labels because they represent categories or groups along the rows of the table or matrix. \"ID\" and \"Name\" are typically used as column labels or values. However, the choice of row labels ultimately depends on the specific analysis and reporting needs of the data."
      },
      {
        "date": "2023-05-17T07:32:00.000Z",
        "voteCount": 6,
        "content": "I've seen your replies in a few questions  now. Have you successfully cleared the exam?"
      },
      {
        "date": "2023-05-09T16:36:00.000Z",
        "voteCount": 1,
        "content": "In a table or matrix visualization in Power BI, the row labels are typically the fields that define the categories or groups along the rows of the table or matrix. In the case of the given fields, \"Cost Center\" and \"Headcount\" can be considered as row labels because they represent categories or groups along the rows of the table or matrix. \"ID\" and \"Name\" are typically used as column labels or values. However, the choice of row labels ultimately depends on the specific analysis and reporting needs of the data."
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 8,
    "url": "https://www.examtopics.com/discussions/microsoft/view/80607-exam-pl-300-topic-2-question-8-discussion/",
    "body": "You have the Power BI model shown in the following exhibit.<br><img src=\"/assets/media/exam-media/04331/0007700001.jpg\" class=\"in-exam-image\"><br>A manager can represent only a single country.<br>You need to use row-level security (RLS) to meet the following requirements:<br>\u2711 The managers must only see the data of their respective country.<br>\u2711 The number of RLS roles must be minimized.<br>Which two actions should you perform? Each correct answer presents a complete solution.<br>NOTE: Each correct selection is worth one point.<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a single role that filters Country[Manager_Email] by using the USERNAME DAX function.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a single role that filters Country[Manager_Email] by using the USEROBJECTID DAX function.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tFor the relationship between Purchase Detail and Purchase, select Apply security filter in both directions.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate one role for each country.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tFor the relationship between Purchase and Purchase Detail, change the Cross filter direction to Single."
    ],
    "answer": "AC",
    "answerDescription": "",
    "votes": [
      {
        "answer": "AC",
        "count": 58,
        "isMostVoted": true
      },
      {
        "answer": "AD",
        "count": 20,
        "isMostVoted": false
      },
      {
        "answer": "AE",
        "count": 4,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2022-10-05T23:13:00.000Z",
        "voteCount": 37,
        "content": "The given answer is correct.\nA. Create a single role that filters Country[Manager_Email] by using the USERNAME DAX function.\nC.For the relationship between Purchase Detail and Purchase, select Apply security filter in both directions."
      },
      {
        "date": "2022-10-26T05:43:00.000Z",
        "voteCount": 33,
        "content": "Ok, I agree with A and C but, \"Each correct answer presents a complete solution\" ?\nI believe that A and C are each one a part of solution not a complete solution...\nAm I worng?"
      },
      {
        "date": "2024-03-12T11:51:00.000Z",
        "voteCount": 3,
        "content": "You are very right; C option is not a complete solution."
      },
      {
        "date": "2024-10-07T19:51:00.000Z",
        "voteCount": 1,
        "content": "A and E should be correct answer. A is obvious, and E because there is no reuirement to filter from details."
      },
      {
        "date": "2024-09-02T20:07:00.000Z",
        "voteCount": 1,
        "content": "When RLS is applied,\nIf the security filter in both direction is not applied, that users may or may not see information that is not related to him or her (depending on how the visuals are designed)\nEnable the security filter in both direction will ensure that only the required information is shown.\n"
      },
      {
        "date": "2024-08-26T02:17:00.000Z",
        "voteCount": 1,
        "content": "A is obvious.\nC does not represent a complete solution. What would happen if you ONLY apply security filter? What filter?? Security filter does not exist if this needs to be a complete solution. \nD - the only drawback is that you need a lot of roles."
      },
      {
        "date": "2024-08-24T06:12:00.000Z",
        "voteCount": 1,
        "content": "the diagram shows the relationship already set as bi directional. Why we need to set this again ?"
      },
      {
        "date": "2024-08-16T09:12:00.000Z",
        "voteCount": 1,
        "content": "The given answer is correct"
      },
      {
        "date": "2024-08-20T02:52:00.000Z",
        "voteCount": 1,
        "content": "Tested, it is"
      },
      {
        "date": "2024-07-22T11:43:00.000Z",
        "voteCount": 1,
        "content": "A&amp;C. To people talking about \"complete solutions,\" consider this: each Correct Selection is worth a point, but each Correct Answer is a complete solution. An Answer is composed of multiple selections, but the Answer itself will be a complete solution (of two parts). Hope this helps."
      },
      {
        "date": "2024-07-21T04:38:00.000Z",
        "voteCount": 1,
        "content": "AC is correct"
      },
      {
        "date": "2024-07-09T23:12:00.000Z",
        "voteCount": 1,
        "content": "I will go with D, E"
      },
      {
        "date": "2024-10-05T11:34:00.000Z",
        "voteCount": 1,
        "content": "D is wrong. Question says number of roles created must be minimized."
      },
      {
        "date": "2024-06-08T22:40:00.000Z",
        "voteCount": 1,
        "content": "On June 8, 2024 exam"
      },
      {
        "date": "2024-04-28T02:57:00.000Z",
        "voteCount": 7,
        "content": "A can't be correct, Create a single role that filters Country[Manager_Email] by using the USERNAME DAX function - USERNAME returns the Username, to get the User-E-Mail you have to use USERPRINCIPALNAME"
      },
      {
        "date": "2024-09-11T16:35:00.000Z",
        "voteCount": 1,
        "content": "That was my thinking. Using username or UPN creates, effectively, a role per country and needs maintenance. My thinking was using a role per country (which you need anyway) and then you can maintain that way."
      },
      {
        "date": "2024-02-26T06:18:00.000Z",
        "voteCount": 12,
        "content": "I believe the given answer is not correct. Furthermore, I believe the most selected answer is incorrect as each option selected should be a complete solution.\nAs mentioned in some other comments, the questions says that each solution should be a COMPLETE solution. If you in isolation performs option C, it would not lead to any RLS being applied in the model. If the question were asking for two alternatives that together were a complete solution, A and C would be correct.\n\nHence, one should opt you alternative A and D where A is dynamic RLS and D is static RLS (credit to the individual(s) mentioning this prior to this comment)."
      },
      {
        "date": "2024-05-26T03:34:00.000Z",
        "voteCount": 1,
        "content": "But it does NOT minimize the number of roles"
      },
      {
        "date": "2024-03-25T05:04:00.000Z",
        "voteCount": 1,
        "content": "That's right! So the correct answer is A and D in this case ( each solution should be a COMPLETE solution)"
      },
      {
        "date": "2024-01-26T22:11:00.000Z",
        "voteCount": 11,
        "content": "A, D. A is dynamic while D is static RLS. Each presents a complete solution. The explanation in C itself is correct but irrelevant. The RLS filter required doesn't come from the Purchase Detail table."
      },
      {
        "date": "2024-09-10T19:05:00.000Z",
        "voteCount": 1,
        "content": "D is a nonsense answer. In practice you would never do it.\nI'm going with A, C."
      },
      {
        "date": "2023-12-26T16:02:00.000Z",
        "voteCount": 4,
        "content": "Why in both directions? The RLS filter comes from the Country table and propagates to the Purchase table, the it propagates to the Purchase Detail table. There's no RLS filter coming from the Purchase Detail table, which it'll justify the use of RLS in both directions."
      },
      {
        "date": "2023-11-03T08:32:00.000Z",
        "voteCount": 4,
        "content": "OK, \ngiven the options, it seems to me that A and C are correct.\nBut wouldn't it be \"more\" correct for \"Apply security filter in both directions\" to be between the tables Country and Purchase?\nThanks in advance for any feedback"
      },
      {
        "date": "2023-11-24T06:37:00.000Z",
        "voteCount": 9,
        "content": "Shouldn't we use the USERPRINCIPALNAME function  DAX as it pertains to the email column?"
      },
      {
        "date": "2023-10-16T09:55:00.000Z",
        "voteCount": 8,
        "content": "I think it should be AE,\nInstead of applying bidirectional security, good to flow data in single direction and it does meet the requirement and best practice as well."
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 9,
    "url": "https://www.examtopics.com/discussions/microsoft/view/80609-exam-pl-300-topic-2-question-9-discussion/",
    "body": "HOTSPOT -<br>You have a Power BI imported dataset that contains the data model shown in the following exhibit.<br><img src=\"/assets/media/exam-media/04331/0007900001.jpg\" class=\"in-exam-image\"><br>Use the drop-down menus to select the answer choice that completes each statement based on the information presented in the graphic.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04331/0008000001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04331/0008000002.jpg\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: Assume Referential Integrity<br>When connecting to a data source using DirectQuery, you can use the Assume Referential Integrity selection to enable running more efficient queries against your data source. This feature has a few requirements of the underlying data, and it is only available when using DirectQuery.<br>Note: The following requirements are necessary for Assume referential integrity to work properly:<br>Data in the From column in the relationship is never Null or blank<br>For each value in the From column, there is a corresponding value in the To column<br><br>Box 2: Star schema -<br>Star schema is a mature modeling approach widely adopted by relational data warehouses. It requires modelers to classify their model tables as either dimension or fact.<br>Generally, dimension tables contain a relatively small number of rows. Fact tables, on the other hand, can contain a very large number of rows and continue to grow over time.<br>Example:<br><img src=\"/assets/media/exam-media/04331/0008100001.jpg\" class=\"in-exam-image\"><br>Reference:<br>https://docs.microsoft.com/en-us/power-bi/connect-data/desktop-assume-referential-integrity https://docs.microsoft.com/en-us/power-bi/guidance/star-schema",
    "votes": [],
    "comments": [
      {
        "date": "2022-09-06T06:17:00.000Z",
        "voteCount": 142,
        "content": "It should be cross filter direction. As the answer correctly states \"Assume Referential Integrity\" only works for direct query connections."
      },
      {
        "date": "2023-12-11T21:40:00.000Z",
        "voteCount": 7,
        "content": "Yep, and to be clear, the first line in this particular question says it's imported data, not direct query."
      },
      {
        "date": "2024-02-05T03:42:00.000Z",
        "voteCount": 3,
        "content": "same, the question says \"imported the data\" and explanation says the \"ARI\" works only for Direct Query"
      },
      {
        "date": "2023-02-14T16:38:00.000Z",
        "voteCount": 3,
        "content": "but it is a Direct query from powerbi service, so the integrity gona make it perform well"
      },
      {
        "date": "2023-04-25T00:43:00.000Z",
        "voteCount": 3,
        "content": "How do you know that? It is stated nowhere"
      },
      {
        "date": "2023-09-21T01:44:00.000Z",
        "voteCount": 4,
        "content": "first line"
      },
      {
        "date": "2023-09-13T04:14:00.000Z",
        "voteCount": 4,
        "content": "\"You have a Power BI imported dataset \".... Imported. It should be Cross filter direction"
      },
      {
        "date": "2022-09-13T06:39:00.000Z",
        "voteCount": 75,
        "content": "It should be : \n- cross filter direction\n- star schema"
      },
      {
        "date": "2024-08-16T09:29:00.000Z",
        "voteCount": 1,
        "content": "I agree with you guys it should be:\n1 - Cross filter direction\n2 - star schema of course"
      },
      {
        "date": "2024-07-21T04:41:00.000Z",
        "voteCount": 1,
        "content": "Cross Filter &amp; Star is correct"
      },
      {
        "date": "2024-04-16T06:40:00.000Z",
        "voteCount": 1,
        "content": "The answers can only be:\n- cross filter direction\n- star schema\n\nCross filter direction set to both in msot relatioships are a mess."
      },
      {
        "date": "2024-02-27T09:37:00.000Z",
        "voteCount": 7,
        "content": "Assume referential integrity? Really? After seeing that mess of cross filters in the star schema? And then in the provided answer it says assume referential integrity setting works for direct query, even though the question states this is an imported dataset."
      },
      {
        "date": "2024-02-24T11:28:00.000Z",
        "voteCount": 11,
        "content": "answer choke"
      },
      {
        "date": "2024-02-20T02:02:00.000Z",
        "voteCount": 7,
        "content": "Honestly.. I think Microsoft is publishing fake answers to avoid people studying answers only and force them to think based on acquired knowledge.\n\nWhen you look at the icons next to the tables in the model, those are IMPORTED icons, not direct query. Direct query icons are represented with a square having at the bottom right corner two arrows, one in, one out.\n\nAlso, when you do the labs, you have an exercise called Sales Analysis  with a similar model (star) that you will publish to PBI service and there is no cross filter direction"
      },
      {
        "date": "2023-12-21T22:11:00.000Z",
        "voteCount": 6,
        "content": "The answer should be:\nCross Filter direction.\nStar Schema."
      },
      {
        "date": "2023-10-16T09:56:00.000Z",
        "voteCount": 4,
        "content": "Cross filter direction &amp; Start schema"
      },
      {
        "date": "2023-09-12T16:30:00.000Z",
        "voteCount": 3,
        "content": "As to the confusion of star or snowflakes schema,  If this is a star schema, then the Employee table is a factless fact table."
      },
      {
        "date": "2023-09-04T21:48:00.000Z",
        "voteCount": 11,
        "content": "Cross filter Direction and Star Schema are the correct options.\nChanging the cross filter direction setting can have a significant impact on query performance. Setting it to \"Single\" when appropriate can often improve performance by reducing unnecessary filtering in both directions. \nIn Star Schema, the central table (usually a fact table) is connected to dimension tables through one-to-many or many-to-many relationships."
      },
      {
        "date": "2023-10-25T11:09:00.000Z",
        "voteCount": 3,
        "content": "Absolutely. Something I did not notice at first was that every single connection has the arrows pointing in both directions. That's a dead giveaway to a flaw in the current design. Changing as many of those to single where appropriate will improve performance since excessive bidirectional cross-filtering can cause Power BI to slow down. Only do that where it is needed"
      },
      {
        "date": "2023-08-24T01:01:00.000Z",
        "voteCount": 2,
        "content": "import dataset --&gt; cross filter, the referential itnegrity only works with direct query.\nAnd star schema, pretty direct"
      },
      {
        "date": "2024-01-07T01:21:00.000Z",
        "voteCount": 1,
        "content": "you are right --&gt; https://learn.microsoft.com/en-us/power-bi/connect-data/desktop-assume-referential-integrity"
      },
      {
        "date": "2023-08-10T03:34:00.000Z",
        "voteCount": 6,
        "content": "I wonder why cardinality is wrong as an answer here. Doesn't the umbrella-term of cardinality also include cross filter direction ?"
      },
      {
        "date": "2023-05-02T01:09:00.000Z",
        "voteCount": 11,
        "content": "Assume Referential Integrity only work for DirectDquery connections. but in the beginning of the question said it is Imported!"
      },
      {
        "date": "2023-04-30T15:39:00.000Z",
        "voteCount": 11,
        "content": "Referential integrity is for data accuracy and preventing dirty reads etc. Cross Filter direction affects performance. I cleared exam today got 100% in Prep Data section"
      },
      {
        "date": "2023-05-17T08:11:00.000Z",
        "voteCount": 2,
        "content": "Can you advise roughly how many of these questions appeared on the exam?"
      },
      {
        "date": "2023-04-29T18:02:00.000Z",
        "voteCount": 11,
        "content": "cross filter direction\nstar schema\n\nyou know this is an imported dataset, because they tell you, and also the icons show an imported dataset. therefore, it cannot be \"assume referential integrity\" because as a rule, assume referential integrity only works for direct query connections\n\ncross filter direction can be seen because the arrows in the diagram show all of the tables are going in both directions. we're looking at a star schema because we have 1 fact table and several dimension tables, so it doesn't make sense that we have all these cross filters going on unnecessarily. therefore, makes snse to have the answer be cross filter and star schema"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 10,
    "url": "https://www.examtopics.com/discussions/microsoft/view/79437-exam-pl-300-topic-2-question-10-discussion/",
    "body": "HOTSPOT -<br>You have a Power BI model that contains a table named Sales and a related date table. Sales contains a measure named Total Sales.<br>You need to create a measure that calculates the total sales from the equivalent month of the previous year.<br>How should you complete the calculation? To answer, select the appropriate options in the answer area.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04331/0008300001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04331/0008500001.png\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: CALCULATE -<br><br>Box 2: PARALLELPERIOD -<br>PARALLELPERIOD returns a table that contains a column of dates that represents a period parallel to the dates in the specified dates column, in the current context, with the dates shifted a number of intervals either forward in time or back in time.<br>Syntax: PARALLELPERIOD(&lt;dates&gt;,&lt;number_of_intervals&gt;,&lt;interval&gt;) dates: A column that contains dates. interval: The interval by which to shift the dates. The value for interval can be one of the following: year, quarter, month.<br>Incorrect:<br>SAMEPERIODLASTYEAR returns a table that contains a column of dates shifted one year back in time from the dates in the specified dates column, in the current context.<br>Syntax: SAMEPERIODLASTYEAR(&lt;dates&gt;)<br>DATESMTD returns a table that contains a column of the dates for the month to date, in the current context.<br>Syntax: DATESMTD(&lt;dates&gt;)<br>Box 3: 'DATE' [Month]<br>Reference:<br>https://docs.microsoft.com/en-us/dax/parallelperiod-function-dax https://docs.microsoft.com/en-us/dax/sameperiodlastyear-function-dax",
    "votes": [],
    "comments": [
      {
        "date": "2022-09-09T11:24:00.000Z",
        "voteCount": 219,
        "content": "CALCULATE\nSAMEPERIODLASTYEAR\n'DATE'[DATE]"
      },
      {
        "date": "2023-02-19T02:48:00.000Z",
        "voteCount": 13,
        "content": "Correct!\n\nPARALLELPERIOD needs 3 arguments and it returns the sales for the entire year\n\n"
      },
      {
        "date": "2024-03-12T04:38:00.000Z",
        "voteCount": 1,
        "content": "There's a Sum missing. CALCULATE(SUM(), SAMEPERIODLASTYEAR(Date[Date]))"
      },
      {
        "date": "2024-03-12T05:19:00.000Z",
        "voteCount": 12,
        "content": "Nevermind, Sum isn't necessary as Total Sales is a measure not a column and already calculates the Sum."
      },
      {
        "date": "2023-11-25T20:24:00.000Z",
        "voteCount": 3,
        "content": "This would return the sales on that single date of last year. You need date[month] to get the sales for the entire month of last year."
      },
      {
        "date": "2024-02-26T02:45:00.000Z",
        "voteCount": 5,
        "content": "no. date([month]) will throw an error as the function expects a DATE format and month is integer(or string if format mmm).\nIt MUST be date[Date]"
      },
      {
        "date": "2022-09-02T07:50:00.000Z",
        "voteCount": 52,
        "content": "Calculate\nSamePeriodLastYear\n'Date'[Month]\nParallelPeriod could work but here the second agrument only takes one parameter and ParallelPeriod requires three"
      },
      {
        "date": "2022-09-14T11:18:00.000Z",
        "voteCount": 68,
        "content": "SAMEPERIODLASTYEAR accepts a data column, Month will usually be either text (Jan) or Integer (1). so: CALCULATE([Total Sales], SAMEPERIODLASTYEAR('Date'[Date]))"
      },
      {
        "date": "2022-12-24T13:20:00.000Z",
        "voteCount": 1,
        "content": "Yup! This is correct!!"
      },
      {
        "date": "2022-09-24T11:24:00.000Z",
        "voteCount": 4,
        "content": "Which one is the correct answer is it 'Date[Month] or 'Date'[Date] as it has got equal number of votes so confused."
      },
      {
        "date": "2024-07-24T19:31:00.000Z",
        "voteCount": 2,
        "content": "'Date'[Date] is the correct type of data. Then you could make use of Table visualization with a column as 'Date'[Month] to see all the Sales of each previous month"
      },
      {
        "date": "2023-11-25T20:24:00.000Z",
        "voteCount": 1,
        "content": "You need date[month] to get the sales for the entire month of last year."
      },
      {
        "date": "2023-01-01T19:44:00.000Z",
        "voteCount": 3,
        "content": "I guess 'Date'[Date]. If you look up for the SAMEPERIODLASTYEAR DAX, it has a Date parameter."
      },
      {
        "date": "2024-08-16T09:33:00.000Z",
        "voteCount": 1,
        "content": "The correct answer is CALCULATE, SAMEPERIODLASTYEAR, 'Date'[Month]"
      },
      {
        "date": "2024-08-20T05:11:00.000Z",
        "voteCount": 1,
        "content": "Sorry I was wrong! If you use Date[Month] It will raise an error because The specified month column in the SAMEPERIODLASTYEAR function is not of type DATE. It should be the following configuration:\n- CALCULATE\n- SAMEPERIODLASTYEAR\n- 'Date'[Date]"
      },
      {
        "date": "2024-06-26T23:15:00.000Z",
        "voteCount": 3,
        "content": "Have tried to build the measures. It woks with the following:\n\n1. SAMEPERIODLASTYEAR(&lt;dates&gt;) \nSales Previous Year = CALCULATE([Total Sales],SAMEPERIODLASTYEAR(Date[Date]))\n\n2. PARALLELPERIOD(&lt;dates&gt;,&lt;number_of_intervals&gt;,&lt;interval&gt;)\nSales Previous Year = CALCULATE([Total ales],PARALLELPERIOD(Date[Date],-12,MONTH))\n\n3. DATEADD(&lt;dates&gt;,&lt;number_of_intervals&gt;,&lt;interval&gt;) \nSales Previous Year = CALCULATE([Total Sales],DATEADD(Date[Date],-12,MONTH))"
      },
      {
        "date": "2024-05-22T14:53:00.000Z",
        "voteCount": 2,
        "content": "CALCULATE is used to change the context in which the data is evaluated.\n[Total Sales] is your existing measure that calculates total sales.\nSAMEPERIODLASTYEAR('Date'[Date]) shifts the context of the date by one year, allowing the calculation to be made for the same period last year.\nThis measure will give you the total sales for the same month in the previous year. Make sure that your date table ('Date') is marked as a date table and properly related to your Sales table."
      },
      {
        "date": "2024-02-21T07:08:00.000Z",
        "voteCount": 2,
        "content": "It needs to be 'DATE'[DATE] because SAMEPERIODLASTYEAR only accepts Date columns as arguments. If you try to input the Month column the following error is prompted:\n\n\"MdxScript(Model) (216, 5) Calculation error in measure \u2022_ProjectMeasures'[Measure Last Year]: A column specified in the call to function 'SAMEPERIODLASTYEAR' is not of type DATE. This is not supported.\""
      },
      {
        "date": "2024-02-20T02:58:00.000Z",
        "voteCount": 2,
        "content": "AS per Microsoft Definition found in:\nhttps://learn.microsoft.com/en-us/dax/sameperiodlastyear-function-dax\n\nExample\nThe following sample formula creates a measure that calculates the previous year sales of Reseller sales.\n\nDAX:\n\nLastYearSales= CALCULATE(SUM(ResellerSales_USD[SalesAmount_USD]), SAMEPERIODLASTYEAR(DateTime[DateKey]))"
      },
      {
        "date": "2024-02-16T11:48:00.000Z",
        "voteCount": 1,
        "content": "The data recording frequency is not specified, but based on the snap, we should assume that the data is recorded on a monthly basis. In accordance with this assumption, the syntax using PARALLELPERIOD AND SAMEPERIODLASTYEAR would be:\n\n1. CALCULATE(SUM('Table Name'[Total Sales]), PARALLELPERIOD('Table Name'[Date], -12, Month)\n\n2.CALCULATE(SUM('Table Name'[Total Sales]), SAMEPERIODLASTYEAR('Table Name'[Date]))\n\nGiven only one argument in the final box, this is the correct answer - CALCULATE, SAMPERIODLASTYEAR, DATE[DATE]"
      },
      {
        "date": "2024-01-26T05:34:00.000Z",
        "voteCount": 1,
        "content": "CALCULATE\nSAMEPERIODLASTYEAR\n'DATE'[DATE] / 'DATE'[MONTH]"
      },
      {
        "date": "2023-12-21T22:17:00.000Z",
        "voteCount": 1,
        "content": "Answer is wrong and misleading. Correct answers:\nCALCULATE\nSAMEPERIODLASTYEAR\n'DATE'[DATE]\n\nWe should use SAMEPERIODLASTYEAR because it as a function would calculate the expression for the previous year period to the period in filter context. Also, we should input the 'DATE'[DATE] column for references the previous year period."
      },
      {
        "date": "2023-12-07T07:39:00.000Z",
        "voteCount": 2,
        "content": "The correct :\n1) CALCULATE\n2) SAMEPERIODLASTYEAR\n3) 'DATE'[DATE]\n\nThe fonction accepte 3 param like this PARALLELPERIOD(&lt;dates&gt;,&lt;number_of_intervals&gt;,&lt;interval&gt;)"
      },
      {
        "date": "2023-11-08T07:05:00.000Z",
        "voteCount": 2,
        "content": "The Suggested Answers are so ridiculous. I answer correctly and later get irritated that again wrong answers under 'Show Suggested Answer'. Mine: CALCULATE\nSAMEPERIODLASTYEAR\n'DATE'[DATE]"
      },
      {
        "date": "2023-10-26T06:40:00.000Z",
        "voteCount": 10,
        "content": "Just one question, why there are so many \"correct answers\" which are actually not correct on this website? Most of the time I need to check the discussions to find the right answer."
      },
      {
        "date": "2023-10-07T00:53:00.000Z",
        "voteCount": 2,
        "content": "It is correct, I think it should be Calculate , Sameperiodlastyear,Date[Month] as they have asked in the question to find the total sales from the equivalent month of the previous Year."
      },
      {
        "date": "2023-09-04T22:01:00.000Z",
        "voteCount": 2,
        "content": "Calculate, Sameperiodlastyear and `Date`[Date] are the answers."
      },
      {
        "date": "2023-08-24T01:15:00.000Z",
        "voteCount": 2,
        "content": "Calculate\nsameperiolastyear\n'DATE'[DATE]\n\nDoes it need a grouping function like SUM around the [TotalSales]?\nOtherwhise how can it group them?\nOr it is only to filter and obtain for a row with a particular data the same the last year?"
      },
      {
        "date": "2023-07-19T04:51:00.000Z",
        "voteCount": 1,
        "content": "PARALLELPERIOD. \nSamePeriodLastYear function in DAX does not support calculating data for multiple months"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 11,
    "url": "https://www.examtopics.com/discussions/microsoft/view/79994-exam-pl-300-topic-2-question-11-discussion/",
    "body": "DRAG DROP -<br>You plan to create a report that will display sales data from the last year for multiple regions.<br>You need to restrict access to individual rows of the data on a per region-basis by using roles.<br>Which four actions should you perform in sequence? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.<br>Select and Place:<br><img src=\"/assets/media/exam-media/04331/0008700001.jpg\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04331/0008700002.jpg\" class=\"in-exam-image\">",
    "answerDescription": "You can define roles and rules within Power BI Desktop. When you publish to Power BI, it also publishes the role definitions.<br>To define security roles, follow these steps.<br>1. Import data into your Power BI Desktop report (Step 1)<br>2. From the Modeling tab, select Manage Roles.<br>3. From the Manage roles window, select Create. (Step 2)<br>4. Under Roles, provide a name for the role.<br>5. Under Tables, select the table to which you want to apply a DAX rule.<br>6. In the Table filter DAX expression box, enter the DAX expressions. This expression returns a value of true or false. For example: [Entity ID] = \u05d2\u20acValue\u05d2\u20ac(Step 3)<br>7. After you've created the DAX expression, select the checkmark above the expression box to validate the expression.<br>8. Select Save.<br>Step 3: Assign Users to the role.<br>You can't assign users to a role within Power BI Desktop. You assign them in the Power BI service.<br>After you've created your roles, test the results of the roles within Power BI Desktop.<br>Step 4: Publish the report.<br>Now that you're done validating the roles in Power BI Desktop, go ahead and publish your report to the Power BI service.<br>Reference:<br>https://docs.microsoft.com/en-us/power-bi/enterprise/service-admin-rls",
    "votes": [],
    "comments": [
      {
        "date": "2022-09-11T04:59:00.000Z",
        "voteCount": 246,
        "content": "Import data\ncreate the roles on power bi\nPublish the report\n Assign Users to the role."
      },
      {
        "date": "2023-01-10T05:27:00.000Z",
        "voteCount": 3,
        "content": "Yes, I tested it !\nYou have to choose a dataset before assigning roles to users.\n(Path : powerbi.com &gt; dataset &gt; more options &gt; security)"
      },
      {
        "date": "2023-12-11T21:53:00.000Z",
        "voteCount": 6,
        "content": "Import, Create, Publish, Assign\nYes, https://learn.microsoft.com/en-us/training/modules/row-level-security-power-bi/2-static-method"
      },
      {
        "date": "2022-11-30T13:38:00.000Z",
        "voteCount": 7,
        "content": "Yes, correct. \nIf publish first and then create a role, then all users will see the info, which against the requirement."
      },
      {
        "date": "2023-07-05T04:01:00.000Z",
        "voteCount": 2,
        "content": "you have to assign roles after publishing as we are already created in 2nd step in Power BI Desktop"
      },
      {
        "date": "2023-02-10T07:15:00.000Z",
        "voteCount": 17,
        "content": "\"You can't assign users to a role within Power BI Desktop. You assign them in the Power BI service. You can enable dynamic security within Power BI Desktop by making use of the username() or userprincipalname() DAX functions and having the proper relationships configured.\" from https://learn.microsoft.com/en-us/power-bi/enterprise/service-admin-rls \n OGESSIUSER is correct"
      },
      {
        "date": "2022-09-15T02:22:00.000Z",
        "voteCount": 29,
        "content": "Import data\ncreate the roles on power bi\nPublish the report\nAssign Users to the role.\nhttps://docs.microsoft.com/en-us/training/modules/row-level-security-power-bi/2-static-method"
      },
      {
        "date": "2024-10-03T11:19:00.000Z",
        "voteCount": 1,
        "content": "It's Import -  Create  - Publish  - Assign"
      },
      {
        "date": "2024-08-17T01:55:00.000Z",
        "voteCount": 1,
        "content": "1 - Import the data to PBI Desktop\n2 - Create a role definition\n3 - Assign users to the role\n4 - Publish the report"
      },
      {
        "date": "2024-03-19T01:07:00.000Z",
        "voteCount": 2,
        "content": "Import--&gt;Create--&gt;Publish--&gt;Assign"
      },
      {
        "date": "2024-02-26T03:18:00.000Z",
        "voteCount": 1,
        "content": "the context is unclear;\nproposed solution can be valid:\nIf you have a fact sales tables \nhaving a country Id \njoined on a dim country table \nwhich itself joins a dim persons table containing the full email.\nYou can create your role and add the dax exp person=username()\nthen Apply security filter in both directions checkbox\nFinally test the report's behavior with \"view as\" (none, other, rule)\nwhen satisfied, publish the report"
      },
      {
        "date": "2024-01-15T18:35:00.000Z",
        "voteCount": 2,
        "content": "Agree with Import &gt; Create &gt; Publish &gt; Assign\nSince roles should be assigned in PowerBI Service, Publish must done before Assign"
      },
      {
        "date": "2023-12-21T22:30:00.000Z",
        "voteCount": 1,
        "content": "Correct.\n1. Import the data to Power BI Desktop\n2. Create a role definition\n3. Publish the report\n4. Assign users to the role (in Power BI Service)"
      },
      {
        "date": "2023-12-18T04:04:00.000Z",
        "voteCount": 2,
        "content": "I think Sequence is wrong \nwe will Assign Users to the role only after we \"Publish the Report\""
      },
      {
        "date": "2023-10-10T10:13:00.000Z",
        "voteCount": 1,
        "content": "Agree with you"
      },
      {
        "date": "2023-09-22T13:43:00.000Z",
        "voteCount": 2,
        "content": "A flavor of this was on the test today."
      },
      {
        "date": "2023-09-04T22:09:00.000Z",
        "voteCount": 2,
        "content": "First Step:  Import the data to Power BI Desktop \nSecond Step: Create a role definition. \nThird Step: Assign Users to the role.\nFourth Step: Add a filter to the report."
      },
      {
        "date": "2023-07-27T04:29:00.000Z",
        "voteCount": 5,
        "content": "This answer is simply wrong. I won't be using this site anymore."
      },
      {
        "date": "2023-04-29T18:21:00.000Z",
        "voteCount": 9,
        "content": "their answer is wrong\n\n1) first need to import the data into PBI\n2) create roles\n3) publish report\n4) assign users to role\n\nstep 1 makes sense because you first need to get the data into PBI before you can do anything\nstep 2: at this point, if you publish the report, then everyone will already have access so you can't do publish. therefore, you need to create roles in PBI\nstep 3: you can't assign users to the role yet because the Power BI desktop doesn't have that ability--it needs to be done in the workspace service online and that can only happen after the report is published to that workspace. therefore step 3 has to be to publish\nstep 4: after publishing, you can then choose the report and the users to assign to the role"
      },
      {
        "date": "2023-04-26T19:14:00.000Z",
        "voteCount": 3,
        "content": "While creating role, dont we need to specify the Dax, ie. Add filter to the report"
      },
      {
        "date": "2023-04-12T00:53:00.000Z",
        "voteCount": 2,
        "content": "Import data\ncreate the roles on power bi\nPublish the report\nAssign Users to the role."
      },
      {
        "date": "2023-04-03T05:25:00.000Z",
        "voteCount": 6,
        "content": "Correct Answer :\nImport Data\nCreate Role on Power BI\nPublish the report\nAssign Users to the role\n\n you cannot assign users to the role before publishing the report in Power BI. You can only assign roles to users or groups once the report is published to the Power BI service.\n\nBefore publishing the report, you can create and define roles in the Power BI Desktop. However, you cannot assign users to these roles until the report is published to the Power BI service.\n\nAfter publishing the report, you can then assign users or groups to the roles that you have defined in the Power BI Desktop. Once users are assigned to a role, they will only be able to see the data that they have permission to view based on their assigned role when they access the report.\n\nNo confusion, and no need to discuss further"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 12,
    "url": "https://www.examtopics.com/discussions/microsoft/view/81713-exam-pl-300-topic-2-question-12-discussion/",
    "body": "DRAG DROP -<br>You create a data model in Power BI.<br>Report developers and users provide feedback that the data model is too complex.<br>The model contains the following tables.<br><img src=\"/assets/media/exam-media/04331/0008800001.png\" class=\"in-exam-image\"><br>The model has the following relationships:<br>\u2711 There is a one-to-one relationship between Sales_Region and Region_Manager.<br>\u2711 There are more records in Manager than in Region_Manager, but every record in Region_Manager has a corresponding record in Manager.<br>\u2711 There are more records in Sales_Manager than in Sales_Region, but every record in Sales_Region has a corresponding record in Sales_Manager.<br>You need to denormalize the model into a single table. Only managers who are associated to a sales region must be included in the reports.<br>Which three actions should you perform in sequence? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.<br>NOTE: More than one order of answer choices is correct. You will receive credit for any of the correct orders you select.<br>Select and Place:<br><img src=\"/assets/media/exam-media/04331/0008900001.jpg\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04331/0008900002.jpg\" class=\"in-exam-image\">",
    "answerDescription": "Step 1: Merge [Sales_Region] and [Sales_Manager] by using an inner join.<br>Inner Join: Returns the rows present in both Left and right table only if there is a match. Otherwise, it returns zero records.<br>Note: Sales_Region and Sales_manager<br>There is a one-to-one relationship between Sales_Region and Region_Manager.<br>There are more records in Sales_Manager than in Sales_Region, but every record in Sales_Region has a corresponding record in Sales_Manager.<br>Step 2: Merge [Region_Manager] and [Manager] by using inner join.<br>Only managers who are associated to a sales region must be included in the reports.<br>Note: Region_Manager and Manager.<br>There are more records in Manager than in Region_Manager, but every record in Region_Manager has a corresponding record in Manager.<br>Step 3: Merge [Sales_region] and [Region_Manager] by using a right join as new query named [Sales_region_and_Region_Manager]<br>Reference:<br>https://www.tutorialgateway.org/joins-in-power-bi/",
    "votes": [],
    "comments": [
      {
        "date": "2022-10-07T00:52:00.000Z",
        "voteCount": 143,
        "content": "1.Merge [Region_Manager] and [Manager] by using an inner join.\n3.Merge [Sales_Region] and [Sales_Manager] by using an inner join.\n6.Merge [Sales_Region] and [Region_Manager] by using an inner join."
      },
      {
        "date": "2024-04-17T00:32:00.000Z",
        "voteCount": 1,
        "content": "Approved"
      },
      {
        "date": "2023-07-10T23:03:00.000Z",
        "voteCount": 6,
        "content": "you are an absolute genius!"
      },
      {
        "date": "2023-01-03T02:36:00.000Z",
        "voteCount": 4,
        "content": "Ok but what about 3,1,6. It will be the same"
      },
      {
        "date": "2022-12-15T10:31:00.000Z",
        "voteCount": 1,
        "content": "I just have a query if  we have  selected first 6 ,3,1 then am I going to get less points here?"
      },
      {
        "date": "2022-12-25T03:02:00.000Z",
        "voteCount": 7,
        "content": "Question states \"You need to denormalize the model into a single table.\"\nsequence 1,3,6 would merge everything into a single table....  but 6,3,1 will have 2 tables..\nso sequence 1,3,6 is correct"
      },
      {
        "date": "2023-02-08T02:03:00.000Z",
        "voteCount": 1,
        "content": "Why two tables? I dont get it"
      },
      {
        "date": "2023-01-04T21:20:00.000Z",
        "voteCount": 1,
        "content": "TestBP,\ncan you plz elaborate , i am not able to understand how 2 table and  1 table will be \ncreated"
      },
      {
        "date": "2022-12-16T01:33:00.000Z",
        "voteCount": 1,
        "content": "me too"
      },
      {
        "date": "2023-04-25T02:13:00.000Z",
        "voteCount": 3,
        "content": "I think so, though the question states that more than one order is correct. 6 merges the two smaller tables, I think it is better to merge the larger tables first, because that means the last inner join will have less rows to fuse."
      },
      {
        "date": "2023-04-25T02:14:00.000Z",
        "voteCount": 2,
        "content": "So I think 1-3-6 is an option, 3-1-6 as well, but starting with 6 is not."
      },
      {
        "date": "2022-09-11T12:55:00.000Z",
        "voteCount": 20,
        "content": "I think the last query in the answer should be  \"Merge [sales_region] and [region_manager] using an inner join\" . Outer join may exclude some records for which region_manager info might be absent."
      },
      {
        "date": "2022-10-16T02:29:00.000Z",
        "voteCount": 8,
        "content": "That did my head in and took at least 20 min to fathom out. In the end, I agree with this answer. I hope I can do it MUCH quicker in the exam."
      },
      {
        "date": "2022-11-22T18:48:00.000Z",
        "voteCount": 1,
        "content": "What did you decide was the correct answer?"
      },
      {
        "date": "2022-09-15T02:33:00.000Z",
        "voteCount": 2,
        "content": "exactly, I agree"
      },
      {
        "date": "2022-10-23T03:40:00.000Z",
        "voteCount": 4,
        "content": "The sales Region and Region manager has one to one relationship, therefore, it does not matter how to join it"
      },
      {
        "date": "2022-11-21T14:37:00.000Z",
        "voteCount": 4,
        "content": "Indeed it doesn't. Only an inner join shows more clearly the intention of the join."
      },
      {
        "date": "2022-11-21T14:35:00.000Z",
        "voteCount": 5,
        "content": "It is the outer join that INCLUDES the records for which a foreign key is absent. It is the inner join that excludes records for which the foreign is absent.\nBut this is exactly what you want, because only managers with a related Sales_Region must be included.\nSo I agree with your answer but not with the reasoning ;-)"
      },
      {
        "date": "2024-10-08T08:13:00.000Z",
        "voteCount": 1,
        "content": "sales_region and Region_manager has 1:1 relationship, so right join as provided in the answer will yield the same result."
      },
      {
        "date": "2024-08-17T02:02:00.000Z",
        "voteCount": 1,
        "content": "1 - Merge RegionManager and Manager by using an inner join\n2 - Merge SalesRegion and SalesManager by using an inner join\n3 - Merge SalesRegion and RegionManager by using a right join as a new query named SalesRegionAndRegionManager"
      },
      {
        "date": "2024-07-17T04:47:00.000Z",
        "voteCount": 1,
        "content": "1,3,6 OR 3,1,6 BUT with assumption that we can loose managers from Sales_Manager by inner join to Sales_Region. I wonder that maybe option \"2\" should be taken instead of \"3\". Doing an inner join from smaller table (Sales_Region) wouldn't result in assigning random Sales Manager...? In fact max(Sales_Manager)"
      },
      {
        "date": "2024-06-08T22:53:00.000Z",
        "voteCount": 2,
        "content": "After the exam, I left feedback to Microsoft saying this question is ambiguous and lacks practicality. \n\"There are more records in Sales_Manager than in Sales_Region, but every record in Sales_Region has a corresponding record in Sales_Manager.\" It means some managers are associated with region_id, but the region_id doesn't lead to a region name. Then it's ambiguous for the question to ask all managers that are associated with a region. In my opinion, step 2 takes care of all. Why 3 steps then? The question lacks practicality."
      },
      {
        "date": "2024-01-15T18:58:00.000Z",
        "voteCount": 3,
        "content": "I think both 1-3-6 and 3-1-6 are correct. \nBe careful of the question \"NOTE\" - More than one order of answer choices is correct"
      },
      {
        "date": "2024-01-03T06:04:00.000Z",
        "voteCount": 8,
        "content": "Why does it feel like a reading test?"
      },
      {
        "date": "2023-12-19T19:36:00.000Z",
        "voteCount": 1,
        "content": "Either 1-3-6 or 3-1-6 is correct. Step 1 and 3 can be done separately. Step 6 is to merge the results of joins in Step 1 and 3 so Step 6 is the last step."
      },
      {
        "date": "2023-11-13T04:53:00.000Z",
        "voteCount": 2,
        "content": "Very confusing question. \n2 out of 3 information is not used in the answers and comments. one-to-one relationship and the fact that some tables contain more records than others.\n\nAlso, the given answer and the answer shared here are not the same."
      },
      {
        "date": "2023-09-25T06:26:00.000Z",
        "voteCount": 2,
        "content": "Either 1-3-6 or 3-1-6 or any other order is correct coz they clearly mentioned in the NOTE which is------ (NOTE: More than one order of answer choices is correct. You will receive credit for any of the correct orders you select)"
      },
      {
        "date": "2023-09-24T07:03:00.000Z",
        "voteCount": 2,
        "content": "I think the options here are wrong cause we need left join to avoid losing some records from manager and sales manager table ."
      },
      {
        "date": "2023-09-04T22:35:00.000Z",
        "voteCount": 3,
        "content": "First Step: Merge [region_manager] and [manager] by using an inner join.\nSecond Step: Merge [Sales_Manager] and [Sales_Region] by using an inner join.\nThird Step: Merge [Sales_Region] and [Sales_Manager] by using an inner join as a new query named [sales_region_and_manager]"
      },
      {
        "date": "2023-08-20T01:33:00.000Z",
        "voteCount": 1,
        "content": "I can understand the answers but does this sequence matter?"
      },
      {
        "date": "2023-12-22T23:10:00.000Z",
        "voteCount": 1,
        "content": "Yes, the sequence does matter since it was mentioned in question \"Which three actions should you perform in sequence?\""
      },
      {
        "date": "2023-06-16T12:31:00.000Z",
        "voteCount": 5,
        "content": "this ones tough. gave me a headache just thinking about it"
      },
      {
        "date": "2023-06-16T02:11:00.000Z",
        "voteCount": 1,
        "content": "its 1,6,2 keeping the sales manager the last selection in inner join to be able to keep in the report. That is first 1- merge RM and M tables, then 6- merge SR and RM tables, then 2- merge SM and SR tables (  keeping the sales manager the last selection in inner join to be able to keep in the report.)"
      },
      {
        "date": "2023-06-02T04:19:00.000Z",
        "voteCount": 1,
        "content": "I dont understnad why the order is 1, 3, 6. why cant i be the other orders like 6, 1, 3. please lmk bec i have exam in 2 days."
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 13,
    "url": "https://www.examtopics.com/discussions/microsoft/view/79995-exam-pl-300-topic-2-question-13-discussion/",
    "body": "You have a Microsoft Power BI report. The size of PBIX file is 550 MB. The report is accessed by using an App workspace in shared capacity of powerbi.com.<br>The report uses an imported dataset that contains one fact table. The fact table contains 12 million rows. The dataset is scheduled to refresh twice a day at 08:00 and 17:00.<br>The report is a single page that contains 15 AppSource visuals and 10 default visuals.<br>Users say that the report is slow to load the visuals when they access and interact with the report.<br>You need to recommend a solution to improve the performance of the report.<br>What should you recommend?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tChange any DAX measures to use iterator functions.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEnable visual interactions.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tReplace the default visuals with AppSource visuals.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSplit the visuals onto multiple pages.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 28,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2022-09-04T02:32:00.000Z",
        "voteCount": 39,
        "content": "Correct answer:  \nD. Split the visuals onto multiple pages."
      },
      {
        "date": "2022-11-29T09:44:00.000Z",
        "voteCount": 8,
        "content": "Correct answer: D. Split the visuals onto multiple pages.\nI experienced this firsthand."
      },
      {
        "date": "2024-08-17T02:04:00.000Z",
        "voteCount": 1,
        "content": "D - Split the visuals onto multiple pages"
      },
      {
        "date": "2024-05-09T10:03:00.000Z",
        "voteCount": 1,
        "content": "Hi Team, can anybody response how many questions matches from examtopics to final PL300 exam?"
      },
      {
        "date": "2024-03-25T04:24:00.000Z",
        "voteCount": 1,
        "content": "CORRECT"
      },
      {
        "date": "2024-03-13T13:39:00.000Z",
        "voteCount": 1,
        "content": "correct"
      },
      {
        "date": "2024-03-13T02:18:00.000Z",
        "voteCount": 1,
        "content": "BINGO!"
      },
      {
        "date": "2023-09-04T22:47:00.000Z",
        "voteCount": 7,
        "content": "D is the correct answer. Because our report page contains a large number of visuals (both default and AppSource visuals) and users are experiencing slow load times, splitting the visuals onto multiple pages can help. This way, each page loads a subset of visuals, reducing the initial load time and improving the overall performance of the report. Users can navigate between pages to access different sets of visuals."
      },
      {
        "date": "2023-07-04T17:36:00.000Z",
        "voteCount": 1,
        "content": "Too many visuals on a single page. Split visuals across multiple pages."
      },
      {
        "date": "2023-07-03T04:10:00.000Z",
        "voteCount": 2,
        "content": "D. I had the same question on my exam"
      },
      {
        "date": "2023-05-31T06:06:00.000Z",
        "voteCount": 1,
        "content": "D is a easy way to avoid this issue."
      },
      {
        "date": "2023-05-08T03:13:00.000Z",
        "voteCount": 3,
        "content": "D is correct. Each visual is a individual query that is triggered once the report page is opened. Logically, the more visual there are on a single report page the slower the report will become. Splitting the report in multiple report pages would be the impropriate solution."
      },
      {
        "date": "2023-05-02T01:32:00.000Z",
        "voteCount": 2,
        "content": "With slow loading always split the report page."
      },
      {
        "date": "2023-04-26T00:18:00.000Z",
        "voteCount": 1,
        "content": "D is correct answer"
      },
      {
        "date": "2023-04-12T01:09:00.000Z",
        "voteCount": 1,
        "content": "D. Split the visuals onto multiple pages."
      },
      {
        "date": "2023-04-10T04:38:00.000Z",
        "voteCount": 1,
        "content": "D. Split the visuals onto multiple pages."
      },
      {
        "date": "2022-12-09T03:29:00.000Z",
        "voteCount": 2,
        "content": "Split the visuals onto multiple pages. (D)"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 14,
    "url": "https://www.examtopics.com/discussions/microsoft/view/79998-exam-pl-300-topic-2-question-14-discussion/",
    "body": "HOTSPOT -<br>You are creating a Microsoft Power BI imported data model to perform basket analysis. The goal of the analysis is to identify which products are usually bought together in the same transaction across and within sales territories.<br>You import a fact table named Sales as shown in the exhibit. (Click the Exhibit tab.)<br><img src=\"/assets/media/exam-media/04331/0009100001.jpg\" class=\"in-exam-image\"><br>The related dimension tables are imported into the model.<br>Sales contains the data shown in the following table.<br><img src=\"/assets/media/exam-media/04331/0009200001.png\" class=\"in-exam-image\"><br>You are evaluating how to optimize the model.<br>For each of the following statements, select Yes if the statement is true. Otherwise, select No.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04331/0009300001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04331/0009300002.jpg\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: Yes -<br>Those two columns not need in the analysis.<br><br>Box 2: No -<br>Can remove the surrogate key OrderDateKey from the analysis.<br><br>Box 3: No -<br>Tax charged not relevant for the analysis.",
    "votes": [],
    "comments": [
      {
        "date": "2022-09-04T02:34:00.000Z",
        "voteCount": 109,
        "content": "Yes - No - No"
      },
      {
        "date": "2022-11-14T12:26:00.000Z",
        "voteCount": 15,
        "content": "NO- SalesRowID is the primary key for the Sales table, hence needed in the model\nNO- the analysis is not time based\nNo- decimal place is irrelevant in the analysis"
      },
      {
        "date": "2022-12-27T17:22:00.000Z",
        "voteCount": 28,
        "content": "you're thinking in \"ops database\" mode... In analytics it's not required for tables to have a primary key. Tables would break NF all the time due to performance needs.\n\nAlso if you read the column description, a sales row is an \"unique combination\" of Sales Order  and Sales Order Details... So  if you need to do analytics at those levels, you can go to those columns."
      },
      {
        "date": "2024-01-18T13:32:00.000Z",
        "voteCount": 3,
        "content": "Primary Key is not needed here"
      },
      {
        "date": "2022-12-25T07:16:00.000Z",
        "voteCount": 1,
        "content": "I agree with you."
      },
      {
        "date": "2024-01-02T19:59:00.000Z",
        "voteCount": 3,
        "content": "SalesRowID is not needed, the Fact table PK will not be needed to connect to other tables, you will need FKs though. \nThe correct answer is Yes, No, No"
      },
      {
        "date": "2024-10-07T09:48:00.000Z",
        "voteCount": 1,
        "content": "This question is not about primary or foreign keys. it about the metrics for basket analysis:\nTransactional Data: You need a dataset that captures individual transactions. This can include:\n1.Transaction IDs\n2.Product IDs or names\n3.Quantity of each item purchased\n4.Date and time of the transaction\nSo, ofc, first option: Yes, no need for these informations. second option: no,we need only the format of date+time Third option: no,tax make no sense for basket analysis"
      },
      {
        "date": "2024-08-17T02:05:00.000Z",
        "voteCount": 2,
        "content": "Yes, No, No"
      },
      {
        "date": "2024-08-16T11:40:00.000Z",
        "voteCount": 1,
        "content": "The Option 2 says \"Both the OrderDateKey and OrderDate....\" If you pick yes it means that you need both of them. But you don't.. at most you need only the OrderDate. So it should be NO"
      },
      {
        "date": "2024-07-17T04:11:00.000Z",
        "voteCount": 3,
        "content": "YES, NO, NO\nThe second answer with assumption of understanding it in a way that we can remove either \"OrderDateKey\" or \"OrderDate\" but not both."
      },
      {
        "date": "2024-05-26T13:41:00.000Z",
        "voteCount": 1,
        "content": "NO - NO - NO \nRetain Primary Keys in Dimension Tables: Do not remove primary keys from dimension tables. They are essential for establishing and maintaining relationships with the fact table, which is critical for the integrity and performance of your data model."
      },
      {
        "date": "2024-01-15T19:37:00.000Z",
        "voteCount": 3,
        "content": "I agree with Yes - No- No\nThere is SaleOrderNumber that identifies the orders. Date should be the same under the same SalesOrderNumber, so Date can be removed"
      },
      {
        "date": "2023-12-31T06:37:00.000Z",
        "voteCount": 1,
        "content": "Yes: Primary key for the fact table is not needed only foreign keys are needed to connect with other dimension tables\nYes: OrderDateKey column is needed to connect with the Date dimension table which may be used for analysis. The basket analysis requires date info\nNo: Not necessary"
      },
      {
        "date": "2023-10-26T05:19:00.000Z",
        "voteCount": 1,
        "content": "Yes Yes No .. the date is important"
      },
      {
        "date": "2023-10-09T10:56:00.000Z",
        "voteCount": 3,
        "content": "But I am thinking that the orderDate is necessary to know when an Item was bought so that one can know the Items that were bought at time and by the same customer. I think is Yes-Yes-No"
      },
      {
        "date": "2023-10-25T11:50:00.000Z",
        "voteCount": 4,
        "content": "I think we do not need dates. We are trying to see if they are within the same transaction (or order). The date is completely irrelevant, what we really would want to see is the orderID. There can be many different items bought on the same date that are part of different transactions, or orders."
      },
      {
        "date": "2023-10-04T07:36:00.000Z",
        "voteCount": 4,
        "content": "This was in the exam this week."
      },
      {
        "date": "2023-05-31T06:18:00.000Z",
        "voteCount": 3,
        "content": "yes No No"
      },
      {
        "date": "2023-04-12T01:21:00.000Z",
        "voteCount": 1,
        "content": "Yes - No - No"
      },
      {
        "date": "2023-01-05T15:05:00.000Z",
        "voteCount": 1,
        "content": "Correct"
      },
      {
        "date": "2022-12-25T07:22:00.000Z",
        "voteCount": 3,
        "content": "YES\nNO\nNO\nis the correct answer"
      },
      {
        "date": "2022-11-22T19:16:00.000Z",
        "voteCount": 4,
        "content": "My choice is\nYES\nNO\nNO"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 15,
    "url": "https://www.examtopics.com/discussions/microsoft/view/79453-exam-pl-300-topic-2-question-15-discussion/",
    "body": "You have a Microsoft Power BI data model that contains three tables named Orders, Date, and City. There is a one-to-many relationship between Date and<br>Orders and between City and Orders.<br>The model contains two row-level security (RLS) roles named Role1 and Role2. Role1 contains the following filter.<br>City[State Province] = \"Kentucky\"<br>Role2 contains the following filter.<br><br>Date[Calendar Year] = 2020 -<br>If a user is a member of both Role1 and Role2, what data will they see in a report that uses the model?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tThe user will see data for which the State Province value is Kentucky or where the Calendar Year is 2020.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tThe user will receive an error and will not be able to see the data in the report.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tThe user will only see data for which the State Province value is Kentucky.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tThe user will only see data for which the State Province value is Kentucky and the Calendar Year is 2020."
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 240,
        "isMostVoted": true
      },
      {
        "answer": "D",
        "count": 29,
        "isMostVoted": false
      },
      {
        "answer": "B",
        "count": 2,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2022-09-02T08:30:00.000Z",
        "voteCount": 141,
        "content": "Wrong , correct answer is A"
      },
      {
        "date": "2022-12-15T11:47:00.000Z",
        "voteCount": 26,
        "content": "I have tried and I was able to see for the year 2020 and area , so D should be correct"
      },
      {
        "date": "2024-06-27T01:15:00.000Z",
        "voteCount": 3,
        "content": "I also tried by creating two roles and assigned the contrains to each but the result is A. D works when I put both two constrains under the same role."
      },
      {
        "date": "2024-09-16T03:27:00.000Z",
        "voteCount": 1,
        "content": "Confirmed - did all the tests and A is the correct answer here. The final result of the report is UNION of what each role can see."
      },
      {
        "date": "2023-09-01T06:09:00.000Z",
        "voteCount": 10,
        "content": "Same i made the test. D is correct !"
      },
      {
        "date": "2022-10-12T00:51:00.000Z",
        "voteCount": 23,
        "content": "User is limited to only Kentucky AND year 2020. He should not have rights to see other years or areas. Come on guys its simple OR/AND!"
      },
      {
        "date": "2022-10-16T02:58:00.000Z",
        "voteCount": 7,
        "content": "Which means D is the correct answer"
      },
      {
        "date": "2022-12-27T17:27:00.000Z",
        "voteCount": 30,
        "content": "Yes it's simple OR/AND, and you simply don't understand how RLS works. Read Microsoft's doc, and pay attention to this sentence: \"Take care: Should a report user map to both roles, they'll see all Payroll table rows.\"\nhttps://learn.microsoft.com/en-us/power-bi/guidance/rls-guidance\n\nThat means different rules don't \"merge\" to become the most restrictive of the component rules. In the context of this question, IF I want to restrict this user to see ONLY Kentucky IN the year 2020, then I'd set up a RLS that has both of those conditions..."
      },
      {
        "date": "2024-05-26T09:24:00.000Z",
        "voteCount": 4,
        "content": "cnmc : Thank YOU! YOU R RIGHT!\nStraight away lifted from microsft page: \"When a report user is assigned to multiple roles, RLS filters become additive. It means report users can see table rows that represent the union of those filters. What's more, in some scenarios it's not possible to guarantee that a report user doesn't see rows in a table. So, unlike permissions applied to SQL Server database objects (and other permission models), the \"once denied always denied\" principle doesn't apply.\"\nLink: https://learn.microsoft.com/en-us/power-bi/guidance/rls-guidance\nJust do Cntrl+F and search on this page."
      },
      {
        "date": "2023-04-25T04:07:00.000Z",
        "voteCount": 2,
        "content": "I tend to agree with what you're saying, but in that example it's a TRUE() going against a FALSE(). One role is explicitly going against the other role, in this case both roles could supplement each other. Again, I agree that this likely means that it's not only the intersection of the two conditions you'll see, but I'm not 100% sure based on that example."
      },
      {
        "date": "2023-09-21T17:39:00.000Z",
        "voteCount": 2,
        "content": "For example, if a user belongs to both the \"Sales\" and \"Marketing\" roles, they can see data for both these roles.\n\nhttps://learn.microsoft.com/en-us/power-bi/enterprise/service-admin-rls#faq"
      },
      {
        "date": "2022-10-19T06:11:00.000Z",
        "voteCount": 24,
        "content": "D is correct.  Why?  Because if they could see Kentucky OR 2020 data then they just have to select Kentucky and they would be able to see data from all years, which would defeat the purpose of RLS"
      },
      {
        "date": "2022-12-27T17:28:00.000Z",
        "voteCount": 7,
        "content": "They would be able to select Kentucky and they would see the KENTUCKY data from all years. They would not be able to see, say New York data or California for years other than 2020"
      },
      {
        "date": "2022-10-26T06:45:00.000Z",
        "voteCount": 45,
        "content": "\"Multiple role mappings can result in unexpected outcomes.\nWhen a report user is assigned to multiple roles, RLS filters become ADDITIVE. It means report users can see table rows that represent the UNION of those filters.\"\nSource : https://learn.microsoft.com/en-us/power-bi/guidance/rls-guidance"
      },
      {
        "date": "2024-01-16T23:24:00.000Z",
        "voteCount": 5,
        "content": "This does not seem logical at all and is not the expected result however I have tested in Power BI Desktop and can confirm this is correct. It creates an OR filter condition rather than an AND filter condition when more than one role is applied :("
      },
      {
        "date": "2022-09-11T23:48:00.000Z",
        "voteCount": 51,
        "content": "Answer should be A, from the Microsoft documentation (https://docs.microsoft.com/en-us/power-bi/guidance/rls-guidance): \n\"When a report user is assigned to multiple roles, RLS filters become additive. It means report users can see table rows that represent the union of those filters.\" \n\nThis means that you would see all data where either Role1 OR Role2 applies, so the answer is A not D."
      },
      {
        "date": "2022-09-20T11:55:00.000Z",
        "voteCount": 1,
        "content": "Thank you, that is the right description."
      },
      {
        "date": "2022-09-20T23:26:00.000Z",
        "voteCount": 8,
        "content": "Union is everything in both, i.e Role1 and Role2"
      },
      {
        "date": "2022-09-26T12:05:00.000Z",
        "voteCount": 26,
        "content": "it's A i just recreated the scenario and it shows all the lines for the Role 1 and adds  all the lines for the Role 2. so keeps all the lines that meet  Role 1 OR Role 2"
      },
      {
        "date": "2022-10-05T23:43:00.000Z",
        "voteCount": 12,
        "content": "That means exactly the opposite \"can see table rows that represent the union of those filters.\"\nTables that represent the union of the filters, not the union of the rows displayed by each filter"
      },
      {
        "date": "2023-08-17T23:24:00.000Z",
        "voteCount": 1,
        "content": "I'd say that you are talking about the intersection"
      },
      {
        "date": "2024-09-06T11:41:00.000Z",
        "voteCount": 1,
        "content": "its simple, Rule1 and Rule2 applied meaning, Rule1 AND Rule2. \nD is the correct answer"
      },
      {
        "date": "2024-08-17T02:07:00.000Z",
        "voteCount": 1,
        "content": "Of course D- The user will only see data for which the State Province value is Kentucky AND the Calendar Year is 2020"
      },
      {
        "date": "2024-08-20T05:57:00.000Z",
        "voteCount": 1,
        "content": "Sorry, I made a mistake! I tested it and it is A because I created two roles; I am member of both of them and it shows data from Role1 OR Role2."
      },
      {
        "date": "2024-08-16T11:49:00.000Z",
        "voteCount": 2,
        "content": "D is correct.\nAdditive means AND."
      },
      {
        "date": "2024-08-09T10:23:00.000Z",
        "voteCount": 1,
        "content": "I think in a nutshell, at any point in time user can view the report as SINGLE role. \n\nHence if the user viewing as ROLE1 then City rule would apply, otherwise if the user viewing as ROLE2 year rule would apply. hence the answer is A (which mean the user has option to view as both roles independently)."
      },
      {
        "date": "2024-07-24T23:26:00.000Z",
        "voteCount": 1,
        "content": "The right answer is A. the user will see RLS 1 or RLS 2.\nIt's a little confusing for some people as they might understand the statement as: RLS 1 AND (not RLS 2) and vice versa. \nHowever, \"OR\" here is like logical operators. They can see, only rows belong to RLS1, only rows belong to RLS 2 and their intersect (both RLS1 &amp; RLS2). In other word, in this case, users can see all [State Province] in 2020, as well as Kentucky through out all [Calendar Year]."
      },
      {
        "date": "2024-07-23T01:36:00.000Z",
        "voteCount": 1,
        "content": "correct answer"
      },
      {
        "date": "2024-07-17T04:07:00.000Z",
        "voteCount": 1,
        "content": "https://learn.microsoft.com/en-us/power-bi/guidance/rls-guidance"
      },
      {
        "date": "2024-07-14T02:33:00.000Z",
        "voteCount": 1,
        "content": "With RLS it's always the combination. Meaning: the user sees the full set for 2020 and the full set for Kentucky. If you want the user to only see the year 2020 for Kentucky, than combine this in the same role."
      },
      {
        "date": "2024-06-27T00:56:00.000Z",
        "voteCount": 2,
        "content": "I tried on Power BI. If you create TWO roles, like Role 1 and Role 2, and assign the province and year to EACH OF THEM SEPERATELY, then the answer will be A -- which is the answer for this question. However, if you only create ONE role and put BOTH province and year UNDER THIS ROLE, the answer will be D."
      },
      {
        "date": "2024-06-13T12:04:00.000Z",
        "voteCount": 2,
        "content": "A he will see both"
      },
      {
        "date": "2024-05-27T02:38:00.000Z",
        "voteCount": 1,
        "content": "I think the confusion on this question is on semantics, a lot people who are saying answer is not D are programmers who want to see brackets enclosing (Kentarky and Year 2020)"
      },
      {
        "date": "2024-05-09T10:50:00.000Z",
        "voteCount": 1,
        "content": "The correct answer is D.\nThe user will only see data for which the State Province value is Kentucky and the Calendar Year is 2020.\n\nIn Power BI, if a user is a member of multiple roles, the filters from all roles are applied. This means that the user will only see data that meets all the conditions from all roles. \nIn this case, the user must see data where the State Province is Kentucky (from Role1) and the Calendar Year is 2020 (from Role2)."
      },
      {
        "date": "2024-05-02T06:45:00.000Z",
        "voteCount": 1,
        "content": "When a report user is assigned to multiple roles, RLS filters become additive. It means report users can see table rows that represent the union of those filters."
      },
      {
        "date": "2024-05-01T06:08:00.000Z",
        "voteCount": 1,
        "content": "D. The user will only see data for which the State Province value is Kentucky and the Calendar Year is 2020.\nBecause user is member of both Roles and hence member access the data only when they statisfies both the condition."
      },
      {
        "date": "2024-04-21T03:34:00.000Z",
        "voteCount": 1,
        "content": "I tested in in power BI and I am pretty sure that 'A' is the correct answer."
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 16,
    "url": "https://www.examtopics.com/discussions/microsoft/view/80001-exam-pl-300-topic-2-question-16-discussion/",
    "body": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.<br>After you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.<br>You are modeling data by using Microsoft Power BI. Part of the data model is a large Microsoft SQL Server table named Order that has more than 100 million records.<br>During the development process, you need to import a sample of the data from the Order table.<br>Solution: From Power Query Editor, you import the table and then add a filter step to the query.<br>Does this meet the goal?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tYes",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tNo\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 70,
        "isMostVoted": true
      },
      {
        "answer": "A",
        "count": 55,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2022-09-04T02:36:00.000Z",
        "voteCount": 76,
        "content": "I agree with the answer. \nB. No"
      },
      {
        "date": "2023-04-10T16:44:00.000Z",
        "voteCount": 22,
        "content": "A, should be correct. We have concept of Query Folding. If we apply the steps and it can be converted to Native Query then it will execute as is.\nBy development process it might mean by building Power BI Report, the view might be production view and as it is having 100 Million record. We cannot update the view for Power BI development."
      },
      {
        "date": "2024-07-27T10:43:00.000Z",
        "voteCount": 3,
        "content": "If you import the entire table, you will increase memory usage and may experience performance issues. Applying a filter only affects the visibility of the data, while still keeping the entire table in memory. Therefore, a more effective method is to sample or filter directly on the data source."
      },
      {
        "date": "2024-07-31T16:04:00.000Z",
        "voteCount": 3,
        "content": "haklisin seda"
      },
      {
        "date": "2024-05-10T15:40:00.000Z",
        "voteCount": 2,
        "content": "but before you apply the filter, you need to load the entire data in full to query editor, then you apply the filter, which turns into native query. It's best when you just add a where clause in sql query when importing"
      },
      {
        "date": "2023-04-10T16:49:00.000Z",
        "voteCount": 14,
        "content": "Great Explanation by Sana\nCorrect Answer A\n\nYes, when you use Power Query Editor to import a table with a filter in Power BI, only the filtered data is imported into the data model.\n\nThe Power Query Editor is used to transform and shape the data before it is loaded into the data model. When you apply a filter step to the query in Power Query Editor, it will only select the records that meet the filter criteria, and exclude the records that do not. This filtered data is then loaded into the data model."
      },
      {
        "date": "2024-03-26T06:43:00.000Z",
        "voteCount": 1,
        "content": "Tested - The correct answer is A -  So how you will apply the filter? \nLoad your data in Power query. \nCreate a \"new parameter\" from \"Manage Parameters Menu\" and assign your sample \"start date\" in \"current value\" field and reach ok. \nFilter your Datekey column by the created \"new parameter\" to get your sample in the model.Hope this will help."
      },
      {
        "date": "2023-06-03T03:49:00.000Z",
        "voteCount": 1,
        "content": "So from:\nhttps://learn.microsoft.com/en-us/power-query/power-query-folding\n\nIf the View Native Query option isn't enabled (greyed out), this is evidence that not all query steps can be folded. However, it could mean that a subset of steps can still be folded. Working backwards from the last step, you can check each step to see if the View Native Query option is enabled.\n\nSo is that enabled by default?"
      },
      {
        "date": "2022-10-28T17:52:00.000Z",
        "voteCount": 11,
        "content": "B is correct. This will load the entire table in the first step when you import. Instead add a WHERE clause to the SQL statement"
      },
      {
        "date": "2023-03-28T01:53:00.000Z",
        "voteCount": 8,
        "content": "It seems the correct answer is A, \"Yes\". because the question said importing in POWER QUERY and not POWER DESKTOP. and before importing POWER DESKTOP it uses filter step and filters the data. it means it will import only part of the table into power bi desktop. Although it is not recommended but still it works. please let me know if I am wrong."
      },
      {
        "date": "2022-09-12T02:41:00.000Z",
        "voteCount": 31,
        "content": "I think query folding can push the filter into the query so A yes"
      },
      {
        "date": "2023-01-13T20:03:00.000Z",
        "voteCount": 1,
        "content": "I agree"
      },
      {
        "date": "2023-01-17T02:34:00.000Z",
        "voteCount": 5,
        "content": "Query folding is only possible when using Direct Query. However, the exercise states import, so query folding cannot be used and as a consequence the filter cannot be pushed into the query."
      },
      {
        "date": "2023-01-17T02:40:00.000Z",
        "voteCount": 8,
        "content": "Correction: For a DirectQuery or Dual storage mode table, the Power Query query must achieve query folding. For an Import table, it may be possible to achieve query folding."
      },
      {
        "date": "2024-10-06T23:54:00.000Z",
        "voteCount": 1,
        "content": "The statement says that \"you import the data and then add the filter step.\" So the answer is NO. If the filter was added before importing then YES."
      },
      {
        "date": "2024-08-17T02:11:00.000Z",
        "voteCount": 1,
        "content": "I agree it is NO 'cause the question asked to avoid importing data from the source so it should be filtered using a WHERE SQL Condition"
      },
      {
        "date": "2024-07-18T00:47:00.000Z",
        "voteCount": 1,
        "content": "Hello Guys,\nCan you explain me this line. , once we start this section, we cannot go back?\n\"After you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\"\nThanks"
      },
      {
        "date": "2024-07-22T14:14:00.000Z",
        "voteCount": 1,
        "content": "Hola, quiere decir que una vez que respondas la pregunta, no tienes derecho a volver a la pregunta para cambiar la respuesta."
      },
      {
        "date": "2024-06-27T05:37:00.000Z",
        "voteCount": 1,
        "content": "I think this is B as the question says:\n'During the development process, you need to import a sample of the data from the Order table.'\n\nso it means only a part must be imported - this is to be achieved by where clause.\nI mporting and filtering will still import all and then filter"
      },
      {
        "date": "2024-04-26T15:49:00.000Z",
        "voteCount": 1,
        "content": "B is correct"
      },
      {
        "date": "2024-03-12T15:12:00.000Z",
        "voteCount": 1,
        "content": "Power Bi is not that smart. even if you have a step that filters data away, it will FIRST import all the data AND THEN apply the filter.\nyou must operate on the first step: import, so a query can do the magic here"
      },
      {
        "date": "2024-02-28T03:19:00.000Z",
        "voteCount": 4,
        "content": "proposed solution states : Import THEN apply a filter --&gt; meaning applying a filter on a 100miio records table -&gt; valid ? hello no!"
      },
      {
        "date": "2024-02-20T04:07:00.000Z",
        "voteCount": 1,
        "content": "Importing 10millions+ and then adding a filter ???\nTo get a sample just use a Select Top N statement where N is the number of records you want to upload"
      },
      {
        "date": "2024-02-16T08:37:00.000Z",
        "voteCount": 1,
        "content": "The answer is No because you firstly import the entire data source (that it takes time to load) and after that you apply a filter step in Power Query Editor."
      },
      {
        "date": "2024-03-11T03:54:00.000Z",
        "voteCount": 1,
        "content": "When you first import, it only selects the first few rows in the table, it doesn't load the whole table into memory"
      },
      {
        "date": "2024-02-09T02:55:00.000Z",
        "voteCount": 2,
        "content": "The Answer should be A. Yes because the question simply asks if the solution works, its not asking for the most optimal one which would be to add a 'WHERE' clause in SQL before importing"
      },
      {
        "date": "2024-01-28T14:37:00.000Z",
        "voteCount": 1,
        "content": "Importing without a filter will bring all the 100 million records before you apply a filter.  Using the native query language with \"where\" clause will filter the data even before importing it into Power BI Desktop."
      },
      {
        "date": "2024-03-11T03:54:00.000Z",
        "voteCount": 1,
        "content": "When you first import, it only selects the first few rows in the table, it doesn't load the whole table into memory"
      },
      {
        "date": "2024-05-20T16:59:00.000Z",
        "voteCount": 1,
        "content": "You might be referring to the Table View not the Power Query.  The Table View displays only 1000 records."
      },
      {
        "date": "2024-01-22T09:53:00.000Z",
        "voteCount": 1,
        "content": "B is correct, if you are thinking to add a filter later after you load the data, then PowerBI is still Loading the whole table first before getting into the filter step. The appropriate action is to add a where section in the SQL Query."
      },
      {
        "date": "2023-10-16T05:46:00.000Z",
        "voteCount": 1,
        "content": "B is correct"
      },
      {
        "date": "2023-10-05T02:50:00.000Z",
        "voteCount": 2,
        "content": "the question is ambiguous. The requirement is to import a SAMPLE to PowerBI. Not the whole database. However importing the whole database into PQE and THEN filtering so as to import a sample into Power BI seems to satisfy the question so answer is yes. Unfortunate phrasing ."
      },
      {
        "date": "2023-10-04T07:37:00.000Z",
        "voteCount": 5,
        "content": "This was in the exam this week."
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 17,
    "url": "https://www.examtopics.com/discussions/microsoft/view/80003-exam-pl-300-topic-2-question-17-discussion/",
    "body": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.<br>After you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.<br>You are modeling data by using Microsoft Power BI. Part of the data model is a large Microsoft SQL Server table named Order that has more than 100 million records.<br>During the development process, you need to import a sample of the data from the Order table.<br>Solution: You write a DAX expression that uses the FILTER function.<br>Does this meet the goal?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tYes",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tNo\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 16,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2022-10-27T13:50:00.000Z",
        "voteCount": 13,
        "content": "Also, common sense, we are trying to import a sample of the data meaning that the data is not yet on Power BI, so where are we going to filter with DAX? On the SQL server? That is not possible hence the answer B is correct."
      },
      {
        "date": "2022-11-04T04:52:00.000Z",
        "voteCount": 12,
        "content": "answer is NO, we need to add a WHERE clause to the SQL statement."
      },
      {
        "date": "2024-08-17T02:12:00.000Z",
        "voteCount": 1,
        "content": "Again, NO because we have to filter by using a WHERE condition"
      },
      {
        "date": "2023-12-12T15:04:00.000Z",
        "voteCount": 3,
        "content": "DAX is applicable in the last step only, so it is not useful for preventing a fully load. answer must be NO"
      },
      {
        "date": "2023-10-04T07:37:00.000Z",
        "voteCount": 2,
        "content": "This was in the exam this week."
      },
      {
        "date": "2023-09-04T23:23:00.000Z",
        "voteCount": 3,
        "content": "The answer is B.\nWriting a DAX expression using the FILTER function alone does not meet the goal of importing a sample of the data into Power BI. The FILTER function in DAX is used for filtering data within a calculated table or a measure, but it does not control the amount of data imported during the data loading process.\nTo import a sample of the data efficiently, you should use Power Query to apply filters during the data loading process, so only the relevant subset of data is imported."
      },
      {
        "date": "2023-08-21T06:55:00.000Z",
        "voteCount": 1,
        "content": "B because You can write dax in power bi desktop so it's already load"
      },
      {
        "date": "2023-05-31T10:25:00.000Z",
        "voteCount": 1,
        "content": "No, sql statement only can solve it"
      },
      {
        "date": "2023-05-02T01:48:00.000Z",
        "voteCount": 1,
        "content": "We cannot write DAX expression at this point! DAX expression is in report part."
      },
      {
        "date": "2023-04-12T02:13:00.000Z",
        "voteCount": 3,
        "content": "The correct answer is B. This is because all of the data is first loaded into Power BI before being filtered."
      },
      {
        "date": "2023-03-03T18:43:00.000Z",
        "voteCount": 2,
        "content": "The correct answer is B. This is because all of the data is first loaded into Power BI before being filtered."
      },
      {
        "date": "2023-01-13T20:08:00.000Z",
        "voteCount": 1,
        "content": "B or No because the Data is already loaded. It is good to select the columns we need at source level .eg create view  . Other wise we can bring to power query and filter is before we load it . He query folding will send the query back to the data source"
      },
      {
        "date": "2022-10-18T04:37:00.000Z",
        "voteCount": 2,
        "content": "The correct answer is B"
      },
      {
        "date": "2022-10-06T15:18:00.000Z",
        "voteCount": 5,
        "content": "B is correct"
      },
      {
        "date": "2022-09-13T13:39:00.000Z",
        "voteCount": 1,
        "content": "Answer is Correct."
      },
      {
        "date": "2022-09-04T02:38:00.000Z",
        "voteCount": 1,
        "content": "You can write a DAX expression after you import the data."
      },
      {
        "date": "2022-09-06T02:49:00.000Z",
        "voteCount": 5,
        "content": "Yes but in that case you import all data from the order table while the question states you only need to import a sample. So B is correct"
      },
      {
        "date": "2022-10-19T06:15:00.000Z",
        "voteCount": 2,
        "content": "Agree with MilouSluijter.  If you apply filter at DAX stage, the data is already in the model"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 18,
    "url": "https://www.examtopics.com/discussions/microsoft/view/82973-exam-pl-300-topic-2-question-18-discussion/",
    "body": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.<br>After you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.<br>You are modeling data by using Microsoft Power BI. Part of the data model is a large Microsoft SQL Server table named Order that has more than 100 million records.<br>During the development process, you need to import a sample of the data from the Order table.<br>Solution: You add a WHERE clause to the SQL statement.<br>Does this meet the goal?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tYes\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tNo"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 31,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2022-10-06T15:19:00.000Z",
        "voteCount": 16,
        "content": "A is correct"
      },
      {
        "date": "2024-08-17T02:13:00.000Z",
        "voteCount": 1,
        "content": "A. Yes - In this case we filter from the import the data"
      },
      {
        "date": "2024-04-26T15:47:00.000Z",
        "voteCount": 1,
        "content": "B is correct"
      },
      {
        "date": "2024-07-27T10:49:00.000Z",
        "voteCount": 3,
        "content": "NO. If you import the entire table, you will increase memory usage and may experience performance issues. Applying a filter only affects the visibility of the data, while still keeping the entire table in memory. Therefore, a more effective method is to sample or filter directly on the data source."
      },
      {
        "date": "2024-07-27T10:49:00.000Z",
        "voteCount": 1,
        "content": "A is correct."
      },
      {
        "date": "2023-11-17T03:55:00.000Z",
        "voteCount": 4,
        "content": "This was on the exam today. Passed with 917/1000\n- I said: A. Yes"
      },
      {
        "date": "2023-10-04T07:36:00.000Z",
        "voteCount": 3,
        "content": "This was in the exam this week."
      },
      {
        "date": "2023-09-04T23:27:00.000Z",
        "voteCount": 1,
        "content": "The answer is A.\nAdding a WHERE clause to the SQL statement used to retrieve data from the Microsoft SQL Serve table named Order can meet the goal of importing a sample of the data into Power BI."
      },
      {
        "date": "2023-05-31T10:29:00.000Z",
        "voteCount": 1,
        "content": "A is correct"
      },
      {
        "date": "2023-04-12T02:13:00.000Z",
        "voteCount": 1,
        "content": "The correct answer is A. This means that the data is being filtered at the source database itself, using a SQL query with a WHERE clause."
      },
      {
        "date": "2023-03-03T18:45:00.000Z",
        "voteCount": 3,
        "content": "The correct answer is A. This means that the data is being filtered at the source database itself, using a SQL query with a WHERE clause."
      },
      {
        "date": "2022-12-16T13:12:00.000Z",
        "voteCount": 2,
        "content": "A is correct"
      },
      {
        "date": "2022-11-29T09:15:00.000Z",
        "voteCount": 1,
        "content": "As the basis is Microsoft SQL (or OData Feed, for that matter), it is actually possible to achieve the goal without a where clause, since this clause will be added by the Power Query enginge. So I think that indeed, query folding is possible and therefore, the answer should be Yes"
      },
      {
        "date": "2022-10-18T04:37:00.000Z",
        "voteCount": 2,
        "content": "Ais the correct Answer"
      },
      {
        "date": "2022-09-20T12:05:00.000Z",
        "voteCount": 4,
        "content": "In my opinion the goal can only be met if you for example know the Id of an item and then filter for this. So the goal can be met but it an ugly solution."
      },
      {
        "date": "2023-01-13T20:10:00.000Z",
        "voteCount": 1,
        "content": "Yes better to use query folding I think.  You are talking about indexing the data source right ?"
      },
      {
        "date": "2022-10-06T15:22:00.000Z",
        "voteCount": 3,
        "content": "You are over thinking it. Its asking for a sample of the data in a table with more than 100 million rows. So a simple select statement like the below would return a sample data set of 1000 rows from the Order table. \nSelect TOP (1000) *\nFrom [dbo].[Order]"
      },
      {
        "date": "2022-10-10T06:56:00.000Z",
        "voteCount": 1,
        "content": "But these is no WHERE clause in your statement. It would have been easier if the TOP 1000 was mentioned."
      },
      {
        "date": "2022-11-22T04:39:00.000Z",
        "voteCount": 2,
        "content": "In practice you would most probably take a sample of the most recently created rows, using a WHERE clause and filtering on a date column."
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 19,
    "url": "https://www.examtopics.com/discussions/microsoft/view/80615-exam-pl-300-topic-2-question-19-discussion/",
    "body": "DRAG DROP -<br>You are preparing a financial report in Power BI.<br>You connect to the data stored in a Microsoft Excel spreadsheet by using Power Query Editor as shown in the following exhibit.<br><img src=\"/assets/media/exam-media/04331/0009800001.jpg\" class=\"in-exam-image\"><br>You need to prepare the data to support the following:<br>\u2711 Visualizations that include all measures in the data over time<br>\u2711 Year-over-year calculations for all the measures<br>Which four actions should you perform in sequence? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.<br>Select and Place:<br><img src=\"/assets/media/exam-media/04331/0009800004.jpg\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04331/0009900001.jpg\" class=\"in-exam-image\">",
    "answerDescription": "Reference:<br>https://docs.microsoft.com/en-us/power-query/unpivot-column",
    "votes": [],
    "comments": [
      {
        "date": "2022-09-11T23:59:00.000Z",
        "voteCount": 352,
        "content": "Answer is wrong, the table shouldn't be transposed, the order should be: \n1. Use first row as header\n2. Unpivot all columns other than \"Measure\"\n3. Rename \"Attribute\" to \"Year\"\n4. Change data type of \"Year\" to date (Date &gt; Year)"
      },
      {
        "date": "2024-05-05T01:03:00.000Z",
        "voteCount": 3,
        "content": "in this method we can plot the graph but we cant about calculate year on year growth for revenue since all the measures are available in the single column."
      },
      {
        "date": "2023-02-15T02:39:00.000Z",
        "voteCount": 1,
        "content": "Why shouldn't? The titles should be on the top."
      },
      {
        "date": "2023-04-25T04:17:00.000Z",
        "voteCount": 1,
        "content": "Transpose swaps rows and columns, which is not at all what you want.\nSource: https://learn.microsoft.com/en-us/power-query/transpose-table"
      },
      {
        "date": "2023-04-25T04:22:00.000Z",
        "voteCount": 4,
        "content": "I stand corrected, you want a year-to-year calculation for all the measures. That means that you need to keep the measures and the years intact. I think both is possible"
      },
      {
        "date": "2023-06-30T02:23:00.000Z",
        "voteCount": 1,
        "content": "If we need to have visuals that show all measures over time, it would be better to have the measures in separate columns"
      },
      {
        "date": "2022-12-20T20:37:00.000Z",
        "voteCount": 1,
        "content": "Hi guys, I am wondering how you can do the second step - Unpivot all columns other than \"Measure\"? There is no column called \"Measure\" unless you transpose or unpivot it. This is a much more serious problem than the problem with the last step in the transpose solution - being the failure of change data type of \"Year\" to date."
      },
      {
        "date": "2022-12-20T22:54:00.000Z",
        "voteCount": 5,
        "content": "Please disregard. long hours studying and I had brain frozen. My apologies."
      },
      {
        "date": "2022-12-14T06:45:00.000Z",
        "voteCount": 2,
        "content": "I agree.\nUsing the transpose solution, when changing the data type of the Year column to date, the date is incorrectly transformed. It doesn't happen when using this solution."
      },
      {
        "date": "2022-10-29T13:22:00.000Z",
        "voteCount": 181,
        "content": "To me, \n1. Transpose the table \n2. Use first row as headers\n3. Rename the Measure column as Year\n4. Change the data type of the Year column to Date.\n\nYo don't need to unpivot but transpose because you need the measures in columns. Don't you agree?"
      },
      {
        "date": "2024-03-03T07:18:00.000Z",
        "voteCount": 3,
        "content": "I agree, I think people disagree because they are not on the same page on the desired outcome table. Since we need a table with the following columns, you just need to transpose:\nYear Revenue Overheads Cost of goods.\nUnpivot in useful if the column measure had category values (Countryname, Productname...) not measures. Here we do not want the measures to repeat."
      },
      {
        "date": "2022-12-27T11:21:00.000Z",
        "voteCount": 2,
        "content": "tried, this one is correct."
      },
      {
        "date": "2023-07-20T10:10:00.000Z",
        "voteCount": 7,
        "content": "You cannot change the data type of only a years to date otherwise it will auto generate a DDMMYY format"
      },
      {
        "date": "2023-07-19T22:00:00.000Z",
        "voteCount": 2,
        "content": "ya i agreed, transpose the table."
      },
      {
        "date": "2024-10-03T11:33:00.000Z",
        "voteCount": 1,
        "content": "Transpose the table\nUse the first row as headers\nRename the Measure column as Year\nChange the datatype of the Year column to Date\nits the correct answer"
      },
      {
        "date": "2024-09-13T02:28:00.000Z",
        "voteCount": 1,
        "content": "Answer is correct. I just try on my computer and works perfectly."
      },
      {
        "date": "2024-08-17T02:20:00.000Z",
        "voteCount": 1,
        "content": "I totally agree with ThariCD:\n1 - Use the first row as headers (we now have column names)\n2 - Unpivot all the columns other than Measure (we have years in one column only)\n3 - Rename the Attribute column as Year (we have the year column)\n4 - Change the data type of the Year column to Date (I only have a doubt for this step, why an year should be considered as a Date???)"
      },
      {
        "date": "2024-07-17T22:53:00.000Z",
        "voteCount": 1,
        "content": "The answer is wrong the table should not be transposed"
      },
      {
        "date": "2024-07-16T02:58:00.000Z",
        "voteCount": 2,
        "content": "With Transpose there is an issue to do in one step conversion of Year data type from Int to Date (it has to be done in 2 steps int-&gt;text-&gt;date) and it results in 5 steps, not 4. IDK the answer here."
      },
      {
        "date": "2024-07-13T18:55:00.000Z",
        "voteCount": 1,
        "content": "\u2022\t1. Transpose the table \n\u2022\t2. Use first row as headers \n\u2022\t3. Rename the Measure column as Year \n\u2022\t4. Change the data type of the Year column to Date."
      },
      {
        "date": "2024-05-21T17:20:00.000Z",
        "voteCount": 2,
        "content": "The given answer is correct."
      },
      {
        "date": "2024-05-13T12:07:00.000Z",
        "voteCount": 5,
        "content": "Transpose\nUse the first rows as headers\nRename the measure as year\nChange the data type of the year column"
      },
      {
        "date": "2024-04-29T01:49:00.000Z",
        "voteCount": 1,
        "content": "Sorry, but the last step is wrong, if you change the year to datatype date you would get 17th July, 1905.\nActually my problem is: which 4th option do I select when all remaining options are wrong?????"
      },
      {
        "date": "2024-04-16T09:11:00.000Z",
        "voteCount": 4,
        "content": "The 3rd step is wrong. You do not need to unpivot. \n\nThe solution must be:\n\n1. Transpose the table \n2. Use first row as headers\n3. Rename the Measure column as Year\n4. Change the data type of the Year column to Date.\n\nThis is really a tricky questions and most of us tend to go immediately to \"unpivot other columns\". The key here is to check the data carefully. And if you noticed on the first column, besides the first row which is measure, the other rows are all fields as well. So transpose instead of unpivot. \n\n"
      },
      {
        "date": "2024-03-28T09:02:00.000Z",
        "voteCount": 2,
        "content": "TRANSPOSE the table\nUse first row as header\nRename the measure column as Year\nChange the data type of the year column to Date"
      },
      {
        "date": "2024-03-20T04:20:00.000Z",
        "voteCount": 3,
        "content": "Tested in Power BI, Both unpivot and transpose worked. \nI think the answer depends on the desired format of outcome table.\nIf you want a 3 * 15 (row * col) table, with each measure and year to be a dependent row, then unpivot.\nIf you want a 5 * 4 (row * col) table, with measures(revenue etc.) are columns and year in the row, then transpose."
      },
      {
        "date": "2024-03-14T12:27:00.000Z",
        "voteCount": 1,
        "content": "1. Transpose\n2. first row as header\n3. Rename the measure coloumn as year\n4. Change the datatype\n\n100% TESTED SEQUENCE in PowerBI !!!"
      },
      {
        "date": "2024-02-28T04:27:00.000Z",
        "voteCount": 1,
        "content": "answer is right; when you transpose you obtain the correct order requested by the question;\nyear to products \n2016-product1;\n2016-product2;\n2016-product3; and so on\n\nwhen you unpivot, you obtain a different order;\nproduct to years\n2016-product1;\n2017-product1;\n2018-product1; and so on"
      },
      {
        "date": "2024-02-20T05:08:00.000Z",
        "voteCount": 3,
        "content": "Tested in PBI Desktop with the exact same excel sheet;\n\nTranspose : first column values become first row and each row contains its respective values\n\nUse first Row as Headers: first row containing values from first excel column, promoting that first row make it a row header : correct.\nPay attention to an automatic applied step changing types on the fly too such as:\n= Table.TransformColumnTypes(#\"Promoted Headers1\",{{\"Measure\", Int64.Type}, {\"Revenue\", type number}, {\"Overheads\", type number}, {\"Cost of Goods\", type number}})\n\nUnpivot Other Columns (having measure column selected):\ncreates 3 columns : Measure - Attribute - Value\nMeasure column contains YEAR values only\n\nRename Measure Column to YEAR : because it's the data in it.\n\nNow you can filter by attributes and see the evolution year by year"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 20,
    "url": "https://www.examtopics.com/discussions/microsoft/view/82784-exam-pl-300-topic-2-question-20-discussion/",
    "body": "HOTSPOT -<br>You are creating an analytics report that will consume data from the tables shown in the following table.<br><img src=\"/assets/media/exam-media/04331/0010000001.png\" class=\"in-exam-image\"><br>There is a relationship between the tables.<br>There are no reporting requirements on employee_id and employee_photo.<br>You need to optimize the data model.<br>What should you configure for employee_id and employee_photo? To answer, select the appropriate options in the answer area.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04331/0010100001.jpg\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04331/0010200001.jpg\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: Hide -<br>Need in the relation, so cannot delete it.<br><br>Box 2: Delete -<br>Reference:<br>https://community.powerbi.com/t5/Desktop/How-to-Hide-a-Column-in-power-Bi/m-p/414470",
    "votes": [],
    "comments": [
      {
        "date": "2022-09-19T04:26:00.000Z",
        "voteCount": 56,
        "content": "Answer is Correct"
      },
      {
        "date": "2022-09-21T05:49:00.000Z",
        "voteCount": 15,
        "content": "Hide &amp; Delete"
      },
      {
        "date": "2024-08-17T02:23:00.000Z",
        "voteCount": 1,
        "content": "Since there are no requirements on emp_id and emp_photo, we can \n1 - hide the emp_id\n2 - delete the emp_photo\nSo, the answer is correct"
      },
      {
        "date": "2024-07-23T01:55:00.000Z",
        "voteCount": 1,
        "content": "correct answer"
      },
      {
        "date": "2023-12-21T22:57:00.000Z",
        "voteCount": 7,
        "content": "Corect answer.\nEmployee_id: Hide\nWe should not delete this as it appears to be the primary key of the Employee table.\n\nemployee_photo: Delete\nAS mentioned in the question, since there is no reporting requiremtns on it, the column can be deleted."
      },
      {
        "date": "2023-10-02T03:56:00.000Z",
        "voteCount": 5,
        "content": "yes answer correct. Photo not needed so delete. Employee ID is the common key between these tables so hide."
      },
      {
        "date": "2023-09-05T07:51:00.000Z",
        "voteCount": 5,
        "content": "Hide and Delete are the correct answers. \nHide: We should hide the \"employee_id\" column if there are no reporting requirements on it. This means it won't be visible in the report, but it will still be available for any potential relationships or calculations with the model. \nDelete: Since there are no reporting requirements on the \"employee_photo\" column, we should delete it from the data model to reduce unnecessary storage and improve performance. This means that the \"employee_photo\" data is not needed for any calculations or relationships within the model."
      },
      {
        "date": "2023-08-02T08:40:00.000Z",
        "voteCount": 3,
        "content": "The answer is correct, and the question was on the exam."
      },
      {
        "date": "2023-07-07T01:23:00.000Z",
        "voteCount": 8,
        "content": "This was on the exam"
      },
      {
        "date": "2023-06-25T10:34:00.000Z",
        "voteCount": 2,
        "content": "Answer is correct. You need Employeeid for creating relations."
      },
      {
        "date": "2023-06-16T00:39:00.000Z",
        "voteCount": 3,
        "content": "For employee_id:\n\nHide: This option should be selected to hide the employee_id column. Since there are no reporting requirements on it, hiding the column can help declutter the report and improve the user experience.\nFor employee_photo:\n\nDelete: This option should be selected to delete the employee_photo column. If there are no reporting requirements for it and it is not needed for any analysis or visualization, removing the column altogether can help reduce the storage space and optimize the data model."
      },
      {
        "date": "2023-06-05T07:16:00.000Z",
        "voteCount": 1,
        "content": "I think it should be change date type and delete because changing the date type of employees ID to VARCHAR will prevent  summation of the column and deleting unwanted column, both scenarios will optimize the report"
      },
      {
        "date": "2023-08-04T06:33:00.000Z",
        "voteCount": 2,
        "content": "VARCHAR is less efficient than integer"
      },
      {
        "date": "2023-05-31T11:04:00.000Z",
        "voteCount": 1,
        "content": "given answer is correct"
      },
      {
        "date": "2023-05-23T21:52:00.000Z",
        "voteCount": 1,
        "content": "Answer is correct!!"
      },
      {
        "date": "2023-05-02T01:53:00.000Z",
        "voteCount": 1,
        "content": "Hiding does not help for optimizing, but Sort helps."
      },
      {
        "date": "2023-05-02T01:52:00.000Z",
        "voteCount": 1,
        "content": "Sort\nDelete"
      },
      {
        "date": "2023-06-06T03:36:00.000Z",
        "voteCount": 1,
        "content": "Is there any url that I can refer to, to read about performance boost using sort on a column?"
      },
      {
        "date": "2023-04-26T23:13:00.000Z",
        "voteCount": 1,
        "content": "Answer is correct"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 21,
    "url": "https://www.examtopics.com/discussions/microsoft/view/80707-exam-pl-300-topic-2-question-21-discussion/",
    "body": "HOTSPOT -<br>You plan to create Power BI dataset to analyze attendance at a school. Data will come from two separate views named View1 and View2 in an Azure SQL database.<br>View1 contains the columns shown in the following table.<br><img src=\"/assets/media/exam-media/04331/0010300001.png\" class=\"in-exam-image\"><br>View2 contains the columns shown in the following table.<br><img src=\"/assets/media/exam-media/04331/0010300002.png\" class=\"in-exam-image\"><br>The views can be related based on the Class ID column.<br>Class ID is the unique identifier for the specified class, period, teacher, and school year. For example, the same class can be taught by the same teacher during two different periods, but the class will have a different class ID.<br>You need to design a star schema data model by using the data in both views. The solution must facilitate the following analysis:<br>\u2711 The count of classes that occur by period<br>\u2711 The count of students in attendance by period by day<br>\u2711 The average number of students attending a class each month<br>In which table should you include the Teacher First Name and Period Number fields? To answer, select the appropriate options in the answer area.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04331/0010500001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04331/0010600001.png\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: Teacher fact -<br>Fact tables store observations or events, and can be sales orders, stock balances, exchange rates, temperatures, etc. A fact table contains dimension key columns that relate to dimension tables, and numeric measure columns.<br>Note: Star schema is a mature modeling approach widely adopted by relational data warehouses. It requires modelers to classify their model tables as either dimension or fact.<br><br>Box 2: Attendance fact -<br>Incorrect:<br>\u05d2\u20ac\"<br>Dimension tables describe business entities<br>the things you model. Entities can include products, people, places, and concepts including time itself. The most consistent table you'll find in a star schema is a date dimension table. A dimension table contains a key column (or columns) that acts as a unique identifier, and descriptive columns.<br>Reference:<br>https://docs.microsoft.com/en-us/power-bi/guidance/star-schema",
    "votes": [],
    "comments": [
      {
        "date": "2022-09-06T12:47:00.000Z",
        "voteCount": 207,
        "content": "I'd say: \nTeacher's dim\nClass dim"
      },
      {
        "date": "2022-11-22T04:59:00.000Z",
        "voteCount": 12,
        "content": "I agree completely. Period is an attribute of Class:\n\"Class ID is the unique identifier for the specified class, period, teacher, and school year. For example, the same class can be taught by the same teacher during two different periods, but the class will have a different class ID.\""
      },
      {
        "date": "2023-12-21T08:40:00.000Z",
        "voteCount": 2,
        "content": "The mean is an aggregate measure that can be calculated on the fact table. However, the dimension table can contain attributes that help you split or filter the average based on certain criteria.\n\"You need to design a star schema data model using the data in both views. Your solution should facilitate the following analysis:\n\u2711 The count of lessons that occur per period\n\u2711 The count of students attending per period per day\n\u2711 The average number of students attending a class each month\"\nso I believe the model must have a fact table. but I see that your model only has dimension tables and it is not correct"
      },
      {
        "date": "2022-12-13T04:36:00.000Z",
        "voteCount": 28,
        "content": "I changed my mind. If there would be a Teacher Dimension, then this Teacher Dimension should have a relationship with the Class Dimension (not directly with the Attendence Fact). That is possible, but that would make it a Snowflake Schema. And what is asked for is a Star Schema.\nSo both TeacherName and Period should be attributes of the Class Dimension."
      },
      {
        "date": "2023-02-28T12:00:00.000Z",
        "voteCount": 6,
        "content": "But the teacher dim can just use the class id to link to the fact table. No need to have it go through the class dim"
      },
      {
        "date": "2023-04-25T04:38:00.000Z",
        "voteCount": 1,
        "content": "You could even add the teacher id to the class table, I don't see why that's not possible"
      },
      {
        "date": "2024-03-06T08:54:00.000Z",
        "voteCount": 6,
        "content": "Adding period number to Class dim will fill the dim with dups, since 1 class can have more than one period.  That means that class dim can only be used when period is part of the requirement.  In real life, this would not work.  Actually, the best option is not even proposed. Class period is its own dimension and would connect to the fact.  Dim period includes period number, period start time and period end time.  Since this option is no available to us, that makes period number a degenerate dimension and it belongs in the fact table.  See below:\nAccording to Ralph Kimball,[1] in a data warehouse, a degenerate dimension is a dimension key in the fact table that does not have its own dimension table, because all the interesting attributes have been placed in analytic dimensions. The term \"degenerate dimension\" was originated by Ralph Kimball."
      },
      {
        "date": "2024-03-26T07:53:00.000Z",
        "voteCount": 22,
        "content": "I will go for:\nTeacher Dim\nAttendance Fact"
      },
      {
        "date": "2022-09-09T06:17:00.000Z",
        "voteCount": 5,
        "content": "Agree with you"
      },
      {
        "date": "2022-09-09T05:01:00.000Z",
        "voteCount": 104,
        "content": "Isn't it teacher dim and attendance fact?"
      },
      {
        "date": "2022-09-11T08:40:00.000Z",
        "voteCount": 7,
        "content": "I agree!"
      },
      {
        "date": "2023-03-28T03:26:00.000Z",
        "voteCount": 3,
        "content": "Isn't here an issue with the requirement: \"The count of classes that occur by period\"?\nA class can be available without attendance, or am I wrong?"
      },
      {
        "date": "2024-09-16T17:36:00.000Z",
        "voteCount": 3,
        "content": "Microsoft's questions often stray into areas where ambiguity is induced and thus multiple answers could work. Without the benefit of a test where you can elaborate on that, being limited to multiple choice, I reckon MSFT needs to tighten their questions and remove any ambiguity. It's pretty poor exam writing."
      },
      {
        "date": "2024-09-10T23:30:00.000Z",
        "voteCount": 1,
        "content": "Proposed Solution:\nClass Dim\nClass Dim\n\nReasoning: The problem particularly states that Class ID is an identifier for the class (name and subject), Period #, Teacher, and School Year. We know that Attendance will represent our fact table and relate to the Class Dimension containing those attributes. Teacher information can be contained in this Class Dimension -- the problem states itself that it is.\n\nWe cannot create a Teacher dimension since we lack a primary key relating to a fact table (unless we also created a Teacher fact, which just creates additional tables without adding any new information to the model, which is unreasonable when the information can already be represented fully by the class dimension, as stated in the problem). If you tried to create a Teacher dim relating to the Class dim on Teacher ID, then it is no longer Star Schema."
      },
      {
        "date": "2024-09-10T23:30:00.000Z",
        "voteCount": 2,
        "content": "So we can create a model in Star Schema that fulfills all the requirements by creating a Class Dimension containing: Class ID, Class Name, Class Subject, ***Period #***,  Teacher ID, ***Teacher First***, Teacher Last, and School Year\nwith this Dimension relating to an Attendance fact table on Class ID as primary key containing: Class ID, Attendance Date, Student ID.\n\nNote that this model fulfills the 3 analytic requirements as well:\n&gt;# Classes by period #:\n&gt;&gt;Count of classes grouped by Class[PeriodNumber]\n\n&gt;# Students by period by day\n&gt;&gt;Count of rows grouped by AttendanceDate in the Attendance fact table\n\n&gt;Avg students by class by month\n&gt;&gt;Count of rows in Attendance fact grouped by AttDate &amp; ClassID, then averaged over a month period"
      },
      {
        "date": "2024-08-17T02:27:00.000Z",
        "voteCount": 1,
        "content": "I'd say teacher dim, class dim"
      },
      {
        "date": "2024-05-22T12:31:00.000Z",
        "voteCount": 1,
        "content": "Class dim\nClass dim"
      },
      {
        "date": "2024-05-08T07:05:00.000Z",
        "voteCount": 2,
        "content": "I would say:\n1. Class DIM\n2. Class DIM\nThe question says the \"Class ID\" column is a unique identifier for the specified class, PERIOD, TEACHER, and school year. So if I connect Class ID to the same column in an Attendance Fact Table and then use the period column from dimension to look at the count of class id from fact - this would give me a break down of period by attending classes."
      },
      {
        "date": "2024-05-03T23:38:00.000Z",
        "voteCount": 1,
        "content": "I was wondering if there should be a dim.period, dim.teacher &amp; dim.class. Then technically you would put Period number in the fact.attendence although I would personally call it Period Id, but there's nothing saying that the star schema uses 'id' and not 'number' as it's key column naming convention.  If period is in dim.class it's not normalised properly.  SO if that is the correct answer then I'm afraid Microsoft have messed up here."
      },
      {
        "date": "2024-05-04T00:10:00.000Z",
        "voteCount": 1,
        "content": "The only issue is this:  The count of classes that occur by period. We can't do this because we don't know the instances of what classes are assigned to what periods.... we would need another table for that and therefore, the answer must be a really SLOPPY Dim.Class for the Period."
      },
      {
        "date": "2024-04-25T03:26:00.000Z",
        "voteCount": 1,
        "content": "i would choose Teacher Dim and Class dim\n\nThe teacher's first name and period number are dimensional fields and therefore shouldn't reside in the fact table. \nInstead, they belong in dimension tables. \nin star schema, we have a fact table containing attendance data linked to other dimensions such as teacher and class. \nConsequently, both the teacher's first name and the period number should be included in dimension tables like the Teacher dimension and the Class dimension, respectively."
      },
      {
        "date": "2024-04-22T13:05:00.000Z",
        "voteCount": 2,
        "content": "100% confirmed, it's Teacher dim and Class dim. How come so many of these answers are wrong?"
      },
      {
        "date": "2024-03-27T02:21:00.000Z",
        "voteCount": 7,
        "content": "I would say it's:\n\nTeacher First Name: Teacher Dim\nPeriod Name: Attendance Fact\n\nIn this STAR Schema case, we only need to have 1 fact table. \nAnd since the question mentioned our purpose \"to analyze ATTENDANCE at school\". So, Fact Attendance should be the only fact table in the star schema (not Fact Teacher), since fact table is defined as \"stores measures that measure the business\". So, in able to analyze ATTENDANCE, we need to collect as much as measures of attendance data, which will be stored in attendance fact!"
      },
      {
        "date": "2024-03-12T15:22:00.000Z",
        "voteCount": 4,
        "content": "i'll say class dim and attendance fact.\nthe question requires a star schema\nso we cannot have more than one fact and only dimension that relates to fact.\nour fact is attendance (because is the many side of the raltionship). and we have a class dimension. it will be possible to create a teacher dim, but it will be related to the class dim, and not tthe fact. so it will not be a star schema anymore but a snowflake.\nso we need to keep the tables as they are in the question. having only a class dimension (first dropdown) and a attendance fact (second one)"
      },
      {
        "date": "2024-03-07T04:16:00.000Z",
        "voteCount": 1,
        "content": "Answer is correct.\nThere will be two fact tables : Teacher fact and Attendance Fact in the model. (That is better model than creating the Teacher dimension)."
      },
      {
        "date": "2024-03-11T05:55:00.000Z",
        "voteCount": 1,
        "content": "Teacher can't be a fact. One class has one teacher, one teacher can teach many classes."
      },
      {
        "date": "2024-02-28T12:28:00.000Z",
        "voteCount": 3,
        "content": "ChatGPT: Teacher dim, Class dim"
      },
      {
        "date": "2024-02-21T09:21:00.000Z",
        "voteCount": 1,
        "content": "Class dim should include one record per class.  But a given class can multiple periods.  For example, class PL-300 can have period 1 and period 2.  Having the period in the class dimension would brake the grain, unless we use Kimbal's grouping approach, where we could have 1 column in class dimension called period_group and could have class PL-300, period_group 1,2.  But the question does not include this option.  Another way to design it is to treat period as a degerate dimension, which means add period to the fact."
      },
      {
        "date": "2024-02-22T05:37:00.000Z",
        "voteCount": 1,
        "content": "It is not degerate dimension, it is degenerate dimension.  According to Ralph Kimball, in a data warehouse, a degenerate dimension is a dimension key in the fact table that does not have its own dimension table, because all the interesting attributes have been placed in analytic dimensions. All interesting attributes related to period are in the class dimension."
      },
      {
        "date": "2024-02-07T02:25:00.000Z",
        "voteCount": 2,
        "content": "Agreed\n\n"
      },
      {
        "date": "2024-02-05T07:15:00.000Z",
        "voteCount": 1,
        "content": "The answer provided is wrong I think, because - can a star schema hace 2 fact tables? no r8"
      },
      {
        "date": "2024-02-06T22:00:00.000Z",
        "voteCount": 2,
        "content": "Apologies, just learned that there could be star schema with multiple fact tables"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 22,
    "url": "https://www.examtopics.com/discussions/microsoft/view/84556-exam-pl-300-topic-2-question-22-discussion/",
    "body": "You have the Power BI model shown in the following exhibit.<br><img src=\"/assets/media/exam-media/04331/0010700001.jpg\" class=\"in-exam-image\"><br>There are four departments in the Departments table.<br>You need to ensure that users can see the data of their respective department only.<br>What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a slicer that filters Departments based on DepartmentID.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a row-level security (RLS) role for each department, and then define the membership of the role.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a DepartmentID parameter to filter the Departments table.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tTo the ConfidentialData table, add a calculated measure that uses the CURRENTGROUP DAX function."
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 48,
        "isMostVoted": true
      },
      {
        "answer": "C",
        "count": 4,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2022-10-06T15:51:00.000Z",
        "voteCount": 32,
        "content": "B is correct"
      },
      {
        "date": "2024-08-17T02:29:00.000Z",
        "voteCount": 1,
        "content": "B of course, we need RLS to meet the requirements"
      },
      {
        "date": "2024-02-28T05:21:00.000Z",
        "voteCount": 2,
        "content": "RLS (row level security) is the way to go WHEN roles are manageable (here we talk about 4 different roles --&gt; 4 departments)"
      },
      {
        "date": "2024-01-29T05:52:00.000Z",
        "voteCount": 1,
        "content": "B is Correct"
      },
      {
        "date": "2024-01-24T08:15:00.000Z",
        "voteCount": 1,
        "content": "B in pbi u do all with RLS"
      },
      {
        "date": "2023-12-21T23:03:00.000Z",
        "voteCount": 1,
        "content": "Correct.\nRLS (row level security) is the answer any time you need users to see data based on a certain value of any given dimension."
      },
      {
        "date": "2023-12-19T20:37:00.000Z",
        "voteCount": 1,
        "content": "B is the correct answer."
      },
      {
        "date": "2023-09-05T08:17:00.000Z",
        "voteCount": 4,
        "content": "B is the correct answer.\nTo ensure that users can see the data of their respective department only, we should implement low-level security (RLS). Here is how it works: \n- Create a separate RLS role for each department.\n- Define the membership of each role by specifying which DepartmentID(s) each role can access. \n- Assign users to the appropriate RLS role based on their department affiliation. \nThis way, each user will only be able to see data related to their respective department, as per the RLS rules you define."
      },
      {
        "date": "2023-05-31T23:47:00.000Z",
        "voteCount": 2,
        "content": "B is the correct option"
      },
      {
        "date": "2023-04-12T02:51:00.000Z",
        "voteCount": 3,
        "content": "B is correct, we must use row level security."
      },
      {
        "date": "2023-03-03T19:33:00.000Z",
        "voteCount": 1,
        "content": "B is correct, we must use row level security."
      },
      {
        "date": "2023-01-05T19:34:00.000Z",
        "voteCount": 2,
        "content": "B is correct"
      },
      {
        "date": "2022-12-12T00:54:00.000Z",
        "voteCount": 2,
        "content": "RLS is the right choice!"
      },
      {
        "date": "2022-11-22T05:16:00.000Z",
        "voteCount": 3,
        "content": "B is correct"
      },
      {
        "date": "2022-10-21T04:08:00.000Z",
        "voteCount": 4,
        "content": "The clue is \"There are four departments ...\"\nsee https://learn.microsoft.com/en-us/power-bi/guidance/rls-guidance \nIt says there:\nAvoid using RLS, whenever it makes sense to do so. If you have only a small number of simplistic RLS rules that apply static filters, consider publishing multiple datasets instead [...] to different workspaces [...] and use query parameters to filter source data."
      },
      {
        "date": "2023-02-02T17:50:00.000Z",
        "voteCount": 1,
        "content": "it's definitely RLS"
      },
      {
        "date": "2022-10-25T07:33:00.000Z",
        "voteCount": 1,
        "content": "To be honest, I am no longer sure. If only the department table is filtered, all facts would still contain all department data."
      },
      {
        "date": "2023-03-03T19:34:00.000Z",
        "voteCount": 3,
        "content": "cant be C because the user has to select the option on the filter. that means they can bypass the filter and view the info from other departments"
      },
      {
        "date": "2023-04-22T23:51:00.000Z",
        "voteCount": 1,
        "content": "Agree with fred92, we need to read between the lines, that's why the questions says -there are 4 departments! from documentation \"Sometimes it makes sense to avoid using RLS. If you have only a few simplistic RLS rules that apply static filters, consider publishing multiple datasets instead. For example, a company that has just two sales regions decides to publish a dataset for each sales region to different workspaces. The datasets don't enforce RLS. They do, however, use query parameters to filter source data. This way, the same model is published to each workspace\u2014they just have different dataset parameter values. advantages- improved query performance and smaller models. So C is correct."
      },
      {
        "date": "2023-08-07T03:57:00.000Z",
        "voteCount": 2,
        "content": "Parameter only makes the report viewing dynamic and not secure (A user can just type a department name he doesn't belong to and view the report). RLS secures access to only those with clearance."
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 23,
    "url": "https://www.examtopics.com/discussions/microsoft/view/83076-exam-pl-300-topic-2-question-23-discussion/",
    "body": "In Power BI Desktop, you are building a sales report that contains two tables. Both tables have row-level security (RLS) configured.<br>You need to create a relationship between the tables. The solution must ensure that bidirectional cross-filtering honors the RLS settings.<br>What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate an inactive relationship between the tables and select Apply security filter in both directions.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate an active relationship between the tables and select Apply security filter in both directions.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate an inactive relationship between the tables and select Assume referential integrity.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate an active relationship between the tables and select Assume referential integrity."
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 68,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2022-12-12T00:56:00.000Z",
        "voteCount": 26,
        "content": "No point of discussion.\nRLS works through ACTIVE links, so inactive will simply no work!"
      },
      {
        "date": "2022-09-21T06:03:00.000Z",
        "voteCount": 19,
        "content": "Answer is B"
      },
      {
        "date": "2024-08-17T02:30:00.000Z",
        "voteCount": 1,
        "content": "I totally agree with you, guys! B - Create an active relationship between the tables and select Apply security filter in both directions"
      },
      {
        "date": "2024-07-23T02:03:00.000Z",
        "voteCount": 1,
        "content": "correct answer"
      },
      {
        "date": "2024-04-07T01:07:00.000Z",
        "voteCount": 2,
        "content": "I passed the exam on 5 April 2024 (906/1000). My answer was:\nB"
      },
      {
        "date": "2024-02-21T04:35:00.000Z",
        "voteCount": 1,
        "content": "B is the answer"
      },
      {
        "date": "2023-12-21T23:05:00.000Z",
        "voteCount": 1,
        "content": "Correct answer.\nRLS only works with active relationships. So, there is no question of building inactive relationships here.\nAlso, we have the set the bi-directional filtering as expected and asked in the question."
      },
      {
        "date": "2023-12-19T20:38:00.000Z",
        "voteCount": 1,
        "content": "B is the correct answer."
      },
      {
        "date": "2023-09-05T08:20:00.000Z",
        "voteCount": 1,
        "content": "B is the correct answer. It enables the bidirectional cross-filtering and respects the RLS settings, ensuring that data in both tables is filtered based on the RLS rules applied to the user."
      },
      {
        "date": "2023-07-20T07:19:00.000Z",
        "voteCount": 11,
        "content": "I passed the exam today (948/1000). My answer was:\n- Create an active relationship between the tables and select Apply security filter in both directions"
      },
      {
        "date": "2023-04-12T02:53:00.000Z",
        "voteCount": 3,
        "content": "B Is the answer. By default RLS has single direction filter but we should create both directional filter and check mark the apply security filter in both directions"
      },
      {
        "date": "2023-01-13T21:06:00.000Z",
        "voteCount": 1,
        "content": "B Is the answer. By default RLS has single direction filter but we should create both directional filter and check mark the apply security filter in both directions"
      },
      {
        "date": "2022-12-28T14:26:00.000Z",
        "voteCount": 1,
        "content": "Answer is B"
      },
      {
        "date": "2022-10-06T15:52:00.000Z",
        "voteCount": 3,
        "content": "B is correct"
      },
      {
        "date": "2022-09-24T07:30:00.000Z",
        "voteCount": 4,
        "content": "B is correct"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 24,
    "url": "https://www.examtopics.com/discussions/microsoft/view/80809-exam-pl-300-topic-2-question-24-discussion/",
    "body": "HOTSPOT -<br>You have a column named UnitsInStock as shown in the following exhibit.<br><img src=\"/assets/media/exam-media/04331/0011000001.jpg\" class=\"in-exam-image\"><br>UnitsInStock has 75 non-null values, of which 51 are unique.<br>Use the drop-down menus to select the answer choice that completes each statement based on the information presented in the graphic.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04331/0011100001.jpg\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04331/0011100002.jpg\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: 75 rows -<br>Is nullable allows NULL values in the column.<br><br>Box 2: reduce -<br>Reference:<br>https://blog.crossjoin.co.uk/2019/01/20/is-nullable-column-property-power-bi/",
    "votes": [],
    "comments": [
      {
        "date": "2022-09-06T23:01:00.000Z",
        "voteCount": 54,
        "content": "If it's the only field in a table only unique values will be shown."
      },
      {
        "date": "2022-09-20T08:50:00.000Z",
        "voteCount": 101,
        "content": "only distinct values not unique values\nso the answer is: 75 rows / reduce"
      },
      {
        "date": "2022-09-27T04:24:00.000Z",
        "voteCount": 21,
        "content": "Exactly, only distinct values but the question says \"UnitsInStock has 75 non-null values, of which 51 are unique\", so it does not say 75 distinct values, it says 75 with non-null values, so we can have repeated values. Therefore, I would say 51 / decrease"
      },
      {
        "date": "2023-03-28T04:16:00.000Z",
        "voteCount": 3,
        "content": "Consider that, this column is in Product dimension table, so all rows are different."
      },
      {
        "date": "2023-03-28T04:18:00.000Z",
        "voteCount": 2,
        "content": "and also should consider the distribution of values in the column is not important, just the number of rows are important, since we have 75 non-null values, then we will have 75 rows."
      },
      {
        "date": "2022-12-19T12:31:00.000Z",
        "voteCount": 11,
        "content": "No, it cannot display only the unique. You know what that means? It means if you have a number that is distinct but not unique for example, 5,5,5, then it will not capture it because it is not unique. The answer is 75. \n\nUnique means it occurs only once in the column which cannot make up the table rows only. I have actually tried this on PBI with some datatset to confirm.\n\nFor the second question, when you summarise, it will reduce the table.\nfor example, all products with the same productname will return one row if you drag the productname and unitInstock to the table visual."
      },
      {
        "date": "2022-12-28T02:18:00.000Z",
        "voteCount": 5,
        "content": "In that case, if you have 5,5,5, the five will only show once, meaning it will show 51 rows, not 75"
      },
      {
        "date": "2022-12-28T13:51:00.000Z",
        "voteCount": 17,
        "content": "Example: 1,2,3,4,4 contains 5 non-nullable, 4 distinct, 3 unique values. When not summarized and placed in a table, there are 4 rows. The answer to this question should be between 51-75, not one or the other."
      },
      {
        "date": "2023-03-28T04:20:00.000Z",
        "voteCount": 4,
        "content": "Name of products should be unique. but number of Unitsinstock column does not need to be unique. And since this column is in the Product dimension table, the product names are unique and there are 75 product."
      },
      {
        "date": "2023-07-02T18:23:00.000Z",
        "voteCount": 7,
        "content": "Correct Answer - Don't Summarize = 75 and After Summarize = 1"
      },
      {
        "date": "2024-07-16T02:18:00.000Z",
        "voteCount": 1,
        "content": "If you have tried in PBI, only put that Unitsinstock column in the table, you will know it should be 51."
      },
      {
        "date": "2023-08-04T04:55:00.000Z",
        "voteCount": 20,
        "content": "Only distinct values will be shown. Unique isnt't the same that distinct"
      },
      {
        "date": "2023-07-11T23:11:00.000Z",
        "voteCount": 19,
        "content": "The answer is correct. 75 rows / reduce. Tested and agreed."
      },
      {
        "date": "2023-07-23T14:01:00.000Z",
        "voteCount": 7,
        "content": "It's 51. Table doesn't show duplicated values when there's only one field added.\nIt will show 75 if you set \"Summerize by: Count\" but Summerize is set to None in the screenshot."
      },
      {
        "date": "2023-07-23T14:10:00.000Z",
        "voteCount": 2,
        "content": "Nvm, I forgot that unique in Power BI removes the value from Unique count if the value repeats itself"
      },
      {
        "date": "2022-09-11T06:05:00.000Z",
        "voteCount": 27,
        "content": "1 - 1 ROW\n2 - increase"
      },
      {
        "date": "2022-09-14T01:11:00.000Z",
        "voteCount": 25,
        "content": "The summarization is set to 'Don't summarize' so you will have 1 row per value, not 1 row total. If you add a summarization it will decrease the number of rows."
      },
      {
        "date": "2022-09-14T08:53:00.000Z",
        "voteCount": 4,
        "content": "I agree"
      },
      {
        "date": "2022-09-18T21:52:00.000Z",
        "voteCount": 10,
        "content": "SO the Answer is- 1. 75Rows, 2. Reduce, right?"
      },
      {
        "date": "2024-01-03T09:08:00.000Z",
        "voteCount": 2,
        "content": "Nice explanation, ThariCD"
      },
      {
        "date": "2023-07-11T11:00:00.000Z",
        "voteCount": 1,
        "content": "Yes, I created a toy excel sheet and tested it. You are correct! The first time we created a table visual, there is only 1 row in the visual and the summarization is set to \"SUM\". After we changed the summarization to \"Dont summarize\", the row increased from 1 row to 51 rows."
      },
      {
        "date": "2023-07-11T11:05:00.000Z",
        "voteCount": 7,
        "content": "Sorry for the confusion, I think my answer was wrong. I noticed in the question image the summarization is set to \"None\", so when you first create the visual, there should be 51 rows. Later change the summarization will change 51 rows to 1 row, so \"Reduce\""
      },
      {
        "date": "2024-03-12T05:33:00.000Z",
        "voteCount": 1,
        "content": "This is correct. I tried and tested."
      },
      {
        "date": "2022-09-18T03:34:00.000Z",
        "voteCount": 35,
        "content": "SO it's\n51 \nReduce"
      },
      {
        "date": "2022-09-19T04:52:00.000Z",
        "voteCount": 20,
        "content": "Answer is correct (51 and Reduce). tested"
      },
      {
        "date": "2022-12-28T13:57:00.000Z",
        "voteCount": 15,
        "content": "You did not test. If there are more non-nullable than unique, there will always be more rows than unique. Example: 1,2,3,4,4 has 3 unique, 5 non-nullable, 4 distinct. Placed in a table shows the rows: 1,2,3,4"
      },
      {
        "date": "2023-04-11T09:33:00.000Z",
        "voteCount": 7,
        "content": "It will be \n1- 75 Rows \n2. Reduce (Summarize By - Sum; it will return only 1 row in table visual)\nI have tested.."
      },
      {
        "date": "2024-07-16T02:21:00.000Z",
        "voteCount": 1,
        "content": "Test. It should be 51.\nAnd please note that the Unitsinstock column here is not a number, it is text. There is no Sigma sign in front. So there is no SUM summary."
      },
      {
        "date": "2023-07-11T11:05:00.000Z",
        "voteCount": 2,
        "content": "Agreed"
      },
      {
        "date": "2024-09-25T20:37:00.000Z",
        "voteCount": 1,
        "content": "The data type is whole number therefore when you add only that field to the table, default summarization will occur - hence only 1 row showing total of all those UnitsInStock\n\nChanging the summarization setting is ambiguous since it can be changed to Average, Min, Max etc. I would guess you should say increase though"
      },
      {
        "date": "2024-09-03T07:53:00.000Z",
        "voteCount": 1,
        "content": "Correct"
      },
      {
        "date": "2024-08-17T02:36:00.000Z",
        "voteCount": 1,
        "content": "So, by default the table contains all the values for a specific field (75 in this case) when we select to don't summarize, then it will be reduced to the number of distinct values (51 in the example). So the given answer is correct"
      },
      {
        "date": "2024-08-15T14:31:00.000Z",
        "voteCount": 2,
        "content": "We assume that our column contains 75 non-null values \u200b\u200bof which 51 are unique, so we have 63 distinct values \u200b\u200bthat will be visualized in the table, so I don't understand why your answers are 75 rows while in powerbi we don't see repeated values \u200b\u200bin a table."
      },
      {
        "date": "2024-07-23T02:06:00.000Z",
        "voteCount": 1,
        "content": "correct answer"
      },
      {
        "date": "2024-07-18T18:20:00.000Z",
        "voteCount": 1,
        "content": "The answer is correct. 75 rows / reduce. When added to a table it will show all the non-null values (75). When summarizing by each of those values, then it will only show each discrete value 1 time to show it's frequency of appearance (51 unique characters). 51 &lt; 75 = reduce. Tested and agreed."
      },
      {
        "date": "2024-07-16T11:08:00.000Z",
        "voteCount": 1,
        "content": "Summarize is set to: None, therefore all values will be shown."
      },
      {
        "date": "2024-05-27T22:48:00.000Z",
        "voteCount": 1,
        "content": "The question was not well structured, obviously distinct values will be more than 51 (the unique values) since we have 75 non-null values. I happen when you try to theorize practical things."
      },
      {
        "date": "2024-05-20T20:08:00.000Z",
        "voteCount": 1,
        "content": "The first question is very tricky.\n\nAssuming that the field accept null values and the question says \"UnitsInStock has 75 non-null values, of which 51 are unique\" should we assume that there is no null value therefor the answer is 75?  But what if there is a null value then the answer is 76 that is one (1) null value plus seventy-five (75) non-null values.\n\nI tested this with a smaller set of data 14 Distinct (including 1 null value) and 10 unique.  With no summarization, my table visual returned 14 rows (representing the distinct value that includes the null value).\nWith summarization, my table visual returned 1 row.\n\nBecause of that, I will just assume that there are no null values and select 75 for the first question and Decrease to the second question."
      },
      {
        "date": "2024-05-02T08:40:00.000Z",
        "voteCount": 2,
        "content": "For the Guys and Girls,\n\nAt this page, you will no longer find any free questions from Examtopics. However, if you're hesitant about purchasing Contributor Access, don't hesitate any longer; buy it. It costs only $50 and provides a significant boost to your CV and career. I recently passed with a score of 917 out of 1000. Save yourself time by learning and memorizing all these questions, as 85% of the 50 exam questions were identical to those provided here.\n\nCheers and good luck!"
      },
      {
        "date": "2024-04-09T22:42:00.000Z",
        "voteCount": 1,
        "content": "The fact that the values are unique or not is not necessary here. If you are visualising the data for a month and plotting a table with unitstocks for each day, thinking that a record or a row will be removed just because two days in a month had same unitstocks is incorrect. Unless you are summarising(aggregating) records will not be removed on grounds that they do not have a unique value.\nanswer would be 75, reduced."
      },
      {
        "date": "2024-04-04T12:52:00.000Z",
        "voteCount": 2,
        "content": "So how should we answer in the exam if we face like this question where no answer is correct."
      },
      {
        "date": "2024-04-04T12:34:00.000Z",
        "voteCount": 1,
        "content": "This question makes no sense:\nit will be 51 values appearing in the visual table for the unique values PLUS the number of distinct values (it could be 1 value or more... so at least we will get 52 values)\nWe have non-null values but if we have null values they will be added also because we are using YES for \"is-nullable\", \nso i think the question is not well formed.\n(try a column from 1 to 51(distinct values) and continue till 75 as u wish and then create a visualization table) and obviously when summarized the rows will be reduced to one."
      },
      {
        "date": "2024-03-18T02:22:00.000Z",
        "voteCount": 1,
        "content": "Tried in power bi. when created a table visual with UnitsInStock column(only this column, without ProductID  column etc / also without summarization)\nThe number of rows equal the number of distinct values.\nSince we don't have distinct value here, the answer of first box really depends on how we define [unique]....if unique here = distinct, then 51. if there is ProductID in the table visual then 75."
      },
      {
        "date": "2024-03-04T15:03:00.000Z",
        "voteCount": 1,
        "content": "Domanda nell'esame di oggi"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 25,
    "url": "https://www.examtopics.com/discussions/microsoft/view/80017-exam-pl-300-topic-2-question-25-discussion/",
    "body": "HOTSPOT -<br>You have a Power BI report.<br>You have the following tables.<br><img src=\"/assets/media/exam-media/04331/0011200001.png\" class=\"in-exam-image\"><br>You have the following DAX measure.<br>Accounts :=<br>CALCULATE (<br>DISTINCTCOUNT (Balances[AccountID]),<br>LASTDATE ('Date'[Date])<br>For each of the following statements, select Yes if the statement is true. Otherwise, select No.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04331/0011300001.jpg\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04331/0011300002.jpg\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: No -<br>It will show the total number of accounts that were live at the last day of the year only.<br>Note:<br>DISTINCTCOUNT counts the number of distinct values in a column.<br>LASTDATE returns the last date in the current context for the specified column of dates.<br><br>Box 2: No -<br>It will show the total number of accounts that were live at the last day of the month only.<br><br>Box 3: Yes -<br>Reference:<br>https://docs.microsoft.com/en-us/dax/distinctcount-function-dax https://docs.microsoft.com/en-us/dax/lastdate-function-dax",
    "votes": [],
    "comments": [
      {
        "date": "2022-10-22T00:54:00.000Z",
        "voteCount": 51,
        "content": "NO\nNO\nYES"
      },
      {
        "date": "2023-12-13T10:54:00.000Z",
        "voteCount": 1,
        "content": "I'm wondering if the last one is NO.  A question for someone to clarify for me... Wouldn't DISTINCTCOUNT (Balances[AccountID]) be a distinct count of the BALANCES ?  So if two accounts have the same balance, wouldn't it only count one time ?  Thus giving an incorrect count of the active accounts ?"
      },
      {
        "date": "2023-12-14T08:55:00.000Z",
        "voteCount": 5,
        "content": "I just realized that Balances is the table name, not a column.  Ignore me !"
      },
      {
        "date": "2022-10-28T21:30:00.000Z",
        "voteCount": 18,
        "content": "The date is hierarchy, the lastdate() is based on the hierarchy, which means the measure should be adjusted with the year/month/day level. Thus N-N-Y is correct."
      },
      {
        "date": "2024-08-17T02:39:00.000Z",
        "voteCount": 1,
        "content": "correct No, No, Yes"
      },
      {
        "date": "2024-07-23T02:09:00.000Z",
        "voteCount": 1,
        "content": "correct answer"
      },
      {
        "date": "2024-05-02T08:40:00.000Z",
        "voteCount": 2,
        "content": "For the Guys and Girls,\n\nAt this page, you will no longer find any free questions from Examtopics. However, if you're hesitant about purchasing Contributor Access, don't hesitate any longer; buy it. It costs only $50 and provides a significant boost to your CV and career. I recently passed with a score of 917 out of 1000. Save yourself time by learning and memorizing all these questions, as 85% of the 50 exam questions were identical to those provided here.\n\nCheers and good luck!"
      },
      {
        "date": "2023-06-01T01:06:00.000Z",
        "voteCount": 4,
        "content": "NO\nNO\nYES"
      },
      {
        "date": "2023-04-29T20:28:00.000Z",
        "voteCount": 1,
        "content": "shouldn't the last one be no too? the question says if it would calculate for the day, but doesn't it only calculate for the last day of the month? eg for the month of Jan, would only show Jan30; February would only show Feb28?"
      },
      {
        "date": "2023-05-03T14:18:00.000Z",
        "voteCount": 5,
        "content": "No, LASTDATE will return the last date from the current context. If the context is the Year, the last date will be 31/12/year. If the context is the Day, LASTDATE will return the day itself\n\nhttps://learn.microsoft.com/en-us/dax/lastdate-function-dax"
      },
      {
        "date": "2023-04-27T00:59:00.000Z",
        "voteCount": 3,
        "content": "NO\nNO\nYES"
      },
      {
        "date": "2023-01-13T21:14:00.000Z",
        "voteCount": 8,
        "content": "No No Yes... Last Date calculates the last day only"
      },
      {
        "date": "2022-11-22T12:35:00.000Z",
        "voteCount": 2,
        "content": "correct"
      },
      {
        "date": "2022-10-26T09:02:00.000Z",
        "voteCount": 3,
        "content": "As I was no sure , I did a test here, and Yes, the answer is correct..."
      },
      {
        "date": "2022-10-20T00:37:00.000Z",
        "voteCount": 2,
        "content": "Shouldn't this be YYY? Lastdate \"returns the last date in the current context for the specified column of dates\".  Therefore, it will be give you the last day of the year or month depending on the context.  If you then do a distinctcount on the accountid, this means that account had a closing balance on that day."
      },
      {
        "date": "2022-11-05T04:13:00.000Z",
        "voteCount": 22,
        "content": "It is NO NO YES and here's why. Just as you mentioned, Lastdate \"returns the last date in the current context for the specified column of dates\" which means it will ONLY RETURN the live account balances for the LAST DAY of the YEAR for year and MONTH for month and not THROUGHOUT THE YEAR &amp; THROUGHOUT THE MONTH as those options stated. Read those options again and the answers will come to you."
      },
      {
        "date": "2024-03-26T19:44:00.000Z",
        "voteCount": 2,
        "content": "Correct. Understood now! Cheers Shakes103"
      },
      {
        "date": "2022-10-06T16:20:00.000Z",
        "voteCount": 6,
        "content": "No\nNo\nYes"
      },
      {
        "date": "2022-09-13T13:20:00.000Z",
        "voteCount": 5,
        "content": "correct"
      },
      {
        "date": "2022-09-04T03:06:00.000Z",
        "voteCount": 5,
        "content": "It should  be   No - No - Yes"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 26,
    "url": "https://www.examtopics.com/discussions/microsoft/view/83060-exam-pl-300-topic-2-question-26-discussion/",
    "body": "You have the tables shown in the following table.<br><img src=\"/assets/media/exam-media/04331/0011400001.png\" class=\"in-exam-image\"><br>The Impressions table contains approximately 30 million records per month.<br>You need to create an ad analytics system to meet the following requirements:<br>\u2711 Present ad impression counts for the day, campaign, and site_name. The analytics for the last year are required.<br>Minimize the data model size.<br><img src=\"/assets/media/exam-media/04331/0011400003.png\" class=\"in-exam-image\"><br>Which two actions should you perform? Each correct answer presents part of the solution.<br>NOTE: Each correct selection is worth one point.<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate one-to-many relationships between the tables.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tGroup the Impressions query in Power Query by Ad_id, Site_name, and Impression_date. Aggregate by using the CountRows function.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a calculated table that contains Ad_id, Site_name, and Impression_date.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a calculated measure that aggregates by using the COUNTROWS function."
    ],
    "answer": "AB",
    "answerDescription": "",
    "votes": [
      {
        "answer": "AB",
        "count": 34,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2022-09-21T04:30:00.000Z",
        "voteCount": 24,
        "content": "I agree."
      },
      {
        "date": "2023-04-12T03:32:00.000Z",
        "voteCount": 16,
        "content": "AB is the correct answer. Grouping in power query reduces the number of rows in the impression table that is gonna be loaded in the model. Creating relationships doesn't increase the size of the model. Therefore, the answer AB is correct!"
      },
      {
        "date": "2024-08-17T02:41:00.000Z",
        "voteCount": 1,
        "content": "AB is the correct one"
      },
      {
        "date": "2024-07-23T02:13:00.000Z",
        "voteCount": 1,
        "content": "correct answer"
      },
      {
        "date": "2024-05-02T08:39:00.000Z",
        "voteCount": 3,
        "content": "For the Guys and Girls,\n\nAt this page, you will no longer find any free questions from Examtopics. However, if you're hesitant about purchasing Contributor Access, don't hesitate any longer; buy it. It costs only $50 and provides a significant boost to your CV and career. I recently passed with a score of 917 out of 1000. Save yourself time by learning and memorizing all these questions, as 85% of the 50 exam questions were identical to those provided here.\n\nCheers and good luck!"
      },
      {
        "date": "2024-04-08T23:13:00.000Z",
        "voteCount": 2,
        "content": "Neither option a or d reduce model size but option a at least allows for proper data structure for accurate analysis -&gt; option A the better of the two\noption C increases model size so hard no\noption b reduces model size , yay\ntherefore answer is A and B"
      },
      {
        "date": "2023-12-19T20:55:00.000Z",
        "voteCount": 5,
        "content": "Creating one-to-many relationships = optimizing the model. =&gt; A is correct.\nGroup the Impressions query in Power Query = pre-summarizing the data which results in a smaller and more efficient data model =&gt; B is correct."
      },
      {
        "date": "2023-11-23T11:00:00.000Z",
        "voteCount": 3,
        "content": "I feel like A and D should be the right answers given the fact that option B does not group by Campaign which is wrong. Any thoughts on this?"
      },
      {
        "date": "2024-02-21T08:15:00.000Z",
        "voteCount": 1,
        "content": "...i also believe that D does not reduce the model size as stated in the requirements. you are keeping the same number of Impressions rows and just adding a DAX measure."
      },
      {
        "date": "2024-02-21T08:11:00.000Z",
        "voteCount": 2,
        "content": "A and B are correct, i believe. B is grouping the Impressions table, it does not have Campaign ID column. That column is in the Ads table, which remains unmodified in solution B."
      },
      {
        "date": "2023-10-09T06:53:00.000Z",
        "voteCount": 4,
        "content": "Guys, I feel like B and C are wrong. They didn't do anything with the campaign but we need to analyze the campaigns. Since D also work, I believe the answer should be \nA &amp; D"
      },
      {
        "date": "2023-10-04T07:38:00.000Z",
        "voteCount": 5,
        "content": "This was in the exam this week."
      },
      {
        "date": "2023-09-05T13:04:00.000Z",
        "voteCount": 1,
        "content": "B and C are the correct answers. \nB. This step will help us aggregate the impression data at the desired level of granularity (day, campaign, and site_name) in Power Query itself, reducing the amount of data loaded into the data model. \nC. By creating a calculated table that contains only the necessary columns (Ad_id, Site_name,and impression_date), we further minimize the data model size."
      },
      {
        "date": "2023-10-02T06:19:00.000Z",
        "voteCount": 6,
        "content": "creating a calculated table will increase the data model size"
      },
      {
        "date": "2023-08-27T18:10:00.000Z",
        "voteCount": 3,
        "content": "I would say AD is correct. \nLet us ignore the day and site_name and focus on the Ad vs Campaign.\nThe reason is campaign to Ad is one to many relation thus one campaign can include some Ads. Assume campaignA(Campaign_ID=1) includes Ad1(Ad_id =1)&amp;Ad2(Ad_id =2),\nRowsOfAD1             =  Countrows(FILTER(Impressions, [Ad_id]=1)) \nRowsOfCampaign1 =  Countrows(FILTER(Impressions, AND([Ad_id]=1,[Ad_id]=2)))\nThey are different."
      },
      {
        "date": "2023-06-01T01:17:00.000Z",
        "voteCount": 6,
        "content": "A and B for optimisation purpose. even if A and D is working"
      },
      {
        "date": "2023-05-02T02:20:00.000Z",
        "voteCount": 2,
        "content": "Given answer is correct."
      },
      {
        "date": "2023-01-15T05:41:00.000Z",
        "voteCount": 4,
        "content": "AB is correct"
      },
      {
        "date": "2023-01-13T21:24:00.000Z",
        "voteCount": 1,
        "content": "It should be A &amp; D we can created aggregation with COUNTROWS DAX and group by Campaign Name, Date &amp; Site name . B is using wrong columns for calculations"
      },
      {
        "date": "2023-01-13T21:33:00.000Z",
        "voteCount": 7,
        "content": "Sorry I am Wring it is A &amp; B"
      },
      {
        "date": "2022-12-27T19:45:00.000Z",
        "voteCount": 4,
        "content": "A is correct. I have a doubt about B. Aren't we suppose to group by campaign too? Grouping by AddID, we might have several campaigns against an add. Pls correct me if I am wrong"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 27,
    "url": "https://www.examtopics.com/discussions/microsoft/view/84214-exam-pl-300-topic-2-question-27-discussion/",
    "body": "HOTSPOT -<br>You are creating a Microsoft Power BI data model that has the tables shown in the following table.<br><img src=\"/assets/media/exam-media/04331/0011600001.png\" class=\"in-exam-image\"><br>The Products table is related to the ProductCategory table through the ProductCategoryID column. Each product has one product category.<br>You need to ensure that you can analyze sales by product category.<br>How should you configure the relationship from ProductCategory to Products? To answer, select the appropriate options in the answer area.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04331/0011700001.jpg\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04331/0011800001.jpg\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: One-to-many -<br>The one-to-many and many-to-one cardinality options are essentially the same, and they're also the most common cardinality types.<br>Incorrect: A many-to-many relationship means both columns can contain duplicate values. This cardinality type is infrequently used. It's typically useful when designing complex model requirements. You can use it to relate many-to-many facts or to relate higher grain facts. For example, when sales target facts are stored at product category level and the product dimension table is stored at product level.<br><br>Box 2: Single -<br>Incorrect:<br>Bear in mind that bi-directional relationships can impact negatively on performance. Further, attempting to configure a bi-directional relationship could result in ambiguous filter propagation paths. In this case, Power BI Desktop may fail to commit the relationship change and will alert you with an error message.<br>Reference:<br>https://docs.microsoft.com/en-us/power-bi/transform-model/desktop-relationships-understand",
    "votes": [],
    "comments": [
      {
        "date": "2022-10-12T06:21:00.000Z",
        "voteCount": 100,
        "content": "Silly comments here. One-to-many because several products have the same product category. Single because the performance is much better and the assignment states only that you need to be able to analyze sales by product category."
      },
      {
        "date": "2022-10-28T16:34:00.000Z",
        "voteCount": 23,
        "content": "Your answer is correct. however, we don't choose single, b/c it has better performance. b/c data flows from product to ProductCategory. This is the reason, we choose single."
      },
      {
        "date": "2022-12-13T05:32:00.000Z",
        "voteCount": 7,
        "content": "you are both right"
      },
      {
        "date": "2023-07-06T00:08:00.000Z",
        "voteCount": 1,
        "content": "How did we figure out that the data flows from Product to Product Category and not the other way around??"
      },
      {
        "date": "2023-07-06T00:15:00.000Z",
        "voteCount": 11,
        "content": "Nevermind, here's the answer: \"For one-to-many relationships, the cross filter direction is always from the \"one\" side, and optionally from the \"many\" side (bi-directional). \" \nhttps://learn.microsoft.com/en-us/power-bi/transform-model/desktop-relationships-understand"
      },
      {
        "date": "2024-10-14T10:18:00.000Z",
        "voteCount": 1,
        "content": "one \"to\" many"
      },
      {
        "date": "2023-07-10T08:23:00.000Z",
        "voteCount": 7,
        "content": "This is the wrong explanation about \"Single\".\nWhen we choose one-to-many of \"ProuctCat to Product\", the default direction of single is from ProuctCat-&gt;Product. \nHowever, \"analyzing sales by product category\" means, information from sales-&gt;Product-&gt;ProductCat. This is the opposite direction of our single direction.\nTherefore, it should be Both. \nKeep in mind, the single direction is determined by your one-to-many design."
      },
      {
        "date": "2023-09-11T06:12:00.000Z",
        "voteCount": 5,
        "content": "But the direction is about the way the filter works. Since analysing sales by ProductCategory means you filter from ProductCategory (via Product) to Sales, the direction is one way from ProductCategory to Sales."
      },
      {
        "date": "2023-07-20T22:04:00.000Z",
        "voteCount": 4,
        "content": "Guys take note. This is tested and confirmed. At first, I wanted to abuse you but then something told me to first put it into practice. And yes. It is one to many and Both. Thank you for standing out"
      },
      {
        "date": "2022-11-12T19:29:00.000Z",
        "voteCount": 28,
        "content": "1 - One to many because every product category has many products\n2 - Both because we need to analyze sales by product category"
      },
      {
        "date": "2022-11-18T16:42:00.000Z",
        "voteCount": 26,
        "content": "you want to analyse SALE BY PRODUCT CATEGORY, you need cross filter direction single to make this work. If you do both that means you want to analyze PRODUCT CATEGORY by SALE. This doesn't make sense so there is no need for both. You're going downstream from product category to sales not the other way around. \n\nThis is what I think but I'd be thankful if someone can help me if I am wrong."
      },
      {
        "date": "2022-11-23T14:19:00.000Z",
        "voteCount": 2,
        "content": "I totally agree what you said that \"If you do both that means you want to analyze PRODUCT CATEGORY by SALE.\", otherwise single can do the trick. I was confused when to use BOTH earlier."
      },
      {
        "date": "2023-10-20T04:52:00.000Z",
        "voteCount": 1,
        "content": "For example, if we want to see the sales by product(Coffee, Tea, Milk) in each region(US, UK, IN). Say we dont want show the product names in the visuals if there no sales for that product in a specific region. So we use bidirectional so that the region and product tables are filtered for only sold products.. where it will not return blank if there's no sale for product tea in US .. it shows sales values for Coffee and Milk only"
      },
      {
        "date": "2022-11-18T09:26:00.000Z",
        "voteCount": 5,
        "content": "Yu always filter from the one side, which in this case, is the productCategory. So one to many - single means filtering from one to the many side, which is correct. So it should be single. Hope this helps."
      },
      {
        "date": "2024-08-17T02:48:00.000Z",
        "voteCount": 2,
        "content": "This is a classical single one-to-many relationship. The given answer is correct"
      },
      {
        "date": "2024-07-14T03:01:00.000Z",
        "voteCount": 1,
        "content": "One-to-many because several products have the same product category.\nBoth, because the filter goes via Products and One-to-many is from product to category."
      },
      {
        "date": "2024-06-28T00:36:00.000Z",
        "voteCount": 1,
        "content": "The answer is correct, one to many, that is from ProductCategory to Products, and direction is Single"
      },
      {
        "date": "2024-05-24T03:19:00.000Z",
        "voteCount": 2,
        "content": "Each product has one product category.\nisn't one-to-one ? They didn't say, every Product has \"atleast\" one product category\n\nconfigure the relationship from ProductCategory to Products?\nOne - Product Category side\nMany on Product side\n? right"
      },
      {
        "date": "2024-05-30T13:36:00.000Z",
        "voteCount": 1,
        "content": "No, this means one category has many products so it one (category) to many (products)"
      },
      {
        "date": "2024-05-02T08:39:00.000Z",
        "voteCount": 1,
        "content": "For the Guys and Girls,\n\nAt this page, you will no longer find any free questions from Examtopics. However, if you're hesitant about purchasing Contributor Access, don't hesitate any longer; buy it. It costs only $50 and provides a significant boost to your CV and career. I recently passed with a score of 917 out of 1000. Save yourself time by learning and memorizing all these questions, as 85% of the 50 exam questions were identical to those provided here.\n\nCheers and good luck!"
      },
      {
        "date": "2023-09-05T13:19:00.000Z",
        "voteCount": 2,
        "content": "One-to-many\nSingel\nOne-to-many: Each product category can have multiple products belonging to it.\nSingle: Because we want to analyze sales by product category."
      },
      {
        "date": "2023-07-20T22:19:00.000Z",
        "voteCount": 1,
        "content": "After further analysis. I think there are two answers available to this\n\nAnswer set A: One to many and Single\n\nAnwer SET B: One to one and both"
      },
      {
        "date": "2023-07-20T22:24:00.000Z",
        "voteCount": 1,
        "content": "But thinking deeper, What is the, The product table and Product category table must be having a one to one cardinality otherwise this would mean that the Products table and sales table will be having a many to many relationship considering that they are related via the product ID. \n\nThus to me the final answer should be One to one and then both directions"
      },
      {
        "date": "2023-06-16T23:24:00.000Z",
        "voteCount": 2,
        "content": "It asks relationship from product category to product not vice versa. Filter will take place at many * direction. So keeping it one to many means product category to product one to many , which is wrong. As there is not an option of many to one then many to many is the best choice here. And for many to many we always need filter in both directions. So the answer is many to many and both."
      },
      {
        "date": "2023-06-06T20:31:00.000Z",
        "voteCount": 2,
        "content": "question is asking ProductCategory to Product Relation..\nFor sure it will be one to many.. if it was product to productcategory, then it would be one to one\nand cross filter : single for performance.."
      },
      {
        "date": "2023-05-02T04:58:00.000Z",
        "voteCount": 2,
        "content": "one-to-many\nsingle"
      },
      {
        "date": "2023-04-24T23:34:00.000Z",
        "voteCount": 5,
        "content": "1. One to many, because one Product Category can have many Products.\n2.Single. It allows to calculate Sales by Product Category. Also the best practice as per this article \nhttps://learn.microsoft.com/en-us/power-bi/transform-model/desktop-relationships-understand\nAlso I tested in Power BI. If you have doubts, recreate the issue in Power BI and you will get the correct answer."
      },
      {
        "date": "2023-04-12T03:39:00.000Z",
        "voteCount": 1,
        "content": "1 - One to Many\n2- Single direction"
      },
      {
        "date": "2023-03-12T20:15:00.000Z",
        "voteCount": 2,
        "content": "1 - One to Many \n2- Single dirction"
      },
      {
        "date": "2022-12-27T19:50:00.000Z",
        "voteCount": 2,
        "content": "We cant make a 1 to 1 cardinality relationship single directional I guess"
      },
      {
        "date": "2022-12-06T06:46:00.000Z",
        "voteCount": 4,
        "content": "One-to-many, both"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 28,
    "url": "https://www.examtopics.com/discussions/microsoft/view/79836-exam-pl-300-topic-2-question-28-discussion/",
    "body": "You import a Power BI dataset that contains the following tables:<br>\u2711 Date<br>\u2711 Product<br>\u2711 Product Inventory<br>The Product Inventory table contains 25 million rows. A sample of the data is shown in the following table.<br><img src=\"/assets/media/exam-media/04331/0011900004.png\" class=\"in-exam-image\"><br>The Product Inventory table relates to the Date table by using the DateKey column. The Product Inventory table relates to the Product table by using the<br>ProductKey column.<br>You need to reduce the size of the data model without losing information.<br>What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tChange Summarization for DateKey to Don't Summarize.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRemove the relationship between Date and Product Inventory",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tChange the data type of UnitCost to Integer.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRemove MovementDate.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 136,
        "isMostVoted": true
      },
      {
        "answer": "A",
        "count": 16,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2022-09-06T01:21:00.000Z",
        "voteCount": 55,
        "content": "D is right"
      },
      {
        "date": "2022-09-06T13:15:00.000Z",
        "voteCount": 23,
        "content": "looks like a typo - D is good as explained below"
      },
      {
        "date": "2024-10-12T02:48:00.000Z",
        "voteCount": 1,
        "content": "This requires you to notice that MovementDate and DateKey have the same date.  I agree that it doesnt tell you they are ALWAYS the same though."
      },
      {
        "date": "2024-09-01T09:28:00.000Z",
        "voteCount": 3,
        "content": "If D is correct - how can we guarrantee that 'Movementdate' always has the same info as DateKey? i.e. having 5 identical rows does not tell us all rows are the same..."
      },
      {
        "date": "2024-08-17T02:52:00.000Z",
        "voteCount": 1,
        "content": "We can remove the movementdate 'cause the same information in kept in the datekey column"
      },
      {
        "date": "2024-07-24T09:19:00.000Z",
        "voteCount": 1,
        "content": "D is right one"
      },
      {
        "date": "2024-07-23T02:17:00.000Z",
        "voteCount": 1,
        "content": "correct answer"
      },
      {
        "date": "2024-06-24T00:34:00.000Z",
        "voteCount": 1,
        "content": "D is correct. We can remove it since it does not provide new information. We can have these information from DateKey column."
      },
      {
        "date": "2024-05-02T08:39:00.000Z",
        "voteCount": 1,
        "content": "For the Guys and Girls,\n\nAt this page, you will no longer find any free questions from Examtopics. However, if you're hesitant about purchasing Contributor Access, don't hesitate any longer; buy it. It costs only $50 and provides a significant boost to your CV and career. I recently passed with a score of 917 out of 1000. Save yourself time by learning and memorizing all these questions, as 85% of the 50 exam questions were identical to those provided here.\n\nCheers and good luck!"
      },
      {
        "date": "2024-06-06T10:25:00.000Z",
        "voteCount": 1,
        "content": "Hey , out of 52 pages , how many pages you referred? Going through 52 pages is not feasible"
      },
      {
        "date": "2024-04-23T07:17:00.000Z",
        "voteCount": 1,
        "content": "D is correct."
      },
      {
        "date": "2024-04-16T10:05:00.000Z",
        "voteCount": 1,
        "content": "Yeah. There's a typo indeed. As per the explanation the response should be D."
      },
      {
        "date": "2024-03-18T09:59:00.000Z",
        "voteCount": 1,
        "content": "D is correct"
      },
      {
        "date": "2024-03-11T06:29:00.000Z",
        "voteCount": 1,
        "content": "You can also remove rows where nothing went in or out"
      },
      {
        "date": "2024-03-08T09:28:00.000Z",
        "voteCount": 2,
        "content": "As per the given explanation option D is crearly the answer. We are achieving required functionality without losing information as both the rows contain same information"
      },
      {
        "date": "2024-02-28T00:54:00.000Z",
        "voteCount": 1,
        "content": "Dates can be removed from fact tables in a data warehouse or analytical database if you replace them with date keys that are linked to a separate date dimension table. Thus, answer D is correct."
      },
      {
        "date": "2024-02-20T06:10:00.000Z",
        "voteCount": 1,
        "content": "wrong typing \nCorrect Answer: A \ud83d\uddf3\ufe0f\n\nas explanation clearly states case D :\n\"The DateKey and MovementDate columns have the same information. Movementdate can be removed.\""
      },
      {
        "date": "2024-02-18T09:31:00.000Z",
        "voteCount": 2,
        "content": "The view solutions pane says correct answer is A, but the explanation given clearly explain why D is the correct answer.\n???"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 29,
    "url": "https://www.examtopics.com/discussions/microsoft/view/79840-exam-pl-300-topic-2-question-29-discussion/",
    "body": "HOTSPOT -<br>You are enhancing a Power BI model that has DAX calculations.<br>You need to create a measure that returns the year-to-date total sales from the same date of the previous calendar year.<br>Which DAX functions should you use? To answer, select the appropriate options in the answer area.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04331/0012100001.jpg\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04331/0012200001.jpg\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: CALCULATE -<br>Example:<br>Total sales on the last selected date =<br>CALCULATE (<br>SUM ( Sales[Sales Amount] ),<br>'Sales'[OrderDateKey] = MAX ( 'Sales'[OrderDateKey] )<br>)<br><br>Box 2: SUM -<br><br>Box 3: SAMEPERIODLASTYEAR -<br>SAMEPERIODLASTYEAR returns a set of dates in the current selection from the previous year.<br>Example:<br>--  SAMEPERIODLASTYEAR returns the selected period shifted back one year.<br><br>EVALUATE -<br>VAR StartDate = DATE ( 2008, 07, 25 )<br>VAR EndDate =   DATE ( 2008, 07, 31 )<br><br>RETURN -<br>CALCULATETABLE (<br>SAMEPERIODLASTYEAR ( 'Date'[Date] ),<br>'Date'[Date] &gt;= StartDate &amp;&amp;<br>'Date'[Date] &lt;= EndDate<br>)<br>ORDER BY [Date]<br>Reference:<br>https://docs.microsoft.com/en-us/dax/calculate-function-dax<br>https://dax.guide/sameperiodlastyear/",
    "votes": [],
    "comments": [
      {
        "date": "2022-09-03T09:20:00.000Z",
        "voteCount": 188,
        "content": "Calculate\nSum \nDatesBetween"
      },
      {
        "date": "2022-09-07T12:00:00.000Z",
        "voteCount": 62,
        "content": "Calculate\nSum\nDatesBetween \n\nSuggested SamePeriodLastYear expects only 1 parameter: column containing dates"
      },
      {
        "date": "2022-09-23T08:44:00.000Z",
        "voteCount": 6,
        "content": "Good explanation"
      },
      {
        "date": "2024-08-17T02:59:00.000Z",
        "voteCount": 1,
        "content": "You can use SAMEPERIODLASTYEAR but in this case 3 arguments are required so we need to use DatesBetween because there are three arguments. \nSo I would say: CALCULATE, SUM, DATESBETWEEN"
      },
      {
        "date": "2023-11-05T14:13:00.000Z",
        "voteCount": 10,
        "content": "Calculate\nSum\nDatesBetween\n\n\n-- \nI always look for the number of arguments necessary:\nDATESBETWEEN(&lt;Dates&gt;, &lt;StartDate&gt;, &lt;EndDate&gt;)\nSAMEPERIODLASTYEAR(&lt;dates&gt;)"
      },
      {
        "date": "2023-09-11T06:20:00.000Z",
        "voteCount": 5,
        "content": "CALCULATE, SUM and DATESBETWEEN. DATESBETWEEN because the variables that are declared already contain the dates of last year."
      },
      {
        "date": "2023-09-05T13:57:00.000Z",
        "voteCount": 3,
        "content": "Calculate\nSum\nDatesbetween"
      },
      {
        "date": "2023-07-08T22:21:00.000Z",
        "voteCount": 12,
        "content": "Who decides on website's final answer? We need to understand his/her level of confidence. Maybe he got the answers from Microsoft."
      },
      {
        "date": "2023-06-22T01:34:00.000Z",
        "voteCount": 1,
        "content": "The location of the formula text in between the images is a bit poorly chosen. It makes it seem like the order is: Option box 1 &gt; ( Sales [sales] ), Option box 2. Even though that wouldn't obviously be possible"
      },
      {
        "date": "2023-06-01T01:49:00.000Z",
        "voteCount": 1,
        "content": "hmm thanks for the explanation. Calculate, sum, datesBetween"
      },
      {
        "date": "2023-05-16T11:52:00.000Z",
        "voteCount": 1,
        "content": "Calculate\nSum\nDatesBetween"
      },
      {
        "date": "2023-04-12T03:42:00.000Z",
        "voteCount": 14,
        "content": "Correct Answer :\nCalculate, Sum, and DateBetween\n\nThe DATESBETWEEN function is used to filter a table or a column of dates to a specified date range. It takes two arguments: the first argument is the date column to filter, and the second and third arguments are the start and end dates of the desired date range, respectively. The function returns a table of dates that fall within the specified range.\n\nOn the other hand, the SAMEPERIODLASTYEAR function is used to retrieve the same period (week, month, quarter, or year) as the one currently selected, but from the previous year. It takes one argument, which is the date column to use as a reference, and returns a table of dates from the previous year that match the current period. This function is often used to compare data across time periods, such as comparing sales in the current year to sales in the same period of the previous year."
      },
      {
        "date": "2023-04-04T03:31:00.000Z",
        "voteCount": 5,
        "content": "Correct Answer :\nCalculate, Sum, and DateBetween\n\nThe DATESBETWEEN function is used to filter a table or a column of dates to a specified date range. It takes two arguments: the first argument is the date column to filter, and the second and third arguments are the start and end dates of the desired date range, respectively. The function returns a table of dates that fall within the specified range.\n\nOn the other hand, the SAMEPERIODLASTYEAR function is used to retrieve the same period (week, month, quarter, or year) as the one currently selected, but from the previous year. It takes one argument, which is the date column to use as a reference, and returns a table of dates from the previous year that match the current period. This function is often used to compare data across time periods, such as comparing sales in the current year to sales in the same period of the previous year.\n\n\nNo confusion, and no need to further discussion"
      },
      {
        "date": "2023-03-16T23:55:00.000Z",
        "voteCount": 1,
        "content": "Answer is correct \nCalculate\nSum\nSameperiodlstyear\n\nno confusion"
      },
      {
        "date": "2023-04-22T07:32:00.000Z",
        "voteCount": 4,
        "content": "The start and end dates has already been calculated in the parameters so DATESBETWEEN is the answer. Using SAMEPERIODLASTYEAR would go an extra year back."
      },
      {
        "date": "2023-03-15T02:06:00.000Z",
        "voteCount": 7,
        "content": "Calculate\nSum\nDatesBetween\n\n* Sales Last Year = CALCULATE(SUM(Sales[Amount]), SAMEPERIODLASTYEAR(Date[Date]))\n* Total Sales Q1 = CALCULATE(SUM(Sales[Amount]), DATESBETWEEN(Sales[Date], DATE(2022,1,1), DATE(2022,3,31)))\n\n* DatesBetween expects 3 parameters as per the exhibit, SamePeriodLastYear expects one parameter"
      },
      {
        "date": "2023-03-12T20:24:00.000Z",
        "voteCount": 1,
        "content": "Calculate \nSum\nDatesBetween"
      },
      {
        "date": "2023-02-23T09:58:00.000Z",
        "voteCount": 1,
        "content": "Calculate\nSum\nDatesBetween"
      },
      {
        "date": "2023-02-20T00:35:00.000Z",
        "voteCount": 1,
        "content": "We're asked to create a measure that returns the year-to-date total sales from the same date of the previous calendar year so why are we not making use of SAMEPERIODLASTYEAR()?"
      },
      {
        "date": "2023-02-22T18:59:00.000Z",
        "voteCount": 2,
        "content": "That\u2019s because the already created variables generates start date and end date of last year hence no need to compute the dates again using SAMEPERIODLASTYEAR(). Also last expression has 3 parameters so DATESBETWEEN would work."
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 30,
    "url": "https://www.examtopics.com/discussions/microsoft/view/84355-exam-pl-300-topic-2-question-30-discussion/",
    "body": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.<br>After you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.<br>You are modeling data by using Microsoft Power BI. Part of the data model is a large Microsoft SQL Server table named Order that has more than 100 million records.<br>During the development process, you need to import a sample of the data from the Order table.<br>Solution: You add a report-level filter that filters based on the order date.<br>Does this meet the goal?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tYes",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tNo\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 39,
        "isMostVoted": true
      },
      {
        "answer": "A",
        "count": 2,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2022-10-04T07:49:00.000Z",
        "voteCount": 34,
        "content": "It says \"you want to import sample data\".  If you are filter at a chart level, you have already imported the data, so the answer is no"
      },
      {
        "date": "2024-08-17T03:04:00.000Z",
        "voteCount": 1,
        "content": "Similar to a previous question, the answer is NO because we need to filter using a WHERE statement rather than a report filter"
      },
      {
        "date": "2023-09-05T14:03:00.000Z",
        "voteCount": 4,
        "content": "B is the correct answer. \nAdding a report-level filter based on the order date doesn't meet the goal of importing a sample of the data from the Order table. A report-level filter affects the data that is displayed within the report but doesn't change the data imported into the data model. To import sample of the data, we need to apply a filter during the data loading process, such as using Power Query Editor or SQL query options, to select a subset of the records from the Order table before importing it into the data model."
      },
      {
        "date": "2023-06-01T01:51:00.000Z",
        "voteCount": 1,
        "content": "No.filter befor import data.SQL statements"
      },
      {
        "date": "2023-05-02T05:04:00.000Z",
        "voteCount": 2,
        "content": "We need to filter before importing data. not in report level!"
      },
      {
        "date": "2023-04-12T03:43:00.000Z",
        "voteCount": 2,
        "content": "It says \"you want to import sample data\". If you are filter at a chart level, you have already imported the data, so the answer is no"
      },
      {
        "date": "2022-11-10T06:50:00.000Z",
        "voteCount": 2,
        "content": "You can limit the imported data to a sample size by using WHERE"
      },
      {
        "date": "2022-10-06T17:54:00.000Z",
        "voteCount": 1,
        "content": "It could be Yes. Filtering on a date range would provide sample data. It also would use query folding so it wouldnt import the entire table rows"
      },
      {
        "date": "2022-11-10T05:37:00.000Z",
        "voteCount": 5,
        "content": "There can't be any query folding at report-level. Query folding happens only in the Power Query engine"
      },
      {
        "date": "2022-11-28T19:14:00.000Z",
        "voteCount": 2,
        "content": "Well explained, I stand corrected, thank you"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 31,
    "url": "https://www.examtopics.com/discussions/microsoft/view/82538-exam-pl-300-topic-2-question-31-discussion/",
    "body": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.<br>After you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.<br>You have a Power BI report that imports a date table and a sales table from an Azure SQL database data source. The sales table has the following date foreign keys:<br>\u2711 Due Date<br>\u2711 Order Date<br>\u2711 Delivery Date<br>You need to support the analysis of sales over time based on all the date foreign keys.<br>Solution: For each date foreign key, you add inactive relationships between the sales table and the date table.<br>Does this meet the goal?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tYes",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tNo\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 45,
        "isMostVoted": true
      },
      {
        "answer": "A",
        "count": 9,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2022-09-17T08:40:00.000Z",
        "voteCount": 53,
        "content": "Should be Yes. You later use a USERELATIONSHIP() to calculate different measures"
      },
      {
        "date": "2022-11-05T07:27:00.000Z",
        "voteCount": 16,
        "content": "Lifted from documentation: \"By default, active relationships propagate filters to other tables. Inactive relationship, however, only propagate filters when a DAX expression activates (uses) the relationship\". Going by this, NO is the answer."
      },
      {
        "date": "2023-03-28T08:26:00.000Z",
        "voteCount": 1,
        "content": "Hey guys, what is the correct answer? we cannot use all relationships in one single measure, but we can use them in different measures."
      },
      {
        "date": "2023-04-25T07:34:00.000Z",
        "voteCount": 1,
        "content": "You can, however, not make multiple active relationships to the same table, in this case date. Or you would need to make three date tables, producing confusing results."
      },
      {
        "date": "2022-10-16T09:52:00.000Z",
        "voteCount": 77,
        "content": "I believe the correct answer is NO. I think you are jumping the gun. Yes, you can use USERELATIONSHIP() later and yes you will need to add inactive relationships in order to make use of USERELATIONSHIP() ....BUT.... Right now! Does the solution offered in the question, at this point in time, provide the SOLUTION???? NO!!! it doesn't because the solution offered as it stands is incomplete."
      },
      {
        "date": "2022-12-14T09:59:00.000Z",
        "voteCount": 2,
        "content": "But the same thing applies to all three possible solutions. Relationships will need to be added unless they are auto-detected. So it comes down to interpretation of the question, but my read is that \"solution\" here can mean a partial solution. But not sure."
      },
      {
        "date": "2022-12-29T10:44:00.000Z",
        "voteCount": 2,
        "content": "I AGREE WITH NEVILLEV"
      },
      {
        "date": "2023-01-17T06:38:00.000Z",
        "voteCount": 16,
        "content": "Should be no. It says \"support\" not \"a complete solution\". The reason is it needs at least one active relationship, instead of 3 inactive ones."
      },
      {
        "date": "2024-03-26T21:13:00.000Z",
        "voteCount": 1,
        "content": "That's the point!  we need at least one \"active relationship\". Cheers Hansen"
      },
      {
        "date": "2022-12-29T06:59:00.000Z",
        "voteCount": 17,
        "content": "The Answer is NO.\nWe need at least one active relationship between sales and date table."
      },
      {
        "date": "2024-08-17T03:06:00.000Z",
        "voteCount": 1,
        "content": "No, the inactive relationships doesn't work in the model"
      },
      {
        "date": "2024-05-17T01:16:00.000Z",
        "voteCount": 1,
        "content": "My question is why should we create a relationship in the first place, if in our sales table we have the sales and the dates, and we want to perform an analysis of sales overtime - why not doing the analysis directly ? \nand regarding the relationships, not all relationships should be inactive - one of them should be active"
      },
      {
        "date": "2024-05-10T14:16:00.000Z",
        "voteCount": 2,
        "content": "According to git hub copilot \nA. Yes\n\nExplanation:\n\nIn Power BI, you can create multiple relationships between tables, but only one of those relationships can be active. The active relationship is used automatically in calculations and in visuals. However, you can use inactive relationships by invoking them in DAX formulas using the `USERELATIONSHIP` function.\n\nIn this scenario, creating inactive relationships for each date foreign key (Due Date, Order Date, Delivery Date) between the sales table and the date table would allow you to analyze sales over time based on all the date foreign keys. You would just need to use the `USERELATIONSHIP` function in your DAX calculations to specify which relationship to use."
      },
      {
        "date": "2024-03-18T11:31:00.000Z",
        "voteCount": 1,
        "content": "Create 3 Dates dims by adding 2 calc tables based on the existing Dates table"
      },
      {
        "date": "2023-12-19T00:13:00.000Z",
        "voteCount": 1,
        "content": "According to chatgpt is Yes ?? whyy"
      },
      {
        "date": "2023-10-12T11:51:00.000Z",
        "voteCount": 1,
        "content": "No, Even though we can do achieve it. But I feel its about standard approach in data Model. In this case one active and 2 inactive relationship."
      },
      {
        "date": "2023-10-04T07:38:00.000Z",
        "voteCount": 2,
        "content": "This was in the exam this week."
      },
      {
        "date": "2023-09-05T14:08:00.000Z",
        "voteCount": 4,
        "content": "B is the correct answer.\nNo, the solution doesn't meet the goal of supporting the analysis of sales over time based on all the date foreign keys. Adding inactive relationships between the sales table and the date table means that those relationships won't be used by default in calculations and visuals. Inactive relationships are typically used for specific scenarios where you want to enable users to switch between different date dimensions interactively."
      },
      {
        "date": "2023-08-02T03:02:00.000Z",
        "voteCount": 6,
        "content": "Answer is no. USERRELATIONSHIP only enables one relationship at a time. If you have to have all relationship enable at the same time, you would create a date table for each column. This is known as role-playing dimension modelling"
      },
      {
        "date": "2023-07-30T06:20:00.000Z",
        "voteCount": 2,
        "content": "Inactive relationships in Power BI allow you to create multiple relationships between two tables without causing conflicts in your data model. By default, Power BI allows only one active relationship between two tables, but you can add additional relationships as inactive. This feature is helpful when you have multiple date foreign keys in the sales table, as is the case in your scenario (Due Date, Order Date, and Delivery Date)."
      },
      {
        "date": "2024-04-16T02:42:00.000Z",
        "voteCount": 1,
        "content": "Good explanation. Cheers"
      },
      {
        "date": "2023-07-23T15:12:00.000Z",
        "voteCount": 5,
        "content": "Similar example was in Microsoft's Learning Path and the solution was to create additional date tables."
      },
      {
        "date": "2023-08-23T00:38:00.000Z",
        "voteCount": 1,
        "content": "This works for sure. But it would be good to know if using only one table in combination with inactive raltionships works as well"
      },
      {
        "date": "2023-07-20T07:21:00.000Z",
        "voteCount": 11,
        "content": "I passed the exam today (948/1000). My answer was:\n- No"
      },
      {
        "date": "2023-07-14T13:07:00.000Z",
        "voteCount": 1,
        "content": "AFAIK, the only major use for inactive relationships (in general) is for when you plan on using DAX. DAX is not used here, so answer is B."
      },
      {
        "date": "2023-07-09T08:56:00.000Z",
        "voteCount": 1,
        "content": "I say No, but not because of the same reason other comments mentioned. It's NO because I think they are after Role Play model, where you can use all 3 date columns at the same time."
      },
      {
        "date": "2023-06-22T23:45:00.000Z",
        "voteCount": 1,
        "content": "Answer should be NO"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 32,
    "url": "https://www.examtopics.com/discussions/microsoft/view/82470-exam-pl-300-topic-2-question-32-discussion/",
    "body": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.<br>After you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.<br>You have a Power BI report that imports a date table and a sales table from an Azure SQL database data source. The sales table has the following date foreign keys:<br>\u2711 Due Date<br>\u2711 Order Date<br>\u2711 Delivery Date<br>You need to support the analysis of sales over time based on all the date foreign keys.<br>Solution: From Power Query Editor, you rename the date query as Due Date. You reference the Due Date query twice to make the queries for Order Date and<br>Delivery Date.<br>Does this meet the goal?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tYes\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tNo"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 71,
        "isMostVoted": true
      },
      {
        "answer": "B",
        "count": 42,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2023-04-27T12:56:00.000Z",
        "voteCount": 122,
        "content": "I dont understand What micorsoft hopes to achieve with trick questions. If questions leave so much to the analysts assumptions then the questions isnt testing the candidates knowledge"
      },
      {
        "date": "2023-05-19T08:47:00.000Z",
        "voteCount": 8,
        "content": "I keep reading \"trick\" questions when reading peoples' experiences recently of PL-300."
      },
      {
        "date": "2024-01-19T08:29:00.000Z",
        "voteCount": 3,
        "content": "100% agree. There is so much ambiguity in the questions, and can easily be interpreted ways."
      },
      {
        "date": "2022-09-16T19:54:00.000Z",
        "voteCount": 23,
        "content": "The answer is correct. However, I believe the alternate solution given is wrong. I would say that 3 relationships for each date respectively would be made from the Date table to the Sales table. One being active and the other two inactive. Thus, allowing to filter by a specific date column\n\nThe solution suggested is not required, as the report does not require any output that involves all 3 dates. It requires only sales over one date column at a time. Moreover, being date tables, they can significantly increase the size of the model (considering that the table is sales related)."
      },
      {
        "date": "2024-10-09T17:14:00.000Z",
        "voteCount": 1,
        "content": "A. Yes.\nYou can only have 1 active relationship at a time.\nUserelationship places processing on the report layer via dax.\nUse powerquery to add the dimension date tables.\nDo your regular Dax calculations after."
      },
      {
        "date": "2024-08-17T03:08:00.000Z",
        "voteCount": 1,
        "content": "I would say No"
      },
      {
        "date": "2024-07-16T01:26:00.000Z",
        "voteCount": 1,
        "content": "I think B. Nothing said about USERELATIONSHIP. Without mentioning it I think the answer is NO."
      },
      {
        "date": "2024-06-16T02:39:00.000Z",
        "voteCount": 1,
        "content": "I think it's B because Due Date come after Order Date so if we reference with the Due Date, you may not have all date for Order Date. That's my point of view."
      },
      {
        "date": "2024-05-10T21:41:00.000Z",
        "voteCount": 1,
        "content": "It gives you three separate date tables but without having to import the date data 3 times."
      },
      {
        "date": "2024-03-08T09:56:00.000Z",
        "voteCount": 2,
        "content": "Please suggest if my thought process is not aligned with the question's constraints.\n\nAs it is said in the proposed solution cant we reference the initial date table 2 more times to obtain other date tables ?? (By renaming the tables and deleting other two  irrelevant columns)"
      },
      {
        "date": "2023-12-19T21:23:00.000Z",
        "voteCount": 3,
        "content": "A is correct. \n\nChatGPT's response: Creating separate queries in Power Query for each date (Due Date, Order Date, and Delivery Date) by referencing a base date query is a recommended way to deal with role-playing dimensions. This method involves creating separate date tables for each date role you need to analyze. In Power BI, each of these tables will be related to the sales table using the respective date foreign key.\n\nThis approach allows for creating active relationships between the sales table and each of the date tables, which enables the use of these dates in filters, slicers, and visuals without the need for DAX measures to handle inactive relationships. It is a common and efficient way to support analysis by different date roles within the same model."
      },
      {
        "date": "2023-11-14T20:58:00.000Z",
        "voteCount": 2,
        "content": "wouldnt it be that since they are imported datasets it would be more productive to use DAX to transform the data?"
      },
      {
        "date": "2023-10-11T08:51:00.000Z",
        "voteCount": 2,
        "content": "I'll select B."
      },
      {
        "date": "2023-09-05T14:13:00.000Z",
        "voteCount": 7,
        "content": "B is the correct answer. \nNo, this solution does not meet the goal of supporting the analysis of sales over time based on all the date foreign keys. Renaming the date query as \"Due Date\" and referencing it twice in Power Query Editor does not create relationships between the sales table and the date table based on the difference date foreign keys (Due Date, Order Date, and Delivery Date)."
      },
      {
        "date": "2023-08-30T14:05:00.000Z",
        "voteCount": 4,
        "content": "A. This was in the learning path."
      },
      {
        "date": "2024-03-14T01:53:00.000Z",
        "voteCount": 10,
        "content": "link, or gtfo"
      },
      {
        "date": "2023-08-12T23:04:00.000Z",
        "voteCount": 3,
        "content": "The key to answering this question correct, is this sentence \"You need to support the analysis of sales over time based on all the date foreign keys.\" \n\nYou cannot achieve this without 3 date tables, which is created in Power Query. 1 is loaded from Azure, the other two are created by reference to the first.\n\nIf you have one date table with 1 active and 2 inactive relationships, then you won't be able to use all 3 dates in the same analysis."
      },
      {
        "date": "2023-08-02T07:33:00.000Z",
        "voteCount": 3,
        "content": "I am going with B and here is why.\nIt says they renamed it. Then they said they used it for 2 of the dates, not all 3. So technically there isn't 3 queries being run just 2...\n\nThoughts?"
      },
      {
        "date": "2023-11-22T07:05:00.000Z",
        "voteCount": 6,
        "content": "I gues whwn you reference twice, it means you are adding two aditional copies, hence you have 3 tables.\n\nBut as the question does not talk about relationship, that is the source of ambiguity."
      },
      {
        "date": "2023-07-24T11:35:00.000Z",
        "voteCount": 1,
        "content": "In such a scenario, I wonder if it makes sense to import a time dimension at all. Better to create three dimensions based on calculated tables like here."
      },
      {
        "date": "2023-07-31T01:36:00.000Z",
        "voteCount": 2,
        "content": "In the documentation, It is advised that. You always use the provided date table if available. Only in situations where they dont exist should you create a calculated date table."
      },
      {
        "date": "2023-07-23T15:30:00.000Z",
        "voteCount": 7,
        "content": "A. Again, this was in the learning path, duplicate date tables with DAX or PowerQuery."
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 33,
    "url": "https://www.examtopics.com/discussions/microsoft/view/86134-exam-pl-300-topic-2-question-33-discussion/",
    "body": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.<br>After you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.<br>You have a Power BI report that imports a date table and a sales table from an Azure SQL database data source. The sales table has the following date foreign keys:<br>\u2711 Due Date<br>\u2711 Order Date<br>\u2711 Delivery Date<br>You need to support the analysis of sales over time based on all the date foreign keys.<br>Solution: From the Fields pane, you rename the date table as Due Date. You use a DAX expression to create Order Date and Delivery Date as calculated tables.<br>Does this meet the goal?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tYes\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tNo"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 42,
        "isMostVoted": true
      },
      {
        "answer": "B",
        "count": 6,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2022-10-21T07:15:00.000Z",
        "voteCount": 25,
        "content": "Yes, that will meet the goal. It will increase the model size, but that was not the question."
      },
      {
        "date": "2022-11-08T02:53:00.000Z",
        "voteCount": 2,
        "content": "I agree with you. \nThe model size is not mentioned in the question, so it would meet the goal."
      },
      {
        "date": "2022-11-01T23:33:00.000Z",
        "voteCount": 15,
        "content": "NO is the Answer. To be able to create the calculations you need the Relationships. They are NOT stated in this suggestion."
      },
      {
        "date": "2022-11-10T12:35:00.000Z",
        "voteCount": 4,
        "content": "These type of questions are not really clear. But agreed, you clearly need relationships. What if you have \"autodetect relationship\" option active?"
      },
      {
        "date": "2023-12-27T07:03:00.000Z",
        "voteCount": 2,
        "content": "foreign keys imply having relationships in place, therefore it is absurd to assume otherwise."
      },
      {
        "date": "2024-08-17T03:10:00.000Z",
        "voteCount": 1,
        "content": "Yes, this will meet the goal"
      },
      {
        "date": "2024-07-16T01:23:00.000Z",
        "voteCount": 1,
        "content": "The question is if we do it in PowerQuery Editor. It's not said. In PowerQuery we can create a copy of table by DAX usage and it will work. \"Create a copy of the role-playing table, providing it with a name that reflects its role. If it's an Import table, we recommend defining a calculated table. If it's a DirectQuery table, you can duplicate the Power Query query.\" Departure Airport = 'Arrival Airport'. \"Create an active relationship to relate the new table.\""
      },
      {
        "date": "2024-02-08T08:13:00.000Z",
        "voteCount": 3,
        "content": "Think the answer should be A, but you need the relationships. Not sure why this question is more one sided than the one above though."
      },
      {
        "date": "2024-01-15T21:37:00.000Z",
        "voteCount": 1,
        "content": "A. Yes (is correct) it's not the best method but it works"
      },
      {
        "date": "2023-11-10T01:42:00.000Z",
        "voteCount": 2,
        "content": "Creating a calculated table does not keep the original table relationship. This solution is even worse than the one using Power Query to duplicate the 3 date tables. If the auto-detect relationship is enabled, at least using Power Query might not require a relationship."
      },
      {
        "date": "2023-10-12T11:54:00.000Z",
        "voteCount": 1,
        "content": "No, again its about how will you design the data model. Even if you can create multiple date table for each date field. Standard approach in this case should be one date table, 1 active and 2 inactive relationships."
      },
      {
        "date": "2023-10-11T08:53:00.000Z",
        "voteCount": 1,
        "content": "No, the correct answer is B."
      },
      {
        "date": "2023-10-11T06:07:00.000Z",
        "voteCount": 2,
        "content": "after you read this https://learn.microsoft.com/en-us/power-bi/guidance/relationships-active-inactive the answer should be clear"
      },
      {
        "date": "2023-09-05T14:22:00.000Z",
        "voteCount": 3,
        "content": "B is the correct answer.\nNo, this solution does not meet the goal of supporting the analysis of sales over time based on all the date foreign keys. Remaining the date table as \"Due Date\" and creating calculated tables for Order Date and Delivery Date using DAX expressions does not establish relationships between the sales table and the date table based on the different date foreign keys (Due Date, Order Date, and Delivery Date)."
      },
      {
        "date": "2023-08-09T13:47:00.000Z",
        "voteCount": 2,
        "content": "Noone of those who say Yes did not mention about creation relationship in the model. And this is a key element in data analysis. So, the answer is No."
      },
      {
        "date": "2023-06-06T21:01:00.000Z",
        "voteCount": 1,
        "content": "No, the reference link given in the answer shows that it needs inactive relationship"
      },
      {
        "date": "2023-05-23T22:18:00.000Z",
        "voteCount": 4,
        "content": "Answer is No.\n Renaming the date table as \"Due Date\" and creating calculated tables for \"Order Date\" and \"Delivery Date\" will not provide the necessary functionality for analyzing sales over time. To achieve the goal, you would typically create relationships between the date table and the sales table based on the respective date foreign keys. This allows Power BI to perform time-based analysis by using the relationships to filter and aggregate data.\n\nInstead of renaming the date table, you should keep it as a separate table, typically named \"Date\" or \"Calendar.\" Then, you would establish relationships between the date table and the sales table using the respective date foreign keys: Due Date, Order Date, and Delivery Date."
      },
      {
        "date": "2023-05-09T04:42:00.000Z",
        "voteCount": 2,
        "content": "No, for so many reasons already mentioned by others in this thread. Here is one other reason; only 2 out of 3 tables are mentioned as calculated tables. What happened to 3rd calcluated table? It is missing so it does not meet the goal."
      },
      {
        "date": "2023-07-23T15:41:00.000Z",
        "voteCount": 2,
        "content": "Third table already exists and is called \"Due Date\", you use it to create the other two."
      },
      {
        "date": "2023-04-25T22:09:00.000Z",
        "voteCount": 1,
        "content": "I would say NO, since the solution does not specify creating the relationships. Auto detection feature does not guarantee the correct relationships creation."
      },
      {
        "date": "2023-04-25T07:48:00.000Z",
        "voteCount": 4,
        "content": "No. We're dealing with role-playing dimensions, and creating additional tables will produce confusing results. Guy in a Cube explained this well in his video. We need ONE date table with inactive relationships.\nSource: https://www.youtube.com/watch?v=2BxaUXlx3K4\nSource: https://learn.microsoft.com/en-us/power-bi/guidance/star-schema"
      },
      {
        "date": "2023-07-23T15:47:00.000Z",
        "voteCount": 1,
        "content": "No, we need additional tables\nhttps://learn.microsoft.com/en-us/training/modules/dax-power-bi-add-calculated-tables/1-introduction"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 34,
    "url": "https://www.examtopics.com/discussions/microsoft/view/80525-exam-pl-300-topic-2-question-34-discussion/",
    "body": "DRAG DROP -<br>You receive revenue data that must be included in Microsoft Power BI reports.<br>You preview the data from a Microsoft Excel source in Power Query as shown in the following exhibit.<br><img src=\"/assets/media/exam-media/04331/0012700001.jpg\" class=\"in-exam-image\"><br>You plan to create several visuals from the data, including a visual that shows revenue split by year and product.<br>You need to transform the data to ensure that you can build the visuals. The solution must ensure that the columns are named appropriately for the data that they contain.<br>Which three actions should you perform in sequence? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.<br>Select and Place:<br><img src=\"/assets/media/exam-media/04331/0012800001.jpg\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/pl-300/image371.png\">",
    "answerDescription": "<img src=\"https://img.examtopics.com/pl-300/image372.png\">",
    "votes": [],
    "comments": [
      {
        "date": "2022-09-06T00:53:00.000Z",
        "voteCount": 255,
        "content": "here is the sequence : 2-3-4"
      },
      {
        "date": "2023-02-28T15:18:00.000Z",
        "voteCount": 6,
        "content": "I believe this is better than pivoting first too."
      },
      {
        "date": "2022-09-12T02:15:00.000Z",
        "voteCount": 8,
        "content": "this is correct"
      },
      {
        "date": "2022-09-15T03:11:00.000Z",
        "voteCount": 178,
        "content": "Select Use First Row as Headers\nSelect Department and Product and Unpivot Other Column\nRename the Attribute column to YEAR and the Value column to REVENUE"
      },
      {
        "date": "2024-06-04T00:03:00.000Z",
        "voteCount": 1,
        "content": "This is correct steps"
      },
      {
        "date": "2024-05-17T02:58:00.000Z",
        "voteCount": 1,
        "content": "agree, that's correct"
      },
      {
        "date": "2023-05-22T11:32:00.000Z",
        "voteCount": 2,
        "content": "Correct!"
      },
      {
        "date": "2024-08-23T06:07:00.000Z",
        "voteCount": 1,
        "content": "The answer is wrong, have you tried your sequence? did you get a correct result? it has to be 2,3,4"
      },
      {
        "date": "2024-08-18T09:05:00.000Z",
        "voteCount": 2,
        "content": "1 - Select Use First Row as Headers\n2 - Select Depertment and Product and Unpivot Other Columns\n3 - Rename the Attribute column to Year and the Value column to Revenue"
      },
      {
        "date": "2024-08-18T03:40:00.000Z",
        "voteCount": 1,
        "content": "la secuencia es 2-3-4"
      },
      {
        "date": "2024-04-17T18:55:00.000Z",
        "voteCount": 7,
        "content": "My question, where did they even get the answers they are showing from?? I can't believe I paid for this thing!!"
      },
      {
        "date": "2024-02-28T07:46:00.000Z",
        "voteCount": 3,
        "content": "Using Power Query : If you follow the sequence of the answer you will have in Attribute column (column3) the following textual values:\ncolumn3\ncolumn4\ncolumn5\ncolumn6\n...\n\nIf you First row as headers first, you will have in Attribute column (column3) the following textual values:\n2016\n2017\n2018\n2019\n...\n\nwhich is what we want right ? the right sequence is : 2-3-4"
      },
      {
        "date": "2024-09-09T18:08:00.000Z",
        "voteCount": 1,
        "content": "Yes, I tried and got the same!"
      },
      {
        "date": "2024-02-17T06:32:00.000Z",
        "voteCount": 1,
        "content": "It should be 3,4,2"
      },
      {
        "date": "2024-08-23T06:14:00.000Z",
        "voteCount": 1,
        "content": "don't guess your answer, tried it then you will see"
      },
      {
        "date": "2024-03-07T06:22:00.000Z",
        "voteCount": 2,
        "content": "No it is 2,3,4"
      },
      {
        "date": "2024-02-05T20:51:00.000Z",
        "voteCount": 1,
        "content": "Refer Q19"
      },
      {
        "date": "2024-01-17T10:36:00.000Z",
        "voteCount": 5,
        "content": "who the F give such stupid answer actually?\nshould be B&gt;C&gt;D!"
      },
      {
        "date": "2023-11-26T22:05:00.000Z",
        "voteCount": 6,
        "content": "Have to do First Rows as Headers first - you can't select the Department and Product columns if there aren't any columns with those names."
      },
      {
        "date": "2024-01-19T08:34:00.000Z",
        "voteCount": 1,
        "content": "very good reason as to why you cannot unpivot first"
      },
      {
        "date": "2023-11-26T19:43:00.000Z",
        "voteCount": 1,
        "content": "People are suggesting Use first row as headers. Wouldn't that make 2016 a  header and then you would have numerous headers (one for each year) ?"
      },
      {
        "date": "2023-11-05T14:23:00.000Z",
        "voteCount": 5,
        "content": "Use first rows as headers\nSelect Department and Product and unpivot the other columns\nRename the attribute to year and Value to Revenue.\n\nI have tested it."
      },
      {
        "date": "2023-11-04T22:55:00.000Z",
        "voteCount": 3,
        "content": "I tried with sample data the correct answer is.  2-3-4"
      },
      {
        "date": "2023-10-07T22:46:00.000Z",
        "voteCount": 4,
        "content": "Tried in Power Query - correct sequence is 2-3-4"
      },
      {
        "date": "2023-09-21T19:35:00.000Z",
        "voteCount": 1,
        "content": "This one took me a minute to understand. I wanted it to be 3-2-4, but it's 2-3-4. You have to use the first row as headers FIRST so that you have a department and product column to unpivot from."
      },
      {
        "date": "2023-09-05T14:32:00.000Z",
        "voteCount": 3,
        "content": "To transform the data appropriately for creating visuals that show revenue split by year and product, we should perform the following actions in sequence.\nAction 3: Select Department and Product and unpivot other columns.\nAction 2: Select Use First Row as Headers.\nAction 4: Rename the attribute column to year and the value column to revenue."
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 35,
    "url": "https://www.examtopics.com/discussions/microsoft/view/82541-exam-pl-300-topic-2-question-35-discussion/",
    "body": "HOTSPOT -<br>You have a Power BI report named Orders that supports the following analysis:<br>\u2711 Total sales over time<br>\u2711 The count of orders over time<br>\u2711 New and repeat customer counts<br>The data model size is nearing the limit for a dataset in shared capacity.<br>The model view for the dataset is shown in the following exhibit.<br><img src=\"/assets/media/exam-media/04331/0013000001.jpg\" class=\"in-exam-image\"><br>The data view for the Orders table is shown in the following exhibit.<br><img src=\"/assets/media/exam-media/04331/0013000002.png\" class=\"in-exam-image\"><br>The Orders table relates to the Customers table by using the CustomerID column.<br>The Orders table relates to the Date table by using the OrderDate column.<br>For each of the following statements, select Yes if the statement is true, Otherwise, select No.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04331/0013100001.jpg\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04331/0013100002.jpg\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: No -<br>Would not support total sales over time.<br><br>Box 2: No -<br>Would not support new and repeat customer counts<br>Box 3: Yes",
    "votes": [],
    "comments": [
      {
        "date": "2022-09-22T01:21:00.000Z",
        "voteCount": 148,
        "content": "My answer is\nNO\nNO\nYES\nSummarizing Orders by CustomerID, OrderId and OrderDate means to group by CustomerID, OrderId and OrderDate and to aggregate the rest of the fields, however the OrderId has unique values so the aggregation will have the same number of rows as the original table"
      },
      {
        "date": "2024-07-16T11:14:00.000Z",
        "voteCount": 1,
        "content": "Unique would be orderline, but since and order can have multiple products..."
      },
      {
        "date": "2024-05-07T06:34:00.000Z",
        "voteCount": 1,
        "content": "Each order may contains number of different products, that mean the orderid will be repeated more than one time in the Order table. The answer should be Yes, No, Yes."
      },
      {
        "date": "2022-10-11T17:52:00.000Z",
        "voteCount": 8,
        "content": "Yes No Yes\nRemoving unnecessary columns already help reduce the model size. We don't know for sure if other order ids have more than one product.."
      },
      {
        "date": "2023-01-12T20:01:00.000Z",
        "voteCount": 2,
        "content": "how do we know OrderID is unique just from the sample data?"
      },
      {
        "date": "2023-03-21T06:49:00.000Z",
        "voteCount": 4,
        "content": "You assume it is because the showed like so. For other columns, you see they included repetitive values to showcase they are not unique"
      },
      {
        "date": "2022-11-26T15:57:00.000Z",
        "voteCount": 17,
        "content": "Box1: Yes\nThe summarizing data will remove Product information which is not required for this analysis. We should not infer from the sample data that OrderId is the primary key for few reasons. 1) the Order table is a common table that is used by Microsoft in learning materials, and the table usually has a surrogate key as the primary key. 2) Order ID can be printed on the invoice, and it is not a surrogate key. BTW, the Customer ID is not a surrogate key as well. 3) An order usually consists of multiple products. 4) The Product Id is unique in the sample data as well, and we won't infer that we must create an order for a separate product.\n\nBox 2: No\nCustomer ID is required for new and returned customer analysis\n\nBox3: Yes\nProduct information is not required for analysis.\n\nNote: if the first analysis requirement changes from \"Total sales over time\" to \"Total sales over time for products\", we will have a different question to deal with"
      },
      {
        "date": "2022-11-26T16:27:00.000Z",
        "voteCount": 1,
        "content": "Please also refer to Question 38 in Topic 2 on how a more completed Sales Order table would look like. In that question the OrderID is called SalesOrderNumber and the surrogate key is the ID column. Please note that those two columns are separated"
      },
      {
        "date": "2024-08-18T09:10:00.000Z",
        "voteCount": 2,
        "content": "In my opinion it is YES, NO, YES"
      },
      {
        "date": "2024-08-20T07:39:00.000Z",
        "voteCount": 1,
        "content": "I changed my mind. It should be No, No, Yes. The first is No because it Would not support total sales over time.\nThe answer is correct"
      },
      {
        "date": "2024-07-14T10:06:00.000Z",
        "voteCount": 1,
        "content": "Yes: Since you don't know the order ID is unique or not but it also contains products so probably not otherwise would have been orderline ID.\n\nYES: You can count the new customers based on this table so no need for a relationship with the customer, there is no extra information visible within the customer table.\n\nYES: Don't need the columns"
      },
      {
        "date": "2024-05-07T06:34:00.000Z",
        "voteCount": 1,
        "content": "Yes\nNo\nYes"
      },
      {
        "date": "2024-03-26T22:27:00.000Z",
        "voteCount": 7,
        "content": "The correct answer is : \n* No ( \"Orderid\" is unique so can't be aggregated with other two columns) \n* No ( Star schema, \"Customerid\" is needed)\n* Yes ( Don't need those columns for analysis)"
      },
      {
        "date": "2024-02-28T08:31:00.000Z",
        "voteCount": 5,
        "content": "When you look at the data in the table you see customer TORTU having ONE order composed of THREE different productID with the same ordered date.\nFurthermore, looking at the data of OrderID, it pretty looks like an autonumber to me which is unique and incremental.\n\nSome might say no, TORTU made 3 different orders. Okay but then I suppose ordered date should be different, right ?\n\nBased on those assumptions, summarizing will have no effect on the size.\nSo, NO, NO, YES"
      },
      {
        "date": "2023-12-19T21:31:00.000Z",
        "voteCount": 3,
        "content": "No / No / Yes"
      },
      {
        "date": "2023-11-14T08:15:00.000Z",
        "voteCount": 3,
        "content": "1/ yes because we remove ProductID. impossible to know if it is unique like OrderID\n2/ No, CustomerID is used in a relationship\n3/ No, UnitPrice is useful for calculating total sales. I don't understand why so many people think it's Yes. How do you calculate Total Sales?"
      },
      {
        "date": "2023-11-28T09:20:00.000Z",
        "voteCount": 5,
        "content": "we already have a total sales column. no need of units price for analysis cases"
      },
      {
        "date": "2023-11-14T08:15:00.000Z",
        "voteCount": 1,
        "content": "1/ oui car on enl\u00e8ve ProductID. impossible savoir s'il est unique comme OrderID\n2/ Non, CustomerID est utilis\u00e9e dans une relation\n3/ Non, UnitPrice est utile pour calculer le total des ventes. je ne comprend pas pourquoi il y a autant de gens qui pensent que c'est Yes. Comment calculez vous Total des ventes  ?"
      },
      {
        "date": "2024-08-18T09:09:00.000Z",
        "voteCount": 1,
        "content": "The question is in English, the answers are in English, the website is in English. So why do you speak French? O.o"
      },
      {
        "date": "2024-02-28T08:20:00.000Z",
        "voteCount": 1,
        "content": "parce que le dernier champ est le total des ventes donc inutile de recalculer"
      },
      {
        "date": "2023-09-05T15:00:00.000Z",
        "voteCount": 6,
        "content": "NO\nNO\nYES\nNo: Summarizing orders with these columns may actually increase the model size as creates a more detailed representation of the data. It will not reduce the model size.\nNo: Since there's a relationship between the Orders table and the Customers table using the CustomerID column, removing it might affect the ability to analyze data by customer, so it may not support the current analysis.\nYes: Removing unnecessary columns like UnitPrice and Discount that are not used in the analysis will likely reduce the model size without affecting the ability to analyze total sales over time, order counts, and customer counts."
      },
      {
        "date": "2023-06-21T10:56:00.000Z",
        "voteCount": 3,
        "content": "Fer079 8 months, 4 weeks ago\nif you see the table, the order ID is unique, so you are not going to have the same Order ID more than twice. For example, you will see that for the customer TORTU has 3 different products (18, 63, 75) under the same order because the OrderDate is exactly the same so we have to think it\u00b4s the same order, however the OrderID is sequential (unique).\nSo NO, NO, YES"
      },
      {
        "date": "2023-05-02T05:14:00.000Z",
        "voteCount": 2,
        "content": "My answer:\nNO: orderID is unique, suppose s CostumerID has several Orders in a day. we cannot aggregate that.\nNO we need CustomerID for the relationship\nYES we do not need them."
      },
      {
        "date": "2023-04-25T23:12:00.000Z",
        "voteCount": 4,
        "content": "1st statement NO. TotalSales is not included in the summarization, therefore won\u2019t support current analysis. Normally after creating the aggregated table, you would disable the original table from loading into the model to reduce overall size.\n2nd statement is NO, you can\u2019t remove the key column, on which relationship is based.\n3r statement is YES, you can remove those columns as they are not needed for current analysis. TotalSales will serve the purpose to calculate Total sales over time. I assume TotalSales is a normal column, not calculated one."
      },
      {
        "date": "2023-04-22T07:49:00.000Z",
        "voteCount": 6,
        "content": "My answer is:\n1. No- can you summarize the date column?\n2. No- this is a star schema, you need to have a connection between the customer dimension and the fact table with the sales\n3. No- the total sales seem to be a calculated column, Unit price*Qty, does it make sense to remove it?"
      },
      {
        "date": "2023-07-30T19:19:00.000Z",
        "voteCount": 2,
        "content": "WE CAN REMOVE THAT COLUMNS AFTER CALCULATING TOTAL SALES IN THE NEW COLUMN."
      },
      {
        "date": "2024-03-26T22:15:00.000Z",
        "voteCount": 1,
        "content": "That's right"
      },
      {
        "date": "2023-05-25T13:25:00.000Z",
        "voteCount": 1,
        "content": "Total Sales column already calculated Unit Price * Qty"
      },
      {
        "date": "2023-04-12T03:57:00.000Z",
        "voteCount": 5,
        "content": "If you see the table, the order ID is unique, so you are not going to have the same Order ID more than twice. For example, you will see that for the customer TORTU has 3 different products (18, 63, 75) under the same order because the OrderDate is exactly the same so we have to think it\u00b4s the same order, however the OrderID is sequential (unique).\nSo NO, NO, YES"
      },
      {
        "date": "2024-03-26T22:16:00.000Z",
        "voteCount": 1,
        "content": "A Legend!"
      },
      {
        "date": "2023-01-22T06:53:00.000Z",
        "voteCount": 2,
        "content": "No - Even if we don't know that OrderId is unique, if you want to see clients that buy more than once, you can summarize the data\nNo - Removing this field will break the relationships \nYes - They are not part of the analysis for the users, so they are \"extra\" data"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 36,
    "url": "https://www.examtopics.com/discussions/microsoft/view/83083-exam-pl-300-topic-2-question-36-discussion/",
    "body": "HOTSPOT -<br>You are building a financial report by using Power BI.<br>You have a table named financials that contains a column named Date and a column named Sales.<br>You need to create a measure that calculates the relative change in sales as compared to the previous quarter.<br>How should you complete the measure? To answer, select the appropriate options in the answer area.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04331/0013300001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04331/0013400001.png\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: CALCULATE -<br>Calculate the sum.<br><br>Box 2: DATEADD -<br>DATEADD -1 QUARTER will give the previous month.<br><br>Box 3: DIVIDE -<br>Use DIVIDE to get the relative change.",
    "votes": [],
    "comments": [
      {
        "date": "2022-09-21T07:01:00.000Z",
        "voteCount": 128,
        "content": "1. Calculate\n2. Dateadd\n3. Divide"
      },
      {
        "date": "2022-12-29T11:05:00.000Z",
        "voteCount": 6,
        "content": "I totally agree with you Nick10"
      },
      {
        "date": "2024-03-21T09:24:00.000Z",
        "voteCount": 3,
        "content": "And I agree with you Junior"
      },
      {
        "date": "2024-04-16T00:48:00.000Z",
        "voteCount": 3,
        "content": "I agree with you ggsss!"
      },
      {
        "date": "2024-05-27T23:26:00.000Z",
        "voteCount": 1,
        "content": "I agree with you Paras97"
      },
      {
        "date": "2024-06-04T08:36:00.000Z",
        "voteCount": 1,
        "content": "And i agree with you e31df62"
      },
      {
        "date": "2022-10-06T19:58:00.000Z",
        "voteCount": 19,
        "content": "Calculate\nDateadd\nDivide"
      },
      {
        "date": "2024-08-18T09:11:00.000Z",
        "voteCount": 1,
        "content": "1 - CALCULATE\n2 - DATEADD\n3 - DIVIDE\n\nThat's correct"
      },
      {
        "date": "2024-08-20T07:50:00.000Z",
        "voteCount": 1,
        "content": "Tested =)"
      },
      {
        "date": "2024-03-05T04:39:00.000Z",
        "voteCount": 2,
        "content": "Is missing a denomiator on Divide? I don't get it."
      },
      {
        "date": "2024-03-31T10:37:00.000Z",
        "voteCount": 1,
        "content": "Numerator is the first argument i.e. SUM('financials'[Sales])-PREV_QUARTER. Denominator is the second argument i.e. PREV_QUARTER \nhttps://learn.microsoft.com/en-us/dax/divide-function-dax"
      },
      {
        "date": "2023-09-05T15:15:00.000Z",
        "voteCount": 3,
        "content": "Calculate \nDateadd\nDivide"
      },
      {
        "date": "2023-08-28T05:16:00.000Z",
        "voteCount": 2,
        "content": "CALCULATE, DATEADD, DIVIDE"
      },
      {
        "date": "2023-08-16T00:32:00.000Z",
        "voteCount": 3,
        "content": "There is a small typo in the DATEADD part, but apart from that the given answer is correct.\nHere it is typed out for easy reference:\nSales QoQ% = IF(ISFILTERED('FACT_Order'[Date]),\n    ERROR(\"Oh noes\"),\n    VAR PREV_QUARTER = CALCULATE(SUM(FACT_Order[OrderID]),\n        DATEADD(FACT_Order[Date], -1, QUARTER))\n    RETURN DIVIDE(SUM(FACT_Order[OrderID]) - PREV_QUARTER, PREV_QUARTER))\n(I used a fact order table to calculate this.)"
      },
      {
        "date": "2023-07-24T22:31:00.000Z",
        "voteCount": 1,
        "content": "As for the correctness of the functions used, the measure is Ok, but does this measure count what is required?\nAccording to this mesure, current sales are the sum of the contents of the entire table minus the previous quarter. When Q3 is current, we divide the sum of Q1 and Q3 by Q2. Shouldn't it be DIVIDE(Q3,Q2) ?"
      },
      {
        "date": "2023-06-03T09:32:00.000Z",
        "voteCount": 2,
        "content": "The first 2 makes sense\nWhat's the logic on DIVIDE?"
      },
      {
        "date": "2023-06-05T02:16:00.000Z",
        "voteCount": 4,
        "content": "b/c any % diff calculations are either (current-previous)/previous or current/previous -1"
      },
      {
        "date": "2023-04-12T04:06:00.000Z",
        "voteCount": 1,
        "content": "1. Calculate\n2. Dateadd\n3. Divide"
      },
      {
        "date": "2023-02-23T11:01:00.000Z",
        "voteCount": 2,
        "content": "Yes Exactly \nCalculate\nDateadd\nDivide"
      },
      {
        "date": "2023-01-05T21:06:00.000Z",
        "voteCount": 2,
        "content": "Calculate\nDateadd\nDivide\nis the answer"
      },
      {
        "date": "2022-12-09T06:34:00.000Z",
        "voteCount": 3,
        "content": "1. Calculate\n2. Dateadd\n3. Divide"
      },
      {
        "date": "2022-12-01T12:08:00.000Z",
        "voteCount": 4,
        "content": "CALCULATE, DATEADD, DIVIDE"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 37,
    "url": "https://www.examtopics.com/discussions/microsoft/view/83084-exam-pl-300-topic-2-question-37-discussion/",
    "body": "DRAG DROP -<br>You are creating a Power BI model and report.<br>You have a single table in a data model named Product. Product contains the following fields:<br>\u2711 ID<br>\u2711 Name<br>\u2711 Color<br>\u2711 Category<br>\u2711 Total Sales<br>You need to create a calculated table that shows only the top eight products based on the highest value in Total Sales.<br>How should you complete the DAX expression? To answer, drag the appropriate values to the correct targets. Each value may be used once, more than once, or not at all. You may need to drag the split bar between panes or scroll to view content.<br>Select and Place:<br><img src=\"/assets/media/exam-media/04331/0013600001.jpg\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04331/0013600002.jpg\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: TOPN -<br>TOPN returns the top N rows of the specified table.<br>Syntax: TOPN(&lt;n_value&gt;, &lt;table&gt;, &lt;orderBy_expression&gt;, [&lt;order&gt;[, &lt;orderBy_expression&gt;, [&lt;order&gt;]]\u05d2\u20ac\u00a6])<br><br>Box 2: DESC -<br>Descending order to get the highest values first.<br>Reference:<br>https://docs.microsoft.com/en-us/dax/topn-function-dax",
    "votes": [],
    "comments": [
      {
        "date": "2022-09-21T07:02:00.000Z",
        "voteCount": 69,
        "content": "TOPN &amp; DESC"
      },
      {
        "date": "2022-10-26T17:38:00.000Z",
        "voteCount": 14,
        "content": "TOPN, DESC"
      },
      {
        "date": "2024-08-18T09:13:00.000Z",
        "voteCount": 1,
        "content": "The answer is correct TOPN, DESC"
      },
      {
        "date": "2024-08-20T07:57:00.000Z",
        "voteCount": 1,
        "content": "Tested =)"
      },
      {
        "date": "2023-09-05T15:23:00.000Z",
        "voteCount": 3,
        "content": "TOPN and DESC are the answers. \nTop 8 products = TOPN(8, 'Product', 'Product'[Total Sales], DESC)"
      },
      {
        "date": "2023-08-28T05:18:00.000Z",
        "voteCount": 2,
        "content": "TOPN, DESC"
      },
      {
        "date": "2023-04-19T10:24:00.000Z",
        "voteCount": 2,
        "content": "Answer is correct"
      },
      {
        "date": "2023-04-12T04:08:00.000Z",
        "voteCount": 3,
        "content": "TOPN &amp; DESC"
      },
      {
        "date": "2022-12-12T12:32:00.000Z",
        "voteCount": 3,
        "content": "TOPN, DESC"
      },
      {
        "date": "2022-12-08T06:47:00.000Z",
        "voteCount": 3,
        "content": "TopN and then DESC"
      },
      {
        "date": "2022-12-08T02:24:00.000Z",
        "voteCount": 3,
        "content": "TOPN, DESC"
      },
      {
        "date": "2022-11-28T19:38:00.000Z",
        "voteCount": 3,
        "content": "Answer is TOPN &amp; DES"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 38,
    "url": "https://www.examtopics.com/discussions/microsoft/view/81328-exam-pl-300-topic-2-question-38-discussion/",
    "body": "You are creating a sales report in Power BI for the NorthWest region sales territory of your company. Data will come from a view in a Microsoft SQL Server database. A sample of the data is shown in the following table:<br><img src=\"/assets/media/exam-media/04331/0013700001.png\" class=\"in-exam-image\"><br>The report will facilitate the following analysis:<br>\u2711 The count of orders and the sum of total sales by Order Date<br>\u2711 The count of customers who placed an order<br>\u2711 The average quantity per order<br>You need to reduce data refresh times and report query times.<br>Which two actions should you perform? Each correct answer presents part of the solution.<br>NOTE: Each correct selection is worth one point.<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSet the data type for SalesOrderNumber to Decimal Number.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRemove the CustomerKey and ProductKey columns.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRemove the TaxAmt and Freight columns.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tFilter the data to only the NorthWest region sales territory.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "CD",
    "answerDescription": "",
    "votes": [
      {
        "answer": "CD",
        "count": 64,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2022-09-09T00:09:00.000Z",
        "voteCount": 41,
        "content": "Correct Answer"
      },
      {
        "date": "2022-09-21T07:03:00.000Z",
        "voteCount": 12,
        "content": "c &amp; D is correct"
      },
      {
        "date": "2024-08-18T09:19:00.000Z",
        "voteCount": 1,
        "content": "CD is the correct one.\nA is wrong, we can't set the datatype as decimal number because it is a string\nB is wrong because we do need the customer key to count the customers for each order.\nC OK, because we don't need the columns for the analysis\nD OK, we can filter to the specified region as requirements"
      },
      {
        "date": "2023-09-05T19:47:00.000Z",
        "voteCount": 2,
        "content": "C and D are correct.\nC. Since these columns are not needed for the specified analysis, removing them can reduce the data size and improve performance. \nD. By filtering the data to include only the NothWest region, we reduce the volume of data that needs to be processed, further improving performance."
      },
      {
        "date": "2023-05-03T00:05:00.000Z",
        "voteCount": 1,
        "content": "Correct Answer"
      },
      {
        "date": "2023-05-02T05:19:00.000Z",
        "voteCount": 1,
        "content": "The given answer is correct."
      },
      {
        "date": "2023-04-12T04:32:00.000Z",
        "voteCount": 1,
        "content": "Correct answer, only using data from northwest and removing data not used in the analysis"
      },
      {
        "date": "2023-04-11T23:09:00.000Z",
        "voteCount": 1,
        "content": "C&amp;D are correct"
      },
      {
        "date": "2022-12-28T07:18:00.000Z",
        "voteCount": 2,
        "content": "Correct, we are removing columns that won't be useful in analysis"
      },
      {
        "date": "2022-12-23T06:45:00.000Z",
        "voteCount": 2,
        "content": "C AND D"
      },
      {
        "date": "2022-12-12T07:13:00.000Z",
        "voteCount": 1,
        "content": "Answer CD"
      },
      {
        "date": "2022-12-11T13:16:00.000Z",
        "voteCount": 2,
        "content": "Correct answer"
      },
      {
        "date": "2022-12-06T15:46:00.000Z",
        "voteCount": 3,
        "content": "c and D"
      },
      {
        "date": "2022-12-03T01:02:00.000Z",
        "voteCount": 2,
        "content": "Correct. It is \"C\" and \"D\""
      },
      {
        "date": "2022-11-04T05:33:00.000Z",
        "voteCount": 4,
        "content": "C and D are correct"
      },
      {
        "date": "2022-10-06T20:06:00.000Z",
        "voteCount": 3,
        "content": "Answer is correct"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 39,
    "url": "https://www.examtopics.com/discussions/microsoft/view/81329-exam-pl-300-topic-2-question-39-discussion/",
    "body": "You are creating a Power BI model that contains a table named Store. Store contains the following fields.<br><img src=\"/assets/media/exam-media/04331/0013800001.png\" class=\"in-exam-image\"><br>You plan to create a map visual that will show store locations and provide the ability to drill down from Country to State/Province to City.<br>What should you do to ensure that the locations are mapped properly?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tChange the data type of City, State/Province, and Country.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSet Summarization for City, State/Province, and Country to Don't summarize.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSet the data category of City, State/Province, and Country.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a calculated column that concatenates the values in City, State/Province, and Country."
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 91,
        "isMostVoted": true
      },
      {
        "answer": "A",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2022-11-23T06:05:00.000Z",
        "voteCount": 40,
        "content": "Answer is C. I only don't agree with the Hierarchy solution that is given in the answer.\nData categorization is something else: https://learn.microsoft.com/en-us/power-bi/transform-model/desktop-data-categorization"
      },
      {
        "date": "2022-10-06T07:24:00.000Z",
        "voteCount": 11,
        "content": "Change the data category from \"Text\" to \"Country\", \"State\", \"City\" will work.\nSee Source:https://www.youtube.com/watch?v=rvlv80WmTgc"
      },
      {
        "date": "2023-08-15T13:57:00.000Z",
        "voteCount": 1,
        "content": "excellent anwer !!!\n here is the truth and right reason of the answer, not the hierarchy (also its important but its not related to the data category)"
      },
      {
        "date": "2024-08-18T09:21:00.000Z",
        "voteCount": 1,
        "content": "C - Set the data category of City, State/Province, and Country"
      },
      {
        "date": "2024-01-31T02:13:00.000Z",
        "voteCount": 1,
        "content": "The answer should be C"
      },
      {
        "date": "2023-12-19T21:42:00.000Z",
        "voteCount": 3,
        "content": "C is correct. Check it out here: https://learn.microsoft.com/en-us/power-bi/transform-model/desktop-data-categorization"
      },
      {
        "date": "2023-10-16T23:09:00.000Z",
        "voteCount": 1,
        "content": "The answer is C"
      },
      {
        "date": "2023-10-11T08:30:00.000Z",
        "voteCount": 1,
        "content": "This answer could be A or C.\n\nBoth solutios works."
      },
      {
        "date": "2023-09-05T19:51:00.000Z",
        "voteCount": 1,
        "content": "C is the correct answer. \nSetting the data category for these fields will allow Power BI to recognize them as location-related fields, enabling proper mapping and drilling down capabilities."
      },
      {
        "date": "2023-06-05T09:33:00.000Z",
        "voteCount": 2,
        "content": "I DONT THINK THE MAP WILL WORK IF THE DATA TYPE IS ON TEXT"
      },
      {
        "date": "2023-10-11T08:28:00.000Z",
        "voteCount": 1,
        "content": "yes it works."
      },
      {
        "date": "2023-05-02T05:20:00.000Z",
        "voteCount": 5,
        "content": "Without setting Data Category, map does not work correctly."
      },
      {
        "date": "2023-04-29T21:43:00.000Z",
        "voteCount": 5,
        "content": "the answer is correct but the explanation is wrong. has nothing to do with hierarchy. has everything to do with data categorization for geographical fields"
      },
      {
        "date": "2023-04-29T21:44:00.000Z",
        "voteCount": 1,
        "content": "an alternative to data categorization is if we had latitude/longitude fields. however, that is not an option here"
      },
      {
        "date": "2023-04-12T04:34:00.000Z",
        "voteCount": 5,
        "content": "Answer is C.\nData categorization is something else: https://learn.microsoft.com/en-us/power-bi/transform-model/desktop-data-categorization"
      },
      {
        "date": "2023-02-15T07:01:00.000Z",
        "voteCount": 1,
        "content": "Don't we need to change data type from \"Text\" if we want to creat a map? It's really strange."
      },
      {
        "date": "2023-03-28T23:10:00.000Z",
        "voteCount": 1,
        "content": "for me also. I think first we should change data type and then create a hierarchy because of Drill down part"
      },
      {
        "date": "2023-05-03T15:28:00.000Z",
        "voteCount": 1,
        "content": "No, the data type will continue to be text. You might be confusing it for the data category"
      },
      {
        "date": "2022-12-12T07:12:00.000Z",
        "voteCount": 1,
        "content": "Answer C"
      },
      {
        "date": "2022-12-11T13:19:00.000Z",
        "voteCount": 2,
        "content": "C is correct"
      },
      {
        "date": "2022-12-06T15:47:00.000Z",
        "voteCount": 2,
        "content": "Answer is correct"
      },
      {
        "date": "2022-10-06T20:12:00.000Z",
        "voteCount": 10,
        "content": "Answer is correct"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 40,
    "url": "https://www.examtopics.com/discussions/microsoft/view/83085-exam-pl-300-topic-2-question-40-discussion/",
    "body": "You are building a data model for a Power BI report.<br>You have data formatted as shown in the following table.<br><img src=\"/assets/media/exam-media/04331/0014000001.jpg\" class=\"in-exam-image\"><br>You need to create a clustered bar chart as shown in the following exhibit.<br><img src=\"/assets/media/exam-media/04331/0014000002.jpg\" class=\"in-exam-image\"><br>What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tFrom Power Query Editor, split the Machine-User column by using a delimiter.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tFrom Power Query Editor, create a column that contains the last three digits of the Machine-User column.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tIn a DAX function, create two calculated columns named Machine and User by using the SUBSTITUTE function.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tIn a DAX function, create two measures named Machine and User by using the SUBSTITUTE function."
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 30,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2022-09-21T07:11:00.000Z",
        "voteCount": 33,
        "content": "Answer A"
      },
      {
        "date": "2024-09-23T22:29:00.000Z",
        "voteCount": 1,
        "content": "Agree with A.\nOnly reason I had for not using B was that we may not be able to guarantee a length of 3 char.\nHas anyone else got a reason for not choosing B?"
      },
      {
        "date": "2023-02-16T05:20:00.000Z",
        "voteCount": 3,
        "content": "Its wrong if you split the column at Powerquery the name of the columns dont split then we need the name to make the legend and the y labels so the correct choice is C"
      },
      {
        "date": "2023-03-28T23:19:00.000Z",
        "voteCount": 1,
        "content": "Yes, but renaming is included in this step."
      },
      {
        "date": "2023-03-28T23:22:00.000Z",
        "voteCount": 2,
        "content": "we use SUBSTITUE function for: Replaces existing text with new text in a text string.\nbut here we do not want replace something, we want split the column by the delimiter \"-\""
      },
      {
        "date": "2023-07-20T07:24:00.000Z",
        "voteCount": 15,
        "content": "A"
      },
      {
        "date": "2023-07-21T06:56:00.000Z",
        "voteCount": 4,
        "content": "Did you find many of these questions on the real exam?"
      },
      {
        "date": "2023-12-18T09:25:00.000Z",
        "voteCount": 2,
        "content": "he somehow answered with right answers for more than 50 questions on this website"
      },
      {
        "date": "2024-03-04T15:05:00.000Z",
        "voteCount": 1,
        "content": "Tante domande da questo sito consiglio l'acquisto come collaboratore"
      },
      {
        "date": "2024-08-18T09:23:00.000Z",
        "voteCount": 1,
        "content": "A - it does make sense to split the column by \"-\" as delimiter"
      },
      {
        "date": "2023-12-19T21:42:00.000Z",
        "voteCount": 1,
        "content": "A is correct"
      },
      {
        "date": "2023-12-06T07:38:00.000Z",
        "voteCount": 1,
        "content": "If we split the column, we might never be able to use the original. Also, the question does not say to maintain the model size. So the best answer should be B."
      },
      {
        "date": "2023-09-13T02:47:00.000Z",
        "voteCount": 2,
        "content": "Correct Answer: A\nIt couldn't be SUBSTITUTE because for one column you could only replace either \"-ABC\" or \"-BAC\" for the \"oldtext\" parameter"
      },
      {
        "date": "2023-09-05T20:06:00.000Z",
        "voteCount": 2,
        "content": "A is the correct answer.\nThis action will allow us to split the combined \"Machine-User\" values into separate columns for \"Machine\" and \"User\", which is for creating a clustered bar chart with the desired X and Y-axis values."
      },
      {
        "date": "2023-07-20T00:56:00.000Z",
        "voteCount": 2,
        "content": "Fairly sure this was on the exam"
      },
      {
        "date": "2023-05-02T05:22:00.000Z",
        "voteCount": 2,
        "content": "A is the correct answer."
      },
      {
        "date": "2023-04-26T22:00:00.000Z",
        "voteCount": 1,
        "content": "Answer is A is the best and fastest solution. Splitting the column into 2 is better that creating an extra 2 calculated columns, this will increase the model size."
      },
      {
        "date": "2023-04-12T04:40:00.000Z",
        "voteCount": 2,
        "content": "The desired visual is provided. However, the dataset shown contains a column where machine and user data from the visual are combined into 1 column. Therefore, to solve this you need to use a delimiter. This will split one column into two, where you will use Machine column (BAC &amp; ABC) as your Y-axis and User column (123 &amp; 657) as your legend."
      },
      {
        "date": "2022-12-31T00:28:00.000Z",
        "voteCount": 2,
        "content": "Can anyone explain this?"
      },
      {
        "date": "2023-01-14T09:59:00.000Z",
        "voteCount": 5,
        "content": "The desired visual is provided. However, the dataset shown contains a column where machine and user data from the visual are combined into 1 column. Therefore, to solve this you need to use a delimiter. This will split one column into two, where you will use Machine column (BAC &amp; ABC) as your Y-axis and User column (123 &amp; 657) as your legend."
      },
      {
        "date": "2022-12-12T07:12:00.000Z",
        "voteCount": 3,
        "content": "Answer A"
      },
      {
        "date": "2022-12-11T13:24:00.000Z",
        "voteCount": 2,
        "content": "A is correct"
      },
      {
        "date": "2022-12-06T15:49:00.000Z",
        "voteCount": 1,
        "content": "Answer A"
      },
      {
        "date": "2022-12-01T13:03:00.000Z",
        "voteCount": 1,
        "content": "Answer A"
      },
      {
        "date": "2022-11-10T23:36:00.000Z",
        "voteCount": 3,
        "content": "Answer A is correct"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 41,
    "url": "https://www.examtopics.com/discussions/microsoft/view/83087-exam-pl-300-topic-2-question-41-discussion/",
    "body": "DRAG DROP -<br>You need create a date table in Power BI that must contain 10 full calendar years, including the current year.<br>How should you complete the DAX expression? To answer, select the appropriate options in the answer area.<br>NOTE: Each correct selection is worth one point.<br>Select and Place:<br><img src=\"/assets/media/exam-media/04331/0014200001.jpg\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04331/0014200002.jpg\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: YEAR -<br>Get the current year.<br><br>Box 2: TODAY -<br>TODAY returns the current date.<br><br>Box 3: CALENDAR -<br>CALENDAR returns a table with a single column named \u05d2\u20acDate\u05d2\u20ac containing a contiguous set of dates. The range of dates is from the specified start date to the specified end date, inclusive of those two dates.<br>The following formula returns a table with dates between January 1st, 2005 and December 31st, 2015.<br>CALENDAR (<br>DATE ( 2005, 1, 1 ),<br>DATE ( 2015, 12, 31 )<br>Reference:<br>https://dax.guide/calendar/",
    "votes": [],
    "comments": [
      {
        "date": "2022-09-21T07:11:00.000Z",
        "voteCount": 65,
        "content": "Year\nToday\nCalendar"
      },
      {
        "date": "2022-10-07T23:11:00.000Z",
        "voteCount": 12,
        "content": "Correct :\nYear\nToday\nCalendar"
      },
      {
        "date": "2024-08-18T09:25:00.000Z",
        "voteCount": 1,
        "content": "The answer is correct, YEAR - TODAY - CALENDAR is the correct sequence"
      },
      {
        "date": "2023-09-17T07:52:00.000Z",
        "voteCount": 2,
        "content": "But, will \"-9\" from today's date give a date of 10years ago?"
      },
      {
        "date": "2023-12-06T10:58:00.000Z",
        "voteCount": 4,
        "content": "Yes, it does. This range included in the explanation is actually 11 years: DATE ( 2005, 1, 1 ),\nDATE ( 2015, 12, 31 ). So, subtracting 9 gives you 10 full years counting from the first full year till the end year."
      },
      {
        "date": "2023-09-05T20:22:00.000Z",
        "voteCount": 8,
        "content": "Year\nToday\nCalendar \nYear: calculates the starting year for the date table. \nToday: simply assigns the current date.\nCalendar: is used to generate a date table. It starts from January 1st of the year and goes up to December 31st of the current year."
      },
      {
        "date": "2023-08-28T05:28:00.000Z",
        "voteCount": 1,
        "content": "Year\nToday\nCalendar"
      },
      {
        "date": "2023-08-16T00:38:00.000Z",
        "voteCount": 1,
        "content": "There is a typo in this exercise, the right code is:\nDate = \n    var var1 = YEAR(TODAY())\n    RETURN CALENDAR(\n        DATE(var1, -9, 01),\n        DATE(var1, 12, 31))"
      },
      {
        "date": "2023-09-10T22:29:00.000Z",
        "voteCount": 4,
        "content": "There is no typo here. The DATE(var1 -9, 01,01) is meant to subtract 9 from the value of var1 which in turn is a YEAR value of TODAY()'s date."
      },
      {
        "date": "2023-06-10T00:54:00.000Z",
        "voteCount": 4,
        "content": "Answer given is correct\n\nDate = \nvar var1 = YEAR(TODAY())    \nreturn CALENDAR(DATE(var1 - 9,01,01),\n                DATE(var1,12,31)\n               )"
      },
      {
        "date": "2023-06-04T11:43:00.000Z",
        "voteCount": 3,
        "content": "was this in the learning paths? how do you find the answer for this"
      },
      {
        "date": "2023-04-17T22:23:00.000Z",
        "voteCount": 1,
        "content": "The answer is correct"
      },
      {
        "date": "2023-04-12T04:42:00.000Z",
        "voteCount": 1,
        "content": "Correct, it is\n\nYear\nToday\nCalendar"
      },
      {
        "date": "2023-01-06T07:46:00.000Z",
        "voteCount": 1,
        "content": "Correct ans:\nYear\nToday\nCalendar"
      },
      {
        "date": "2022-12-06T15:50:00.000Z",
        "voteCount": 2,
        "content": "Year\nToday\nCalendar"
      },
      {
        "date": "2022-10-21T00:01:00.000Z",
        "voteCount": 4,
        "content": "The answer is correct"
      },
      {
        "date": "2022-10-06T20:34:00.000Z",
        "voteCount": 5,
        "content": "Answer is correct"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 42,
    "url": "https://www.examtopics.com/discussions/microsoft/view/82471-exam-pl-300-topic-2-question-42-discussion/",
    "body": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.<br>After you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.<br>You have a Power BI report that imports a date table and a sales table from an Azure SQL database data source. The sales table has the following date foreign keys:<br>\u2711 Due Date<br>\u2711 Order Date<br>\u2711 Delivery Date<br>You need to support the analysis of sales over time based on all the date foreign keys.<br>Solution: You create measures that use the USERELATIONSHIP DAX function to filter sales on the active relationship between the sales table and the date table.<br>Does this meet the goal?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tYes",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tNo\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 71,
        "isMostVoted": true
      },
      {
        "answer": "A",
        "count": 2,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2022-09-17T12:56:00.000Z",
        "voteCount": 38,
        "content": "You can't use USERELATIONSHIP() to filter on an active relationship, but need additional innactive relationships"
      },
      {
        "date": "2022-09-28T20:00:00.000Z",
        "voteCount": 21,
        "content": "https://learn.microsoft.com/en-us/dax/userelationship-function-dax\n\n\"In USERELATIONSHIP, the status of a relationship is not important; that is, whether the relationship is active or not does not affect the usage of the function. Even if the relationship is inactive, it will be used and overrides any other active relationships that might be present in the model but not mentioned in the function arguments.\""
      },
      {
        "date": "2022-11-23T06:42:00.000Z",
        "voteCount": 28,
        "content": "Actually the DAX USERELATIONSHIP() function could offer a solution, but not how it is stated as an option: \"You create measures that use the USERELATIONSHIP DAX function to filter sales on the ACTIVE relationship between the sales table and the date table.\"\n\nBecause the report must be filtered on all 3 dates, the ACTIVE (1) AND INACTIVE (2) relationships should be used with function USERELATIONSHIP, not only the ACTIVE relationship."
      },
      {
        "date": "2023-07-05T12:34:00.000Z",
        "voteCount": 5,
        "content": "Correct Answer!. \nThe method \"USERELATIONSHIP\" DAX FUNCTION is right, but the explanation which only limited to active relationship is wrong."
      },
      {
        "date": "2024-06-13T03:11:00.000Z",
        "voteCount": 1,
        "content": "A is correct.\n\n In USERELATIONSHIP, the status of a relationship is not important; that is, whether the relationship is active or not does not affect the usage of the function. \n\nCheck this link out:\nhttps://learn.microsoft.com/en-us/dax/userelationship-function-dax"
      },
      {
        "date": "2023-09-05T20:31:00.000Z",
        "voteCount": 3,
        "content": "A is correct.\nThis solution meets the goal. By creating measures that use the USERELATIONSHIP DAX function, we can specify which relationship between the sales table and the date table to use for filtering in our calculations. This allows us to analyze sales over time based on all the date foreign keys, ensuring that the correct relationship is applied in each scenario."
      },
      {
        "date": "2023-07-04T04:46:00.000Z",
        "voteCount": 2,
        "content": "You can relate all 3 date columns to Date table, and you can make all of them inactive.\n(2 of them will be initially inactive anyway)\nSo you can use USERELATIONSHIP in your calculations.\nIt's YES for me."
      },
      {
        "date": "2023-07-04T06:33:00.000Z",
        "voteCount": 3,
        "content": "OK, I've changed my mind, you don't use USERELATIONSHIP on active relations."
      },
      {
        "date": "2023-02-15T05:11:00.000Z",
        "voteCount": 4,
        "content": "it's not necessary to userelationship on active relationship. only inactive. furthermore, userelationship should be used on all relationships, active or inactive"
      },
      {
        "date": "2023-02-09T09:52:00.000Z",
        "voteCount": 5,
        "content": "For sure B. WE don't use dax for active relationship. watch this video for understanding. https://www.youtube.com/watch?v=LfVDUiU8vaU"
      },
      {
        "date": "2023-04-01T06:17:00.000Z",
        "voteCount": 1,
        "content": "Thanks for the video link."
      },
      {
        "date": "2022-10-27T03:45:00.000Z",
        "voteCount": 4,
        "content": "After all, Yes you will use USERELATIONSHIP \nBUT, not like as provided... It will be used to activate the inactive relationships as needed"
      },
      {
        "date": "2022-11-23T06:33:00.000Z",
        "voteCount": 4,
        "content": "It can be used for active and inactive relationships:\n\"In USERELATIONSHIP, the status of a relationship is not important; that is, whether the relationship is active or not does not affect the usage of the function. Even if the relationship is inactive, it will be used and overrides any other active relationships that might be present in the model but not mentioned in the function arguments.\""
      },
      {
        "date": "2022-10-02T22:03:00.000Z",
        "voteCount": 3,
        "content": "I think it's correct, USERELATIONSHIP() on active relationships will only use one of them."
      },
      {
        "date": "2023-02-17T11:34:00.000Z",
        "voteCount": 2,
        "content": "You do not need to use USERELATIONSHIP() if it is already an active relationship, it is used on inactive relationships"
      },
      {
        "date": "2022-09-16T20:40:00.000Z",
        "voteCount": 8,
        "content": "The solution I believe is incorrect. The solution must be A as there is no reporting need to use all 3 dates simultaneously."
      },
      {
        "date": "2022-12-01T13:32:00.000Z",
        "voteCount": 3,
        "content": "I was thinking the same but then if you read the options again, it says create measure on active relationship. So the answer is A is wrong , we don't create userelationship function on active relationship. No need."
      },
      {
        "date": "2022-10-10T10:07:00.000Z",
        "voteCount": 5,
        "content": "\"You need to support the analysis of sales over time based on all the date foreign keys.\" We need all 3 dates right?"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 43,
    "url": "https://www.examtopics.com/discussions/microsoft/view/84567-exam-pl-300-topic-2-question-43-discussion/",
    "body": "HOTSPOT -<br>You have a Power BI report that contains a measure named Total Sales.<br>You need to create a new measure that will return the sum of Total Sales for a year up to a selected date.<br>How should you complete the DAX expression? To answer, select the appropriate options in the answer area.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04331/0014500001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04331/0014600001.png\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: TOTALYTD -<br>TOTALYTD evaluates the specified expression over the interval which begins on the first day of the year and ends with the last date in the specified date column after applying specified filters.<br>Syntax: TOTALYTD (<br>&lt;Expression&gt;,<br>&lt;Dates&gt;<br>[, &lt;Filter&gt;]<br>[, &lt;YearEndDate&gt;]<br>Expression - The expression to be evaluated.<br>Dates - The name of a column containing dates or a one column table containing dates.<br>Example:<br>TOTALYTD (            -- 2007-01-01 : 2007-05-12<br>[Sales Amount],<br>'Date'[Date]<br>Box 2: 'Date'[Date]<br>Reference:<br>https://dax.guide/totalytd/",
    "votes": [],
    "comments": [
      {
        "date": "2022-10-06T20:38:00.000Z",
        "voteCount": 46,
        "content": "Answer is correct"
      },
      {
        "date": "2023-12-08T01:08:00.000Z",
        "voteCount": 2,
        "content": "Not quite, the last closing bracket should be at the end."
      },
      {
        "date": "2022-10-27T08:04:00.000Z",
        "voteCount": 14,
        "content": "Answer is correct."
      },
      {
        "date": "2024-08-18T09:28:00.000Z",
        "voteCount": 1,
        "content": "Answer is correct TOTALYTD, 'Date'[Date]"
      },
      {
        "date": "2024-03-27T05:45:00.000Z",
        "voteCount": 1,
        "content": "Correct!\nCould Be:\nCALCULATE(\n    [Total Revenue],\n    TOTALYTD('Date'[Date])\n    )"
      },
      {
        "date": "2023-09-05T20:44:00.000Z",
        "voteCount": 12,
        "content": "TOTALYTD\n`Date`[Date]\n\nTOTALYTD: is being used to calculate the sum of \"Total Sales\" year-to-date up to the selected date.\n`Date`[Date]: provides the date context for the calculation."
      },
      {
        "date": "2023-05-02T07:17:00.000Z",
        "voteCount": 1,
        "content": "Answer is correct."
      },
      {
        "date": "2023-04-20T00:35:00.000Z",
        "voteCount": 4,
        "content": "Why can't we use LASTDATE instead of date ?"
      },
      {
        "date": "2023-04-24T15:31:00.000Z",
        "voteCount": 2,
        "content": "because the requirement is the sum of Total Sales for a year up to a selected date."
      },
      {
        "date": "2023-05-01T02:04:00.000Z",
        "voteCount": 1,
        "content": "So including the  most recent year in the data right?"
      },
      {
        "date": "2023-04-12T04:43:00.000Z",
        "voteCount": 2,
        "content": "Answer is correct"
      },
      {
        "date": "2023-03-08T21:46:00.000Z",
        "voteCount": 1,
        "content": "can someone explain why can't we use SUM function?"
      },
      {
        "date": "2023-03-17T06:32:00.000Z",
        "voteCount": 4,
        "content": "it already using the measure"
      },
      {
        "date": "2022-12-25T08:29:00.000Z",
        "voteCount": 2,
        "content": "Answer is correct"
      },
      {
        "date": "2022-12-09T06:42:00.000Z",
        "voteCount": 4,
        "content": "TotalYTD; 'Date'[date]"
      },
      {
        "date": "2022-12-09T05:45:00.000Z",
        "voteCount": 3,
        "content": "Answer is Correct!"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 44,
    "url": "https://www.examtopics.com/discussions/microsoft/view/80827-exam-pl-300-topic-2-question-44-discussion/",
    "body": "DRAG DROP -<br>You are modifying a Power BI model by using Power BI Desktop.<br>You have a table named Sales that contains the following fields.<br><img src=\"/assets/media/exam-media/04331/0014700001.jpg\" class=\"in-exam-image\"><br>You have a table named Transaction Size that contains the following data.<br><img src=\"/assets/media/exam-media/04331/0014800001.jpg\" class=\"in-exam-image\"><br>You need to create a calculated column to classify each transaction as small, medium, or large based on the value in Sales Amount.<br>How should you complete the code? To answer, drag the appropriate values to the correct targets. Each value may be used once, more than once, or not at all.<br>You may need to drag the split bar between panes or scroll to view content.<br>NOTE: Each correct selection is worth one point.<br>Select and Place:<br><img src=\"/assets/media/exam-media/04331/0014800002.jpg\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04331/0014900001.jpg\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: CALCULATE -<br>CALCULATE evaluates an expression in a modified filter context.<br>Syntax: CALCULATE(&lt;expression&gt;[, &lt;filter1&gt; [, &lt;filter2&gt; [, \u05d2\u20ac\u00a6]]])<br>The expression used as the first parameter is essentially the same as a measure.<br>Filters can be:<br><br>Boolean filter expressions -<br><br>Table filter expressions -<br><br>Filter modification functions -<br><br>Table filter expression -<br>A table expression filter applies a table object as a filter. It could be a reference to a model table, but more likely it's a function that returns a table object. You can use the FILTER function to apply complex filter conditions, including those that cannot be defined by a Boolean filter expression.<br><br>Box 2: AND -<br><br>Box 3: FILTER -<br>FILTER returns a table that represents a subset of another table or expression.<br>Syntax: FILTER(&lt;table&gt;,&lt;filter&gt;)<br>Note: DISTINCT returns a one-column table that contains the distinct values from the specified column. In other words, duplicate values are removed and only unique values are returned.<br>Reference:<br>https://docs.microsoft.com/en-us/dax/calculate-function-dax<br>https://docs.microsoft.com/en-us/dax/filter-function-dax",
    "votes": [],
    "comments": [
      {
        "date": "2022-09-07T01:13:00.000Z",
        "voteCount": 144,
        "content": "Filter\nAnd\nCalculate"
      },
      {
        "date": "2022-09-13T10:12:00.000Z",
        "voteCount": 7,
        "content": "Correct! tested."
      },
      {
        "date": "2023-12-12T11:42:00.000Z",
        "voteCount": 1,
        "content": "It's giving the wrong result. How and what formula have you used?"
      },
      {
        "date": "2022-10-05T00:20:00.000Z",
        "voteCount": 2,
        "content": "how to test ? i did not find a right answer.."
      },
      {
        "date": "2022-10-06T08:41:00.000Z",
        "voteCount": 5,
        "content": "Hi, you can create the two tables in Excel, then try different options. I have never used \"Calculate\" with a categorical field before and this is a good learning experience."
      },
      {
        "date": "2022-09-23T09:38:00.000Z",
        "voteCount": 9,
        "content": "I agree. You must provide an expression into calculate, not table column"
      },
      {
        "date": "2022-10-06T21:00:00.000Z",
        "voteCount": 16,
        "content": "Tested, following is correct\n&gt;Filter\n&gt;And\n&gt;Calculate"
      },
      {
        "date": "2024-08-19T13:50:00.000Z",
        "voteCount": 1,
        "content": "I have a question about their formula:\nDo you even need to declare and use the VAR SalesTotal? Why not just use the column of 'Sales'[Sales] directly in the inequality expression?\n\nI replicated this in Power BI and found that only Filter And Calculate works for me by the way."
      },
      {
        "date": "2024-08-18T09:36:00.000Z",
        "voteCount": 1,
        "content": "Filter, And, Calculate"
      },
      {
        "date": "2024-05-22T11:37:00.000Z",
        "voteCount": 2,
        "content": "The CORRECT ANSWER IS : \nFILTER AND CALCULATE \nWhy : Filter returns a table, and we need to create a calculated column"
      },
      {
        "date": "2024-03-14T01:36:00.000Z",
        "voteCount": 4,
        "content": "Filter \nAND\nCALCULATE"
      },
      {
        "date": "2024-02-29T18:19:00.000Z",
        "voteCount": 1,
        "content": "I thought the FILTER function needs a condition as an argument? But in the FILTER segment here it has no condition...?"
      },
      {
        "date": "2024-02-29T00:52:00.000Z",
        "voteCount": 2,
        "content": "answer is wrong; if you follow it you will receive a dax error (expression refers to multiple columns) the right sequence is Filter And Calculate"
      },
      {
        "date": "2024-02-21T01:24:00.000Z",
        "voteCount": 2,
        "content": "that kind of question goes far beyond POWER BI!\nIt addresses specific DAX programming skillset..."
      },
      {
        "date": "2024-02-12T08:37:00.000Z",
        "voteCount": 2,
        "content": "Filter\nAnd\nCalculate"
      },
      {
        "date": "2024-01-26T12:55:00.000Z",
        "voteCount": 2,
        "content": "Filter - And - Calculate"
      },
      {
        "date": "2023-12-13T05:26:00.000Z",
        "voteCount": 4,
        "content": "Could anybody explain this? I don't understand especially that filter-thing there."
      },
      {
        "date": "2023-11-20T11:27:00.000Z",
        "voteCount": 9,
        "content": "ExamTopics is still going on because of you. Without your corrections, comments, links, experiences, questions, this page will be one of the thousand going there. Thank you."
      },
      {
        "date": "2023-10-31T05:48:00.000Z",
        "voteCount": 1,
        "content": "I don't quite understand the answer. Wouldn't the result variable just give a single table with just 1 column showing 'Small', 'Medium', and 'Large'? \nWhere is the VAR SalesTotal in such a table?"
      },
      {
        "date": "2023-10-12T12:51:00.000Z",
        "voteCount": 2,
        "content": "FILTER, AND , CALCULATE"
      },
      {
        "date": "2023-09-05T20:58:00.000Z",
        "voteCount": 1,
        "content": "FILTER\nAND\nCALCULATE"
      },
      {
        "date": "2023-08-28T05:38:00.000Z",
        "voteCount": 1,
        "content": "Filter\nAnd\nCalculate"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 45,
    "url": "https://www.examtopics.com/discussions/microsoft/view/82102-exam-pl-300-topic-2-question-45-discussion/",
    "body": "You have a Power BI report for the procurement department. The report contains data from the following tables.<br><img src=\"/assets/media/exam-media/04331/0015100001.jpg\" class=\"in-exam-image\"><br>There is a one-to-many relationship from Suppliers to LineItems that uses the ID and Supplier ID columns.<br>The report contains the visuals shown in the following table.<br><img src=\"/assets/media/exam-media/04331/0015200001.png\" class=\"in-exam-image\"><br>You need to minimize the size of the dataset without affecting the visuals.<br>What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tMerge Suppliers and LineItems.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRemove the LineItems[Description] column.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRemove the rows from LineItems where LineItems[Invoice Date] is before the beginning of last month.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tGroup LineItems by LineItems[Invoice ID] and LineItems[Invoice Date] with a sum of LineItems[Price]."
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 35,
        "isMostVoted": true
      },
      {
        "answer": "D",
        "count": 2,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2022-11-20T10:02:00.000Z",
        "voteCount": 78,
        "content": "Questions like these scare me. Huge description, and such a simple answer, makes me think if there is a trick here. Why Microsoft why!?"
      },
      {
        "date": "2022-12-25T10:56:00.000Z",
        "voteCount": 4,
        "content": "Exactly!! Idk why they do this because it makes no sense specially for such silly questions like this. The point is to test the understanding.."
      },
      {
        "date": "2023-04-04T02:17:00.000Z",
        "voteCount": 4,
        "content": "OMG it seems like a riddle!!! they do it on purpose to distract the reader"
      },
      {
        "date": "2022-12-29T13:02:00.000Z",
        "voteCount": 2,
        "content": "hahahahahahahaha its scare me too hahaha why MS why???"
      },
      {
        "date": "2023-07-02T23:47:00.000Z",
        "voteCount": 6,
        "content": "WHY MICROSOFT WHY?!!!!!!!!!!!!!    You scare me bro. LOL XD"
      },
      {
        "date": "2023-01-14T13:33:00.000Z",
        "voteCount": 8,
        "content": "WHY???? LOL ....so true..it looks like a reading test"
      },
      {
        "date": "2022-10-10T19:52:00.000Z",
        "voteCount": 19,
        "content": "B is correct"
      },
      {
        "date": "2024-08-18T09:38:00.000Z",
        "voteCount": 1,
        "content": "I agree, we can safely remove the Description because it is not used in the final report"
      },
      {
        "date": "2024-08-01T20:01:00.000Z",
        "voteCount": 1,
        "content": "is it possible to pay for certification in Africa and then compose it in Europe?"
      },
      {
        "date": "2023-12-19T22:08:00.000Z",
        "voteCount": 2,
        "content": "B is correct"
      },
      {
        "date": "2023-10-31T05:52:00.000Z",
        "voteCount": 4,
        "content": "C is wrong because doing so will remove older rows of [Invoice ID] still needed for the 'Supplier usage by count and usage of invoices'"
      },
      {
        "date": "2023-12-07T12:54:00.000Z",
        "voteCount": 1,
        "content": "EXACTLY."
      },
      {
        "date": "2023-09-06T08:26:00.000Z",
        "voteCount": 1,
        "content": "C is the answer.\nThis option involves filtering out data that is not relevant to the report's time frame. By removing the rows from LineItems that are not within the last calendar month, we can significantly reduce the size of the dataset without affecting the visuals. \nOther options cannot be answers because:\nA: Typically increase dataset size. It might even create data redundancy if not done carefully. \nB. Removing a single column from a table might save some space, but it is unlikely to have a significant impact on the overall dataset size, especially when compared to filtering the data based on the date. \nD. This option would change the granularity of your data, potentially causing issues with our visuals. it would also likely increase the size of the dataset if we are aggregating data instead of filtering it."
      },
      {
        "date": "2023-09-21T19:56:00.000Z",
        "voteCount": 4,
        "content": "The users of the Spend by Supplier Location have no interest in being limited to the last calendar month. They need a much larger time series. You're offering to remove a significant chunk of model data--but that's only appropriate for one of three report consumer groups.\n\nB doesn't save a ton of space, but it does so without impacting any reporting group. It's the only viable win from the four options provided."
      },
      {
        "date": "2023-05-16T22:44:00.000Z",
        "voteCount": 1,
        "content": "Why cant C be correct? The question does not say anything about that we need historical data before the beginning of previous month, or does it?"
      },
      {
        "date": "2023-05-16T22:45:00.000Z",
        "voteCount": 3,
        "content": "Is it the lack of filter in visual 1 and 2 that implicitly states that we need it?"
      },
      {
        "date": "2023-09-21T19:57:00.000Z",
        "voteCount": 1,
        "content": "Exactly. One group needs data only from the last month. The other groups need the full time range."
      },
      {
        "date": "2023-11-14T09:48:00.000Z",
        "voteCount": 2,
        "content": "I also think that removing a whole column will reduce dataset more than removing \"some\" rows. Also btw. it will take less processing time than reducing number of rows based on some criteria."
      },
      {
        "date": "2023-05-02T07:29:00.000Z",
        "voteCount": 3,
        "content": "There is no need for Description column."
      },
      {
        "date": "2023-04-26T22:52:00.000Z",
        "voteCount": 7,
        "content": "Answer is B. \nD won't work due to the fact the Supplier ID (key column) will be removed as it's not included in the Group by function."
      },
      {
        "date": "2024-04-23T00:22:00.000Z",
        "voteCount": 2,
        "content": "correct, without supplier id in the group there will be no way to join to the supplier table."
      },
      {
        "date": "2023-04-12T04:52:00.000Z",
        "voteCount": 1,
        "content": "Correct answer is B"
      },
      {
        "date": "2022-12-29T12:19:00.000Z",
        "voteCount": 2,
        "content": "B is correct"
      },
      {
        "date": "2022-12-13T03:13:00.000Z",
        "voteCount": 2,
        "content": "B is correct"
      },
      {
        "date": "2022-12-12T07:24:00.000Z",
        "voteCount": 1,
        "content": "Answer B"
      },
      {
        "date": "2022-12-09T06:46:00.000Z",
        "voteCount": 1,
        "content": "B is correct"
      },
      {
        "date": "2022-09-22T04:57:00.000Z",
        "voteCount": 7,
        "content": "Agree. the correcte answer is B. If you choose C you will loose the Supplier ID and it is used in the report."
      },
      {
        "date": "2022-09-21T09:24:00.000Z",
        "voteCount": 4,
        "content": "Option D will lose LineItem.Id therefore link to Supplier, correct answer is B"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 46,
    "url": "https://www.examtopics.com/discussions/microsoft/view/80829-exam-pl-300-topic-2-question-46-discussion/",
    "body": "You have a Power BI report for the marketing department. The report reports on web traffic to a blog and contains data from the following tables.<br><img src=\"/assets/media/exam-media/04331/0015300001.jpg\" class=\"in-exam-image\"><br>There is a one-to-many relationship from Posts to Traffic that uses the URL and URL Visited columns.<br>The report contains the visuals shown in the following table.<br><img src=\"/assets/media/exam-media/04331/0015400001.png\" class=\"in-exam-image\"><br>The dataset takes a long time to refresh.<br>You need to modify Posts and Traffic queries to reduce load times.<br>Which two actions will reduce the load times? Each correct answer presents part of the solution.<br>NOTE:<br>Each correct selection is worth one point.<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRemove the rows in Posts in which Posts[Publish Date] is in the last seven days.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRemove the rows in Traffic in which Traffic[URL Visited] does not contain \u05d2\u20acblog\u05d2\u20ac.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRemove Traffic[IP Address], Traffic[Browser Agent], and Traffic[Referring URL].",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRemove Posts[Full Text] and Posts[Summary].\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRemove the rows in Traffic in which Traffic[Referring URL] does not start with \u05d2\u20ac/\u05d2\u20ac."
    ],
    "answer": "BD",
    "answerDescription": "",
    "votes": [
      {
        "answer": "BD",
        "count": 62,
        "isMostVoted": true
      },
      {
        "answer": "DE",
        "count": 5,
        "isMostVoted": false
      },
      {
        "answer": "B",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2023-01-06T09:32:00.000Z",
        "voteCount": 20,
        "content": "B &amp; D Agreed with  XIKTA"
      },
      {
        "date": "2022-09-15T19:20:00.000Z",
        "voteCount": 18,
        "content": "D&amp;E? Anyone have the same thoughts?"
      },
      {
        "date": "2023-09-21T20:04:00.000Z",
        "voteCount": 7,
        "content": "E is not correct. There are perfectly valid blog hits that won't have a referring URL, so filtering those rows removes valid hits that need to be counted.\n\nThe answer is D &amp; B. It feels a bit unnatural to me to be pulling rows instead of columns, but all the visuals we're talking about here involve blog hits specifically, so pulling the non-blog website traffic out of the dataset appears to be the right path forward."
      },
      {
        "date": "2022-11-15T22:49:00.000Z",
        "voteCount": 1,
        "content": "Must be....presume the whacko characters are the same filtered '/' character.  A, B and C all definitely don't work."
      },
      {
        "date": "2023-03-18T06:47:00.000Z",
        "voteCount": 5,
        "content": "I disagree, we would remove the line which do not start with \"/\", but those are the lines exactly what we need in the last visual"
      },
      {
        "date": "2023-07-23T18:14:00.000Z",
        "voteCount": 5,
        "content": "That would remove Traffic data that is used in other visuals, so it's incorrect."
      },
      {
        "date": "2024-08-18T09:49:00.000Z",
        "voteCount": 1,
        "content": "Help me guys! I totally agree with D because we do not user Full Text and Summary in any visual. But why B is correct? We can't filter the traffic by URL because there is the report \"Top 10 blog posts from the last seven days\" which shows the traffic in the last 7 days independently from the URL"
      },
      {
        "date": "2024-08-20T09:00:00.000Z",
        "voteCount": 2,
        "content": "I will answer to myself =) I just realized that we can filter the blogs because it is a specific requirement. So BD is correct =)"
      },
      {
        "date": "2024-01-15T06:43:00.000Z",
        "voteCount": 2,
        "content": "B and D are correct because the data are not needed"
      },
      {
        "date": "2023-12-19T22:09:00.000Z",
        "voteCount": 2,
        "content": "B and D are correct"
      },
      {
        "date": "2023-11-13T04:11:00.000Z",
        "voteCount": 6,
        "content": "Although some visuals have no filter related to \"blog\", the title of the visual suggests that only blogs are being analyzed. Therefore, we can safely remove everything that does not contain \"blog\". B and D are correct."
      },
      {
        "date": "2024-03-11T08:21:00.000Z",
        "voteCount": 3,
        "content": "That's not \"safely\" removing. Going by just the title is exactly the opposite of safely removing, it's unsafely removing."
      },
      {
        "date": "2024-04-23T00:34:00.000Z",
        "voteCount": 1,
        "content": "i agree, you can't just assume based on the description of the visual. if it was necessary to  include 'blog' in one filter it should be included in others if that was the intention.\n\nthe only correct answer is D based on the limited information provided"
      },
      {
        "date": "2023-11-10T02:32:00.000Z",
        "voteCount": 5,
        "content": "B makes no sense because there is no filter on \"blog\" on the first two visuals, so removing it causes a lack of data."
      },
      {
        "date": "2023-08-10T03:33:00.000Z",
        "voteCount": 3,
        "content": "B and D"
      },
      {
        "date": "2023-07-28T02:35:00.000Z",
        "voteCount": 1,
        "content": "so how decides the final answer?"
      },
      {
        "date": "2024-03-04T15:07:00.000Z",
        "voteCount": 1,
        "content": "B&amp;D risposta corretta"
      },
      {
        "date": "2023-10-01T05:25:00.000Z",
        "voteCount": 4,
        "content": "B &amp; D you don't need rows of data which has no \"blog\" in it in the Traffic table, and in regards of the Posts table we don't either used the \"Full Text &amp; Summary\" data in the analysis. Hope it makes sense to you."
      },
      {
        "date": "2023-10-13T06:29:00.000Z",
        "voteCount": 1,
        "content": "I agree, but looking at the filters, in the first two visuals even posts that are not \"blog\" are used. Looking at the name they seems to be filtered, but hard to decide without the actual filter"
      },
      {
        "date": "2023-07-17T02:49:00.000Z",
        "voteCount": 3,
        "content": "The filters of the first two reports don't mention 'contains BLOG' So for me deleting lines with BLOG has impacts. The basis is not clear for the two reports."
      },
      {
        "date": "2023-07-17T02:52:00.000Z",
        "voteCount": 2,
        "content": "ok join by URL so implicite..."
      },
      {
        "date": "2023-09-21T20:06:00.000Z",
        "voteCount": 1,
        "content": "It's a fair criticism of the way the question is laid out. For me, the intention was clear enough in the visual names, but I see what you're saying there."
      },
      {
        "date": "2023-05-02T07:33:00.000Z",
        "voteCount": 3,
        "content": "both are clear!"
      },
      {
        "date": "2023-04-26T23:02:00.000Z",
        "voteCount": 3,
        "content": "I would go with B and D."
      },
      {
        "date": "2023-04-12T04:53:00.000Z",
        "voteCount": 6,
        "content": "All 4 visualizations are about blogs: so we can remove rows what do not contain \"blog\" - thus B is correct. We do not need columns Posts[Full Text] and Posts[Summary] in any visualization, they can be removed."
      },
      {
        "date": "2023-06-03T10:01:00.000Z",
        "voteCount": 3,
        "content": "Do all blogs have \"blog\" in the URL?\nI would say most don't."
      },
      {
        "date": "2023-02-08T11:45:00.000Z",
        "voteCount": 2,
        "content": "I dont understand what \"\u05d2\u20acblog\u05d2\u20ac.\" means in the possible answers. Can someone explain?"
      },
      {
        "date": "2023-06-03T10:07:00.000Z",
        "voteCount": 4,
        "content": "Its character encoding, its a mistake on this website\nB should have \"blog\"\nE should have \"/\""
      },
      {
        "date": "2023-01-04T21:33:00.000Z",
        "voteCount": 1,
        "content": "E is not correct as it would remove traffic rows based on the referral that is a requisite only for the latest visual"
      },
      {
        "date": "2023-03-29T00:25:00.000Z",
        "voteCount": 1,
        "content": "E is incorrect, because if we remove the rows that does not start with \"/\", it may possible removes the rows that in the \"URL visited\" column contains \"blog\".\nI think B is correct, because we just need the rows that are related to the blog, and if a URL does not contain \"blog\", it means it is not related to \"blog\" and is useless."
      },
      {
        "date": "2023-09-21T20:08:00.000Z",
        "voteCount": 1,
        "content": "E is incorrect because Referral URL may be a null or empty value."
      },
      {
        "date": "2022-12-29T12:16:00.000Z",
        "voteCount": 3,
        "content": "BD are the right answer as E is double negative and therefore required."
      },
      {
        "date": "2022-12-28T08:30:00.000Z",
        "voteCount": 1,
        "content": "D &amp; E \n\nRemoving B would mean killing Top 10 external referrals to blog of all time since it requires that Traffic[URL visited] contains \"blog\". Option B removes all rows where Traffic[URL visited] contains \"blog\""
      },
      {
        "date": "2023-03-29T00:26:00.000Z",
        "voteCount": 1,
        "content": "Does Not contain!"
      },
      {
        "date": "2022-12-29T00:55:00.000Z",
        "voteCount": 6,
        "content": "you should read every sentence again.\n B removes all rows where Traffic[URL visited]  NOT contains \"blog\". ----&gt; Therefore B is true. \nAnd E, we NEED the rows which DONT contain \"/\", so why remove these rows?"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 47,
    "url": "https://www.examtopics.com/discussions/microsoft/view/94711-exam-pl-300-topic-2-question-47-discussion/",
    "body": "HOTSPOT<br> -<br><br>You are creating a quick measure as shown in the following exhibit.<br><br><img src=\"https://img.examtopics.com/pl-300/image287.png\"><br><br>You need to create a monthly rolling average measure for Sales over time.<br><br>How should you configure the quick measure calculation? To answer, select the appropriate options in the answer area.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/pl-300/image288.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/pl-300/image289.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2023-01-10T11:33:00.000Z",
        "voteCount": 47,
        "content": "Corect Answer.\n1. Total Sales;\n2. Date;\n3. Months"
      },
      {
        "date": "2023-10-04T07:40:00.000Z",
        "voteCount": 13,
        "content": "This was in the exam this week."
      },
      {
        "date": "2024-08-19T01:23:00.000Z",
        "voteCount": 1,
        "content": "The answer is correct: Total Sales, Date, Months"
      },
      {
        "date": "2023-07-03T04:51:00.000Z",
        "voteCount": 6,
        "content": "Total Sales, Date, Months"
      },
      {
        "date": "2023-05-02T07:35:00.000Z",
        "voteCount": 2,
        "content": "Answer is correct."
      },
      {
        "date": "2023-04-27T06:11:00.000Z",
        "voteCount": 1,
        "content": "Answer is correct"
      },
      {
        "date": "2023-01-15T08:14:00.000Z",
        "voteCount": 4,
        "content": "Correct"
      },
      {
        "date": "2023-01-12T00:01:00.000Z",
        "voteCount": 3,
        "content": "Correct answer"
      },
      {
        "date": "2023-01-10T15:56:00.000Z",
        "voteCount": 4,
        "content": "Assuming we evaluate total sales then answer si correct"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 48,
    "url": "https://www.examtopics.com/discussions/microsoft/view/94713-exam-pl-300-topic-2-question-48-discussion/",
    "body": "You have the Power BI data model shown in the following exhibit.<br><br><img src=\"https://img.examtopics.com/pl-300/image290.png\"><br><br>The Sales table contains records of sales by day from the last five years up until today\u2019s date.<br><br>You plan to create a measure to return the total sales of March 2021 when March 2022 is selected.<br><br>Which DAX expression should you use?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCalculate (Sum(Sales[Sales]), PREVIOUSYEAR( dimDate[Date])",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tTOTALYTD (SUM(Sales[Sales]), dimDate[Date] )",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCalculate (SUM(Sales[Sales]), SAMEPERIODLASTYEAR(dimDate[Date] ))\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSUM(Sales[Sales])"
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 31,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-07-12T13:30:00.000Z",
        "voteCount": 8,
        "content": "Correct"
      },
      {
        "date": "2023-01-11T08:21:00.000Z",
        "voteCount": 6,
        "content": "Yup! answer is correct!"
      },
      {
        "date": "2024-02-25T22:38:00.000Z",
        "voteCount": 3,
        "content": "Copy-pasted from MS forum: \n\nPreviousyear: This function returns all dates from the previous year given the latest date in the input parameter. For example, if the latest date in the dates argument refers to the year 2009, then this function returns all dates for the year of 2008, up to the specified year_end_date.\n\n \n\nSAMEPERIODLASTYEAR: Returns a table that contains a column of dates shifted one year back in time from the dates in the specified dates column, in the current context."
      },
      {
        "date": "2023-11-01T07:20:00.000Z",
        "voteCount": 4,
        "content": "A is wrong because of wrong syntax. The close bracket at the end is missing"
      },
      {
        "date": "2023-07-11T13:07:00.000Z",
        "voteCount": 2,
        "content": "I tested it in the Power Bi. A and C both give the same result so I think A and C are both correct."
      },
      {
        "date": "2023-07-20T13:20:00.000Z",
        "voteCount": 7,
        "content": "A is not correct. \nPREVIOUSYEAR will generate the date from the whole previous year, which means that if your current context is only about 3 months, you're getting a 12 months (from previous year) context, and comparing 3 months with 12 months is nonsense"
      },
      {
        "date": "2023-09-18T05:23:00.000Z",
        "voteCount": 1,
        "content": "PREVIOUSYEAR calculates the cumulative till the year"
      },
      {
        "date": "2023-06-14T01:59:00.000Z",
        "voteCount": 4,
        "content": "Why not A?"
      },
      {
        "date": "2023-07-13T12:34:00.000Z",
        "voteCount": 13,
        "content": "\"PREVIOUSYEAR: Returns a table that contains a column of all dates from the previous year, given the last date in the dates column, in the current context.\"\nThis means, if my date data ranges from 2007/08/05 -2007/09/05. The last date in this column is 2007/09/05. The returned column would be 365 date from 2006/01/01 to 2006/12/31.\nfor  SAMEPERIODLASTYEAR, the result would only be 2006/08/05 -2006/09/05"
      },
      {
        "date": "2023-05-25T02:48:00.000Z",
        "voteCount": 3,
        "content": "Correct answer given"
      },
      {
        "date": "2023-05-02T07:37:00.000Z",
        "voteCount": 4,
        "content": "The Given answer is correct."
      },
      {
        "date": "2023-04-16T07:58:00.000Z",
        "voteCount": 2,
        "content": "That's correct: C"
      },
      {
        "date": "2023-04-16T05:11:00.000Z",
        "voteCount": 1,
        "content": "C is Correct!"
      },
      {
        "date": "2023-04-12T05:01:00.000Z",
        "voteCount": 3,
        "content": "Yup! answer is correct!"
      },
      {
        "date": "2023-04-07T06:57:00.000Z",
        "voteCount": 1,
        "content": "That is correct only"
      },
      {
        "date": "2023-01-27T00:28:00.000Z",
        "voteCount": 1,
        "content": "Correct Ans!!"
      },
      {
        "date": "2023-01-25T11:35:00.000Z",
        "voteCount": 2,
        "content": "C Correct"
      },
      {
        "date": "2023-01-15T08:15:00.000Z",
        "voteCount": 2,
        "content": "C Correct"
      },
      {
        "date": "2023-01-12T00:02:00.000Z",
        "voteCount": 2,
        "content": "Correct answer"
      },
      {
        "date": "2023-01-10T16:17:00.000Z",
        "voteCount": 3,
        "content": "Correct answer"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 49,
    "url": "https://www.examtopics.com/discussions/microsoft/view/94820-exam-pl-300-topic-2-question-49-discussion/",
    "body": "You use Power BI Desktop to load data from a Microsoft SQL Server database.<br><br>While waiting for the data to load, you receive the following error.<br><br><img src=\"https://img.examtopics.com/pl-300/image292.png\"><br><br>You need to resolve the error.<br><br>What are two ways to achieve the goal? Each correct answer presents a complete solution.<br><br>NOTE: Each correct selection is worth one point.",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tReduce the number of rows and columns returned by each query.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSplit log running queries into subsets of columns and use Power Query to merge the queries.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse Power Query to combine log running queries into one query.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDisable query folding on long running queries."
    ],
    "answer": "AB",
    "answerDescription": "",
    "votes": [
      {
        "answer": "AB",
        "count": 28,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-02-26T16:20:00.000Z",
        "voteCount": 29,
        "content": "This link helps explain query timeout and how to work around it.\nhttps://learn.microsoft.com/en-us/training/modules/get-data/9-import-errors"
      },
      {
        "date": "2023-07-20T07:29:00.000Z",
        "voteCount": 13,
        "content": "AB"
      },
      {
        "date": "2023-08-14T01:27:00.000Z",
        "voteCount": 1,
        "content": "Hey have you gone through the questions after 22nd page"
      },
      {
        "date": "2024-08-20T10:16:00.000Z",
        "voteCount": 1,
        "content": "I'm not sure why A is marked as a correct answer - what if you needed all of those rows instead of arbitrarily filtering them out? Agree with B. C looked like it may have been part of the procedure achieved by B"
      },
      {
        "date": "2024-08-19T01:28:00.000Z",
        "voteCount": 1,
        "content": "A and B is the correct one: \n- Reduce the number of rows and columns returned by each query\n- Split log running queries into subsets of columns and use Power Query to merge the queries"
      },
      {
        "date": "2024-04-17T19:59:00.000Z",
        "voteCount": 2,
        "content": "Geee, I'm gonna do some \"log\" running today!  Wow, once again, I paid for this, be nice if someone proof read the questions.  Regardless, A and B are correct."
      },
      {
        "date": "2024-03-02T09:46:00.000Z",
        "voteCount": 1,
        "content": "B is correct\n\nSplitting date/time BEFORE loading to Power BI will increase the performance and not AFTER:\nSource: https://learn.microsoft.com/en-us/training/modules/get-data/8-performance-issues?ns-enrollment-type=learningpath&amp;ns-enrollment-id=learn-bizapps.data-preparation-in-power-bi\nIf any of your tables have columns that combine date and time, make sure that you separate them into distinct columns before importing them into Power BI."
      },
      {
        "date": "2024-01-13T14:28:00.000Z",
        "voteCount": 2,
        "content": "Question uses the phrase \"log running.\"  This is a mis-spelling.  It should be long running."
      },
      {
        "date": "2023-10-11T07:53:00.000Z",
        "voteCount": 1,
        "content": "A&amp;D for this question"
      },
      {
        "date": "2023-09-06T08:48:00.000Z",
        "voteCount": 2,
        "content": "A &amp; D are correct.\nA. By reducing the amount of data retrieved from the SQL server database, you can make the query execution more efficient and reduce the likelihood of encountering errors due to resource constraints.\nD. Query folding is a feature in power query that pushes some of the data transformation operations back to the data source (in this case, SQL server) for processing. Query folding can sometimes cause issues with long-running queries. \nB and C are not appropriate solutions for resolving the error related to long-running queries. These options focus on combining or splitting queries, which may not directly address the root cause of the issue."
      },
      {
        "date": "2023-05-02T07:40:00.000Z",
        "voteCount": 3,
        "content": "Given answer is correct."
      },
      {
        "date": "2023-04-12T05:04:00.000Z",
        "voteCount": 4,
        "content": "Exactly! The answer is correct.\nhttps://learn.microsoft.com/en-us/training/modules/get-data/9-import-errors"
      },
      {
        "date": "2023-03-17T18:31:00.000Z",
        "voteCount": 6,
        "content": "Disabling query folding on long running queries is not a recommended solution for resolving the error.\n\nQuery folding is an optimization technique used by Power Query to translate transformations into optimized SQL statements. Disabling query folding may lead to less optimized query execution plans, which could result in longer query execution times and higher resource consumption."
      },
      {
        "date": "2023-03-01T04:50:00.000Z",
        "voteCount": 2,
        "content": "seems ok"
      },
      {
        "date": "2023-01-21T04:55:00.000Z",
        "voteCount": 10,
        "content": "Can someone explain why AB are the correct answers?"
      },
      {
        "date": "2023-04-25T22:53:00.000Z",
        "voteCount": 23,
        "content": "A reduces the amount of results that you're getting back, therefore reduces query time, and reduces the chances of a timeout occuring.\nB basically does the same, and is a solution for when you really need al columns and rows: instead of getting one large table back, you'll get multiple smaller ones, then you can combine those after loading.\nC does exactly the opposite, making the resulting table even larger.\nD will not help either, as query folding basically expands on the 'select * from &lt;table&gt;' that Power BI fires to the database. It can, for instance, add a where-clause to that statement if you're filtering in Power Query. That also reduces query time.\nSource for query folding: https://learn.microsoft.com/en-us/power-query/power-query-folding"
      },
      {
        "date": "2023-01-15T08:16:00.000Z",
        "voteCount": 3,
        "content": "AB is correct"
      },
      {
        "date": "2023-01-12T00:03:00.000Z",
        "voteCount": 3,
        "content": "A &amp; B correct answer"
      },
      {
        "date": "2023-01-11T12:35:00.000Z",
        "voteCount": 1,
        "content": "AGRRREEEE"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 50,
    "url": "https://www.examtopics.com/discussions/microsoft/view/94716-exam-pl-300-topic-2-question-50-discussion/",
    "body": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.<br><br>After you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.<br><br>From Power Query Editor, you profile the data shown in the following exhibit.<br><br><img src=\"https://img.examtopics.com/pl-300/image291.png\"><br><br>The IoT GUID and IoT ID columns are unique to each row in the query.<br><br>You need to analyze IoT events by the hour and day of the year. The solution must improve dataset performance.<br><br>Solution: You split the IoT DateTime column into a column named Date and a column named Time.<br><br>Does this meet the goal?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tYes\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tNo"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 98,
        "isMostVoted": true
      },
      {
        "answer": "B",
        "count": 23,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2023-01-17T10:51:00.000Z",
        "voteCount": 64,
        "content": "The correct answer is A. Splitting datetime column will improve the perfomance even if it generates one more column, having less unique values in separated date and time columns will achieve better compression."
      },
      {
        "date": "2024-03-02T09:49:00.000Z",
        "voteCount": 5,
        "content": "Not after the data is loaded into Power BI.\nSplitting the date time BEFORE loading to PBI will improve performance"
      },
      {
        "date": "2023-01-10T11:46:00.000Z",
        "voteCount": 16,
        "content": "The correct answern is A. Bcause Split a datetime column improve the perfomance even if you will have one more column."
      },
      {
        "date": "2023-01-11T13:50:00.000Z",
        "voteCount": 3,
        "content": "Agree. A is the correct answer"
      },
      {
        "date": "2024-04-10T02:16:00.000Z",
        "voteCount": 2,
        "content": "If the analysis only requires the date part and the time part results in high cardinality without being used in the analysis, splitting will improve performance. If both date and time are necessary and are used together frequently in the analysis, splitting them might not provide a performance benefit and could even complicate measures and calculations."
      },
      {
        "date": "2024-03-07T09:10:00.000Z",
        "voteCount": 3,
        "content": "B is Right"
      },
      {
        "date": "2024-03-02T09:47:00.000Z",
        "voteCount": 2,
        "content": "B is correct \n\nplitting date/time BEFORE loading to Power BI will increase the performance and not AFTER:\nSource: https://learn.microsoft.com/en-us/training/modules/get-data/8-performance-issues?ns-enrollment-type=learningpath&amp;ns-enrollment-id=learn-bizapps.data-preparation-in-power-bi\nIf any of your tables have columns that combine date and time, make sure that you separate them into distinct columns before importing them into Power BI."
      },
      {
        "date": "2024-01-18T04:13:00.000Z",
        "voteCount": 4,
        "content": "But A is not a solution because you have to analyze IoT events by the hour and day of the year. When splitting the datetime you will get multiple equal values for time... Which should be aggregated right?"
      },
      {
        "date": "2024-01-07T06:28:00.000Z",
        "voteCount": 1,
        "content": "Splitting datetime column will improve but it's not enough. We can remove either IoT GUID or IoT ID column in addition."
      },
      {
        "date": "2023-12-07T14:49:00.000Z",
        "voteCount": 4,
        "content": "Yes, it will improve the performance, because splitting date-time will increase compression abilities. Reference:\nhttps://learn.microsoft.com/en-us/training/modules/get-data/8-performance-issues?ns-enrollment-type=learningpath&amp;ns-enrollment-id=learn-bizapps.data-preparation-in-power-bi\nReference 2:\nhttps://www.algorhythmblog.be/2022/08/02/time-to-split-are-datetimes-bogging-down-your-model/"
      },
      {
        "date": "2024-02-26T14:56:00.000Z",
        "voteCount": 2,
        "content": "I checked the your first Reference, your right. Here is what it said \"Separate date and time, if bound together. If any of your tables have columns that combine date and time, make sure that you separate them into distinct columns before importing them into Power BI. This approach will increase compression abilities.\""
      },
      {
        "date": "2023-11-21T20:05:00.000Z",
        "voteCount": 3,
        "content": "Google this \"You need to analyze IoT events by the hour and day of the year\" you'll find the same question and most correct answers are Yes."
      },
      {
        "date": "2023-11-06T22:55:00.000Z",
        "voteCount": 1,
        "content": "I am pretty sure that it should be A and not B, because according to many experts, splitting date and time will make the performance even better."
      },
      {
        "date": "2023-10-11T07:58:00.000Z",
        "voteCount": 1,
        "content": "I think the answer is B beacuse we need improve the dataseet performance, splitting or make a new column will make it slower."
      },
      {
        "date": "2024-03-22T21:55:00.000Z",
        "voteCount": 1,
        "content": "No. Splitting the column will reduces the amount of result. Hence, increase the query performance."
      },
      {
        "date": "2024-03-22T21:57:00.000Z",
        "voteCount": 1,
        "content": "And the question requires an analyzation of both HOUR and DATE. In able to do that, we need split the column into both to allow a separate analyzation."
      },
      {
        "date": "2023-10-29T09:13:00.000Z",
        "voteCount": 3,
        "content": "in this case nop"
      },
      {
        "date": "2023-09-27T05:18:00.000Z",
        "voteCount": 1,
        "content": "There is an error guys \"A\" is 85% correct"
      },
      {
        "date": "2023-09-18T05:46:00.000Z",
        "voteCount": 2,
        "content": "It actually will decrease a cardinality by improving the performance so answer is A"
      },
      {
        "date": "2023-09-06T08:57:00.000Z",
        "voteCount": 5,
        "content": "B is correct.\nIt is because the proposed solution does not improve dataset performance in this context, it focuses on splitting the DateTime column into Date and Time without addressing the desired analysis."
      },
      {
        "date": "2023-08-23T02:37:00.000Z",
        "voteCount": 4,
        "content": "A is correct and here's a technical answer to it:\nhttps://www.algorhythmblog.be/2022/08/02/time-to-split-are-datetimes-bogging-down-your-model/"
      },
      {
        "date": "2023-08-01T03:43:00.000Z",
        "voteCount": 9,
        "content": "why is everyone's focus only on improving the dataset. the question is in 2 parts. \n- analyze the IoT events based on DAY &amp; HOURS. \n- solution must improve dataset performance. \n\nthe IoT date time column doesn't have DAY values. so by just splitting date&amp; time, it wont meet our solution. \nhence correct answer is B.No"
      },
      {
        "date": "2024-02-29T02:57:00.000Z",
        "voteCount": 3,
        "content": "wrong; IoTdate time column is expressed in dd/mm/yyyy hh:mm:ss format. Furthermore when you split that field PBI automatically builds a date hierarchy thus improving performances as you can directly use the DAY part of the hierarchy. You can even categorize your columns yourself if needed"
      },
      {
        "date": "2023-07-21T02:57:00.000Z",
        "voteCount": 1,
        "content": "A is the correct answer"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 51,
    "url": "https://www.examtopics.com/discussions/microsoft/view/94717-exam-pl-300-topic-2-question-51-discussion/",
    "body": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.<br><br>After you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.<br><br>From Power Query Editor, you profile the data shown in the following exhibit.<br><br><img src=\"https://img.examtopics.com/pl-300/image291.png\"><br><br>The IoT GUID and IoT ID columns are unique to each row in the query.<br><br>You need to analyze IoT events by the hour and day of the year. The solution must improve dataset performance.<br><br>Solution: You remove the IoT GUID column and retain the IoT ID column.<br><br>Does this meet the goal?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tYes\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tNo"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 75,
        "isMostVoted": true
      },
      {
        "answer": "B",
        "count": 24,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2023-05-03T13:08:00.000Z",
        "voteCount": 47,
        "content": "There are two requirements to the question - improve the performance and enable the required analysis.  Removing the GUID column will do exactly that - it will improve the performance because it is one less column of data to load but it still enables the required analysis given the IOT ID column is equally unique."
      },
      {
        "date": "2023-12-10T01:01:00.000Z",
        "voteCount": 2,
        "content": "correct"
      },
      {
        "date": "2023-03-09T01:43:00.000Z",
        "voteCount": 29,
        "content": "Chatgpt: B. No, removing the IoT GUID column and retaining the IoT ID column will not meet the goal of analyzing IoT events by the hour and day of the year. The IoT GUID and IoT ID columns are both unique identifiers for each row in the query, and removing either of them would result in losing important information about each event. In order to analyze events by the hour and day of the year, it is necessary to split the DateTime column into separate Date and Time columns, as well as retaining the unique identifiers for each event. Removing the IoT GUID column would not improve dataset performance, as it does not have any impact on the analysis or querying of the data."
      },
      {
        "date": "2023-04-22T21:45:00.000Z",
        "voteCount": 47,
        "content": "This is wrong. The database uses the GUID for performance but PowerBI does not. Power BI only needs one unique column to perform so eliminating the GUID reduces the dataset size and consequently, the performance of PowerBI.\nChatGPT is very good at confidently giving wrong answers, smart people know to do their own verification."
      },
      {
        "date": "2024-02-27T06:24:00.000Z",
        "voteCount": 5,
        "content": "Do not trust chatgpt bindly"
      },
      {
        "date": "2023-07-23T18:40:00.000Z",
        "voteCount": 7,
        "content": "You're only addressing performance and missing the second part where the events need to analysed by day of the year and hour."
      },
      {
        "date": "2023-10-02T05:04:00.000Z",
        "voteCount": 2,
        "content": "In my understanding of the question, we are only supposed to increase performance (without affecting the analysis). So removing the GUID column will increase performance without affecting analysis, and is therefore a sorrect solution."
      },
      {
        "date": "2024-02-01T02:32:00.000Z",
        "voteCount": 2,
        "content": "you understanding wrong, it clearly says analyze by hour and day of the year. Given solution only improves performance, you are still not able to do the analysis. You either need to create a calculated column for time, or split the column(best option)."
      },
      {
        "date": "2024-03-22T22:05:00.000Z",
        "voteCount": 2,
        "content": "I dont think so. Having IoT ID only already contribute to a unique row. In PowerBI we are able to add index column by the end of the table. Its possible for the user in this question to add his own unique identifier (index) by taking both IoT GUID and IoT DateTime as their unique reference.\n\nHence, since we only want to analyze the DateTime while ensuring a good performance quality, we DO NOT NEED IoT GUID."
      },
      {
        "date": "2023-04-04T02:29:00.000Z",
        "voteCount": 5,
        "content": "Agree!   The IoT GUID and IoT ID columns are keys columns  and removing either of them would result in losing important information!"
      },
      {
        "date": "2023-08-02T16:33:00.000Z",
        "voteCount": 2,
        "content": "They are independently unique, they are not a composite key made of up both to be unique."
      },
      {
        "date": "2023-08-07T07:36:00.000Z",
        "voteCount": 1,
        "content": "They can be made compsite keys though due to their uniquesness."
      },
      {
        "date": "2023-04-25T23:06:00.000Z",
        "voteCount": 16,
        "content": "But if they are *both* unique for each event, then removing one of them still allows you to identify events. Moreover, you could even remove both if aggregating on the date column (e.g. with a count column)."
      },
      {
        "date": "2024-02-29T03:09:00.000Z",
        "voteCount": 1,
        "content": "it says : The IoT GUID and IoT ID columns are unique to each row in the query.\nBOTH UNIQUES to EACH row...\n\nSo basically each one can be used as primary key for the table.\nremoving the guid column does improve performance.\nBetter to remove the guid because it 's a 16-byte binary data type compared to a unsigned long which is a 4-byte binary data type"
      },
      {
        "date": "2024-02-23T07:39:00.000Z",
        "voteCount": 1,
        "content": "Agree! The IoT GUID and IoT ID columns are keys columns and removing either of them would result in losing important information!"
      },
      {
        "date": "2024-02-21T08:25:00.000Z",
        "voteCount": 1,
        "content": "Answer should be NO..."
      },
      {
        "date": "2023-12-19T22:28:00.000Z",
        "voteCount": 2,
        "content": "Yes-A is correct."
      },
      {
        "date": "2023-11-10T02:30:00.000Z",
        "voteCount": 4,
        "content": "The goal is to analyze IoT events by the hour and day of the year.\nThe A answer doesn't meet that goal."
      },
      {
        "date": "2023-10-16T10:26:00.000Z",
        "voteCount": 1,
        "content": "YES (no data loss and removing one  primary key column (as we have 2 here) will help in performance)"
      },
      {
        "date": "2023-09-06T09:06:00.000Z",
        "voteCount": 2,
        "content": "B is correct.\nRemoving the loT GUID column and retaining the loT ID column will not directly help in analyzing loT events by the hour and day of the year."
      },
      {
        "date": "2023-08-02T16:35:00.000Z",
        "voteCount": 2,
        "content": "A. here is the one thing that many are saying \"they have to be able to do the analysis\". Thats implied already. No where does it say that the solution makes that possible. It says they need to do that AND the solution must make it more performant. Since its clear they can already do that (as there is nothing you can select to change that just by increasing performance), then removing a column would in fact increase performance, regardless if splitting etc would be more performant."
      },
      {
        "date": "2023-07-23T18:49:00.000Z",
        "voteCount": 5,
        "content": "There has to be a date column and a time column to perform the analysis by day of the year and by hour. Removing IoT GUID doesn't solve that, it only improves performance but so does splitting the date column. Previous question was YES, this one is NO."
      },
      {
        "date": "2023-07-21T03:04:00.000Z",
        "voteCount": 3,
        "content": "A because we the ID column can server the purpose of the analysis"
      },
      {
        "date": "2023-07-15T06:05:00.000Z",
        "voteCount": 4,
        "content": "The answer is Yes, having two primary keys in a table is not the best practice."
      },
      {
        "date": "2023-06-10T01:24:00.000Z",
        "voteCount": 4,
        "content": "Answer is Yes. This GUID columns is not necessary as the other column plays the role of Id column. As it is a large text column, removing it will significantly reduce the size of the model, thus increase performance"
      },
      {
        "date": "2023-05-26T22:31:00.000Z",
        "voteCount": 2,
        "content": "IoT GUID column is string the other column is number"
      },
      {
        "date": "2023-05-26T22:30:00.000Z",
        "voteCount": 2,
        "content": "the best way is to remove the IoT GUID column because it's string identifier of table the other column is number witch improve the performance the answer is Yes"
      },
      {
        "date": "2023-05-25T03:00:00.000Z",
        "voteCount": 5,
        "content": "Guys what is the answer .."
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 52,
    "url": "https://www.examtopics.com/discussions/microsoft/view/94718-exam-pl-300-topic-2-question-52-discussion/",
    "body": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.<br><br>After you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.<br><br>From Power Query Editor, you profile the data shown in the following exhibit.<br><br><img src=\"https://img.examtopics.com/pl-300/image291.png\"><br><br>The IoT GUID and IoT ID columns are unique to each row in the query.<br><br>You need to analyze IoT events by the hour and day of the year. The solution must improve dataset performance.<br><br>Solution: You change the IoT DateTime column to the Date data type.<br><br>Does this meet the goal?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tYes",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tNo\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 38,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-01-10T11:49:00.000Z",
        "voteCount": 19,
        "content": "Agreeded. Bcause, if you just transform the data type you will not be able to analyse the information by time, as requested."
      },
      {
        "date": "2023-12-10T01:01:00.000Z",
        "voteCount": 2,
        "content": "agreed"
      },
      {
        "date": "2023-06-11T06:32:00.000Z",
        "voteCount": 5,
        "content": "You need to analyse by hour. If you change to date you remove the time"
      },
      {
        "date": "2024-08-19T01:31:00.000Z",
        "voteCount": 1,
        "content": "No, we need the time in the analysis"
      },
      {
        "date": "2023-12-19T22:25:00.000Z",
        "voteCount": 3,
        "content": "If you change data type to Date only, you will lose the data (time)."
      },
      {
        "date": "2023-11-28T10:15:00.000Z",
        "voteCount": 1,
        "content": "I believe wthout splitting datatime to date and time, you can still be able to analyse IoT events by the hour and day of the year"
      },
      {
        "date": "2023-09-06T09:11:00.000Z",
        "voteCount": 2,
        "content": "B is correct. \nConverting it to the date data type would only allow you to work with dates, but it wouldn't provide the necessary granularity to analyze events by the hour or day of the year."
      },
      {
        "date": "2023-05-26T22:35:00.000Z",
        "voteCount": 1,
        "content": "il you change the data type you will not be able to analyse by hour"
      },
      {
        "date": "2023-04-12T05:10:00.000Z",
        "voteCount": 2,
        "content": "The answer is B because the instruction says to analyze based on date and time. Changing the IoT date column to the date data type takes out the time needed for the analyses."
      },
      {
        "date": "2023-01-12T02:55:00.000Z",
        "voteCount": 1,
        "content": "B is correct"
      },
      {
        "date": "2023-01-11T08:39:00.000Z",
        "voteCount": 4,
        "content": "B is correct because changing the IoT DateTime column to the Date data type alone will not meet the goal of analyzing IoT events by the hour and day of the year in power query."
      },
      {
        "date": "2023-01-11T08:38:00.000Z",
        "voteCount": 2,
        "content": "The answer is B because the instruction says to analyze based on date and time. Changing the IoT date column to the date data type takes out the time needed for the analyses."
      },
      {
        "date": "2023-01-11T07:54:00.000Z",
        "voteCount": 3,
        "content": "B. because the column has both data and time values"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 53,
    "url": "https://www.examtopics.com/discussions/microsoft/view/94719-exam-pl-300-topic-2-question-53-discussion/",
    "body": "You have a Microsoft Power BI report. The size of PBIX file is 550 MB. The report is accessed by using an App workspace in shared capacity of powerbi.com.<br><br>The report uses an imported dataset that contains one fact table. The fact table contains 12 million rows. The dataset is scheduled to refresh twice a day at 08:00 and 17:00.<br><br>The report is a single page that contains 15 AppSource visuals and 10 default visuals.<br><br>Users say that the report is slow to load the visuals when they access and interact with the report.<br><br>You need to recommend a solution to improve the performance of the report.<br><br>What should you recommend?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tChange any DAX measures to use iterator functions.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRemove unused columns from tables in the data model.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tReplace the default visuals with AppSource visuals.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tIncrease the number of times that the dataset is refreshed."
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 24,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-01-10T11:52:00.000Z",
        "voteCount": 14,
        "content": "Dropping unnecessary columns to reduce the data model is indeed a better way to improve query and refresh performance."
      },
      {
        "date": "2023-01-11T13:53:00.000Z",
        "voteCount": 4,
        "content": "To me the only correct answer is A. B is wrong because you just reduce the dimension of the dataset but you are not improving the performance and the time needed to load the visualization. correct answer is A"
      },
      {
        "date": "2023-04-25T23:27:00.000Z",
        "voteCount": 5,
        "content": "B is correct, because this will also help for visuals: \"A smaller sized data model uses less resources (memory) and achieves faster data refresh, calculations, and rendering of visuals in reports.\"\nSource: https://learn.microsoft.com/en-us/training/modules/optimize-model-power-bi/1-introduction"
      },
      {
        "date": "2023-08-02T16:38:00.000Z",
        "voteCount": 1,
        "content": "Also image there are 15 unused columns that are being loaded. Since they don't give you a specific number, it could be 0,1 or 100. But its the one thing that for sure would increase performance."
      },
      {
        "date": "2023-11-06T14:33:00.000Z",
        "voteCount": 1,
        "content": "Iterator functions are used for some scenarios, but don't assume that all visuals need them. In this case, it is not even stated the need for iterator functions. So I'd say, A is wrong since its effect for this question is ambiguous."
      },
      {
        "date": "2024-08-19T01:32:00.000Z",
        "voteCount": 1,
        "content": "B. Remove unused columns from tables in the data model.\nIt makes sense to remove unused columns from the tables in the model if they are not required in the analysis"
      },
      {
        "date": "2023-09-06T09:17:00.000Z",
        "voteCount": 1,
        "content": "B is correct.\nBy removing columns that are not needed for the report, you can reduce the size of the data model. This can lead to faster loading times, especially when dealing with large datasets. Unused columns contribute to unnecessary overhead and can impact performance."
      },
      {
        "date": "2023-08-20T07:01:00.000Z",
        "voteCount": 2,
        "content": "B is correct."
      },
      {
        "date": "2023-05-26T22:38:00.000Z",
        "voteCount": 2,
        "content": "dropping unused columns may improve the performance"
      },
      {
        "date": "2023-04-12T05:11:00.000Z",
        "voteCount": 3,
        "content": "Dropping unnecessary columns to reduce the data model is indeed a better way to improve query and refresh performance."
      },
      {
        "date": "2023-01-15T08:31:00.000Z",
        "voteCount": 2,
        "content": "B, it's always good for performance to remove unused columns"
      },
      {
        "date": "2023-01-12T02:58:00.000Z",
        "voteCount": 2,
        "content": "B is correct. from performance point of view its always good to drop unwanted columns. Avoid complicated DAX and iterator functions as much as possible"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 54,
    "url": "https://www.examtopics.com/discussions/microsoft/view/94648-exam-pl-300-topic-2-question-54-discussion/",
    "body": "DRAG DROP<br> -<br><br>You have a Power BI data model that contains two tables named Products and Sales.<br><br>A one-to-many relationship exists between the tables.<br><br>You have a report that contains a report-level filter for Products.<br><br>You need to create a measure that will return the percent of total sales for each product. The measure must respect the report-level filter when calculating the total.<br><br>How should you complete the DAX measure? To answer, drag the appropriate DAX functions to the correct targets. Each function may be used once, more than once, or not at all. You may need to drag the split bar between panes or scroll to view content.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/pl-300/image293.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/pl-300/image294.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2023-01-10T11:56:00.000Z",
        "voteCount": 107,
        "content": "Incorrect answer.\n\n1.Calculate\n2. ALLSELECTED.\n\nALLSELECTED Removes only the filter on the expression visual but respect all external filters."
      },
      {
        "date": "2023-04-09T23:00:00.000Z",
        "voteCount": 9,
        "content": "ALLSELECTED is correct. ALLSELECTED: Returns all the rows in a table, or all the values in a column, ignoring any filters that may have been applied inside the query, but keeping filters that come from the outside.\nhttps://mitchellpearson.com/2020/09/14/understanding-row-context-in-dax-and-power-bi/#:~:text=ALLSELECTED%20DAX%20functions,coming%20from%20the%20inner%20query."
      },
      {
        "date": "2023-03-05T07:33:00.000Z",
        "voteCount": 22,
        "content": "ALLSELECTED IS WRONG. THE CORRECT ANSWER IS ALL, BECAUSE WE NEED THE TOTAL SALES IN DIVISOR, AND ONLY FILTERED PRODUCTS IN NUMERATOR. I TESTED IN POWER BI AND ALL WORKS FINE FOR ME."
      },
      {
        "date": "2023-04-25T23:53:00.000Z",
        "voteCount": 21,
        "content": "No, ALL() will remove the report filter"
      },
      {
        "date": "2023-07-27T00:28:00.000Z",
        "voteCount": 2,
        "content": "that what he's doing in order to get all sales. Have you even tried what you're saying?"
      },
      {
        "date": "2023-08-16T04:46:00.000Z",
        "voteCount": 2,
        "content": "ALL indeed removes/disregards the report filter. I tried both in one table, and the ALL option gave lower percentages for Products than the ALLSELECTED way, because ALL considers all Products while calculating the percentage."
      },
      {
        "date": "2024-02-27T06:38:00.000Z",
        "voteCount": 1,
        "content": "All is not good if you want to have some filters"
      },
      {
        "date": "2023-07-16T01:30:00.000Z",
        "voteCount": 2,
        "content": "Correct."
      },
      {
        "date": "2023-02-21T15:34:00.000Z",
        "voteCount": 29,
        "content": "The tricky thing here is that the report contains a report-level filter for Products and you need to calculate all sales (for all products) for the divisor. So I'll share here both functions definition from dax.guide:\n\nALLSELECTED: Returns all the rows in a table, or all the values in a column, ignoring any filters that might have been applied inside the query, but keeping filters that come from outside.\n\nALL: Returns all the rows in a table, or all the values in a column, ignoring any filters that might have been applied.\n\nSo, for me the correct answer is CALCULATE &amp; ALL"
      },
      {
        "date": "2023-07-11T15:26:00.000Z",
        "voteCount": 10,
        "content": "I think you are wrong, the answer should be \"ALLSelected\" instead of \"ALL\". Lets think about the difference here: \"ALLSelected\" takes consider of external filter (here we have a report-level filter as we are filtering products to check their sales percentage), while \"ALL\" ingnores all filters. \nI also tested out a toy dataset in Power BI. Say I have four products, each makes up 25% of total sales. If we use \"ALL\" DAX and choose product A&amp;B in the filter, we will see A and B both make up 25% of total sales, but instead what we want is \"ALLSELECT\" DAX which gives us A and B both makes up 50% of total sales, this meets the question requirement of \"respect the report-level filter\"."
      },
      {
        "date": "2023-03-01T01:24:00.000Z",
        "voteCount": 16,
        "content": "\"The measure must respect the report-level filter when calculating the total\" so shouldn't it be ALLSELECTED?"
      },
      {
        "date": "2024-09-03T15:15:00.000Z",
        "voteCount": 1,
        "content": "Must be ALLSELECTED as one of the requirements is \"The measure must respect the report-level filter when calculating the total\" ALL is wrong as it ignores any filters."
      },
      {
        "date": "2024-08-21T02:13:00.000Z",
        "voteCount": 1,
        "content": "For sure we have:\n1 - CALCULATE\n2 - ALL or ALLSELECTED but IDK which one :("
      },
      {
        "date": "2024-06-06T05:08:00.000Z",
        "voteCount": 1,
        "content": "Use ALL and not ALLSELECTED, as ALL does not respect filters at report level, whereas ALLSELECTED respects them with the exception of the selected column."
      },
      {
        "date": "2024-04-26T12:06:00.000Z",
        "voteCount": 1,
        "content": "I prefer ALL over ALLSELECTED here because the name of the VAR is for all sales instead of all selected cells, I guess the intention is to have a denominator which includes all products and disregard the visual level filter, so ALL is more appropriate than ALLSELECTED here. By the way, both functions respect page and report-level filter."
      },
      {
        "date": "2024-03-28T01:26:00.000Z",
        "voteCount": 3,
        "content": "- Calculate\n- ALLSELECTED\nCould be:\n% of productcode sales = \nVAR productCode = SUM(Sales[Revenue])\nVAR AllSales = CALCULATE(SUM(Sales[Revenue]), ALLSELECTED('Product'[Product Code]))\nRETURN\nDIVIDE( productCode , AllSales)"
      },
      {
        "date": "2024-03-19T16:20:00.000Z",
        "voteCount": 2,
        "content": "All &amp; Allselected are both fine. I'm currently studying for PL-300 and I've been going around for this one... I've just tested it and here's what I've learned.\nIf the function would have been: Calculate(Sales, ........ ('Products')) then ALLSELECTED is 100% the right choice. But since we are filtering only a column ('Products'[Product]) we can use either ALL or ALLSELECTED. Go ahead and test it on a small report, you'll se how it works. I really hope microsoft takes both answers as correct cause I've been thinking and testing for a while to realise about this."
      },
      {
        "date": "2024-03-07T09:37:00.000Z",
        "voteCount": 1,
        "content": "Calculate and Allselected because the question is to respect the report level/external filter wile calculating TOTAL SALES. Allselected() helps us to keep visual selected or filter level context"
      },
      {
        "date": "2024-03-03T08:14:00.000Z",
        "voteCount": 2,
        "content": "ALLSELECTED is the correct answer, "
      },
      {
        "date": "2024-02-21T06:53:00.000Z",
        "voteCount": 3,
        "content": "Based on DAX definitions:\nALL :useful for CLEARING filters and creating calculations on all the rows in a table.\n(https://learn.microsoft.com/en-us/dax/all-function-dax)\n\nALLSELECTED: gets the context that represents all rows and columns in the query, while KEEPING EXPLICIT FILTERS and contexts other than row and column filters. This function can be used to obtain visual totals in queries.\n(https://learn.microsoft.com/en-us/dax/allselected-function-dax)\n\nALLSELECTED applies to one context(one visual)\nALL : if clearing means what it means, you will have no filters anymore\n\nSo for me : \nCALCULATE \nALLSELECTED"
      },
      {
        "date": "2024-02-02T01:40:00.000Z",
        "voteCount": 2,
        "content": "CALCULATE and ALLSELECTED. \nUse of all selected will show Sales % based on the selected Products in a Slicer. This is instead of showing sales % across all products"
      },
      {
        "date": "2024-01-30T17:57:00.000Z",
        "voteCount": 2,
        "content": "Calculate ,ALL"
      },
      {
        "date": "2024-01-10T20:26:00.000Z",
        "voteCount": 1,
        "content": "AllSales measure is used as a denominator when calculating percentages, so i think it should include all sales data and the answer should be:\n\nCALCULATE\nALL"
      },
      {
        "date": "2024-01-23T09:44:00.000Z",
        "voteCount": 3,
        "content": "using ALL() will not respect the report-level filters. ALLSELECTED() will respect report-level filters. Since the solution must respect report-level filters, I believe we should use ALLSELECTED()."
      },
      {
        "date": "2024-01-07T04:58:00.000Z",
        "voteCount": 1,
        "content": "Percent of Selected Product Sales =\nVAR SelectedProductSales = SUM('Sales'[Sales])\nVAR TotalSalesAllProducts = \n    CALCULATE(\n        SUM('Sales'[Sales]),\n        ALL('Products'[Product])\n    )\nRETURN\n    DIVIDE(SelectedProductSales, TotalSalesAllProducts)\n\n\nAll will only work on product column while respecting the slicers from other columns, this is what is required in the question"
      },
      {
        "date": "2024-01-03T14:42:00.000Z",
        "voteCount": 1,
        "content": "because you need all sales, you will have to remove filters. the options are removefilters or All.\nthe correct answer is Calculate, All"
      },
      {
        "date": "2023-12-27T04:43:00.000Z",
        "voteCount": 2,
        "content": "Correct Answer is \nCALCULATE \nALLSELECTED\n.There is a narrow line of difference between ALL and ALLSELECTED and that is \nALLSELECTED don't ignore Report level Filters which is the key requirement here if you read the question. \nWhereas ALL ignores any level of filter whether it is outside or inside."
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 55,
    "url": "https://www.examtopics.com/discussions/microsoft/view/94720-exam-pl-300-topic-2-question-55-discussion/",
    "body": "You have a Power BI data model that analyzes product sales over time. The data model contains the following tables.<br><br><img src=\"https://img.examtopics.com/pl-300/image295.png\"><br><br>A one-to-many relationship exists between the tables.<br><br>The auto date/time option for the data model is enabled.<br><br>You need to reduce the size of the data model while maintaining the ability to analyze product sales by month and quarter.<br><br>Which two actions should you perform? Each correct answer presents part of the solution.<br><br>NOTE: Each correct answer is worth one point.",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a relationship between the Date table and the Sales table.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDisable the auto date/time option.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a Date table and select Mark as Date Table.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDisable the load on the Date table.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRemove the relationship between the Product table and the Sales table."
    ],
    "answer": "AC",
    "answerDescription": "",
    "votes": [
      {
        "answer": "AC",
        "count": 75,
        "isMostVoted": true
      },
      {
        "answer": "BC",
        "count": 9,
        "isMostVoted": false
      },
      {
        "answer": "AB",
        "count": 2,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2023-02-17T11:04:00.000Z",
        "voteCount": 53,
        "content": "AC is the correct answer. According to https://learn.microsoft.com/en-us/power-bi/transform-model/desktop-date-tables, marking a table as a Date Table automatically removes the auto-generated date table."
      },
      {
        "date": "2024-03-07T23:57:00.000Z",
        "voteCount": 1,
        "content": "thanks dude ! i didnt knew this i was manually disabling the auto generated date table"
      },
      {
        "date": "2023-11-06T15:39:00.000Z",
        "voteCount": 3,
        "content": "Woah, thanks for sharing!"
      },
      {
        "date": "2023-08-20T06:11:00.000Z",
        "voteCount": 2,
        "content": "Thank you, learnt something new"
      },
      {
        "date": "2023-04-29T23:26:00.000Z",
        "voteCount": 9,
        "content": "This is the tricky question. If I could, I would go with A, B and C. \nAs, first, you'll need to create a date table and mark it as the Date Table. Second you'll need to create the relationship between this table and the Sales table. And lastly, you will need to disable auto date and time option, as per this article, it will decrease the model size.\n\nOption A and C does not decrease the model size.\nMarking a table as a Date table does not automatically remove the auto-hierarchies in other tables, which makes your data model bigger, so you DO need to disable the auto date/time option."
      },
      {
        "date": "2024-08-21T13:54:00.000Z",
        "voteCount": 1,
        "content": "Yesss dude....my thoughts exactly! I chose B and C as a result, knowing that it would be incomplete without creating the relationship (A)"
      },
      {
        "date": "2023-09-21T20:28:00.000Z",
        "voteCount": 5,
        "content": "That last part is not aligned to what Microsoft says. Per https://learn.microsoft.com/en-us/power-bi/transform-model/desktop-date-tables#set-your-own-date-table, \"when you mark a table as a date table, Power BI Desktop removes the built-in (automatically created) date table\""
      },
      {
        "date": "2024-10-16T08:02:00.000Z",
        "voteCount": 1,
        "content": "BC:  When you mark a Date table you don't need to create a relationship to work with DAX time intelligence. Only for filtering you need to create relationships."
      },
      {
        "date": "2024-08-23T06:08:00.000Z",
        "voteCount": 1,
        "content": "A and C:\nSmaller Model Size: By using a custom date table, you avoid the need for multiple auto-generated date tables that Power BI creates by default for each date column in your dataset, leading to a smaller, more efficient model."
      },
      {
        "date": "2024-08-21T13:55:00.000Z",
        "voteCount": 1,
        "content": "I chose B and C as a result, knowing that it would be incomplete without creating the relationship (A) but choosing B would reduce the model size while still getting halfway to the required analysis stage."
      },
      {
        "date": "2024-08-19T01:41:00.000Z",
        "voteCount": 1,
        "content": "It does make sense B and C, but in order to optimize query performances also B (Disable the auto date/time option) should be correct, right?"
      },
      {
        "date": "2024-08-21T02:15:00.000Z",
        "voteCount": 1,
        "content": "I changed my mind, in my opinion it is AC"
      },
      {
        "date": "2024-03-19T15:29:00.000Z",
        "voteCount": 1,
        "content": "Correct"
      },
      {
        "date": "2024-02-01T02:52:00.000Z",
        "voteCount": 4,
        "content": "The answer is BC, AC will not reduce the model size. BC on the other will reduce the model size since you disable auto date/time, and when you mark the date table as the date table the relationship will become automatic, there is no obligation to connect them to do the analysis."
      },
      {
        "date": "2024-02-01T03:05:00.000Z",
        "voteCount": 1,
        "content": "ok I was wrong, marking as date table will also remove auto created date tables, and the relationship will be clear ( too many date columns)"
      },
      {
        "date": "2024-07-28T15:39:00.000Z",
        "voteCount": 1,
        "content": "If the auto date/time option remains enabled, Power BI might still create hidden date tables for other date columns, potentially increasing the model size unnecessarily."
      },
      {
        "date": "2024-05-15T08:56:00.000Z",
        "voteCount": 2,
        "content": "No it DOES NOT"
      },
      {
        "date": "2024-01-31T15:20:00.000Z",
        "voteCount": 2,
        "content": "The questions informs that a one-to-many relationship exists between the tables, so I would go B and C"
      },
      {
        "date": "2023-12-19T00:58:00.000Z",
        "voteCount": 2,
        "content": "chatgpt&gt; BC is correct"
      },
      {
        "date": "2023-11-19T09:33:00.000Z",
        "voteCount": 2,
        "content": "Answer - A &amp; C\nCreating a Date table and selecting Mark as Date Table will automatically disable the auto date/time option in Power BI. This is because Power BI recognizes the designated Date table as the primary source of date information for the data model. When a Date table is marked as such, Power BI will use the date values from this table for all date-related calculations and visualizations. As a result, the auto date/time option becomes redundant and is automatically disabled to avoid potential conflicts or inconsistencies."
      },
      {
        "date": "2023-09-06T09:45:00.000Z",
        "voteCount": 2,
        "content": "C and A are correct answers. \nC. You should create a dedicated date table in your data model that contains a continuous date sequence covering the range of your data. \nA. After creating the Date table, you should establish a relationship between thid date table and the Sales table using the common date-related column (e.g.,\"Order Date\"). This relationship will allow you to perform time-based analysis by month and quarter while minimizing data redundancy."
      },
      {
        "date": "2023-07-17T04:59:00.000Z",
        "voteCount": 4,
        "content": "Selecting Mark as date table will remove autogenerated hierarchies from the Date field in the table that you marked as a date table. For other date fields, the auto hierarchy will still be present until you establish a relationship between that field and the date table or until you turn off the Auto Date/Time feature. \nSo B is implicite if you do A.\nhttps://learn.microsoft.com/en-us/training/modules/design-model-power-bi/3-date-table"
      },
      {
        "date": "2023-06-13T12:51:00.000Z",
        "voteCount": 2,
        "content": "C. Create a Date table and select Mark as Date Table.\nA. Create a relationship between the Date table and the Sales table."
      },
      {
        "date": "2023-06-08T11:36:00.000Z",
        "voteCount": 3,
        "content": "According to https://learn.microsoft.com/en-us/power-bi/transform-model/desktop-date-tables\nIt's important to note that when you specify your own date table, Power BI Desktop doesn't auto-create the hierarchies that it would otherwise build into your model on your behalf. If you later deselect your date table (and no longer have a manually set date table), Power BI Desktop recreates the automatically created built-in date tables for you, for the date columns in the table.\n\nAlso important to note is that when you mark a table as a date table, Power BI Desktop removes the built-in (automatically created) date table. And any visuals or DAX expressions you previously created based on those built-in tables will no longer work properly."
      },
      {
        "date": "2023-05-26T22:51:00.000Z",
        "voteCount": 2,
        "content": "Disable the auto date/time option my improve the performance of the model not A"
      },
      {
        "date": "2023-04-23T10:28:00.000Z",
        "voteCount": 3,
        "content": "when you specify your own date table, Power BI Desktop doesn't auto-create the hierarchies that it would otherwise build into your model on your behalf. If you later deselect your date table (and no longer have a manually set date table), Power BI Desktop recreates the automatically created built-in date tables for you, for the date columns in the table.\nhttps://learn.microsoft.com/en-us/power-bi/transform-model/desktop-date-tables"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 56,
    "url": "https://www.examtopics.com/discussions/microsoft/view/95302-exam-pl-300-topic-2-question-56-discussion/",
    "body": "You have a Microsoft Power BI report. The size of PBIX file is 550 MB. The report is accessed by using an App workspace in shared capacity of powerbi.com.<br><br>The report uses an imported dataset that contains one fact table. The fact table contains 12 million rows. The dataset is scheduled to refresh twice a day at 08:00 and 17:00.<br><br>The report is a single page that contains 15 AppSource visuals and 10 default visuals.<br><br>Users say that the report is slow to load the visuals when they access and interact with the report.<br><br>You need to recommend a solution to improve the performance of the report.<br><br>What should you recommend?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tImplement row-level security (RLS).",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRemove unused columns from tables in the data model.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tReplace the default visuals with AppSource visuals.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEnable visual interactions."
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 16,
        "isMostVoted": true
      },
      {
        "answer": "C",
        "count": 2,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2023-01-14T10:02:00.000Z",
        "voteCount": 23,
        "content": "Deja vu"
      },
      {
        "date": "2023-06-07T05:56:00.000Z",
        "voteCount": 8,
        "content": "I think it is 3rd DejaVu"
      },
      {
        "date": "2023-12-10T01:27:00.000Z",
        "voteCount": 1,
        "content": "agreed"
      },
      {
        "date": "2023-01-15T09:06:00.000Z",
        "voteCount": 6,
        "content": "B is correct\nalmost the same as Question #53, Topic 2"
      },
      {
        "date": "2024-08-21T14:01:00.000Z",
        "voteCount": 1,
        "content": "Reducing data model may improve load time for visual interactions."
      },
      {
        "date": "2024-08-19T01:42:00.000Z",
        "voteCount": 1,
        "content": "Still B: Remove unused columns from tables in the data model."
      },
      {
        "date": "2024-07-01T06:34:00.000Z",
        "voteCount": 1,
        "content": "B is correct"
      },
      {
        "date": "2024-03-19T15:34:00.000Z",
        "voteCount": 1,
        "content": "Flashback"
      },
      {
        "date": "2024-02-27T06:50:00.000Z",
        "voteCount": 1,
        "content": "Repeated Question Obviosuly B"
      },
      {
        "date": "2024-02-18T22:08:00.000Z",
        "voteCount": 2,
        "content": "The correct answer is C. Replace the default visuals with AppSource visuals.\n\nThe question never mentioned about to reduce the size of the data model. The problem was the visuals taking so long to load. Placing multiple visuals in a single page makes the visuals to slow load. Limiting visuals in a single page makes the visual loading time faster. \n\nReference: https://learn.microsoft.com/en-us/power-bi/guidance/power-bi-optimization#limit-visuals-on-report-pages"
      },
      {
        "date": "2024-08-21T14:00:00.000Z",
        "voteCount": 1,
        "content": "Interesting but replacing the default visuals with AppSource visuals doesn't mean that the count of visuals is changing on that page. Is there other documentation that says AppSource visuals are faster than default visuals? My intuition tells me not...but happy to be proven wrong."
      },
      {
        "date": "2023-09-06T09:54:00.000Z",
        "voteCount": 1,
        "content": "IF\n&amp;\nActive Store Name = IF([Status] = \"A\", [Store Name], \"Inactive - \" &amp; [Store Name])"
      },
      {
        "date": "2023-09-06T09:48:00.000Z",
        "voteCount": 1,
        "content": "B is correct.\nBy removing columns that are not needed for the report, you can reduce the size of the data model. this can lead to faster loading times, especially when dealing with large datasets."
      },
      {
        "date": "2023-08-24T19:38:00.000Z",
        "voteCount": 2,
        "content": "i wish all questions were this easy and straightforward."
      },
      {
        "date": "2023-05-26T22:53:00.000Z",
        "voteCount": 1,
        "content": "remove unused columns"
      },
      {
        "date": "2023-05-02T08:35:00.000Z",
        "voteCount": 1,
        "content": "Given answer is correct."
      },
      {
        "date": "2023-04-12T05:16:00.000Z",
        "voteCount": 1,
        "content": "B is correct\nalmost the same as Question #53, Topic 2"
      },
      {
        "date": "2023-02-09T10:43:00.000Z",
        "voteCount": 3,
        "content": "B CORRECT"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 57,
    "url": "https://www.examtopics.com/discussions/microsoft/view/94721-exam-pl-300-topic-2-question-57-discussion/",
    "body": "HOTSPOT<br> -<br><br>You have a Power BI data model that contains a table named Stores. The table has the following columns:<br><br>\u2022\tStore Name<br>\u2022\tOpen Date<br>\u2022\tStatus<br>\u2022\tState<br>\u2022\tCity<br><br>You need to create a calculated column named Active Store Name that meets the following requirements:<br><br>\u2022\tWhen the value of the Status column is \u201cA\u201d, the value in the Store Name column must be returned.<br>\u2022\tWhen the value of the Status column is NOT \u201cA\u201d, the value in the Store Name column that is prefixed with \"Inactive - \" must be returned.<br><br>How should you complete the DAX expression? To answer, select the appropriate options in the answer area.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/pl-300/image296.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/pl-300/image297.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2023-01-10T12:12:00.000Z",
        "voteCount": 43,
        "content": "Correct Answer.\n&amp;&amp; Is the same for AND function in DAX, nd &amp; is the same for concatenate on Excel."
      },
      {
        "date": "2024-02-27T06:59:00.000Z",
        "voteCount": 1,
        "content": "Yes we have to use &amp; for contention"
      },
      {
        "date": "2023-06-17T12:44:00.000Z",
        "voteCount": 9,
        "content": "With SWITCH Function:\nActive Store Name = SWITCH ( [Status], \"A\", [Store Name], \"Inactive - \" &amp; [Store Name] )"
      },
      {
        "date": "2024-09-13T17:08:00.000Z",
        "voteCount": 1,
        "content": "Wrong!!"
      },
      {
        "date": "2024-08-22T08:34:00.000Z",
        "voteCount": 1,
        "content": "Answer is correct"
      },
      {
        "date": "2024-08-19T01:43:00.000Z",
        "voteCount": 2,
        "content": "The answer is correct, it is an IF statement and we need the &amp; operator to concatenate"
      },
      {
        "date": "2024-07-01T06:36:00.000Z",
        "voteCount": 2,
        "content": "The answer is correct"
      },
      {
        "date": "2024-06-06T05:06:00.000Z",
        "voteCount": 1,
        "content": "Hello , Is true"
      },
      {
        "date": "2024-01-10T20:37:00.000Z",
        "voteCount": 2,
        "content": "Correct answer"
      },
      {
        "date": "2023-12-28T01:50:00.000Z",
        "voteCount": 6,
        "content": "&amp;&amp; is used as a Replacement of 'AND' function.\nWhereas &amp; is used to concatenate two strings. \nSo answer will be  \"If - &amp;\"."
      },
      {
        "date": "2023-12-14T04:01:00.000Z",
        "voteCount": 4,
        "content": "And (&amp;&amp;) DAX Operator for conditions or expressions;\nConcatenation (&amp;) DAX Operator for values or texts strings etc;\nI believe it is:\n\nif \n&amp;"
      },
      {
        "date": "2023-10-25T07:55:00.000Z",
        "voteCount": 3,
        "content": "If and &amp;&amp; is the correct answer"
      },
      {
        "date": "2023-11-20T10:23:00.000Z",
        "voteCount": 2,
        "content": "Sorry, I changed my mind and I can't delete my first comment.\nIf and &amp; are the correct answers. Because &amp; is used to concatenate two values."
      },
      {
        "date": "2023-05-02T08:37:00.000Z",
        "voteCount": 2,
        "content": "Correct answer."
      },
      {
        "date": "2023-04-29T23:43:00.000Z",
        "voteCount": 4,
        "content": "Correct answer is IF and &amp;. &amp; combines text and column values.\n&amp;&amp; is used when you need to combine 2 conditions, replacement for AND in SQL."
      },
      {
        "date": "2024-03-22T22:52:00.000Z",
        "voteCount": 1,
        "content": "we are not combining 2 condition in the RETURN FALSE statement..."
      },
      {
        "date": "2023-10-21T00:29:00.000Z",
        "voteCount": 1,
        "content": "Test it in PBI before submitting incorrect answers.nswers"
      },
      {
        "date": "2023-04-12T05:18:00.000Z",
        "voteCount": 1,
        "content": "The provided answer is correct: it is 'IF' '&amp;'."
      },
      {
        "date": "2023-01-20T05:42:00.000Z",
        "voteCount": 1,
        "content": "Correct answers"
      },
      {
        "date": "2023-01-15T09:07:00.000Z",
        "voteCount": 4,
        "content": "Correct: If, &amp;"
      },
      {
        "date": "2023-01-14T14:01:00.000Z",
        "voteCount": 3,
        "content": "The provided answer is correct: it is 'IF' '&amp;'."
      },
      {
        "date": "2023-01-12T03:07:00.000Z",
        "voteCount": 5,
        "content": "Correct \nIF\n&amp;"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 58,
    "url": "https://www.examtopics.com/discussions/microsoft/view/94686-exam-pl-300-topic-2-question-58-discussion/",
    "body": "You have a CSV file that contains user complaints. The file contains a column named Logged. Logged contains the date and time each complaint occurred. The data in Logged is in the following format: 2018-12-31 at 08:59.<br><br>You need to be able to analyze the complaints by the logged date and use a built-in date hierarchy.<br><br>What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tApply a transformation to extract the first 11 characters of the logged column.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAdd a conditional column that outputs 2018 if the Logged column starts with 2018 and set the data type of the new column to Whole Number.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a column by example that starts with 2018-12-31 and set the data type of the new column to Date.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tApply a transformation to extract the last 11 characters of the Logged column and set the data type of the new column to Date."
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 44,
        "isMostVoted": true
      },
      {
        "answer": "N",
        "count": 2,
        "isMostVoted": false
      },
      {
        "answer": "A",
        "count": 1,
        "isMostVoted": false
      },
      {
        "answer": "B",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2023-01-10T07:28:00.000Z",
        "voteCount": 49,
        "content": "Option C should be the correct answer not option B"
      },
      {
        "date": "2023-04-06T06:29:00.000Z",
        "voteCount": 15,
        "content": "To analyze the complaints by the logged date and use a built-in date hierarchy, we need to extract the date portion of the \"Logged\" column and convert it to a date format. Therefore, the best option among the given choices is:\n\nA. Apply a transformation to extract the first 11 characters of the logged column.\n\nSince the date value is stored in the first 11 characters of the \"Logged\" column, extracting those characters using the \"Extract\" transformation in Power Query will give us the date value in the format \"yyyy-MM-dd\". We can then set the data type of the new column to \"Date\" to convert it into a date format. This will allow us to analyze the complaints by the logged date and use the built-in date hierarchy in Power BI.\n\nOption B is not necessary and will not achieve the desired result. Option C will create a single date value and not allow us to analyze the complaints by the logged date. Option D suggested extracting the last 11 characters, but they contain both date and time values and may not result in the correct date format."
      },
      {
        "date": "2023-10-04T19:41:00.000Z",
        "voteCount": 3,
        "content": "i did try extracting first 11 characters but then cannot change the data type of 2018-12-31 to date. still dont know why"
      },
      {
        "date": "2023-12-08T03:00:00.000Z",
        "voteCount": 14,
        "content": "The date part is the first 10 characters, if you extract 11 characters then there will be a trailing space behind the date part thus won't be able to convert it to date. thus A is NOT the correct answer."
      },
      {
        "date": "2024-09-24T00:50:00.000Z",
        "voteCount": 1,
        "content": "Well, you can Trim it!"
      },
      {
        "date": "2024-09-24T00:51:00.000Z",
        "voteCount": 1,
        "content": "You would then also have to convert it to a date."
      },
      {
        "date": "2024-09-17T00:53:00.000Z",
        "voteCount": 1,
        "content": "Thanks for this!!"
      },
      {
        "date": "2024-08-22T08:56:00.000Z",
        "voteCount": 3,
        "content": "Option C is correct only - I created an example csv and tested it. Using this, Power BI automatically generates the hierarchy required by the question also.\nA is wrong because it will only partially get you there, returning the date as a String value not formatted as date.\nB is only going to return the Year number\nD is going to give you some of time, including the word 'at' etc."
      },
      {
        "date": "2024-07-01T06:37:00.000Z",
        "voteCount": 1,
        "content": "I'd select option C"
      },
      {
        "date": "2024-05-17T20:03:00.000Z",
        "voteCount": 2,
        "content": "I am not sure also why there was a correct answer on getting first 11 characters as there are only 10, 11 will have a space and not be recognized if trying to convert to date format, however, it will never be \"B\", as the question is to analyse over time, not just by year. Answer \"B\" is just year."
      },
      {
        "date": "2024-05-10T23:22:00.000Z",
        "voteCount": 1,
        "content": "Same this question came in previous topic (question #10, Topic1), and the answer was (Apply a transformation to extract the first 11 characters of the Logged column). So which one is correct?"
      },
      {
        "date": "2024-05-06T19:49:00.000Z",
        "voteCount": 2,
        "content": "Yes C is correct answer, B is making the date field a whole number which doesnt help in analysing the date field data"
      },
      {
        "date": "2024-05-06T19:46:00.000Z",
        "voteCount": 1,
        "content": "B is the correct answer , because C is making the table as Date Table, which will remove the Date hierarchy feature .Question demands Date Hierarchy"
      },
      {
        "date": "2024-04-29T07:29:00.000Z",
        "voteCount": 1,
        "content": "we didn't get the answer :c"
      },
      {
        "date": "2024-03-29T11:47:00.000Z",
        "voteCount": 3,
        "content": "I'm starting to think that the person who posts those questions just answers them at random. B? really? that is absurd"
      },
      {
        "date": "2024-03-18T04:21:00.000Z",
        "voteCount": 4,
        "content": "this question is more than once in the test examples but i still dont understand which is the correct answer :)"
      },
      {
        "date": "2024-03-07T09:53:00.000Z",
        "voteCount": 2,
        "content": "C is the correct answer."
      },
      {
        "date": "2024-02-21T07:11:00.000Z",
        "voteCount": 2,
        "content": "A extracts 11 characters, the date format is 10 characters, including the last spacing characters will keep the data in string format --&gt; not possible to create a date hierarchy;\nB extracting the year only will not enable a date hierarchy either and will set the year format to whole number \nD extracts the LAST 11 characters, there will be no date in there\n\nOnly valid answer is C: you create by example and PBI will recognize the date format and automatically apply hierarchy"
      },
      {
        "date": "2024-01-16T19:26:00.000Z",
        "voteCount": 2,
        "content": "C is correct"
      },
      {
        "date": "2024-01-03T15:22:00.000Z",
        "voteCount": 2,
        "content": "A is less steps and lowers model size"
      },
      {
        "date": "2024-01-22T02:26:00.000Z",
        "voteCount": 1,
        "content": "Date type is missing for built-in hierarchy feature use"
      },
      {
        "date": "2024-01-02T15:02:00.000Z",
        "voteCount": 1,
        "content": "From a quick search, here's what I discovered.\n\nTo analyze the complaints in the CSV file by the logged date and use a built-in date hierarchy, you should apply a transformation to extract the first 11 characters of the logged column. This action will isolate the date part of the 'Logged' column (e.g., '2018-12-31'), which is suitable for date hierarchy analysis. This approach is effective as it maintains the date in a recognizable format while discarding the time part, which may not be necessary for your date hierarchy analysis. This method ensures that you can analyze the data by year, month, and day without unnecessary complications.\n\nFor further detailed steps and examples, you can refer to Microsoft's documentation on Power BI and data transformation techniques, such as Power BI Desktop - Add Column From Example and Power Query - Split Date and Time into Separate Columns. the answer is A"
      },
      {
        "date": "2024-01-02T15:01:00.000Z",
        "voteCount": 1,
        "content": "From a quick search, here's what I discovered.\n\nTo analyze the complaints in the CSV file by the logged date and use a built-in date hierarchy, you should apply a transformation to extract the first 11 characters of the logged column. This action will isolate the date part of the 'Logged' column (e.g., '2018-12-31'), which is suitable for date hierarchy analysis. This approach is effective as it maintains the date in a recognizable format while discarding the time part, which may not be necessary for your date hierarchy analysis. This method ensures that you can analyze the data by year, month, and day without unnecessary complications.\n\nFor further detailed steps and examples, you can refer to Microsoft's documentation on Power BI and data transformation techniques, such as Power BI Desktop - Add Column From Example and Power Query - Split Date and Time into Separate Columns."
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 59,
    "url": "https://www.examtopics.com/discussions/microsoft/view/94744-exam-pl-300-topic-2-question-59-discussion/",
    "body": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.<br><br>After you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.<br><br>From Power Query Editor, you profile the data shown in the following exhibit.<br><br><img src=\"https://img.examtopics.com/pl-300/image298.png\"><br><br>The IoT GUID and IoT ID columns are unique to each row in the query.<br><br>You need to analyze IoT events by the hour and day of the year. The solution must improve dataset performance.<br><br>Solution: You create a custom column that concatenates the IoT GUID column and the IoT ID column and then delete the IoT GUID and IoT ID columns.<br><br>Does this meet the goal?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tYes",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tNo\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 56,
        "isMostVoted": true
      },
      {
        "answer": "A",
        "count": 26,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2023-04-12T23:12:00.000Z",
        "voteCount": 34,
        "content": "No, creating a custom column that concatenates the IoT GUID and IoT ID columns and then deleting the IoT GUID and IoT ID columns will not help in analyzing IoT events by the hour and day of the year. The solution does not address the need to extract the hour and day of the year from the DateTime column, which is essential for the required analysis.\n\nTo analyze IoT events by the hour and day of the year, you need to extract the hour and day of the year from the DateTime column and create new columns for them. This can be done using the Power Query Editor in Power BI. Once the new columns are created, you can use them to group and aggregate the data by hour and day of the year, respectively. This approach will also help to improve dataset performance by reducing the amount of data that needs to be processed."
      },
      {
        "date": "2023-09-14T04:37:00.000Z",
        "voteCount": 4,
        "content": "You do not need two columns for date and time, you can do the analysis with the DateTime column. ChatGPT is wrong (again). \n\nYou do not need two columns for this analyses\n\nChatGPT\nYou are correct; you do not necessarily need two separate columns for analyzing IoT events by the hour and day of the year. One column representing a combination of date and time information can suffice for this analysis.\n\nIf you have a timestamp column that includes both date and time information, you can extract the hour and day of the year from that single column. You do not need two separate columns for this purpose.\n\nSo, the original solution of creating a custom column that concatenates the IoT GUID column and the IoT ID column and then deleting the IoT GUID and IoT ID columns is acceptable for this specific analysis, assuming that the timestamp data is available and appropriately formatted in the concatenated column.\n\nTherefore, the answer is:\n\nA. Yes"
      },
      {
        "date": "2023-08-07T10:58:00.000Z",
        "voteCount": 2,
        "content": "Yes\u2714\u2714\u2714\nIt says both IoT GUID and IoT ID are unique on each row. Both will have same visualization on what ever you chose to analyze. As such merging them is not a bad idea."
      },
      {
        "date": "2023-06-23T13:49:00.000Z",
        "voteCount": 2,
        "content": "a bit ambiguous. I assume by previous questions that when they say date AND time of the year, we analyse them together in the same pack, otherwise it could say by date and by hour or by date or hour."
      },
      {
        "date": "2023-04-10T06:44:00.000Z",
        "voteCount": 14,
        "content": "A. Yes, creating a custom column that concatenates the IoT GUID column and the IoT ID column and then deleting the IoT GUID and IoT ID columns can improve dataset performance and meet the goal of analyzing IoT events by the hour and day of the year. By combining the two columns into one custom column, it reduces the number of columns in the dataset and simplifies the query, which can improve performance. Additionally, the concatenated column can be used to group and analyze events by the hour and day of the year.\n\nNo confusion, and no need to discuss further"
      },
      {
        "date": "2023-05-13T07:44:00.000Z",
        "voteCount": 17,
        "content": "but you can't concatenate different data types. it will throw an error"
      },
      {
        "date": "2024-08-22T09:07:00.000Z",
        "voteCount": 2,
        "content": "You have an eagle eye bro...this is the whole reason right here, well spotted!"
      },
      {
        "date": "2023-09-22T02:07:00.000Z",
        "voteCount": 1,
        "content": "Who said that?"
      },
      {
        "date": "2023-11-27T02:48:00.000Z",
        "voteCount": 2,
        "content": "Power Query throws error, but DAX do the job. the question mentions Power Query. so  it will throws error."
      },
      {
        "date": "2024-02-09T04:30:00.000Z",
        "voteCount": 1,
        "content": "Great spot didnt see that at all  - Answer likely B"
      },
      {
        "date": "2023-10-01T07:48:00.000Z",
        "voteCount": 5,
        "content": "Mate you got two different data types there don't you see that, you will get an error by trying to concatenate those columns lol you just confuse people here with answers like this....go on Microsofts webiste and read bruv lol"
      },
      {
        "date": "2023-07-23T19:10:00.000Z",
        "voteCount": 35,
        "content": "\"No confusion, and no need to discuss further\"\n\nInsufferable."
      },
      {
        "date": "2023-09-21T20:40:00.000Z",
        "voteCount": 17,
        "content": "Literally the dumbest thing you can say on this site."
      },
      {
        "date": "2024-09-13T17:13:00.000Z",
        "voteCount": 1,
        "content": "B is the correct answer"
      },
      {
        "date": "2024-08-21T02:19:00.000Z",
        "voteCount": 1,
        "content": "In my opinion it is NO, I'll go for B"
      },
      {
        "date": "2024-02-29T05:03:00.000Z",
        "voteCount": 6,
        "content": "stop bringing  confusion, and untested discussions. \nThe right answer is B NO because:\nOpen PBI Desktop, Home &gt; Queries &gt; Transform data --&gt; OPEN QUERY EDITOR \nThat's the starting point of the question.\nFrom Query editor, import the exact same dataset (you can ask gpt to build it for you)\nSelect your excel file and import it. Power query will create your 3 fields:\nIot Guid : string\nIoTDateTime : date\nIoTID: number\n\nAccording to the question, you create a CUSTOM Column: Add Columns &gt; General &gt; Custom columns. ([IotGUID] &amp; [IoT ID])\nYou are presented with a pop up window, name your column GUIDID and select the 2 columns.\nYou have a new column called GuidID with all its data is Error!\nFrom there... feel free to decide if you want to delete [IotGUID] &amp; [IoT ID] being confident to perform analysis with a primary key saying \"Error\".... I would not."
      },
      {
        "date": "2024-02-25T23:05:00.000Z",
        "voteCount": 1,
        "content": "B is the correct"
      },
      {
        "date": "2024-01-12T19:53:00.000Z",
        "voteCount": 4,
        "content": "we cannot concatenate Text and DateTime in Power Query, it will throw an error"
      },
      {
        "date": "2023-12-19T22:44:00.000Z",
        "voteCount": 1,
        "content": "Concatenating the IoT GUID column and the IoT ID column cannot help the requirement to analyze IoT events by the hour and day of the year."
      },
      {
        "date": "2023-11-28T11:52:00.000Z",
        "voteCount": 1,
        "content": "combining GUID&amp;ID together and remove the other tow will reduce the size of the model by one column, thus will theoratically improve the perfomance. as of analyzing by hour and day, HOUR() and DAY() function will do the work without split the column."
      },
      {
        "date": "2023-10-12T03:31:00.000Z",
        "voteCount": 2,
        "content": "hm i don't want to soun d arrogant, but the comment sections would be a lot smaller if people would correctly read the ask..."
      },
      {
        "date": "2023-09-06T10:24:00.000Z",
        "voteCount": 3,
        "content": "B is correct. \nThe solution doesn't address the datetime information required for such analysis. \nTo analyze loT events by the hour and day of the year, you need to perform transformations specifically on the loT datetime column to extract the hour and day of the year information."
      },
      {
        "date": "2023-09-20T16:05:00.000Z",
        "voteCount": 1,
        "content": "NICE ONE THERE"
      },
      {
        "date": "2023-08-18T08:01:00.000Z",
        "voteCount": 5,
        "content": "As said Before, the columns have differente type of data, and only text colums can be concatenated. Tested at Power BI:\n\"Expression.Error: We cannot apply operator &amp; to types Text and Number\"\n\nSo, answer it's B"
      },
      {
        "date": "2023-08-03T07:33:00.000Z",
        "voteCount": 3,
        "content": "A: Again its a case of, am I solving it the right way, best way or just a way that helps (in any way at all). Deleting 2 and merging into 1 does help. It may not be the best way or even a way we love, but the point is it will help"
      },
      {
        "date": "2023-08-01T02:21:00.000Z",
        "voteCount": 3,
        "content": "\ud83d\uded1\u274c\nI dont think it is B for this reasons:\n1. Both IoT GUID and IOT ID are unique. Which means Concatenating them is not an Issue whatsover ( Dont bring the argument of difference in data type. You can actually merge those columns without any error)\n2. The Date columns has all the component needed for the analysis and dont require any further extraction of hour or year.\n3. Merging and Deleting those columns will improve the case."
      },
      {
        "date": "2023-07-22T02:03:00.000Z",
        "voteCount": 1,
        "content": "A is correct"
      },
      {
        "date": "2023-06-17T15:37:00.000Z",
        "voteCount": 1,
        "content": "No, creating a custom column that concatenates the IoT GUID and IoT ID columns and then deleting the IoT GUID and IoT ID columns will not help in analyzing IoT events by the hour and day of the year. The solution does not address the need to extract the hour and day of the year from the DateTime column, which is essential for the required analysis.\n\nTo analyze IoT events by the hour and day of the year, you need to extract the hour and day of the year from the DateTime column and create new columns for them. This can be done using the Power Query Editor in Power BI. Once the new columns are created, you can use them to group and aggregate the data by hour and day of the year, respectively. This approach will also help to improve dataset performance by reducing the amount of data that needs to be processed."
      },
      {
        "date": "2023-04-10T07:07:00.000Z",
        "voteCount": 2,
        "content": "One is better, and it is better to keep only the IOT ID instead of combining two. That is why the answer is B"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 60,
    "url": "https://www.examtopics.com/discussions/microsoft/view/94722-exam-pl-300-topic-2-question-60-discussion/",
    "body": "You have a Power BI model that contains a table named Employee. The table contains the following data.<br><br><img src=\"https://img.examtopics.com/pl-300/image299.png\"><br><br>Each employee has one manager as shown in the ParentEmployeeID column.<br><br>All reporting paths lead to the CEO at the top of the organizational hierarchy.<br><br>You need to create a calculated column that returns the count of levels from each employee to the CEO.<br><br>Which DAX expression should you use?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tPATHLENGTH(PATH(Employee[EmployeeID],Employee[ParentEmployeeID]))\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tPATHITEM(PATH(Employee[EmployeeID],Employee[ParentEmployeeID]),1,INTEGER)",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tPATHCONTAINS(PATH(Employee[EmployeeID],Employee[ParentEmployeeID]),1)",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tPATH(Employee[EmployeeID],Employee[ParentEmployeeID])"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 37,
        "isMostVoted": true
      },
      {
        "answer": "D",
        "count": 2,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2023-01-11T16:01:00.000Z",
        "voteCount": 32,
        "content": "A is correct answer. This video proves all\nhttps://www.youtube.com/watch?v=uE0G6gLz7WM"
      },
      {
        "date": "2024-03-28T03:45:00.000Z",
        "voteCount": 1,
        "content": "Great link. Ta"
      },
      {
        "date": "2023-04-01T08:39:00.000Z",
        "voteCount": 2,
        "content": "Thanks for the video link."
      },
      {
        "date": "2023-08-09T01:33:00.000Z",
        "voteCount": 1,
        "content": "Thanks!"
      },
      {
        "date": "2023-09-08T12:37:00.000Z",
        "voteCount": 2,
        "content": "what a great video man."
      },
      {
        "date": "2023-01-15T09:27:00.000Z",
        "voteCount": 25,
        "content": "Answer A is correct - tested\nAlthough for CEO it returns 1 - so I personally would substract 1 from this PATHLENGTH when creating the report, as I think numbers of levels from CEO to CEO is 0, formanagaers directly under CEO it is 1 etc"
      },
      {
        "date": "2023-07-06T18:07:00.000Z",
        "voteCount": 15,
        "content": "PATH will give this - ToTop\n100\n100|101\n100|102\n100|101|103\n100|101|103|104\n100|101|103|105\n100|102|106\nPATHLENGTH(PATH...) will give this \n1\n2\n2\n3\n4\n4\n3"
      },
      {
        "date": "2024-08-22T09:29:00.000Z",
        "voteCount": 1,
        "content": "A is correct"
      },
      {
        "date": "2024-08-21T02:34:00.000Z",
        "voteCount": 1,
        "content": "Tested! A is the correct option, it returns the number of levels from the CEO.\nB always returns 100, C returns a boolean, and D return the concatenation of the paths"
      },
      {
        "date": "2024-01-12T20:37:00.000Z",
        "voteCount": 1,
        "content": "tested in PBI, PATHLENGTH(PATH(Employee[EmployeeID],Employee[ParentEmployeeID])) will return the count of levels including 1 for the CEO itself as ewelaela mentioned earlier"
      },
      {
        "date": "2024-01-12T20:49:00.000Z",
        "voteCount": 1,
        "content": "PATHLENGTH return 1 for top level"
      },
      {
        "date": "2023-09-06T11:17:00.000Z",
        "voteCount": 1,
        "content": "A is correct answer. \nThis expression calculates the path length from each employee to the CEO, effectively giving you the count of levels in the hierarchy."
      },
      {
        "date": "2023-05-16T20:22:00.000Z",
        "voteCount": 3,
        "content": "A\nhttps://learn.microsoft.com/en-us/dax/pathlength-function-dax"
      },
      {
        "date": "2023-04-12T05:32:00.000Z",
        "voteCount": 1,
        "content": "Answer A is correct - tested\nAlthough for CEO it returns 1 - so I personally would substract 1 from this PATHLENGTH when creating the report, as I think numbers of levels from CEO to CEO is 0, formanagaers directly under CEO it is 1 etc"
      },
      {
        "date": "2023-11-27T03:12:00.000Z",
        "voteCount": 1,
        "content": "these types of conventions kill me. for example python and nmpy will start their indexes from 0, but pandas will use 1."
      },
      {
        "date": "2023-02-17T11:13:00.000Z",
        "voteCount": 7,
        "content": "According to https://learn.microsoft.com/en-us/dax/path-function-dax, PATH returns a string containing \"the identifiers of all the parents to the current identifier\", whereas PATHLENGTH returns \"the number of items that are parents to the specified item.\""
      },
      {
        "date": "2023-01-18T12:53:00.000Z",
        "voteCount": 1,
        "content": "PathLength function needs a path to travel and provide length of the hierarchy"
      },
      {
        "date": "2023-01-11T09:52:00.000Z",
        "voteCount": 2,
        "content": "The Answer is A because the question instructs that we count the different levels of each employee. The PathLength gives the result. For more information see the link https://learn.microsoft.com/en-us/dax/pathlength-function-dax\n\nAnswer D is wrong because it only returns the items related to the current row value and does not give the count."
      },
      {
        "date": "2023-01-10T23:03:00.000Z",
        "voteCount": 3,
        "content": "A is correct answer"
      },
      {
        "date": "2023-01-10T16:54:00.000Z",
        "voteCount": 2,
        "content": "Correct answer"
      },
      {
        "date": "2023-01-10T12:23:00.000Z",
        "voteCount": 2,
        "content": "https://simplebiinsights.com/power-bi-path-function-for-parent-child-hierarchies-in-dax/#:~:text=PATH%20function%20returns%20a%20delimited,to%20the%20current%20row%20value."
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 61,
    "url": "https://www.examtopics.com/discussions/microsoft/view/94651-exam-pl-300-topic-2-question-61-discussion/",
    "body": "You have a Microsoft Power BI report. The size of PBIX file is 550 MB. The report is accessed by using an App workspace in shared capacity of powerbi.com.<br><br>The report uses an imported dataset that contains one fact table. The fact table contains 12 million rows. The dataset is scheduled to refresh twice a day at 08:00 and 17:00.<br><br>The report is a single page that contains 15 AppSource visuals and 10 default visuals.<br><br>Users say that the report is slow to load the visuals when they access and interact with the report.<br><br>You need to recommend a solution to improve the performance of the report.<br><br>What should you recommend?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tReplace the default visuals with AppSource visuals.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRemove unused columns from tables in the data model.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tChange the imported dataset to DirectQuery",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tIncrease the number of times that the dataset is refreshed."
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 26,
        "isMostVoted": true
      },
      {
        "answer": "C",
        "count": 3,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2023-02-06T11:05:00.000Z",
        "voteCount": 44,
        "content": "deja vu"
      },
      {
        "date": "2023-01-15T09:32:00.000Z",
        "voteCount": 18,
        "content": "B is correct\nsame as questions 53 and 56"
      },
      {
        "date": "2024-08-12T14:00:00.000Z",
        "voteCount": 1,
        "content": "C.  There is a reason that the answer options keep changing.  DirectQuery can help with performance by querying the data source directly rather than loading all data into memory."
      },
      {
        "date": "2024-08-22T10:03:00.000Z",
        "voteCount": 1,
        "content": "This isn't correct because that means when the user clicks a visual for interaction, the measures that generate the data to be visuals send the query to the data source - could be a very remote server and force that to do the querying before returning it to the published report. That is going to take longer than if the data was imported/cached on power bi online service."
      },
      {
        "date": "2024-03-04T14:28:00.000Z",
        "voteCount": 3,
        "content": "This question and the CSV complaint question: all-time most repeated questions."
      },
      {
        "date": "2024-02-12T02:43:00.000Z",
        "voteCount": 5,
        "content": "Was at the exam on February 12th 2024"
      },
      {
        "date": "2023-11-24T12:20:00.000Z",
        "voteCount": 1,
        "content": "You should also minimize the amount of visuals on that particular page."
      },
      {
        "date": "2023-09-06T11:26:00.000Z",
        "voteCount": 1,
        "content": "B is the correct answer. \nBy removing columns that are not needed for the report, you can reduce the size of the data model. This can lead to faster loading times, especially when dealing with large datasets."
      },
      {
        "date": "2023-08-23T00:07:00.000Z",
        "voteCount": 1,
        "content": "Deja vu"
      },
      {
        "date": "2023-05-25T03:11:00.000Z",
        "voteCount": 7,
        "content": "This question is making me question my own memory."
      },
      {
        "date": "2023-09-22T11:24:00.000Z",
        "voteCount": 1,
        "content": "lol lol lol"
      },
      {
        "date": "2023-04-12T05:32:00.000Z",
        "voteCount": 3,
        "content": "B is correct\nsame as questions 53 and 56"
      },
      {
        "date": "2023-01-14T16:05:00.000Z",
        "voteCount": 5,
        "content": "This question appears several times and B is the correct answer."
      },
      {
        "date": "2023-01-12T04:16:00.000Z",
        "voteCount": 5,
        "content": "B is correct\nRemoving unwanted columns from the data model is a good trick to improve the performance"
      },
      {
        "date": "2023-01-11T09:03:00.000Z",
        "voteCount": 3,
        "content": "Actually both B and C can improve performance but C seems to be the best solution for this case because this can significantly improve performance by allowing the report to retrieve data directly from the data source, rather than loading the large dataset into memory. This can also allow the data to be more fresh, while reducing the burden on the report by limiting the amount of data that needs to be loaded and processed."
      },
      {
        "date": "2023-03-29T11:43:00.000Z",
        "voteCount": 6,
        "content": "Remmember it! from Direct query or Daul we can change to Import mode. But from import mode we cannot change to Direct Query."
      },
      {
        "date": "2024-03-28T03:50:00.000Z",
        "voteCount": 1,
        "content": "Thank you for this reminder!"
      },
      {
        "date": "2023-01-15T09:31:00.000Z",
        "voteCount": 6,
        "content": "But changing to DirectQuery will increase load time for visuals, which already are complained about, so it's not a way to go in this case"
      },
      {
        "date": "2023-04-26T01:34:00.000Z",
        "voteCount": 3,
        "content": "Agreed, DirectQuery would be a solution if refresh times were the issue, not visual loading times. That should always be better with Import."
      },
      {
        "date": "2023-02-15T11:37:00.000Z",
        "voteCount": 3,
        "content": "Yes correct. Import mode is the best option if your data is less than 1 GB and isn't constantly updating. Because all data comes from the Power BI Desktop Cache. So in such scenario, an import mode is faster than Direct Query mode when the data file size is below 1 GB. So DirectQuery refresh rate time will be more which impact the performance."
      },
      {
        "date": "2023-01-10T23:06:00.000Z",
        "voteCount": 1,
        "content": "B is correct\nRemoving unwanted columns from the data model is a good trick to improve the performance"
      },
      {
        "date": "2023-01-10T01:22:00.000Z",
        "voteCount": 1,
        "content": "\"Increase the number of times that the dataset is refreshed\" is the correct answer"
      },
      {
        "date": "2023-01-10T15:49:00.000Z",
        "voteCount": 1,
        "content": "But it will not improve performance"
      },
      {
        "date": "2023-01-10T16:57:00.000Z",
        "voteCount": 1,
        "content": "Refresh has nothing to do with performance. Answer B is correct."
      },
      {
        "date": "2023-01-10T12:25:00.000Z",
        "voteCount": 1,
        "content": "i donot agree with you.\nremove column will reduce the size of the model and automaticaly it will improve the perfomance."
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 62,
    "url": "https://www.examtopics.com/discussions/microsoft/view/134928-exam-pl-300-topic-2-question-86-discussion/",
    "body": "You use Power Query Editor to preview a query that contains sales order data in the following columns:<br><br>\u2022\tTax Amount<br>\u2022\tSales Order ID<br>\u2022\tFreight Amount<br>\u2022\tSubtotal Amount<br>\u2022\tTotal Item Quantity<br><br>The Sales Order ID column uniquely identifies each sales order. The Subtotal Amount and Total Item Quantity columns are always populated, but the Tax Amount and Freight Amount columns are sometimes null when an order has no associated amount.<br><br>You need to query the data to identify the following metrics by month:<br><br>\u2022\tThe average item quantity per order<br>\u2022\tThe average freight amount per order<br>\u2022\tThe maximum item quantity per order<br><br>How should you modify the query?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tIn the Total Item Quantity column, replace the null values with 0.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tIn the Tax Amount column, remove rows that contain null values.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tIn the Freight Amount column, remove rows that contain null values.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tIn the Freight Amount column, replace the null values with 0.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 7,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-03-05T09:37:00.000Z",
        "voteCount": 9,
        "content": "D is the correct answer.\nRemoving rows is not the solution. \nItem Quantity is always present.\nReplace Freight Amount with 0 if it is null"
      },
      {
        "date": "2024-03-13T12:46:00.000Z",
        "voteCount": 6,
        "content": "Won't replacing null values with zero bring down the average freight amount? That wouldn't be an accurate average of the freight amounts when rows with no data are still included. Unless the client would be okay with that,"
      },
      {
        "date": "2024-03-18T03:56:00.000Z",
        "voteCount": 3,
        "content": "It says \"when there is no associated value\" which i inferred to mean the amount is 0."
      },
      {
        "date": "2024-08-19T02:33:00.000Z",
        "voteCount": 2,
        "content": "Replace the nulls with 0's in the Freight Amount column"
      },
      {
        "date": "2024-05-14T09:52:00.000Z",
        "voteCount": 2,
        "content": "I agree with the response.\nHowever, If replacing null values by zero for freight amounts is correct, I suppose that replacing null values by zero for Tax amount would be correct, as well. To have a more complete response, why not considering also this option?"
      },
      {
        "date": "2024-04-19T03:02:00.000Z",
        "voteCount": 1,
        "content": "Svp pourquoi D serait vrai et pas A?"
      },
      {
        "date": "2024-08-06T10:07:00.000Z",
        "voteCount": 1,
        "content": "parce que \"Total Item Quantity columns are always populated\", aucune raison pour faire un changement la. \"Freight Amount\" contient des valuers \"nulls\" qu'on neut peut pas utiliser pour recevoir un moyen. Alors on remplace tous les valuers nulles avec 0. J'espere que ca fais du sense, francais c'est pas mon premier langue"
      },
      {
        "date": "2024-03-18T03:55:00.000Z",
        "voteCount": 3,
        "content": "D is the answer"
      },
      {
        "date": "2024-03-13T06:54:00.000Z",
        "voteCount": 2,
        "content": "Need to get rid of nulls so we can aggregate"
      },
      {
        "date": "2024-02-29T10:20:00.000Z",
        "voteCount": 4,
        "content": "From my point of view, no option is correct!\nWhy? Because the \"freight Amount\" column is the problem. If this column has no values for all rows, so it can have \"null\" values, it is not recommended to create a visualization where we use the AVERAGE operation for this column (the sum will always be ok, but the number by which it is divided is not correct, taking into account null values it will be higher and we will never obtain a correct average ). A similar question was in the documentation for the preparation of this exam. \n\nAlso, we can't remove the rows that contain null values based on \"Freight Amount\" column, because the deleted rows will contain information for the other columns that are used in the analysis and we won't get real and correct results in their analysis."
      },
      {
        "date": "2024-03-13T05:14:00.000Z",
        "voteCount": 1,
        "content": "I would keep the table as is, but get the average of freight by a DAX using Calculate and filter rows to where freight is not null."
      },
      {
        "date": "2024-03-13T05:16:00.000Z",
        "voteCount": 2,
        "content": "2nd thought, let's replace nulls to 0 in the freight, but use the filter in calculate dax to [Freight]&gt;0. So option D is fine."
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 63,
    "url": "https://www.examtopics.com/discussions/microsoft/view/94745-exam-pl-300-topic-2-question-63-discussion/",
    "body": "HOTSPOT<br> -<br><br>You have the Power BI data model shown in the following exhibit.<br><br><img src=\"https://img.examtopics.com/pl-300/image300.png\"><br><br>You need to create a measure to count the number of product categories that had products sold during a selected period.<br><br>How should you complete the DAX expression? To answer, select the appropriate options in the answer area.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/pl-300/image301.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/pl-300/image302.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2023-01-11T00:26:00.000Z",
        "voteCount": 90,
        "content": "Wrong\nTested, correct answer is\nDistinctcount('Product'[product category],\n'sales'"
      },
      {
        "date": "2023-01-12T01:34:00.000Z",
        "voteCount": 2,
        "content": "I have the feeling that this answer is correct. Can you please explain more details for your test and the result?"
      },
      {
        "date": "2024-05-21T01:58:00.000Z",
        "voteCount": 1,
        "content": "But Distinctcount takes one argument which is the column for which you want to apply the function, am I wrong ?"
      },
      {
        "date": "2023-01-14T16:09:00.000Z",
        "voteCount": 3,
        "content": "Distinctcount would make sense if the column to be counted has duplicates. Not applicable here, so COUNT would be the right answer. Second one would be Date"
      },
      {
        "date": "2024-02-27T07:57:00.000Z",
        "voteCount": 1,
        "content": "I agree , That is dimension table so no need of having duplicates"
      },
      {
        "date": "2023-04-26T01:39:00.000Z",
        "voteCount": 5,
        "content": "A product category can be assigned to multiple products, so there is a possibility of duplicates."
      },
      {
        "date": "2023-05-21T19:52:00.000Z",
        "voteCount": 1,
        "content": "If cat A has product B and product C. If B is sold twice and C is sold 4 times, the total count of cat A sold is 6. So it should be COUNT."
      },
      {
        "date": "2023-06-09T05:42:00.000Z",
        "voteCount": 2,
        "content": "In your example scenario, Cat A should be included in the count of categories having sales. It doesn't matter how much sale it has, the fact that it is present in 'Sales' means that category has some sale and it should be included in the count."
      },
      {
        "date": "2023-01-12T06:27:00.000Z",
        "voteCount": 6,
        "content": "That can't be right, DISTINCTCOUNT requires a column as parameter not a table.\nhttps://learn.microsoft.com/en-us/dax/distinctcount-function-dax\nRight answer is: COUNT(Product[ProductCategory],'Date')"
      },
      {
        "date": "2023-04-26T01:39:00.000Z",
        "voteCount": 10,
        "content": "But he gave a column as a parameter?"
      },
      {
        "date": "2023-05-29T08:54:00.000Z",
        "voteCount": 22,
        "content": "This question was definitely on todays exam"
      },
      {
        "date": "2024-08-19T01:55:00.000Z",
        "voteCount": 1,
        "content": "The correct answer is DISTINCTCOUNT('Product'[ProductCategory]), 'Date'"
      },
      {
        "date": "2024-08-21T02:49:00.000Z",
        "voteCount": 2,
        "content": "Sorry I was wrong the correct answer is DISTINCTCOUNT('Product'[ProductCategory]), Sales). I tested it"
      },
      {
        "date": "2024-05-15T11:41:00.000Z",
        "voteCount": 2,
        "content": "Tested \nCategorySoldCount = CALCULATE(\n     DISTINCTCOUNT(Products[ProductCategory]),Sales)"
      },
      {
        "date": "2024-03-29T12:22:00.000Z",
        "voteCount": 1,
        "content": "it has to be sales and not date because of the filter flow"
      },
      {
        "date": "2024-03-11T09:12:00.000Z",
        "voteCount": 1,
        "content": "Both Sales and Date passed as a calculate modifier seem unnecessary"
      },
      {
        "date": "2024-02-21T23:00:00.000Z",
        "voteCount": 11,
        "content": "The question is:\nthe number of product categories\nthat had products sold \nduring a selected period.\n\nTested with data from adventureWorks using:\n1 report, 2 cards, 1 slicer\ncard 1 has 'date'\ncard 2 has 'sales'\nslicer is connected to Date table (using between dates parameters)\n\nUsing 'Date' will always return all the distinct categories no matter the selected dates in the slicer.\n\nUsing 'Sales' returns the number of distinct categories sold between the two dates of the slicer\n\ncorrect tested answer is: \nDistinctcount('Product'[product category],\n'sales'"
      },
      {
        "date": "2024-02-04T12:55:00.000Z",
        "voteCount": 1,
        "content": "This is a terrible question but I am going to say the posted answer is corrected since there is no cross filter direction in the relationship or DAX to indicate that Sales should be filtered on.  \n\nThe date table has to be connected to the Sales table by the sales date and by using date to filter, you are not using a fact table to filter in the answer. \n\nTerrible question, but this is my best attempt to defend the posted answer."
      },
      {
        "date": "2024-02-04T13:07:00.000Z",
        "voteCount": 2,
        "content": "I would like to withdraw or edit my prior comment. I believe the answer should be DistinctCount, Sales. I did not test it out properly before, when mirroring the model relationship as shown in the question.\n\nDISTINCTCOUNT on Sales is the answer I believe"
      },
      {
        "date": "2024-01-16T20:02:00.000Z",
        "voteCount": 4,
        "content": "correct answer is\nDistinctcount('Product'[product category],\n'sales'"
      },
      {
        "date": "2024-01-13T11:41:00.000Z",
        "voteCount": 3,
        "content": "tested in PBI:\nProduct Categories Sold = CALCULATE(DISTINCTCOUNT('Product'[ProductCategory]), Sales) will return count of categories sold per selected time period"
      },
      {
        "date": "2023-10-30T23:04:00.000Z",
        "voteCount": 6,
        "content": "Answer:\nCALCULATE(DISTINCTCOUNT('Product'[ProductCategory]), 'Sales')\nExplanation (my attempt):\n\"to count num. of prod. categories\" -&gt; DISTINCTCOUNT('Product'[ProductCategory])\n\"had products sold\" -&gt; therefore, we want the filter to be the table sales, so that if a product ID is not found in sales table, then this ID's product category will not be counted in DISTINCTCOUNT\n\"during a selected period\" -&gt; I think this means we can \"select\" the desired period from a slicer in the report's page, or in the **Filters** pane, so this filter will automatically propagate to this DAX formula."
      },
      {
        "date": "2024-01-30T05:28:00.000Z",
        "voteCount": 2,
        "content": "Can you please explain why filtering by Sales table is working? The filter is directed from Product to Sales table, and the filter context won't be able to go in the opposite direction."
      },
      {
        "date": "2023-12-14T13:47:00.000Z",
        "voteCount": 2,
        "content": "perfect explanation"
      },
      {
        "date": "2023-10-12T14:05:00.000Z",
        "voteCount": 2,
        "content": "Distinctcount('Product'[product category],\n'Date'"
      },
      {
        "date": "2023-12-14T13:47:00.000Z",
        "voteCount": 3,
        "content": "it is 'Sales' \nnot  Date'"
      },
      {
        "date": "2023-09-15T23:56:00.000Z",
        "voteCount": 2,
        "content": "I was wondering why it should be 'Sales,' not 'Date,' but here's chat GPT's explanation.\n\nProduct Categories Sold = \nCALCULATE(\n    DISTINCTCOUNT(Product[ProductCategory]),\n    Date\n)\n\nwhat this formula does:\n- It counts the distinct product categories from the 'Product' table.\n- The filter context is based on the 'Date' table, meaning the calculation will consider only the dates that are currently selected or visible in your report.\n\nIn short, it has nothing to do with Sales, which is not what we want."
      },
      {
        "date": "2023-10-05T02:40:00.000Z",
        "voteCount": 6,
        "content": "chat GPT is totally wrong. Assuming we have another FACT table called STOCK. in this fact table we do have relationship with Product and Date. \nso if we use DATE not SALES, how power BI can calculate and distinguish the point \"products sold during a selected period\" with \"products in stock during a selected period"
      },
      {
        "date": "2023-10-05T02:41:00.000Z",
        "voteCount": 3,
        "content": "so we need to add SALES here, not DATE"
      },
      {
        "date": "2023-08-03T07:45:00.000Z",
        "voteCount": 8,
        "content": "Distinctcount('Product'[product category],\n'sales'\n\nFor those saying Count, it cannot be count. Yes the words they use are give us the count of categories in this period. But they mean Distinct, it has too. If you have \nCategories \nA\nB\nC\nAnd selling stuff like\nA bike\nA chain\nB wheel\n\nThere are only 2 categories. Now 3. If you do a count now you said 3... But there will never be 3 categories its 1 and 1 with a duplicate... = 2.\n\nAnd sales not Date, because date has a 1 - Many relationship with Sales. so if you do a count on Date, you could end up with more than you expected as it would include duplicate categories from sales to cover the dates of those sales."
      },
      {
        "date": "2023-07-06T11:33:00.000Z",
        "voteCount": 6,
        "content": "The answer should be:\nDistinctcount('Product'[product category],\n'sales'\nas the question clearly states:\nproduct categories that had products sold during a \"selected period\" so the period is already selected."
      },
      {
        "date": "2023-07-04T11:35:00.000Z",
        "voteCount": 4,
        "content": "DISTINCTCOUNT ( 'Product' [ProductCategory] ),\n'Sales'\n- Context Transition thanks to CALCULATE"
      },
      {
        "date": "2023-06-19T09:58:00.000Z",
        "voteCount": 2,
        "content": "Correct Answer:\nTested:\nCOUNT(\u2018Product\u2019[Product Category]),\n\u2018Sales\u2019"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 64,
    "url": "https://www.examtopics.com/discussions/microsoft/view/134836-exam-pl-300-topic-2-question-85-discussion/",
    "body": "You have a Power BI model that contains a table named Employees. The table contains the following columns:<br><br>\u2022\tEmployee ID<br>\u2022\tFirst Name<br>\u2022\tLast Name<br>\u2022\tDepartment<br>\u2022\tSalary<br><br>Each employee is uniquely identified by using Employee ID.<br><br>You need to create a DAX measure that will calculate the average salary of all the employees in the sales department.<br><br>Which DAX expression should you use?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDISTINCTCOUNT(\u2018Employees\u2019[Salary])",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCALCULATE(DISTINCTCOUNT(\u2018Employees\u2019[Salary]), \u2018Employees\u2019[Department] = \u201cSales\u201d)",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCALCULATE(AVERAGE(\u2018Employees\u2019[Salary]), \u2018Employees\u2019[Department] = \u201cSales\u201d)\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAVERAGE(\u2018Employees\u2019[Salary])"
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 13,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-07-31T05:32:00.000Z",
        "voteCount": 2,
        "content": "C is the correct answer."
      },
      {
        "date": "2024-06-17T03:15:00.000Z",
        "voteCount": 3,
        "content": "C is the correct answer."
      },
      {
        "date": "2024-06-11T13:23:00.000Z",
        "voteCount": 1,
        "content": "C is correct"
      },
      {
        "date": "2024-03-07T18:11:00.000Z",
        "voteCount": 4,
        "content": "C is right"
      },
      {
        "date": "2024-02-29T10:39:00.000Z",
        "voteCount": 3,
        "content": "C. CALCULATE(AVERAGE(\u2018Employees\u2019[Salary]), \u2018Employees\u2019[Department] = \u201cSales\u201d)"
      },
      {
        "date": "2024-02-29T10:07:00.000Z",
        "voteCount": 1,
        "content": "Yes, the correct answer is C."
      },
      {
        "date": "2024-02-28T10:31:00.000Z",
        "voteCount": 3,
        "content": "C. CALCULATE(AVERAGE(\u2018Employees\u2019[Salary]), \u2018Employees\u2019[Department] = \u201cSales\u201d)"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 65,
    "url": "https://www.examtopics.com/discussions/microsoft/view/104331-exam-pl-300-topic-2-question-65-discussion/",
    "body": "HOTSPOT<br> -<br><br>You have the Power BI data model shown in the following exhibit.<br><br><img src=\"https://img.examtopics.com/pl-300/image316.png\"><br><br>The Sales table has the following columns.<br><br><img src=\"https://img.examtopics.com/pl-300/image317.png\"><br><br>The data model must support the following analysis:<br><br>\u2022\tTotal sales by product by month in which the order was placed<br>\u2022\tQuantities sold by product by day on which the order was placed<br>\u2022\tNumber of sales transactions by quarter in which the order was placed<br><br>For each of the following statements, select Yes if the statement is true. Otherwise, select No.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/pl-300/image318.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/pl-300/image319.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2023-04-12T05:40:00.000Z",
        "voteCount": 61,
        "content": "Yes - No - Yes\nno need to discuss anymore"
      },
      {
        "date": "2024-09-16T21:34:00.000Z",
        "voteCount": 2,
        "content": "you can't tell me what to discuss - you're not the boss of me"
      },
      {
        "date": "2024-01-23T10:23:00.000Z",
        "voteCount": 26,
        "content": "I think we're all here to literally discuss"
      },
      {
        "date": "2023-10-03T04:05:00.000Z",
        "voteCount": 22,
        "content": "I discuss if i want but yesnoyes"
      },
      {
        "date": "2023-11-06T16:16:00.000Z",
        "voteCount": 14,
        "content": "Yeah, we'll discuss if we want, don't order us around xD"
      },
      {
        "date": "2023-12-30T12:28:00.000Z",
        "voteCount": 7,
        "content": "Can't understand why \"no need to discuss anymore\" lol."
      },
      {
        "date": "2024-07-23T16:29:00.000Z",
        "voteCount": 1,
        "content": "so what are we discussing.."
      },
      {
        "date": "2023-03-29T12:09:00.000Z",
        "voteCount": 5,
        "content": "correct, yes, no, yes"
      },
      {
        "date": "2024-08-19T01:57:00.000Z",
        "voteCount": 1,
        "content": "Yes, No, YEs"
      },
      {
        "date": "2024-08-21T03:08:00.000Z",
        "voteCount": 1,
        "content": "Yes, We can remove the LastUpdated column and support the requirements\nNo, we need the productId in the requirements\nYes, we can remove the shipDate and still support the requirements"
      },
      {
        "date": "2024-02-15T22:42:00.000Z",
        "voteCount": 2,
        "content": "Second one is no because productID is the foreign key that links to product table to filter by product. Can't filter by product without it."
      },
      {
        "date": "2023-11-11T11:39:00.000Z",
        "voteCount": 2,
        "content": "YES - YES - YES\nWe don't need ProductID, there is AUDITID"
      },
      {
        "date": "2023-10-17T23:54:00.000Z",
        "voteCount": 4,
        "content": "The second one cannot be YES?\nWe have the AuditId field, and even if it was not a PK, by deleting ProductId we would lose the relationship between the Product and Sales tables, but we could continue to perform the required analysis (without the product detail, we would only have the id)."
      },
      {
        "date": "2023-12-03T09:35:00.000Z",
        "voteCount": 4,
        "content": "What is the relation AuditID has with products? I mean, How can you know that each audit id refers to a product? It may reference the lastupdate time."
      },
      {
        "date": "2023-10-12T14:10:00.000Z",
        "voteCount": 2,
        "content": "why second is No, we have auditID column in both tables (sales and Product)"
      },
      {
        "date": "2023-10-01T23:21:00.000Z",
        "voteCount": 3,
        "content": "the final sentence is Yes. All requirements can be calculated with only Order Date, so the Ship Date is no need for using."
      },
      {
        "date": "2023-09-06T12:35:00.000Z",
        "voteCount": 2,
        "content": "Yes\nNo\nNO\nYes, you can remove the lastupdated column without affecting the ability to perform the required analysis. \nNo, you should not remove the ProductID column. It is a critical column for linking the sales table to the product table and performing analysis by product.\nNo, you should not remove the shipdate column. It is essential for analyzing sales by day, which is one of the require analyses."
      },
      {
        "date": "2023-12-20T19:36:00.000Z",
        "voteCount": 5,
        "content": "- Total sales by product by month in which the order was placed: This analysis requires the OrderDate, ProductID, and SalesAmount columns. The ShipDate column is not required for this analysis.\n- Quantities sold by product by day on which the order was placed: This analysis requires the OrderDate, ProductID, and SalesQuantity columns. Again, the ShipDate column is not necessary for this analysis.\n- Number of sales transactions by quarter in which the order was placed: This analysis requires the OrderDate and InvoiceNumber columns. The ShipDate column is not needed for determining the number of transactions by quarter.\n\nTherefore, ShipDate column is not needed. So the 3rd answer should be Yes."
      },
      {
        "date": "2023-09-12T03:21:00.000Z",
        "voteCount": 2,
        "content": "You don't need ShipDate. Analysis by day should be done with OrderDate. The last one should also be yes."
      },
      {
        "date": "2023-05-31T23:57:00.000Z",
        "voteCount": 3,
        "content": "Yes\nNo\nYes"
      },
      {
        "date": "2023-05-20T00:05:00.000Z",
        "voteCount": 4,
        "content": "Can't we remove the ProductID column, as we have the AuditID column in both tables anyway?"
      },
      {
        "date": "2023-08-16T05:21:00.000Z",
        "voteCount": 1,
        "content": "It's an unlikely Primary Key."
      },
      {
        "date": "2023-12-08T11:20:00.000Z",
        "voteCount": 1,
        "content": "as Starvosxant said: What is the relation AuditID has with products? I mean, How can you know that each audit id refers to a product? It may reference the lastupdate time."
      },
      {
        "date": "2023-05-19T18:25:00.000Z",
        "voteCount": 2,
        "content": "I think the answer should be Y-N-N. The last one is NO because we need shipdate for transaction as required"
      },
      {
        "date": "2023-05-25T12:11:00.000Z",
        "voteCount": 3,
        "content": "In which the order was placed,order date.  Last one is yes."
      },
      {
        "date": "2023-05-02T09:12:00.000Z",
        "voteCount": 1,
        "content": "YES-NO-YES"
      },
      {
        "date": "2023-04-30T23:28:00.000Z",
        "voteCount": 1,
        "content": "Yes, No, Yes"
      },
      {
        "date": "2023-04-11T00:49:00.000Z",
        "voteCount": 1,
        "content": "Why do we need the ship date then? why don't we remove it?"
      },
      {
        "date": "2023-04-22T05:43:00.000Z",
        "voteCount": 2,
        "content": "I've got the same question, in all three options we need to sort by order date right?"
      },
      {
        "date": "2023-05-25T16:40:00.000Z",
        "voteCount": 2,
        "content": "We don't need the ShipDate. It's removed from the answer!"
      },
      {
        "date": "2023-03-29T10:20:00.000Z",
        "voteCount": 2,
        "content": "Answer is correct"
      },
      {
        "date": "2023-03-29T02:51:00.000Z",
        "voteCount": 2,
        "content": "Correct"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 66,
    "url": "https://www.examtopics.com/discussions/microsoft/view/134820-exam-pl-300-topic-2-question-84-discussion/",
    "body": "HOTSPOT -<br><br>You have Power BI report that contains the fields shown in the following exhibit.<br><br><img src=\"https://img.examtopics.com/pl-300/image364.png\"><br><br>Use the drop-down menus to select the answer choice that completes each statement based on the information presented in the graphic.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/pl-300/image365.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/pl-300/image366.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-02-28T10:30:00.000Z",
        "voteCount": 35,
        "content": "- Two explicit measures\n- Summarization setting"
      },
      {
        "date": "2024-09-13T22:59:00.000Z",
        "voteCount": 1,
        "content": "No explanation given. Wadyba gave an explanation."
      },
      {
        "date": "2024-02-29T10:04:00.000Z",
        "voteCount": 10,
        "content": "The correct answer is : \n- 2 explicit measures\n- Summarization setting"
      },
      {
        "date": "2024-05-13T07:34:00.000Z",
        "voteCount": 6,
        "content": "The given answer is incorrect...\n\nI have put \n- 2 measures\n- Summarization setting"
      },
      {
        "date": "2024-05-06T10:02:00.000Z",
        "voteCount": 7,
        "content": "- one explicit measure\n- summarization settings\nexplanation: from the visual, there is only one implicit measure that can be replaced which is the 'sum of sales amount'. the 'sum of product cost' is not an implicit measure because the cost of individual products cannot be aggregated, hence, there is no such thing as 'sum of product cost'. It is only a wrong guess by power bi. what power bi does is that whenever a table is loaded into the model, it goes through each column of the table and make a guess of their data types. whenever it sees numeric columns such as date, product cost, and sales amount, it assumes that they are aggregable and automatically creates implicit measures for those columns by adding the summation sign next to those columns as shown in the example. To mitigate this weakness, developers have to manually go through each numeric column in their data model and change the summarization settings for non-aggregable columns just as part B of this question is suggesting. Thanks, Shalom!"
      },
      {
        "date": "2024-04-30T14:29:00.000Z",
        "voteCount": 1,
        "content": "Will changing the \"Summarization setting\" impact additional visuals as well? I thought it would only impact the current visual."
      },
      {
        "date": "2024-03-08T04:52:00.000Z",
        "voteCount": 4,
        "content": "- Two explicit measures\n- Summarization setting"
      },
      {
        "date": "2024-03-08T01:02:00.000Z",
        "voteCount": 3,
        "content": "- Two explicit measures\n- Summarization setting"
      },
      {
        "date": "2024-02-28T09:34:00.000Z",
        "voteCount": 4,
        "content": "two explicit measures\nSummarization setting"
      },
      {
        "date": "2024-02-28T06:30:00.000Z",
        "voteCount": 4,
        "content": "Two explicit measures &amp; summarization settings (if used as implicit measure as on the visual)"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 67,
    "url": "https://www.examtopics.com/discussions/microsoft/view/104403-exam-pl-300-topic-2-question-67-discussion/",
    "body": "You have a Power BI data model that contains a table named Employees. The table has the following columns:<br><br>\u2022\tEmployee Name<br>\u2022\tEmail Address<br>\u2022\tStart Date<br>\u2022\tJob Title<br><br>You are implementing dynamic row-level security (RLS).<br><br>You need to create a table filter to meet the following requirements:<br><br>\u2022\tUsers must see only their own employee data.<br>\u2022\tThe DAX expression must work in both Power BI Desktop and the Power BI service.<br><br>Which expression should you use?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t[Email Address] - USERNAME()",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t[Employee Name] - USERPRINCIPALNAME()",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t[Employee Name] = USERNAME()",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t[Email Address] = USERPRINCIPALNAME()\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 45,
        "isMostVoted": true
      },
      {
        "answer": "A",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2023-04-28T06:47:00.000Z",
        "voteCount": 26,
        "content": "Within Power BI Desktop, username() will return a user in the format of DOMAIN\\User and userprincipalname() will return a user in the format of user@contoso.com. Within the Power BI service, username() and userprincipalname() will both return the user's User Principal Name (UPN). This looks similar to an email address."
      },
      {
        "date": "2023-06-10T11:00:00.000Z",
        "voteCount": 4,
        "content": "https://learn.microsoft.com/en-us/power-bi/enterprise/service-admin-rls"
      },
      {
        "date": "2023-03-31T03:32:00.000Z",
        "voteCount": 9,
        "content": "username() has the format of DOMAIN\\username\nuserprincipalname() always returns the user in the format of their user principal name, like username@contoso.com\nWe want mail, so userprincipalname() is right"
      },
      {
        "date": "2024-08-19T02:00:00.000Z",
        "voteCount": 1,
        "content": "D - [Email Address] = USERPRINCIPALNAME() is the correct one because it always returns the email address"
      },
      {
        "date": "2024-03-06T05:15:00.000Z",
        "voteCount": 6,
        "content": "WAS ON THE EXAM 02 03 2024"
      },
      {
        "date": "2024-02-23T07:55:00.000Z",
        "voteCount": 5,
        "content": "This was on the exam on 22/2/2024 (:"
      },
      {
        "date": "2024-02-16T04:07:00.000Z",
        "voteCount": 1,
        "content": "Easy, for manager role (Each manager must see only the data in the Sales and Human Resources tables for their own country)\n\nROLE:      Manager\nTABLE:    Country\nDAX:        [Email] = userprincipalname()   \n\nFiltering the table COUNTRY for the USERNAME will only allow Manager role to see data in other tables filtered by her/his own country\n\nROLE:      CFO\nTABLE:    Human Resources\nDAX:       false()\n\nThe CFO role will only have 1 restricted (false()) table that is Human resources. The rest is without filters"
      },
      {
        "date": "2023-09-06T12:42:00.000Z",
        "voteCount": 1,
        "content": "D is the correct answer."
      },
      {
        "date": "2023-07-12T08:13:00.000Z",
        "voteCount": 5,
        "content": "https://www.youtube.com/watch?v=TGgec9oP8oU\n\nthis video explains it."
      },
      {
        "date": "2023-05-02T22:10:00.000Z",
        "voteCount": 1,
        "content": "To create dynamic row-level security (RLS) in Power BI that allows users to see only their own employee data, you can create a DAX expression using the USERNAME function.\n\nHere's the DAX expression you can use for the table filter:\n\nscss\nCopy code\nEmployees[Email Address] = USERNAME() &amp; \"@contoso.com\"\nAssuming that the domain for the email addresses is contoso.com, this expression filters the Employees table to show only the rows where the Email Address column matches the email address of the current user.\n\nThe USERNAME() function returns the Windows account name of the current user in the format DOMAIN\\Username. By concatenating the returned value with \"@contoso.com\", the DAX expression generates the email address of the current user that matches the email address in the Employees table.\n\nNote that to use this DAX expression, you need to configure row-level security in Power BI Desktop or the Power BI service. You can assign roles to users and apply filters based on the DAX expression for each role."
      },
      {
        "date": "2024-01-14T17:43:00.000Z",
        "voteCount": 1,
        "content": "my understanding is that to make the provided expression work in both the desktop and PBI service you should use userprincipal(), username works on the desktop"
      },
      {
        "date": "2023-05-02T20:48:00.000Z",
        "voteCount": 1,
        "content": "does anaybody have any source for this question?"
      },
      {
        "date": "2023-04-12T05:48:00.000Z",
        "voteCount": 4,
        "content": "To implement dynamic row-level security (RLS) on the Employees table, a table filter must be created. The table filter should be based on the user's email address or user principal name (UPN), as these are unique identifiers for each user.\n\nThe DAX expression [Email Address] = USERPRINCIPALNAME() will filter the Employees table to only show rows where the Email Address column matches the UPN of the current user. This expression works in both Power BI Desktop and the Power BI service, and will ensure that each user only sees their own employee data."
      },
      {
        "date": "2023-04-06T22:52:00.000Z",
        "voteCount": 1,
        "content": "But if we use the USERPRINCIPALNAME() function it returns the user's login name, which may not be the same as their email address. right?"
      },
      {
        "date": "2023-03-29T12:14:00.000Z",
        "voteCount": 1,
        "content": "Does someone know why C is not correct?"
      },
      {
        "date": "2023-04-01T23:28:00.000Z",
        "voteCount": 3,
        "content": "Option C is incorrect because it checks for an exact match on the Employee Name column, which may not always be unique for each user."
      },
      {
        "date": "2024-01-11T09:08:00.000Z",
        "voteCount": 1,
        "content": "Thanks for the explanation, appreciate it!"
      },
      {
        "date": "2023-03-29T10:28:00.000Z",
        "voteCount": 2,
        "content": "answer is right"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 68,
    "url": "https://www.examtopics.com/discussions/microsoft/view/104676-exam-pl-300-topic-2-question-68-discussion/",
    "body": "DRAG DROP<br> -<br><br>You have the Power BI data model shown in the following exhibit.<br><br><img src=\"https://img.examtopics.com/pl-300/image320.png\"><br><br>The Country table contains the following data.<br><br><img src=\"https://img.examtopics.com/pl-300/image321.png\"><br><br>You create two row-level security (RLS) roles named Manager and CFO.<br><br>You plan to publish the dataset to the Power BI service.<br><br>You need to create DAX expressions for the RLS filters. The solution must meet the following requirements:<br><br>\u2022\tEach manager must see only the data in the Sales and Human Resources tables for their own country.<br>\u2022\tThe CFO must be prevented from seeing the data in the Human Resources table.<br>\u2022\tThe CFO must see the sales data of all countries.<br><br>How should you complete the DAX expressions to meet the requirements? To answer, drag the appropriate expressions to the correct targets. Each expression may be used once, more than once, or not at all. You may need to drag the split bar between panes or scroll to view content.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/pl-300/image322.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/pl-300/image323.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2023-04-26T02:10:00.000Z",
        "voteCount": 84,
        "content": "I simply don't get the answers to the question, or the question at all for that matter. I feel both should have two conditions... Like:\nHR = AND([Manager] &lt;&gt; \"CFO\", [Email] = userprinciplename())\nCountry = OR([MANAGER = \"CFO\", [Email] = userprinciplename())\nWhat am I missing here?"
      },
      {
        "date": "2024-04-02T09:56:00.000Z",
        "voteCount": 3,
        "content": "I thought, I was the only one"
      },
      {
        "date": "2023-06-07T01:32:00.000Z",
        "voteCount": 62,
        "content": "Human Resources &gt; False () \n\tCountry &gt; [Email] = USERPRINCIPALNAME () \n\t\n\tExplanation:\n\tI would create 2 RLS:\n\t\n\t1st with Human Resources &gt; False () \n\tAdd CFO user\n\t\u2022 The CFO must be prevented from seeing the data in the Human Resources table.\n\t\u2022 The CFO must see the sales data of all countries.\n\t\n\t2nd  with Country &gt; [Email] = USERPRINCIPALNAME () \n\tAdd manger users:\n\u2022Each manager must see only the data in the Sales and Human Resources tables for their own country."
      },
      {
        "date": "2024-04-17T09:13:00.000Z",
        "voteCount": 1,
        "content": "I agree that the correct answer is:\nHuman Resources &gt; False () \nCountry &gt; [Email] = USERPRINCIPALNAME () \n\nHowever, I wouldn't create two roles. \n\nPlease be aware that if you create 2 roles and you assign the same person to the 2 roles, the result will work as an OR instead of an AND. This means, that even if you assign the CFO to the second role (False on Human Resources), he would still get access to all regions because he is assigned to the first role for Country.\n\nIn this case, the solution is to create just one role and create two filters:\n- Human Resources &gt; False () \n- Country &gt; [Email] = USERPRINCIPALNAME ()\n\nThen assign the CFO to the role Power BI Service.\n\nI presume, that the CFO is a Manager. Therefore in this contaxt the other Managers would not get access to the Human resources. Please check:\nhttps://www.youtube.com/watch?v=M5K_jKPxdqI"
      },
      {
        "date": "2024-02-26T15:00:00.000Z",
        "voteCount": 8,
        "content": "To build on top of saraplez answer, note that we are defining two roles: Manager and CFO\n\nFor the role CFO we create the following filter on the Human Resources table:\nfalse()\nAnyone assigned to this CFO role, will not have access to the Human Resources data. We only add the first manager (CFO) to this role.\n\nfor the role Manager, we create the following filter on the Country table:\n[Email] = USERPRINCIPALNAME ()\n\nWe add Philipe, Juan and Sirini to this role. Then they would only have access to their own country data."
      },
      {
        "date": "2023-07-08T06:05:00.000Z",
        "voteCount": 1,
        "content": "I agree"
      },
      {
        "date": "2024-03-29T02:48:00.000Z",
        "voteCount": 2,
        "content": "Understood now. Thank you very for your contribution. Much appreciated."
      },
      {
        "date": "2023-07-31T07:48:00.000Z",
        "voteCount": 7,
        "content": "For those who don't understand, watch this: https://www.youtube.com/watch?v=XMLXbbSgiM0\nNB: False() restricts the entry to the table."
      },
      {
        "date": "2024-10-10T12:19:00.000Z",
        "voteCount": 1,
        "content": "For CFO: Human Resources table -&gt; False ()\nFor Managers: Country table-&gt; [Email] = USERPRINCIPALNAME ()\n\nCFO role only needs to be restricted in the hr table.\nmanager role only needs to be restricted to their own country in the country table."
      },
      {
        "date": "2024-09-05T21:56:00.000Z",
        "voteCount": 1,
        "content": "After thorought testing I found out that one of the given answer False() is not exactly right.\nIf you only apply False() to the HR table then every manager can't see the Data.\n1st requirement: \n\u2022 Each manager must see only the data in the Sales and Human Resources tables for their own country.\nCountry: [Email] = USERPRINCIPALNAME()\n\n2nd requirement:\n\u2022 The CFO must be prevented from seeing the data in the Human Resources table.\nBecause there is no manager column for HR table, I have created a measure that returns select manager from Country table and use that measure to filter the HR table.\nHR: [Selected Manager] &lt;&gt; \"CFO\" &lt;--this will return false otherwise true\n\n3rd requirement\nThe CFO must see the sales data of all countries.\n-no filter to apply\n\nI would say the selection of answers has to be corrected."
      },
      {
        "date": "2024-03-04T15:36:00.000Z",
        "voteCount": 2,
        "content": "Disregard my previous comment. I think I've figured it out. The header on the left selection says, \"Table Filter DAX Expression.\" I think it's asking by which to filter OUT. Therefore, we only need to filter CFO out of HR and filter country by user."
      },
      {
        "date": "2024-03-04T15:34:00.000Z",
        "voteCount": 1,
        "content": "Are the CFO and managers different? I thought the CFO can't access HR? What is going on? What is it saying? This question is so stupid."
      },
      {
        "date": "2024-03-03T00:57:00.000Z",
        "voteCount": 2,
        "content": "Human Resource table -&gt; False() -&gt; Assign the CFO as member in PBI service \nCountry -&gt; [Email] = USERPRINCIPLENAME() -&gt; Assign the other 3 managers in PBI service"
      },
      {
        "date": "2024-02-27T08:47:00.000Z",
        "voteCount": 2,
        "content": "First those they have very long .After reading the entire question and see then seeing options people will realise like \"kahna kya chate ho ?(what)\" We can't even do any guess."
      },
      {
        "date": "2024-02-26T06:28:00.000Z",
        "voteCount": 2,
        "content": "firstly, they asked for two roles but for which role we need to answer is not given\nSecondly, I do not think we can use column from different table while defining filter condition in mange roles.\nso for HR table, we can't have option b,c and \nfor Country table, can't use option a ,c  because for both the roles it will be wrong \nso answer colud be\n=&gt; for CFO role:\nHR : False()\nCountry : True() (CFO should see the sale for all countries)\n=&gt;for manager role:\nHR: True() (this table would be filtered by country table itself)\nCountry: [email=userprinciple()]"
      },
      {
        "date": "2024-02-22T00:10:00.000Z",
        "voteCount": 5,
        "content": "I simply don't get the question"
      },
      {
        "date": "2024-01-15T05:51:00.000Z",
        "voteCount": 1,
        "content": "Answer is Reciprocal of what it should have had been..\nBy the way correct values are choosen."
      },
      {
        "date": "2024-01-09T01:18:00.000Z",
        "voteCount": 1,
        "content": "I think the correct answer is:\n\nHuman Resource Table: [manager]=\"CFO\" (Should filter the CFO out and return a false())\nCountry: [Email]= USERPRINCIPLENAME() (Direct managers other than CFO to their country data, both sales and human resources)"
      },
      {
        "date": "2023-12-29T01:52:00.000Z",
        "voteCount": 1,
        "content": "Hacen Falta tres expresiones DAX:\n\nPara Rol gerente, tanto pais como recursos humanos: [Correo electr\u00f3nico] = USERPRINCIPALNAME ()\n\nPara rol CFO , dos expresiones: Una en pais: [Correo electr\u00f3nico] = USERPRINCIPALNAME ()\ny otra en RRHH, true() para que vea todo"
      },
      {
        "date": "2023-10-25T07:21:00.000Z",
        "voteCount": 5,
        "content": "What it the correct answer?"
      },
      {
        "date": "2023-10-01T23:46:00.000Z",
        "voteCount": 7,
        "content": "In my opinion, because it can be assign users to each RLS so the correct answer is HR - False() and Country - USERPRINCIPLENAME().\nSo the CFO will be assign to the RLS of HR and other Managers will be assign to the RLS of Country."
      },
      {
        "date": "2023-09-06T13:25:00.000Z",
        "voteCount": 1,
        "content": "[manager]=\"CFO'\n [Email] = userprinciplaname()\n\n[manager]=\"CFO': ensures that only the \"CFO\" role can see Human Resources data for the USA.\n [Email] = userprinciplaname(): ensures that each manager sees only their country's data in the Sales and Human resources tables."
      },
      {
        "date": "2024-04-05T21:14:00.000Z",
        "voteCount": 1,
        "content": "CFO isn't supposed to see any human resources information, so \"false()\" works better. if there were a manager column in HR table, he could then see human resources info where CFO is listed"
      },
      {
        "date": "2023-09-12T04:04:00.000Z",
        "voteCount": 6,
        "content": "From the question:\"The CFO must be prevented from seeing the data in the Human Resources table.\" So your logic about the CFO does not hold right?"
      },
      {
        "date": "2023-08-30T01:40:00.000Z",
        "voteCount": 7,
        "content": "I don't get the point..."
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 69,
    "url": "https://www.examtopics.com/discussions/microsoft/view/104406-exam-pl-300-topic-2-question-69-discussion/",
    "body": "You have a Power BI data model that imports data from a Microsoft Excel spreadsheet.<br><br>You use Power Query to load a query that contains both renamed and custom columns.<br><br>Later, you attempt to reload the query and receive the following error message.<br><br>Expression.Error: The column 'Category' of the table wasn't found.<br><br>What are two possible causes of the error? Each correct answer presents a complete solution.<br><br>NOTE: Each correct selection is worth one point.",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tThe column was removed from the source file.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tThe column was renamed in the source file.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tThe file is no longer in the specified location.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tThe data type of the column was changed."
    ],
    "answer": "AB",
    "answerDescription": "",
    "votes": [
      {
        "answer": "AB",
        "count": 32,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-03-31T03:39:00.000Z",
        "voteCount": 20,
        "content": "correct"
      },
      {
        "date": "2023-12-03T09:39:00.000Z",
        "voteCount": 15,
        "content": "All the questions of those who upvote this comment will be at this level of difficult on the exam \ud83d\ude4f\ud83d\ude4c"
      },
      {
        "date": "2023-12-13T04:16:00.000Z",
        "voteCount": 4,
        "content": "bruh this isn't reddit, why are u even asking for upvotes here ?"
      },
      {
        "date": "2024-08-19T02:02:00.000Z",
        "voteCount": 1,
        "content": "A,B correct it can be either the column has been renamed or deleted as well"
      },
      {
        "date": "2024-03-20T06:29:00.000Z",
        "voteCount": 3,
        "content": "correct"
      },
      {
        "date": "2024-02-22T00:20:00.000Z",
        "voteCount": 2,
        "content": "the question is about a column, not the file in itself"
      },
      {
        "date": "2023-09-21T13:27:00.000Z",
        "voteCount": 3,
        "content": "The error message is column specific Error: The column 'Category' of the table wasn't found. Both option A and B in in line with this"
      },
      {
        "date": "2023-09-06T13:31:00.000Z",
        "voteCount": 4,
        "content": "A &amp; B are correct answers. \nA. If the column 'Category' was present in the source file when the query was initially loaded but has been removed from the sources file since then, you would encounter this error when attempting to reload the query. \nB. If the \"Category\" column in the source file was renamed after the query was initially loaded, power query wouldn't be able to find the column with the original name, resulting in the error."
      },
      {
        "date": "2023-08-13T11:31:00.000Z",
        "voteCount": 1,
        "content": "Apart from this questions, can we also practice with Microsoft Assessment?"
      },
      {
        "date": "2023-06-07T12:02:00.000Z",
        "voteCount": 2,
        "content": "A. The column was removed from the source file.\nB. The column was renamed in the source file."
      },
      {
        "date": "2023-05-02T20:35:00.000Z",
        "voteCount": 2,
        "content": "Correct"
      },
      {
        "date": "2023-04-12T05:56:00.000Z",
        "voteCount": 4,
        "content": "Answer is correct"
      },
      {
        "date": "2023-03-29T22:36:00.000Z",
        "voteCount": 3,
        "content": "answer is correct"
      },
      {
        "date": "2023-03-29T10:48:00.000Z",
        "voteCount": 2,
        "content": "answer is correct"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 70,
    "url": "https://www.examtopics.com/discussions/microsoft/view/104354-exam-pl-300-topic-2-question-70-discussion/",
    "body": "You have a Power BI model that contains a table named Sales. The Sales table contains the following columns:<br><br>\u2022\tOrder Line ID<br>\u2022\tProduct ID<br>\u2022\tUnit Price<br>\u2022\tOrder ID<br>\u2022\tQuantity<br><br>Orders are uniquely identified by using the order ID and can have multiple order lines. Each order line within an order contains a different product ID.<br><br>You need to write a DAX measure that counts the number of orders.<br><br>Which formula should you use?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCount('Sales'[Order ID])",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCountA('Sales' [Order ID])",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCountRows('Sales')",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDistinctCount('Sales' [Order ID])\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 85,
        "isMostVoted": true
      },
      {
        "answer": "A",
        "count": 41,
        "isMostVoted": false
      },
      {
        "answer": "C",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2023-04-07T23:12:00.000Z",
        "voteCount": 41,
        "content": "Order only once but can have multiple line based of different procduct\n\nOrder ID A000101....Product A\nOrder ID A000101.....Product B\nOrder ID A000101....Product C\nOrder ID A000101....Product D\n\nCorrect Answer only D\n\nNo confusion, and no need to discuss further"
      },
      {
        "date": "2023-06-23T08:49:00.000Z",
        "voteCount": 23,
        "content": "you had put A as selected answer"
      },
      {
        "date": "2023-09-21T21:09:00.000Z",
        "voteCount": 40,
        "content": "Apparently there is confusion and a need to discuss further?"
      },
      {
        "date": "2024-05-31T03:43:00.000Z",
        "voteCount": 1,
        "content": "seriously"
      },
      {
        "date": "2023-11-06T17:17:00.000Z",
        "voteCount": 35,
        "content": "I hate it when someone says there's no need to discuss further. Like are u from Microsoft or what?"
      },
      {
        "date": "2023-11-26T01:07:00.000Z",
        "voteCount": 8,
        "content": "There's no confussion that the person is clearly confuse so no need to discuss further!"
      },
      {
        "date": "2024-02-02T02:19:00.000Z",
        "voteCount": 4,
        "content": "thanks there is no need for no confusion in my no thinking head"
      },
      {
        "date": "2023-03-31T05:31:00.000Z",
        "voteCount": 37,
        "content": "\"Orders are uniquely identified by using the order ID and can have multiple order lines\" - I think the important statement is \"and can have multiple order lines\" which means that the order ID can appear more than once in the table if the order contains more than one products - so I think the answer is correct."
      },
      {
        "date": "2024-08-22T20:21:00.000Z",
        "voteCount": 2,
        "content": "D is correct. SanaCanada is a bit loco"
      },
      {
        "date": "2024-08-21T06:41:00.000Z",
        "voteCount": 1,
        "content": "The correct answer is D"
      },
      {
        "date": "2024-08-19T02:03:00.000Z",
        "voteCount": 1,
        "content": "The correct answer is D: DistinctCount('Sales' [Order ID])"
      },
      {
        "date": "2024-04-28T06:44:00.000Z",
        "voteCount": 1,
        "content": "Order ID will be repeated if more than one product lines are in that order. So, I think distinctcount is necessary."
      },
      {
        "date": "2024-02-22T02:47:00.000Z",
        "voteCount": 4,
        "content": "Count only supports :Numbers,Dates,Strings\nCountA also supports Boolean\nCountRows will return values depending on relatedtable if any else counts number of rows in table\nDistinctCount as it says \"distinct\" counts distinct values (same as sql select distinct statement)\n\nAnswer is D"
      },
      {
        "date": "2024-01-16T20:24:00.000Z",
        "voteCount": 2,
        "content": "D is correct"
      },
      {
        "date": "2024-01-15T07:50:00.000Z",
        "voteCount": 2,
        "content": "D is correct"
      },
      {
        "date": "2023-12-03T09:42:00.000Z",
        "voteCount": 2,
        "content": "Fact tables dont have primary key. So, you cant assume that order id is unique. Thats why a lot of you are voting for countrows or count. The right answer is distinct count"
      },
      {
        "date": "2024-02-18T09:51:00.000Z",
        "voteCount": 1,
        "content": "Yes, in the fact table we can have multiple rows with the same OrderID. The correct answer is D."
      },
      {
        "date": "2023-11-13T22:24:00.000Z",
        "voteCount": 2,
        "content": "D for sure"
      },
      {
        "date": "2023-11-13T04:55:00.000Z",
        "voteCount": 2,
        "content": "Answer is D."
      },
      {
        "date": "2023-10-09T18:22:00.000Z",
        "voteCount": 1,
        "content": "Why not C?"
      },
      {
        "date": "2023-11-06T17:20:00.000Z",
        "voteCount": 1,
        "content": "Because the number of rows in the table does not directly translate to the number of distinct Order IDs"
      },
      {
        "date": "2023-10-01T23:53:00.000Z",
        "voteCount": 2,
        "content": "Absolutely agree with answer is D."
      },
      {
        "date": "2023-09-22T13:08:00.000Z",
        "voteCount": 3,
        "content": "D for sure"
      },
      {
        "date": "2023-09-18T05:24:00.000Z",
        "voteCount": 4,
        "content": "Answer is D."
      },
      {
        "date": "2023-09-18T05:24:00.000Z",
        "voteCount": 2,
        "content": "Answer is D."
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 71,
    "url": "https://www.examtopics.com/discussions/microsoft/view/105080-exam-pl-300-topic-2-question-71-discussion/",
    "body": "HOTSPOT<br> -<br><br>You are creating a Power BI model in Power BI Desktop.<br><br>You need to create a calculated table named Numbers that will contain all the integers from -100 to 100.<br><br>How should you complete the DAX calculation? To answer, select the appropriate options in the answer area.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/pl-300/image337.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/pl-300/image338.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2023-04-07T23:16:00.000Z",
        "voteCount": 43,
        "content": "Correct Answer\n\nTo create a calculated table named Numbers in Power BI Desktop that contains all the integers from -100 to 100, you can use the following DAX calculation:\n\nNumbers = GENERATESERIES(-100, 100, 1)\n\nExplanation:\n\nThe GENERATESERIES function generates a table of values that starts at the first argument (-100), ends at the second argument (100), and increments by the third argument (1) in this case. The resulting table will contain all the integers from -100 to 100 inclusive.\n\nThe calculated table is named \"Numbers\" and is created by assigning the output of the GENERATESERIES function to it using the \"=\" operator.\n\nNo confusion, and no need to discuss further"
      },
      {
        "date": "2023-04-04T04:33:00.000Z",
        "voteCount": 7,
        "content": "Correct! \nGENERATESERIES - (-100,100,1)"
      },
      {
        "date": "2024-08-19T02:04:00.000Z",
        "voteCount": 1,
        "content": "The answer is correct!"
      },
      {
        "date": "2024-02-22T03:16:00.000Z",
        "voteCount": 2,
        "content": "GenerateSeries uses 3 arguments, lower value, upper value, step (from -100 to 100 increment by 1)\n\nGenerate(table1, table2) creates a new table with cartesian products (for each row in table 2 add  all rows from table1)\nIf table1 has 2 records and table 2 has 3 records, new table will have 2X3=6records\nBY RECORD ORDER OF TABLE 1\nt1\tt2\n1\t1\n2\t1\n1\t2\n2\t2\n1\t3\n2\t3\n\n\nGenerateAll(table1, table2) creates a new table with cartesian products (for each row in table 1 add all rows from table2)\nIf table1 has 2 records and table 2 has 3 records, new table will have 2X3=6records\nBY RECORD ORDER OF TABLE 2\nt1\tt2\n1\t1\n1\t2\n1\t3\n2\t1\n2\t2\n2\t3\n\nGenerate and GenerateAll use the same principle as multidimension arrays"
      },
      {
        "date": "2024-01-16T20:26:00.000Z",
        "voteCount": 1,
        "content": "Correct Answer given"
      },
      {
        "date": "2023-09-06T13:42:00.000Z",
        "voteCount": 1,
        "content": "Generateseries (-100,100,1)\nThis formula generates a serious of numbers starting from -100, ending at 100, with an increment of 1."
      },
      {
        "date": "2023-06-07T12:21:00.000Z",
        "voteCount": 1,
        "content": "Correct \nNumbers = GENERATESERIES(-100, 100, 1)\nStart -100\nEnd 100\nIncrement 1"
      },
      {
        "date": "2023-04-16T08:07:00.000Z",
        "voteCount": 4,
        "content": "Correct.\nGENERATESERIES(-100, 100, 1)"
      },
      {
        "date": "2023-04-12T06:12:00.000Z",
        "voteCount": 5,
        "content": "GENERATESERIES function will generate a table of integers from the starting value (-100) to the ending value (100), with an increment of 1.\nThis table will be returned as a new calculated table named \"Numbers\"."
      },
      {
        "date": "2023-04-11T05:31:00.000Z",
        "voteCount": 3,
        "content": "Correct"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 72,
    "url": "https://www.examtopics.com/discussions/microsoft/view/117396-exam-pl-300-topic-2-question-72-discussion/",
    "body": "In Power Query Editor, you have a query named Sales Data that contains the following columns.<br><br><img src=\"https://img.examtopics.com/pl-300/image342.png\"><br><br>You need to create two queries named Product Dimension and Sales Fact based on the Sales Data query. The solution must minimize maintenance effort and the size of the dataset.<br><br>Which two actions should you perform? Each correct answer presents part of the solution.<br><br>NOTE: Each correct selection is worth one point.",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tReference the Sales Data query to create the new queries.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDisable the load for the Sales Fact query.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDuplicate the Sales Data query to create the new queries.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tClear Include in report refresh for the Sales Data query.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDisable the load for the Sales Data query.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "AE",
    "answerDescription": "",
    "votes": [
      {
        "answer": "AE",
        "count": 29,
        "isMostVoted": true
      },
      {
        "answer": "AC",
        "count": 2,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2023-09-18T18:00:00.000Z",
        "voteCount": 40,
        "content": "Please be responsible. Comment and vote carefully.\nThe answer is A&amp;E.\t\nTo choose reference or duplicate or copy, the points are:\n1: Reference, duplicate, copy queries will all make the file bigger to a similar size.\n2: Choose Reference if you want the referenced queries to change when the original query changes. Choose Duplicate or Copy if you don\u2019t want that. Reference queries is more common in many real-world scenarios because the fact table is always changing.\n3: Copy and Duplicate copy the transformation steps but reference not.\nDisable the load for the Sales Data query will : (1) It will be cleaner in Power BI desktop because you won\u2019t see the Sales data query. (2) improve performance. The star schema is normally the best in Power Bi modelling because of the performance. And this is the reason why we need to separate the main table into different tables(Normalization). The main table itself should not be included in a star scheme."
      },
      {
        "date": "2023-08-05T04:35:00.000Z",
        "voteCount": 16,
        "content": "Agreed, A &amp; E are correct"
      },
      {
        "date": "2024-08-22T20:26:00.000Z",
        "voteCount": 1,
        "content": "A &amp; E is correct"
      },
      {
        "date": "2024-08-19T02:08:00.000Z",
        "voteCount": 1,
        "content": "A, E is the correct one"
      },
      {
        "date": "2024-03-07T23:28:00.000Z",
        "voteCount": 1,
        "content": "Reference queries and Disable Sales Data Query works as per real-world scenarios."
      },
      {
        "date": "2024-01-16T20:30:00.000Z",
        "voteCount": 1,
        "content": "A&amp;E is correct"
      },
      {
        "date": "2024-01-02T22:45:00.000Z",
        "voteCount": 7,
        "content": "To create two queries named Product Dimension and Sales Fact based on the Sales Data query in Power Query Editor, while minimizing maintenance effort and the size of the dataset, you should perform the following two actions:\n\nReference the Sales Data query to create the new queries: This allows you to reuse the loaded data without the need for additional storage or processing. You will not be duplicating data, which helps to keep the dataset size down and maintenance effort low.\n\nDisable the load for the Sales Data query: This step prevents the original Sales Data query from being loaded into the model, which minimizes the size of the dataset since only the necessary tables (Product Dimension and Sales Fact) will be loaded.\n\nThese steps are recommended practices in scenarios where dimension tables need to be dynamic and are derived from fact tables within Power Query Editor, as they avoid unnecessary duplication of data and keep the dataset optimized."
      },
      {
        "date": "2023-11-03T16:39:00.000Z",
        "voteCount": 1,
        "content": "I think A et C"
      },
      {
        "date": "2023-09-23T09:53:00.000Z",
        "voteCount": 1,
        "content": "I'm not sure 100%"
      },
      {
        "date": "2023-09-18T05:36:00.000Z",
        "voteCount": 1,
        "content": "I think A &amp; C is correct answer."
      },
      {
        "date": "2023-09-06T13:51:00.000Z",
        "voteCount": 2,
        "content": "A &amp; C are correct. \nA. Referencing the sales data query ensures that the new queries use the same data source and structure, minimizing maintenance effort. \nC. Duplicate the sales data query creates copies of the data in separate queries. This allows you to work with the data independently for Product Dimension and Sales Fact without impacting the original sales data query."
      },
      {
        "date": "2023-08-12T10:57:00.000Z",
        "voteCount": 1,
        "content": "I think it's A and C."
      },
      {
        "date": "2023-08-16T05:35:00.000Z",
        "voteCount": 1,
        "content": "A and C would give you too many queries, and make the dataset unnecessarily large."
      },
      {
        "date": "2023-08-05T02:16:00.000Z",
        "voteCount": 2,
        "content": "The correct answer should be A and C"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 73,
    "url": "https://www.examtopics.com/discussions/microsoft/view/117375-exam-pl-300-topic-2-question-73-discussion/",
    "body": "You have a Power BI model that contains a table named Date. The Date table contains the following columns:<br><br>\u2022\tDate<br>\u2022\tFiscal Year<br>\u2022\tFiscal Quarter<br>\u2022\tMonth Name<br>\u2022\tCalendar Year<br>\u2022\tWeek Number<br>\u2022\tMonth Number<br>\u2022\tCalendar Quarter<br><br>You need to create a calculated table based on the Date table. The calculated table must contain only unique combinations of values for Calendar Year, Calendar Quarter, and Calendar Month.<br><br>Which DAX function should you include in the table definition?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tADDCOLUMNS",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCALCULATE",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSUMMARIZE\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDATATABLE"
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 32,
        "isMostVoted": true
      },
      {
        "answer": "A",
        "count": 1,
        "isMostVoted": false
      },
      {
        "answer": "D",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2023-09-19T13:29:00.000Z",
        "voteCount": 78,
        "content": "I wanna say that again. Comment and vote carefully before you have actually done some research otherwise It will cause confusion to other people.\nThe answer is Summarize. \nUniqueCalendarTable = \nSUMMARIZE(\n    Date,\n    'Date'[Calendar Year],\n    'Date'[Calendar Quarter],\n    'Date'[Month Name]\n)"
      },
      {
        "date": "2024-04-29T11:03:00.000Z",
        "voteCount": 1,
        "content": "SUMMARIZE may provide the sum of quarter no?"
      },
      {
        "date": "2023-10-26T02:34:00.000Z",
        "voteCount": 17,
        "content": "\"Comment and vote carefully before you have actually done some research\" or after you've actually done some research?"
      },
      {
        "date": "2023-08-13T06:34:00.000Z",
        "voteCount": 12,
        "content": "Should be Summarized"
      },
      {
        "date": "2024-05-04T02:04:00.000Z",
        "voteCount": 3,
        "content": "Thank you for your solution, Pocu, it helped a lot!"
      },
      {
        "date": "2024-03-07T23:33:00.000Z",
        "voteCount": 3,
        "content": "Summarize is the correct answer!"
      },
      {
        "date": "2024-02-25T17:44:00.000Z",
        "voteCount": 1,
        "content": "Should be Summarized"
      },
      {
        "date": "2024-02-22T03:59:00.000Z",
        "voteCount": 3,
        "content": "AddColumns creates a new table including ALL FIELDS from the selected table AND ADD new columns to it based on parameters\n\nSummarize creates a new EMPTY table using the table name given as first parameter and including the fields parameters that Intellisense is giving you\n\nSUMMARIZE is the function to use"
      },
      {
        "date": "2023-11-03T15:37:00.000Z",
        "voteCount": 1,
        "content": "It must be C not A"
      },
      {
        "date": "2023-09-18T06:08:00.000Z",
        "voteCount": 1,
        "content": "A is the correct answer I have tested."
      },
      {
        "date": "2023-10-08T01:23:00.000Z",
        "voteCount": 5,
        "content": "Nope, ADDCOLUMNS will add additional column to given table. Therefore, outcome is given table with all its original columns and the added ones. \nBut the question only requires 3 columns. --&gt; SUMMARIZE is correct answer here"
      },
      {
        "date": "2023-08-17T16:45:00.000Z",
        "voteCount": 4,
        "content": "https://youtu.be/VurpXBcbrT0"
      },
      {
        "date": "2023-08-14T03:15:00.000Z",
        "voteCount": 3,
        "content": "ADDCOLUMNS is correct. It Adds calculated columns to the given table or table expression whereas SUMMARIZE Returns a summary table for the requested totals over a set of groups."
      },
      {
        "date": "2023-08-12T11:02:00.000Z",
        "voteCount": 1,
        "content": "The DATATABLE function in DAX allows you to create a calculated table. The calculated table can be based on any data source, including the Date table.\n\nTo create a calculated table that contains only unique combinations of values for Calendar Year, Calendar Quarter, and Calendar Month, you can use the following DAX code:"
      },
      {
        "date": "2024-09-18T01:31:00.000Z",
        "voteCount": 1,
        "content": "DATATABLE: This function allows you to manually define a table by specifying column names and rows, but it\u2019s not used for summarizing an existing table."
      },
      {
        "date": "2023-08-07T11:14:00.000Z",
        "voteCount": 3,
        "content": "Addcolumns does not create a new table, but Summarize does create it"
      },
      {
        "date": "2023-08-05T06:40:00.000Z",
        "voteCount": 3,
        "content": "SUMMARIZE should be the answer"
      },
      {
        "date": "2023-08-05T04:44:00.000Z",
        "voteCount": 7,
        "content": "I think it should be SUMMARIZE\n\n\nSUMMARIZE:\n\"Creates a summary of the input table grouped by the specified columns.\"\n\nADDCOLUMNS:\n\"Returns a table with new columns specified by the DAX expressions.\"\n\nBased on this, using SUMMARIZE will give us the unique combination we want and don't need to use DAX expressions to create the calculated table."
      },
      {
        "date": "2023-08-05T02:14:00.000Z",
        "voteCount": 1,
        "content": "The correct answer should be SUMMARIZE"
      },
      {
        "date": "2023-08-04T22:35:00.000Z",
        "voteCount": 1,
        "content": "CalculatedTable =\nSUMMARIZECOLUMNS(\n    'Date'[Calendar Year],\n    'Date'[Calendar Quarter],\n    'Date'[Month Name]\n)"
      },
      {
        "date": "2023-08-04T22:37:00.000Z",
        "voteCount": 1,
        "content": "I think SUMMARIZE"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 74,
    "url": "https://www.examtopics.com/discussions/microsoft/view/117413-exam-pl-300-topic-2-question-74-discussion/",
    "body": "HOTSPOT<br> -<br><br>You have a Power BI model that contains the following data.<br><br><img src=\"https://img.examtopics.com/pl-300/image343.png\"><br><br>The Date table relates to the Sales table by using the Date columns.<br><br>You need to create a calculated table that will contain the following:<br><br>\u2022\tA row for each year<br>\u2022\tA column that contains the total sales per year<br><br>How should you complete the DAX calculation? To answer, select the appropriate options in the answer area.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/pl-300/image344.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/pl-300/image345.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2023-08-05T05:20:00.000Z",
        "voteCount": 26,
        "content": "Agreed with SUMMARIZE - Date[Year]"
      },
      {
        "date": "2024-10-09T17:48:00.000Z",
        "voteCount": 1,
        "content": "The ROLLUP function is used exclusively within SUMMARIZE.\nE.g. \nSUMMARIZE (\n        Sales,\n        ROLLUP ( 'Date'[Calendar Year] ),\n        \"Year total\", ISSUBTOTAL ( 'Date'[Calendar Year] ),\n        \"Amount\", [Sales Amount]\n    )"
      },
      {
        "date": "2024-10-09T17:50:00.000Z",
        "voteCount": 1,
        "content": "Correct answer -&gt; SUMMARIZE, Date[Year]"
      },
      {
        "date": "2024-04-02T02:33:00.000Z",
        "voteCount": 3,
        "content": "I've recreated mock data through ChatGPT and in PowerBI.\nI've tested the following dax measure :\n- SalesSummary = SUMMARIZE(Sales,Date[Date],\"Sales\",SUM(Sales[Sales]))\n- SalesSummary = SUMMARIZE(Sales,Date[Year],\"Sales\",SUM(Sales[Sales]))\n\nFirst dax measures creates a table that has many rows as many sales in that month have been sold and does not respond to \"A row for each year\" requirement.\nBy using Date[Year], you have a summarized Table which you have ONLY one row per each year with the value as sum\nSomething like this :\n2024 | 8000,00$\n2023 | 5000,00$\n\nRollup and Select Columns in first menu are wrong as they don't match parameters.\nSo, Correct answer is *SalesSummary = SUMMARIZE(Sales,Date[Year],\"Sales\",SUM(Sales[SalesAmount]))*\n\n(don't mind the names used for mockup data)"
      },
      {
        "date": "2024-02-21T08:11:00.000Z",
        "voteCount": 1,
        "content": "I think it should be..\nSummarize , sales [date]"
      },
      {
        "date": "2024-02-26T01:43:00.000Z",
        "voteCount": 6,
        "content": "Guys please read the question, you you chose date you will have many rows...\nA column that contains the total sales per year"
      },
      {
        "date": "2023-10-30T05:06:00.000Z",
        "voteCount": 1,
        "content": "How this can be correct if Date[Year] is integer?"
      },
      {
        "date": "2024-01-14T20:28:00.000Z",
        "voteCount": 1,
        "content": "in the Date table Year is an integer"
      },
      {
        "date": "2023-08-17T16:49:00.000Z",
        "voteCount": 4,
        "content": "Ans is correct"
      },
      {
        "date": "2023-08-17T16:50:00.000Z",
        "voteCount": 4,
        "content": "https://learn.microsoft.com/en-us/dax/summarize-function-dax"
      },
      {
        "date": "2023-08-14T03:17:00.000Z",
        "voteCount": 1,
        "content": "Agreed"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 75,
    "url": "https://www.examtopics.com/discussions/microsoft/view/117414-exam-pl-300-topic-2-question-75-discussion/",
    "body": "You use Power Query Editor to import and preview sales data from the years 2020 and 2021 in a Microsoft Excel file as shown in the following exhibit.<br><br><img src=\"https://img.examtopics.com/pl-300/image346.png\"><br><br>You need to shape the query to display the following three columns:<br><br>\u2022\tMonth<br>\u2022\tSales<br>\u2022\tYear<br><br>What should you select in Power Query Editor?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tMerge columns",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tTranspose",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUnpivot columns\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tPivot column"
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 37,
        "isMostVoted": true
      },
      {
        "answer": "B",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2023-08-17T16:52:00.000Z",
        "voteCount": 25,
        "content": "It's the classic definition of unpivot"
      },
      {
        "date": "2023-12-03T09:49:00.000Z",
        "voteCount": 19,
        "content": "Upvote this comment so all your exam questions will be like this \ud83d\ude4c\ud83d\ude4f"
      },
      {
        "date": "2024-08-19T02:10:00.000Z",
        "voteCount": 1,
        "content": "We need to unpivot columns and rename them"
      },
      {
        "date": "2024-03-20T11:43:00.000Z",
        "voteCount": 2,
        "content": "Sales numbers are pivoted in 2 \"year\" columns. Just need to unpivot these columns, then rename atribute and value columns to something like \"Year\" and \"Total Sales\"."
      },
      {
        "date": "2023-09-24T01:55:00.000Z",
        "voteCount": 4,
        "content": "C Correct"
      },
      {
        "date": "2023-09-06T14:28:00.000Z",
        "voteCount": 5,
        "content": "C is correct. \nTo shape the query to display the required three columns (month, sales,year), you should select the \"Unpivot columns\" option in Power Query Editor. This will transfer the data from its current columnar structure (where each year is a separate column) into a tabular format with separate rows for each combination of Month, Sales, and Year."
      },
      {
        "date": "2023-08-09T04:00:00.000Z",
        "voteCount": 4,
        "content": "Tested"
      },
      {
        "date": "2023-08-08T18:15:00.000Z",
        "voteCount": 1,
        "content": "Wouldn't it be transpose? Transpose rows 2020 and 2021 and rename new column to Revenue?"
      },
      {
        "date": "2023-08-08T18:18:00.000Z",
        "voteCount": 5,
        "content": "ope, scratch that. I see that it's unpivot now"
      },
      {
        "date": "2023-08-05T05:29:00.000Z",
        "voteCount": 1,
        "content": "C is correct assuming we are selecting the \"2020\" and \"2021\" columns"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 76,
    "url": "https://www.examtopics.com/discussions/microsoft/view/117415-exam-pl-300-topic-2-question-76-discussion/",
    "body": "HOTSPOT<br> -<br><br>You are creating a Power BI model to analyze inventory.<br><br>You load data into three tables named Date, Product, and Inventory. The Inventory table relates to the Date and Product tables by using one-to-many relationships.<br><br>Inventory data is recorded daily with no exceptions. The correct inventory quantity for a given product in a month is the last recorded value for that month.<br><br>You need to write a DAX measure that will show the correct inventory value when a user analyzes inventory by year, month, or date.<br><br>How should you complete the measure? To answer, select the appropriate options in the answer area.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/pl-300/image347.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/pl-300/image348.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2023-08-05T05:44:00.000Z",
        "voteCount": 21,
        "content": "I believe the answer is correct"
      },
      {
        "date": "2023-08-13T08:42:00.000Z",
        "voteCount": 10,
        "content": "Calculate\nLastNonBlankValue\n\nLASTDATE will NOT work. Date - is a date table and it contains all days of the calendar month continuously so it will always return the last day of the month even if there is no inventory records. \"The correct inventory quantity for a given product in a month is the last recorded value for that month.\". That's why we should use LastNonBlankValue instead."
      },
      {
        "date": "2023-08-16T05:48:00.000Z",
        "voteCount": 6,
        "content": "LASTNONBLANKVALUE also requires an expression though.\nhttps://learn.microsoft.com/nl-nl/dax/lastnonblankvalue-function-dax"
      },
      {
        "date": "2024-05-09T02:46:00.000Z",
        "voteCount": 1,
        "content": "The right answer should be LastDate.\nIt can't be LASTNONBLANK as it is requires an expresion. Please find below the sintax for LASTNONBLANK:\n\n- LASTNONBLANK(&lt;column&gt;,&lt;expression&gt;) \n\nThis function is typically used to return the last value of a column for which the expression is not blank. For example, you could get the last value for which there were sales of a product (for instance if you want to exclude holidays from the calculation)."
      },
      {
        "date": "2023-08-22T07:48:00.000Z",
        "voteCount": 8,
        "content": "It also says 'Inventory data is recorded daily with no exceptions.' so I concluded that each day would have an inventory record."
      },
      {
        "date": "2024-08-19T02:11:00.000Z",
        "voteCount": 1,
        "content": "Correct answer"
      },
      {
        "date": "2024-04-08T05:10:00.000Z",
        "voteCount": 2,
        "content": "Hello, can someone explain to me why Max won't do (if that's the case, as it seems)? Thank you in advance!"
      },
      {
        "date": "2024-03-22T02:43:00.000Z",
        "voteCount": 2,
        "content": "LASTNONBLANKVALUE this will not working as it requires 2 parameters."
      },
      {
        "date": "2024-01-15T10:15:00.000Z",
        "voteCount": 1,
        "content": "how do you guys use Date[Date] as the expression in the LASTNONBLANK function like in the example from earlier answers \"LASTNONBLANK('Inventory'[QuantityAvailable], 'Date'[Date])\"?"
      },
      {
        "date": "2024-01-15T13:15:00.000Z",
        "voteCount": 2,
        "content": "I was able to do it this way:\nCALCULATE(SUM(Inventory[QuantityAvailable]),LASTDATE('Inventory'[Date])\n)\nmy sample dataset dates (Jan-Apr 2023) and Date table (Jan-Dec 2023) dates probably not tuned properly so if I use Date[Date] instead of Inventory[Date] my measure returns Blank"
      },
      {
        "date": "2023-09-06T14:35:00.000Z",
        "voteCount": 1,
        "content": "Calculate\nLastDate \nLast Inventory Count =\nCALCULATE(\n    LASTNONBLANK('Inventory'[QuantityAvailable], 'Date'[Date]),\n    LASTDATE('Date'[Date])\n)"
      },
      {
        "date": "2023-09-03T00:29:00.000Z",
        "voteCount": 7,
        "content": "CALCULATE\nLASTDATE\n\nIt isn't MAX because that would returns an scalar instead of a table.\nhttps://www.sqlbi.com/blog/marco/2013/10/22/difference-between-lastdate-and-max-for-semi-additive-measures-in-dax/"
      },
      {
        "date": "2024-03-10T22:34:00.000Z",
        "voteCount": 1,
        "content": "how you are saying it is returning table? how did you find that?"
      },
      {
        "date": "2023-08-29T05:36:00.000Z",
        "voteCount": 6,
        "content": "The answer is correct"
      },
      {
        "date": "2023-08-14T15:55:00.000Z",
        "voteCount": 5,
        "content": "I think this questions is not well explained.\nLet me say why ( from brazil, sorry if I write wrong):\n1. That is form to create a calendar table based in the dates of the fact table, for example: if I create based on the fact table, the last date will be the last date of the fact table.\n\n2. Other way of create a calendar table is just to put the days of a number of years that you want, so, in this case the last date will be the last date of the calendar table and not the last date of the fact table. \nSo, in my opinion it is better annul this question, or consider lastnonblankvalue and lastdate correct."
      },
      {
        "date": "2024-08-25T06:45:00.000Z",
        "voteCount": 2,
        "content": "yep question is confusing indeed"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 77,
    "url": "https://www.examtopics.com/discussions/microsoft/view/117556-exam-pl-300-topic-2-question-77-discussion/",
    "body": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.<br><br>After you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.<br><br>You have a Power BI report that imports a date table and a sales table from an Azure SQL database data source. The sales table has the following date foreign keys:<br><br>\u2022\tDue Date<br>\u2022\tOrder Date<br>\u2022\tDelivery Date<br><br>You need to support the analysis of sales over time based on all three dates at the same time.<br><br>Solution: From the Fields pane, you rename the date table as Due Date. You use a DAX expression to create Order Date and Delivery Date as calculated tables. You create active relationships between the sales table and each date table.<br><br>Does this meet the goal?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tYes\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tNo"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 12,
        "isMostVoted": true
      },
      {
        "answer": "B",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2023-08-07T15:10:00.000Z",
        "voteCount": 15,
        "content": "100% Just finish reading about that."
      },
      {
        "date": "2024-02-23T07:56:00.000Z",
        "voteCount": 6,
        "content": "This was on the exam on 22/2/2024 (:"
      },
      {
        "date": "2024-08-19T02:13:00.000Z",
        "voteCount": 1,
        "content": "Yes, we have 3 active relationships one for each date"
      },
      {
        "date": "2024-04-17T23:33:00.000Z",
        "voteCount": 1,
        "content": "A is correct"
      },
      {
        "date": "2024-03-20T11:58:00.000Z",
        "voteCount": 1,
        "content": "Correct"
      },
      {
        "date": "2024-02-19T02:07:00.000Z",
        "voteCount": 5,
        "content": "Its called Refactoring methodology"
      },
      {
        "date": "2024-02-08T11:49:00.000Z",
        "voteCount": 3,
        "content": "Question says \"it can support the anaysis....\" by creating three tables and having a relationship of each with fact table let it support the analysis...it's not best from data model size perspective....Ideal step would be to have 1 active, 2 inactive relationship and create DAX userelationship function with inactive columns ...\nBut for this question, it seems A"
      },
      {
        "date": "2024-02-17T08:08:00.000Z",
        "voteCount": 3,
        "content": "Your explanation is correct but your answer is wrong. This is because power Bi can only allow one active relationship at a time. the others will be inactive until you need them.  Check these links:\n\nhttps://support.microsoft.com/en-us/office/create-relationships-in-diagram-view-in-power-pivot-12e00cb6-cb4d-469c-97ce-caa08349ad76#:~:text=Tables%20can%20have%20multiple%20relationships,calculations%20via%20the%20USERELATIONSHIP%20function\n\nhttps://community.fabric.microsoft.com/t5/Desktop/Power-BI-quot-An-Active-relationship-already-exists-between/m-p/768911#:~:text=Proud%20to%20be%20a%20Super%20User\n\nBased on the referenced links, I support that the answer is NO: B"
      },
      {
        "date": "2023-12-19T01:45:00.000Z",
        "voteCount": 2,
        "content": "Chatgpt: NO"
      },
      {
        "date": "2024-05-16T02:48:00.000Z",
        "voteCount": 3,
        "content": "Chatgpt makes mistakes \u263a"
      },
      {
        "date": "2023-09-06T14:42:00.000Z",
        "voteCount": 3,
        "content": "B is the answer. \nThe solution will not meet the goal because renaming the date table in the Fields pane does not create calculated tables for Order Date and Delivery Date. Additionally, creating active relationships between the sales table and each date table would not address the requirement to support the analysis of sales over time based on all three dates simultaneously. \nTo achieve the goal, you should create calculated tables for Order Date and Delivery Date using DAX expressions, and then you should establish active relationships between the sales table and these calculated date tables."
      },
      {
        "date": "2023-09-22T14:38:00.000Z",
        "voteCount": 1,
        "content": "And yes literally that what the solution is lol...."
      },
      {
        "date": "2023-09-03T00:36:00.000Z",
        "voteCount": 2,
        "content": "Can someone tell where is located that \"Fields pane\"? Is it in powerquey or in Power  Bi's report view?"
      },
      {
        "date": "2024-01-15T12:46:00.000Z",
        "voteCount": 3,
        "content": "Power Bi's report view\nhttps://learn.microsoft.com/en-us/power-bi/create-reports/service-the-report-editor-take-a-tour#the-fields-pane"
      },
      {
        "date": "2023-09-23T04:29:00.000Z",
        "voteCount": 2,
        "content": "Power Bi"
      },
      {
        "date": "2023-08-29T05:37:00.000Z",
        "voteCount": 3,
        "content": "Correct"
      },
      {
        "date": "2023-08-27T03:54:00.000Z",
        "voteCount": 4,
        "content": "Correct answer"
      },
      {
        "date": "2023-08-23T06:37:00.000Z",
        "voteCount": 1,
        "content": "It's impossible to have active relationships between the sales table and EACH date table"
      },
      {
        "date": "2023-08-27T03:54:00.000Z",
        "voteCount": 7,
        "content": "It is possible. You will be making connections from three different fields in the fact table to three separate tables."
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 78,
    "url": "https://www.examtopics.com/discussions/microsoft/view/122839-exam-pl-300-topic-2-question-78-discussion/",
    "body": "HOTSPOT<br> -<br><br>You are creating a Power BI report that will show the number of current employees over time. The report will use Import storage mode for all tables.<br><br>The employment data will be imported from Azure SQL Database in a monthly snapshot. The data will be stored in a table named Headcount and will contain the following:<br><br>\u2022\tOne row per employee for each month the employee is employed<br>\u2022\tIn each row, a date key that shows the first day of the month of each snapshot<br><br>You have a related date table that contains dates for the years 2020 to 2030.<br><br>You need to create a semi-additive DAX measure that will return the count of employees for the last available date in a year, quarter, or month.<br><br>How should you complete the measure? To answer, select the appropriate options in the answer area.<br><br><img src=\"https://img.examtopics.com/pl-300/image356.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/pl-300/image357.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2023-11-22T02:30:00.000Z",
        "voteCount": 27,
        "content": "LASTNONBLANK doesn't work as it requires 2 inputs\n\nLastDate('headcount'[datekey])/ FirstDate('headcount'[datekey]) doesn't work simply because firstdate and lastdate requires a date. Datekey is not a date\n\nTherefore, Lastdate('date'[date]) is correct"
      },
      {
        "date": "2023-10-19T06:31:00.000Z",
        "voteCount": 15,
        "content": "CountRows(\"HeadCount\")\nLastDate(headcount[\"DateKey\"])\n\nWhy?\nThe first to count the number of employes\n\nThe second because if we use lastDate over Date it will retrieve always the 31 december 2030 (It says that in date table are present dates from 2020 to 2030)\n\nSo the result will always be the same. But if we take the lastDate in the DateKey we'll have the first day of the month and year of the last snapshot. \n\nAm i correct?"
      },
      {
        "date": "2024-08-24T21:25:00.000Z",
        "voteCount": 1,
        "content": "You are right Rico. Tried it in power bi and it works perfectly"
      },
      {
        "date": "2024-05-26T05:01:00.000Z",
        "voteCount": 2,
        "content": "No, the LASTDATE('Date'[Date]) function does not always return the latest date in the entire range of the Date table (which would be 12/31/2030 in this case). Instead, it returns the latest date within the current filter context. This means it considers the dates that are relevant to the current context of your report, visualization, or calculation."
      },
      {
        "date": "2023-12-12T09:53:00.000Z",
        "voteCount": 4,
        "content": "I don't think so.  Every employee has an entry for EVERY month they are employed.  So counting the rows in that table will be too high."
      },
      {
        "date": "2024-02-16T06:19:00.000Z",
        "voteCount": 2,
        "content": "Yes but in this case, we will use the calculate function that evaluates an expression in a modified filter context.\nHere the filter is on the dates. It will give us the last available date in a year, quarter, or month.: Lastdate('date'[date]). So you will have only one date for each employee=&gt; one row for each employee."
      },
      {
        "date": "2024-10-10T15:01:00.000Z",
        "voteCount": 2,
        "content": "EmployeeCount = \nCALCULATE(\n    APPROXIMATEDISTINCTCOUNT(Headcount[EmployeeID]),\n    LASTDATE('Date'[Date])\n)"
      },
      {
        "date": "2024-05-09T02:55:00.000Z",
        "voteCount": 2,
        "content": "The answer seems correct."
      },
      {
        "date": "2024-02-27T15:45:00.000Z",
        "voteCount": 7,
        "content": "There is no much upvotes.Feels like everyone in tired of solving these questions."
      },
      {
        "date": "2023-12-05T06:16:00.000Z",
        "voteCount": 8,
        "content": "Table Headcount will contain \u201cone row per employee for each month the employee is employed\u201d. As I understand it, if we run the newly created measure for quarter or year, then the table will contain multiple rows of the same employee, given that the employee was employed the whole time. Therefore using CountRows(\u2018\u2019Headcount) would retrieve 3 or 12 for each employee being present in the whole period, which seems problematic as he is only one person. On the other hand, ApproximateDistinctCount will count an instance of that same employee only once, since the function aggregates on the passed column (key) before counting. Correct me if I am wrong, but I think the correct answer should be ApproximateDistinctCount and LastDate(\u2018Date\u2019[Date]) \nReference: https://learn.microsoft.com/en-us/dax/approximate-distinctcount-function-dax"
      },
      {
        "date": "2023-12-18T19:27:00.000Z",
        "voteCount": 9,
        "content": "Unfortunately, you are wrong. \"This function requires DirectQuery mode\" (https://learn.microsoft.com/en-us/dax/approximate-distinctcount-function-dax). In our case \"The report will use Import storage mode for all tables\" . So the only one solution - COUNTROWS and LastDate('Date'[Date])."
      },
      {
        "date": "2023-12-08T20:51:00.000Z",
        "voteCount": 2,
        "content": "I agree. \nI thought of the same thing. I wonder if anyone has a definitive answer to help us here."
      },
      {
        "date": "2023-12-12T09:51:00.000Z",
        "voteCount": 3,
        "content": "I agree with you.  Countrows will not work because of what you have pointed out."
      },
      {
        "date": "2023-11-13T22:48:00.000Z",
        "voteCount": 5,
        "content": "CALCULATE(\n    COUNTROWS('Headcount'),\n    LASTNONBLANK('Headcount'[Date])\n)\nThe problem is the table \"Headcount\"'s date key is the first day of each month. LASTDATE('DATE'[DATE]) returns the last day of the selected period, which filters out the value in the \"Headcount\" table."
      },
      {
        "date": "2023-11-22T02:30:00.000Z",
        "voteCount": 3,
        "content": "LASTNONBLANK doesn't work as it requires 2 inputs\n\nLastDate('headcount'[datekey])/ FirstDate('headcount'[datekey]) doesn't work simply because firstdate and lastdate requires a date. Datekey is not a date\n\nTherefore, Lastdate('date'[date]) is correct"
      },
      {
        "date": "2023-10-30T05:38:00.000Z",
        "voteCount": 3,
        "content": "Chat GTP \nLastDateHeadcount := \nVAR LastDate = \n    MAXX(\n        FILTER(\n            ALL('Date'[Date]), \n            'Date'[Date] &lt;= MAX('Date'[Date]) &amp;&amp; \n            'Date'[Year] = MAX('Date'[Year])\n        ),\n        'Date'[Date]\n    )\nRETURN\n    CALCULATE(\n        COUNTROWS('Headcount'), \n        'Headcount'[DateKey] = LastDate\n    )\n\nSo Chat GTP also suggest:\n CountRows(\"HeadCount\")\nLastDate(headcount[\"DateKey\"])"
      },
      {
        "date": "2023-10-16T12:06:00.000Z",
        "voteCount": 4,
        "content": "CORRECT"
      },
      {
        "date": "2023-10-08T05:15:00.000Z",
        "voteCount": 3,
        "content": "while the input is the first day of month, but the request is the last date. How can we set the filter as lastdate? i testes but it gave blank()"
      },
      {
        "date": "2023-10-08T05:21:00.000Z",
        "voteCount": 1,
        "content": "LASTNONBLANK requests two argument while in the question only show one agurment"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 79,
    "url": "https://www.examtopics.com/discussions/microsoft/view/122841-exam-pl-300-topic-2-question-79-discussion/",
    "body": "HOTSPOT<br> -<br><br>You have a query named All Sales that imports sales data into a Power BI model.<br><br>You plan to create a star schema by separating columns into separate queries and performing further transformations. The solution must meet the following requirements:<br><br>\u2022\tUse All Sales as the source for three other queries named Sales Fact, Product Dimension, and Customer Dimension.<br>\u2022\tMinimize maintenance effort.<br><br>What should you do to create the Sales Fact query, and for which query should you clear Enable load? To answer, select the appropriate options in the answer area.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/pl-300/image358.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/pl-300/image359.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2023-10-08T05:25:00.000Z",
        "voteCount": 34,
        "content": "Reference is the most common way to replicate origninal query. \nClear \"enable load\" to \"All Sales\" cause the data of this query is now loaded to other table. It is not necessary to load it to Report view anymore"
      },
      {
        "date": "2023-10-09T15:52:00.000Z",
        "voteCount": 24,
        "content": "The question provides the answer. We are referencing All Sales for all three tables, and then we are clearing Enable load for All Sales to reduce the data model and increase performance.\n\nReferencing will reduce maintenance because the three tables will be derived from the original data and we can keep the transformations to the source data without having to modify three queries."
      },
      {
        "date": "2024-01-23T12:55:00.000Z",
        "voteCount": 2,
        "content": "totally agree, good explanation"
      },
      {
        "date": "2024-08-26T11:29:00.000Z",
        "voteCount": 1,
        "content": "Answer is correct"
      },
      {
        "date": "2024-08-19T02:15:00.000Z",
        "voteCount": 1,
        "content": "The answer seems to be correct"
      },
      {
        "date": "2024-05-14T09:34:00.000Z",
        "voteCount": 1,
        "content": "Totally agree.\n\nReference the All sales query\nAll sales"
      },
      {
        "date": "2024-05-09T02:57:00.000Z",
        "voteCount": 1,
        "content": "Right answer."
      },
      {
        "date": "2023-12-20T20:42:00.000Z",
        "voteCount": 2,
        "content": "The answer is correct."
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 80,
    "url": "https://www.examtopics.com/discussions/microsoft/view/122843-exam-pl-300-topic-2-question-80-discussion/",
    "body": "You have a Power BI model that contains the following data.<br><br><img src=\"https://img.examtopics.com/pl-300/image360.png\"><br><br>The Date table relates to the Sales table by using the Date columns.<br><br>The model contains the following DAX measure.<br><br>Total Sales = SUM(Sales[Sale])<br><br>You need to create another measure named Previous Quarter to display the sales one quarter before the selected period.<br><br>Which DAX calculation should you use?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCALCULATE ( [Total Sales], DATEADD (Date[Date], -1, QUARTER ) )\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCALCULATE ( [Total Sales], DATESQTD (Date[Date] ) )",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tTOTALQTD ( [Total Sales], Date[Date] )",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCALCULATE ( [Total Sales], PARALLELPERIOD (Date[Date], 1, QUARTER ) )"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 16,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-10-08T05:34:00.000Z",
        "voteCount": 18,
        "content": "DATEADD is correct. \nPARALLELPERIOD also calculate one quarter before, but the out come is the total sales of three months of previous quarter not only one day or one month of previous quarter"
      },
      {
        "date": "2023-10-30T05:45:00.000Z",
        "voteCount": 6,
        "content": "A is correct."
      },
      {
        "date": "2023-11-16T18:45:00.000Z",
        "voteCount": 7,
        "content": "we can use PARALLELPERIOD() as well. It's just that the option for that is 1 year later rather than 1 year earlier"
      },
      {
        "date": "2024-08-26T11:48:00.000Z",
        "voteCount": 1,
        "content": "I think the answer D is 1 quarter later, not earlier as required. Other than that I think you're correct that it would have been ok too"
      },
      {
        "date": "2023-12-08T11:52:00.000Z",
        "voteCount": 1,
        "content": "Good observation!"
      },
      {
        "date": "2024-08-19T02:16:00.000Z",
        "voteCount": 2,
        "content": "A - CALCULATE ( [Total Sales], DATEADD (Date[Date], -1, QUARTER ) )"
      },
      {
        "date": "2024-06-17T02:45:00.000Z",
        "voteCount": 1,
        "content": "The answer is correct."
      },
      {
        "date": "2024-05-09T03:02:00.000Z",
        "voteCount": 1,
        "content": "Totaly right.\nFor this kind of situation, using DATEADD is the best approach. It is dynamic."
      },
      {
        "date": "2024-02-27T16:02:00.000Z",
        "voteCount": 3,
        "content": "-1 so A"
      },
      {
        "date": "2024-02-22T06:28:00.000Z",
        "voteCount": 2,
        "content": "DATEADD ( from date, direction(before/after), interval (in days, months, quarters, years) )"
      },
      {
        "date": "2023-11-19T23:53:00.000Z",
        "voteCount": 1,
        "content": "Option A is correct \nHere is chatgpt solution::--Previous Quarter = \nCALCULATE (\n    [Total Sales], \n    DATEADD ( Date[Date], -1, QUARTER )\n)"
      },
      {
        "date": "2023-11-08T23:00:00.000Z",
        "voteCount": 2,
        "content": "Given answer is right"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 81,
    "url": "https://www.examtopics.com/discussions/microsoft/view/134819-exam-pl-300-topic-2-question-83-discussion/",
    "body": "You have a Power BI data model that contains two tables named Sales and Date. The Sales table contains three measures named Order Quantity, Product Cost, and Sales Amount.<br><br>You need to create the visual shown in the following exhibit.<br><br><img src=\"https://img.examtopics.com/pl-300/image363.png\"><br><br>In which section of the Fields well should you place the measures?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tColumns",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRows",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tValues\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDrill through"
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 8,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-03-04T05:13:00.000Z",
        "voteCount": 20,
        "content": "Correct answer is C\nTo have the same exact matrix, you need to put the different measures in the \"Values\" well and then to go to the format pane of your matrix and select \"Switch values to rows\" under the \"Values\" section."
      },
      {
        "date": "2024-03-29T06:26:00.000Z",
        "voteCount": 2,
        "content": "Done! Thank you very much"
      },
      {
        "date": "2024-03-20T02:49:00.000Z",
        "voteCount": 5,
        "content": "Here's a tutorial https://datasavvy.me/2017/08/10/you-can-now-put-values-on-rows-in-power-bi/"
      },
      {
        "date": "2024-08-26T12:20:00.000Z",
        "voteCount": 2,
        "content": "C is correct. Put measures in Values then switch values to rows in the formatting of the matrix"
      },
      {
        "date": "2024-08-19T02:23:00.000Z",
        "voteCount": 1,
        "content": "It seems to be a matrix, we need to put the measures in the values"
      },
      {
        "date": "2024-03-16T21:36:00.000Z",
        "voteCount": 2,
        "content": "c. Value"
      },
      {
        "date": "2024-03-03T17:15:00.000Z",
        "voteCount": 3,
        "content": "Values"
      },
      {
        "date": "2024-02-29T10:30:00.000Z",
        "voteCount": 1,
        "content": "none of the solutions work in a PBI desktop report.\nYou can put ONE measure into values but as soon as you put the second one it becomes a second row header with corresponding values"
      },
      {
        "date": "2024-04-12T10:44:00.000Z",
        "voteCount": 6,
        "content": "Make sure you got a matrix type of visual. It looks like you had just a table."
      },
      {
        "date": "2024-02-29T09:56:00.000Z",
        "voteCount": 4,
        "content": "The correct answer is C - Values. \nFirstly, this type of visualization is a MATRIX. \nIf you do a simple test in PowerBI Desktop, you can see that in the \"Rows\" section, we can't add measures! \nMost likely, the names of the measures in the rows of the matrix appear because the measures were put in \"fields parameteres\" that generated a Calculated Table, and the actual values of the measures appear by adding the measures (not from the Calculated Table) in the \"Values\" section."
      },
      {
        "date": "2024-02-28T10:27:00.000Z",
        "voteCount": 3,
        "content": "It is not possible to put a measure in Columns. You can only put a measure in Values. However, putting the measures in Values is not going to produce the same visual. Neither of the answers is correct in my opinion."
      },
      {
        "date": "2024-03-04T05:15:00.000Z",
        "voteCount": 2,
        "content": "Answer C is correct, to produce the same visual you need to turn ON \"switch values to rows\" in the format pane of your matrix"
      },
      {
        "date": "2024-02-28T09:35:00.000Z",
        "voteCount": 3,
        "content": "C. Values"
      },
      {
        "date": "2024-02-28T08:39:00.000Z",
        "voteCount": 3,
        "content": "Values"
      },
      {
        "date": "2024-02-28T06:27:00.000Z",
        "voteCount": 3,
        "content": "Should be Values"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 82,
    "url": "https://www.examtopics.com/discussions/microsoft/view/134813-exam-pl-300-topic-2-question-82-discussion/",
    "body": "You are reviewing a Power BI data model.<br><br>You have a calculated table that has the following definition.<br><br>ProductList = INTERSECT ( ProductsGroupA, ProductsGroupB )<br><br>You need to identify the results of the DAX expression.<br><br>Which rows will be returned in ProductList?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tall the rows in ProductsGroupB that have a matching row in ProductsGroupA",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tall the rows in both tables",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tall the rows in ProductsGroupA that have a matching row in ProductsGroupB\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tall the rows in ProductsGroupA that have no matching row in ProductsGroupB."
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 13,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-02-28T10:13:00.000Z",
        "voteCount": 11,
        "content": "C. all the rows in ProductsGroupA that have a matching row in ProductsGroupB"
      },
      {
        "date": "2024-08-19T02:18:00.000Z",
        "voteCount": 1,
        "content": "C - all the rows in ProductsGroupA that have a matching row in ProductsGroupB"
      },
      {
        "date": "2024-06-17T02:57:00.000Z",
        "voteCount": 1,
        "content": "The answer is correct. \nINTERSECT(&lt;table_expression1&gt;, &lt;table_expression2&gt;)  \nDuplicate rows are retained. If a row appears in table_expression1 and table_expression2, it and any duplicates in table_expression_1 are included in the result set.\nReference:\n\nhttps://learn.microsoft.com/sv-se/dax/intersect-function-dax"
      },
      {
        "date": "2024-03-11T15:56:00.000Z",
        "voteCount": 4,
        "content": "The INTERSECT function in DAX is order-independent. It returns the common rows between two tables, regardless of the order in which you specify the tables. both a and c are correct."
      },
      {
        "date": "2024-03-12T04:58:00.000Z",
        "voteCount": 1,
        "content": "Intersect is not commutative. In general, Intersect(T1, T2) will have a different result set than Intersect(T2, T1)."
      },
      {
        "date": "2024-03-05T09:05:00.000Z",
        "voteCount": 2,
        "content": "Intersect is not commutative. In general, Intersect(T1, T2) will have a different result set than Intersect(T2, T1).\n\nDuplicate rows are retained. If a row appears in table_expression1 and table_expression2, it and all duplicates in table_expression_1 are included in the result set."
      },
      {
        "date": "2024-03-05T09:08:00.000Z",
        "voteCount": 1,
        "content": "Answer: C"
      },
      {
        "date": "2024-02-29T09:44:00.000Z",
        "voteCount": 1,
        "content": "The correct answer is C. \nSee the example : \nhttps://learn.microsoft.com/en-us/dax/intersect-function-dax\n\n\"Intersect is not commutative. In general, Intersect(T1, T2) will have a different result set than Intersect(T2, T1).\""
      },
      {
        "date": "2024-02-28T04:33:00.000Z",
        "voteCount": 3,
        "content": "Would not A and C be both correct? \n\nince INTERSECT finds rows that exist in both tables, the statement is correct from the perspective of either table\u2014whether you're looking for matches in ProductsGroupA against ProductsGroupB or vice versa. The result is a table with rows that are common to both."
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 83,
    "url": "https://www.examtopics.com/discussions/microsoft/view/146912-exam-pl-300-topic-2-question-83-discussion/",
    "body": "HOTSPOT<br> -<br><br>You have a Power BI tenant that contains a workspace. The workspace contains a dataset named datasetA.<br><br>You need to build a pivot table report in Microsoft Excel. The report must use datasetA as the data source. The solution must meet the following requirements:<br><br>\u2022\tEnsure that the report can be refreshed to get the latest available data from the Power BI service.<br>\u2022\tEnsure that all the visible data in datasetA is available for use in Excel.<br><br>What should you do to connect Excel to datasetA, and which element in datasetA will be incompatible with the Excel connection? To answer, select the appropriate options in the answer area.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/pl-300/image384.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/pl-300/image385.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-10-16T09:08:00.000Z",
        "voteCount": 1,
        "content": "Report Measures is the correct answer:\nReport measures in Power BI are often incompatible with Excel connections when using a live connection because they are tightly integrated with specific visualizations and context in Power BI. While basic measures will work, report-level measures, especially those related to specific visual filters or slicers in Power BI reports, may not transfer correctly into Excel."
      },
      {
        "date": "2024-09-08T04:07:00.000Z",
        "voteCount": 3,
        "content": "Given answers are correct"
      },
      {
        "date": "2024-09-05T22:56:00.000Z",
        "voteCount": 4,
        "content": "I had a dataset in powerbi.com and was able to open it with the Analyze in Excel so I say these answer are correct"
      },
      {
        "date": "2024-09-04T09:06:00.000Z",
        "voteCount": 2,
        "content": "Para conectar Excel a datasetA:\nSelect Analyze in Excel: Esta opci\u00f3n te permite conectar Excel directamente a un conjunto de datos en Power BI usando \"Analizar en Excel\". Esto es lo que necesitas para crear un informe de tabla din\u00e1mica en Excel que se puede actualizar con los datos m\u00e1s recientes desde el servicio Power BI.\nIncompatible con la conexi\u00f3n a Excel:\nField parameters: Los par\u00e1metros de campo (Field parameters) en Power BI no son totalmente compatibles con las conexiones a Excel. Esto puede causar problemas al intentar utilizar estas caracter\u00edsticas avanzadas en un entorno de Excel.\nPor lo tanto, las selecciones correctas son:\n\nPara conectar Excel a datasetA: Select Analyze in Excel.\nIncompatible con la conexi\u00f3n a Excel: Field parameters."
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 84,
    "url": "https://www.examtopics.com/discussions/microsoft/view/147009-exam-pl-300-topic-2-question-84-discussion/",
    "body": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.<br><br>After you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.<br><br>You have a Power BI report that imports a date table and a sales table from an Azure SQL database data source. The sales table has the following date foreign keys:<br><br>\u2022\tDue Date<br>\u2022\tOrder Date<br>\u2022\tDelivery Date<br><br>You need to support the analysis of sales over time based on all the date foreign keys.<br><br>Solution: You create measures that use the USERELATIONSHIP DAX function to filter sales on the inactive relationship between the sales table and the date table.<br><br>Does this meet the goal?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tYes\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tNo"
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 2,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-10-02T22:53:00.000Z",
        "voteCount": 1,
        "content": "Yes, USERELATIONSHIP() activates a disables relationship, and therefore pairs well with an inactive relationship, like in the question."
      },
      {
        "date": "2024-10-02T22:53:00.000Z",
        "voteCount": 1,
        "content": "Yes, USERELATIONSHIP() activates a disables relationship, and therefore pairs well with an inactive relationship, like in the question."
      },
      {
        "date": "2024-09-11T22:37:00.000Z",
        "voteCount": 1,
        "content": "Yes is the correct answer"
      },
      {
        "date": "2024-09-05T05:08:00.000Z",
        "voteCount": 2,
        "content": "Yes, is the correct answer"
      },
      {
        "date": "2024-09-05T22:57:00.000Z",
        "voteCount": 1,
        "content": "i agree the dax function to userelationship is for this purpose."
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 85,
    "url": "https://www.examtopics.com/discussions/microsoft/view/147010-exam-pl-300-topic-2-question-85-discussion/",
    "body": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.<br><br>After you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.<br><br>You have a Power BI report that imports a date table and a sales table from an Azure SQL database data source. The sales table has the following date foreign keys:<br><br>\u2022\tDue Date<br>\u2022\tOrder Date<br>\u2022\tDelivery Date<br><br>You need to support the analysis of sales over time based on all the date foreign keys.<br><br>Solution: From the Fields pane, you rename the date table as Due Date. You use a DAX expression to create Order Date and Delivery Date as calculated tables. You create active relationships between the sales table and each date table.<br><br>Does this meet the goal?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tYes\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tNo"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 5,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-09-11T22:39:00.000Z",
        "voteCount": 1,
        "content": "Yes is the correct answer"
      },
      {
        "date": "2024-09-06T18:25:00.000Z",
        "voteCount": 3,
        "content": "Deja vu"
      },
      {
        "date": "2024-09-06T12:29:00.000Z",
        "voteCount": 2,
        "content": "Yes is the correct answer"
      },
      {
        "date": "2024-09-05T22:39:00.000Z",
        "voteCount": 2,
        "content": "Yes - correct"
      },
      {
        "date": "2024-09-05T06:17:00.000Z",
        "voteCount": 2,
        "content": "Yes, is the correct answer"
      },
      {
        "date": "2024-09-05T05:09:00.000Z",
        "voteCount": 1,
        "content": "No is the correct answer"
      },
      {
        "date": "2024-09-05T22:59:00.000Z",
        "voteCount": 2,
        "content": "I would have thought the Answer is yes as you create the other required tables using the dax function and create relationships to the required dates"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 86,
    "url": "https://www.examtopics.com/discussions/microsoft/view/146906-exam-pl-300-topic-2-question-86-discussion/",
    "body": "You have a Power BI semantic model that contains item, price, and country data. The data is displayed in a report that uses filters.<br><br>You need to calculate the average item price for a given country. The solution must support the existing filters.<br><br>Which type of quick measure should you use?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tTotal for category (filters applied)",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAverage per category\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRolling average",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tWeighted average per category"
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 5,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-09-17T01:50:00.000Z",
        "voteCount": 1,
        "content": "I think B"
      },
      {
        "date": "2024-09-12T20:45:00.000Z",
        "voteCount": 1,
        "content": "Beeeeeee"
      },
      {
        "date": "2024-09-12T10:03:00.000Z",
        "voteCount": 1,
        "content": "I would say thats A, beacuse you can change summarization on total to average"
      },
      {
        "date": "2024-09-11T23:09:00.000Z",
        "voteCount": 1,
        "content": "In my opinion, B"
      },
      {
        "date": "2024-09-11T22:43:00.000Z",
        "voteCount": 1,
        "content": "B is the correct answer. It wants to calculate average not the total"
      },
      {
        "date": "2024-09-05T06:20:00.000Z",
        "voteCount": 1,
        "content": "B. Average per category"
      },
      {
        "date": "2024-09-05T05:10:00.000Z",
        "voteCount": 3,
        "content": "B is the answer."
      },
      {
        "date": "2024-09-04T07:35:00.000Z",
        "voteCount": 1,
        "content": "https://learn.microsoft.com/en-us/power-bi/transform-model/desktop-quick-measures"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 87,
    "url": "https://www.examtopics.com/discussions/microsoft/view/147011-exam-pl-300-topic-2-question-87-discussion/",
    "body": "DRAG DROP<br> -<br><br>You use Power Query Editor to import three tables named Customers, Address, and Country.<br><br>In the source system, not every customer has a related address, but every address has a related country.<br><br>You need to merge all the tables into a single query. The solution must optimize query refresh performance.<br><br>Which type of join should you use for each merge operation? To answer, drag the appropriate join types to the correct operations. Each join type may be used once, more than once, or not at all. You may need to drag the split bar between panes or scroll to view content.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/pl-300/image394.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/pl-300/image395.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-09-05T05:12:00.000Z",
        "voteCount": 11,
        "content": "This should be left outer join, since the customer table is on the left side."
      },
      {
        "date": "2024-09-05T05:41:00.000Z",
        "voteCount": 7,
        "content": "In my opinion it is wrong, it should be: Left outer, inner join"
      },
      {
        "date": "2024-09-05T07:58:00.000Z",
        "voteCount": 1,
        "content": "what do you think guys?"
      },
      {
        "date": "2024-10-10T06:46:00.000Z",
        "voteCount": 1,
        "content": "I think the answer should be left outer since the customer table is on the left. so we should be all the records on the left table and the matching records on the right table."
      },
      {
        "date": "2024-10-08T00:28:00.000Z",
        "voteCount": 1,
        "content": "Left outer, Inner"
      },
      {
        "date": "2024-10-02T22:57:00.000Z",
        "voteCount": 1,
        "content": "Left outer, Inner"
      },
      {
        "date": "2024-09-11T22:50:00.000Z",
        "voteCount": 3,
        "content": "My previous comment is wrong. I am sorry it is left outer and inner"
      },
      {
        "date": "2024-09-08T04:29:00.000Z",
        "voteCount": 3,
        "content": "Right outer is correct because some customers have no address"
      },
      {
        "date": "2024-09-09T17:26:00.000Z",
        "voteCount": 5,
        "content": "Left outer join is correct because we cant ignore the customers who does not have a address. Left table (Customers) should be included. \n\n1. Left Outer Join\n2. Inner Join"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 88,
    "url": "https://www.examtopics.com/discussions/microsoft/view/147012-exam-pl-300-topic-2-question-88-discussion/",
    "body": "You have a Power BI semantic model that contains four queries named Query 1, Query2. Query3, and Query4.<br><br>Query1 loads customer data into the model and is referenced by the other three queries.<br><br>You discover that data refresh for the model is slow.<br><br>You need to improve the data refresh time. The solution must minimize costs.<br><br>What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRun the Table.buffer function in Query1.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDuplicate Query1 to all the other queries.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tReconfigure Query1 as a dataflow entity.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tFrom the Power BI Admin portal, increase the Capacity settings."
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 5,
        "isMostVoted": true
      },
      {
        "answer": "A",
        "count": 2,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2024-09-24T14:10:00.000Z",
        "voteCount": 1,
        "content": "Its C: your comment is too short"
      },
      {
        "date": "2024-09-11T23:23:00.000Z",
        "voteCount": 4,
        "content": "https://learn.microsoft.com/en-us/power-bi/guidance/power-query-referenced-queries\n\"In the example, if Query1 is redesigned as a dataflow entity, Query2, Query3, and Query4 can use it as a data source. With this design, the entity sourced by Query1 will be evaluated only once.\""
      },
      {
        "date": "2024-09-15T17:48:00.000Z",
        "voteCount": 1,
        "content": "Per the above reference...\nWe recommend you create a dataflow instead. Using a dataflow can improve data refresh time and reduce impact on your data sources."
      },
      {
        "date": "2024-09-11T04:13:00.000Z",
        "voteCount": 1,
        "content": "https://learn.microsoft.com/en-us/power-bi/guidance/power-query-referenced-queries"
      },
      {
        "date": "2024-09-11T23:23:00.000Z",
        "voteCount": 1,
        "content": "you selected A, but your link says that the correct answer is C, about Table.Buffer it says \"This result could in fact compound the negative performance, because the table will be buffered by each referencing query.\" While about evaluating Query1 as dataflow entity  it says \"In the example, if Query1 is redesigned as a dataflow entity, Query2, Query3, and Query4 can use it as a data source. With this design, the entity sourced by Query1 will be evaluated only once.\" So the correct answer is C"
      },
      {
        "date": "2024-09-07T07:13:00.000Z",
        "voteCount": 1,
        "content": "Table.Buffer will keep the data in memory as buffer. So there wont be any changes in data. this is similar to referencing the data."
      },
      {
        "date": "2024-09-05T05:15:00.000Z",
        "voteCount": 1,
        "content": "Run the Table.Buffer function in Query1"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 89,
    "url": "https://www.examtopics.com/discussions/microsoft/view/147019-exam-pl-300-topic-2-question-89-discussion/",
    "body": "HOTSPOT<br> -<br><br>You have an organization dimension named DimOrganizations.<br><br>You have four related tables as shown in the following exhibit.<br><br><img src=\"https://img.examtopics.com/pl-300/image396.png\"><br><br>Use the drop-down menus to select the answer choice that completes each statement based on the information presented in the graphic.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/pl-300/image397.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/pl-300/image398.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-09-05T06:23:00.000Z",
        "voteCount": 6,
        "content": "The answer is correct. It is a snowflakeschema and DimOrgSubVertical is the only table that supports a hierarchy model for DimOrgVertical"
      },
      {
        "date": "2024-09-17T02:00:00.000Z",
        "voteCount": 2,
        "content": "I agree"
      },
      {
        "date": "2024-10-10T06:51:00.000Z",
        "voteCount": 2,
        "content": "can someone please explain why DimOrgSubVertical supports a hierarchy for the model?"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 90,
    "url": "https://www.examtopics.com/discussions/microsoft/view/147013-exam-pl-300-topic-2-question-90-discussion/",
    "body": "HOTSPOT<br> -<br><br>You have a Power BI semantic model that contains a table named Opportunity.<br><br>The Opportunity table contains a column named Qualification. The Qualification column contains values between 0 and 1.<br><br>You need to build a new measure to score the opportunities on a scale of low. medium, and high.<br><br>How should you complete the DAX formula? To answer, select the appropriate options in the answer area.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/pl-300/image399.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/pl-300/image400.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-09-20T22:46:00.000Z",
        "voteCount": 2,
        "content": "I will use IF instead of IF.EAGER due to values that are used in true/false arguments. If there would be more complex values (another formulas, references to columns etc.) I will prefer IF.EAGER. See https://learn.microsoft.com/en-us/dax/if-eager-function-dax -cdot above Examples part."
      },
      {
        "date": "2024-09-10T17:30:00.000Z",
        "voteCount": 1,
        "content": "interestingly this article - https://dax.guide/if-eager/ - indicates that if and if.eager do pretty much the same thing but if.eager optimises better. So I can't say the answer is incorrect but which one are they looking for can't say."
      },
      {
        "date": "2024-09-10T13:59:00.000Z",
        "voteCount": 4,
        "content": "IF is correct answer   \nhttps://learn.microsoft.com/en-us/dax/if-function-dax        check last example"
      },
      {
        "date": "2024-09-15T18:31:00.000Z",
        "voteCount": 1,
        "content": "I'm going with just 'IF'. \nIF.Eager seems to only be required for variant data type comparison...\nThe IF.EAGER function can return a variant data type if value_if_true and value_if_false are of different data types, but the function attempts to return a single data type if both value_if_true and value_if_false are of numeric data types. In the latter case, the IF.EAGER function will implicitly convert data types to accommodate both values."
      },
      {
        "date": "2024-09-06T17:18:00.000Z",
        "voteCount": 3,
        "content": "The correct answer is IF, HIGH and MEDIUM"
      },
      {
        "date": "2024-09-05T23:17:00.000Z",
        "voteCount": 2,
        "content": "IF is also fine"
      },
      {
        "date": "2024-09-05T05:21:00.000Z",
        "voteCount": 2,
        "content": "Answer is correct.\nhttps://learn.microsoft.com/en-us/dax/if-eager-function-dax"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 91,
    "url": "https://www.examtopics.com/discussions/microsoft/view/147016-exam-pl-300-topic-2-question-91-discussion/",
    "body": "You have a Power BI semantic model that connects to a streaming data source. The data source is updated frequently.<br><br>You need to create a Power BI report that meets the following requirements:<br><br>\u2022\tSupports real-time analytics<br>\u2022\tMinimizes performance impact on the data source<br>\u2022\tDisplays the most recent data without performing a data refresh<br><br>Which connectivity mode should you use for the dataset?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDirectQuery mode\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\timport mode",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tLiveConnect mode",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tpush mode"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 8,
        "isMostVoted": true
      },
      {
        "answer": "D",
        "count": 4,
        "isMostVoted": false
      },
      {
        "answer": "C",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2024-09-05T05:45:00.000Z",
        "voteCount": 5,
        "content": "real-time analytics =&gt; DirectQuery"
      },
      {
        "date": "2024-10-02T01:22:00.000Z",
        "voteCount": 2,
        "content": "Correct answer is D\n"
      },
      {
        "date": "2024-09-30T14:52:00.000Z",
        "voteCount": 2,
        "content": "I think it's Push mode based on this article:"
      },
      {
        "date": "2024-09-26T12:10:00.000Z",
        "voteCount": 1,
        "content": "Should be C. The power bi semantic model that's connected to the live streaming data source already is created and exists. You want to build a report by connecting to that semantic model, therefore you should just connect to it as a live dataset."
      },
      {
        "date": "2024-09-20T06:42:00.000Z",
        "voteCount": 3,
        "content": "Direct Query."
      },
      {
        "date": "2024-09-15T18:48:00.000Z",
        "voteCount": 3,
        "content": "Live connection and DirectQuery comparison\nhttps://learn.microsoft.com/en-us/power-bi/connect-data/service-live-connect-dq-datasets\nLive connection is a method that lets you build a report in Power BI Desktop without having to build a semantic model for it. \nThe semantic model can dynamically request data from a data source it's connected to using a method called DirectQuery.\nWhen using DirectQuery, your report uses Data Analysis Expression (DAX) queries to get data. \nAfter the semantic model receives the report's DAX query, \nit generates another set of queries that are run on your data source, to get the required data. \n\nFrom this I am concluding use DirectQuery."
      },
      {
        "date": "2024-09-15T03:45:00.000Z",
        "voteCount": 2,
        "content": "As I guess answer is push mode"
      },
      {
        "date": "2024-09-22T14:17:00.000Z",
        "voteCount": 1,
        "content": "Push isn\u2019t a type of connectivity. It\u2019s a kind of semantic model"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 92,
    "url": "https://www.examtopics.com/discussions/microsoft/view/147006-exam-pl-300-topic-2-question-92-discussion/",
    "body": "HOTSPOT<br> -<br><br>You have a Power BI semantic model that contains a table named Item. The Item table contains a column named Quantity.<br><br>You need to create a DAX query that meets the following requirements:<br><br>\u2022\tThe rank of items must be calculated according to the values in Quantity.<br>\u2022\tRanking must NOT be skipped if two or more items have the same value in Quantity.<br>\u2022\tIf an item is unfiltered, the total of Quantity must display a blank value.<br><br>How should you complete the DAX formula? To answer, select the appropriate options in the answer area.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/pl-300/image401.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/pl-300/image402.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-09-28T06:33:00.000Z",
        "voteCount": 2,
        "content": "HASONEVALUE ('Item'[Item])  check if 'item' is filtered to a single value. if not, it returns blank by default.\nRank method : DENSE  ensure that ranks are not skipped when there are ties."
      },
      {
        "date": "2024-09-12T09:41:00.000Z",
        "voteCount": 1,
        "content": "HASONEVALUE garantiza que la f\u00f3rmula se ejecute \u00fanicamente cuando haya un solo valor de Item seleccionado. Esto evita que se devuelva un valor de clasificaci\u00f3n cuando no se ha seleccionado ning\u00fan elemento, cumpliendo con el requisito de mostrar un valor en blanco si no se ha filtrado ning\u00fan elemento. \n\nDENSE se asegura de que, si dos o m\u00e1s elementos tienen la misma cantidad, no se omitan n\u00fameros en la clasificaci\u00f3n, lo cual era otro de los requisitos."
      },
      {
        "date": "2024-09-06T05:12:00.000Z",
        "voteCount": 4,
        "content": "Correct Answer: HASONEVALUE, DENSE"
      },
      {
        "date": "2024-09-05T02:24:00.000Z",
        "voteCount": 3,
        "content": "Wrong. It should be HASONEVALUE and DENSE"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 93,
    "url": "https://www.examtopics.com/discussions/microsoft/view/146910-exam-pl-300-topic-2-question-93-discussion/",
    "body": "HOTSPOT<br> -<br><br>You use Power Query Editor to pull data from a Microsoft SharePoint Online list.<br><br>You plan to use Advanced Editor to build a Power Query M formula language query.<br><br>You need to create a query that loads the data, expands a column named location, and hides a column named CountryOrRegion from the dataset.<br><br>How should you complete the query? To answer, select the appropriate options in the answer area.<br><br>NOTE: Each correct answer is worth one point.<br><br><img src=\"https://img.examtopics.com/pl-300/image403.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/pl-300/image404.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-09-05T07:33:00.000Z",
        "voteCount": 3,
        "content": "ExpandRecordColumnn and  RemoveColumns"
      },
      {
        "date": "2024-09-05T05:28:00.000Z",
        "voteCount": 2,
        "content": "Answer should be Table.ExpandRecordColumn and Table.Removecolumns"
      },
      {
        "date": "2024-09-04T08:41:00.000Z",
        "voteCount": 3,
        "content": "Table.ExpandRecordColumn"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 94,
    "url": "https://www.examtopics.com/discussions/microsoft/view/147014-exam-pl-300-topic-2-question-94-discussion/",
    "body": "HOTSPOT<br> -<br><br>You have a Power BI semantic model that contains two tables as shown in the following exhibit.<br><br><img src=\"https://img.examtopics.com/pl-300/image414.png\"><br><br>Use the drop-down menus to select the answer choice that completes each statement based on the information presented in the graphic.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/pl-300/image415.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/pl-300/image416.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-10-16T11:06:00.000Z",
        "voteCount": 1,
        "content": "Both answers are correct. Only active relationships can participate in filtering and RLS, so if it\u2019s currently inactive, you need to activate the relationship."
      },
      {
        "date": "2024-09-12T00:08:00.000Z",
        "voteCount": 4,
        "content": "1. Single\n2. Delete the many to one relationship, because the question asks what do you have to do first, if you set the relationship active as first step, you will receive an error message, because there would be 2 active relationship with the same 2 tables"
      },
      {
        "date": "2024-09-12T00:13:00.000Z",
        "voteCount": 1,
        "content": "https://learn.microsoft.com/en-us/power-bi/transform-model/desktop-relationships-understand\n\"There can only be one active filter propagation path between two model tables.\""
      },
      {
        "date": "2024-09-06T03:14:00.000Z",
        "voteCount": 1,
        "content": "Both, define the relationship as active"
      },
      {
        "date": "2024-10-12T11:12:00.000Z",
        "voteCount": 1,
        "content": "correction: single,  Delete the many to one relationship"
      },
      {
        "date": "2024-09-05T05:47:00.000Z",
        "voteCount": 3,
        "content": "Answer is right the many-to-one relationship is single and we need first to remove the many-to-many relationship"
      },
      {
        "date": "2024-09-05T05:31:00.000Z",
        "voteCount": 1,
        "content": "Answer should be None, Delete the many to one relationship"
      },
      {
        "date": "2024-09-05T23:55:00.000Z",
        "voteCount": 2,
        "content": "Are you sure about this - when I look at my models in Power BI the single arrow in the 1 to many relationship means it is single, the double arrow means it is both.  To enable the filtering the relationship must be active in the many-to-many."
      },
      {
        "date": "2024-09-05T05:30:00.000Z",
        "voteCount": 2,
        "content": "Who is answering this question for Examtopics please? Your answers are so misleading"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 95,
    "url": "https://www.examtopics.com/discussions/microsoft/view/147094-exam-pl-300-topic-2-question-95-discussion/",
    "body": "You create a Power BI report named Summary1.<br><br>You discover that Summary1 is slow.<br><br>You run Performance analyzer to identify performance metrics for Summary1.<br><br>Which two metrics display the execution duration in Performance analyzer? Each correct answer present part of the solution.<br><br>NOTE: Each correct answer is worth one point.",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tTop Operations",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDAX query\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tServer requests",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDependencies",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tVisual display\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "BE",
    "answerDescription": "",
    "votes": [
      {
        "answer": "BE",
        "count": 4,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-09-20T06:56:00.000Z",
        "voteCount": 1,
        "content": "Dax Query\nVisual Display"
      },
      {
        "date": "2024-09-07T08:17:00.000Z",
        "voteCount": 3,
        "content": "Answer is correct!"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 96,
    "url": "https://www.examtopics.com/discussions/microsoft/view/146997-exam-pl-300-topic-2-question-96-discussion/",
    "body": "You have a Microsoft 365 subscription that contains the resources shown in the following table.<br><br><img src=\"https://img.examtopics.com/pl-300/image417.png\"><br><br>You create a new dashboard that uses row-level security (RLS) filters. You define a new role named Consultants.<br><br>To which resource can you assign the Consultants role?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tGroup2\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tTeam1",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSales reports",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tGroup1"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 2,
        "isMostVoted": false
      },
      {
        "answer": "A",
        "count": 2,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-09-05T05:33:00.000Z",
        "voteCount": 7,
        "content": "Sales Report"
      },
      {
        "date": "2024-10-10T07:45:00.000Z",
        "voteCount": 1,
        "content": "I agree the answer is sales report"
      },
      {
        "date": "2024-10-05T00:34:00.000Z",
        "voteCount": 1,
        "content": "Answer is A!\nhttps://learn.microsoft.com/en-us/fabric/security/service-admin-row-level-security#add-members"
      },
      {
        "date": "2024-09-27T09:34:00.000Z",
        "voteCount": 1,
        "content": "Roles are assigned in PowerBI Service which means the answer must be C sales reports"
      },
      {
        "date": "2024-09-17T08:35:00.000Z",
        "voteCount": 1,
        "content": "group 1"
      },
      {
        "date": "2024-09-12T06:31:00.000Z",
        "voteCount": 1,
        "content": "what's the correct answer then?"
      },
      {
        "date": "2024-09-12T04:33:00.000Z",
        "voteCount": 1,
        "content": "why not C?"
      },
      {
        "date": "2024-09-07T05:38:00.000Z",
        "voteCount": 2,
        "content": "Group 1 is the right answer"
      },
      {
        "date": "2024-09-08T17:37:00.000Z",
        "voteCount": 3,
        "content": "Do you mean Answer A which is Group 2 not Group 1.  In this link https://learn.microsoft.com/en-us/power-bi/guidance/rls-guidance it says Members can be user accounts, security groups, distribution groups or mail enabled groups so I think it is A as well"
      },
      {
        "date": "2024-09-06T04:04:00.000Z",
        "voteCount": 3,
        "content": "I think the answer is D:Group 1 as it's a MS 365 group that you can assign not a Mail enabled group"
      },
      {
        "date": "2024-09-05T00:52:00.000Z",
        "voteCount": 1,
        "content": "Why A ?"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 97,
    "url": "https://www.examtopics.com/discussions/microsoft/view/147096-exam-pl-300-topic-2-question-97-discussion/",
    "body": "You have a Power BI model that contains two tables named Sales and Date. The Sales table relates to the Date table by using a many-to-one relationship. The Sales table contains the following columns:<br><br>\u2022\tDate<br>\u2022\tProduct<br>\u2022\tSalesAmount<br><br>You need to create a DAX measure for a rolling 31-day sales total that will return the total sales amount for a selected date and the previous 30 days.<br><br>Which DAX expression should you use?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCALCULATE(SUM(Sales[SalesAmount]), DATEADD(Date[Date], -30, DAY))\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCALCULATE(SUM(Sales[SalesAmount]), DATESBETWEEN(Date[Date], Max('Date'[Date])-30, Max('Date'[Date])))\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCALCULATE(SUM(Sales[SalesAmount]), DATESMTD(Date[Date]))",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCALCULATE(SUM(Sales[SalesAmount]), DISTINCTCOUNT(Date[Date]) = 31)"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 11,
        "isMostVoted": true
      },
      {
        "answer": "A",
        "count": 7,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-09-17T03:59:00.000Z",
        "voteCount": 6,
        "content": "DATESBETWEEN creates a continuous range of dates from the selected date back 30 days. So option B is more suitable for calculating a rolling 31-day total because it correctly defines the date range needed for the calculation."
      },
      {
        "date": "2024-10-09T00:17:00.000Z",
        "voteCount": 2,
        "content": "B DATESBETWEEN as DATEADD returns only 1date while we need a series of dates."
      },
      {
        "date": "2024-09-24T04:48:00.000Z",
        "voteCount": 1,
        "content": "I changed my mind, Max(Date[Date]-30) will not work, so I would go with DATEADD"
      },
      {
        "date": "2024-09-25T00:28:00.000Z",
        "voteCount": 1,
        "content": "I thought A would just give you a single day 30 days earlier.\n-&gt; Ans : B"
      },
      {
        "date": "2024-09-16T08:32:00.000Z",
        "voteCount": 3,
        "content": "I would say A, but after testing im certain thats B"
      },
      {
        "date": "2024-09-12T04:17:00.000Z",
        "voteCount": 1,
        "content": "B in my opinion"
      },
      {
        "date": "2024-09-08T20:33:00.000Z",
        "voteCount": 4,
        "content": "Answer A is correct because Dateadd provides required set of dates"
      },
      {
        "date": "2024-09-16T14:54:00.000Z",
        "voteCount": 1,
        "content": "A is simple and I can't see whats wrong with it.\n-&gt; Ans : A"
      },
      {
        "date": "2024-10-09T22:20:00.000Z",
        "voteCount": 1,
        "content": "Changed mind...\nI thought A would just give you a single day 30 days earlier.\n-&gt; Ans : B"
      },
      {
        "date": "2024-09-07T05:40:00.000Z",
        "voteCount": 2,
        "content": "B is the right answer."
      },
      {
        "date": "2024-09-06T19:23:00.000Z",
        "voteCount": 2,
        "content": "The expresion B Max(Date[]-30) is wrong"
      },
      {
        "date": "2024-09-06T05:20:00.000Z",
        "voteCount": 1,
        "content": "A is the correct answer"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 98,
    "url": "https://www.examtopics.com/discussions/microsoft/view/148490-exam-pl-300-topic-2-question-98-discussion/",
    "body": "You publish a semantic model to the Power BI service. The semantic model contains data from the following data sources:<br><br>\u2022\tSource1: A Microsoft Excel file stored in Microsoft OneDrive for Business<br>\u2022\tSource2: An Azure SQL database on a virtual network<br>\u2022\tSource3: A public website<br><br>Which data sources require an on-premises data gateway?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSource1 only",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSource2 only\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSource3 only",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSource1 and Source2 only",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSource2 and Source3 only",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"F\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tF.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSource1, Source2, and Source3"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 6,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-10-01T01:17:00.000Z",
        "voteCount": 6,
        "content": "You need a gateway to connect to data sources that are located in a private network, such as an Azure Virtual Network (Azure VNet). A virtual network, or VNet, is a logically isolated segment of a network that insulates traffic from the public internet. A VNet provides enhanced network security.\n\nhttps://learn.microsoft.com/en-us/power-bi/guidance/powerbi-implementation-planning-data-gateways\n\nExcel file you can access via SharePoint connector and a public site is well... a public site..."
      },
      {
        "date": "2024-10-11T09:47:00.000Z",
        "voteCount": 1,
        "content": "The correct answer is B. Reason is because Power Bi cannot access the virtual network without a gateway path. \n The excel file can be easily accessed by powerBi likewise the public website."
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 99,
    "url": "https://www.examtopics.com/discussions/microsoft/view/148503-exam-pl-300-topic-2-question-99-discussion/",
    "body": "HOTSPOT<br> -<br><br>You have a Power BI semantic model named ModelA that contains the following columns:<br><br><img src=\"https://img.examtopics.com/pl-300/image427.png\"><br><br>All of the columns use the Text data type.<br><br>Based on the model, you create a report named ReportA that contains the following columns:<br><br>\u2022\tOrderID<br>\u2022\tOrderDate<br>\u2022\tCustomerID<br>\u2022\tShippingAddress<br><br>ReportA is the only report connected to ModelA.<br><br>You discover that ReportA has performance issues caused by the size of ModelA.<br><br>What should you do to optimize and reduce the size of ModelA? To answer, select the appropriate options in the answer area.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/pl-300/image428.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/pl-300/image429.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-10-12T19:16:00.000Z",
        "voteCount": 2,
        "content": "https://learn.microsoft.com/en-us/power-bi/guidance/import-modeling-data-reduction\nanswer is correct"
      },
      {
        "date": "2024-10-02T14:15:00.000Z",
        "voteCount": 2,
        "content": "I think the answer is correct. Enable summarization will work with there are numbers to be summed by. There is no summarize for column type text."
      },
      {
        "date": "2024-10-01T05:05:00.000Z",
        "voteCount": 1,
        "content": "I think\n- Enable Summarization\n-Delete the OrderTitle and OrderDescription columns"
      },
      {
        "date": "2024-10-18T04:12:00.000Z",
        "voteCount": 1,
        "content": "why , do we need summarization for ID column. it should be disable."
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 100,
    "url": "https://www.examtopics.com/discussions/microsoft/view/148849-exam-pl-300-topic-2-question-100-discussion/",
    "body": "You have a Power BI semantic model that contains two queries.<br><br>You discover that a report based on the model has performance issues.<br><br>You plan to use Power Query to reduce the data loaded to the model.<br><br>Which two actions should you perform? Each correct answer presents part of the solution.<br><br>NOTE: Each correct answer is worth one point.",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tApply group by and summarize techniques.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCombine the queries by using Append.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRemove unnecessary columns and rows.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCombine the queries by using Merge.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a new query group."
    ],
    "answer": "AC",
    "answerDescription": "",
    "votes": [
      {
        "answer": "AC",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2024-10-10T07:53:00.000Z",
        "voteCount": 2,
        "content": "A and C are the correct answers"
      },
      {
        "date": "2024-10-08T01:10:00.000Z",
        "voteCount": 1,
        "content": "Correct answers\nhttps://learn.microsoft.com/en-us/power-bi/guidance/import-modeling-data-reduction"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 101,
    "url": "https://www.examtopics.com/discussions/microsoft/view/148896-exam-pl-300-topic-2-question-101-discussion/",
    "body": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.<br><br>After you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.<br><br>You have an on-premises data gateway.<br><br>You need to reduce the amount of data sent through the gateway by semantic models that run in Import storage mode.<br><br>Solution: You create aggregations to summarize results.<br><br>Does this meet the goal?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tYes",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tNo"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2024-10-16T11:25:00.000Z",
        "voteCount": 1,
        "content": "answer is yes. Aggregating ans summarizing reduces data."
      },
      {
        "date": "2024-10-11T09:49:00.000Z",
        "voteCount": 1,
        "content": "The answer is A."
      },
      {
        "date": "2024-10-08T21:23:00.000Z",
        "voteCount": 1,
        "content": "Create aggregations to summarize results.\nThis seems to be saying group and summarize after the data has come through the gateway as an import.\nThis will not reduce the traffic as it has already come through the gateway.\nAnswer : B.No."
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 102,
    "url": "https://www.examtopics.com/discussions/microsoft/view/148848-exam-pl-300-topic-2-question-102-discussion/",
    "body": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.<br><br>After you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.<br><br>You have an on-premises data gateway.<br><br>You need to reduce the amount of data sent through the gateway by semantic models that run in import storage mode.<br><br>Solution: You increase Automatic page refresh intervals.<br><br>Does this meet the goal?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tYes",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tNo"
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 2,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2024-10-11T09:55:00.000Z",
        "voteCount": 2,
        "content": "The correct answer is No. Automatic Refresh can only be used in direct query mode"
      },
      {
        "date": "2024-10-08T00:43:00.000Z",
        "voteCount": 2,
        "content": "1) Nothing to do with On-Prem data gateway\n2) It can be used with DirectQuery storage mode only\nhttps://learn.microsoft.com/en-us/power-bi/create-reports/desktop-automatic-page-refresh"
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  },
  {
    "topic": 2,
    "index": 103,
    "url": "https://www.examtopics.com/discussions/microsoft/view/148593-exam-pl-300-topic-2-question-103-discussion/",
    "body": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.<br><br>After you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.<br><br>You have an on-premises data gateway.<br><br>You need to reduce the amount of data sent through the gateway by semantic models that run in import storage mode.<br><br>Solution: You configure incremental refresh.<br><br>Does this meet the goal?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tYes",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tNo"
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 4,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2024-10-16T11:28:00.000Z",
        "voteCount": 1,
        "content": "Incremental refresh allows you to load only new or changed data, rather than refreshing the entire dataset. This can significantly reduce the amount of data that needs to be processed and transferred, especially in large datasets."
      },
      {
        "date": "2024-10-10T07:59:00.000Z",
        "voteCount": 2,
        "content": "The correct answer should be A. Incremental refresh refreshes the latest data"
      },
      {
        "date": "2024-10-04T00:36:00.000Z",
        "voteCount": 3,
        "content": "Incremental reloads do reduce the workload\n\n"
      },
      {
        "date": "2024-10-03T01:39:00.000Z",
        "voteCount": 3,
        "content": "I think using incremental reloads DOES reduce the amount of data sent through the gateway, so option A"
      },
      {
        "date": "2024-10-04T00:33:00.000Z",
        "voteCount": 1,
        "content": "Ta, I thought that too."
      }
    ],
    "examNameCode": "pl-300",
    "topicNumber": "2"
  }
]