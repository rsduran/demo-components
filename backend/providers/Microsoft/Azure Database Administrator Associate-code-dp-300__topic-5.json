[
  {
    "topic": 5,
    "index": 1,
    "url": "https://www.examtopics.com/discussions/microsoft/view/65801-exam-dp-300-topic-5-question-1-discussion/",
    "body": "HOTSPOT -<br>You have an Azure Data Factory instance named ADF1 and two Azure Synapse Analytics workspaces named WS1 and WS2.<br>ADF1 contains the following pipelines:<br>\u2711 P1: Uses a copy activity to copy data from a nonpartitioned table in a dedicated SQL pool of WS1 to an Azure Data Lake Storage Gen2 account<br>\u2711 P2: Uses a copy activity to copy data from text-delimited files in an Azure Data Lake Storage Gen2 account to a nonpartitioned table in a dedicated SQL pool of WS2<br>You need to configure P1 and P2 to maximize parallelism and performance.<br>Which dataset settings should you configure for the copy activity of each pipeline? To answer, select the appropriate options in the answer area.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04275/0023200003.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04275/0023300001.png\" class=\"in-exam-image\">",
    "answerDescription": "P1: Set the Partition option to Dynamic Range.<br>The SQL Server connector in copy activity provides built-in data partitioning to copy data in parallel.<br>P2: Set the Copy method to PolyBase<br>Polybase is the most efficient way to move data into Azure Synapse Analytics. Use the staging blob feature to achieve high load speeds from all types of data stores, including Azure Blob storage and Data Lake Store. (Polybase supports Azure Blob storage and Azure Data Lake Store by default.)<br>Reference:<br>https://docs.microsoft.com/en-us/azure/data-factory/connector-azure-sql-data-warehouse https://docs.microsoft.com/en-us/azure/data-factory/load-azure-sql-data-warehouse",
    "votes": [],
    "comments": [
      {
        "date": "2022-11-01T05:20:00.000Z",
        "voteCount": 5,
        "content": "This question is for DP-203 exam (Data Engineer)."
      },
      {
        "date": "2023-08-29T06:22:00.000Z",
        "voteCount": 1,
        "content": "P1 : PolyBase\nP2 : Bulk Insert"
      },
      {
        "date": "2023-02-25T04:15:00.000Z",
        "voteCount": 2,
        "content": "For P1:\n\nSet the Copy method to PolyBase\nFor P2:\n\nSet the Copy method to Bulk insert"
      },
      {
        "date": "2022-04-01T06:53:00.000Z",
        "voteCount": 3,
        "content": "DP-203"
      },
      {
        "date": "2022-01-22T13:07:00.000Z",
        "voteCount": 3,
        "content": "Looks correct"
      },
      {
        "date": "2021-11-10T11:55:00.000Z",
        "voteCount": 1,
        "content": "its ok?"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "5"
  },
  {
    "topic": 5,
    "index": 2,
    "url": "https://www.examtopics.com/discussions/microsoft/view/84824-exam-dp-300-topic-5-question-2-discussion/",
    "body": "You have the following Azure Data Factory pipelines:<br>\u2711 Ingest Data from System1<br><br>Ingest Data from System2 -<br><img src=\"/assets/media/exam-media/04275/0023300003.png\" class=\"in-exam-image\"><br>\u2711 Populate Dimensions<br>\u2711 Populate Facts<br>Ingest Data from System1 and Ingest Data from System2 have no dependencies. Populate Dimensions must execute after Ingest Data from System1 and Ingest<br>Data from System2. Populate Facts must execute after the Populate Dimensions pipeline. All the pipelines must execute every eight hours.<br>What should you do to schedule the pipelines for execution?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAdd a schedule trigger to all four pipelines.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAdd an event trigger to all four pipelines.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a parent pipeline that contains the four pipelines and use an event trigger.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a parent pipeline that contains the four pipelines and use a schedule trigger.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "Reference:<br>https://www.mssqltips.com/sqlservertip/6137/azure-data-factory-control-flow-activities-overview/",
    "votes": [
      {
        "answer": "D",
        "count": 1,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2022-10-09T04:43:00.000Z",
        "voteCount": 5,
        "content": "DP-203: Data Engineering on Microsoft Azure"
      },
      {
        "date": "2023-09-02T15:56:00.000Z",
        "voteCount": 1,
        "content": "It should be event not schedule?."
      },
      {
        "date": "2022-12-25T10:47:00.000Z",
        "voteCount": 1,
        "content": "answer is correct"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "5"
  },
  {
    "topic": 5,
    "index": 3,
    "url": "https://www.examtopics.com/discussions/microsoft/view/65796-exam-dp-300-topic-5-question-3-discussion/",
    "body": "You have an Azure Data Factory pipeline that performs an incremental load of source data to an Azure Data Lake Storage Gen2 account.<br>Data to be loaded is identified by a column named LastUpdatedDate in the source table.<br>You plan to execute the pipeline every four hours.<br>You need to ensure that the pipeline execution meets the following requirements:<br>\u2711 Automatically retries the execution when the pipeline run fails due to concurrency or throttling limits.<br>\u2711 Supports backfilling existing data in the table.<br>Which type of trigger should you use?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ttumbling window\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ton-demand",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tevent",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tschedule"
    ],
    "answer": "A",
    "answerDescription": "The Tumbling window trigger supports backfill scenarios. Pipeline runs can be scheduled for windows in the past.<br>Incorrect Answers:<br>D: Schedule trigger does not support backfill scenarios. Pipeline runs can be executed only on time periods from the current time and the future.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/data-factory/concepts-pipeline-execution-triggers",
    "votes": [
      {
        "answer": "A",
        "count": 1,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2022-10-16T04:10:00.000Z",
        "voteCount": 3,
        "content": "Not related to DP-300 exam."
      },
      {
        "date": "2022-04-01T06:54:00.000Z",
        "voteCount": 3,
        "content": "DP-203"
      },
      {
        "date": "2022-01-24T11:48:00.000Z",
        "voteCount": 1,
        "content": "Tumbling window is correct, link explains it all"
      },
      {
        "date": "2022-01-17T02:37:00.000Z",
        "voteCount": 2,
        "content": "Its correct\nhttps://docs.microsoft.com/en-us/azure/data-factory/how-to-create-tumbling-window-trigger?tabs=data-factory%2Cazure-powershell"
      },
      {
        "date": "2021-11-10T11:34:00.000Z",
        "voteCount": 1,
        "content": "its ok?"
      },
      {
        "date": "2021-11-10T11:34:00.000Z",
        "voteCount": 1,
        "content": "\u00bfest\u00e1 bien?"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "5"
  },
  {
    "topic": 5,
    "index": 4,
    "url": "https://www.examtopics.com/discussions/microsoft/view/65797-exam-dp-300-topic-5-question-4-discussion/",
    "body": "You have an Azure Data Factory that contains 10 pipelines.<br>You need to label each pipeline with its main purpose of either ingest, transform, or load. The labels must be available for grouping and filtering when using the monitoring experience in Data Factory.<br>What should you add to each pipeline?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tan annotation\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ta resource tag",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ta run group ID",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ta user property",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ta correlation ID"
    ],
    "answer": "A",
    "answerDescription": "Azure Data Factory annotations help you easily filter different Azure Data Factory objects based on a tag. You can define tags so you can see their performance or find errors faster.<br>Reference:<br>https://www.techtalkcorner.com/monitor-azure-data-factory-annotations/",
    "votes": [
      {
        "answer": "A",
        "count": 2,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2022-11-08T11:12:00.000Z",
        "voteCount": 3,
        "content": "Azure Data Factory is out of DP-300 exam."
      },
      {
        "date": "2022-04-01T06:54:00.000Z",
        "voteCount": 4,
        "content": "DP-203"
      },
      {
        "date": "2021-12-02T12:14:00.000Z",
        "voteCount": 2,
        "content": "https://www.techtalkcorner.com/monitor-azure-data-factory-annotations/"
      },
      {
        "date": "2021-11-10T11:34:00.000Z",
        "voteCount": 1,
        "content": "its ok?"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "5"
  },
  {
    "topic": 5,
    "index": 5,
    "url": "https://www.examtopics.com/discussions/microsoft/view/65798-exam-dp-300-topic-5-question-5-discussion/",
    "body": "HOTSPOT -<br>You have an Azure data factory that has two pipelines named PipelineA and PipelineB.<br>PipelineA has four activities as shown in the following exhibit.<br><img src=\"/assets/media/exam-media/04275/0023600001.jpg\" class=\"in-exam-image\"><br>PipelineB has two activities as shown in the following exhibit.<br><img src=\"/assets/media/exam-media/04275/0023600002.jpg\" class=\"in-exam-image\"><br>You create an alert for the data factory that uses Failed pipeline runs metrics for both pipelines and all failure types. The metric has the following settings:<br>\u2711 Operator: Greater than<br>\u2711 Aggregation type: Total<br>\u2711 Threshold value: 2<br>\u2711 Aggregation granularity (Period): 5 minutes<br>\u2711 Frequency of evaluation: Every 5 minutes<br>Data Factory monitoring records the failures shown in the following table.<br><img src=\"/assets/media/exam-media/04275/0023600008.png\" class=\"in-exam-image\"><br>For each of the following statements, select Yes if the statement is true. Otherwise, select No.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04275/0023700001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04275/0023700002.png\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: No -<br>Just one failure within the 5-minute interval.<br><br>Box 2: No -<br>Just two failures within the 5-minute interval.<br><br>Box 3: No -<br>Just two failures within the 5-minute interval.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/azure-monitor/alerts/alerts-metric-overview",
    "votes": [],
    "comments": [
      {
        "date": "2022-10-16T03:37:00.000Z",
        "voteCount": 5,
        "content": "Not related to DP-300 exam"
      },
      {
        "date": "2023-07-16T01:03:00.000Z",
        "voteCount": 1,
        "content": "bouncer for me.."
      },
      {
        "date": "2023-05-14T22:30:00.000Z",
        "voteCount": 1,
        "content": "The answer No-No-No is correct.\nEvery 5 minutes period you need at least 3 errors in order to trigger the alert."
      },
      {
        "date": "2023-01-26T10:58:00.000Z",
        "voteCount": 2,
        "content": "same here, do not understand the explanation"
      },
      {
        "date": "2023-01-12T08:19:00.000Z",
        "voteCount": 1,
        "content": "explanation does not make sense"
      },
      {
        "date": "2022-04-01T06:55:00.000Z",
        "voteCount": 3,
        "content": "DP-203"
      },
      {
        "date": "2021-11-10T11:34:00.000Z",
        "voteCount": 1,
        "content": "its ok?"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "5"
  },
  {
    "topic": 5,
    "index": 6,
    "url": "https://www.examtopics.com/discussions/microsoft/view/65799-exam-dp-300-topic-5-question-6-discussion/",
    "body": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.<br>After you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.<br>You have an Azure Data Lake Storage account that contains a staging zone.<br>You need to design a daily process to ingest incremental data from the staging zone, transform the data by executing an R script, and then insert the transformed data into a data warehouse in Azure Synapse Analytics.<br>Solution: You use an Azure Data Factory schedule trigger to execute a pipeline that executes mapping data flow, and then inserts the data into the data warehouse.<br>Does this meet the goal?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tYes",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tNo"
    ],
    "answer": "B",
    "answerDescription": "Correct solution: You use an Azure Data Factory schedule trigger to execute a pipeline that executes an Azure Databricks notebook, and then inserts the data into the data warehouse.<br>Reference:<br>https://docs.microsoft.com/en-US/azure/data-factory/transform-data",
    "votes": [],
    "comments": [
      {
        "date": "2022-04-01T06:55:00.000Z",
        "voteCount": 6,
        "content": "DP-203"
      },
      {
        "date": "2022-10-16T03:38:00.000Z",
        "voteCount": 3,
        "content": "Not related to DP-300 exam."
      },
      {
        "date": "2021-11-10T11:34:00.000Z",
        "voteCount": 1,
        "content": "looks correct"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "5"
  },
  {
    "topic": 5,
    "index": 7,
    "url": "https://www.examtopics.com/discussions/microsoft/view/65792-exam-dp-300-topic-5-question-7-discussion/",
    "body": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.<br>After you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.<br>You have an Azure Data Lake Storage account that contains a staging zone.<br>You need to design a daily process to ingest incremental data from the staging zone, transform the data by executing an R script, and then insert the transformed data into a data warehouse in Azure Synapse Analytics.<br>Solution: You schedule an Azure Databricks job that executes an R notebook, and then inserts the data into the data warehouse.<br>Does this meet the goal?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tYes\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tNo"
    ],
    "answer": "B",
    "answerDescription": "Must use an Azure Data Factory, not an Azure Databricks job.<br>Correct solution: You use an Azure Data Factory schedule trigger to execute a pipeline that executes an Azure Databricks notebook, and then inserts the data into the data warehouse.<br>Reference:<br>https://docs.microsoft.com/en-US/azure/data-factory/transform-data",
    "votes": [
      {
        "answer": "A",
        "count": 1,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-07-22T08:04:00.000Z",
        "voteCount": 1,
        "content": "Answer should be yes."
      },
      {
        "date": "2023-04-07T08:23:00.000Z",
        "voteCount": 3,
        "content": "Yes, this solution meets the goal. By scheduling an Azure Databricks job that executes an R notebook, you can transform the data from the staging zone in your Azure Data Lake Storage account. Then, by inserting the data into the data warehouse in Azure Synapse Analytics, you can complete the daily process of ingesting incremental data. So, the answer is A. Yes."
      },
      {
        "date": "2024-06-29T07:15:00.000Z",
        "voteCount": 1,
        "content": "DP-203, Question! \nBUT Ans is Yes Databricks can do that and very easily."
      },
      {
        "date": "2023-02-26T02:31:00.000Z",
        "voteCount": 2,
        "content": "A. Yes, this solution meets the goal of ingesting incremental data from the staging zone, transforming the data by executing an R script, and inserting the transformed data into a data warehouse in Azure Synapse Analytics using Azure Databricks. The scheduled Azure Databricks job can be used to execute the R notebook and insert the transformed data into the data warehouse."
      },
      {
        "date": "2022-10-16T03:38:00.000Z",
        "voteCount": 2,
        "content": "Not related to DP-300 exam."
      },
      {
        "date": "2022-04-01T06:56:00.000Z",
        "voteCount": 4,
        "content": "DP-203"
      },
      {
        "date": "2021-11-10T11:27:00.000Z",
        "voteCount": 1,
        "content": "looks good, what do you think?"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "5"
  },
  {
    "topic": 5,
    "index": 8,
    "url": "https://www.examtopics.com/discussions/microsoft/view/65793-exam-dp-300-topic-5-question-8-discussion/",
    "body": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.<br>After you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.<br>You have an Azure Data Lake Storage account that contains a staging zone.<br>You need to design a daily process to ingest incremental data from the staging zone, transform the data by executing an R script, and then insert the transformed data into a data warehouse in Azure Synapse Analytics.<br>Solution: You use an Azure Data Factory schedule trigger to execute a pipeline that executes an Azure Databricks notebook, and then inserts the data into the data warehouse.<br>Does this meet the goal?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tYes",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tNo"
    ],
    "answer": "A",
    "answerDescription": "An Azure Data Factory can trigger a Databricks notebook.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/data-factory/transform-data-using-databricks-notebook",
    "votes": [],
    "comments": [
      {
        "date": "2023-04-07T08:26:00.000Z",
        "voteCount": 1,
        "content": "Yes, this solution meets the goal. By using an Azure Data Factory schedule trigger to execute a pipeline that executes an Azure Databricks notebook, you can transform the data from the staging zone in your Azure Data Lake Storage account. Then, by inserting the data into the data warehouse in Azure Synapse Analytics, you can complete the daily process of ingesting incremental data. So, the answer is A. Yes."
      },
      {
        "date": "2022-10-16T03:39:00.000Z",
        "voteCount": 1,
        "content": "Not related to DP-300 exam."
      },
      {
        "date": "2022-09-03T07:39:00.000Z",
        "voteCount": 1,
        "content": "In the Question mentioned \"Execute R script\" not \"executes an Azure Databricks notebook\" \nThe correct answer should be - B (No)"
      },
      {
        "date": "2022-09-03T09:38:00.000Z",
        "voteCount": 1,
        "content": "Sorry ignore my comment, it should be A. Yes.\nDatabricks can run R script Notebook. \nhttps://docs.databricks.com/spark/latest/sparkr/index.html"
      },
      {
        "date": "2022-04-01T06:56:00.000Z",
        "voteCount": 2,
        "content": "DP-203"
      },
      {
        "date": "2021-11-10T11:29:00.000Z",
        "voteCount": 2,
        "content": "looks correct"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "5"
  },
  {
    "topic": 5,
    "index": 9,
    "url": "https://www.examtopics.com/discussions/microsoft/view/65795-exam-dp-300-topic-5-question-9-discussion/",
    "body": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.<br>After you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.<br>You have an Azure Data Lake Storage account that contains a staging zone.<br>You need to design a daily process to ingest incremental data from the staging zone, transform the data by executing an R script, and then insert the transformed data into a data warehouse in Azure Synapse Analytics.<br>Solution: You use an Azure Data Factory schedule trigger to execute a pipeline that copies the data to a staging table in the data warehouse, and then uses a stored procedure to execute the R script.<br>Does this meet the goal?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tYes",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tNo\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 5,
        "isMostVoted": true
      },
      {
        "answer": "A",
        "count": 2,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2022-04-01T06:56:00.000Z",
        "voteCount": 8,
        "content": "DP-203"
      },
      {
        "date": "2024-01-09T07:06:00.000Z",
        "voteCount": 2,
        "content": "Transform Data using R Script: The solution suggests using a stored procedure to execute the R script. While stored procedures can be used for certain types of processing, executing an R script might be more efficiently done using tools that natively support R, such as Azure Machine Learning Services or Azure Databricks."
      },
      {
        "date": "2023-04-07T08:30:00.000Z",
        "voteCount": 2,
        "content": "B. No.\n\nThe solution described does not fully meet the stated goal. While it includes a pipeline to copy data to a staging table in the data warehouse, it does not account for the incremental nature of the data. Additionally, using a stored procedure to execute the R script may not be the most efficient approach for transforming the data."
      },
      {
        "date": "2023-03-02T23:42:00.000Z",
        "voteCount": 1,
        "content": "A. Yes.\n\nThis solution meets the goal of ingesting incremental data from the staging zone, transforming the data using an R script, and inserting the transformed data into a data warehouse in Azure Synapse Analytics. By using Azure Data Factory to copy the data to a staging table in the data warehouse, and then using a stored procedure to execute the R script, you can ensure that the data is transformed correctly before it is inserted into the data warehouse. Additionally, using a stored procedure can help simplify the pipeline and reduce maintenance efforts, since the R script can be updated in a single location"
      },
      {
        "date": "2022-11-13T10:23:00.000Z",
        "voteCount": 3,
        "content": "This question is not for DBA (DP-300 exam)."
      },
      {
        "date": "2022-09-03T08:16:00.000Z",
        "voteCount": 3,
        "content": "Insert to DWH comes after the Execution of R script, so the correct Answer should be (B. No)"
      },
      {
        "date": "2022-01-25T11:33:00.000Z",
        "voteCount": 1,
        "content": "Seems right\nhttps://docs.microsoft.com/en-us/sql/machine-learning/tutorials/quickstart-r-create-script?view=sql-server-ver15\nBy default, sp_execute_external_script accepts a single dataset as input, which typically you supply in the form of a valid SQL query. It then returns a single R data frame as output."
      },
      {
        "date": "2021-11-10T11:29:00.000Z",
        "voteCount": 1,
        "content": "looks correct"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "5"
  },
  {
    "topic": 5,
    "index": 10,
    "url": "https://www.examtopics.com/discussions/microsoft/view/65794-exam-dp-300-topic-5-question-10-discussion/",
    "body": "DRAG DROP -<br>You have an Azure subscription that contains an Azure SQL managed instance named SQLMi1 and a SQL Agent job named Backupdb. Backupdb performs a daily backup of the databases hosted on SQLMi1.<br>You need to be notified by email if the job fails.<br>Which three actions should you perform in sequence? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.<br>NOTE: More than one order of answer choices is correct. You will receive credit for any of the correct orders you select.<br>Select and Place:<br><img src=\"/assets/media/exam-media/04275/0024200001.jpg\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04275/0024200002.jpg\" class=\"in-exam-image\">",
    "answerDescription": "Step 1: Enable Database Mail -<br>If it isn't already enabled, first you would need to configure the Database Mail feature on SQL Managed Instance.<br>Box 2: Create an operator.<br>You can notify the operator that something happened with your SQL Agent jobs. An operator defines contact information for an individual responsible for the maintenance of one or more instances in SQL Managed Instance.<br>Box 3: Add a failure notification to the job,<br>You can then modify any SQL Agent job and assign operators that will be notified via email if the job completes, fails, or succeeds using SSMS or the following T-<br>SQL script:<br>EXEC msdb.dbo.sp_update_job @job_name=N'Load data using SSIS',<br>@notify_level_email=3, -- Options are: 1 on succeed, 2 on failure, 3 on complete<br>@notify_email_operator_name=N'AzureSQLTeam';<br>Reference:<br>https://docs.microsoft.com/en-us/azure/azure-sql/managed-instance/job-automation-managed-instance",
    "votes": [],
    "comments": [
      {
        "date": "2024-04-21T07:19:00.000Z",
        "voteCount": 1,
        "content": "It's correct."
      },
      {
        "date": "2023-04-26T02:51:00.000Z",
        "voteCount": 2,
        "content": "Correct.\nhttps://learn.microsoft.com/en-us/azure/azure-sql/managed-instance/job-automation-managed-instance?view=azuresql"
      },
      {
        "date": "2022-09-18T22:26:00.000Z",
        "voteCount": 2,
        "content": "Not a fair question. An operator can be created before Database Mail is enabled or after, it doesnt matter which way around. As long as the Database Mail is enabled and an Operator created before adding a failure notification to a job."
      },
      {
        "date": "2022-11-12T07:15:00.000Z",
        "voteCount": 4,
        "content": "NOTE: More than one order of answer choices is correct."
      },
      {
        "date": "2022-01-21T13:30:00.000Z",
        "voteCount": 1,
        "content": "Answer is correct"
      },
      {
        "date": "2021-11-10T11:29:00.000Z",
        "voteCount": 2,
        "content": "looks correct"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "5"
  },
  {
    "topic": 5,
    "index": 11,
    "url": "https://www.examtopics.com/discussions/microsoft/view/63878-exam-dp-300-topic-5-question-11-discussion/",
    "body": "DRAG DROP -<br>You have SQL Server on an Azure virtual machine.<br>You need to use Policy-Based Management in Microsoft SQL Server to identify stored procedures that do not comply with your naming conventions.<br>Which three actions should you perform in sequence? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.<br>Select and Place:<br><img src=\"/assets/media/exam-media/04275/0024400001.jpg\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04275/0024400002.jpg\" class=\"in-exam-image\">",
    "answerDescription": "First create a condition, then a custom policy based on the condition, finally run a policy evaluation.<br>Reference:<br>https://www.mssqltips.com/sqlservertip/2298/enforce-sql-server-database-naming-conventions-using-policy-based-management/",
    "votes": [],
    "comments": [
      {
        "date": "2022-12-29T11:33:00.000Z",
        "voteCount": 1,
        "content": "Condition--&gt;Policy-&gt;Evaluate.\nhttps://learn.microsoft.com/en-us/sql/relational-databases/policy-based-management/administer-servers-by-using-policy-based-management?view=sql-server-ver16"
      },
      {
        "date": "2022-10-24T04:04:00.000Z",
        "voteCount": 3,
        "content": "Remember CP: firts the Condition, then the Policy."
      },
      {
        "date": "2024-05-16T04:56:00.000Z",
        "voteCount": 1,
        "content": "Thanks man. Good way to remember."
      },
      {
        "date": "2022-03-15T04:48:00.000Z",
        "voteCount": 3,
        "content": "Correct Answer\n\n-&gt; Create a custom condition based on a built-in facet\n-&gt; Create a custom policy based on a condition\n-&gt; Run a policy evaluation\n\nhttps://www.mssqltips.com/sqlservertip/2298/enforce-sql-server-database-naming-conventions-using-policy-based-management/"
      },
      {
        "date": "2022-01-30T19:14:00.000Z",
        "voteCount": 1,
        "content": "https://docs.microsoft.com/en-us/sql/relational-databases/policy-based-management/administer-servers-by-using-policy-based-management?view=sql-server-ver15\n\nLooks like given answer is correct."
      },
      {
        "date": "2022-01-05T19:44:00.000Z",
        "voteCount": 1,
        "content": "Existing answer is correct. We should create a condition before creating policy."
      },
      {
        "date": "2021-10-09T18:57:00.000Z",
        "voteCount": 3,
        "content": "I think the correct answer is: B-C-F"
      },
      {
        "date": "2021-10-11T16:50:00.000Z",
        "voteCount": 1,
        "content": "Yes, The correct answer is BCF."
      },
      {
        "date": "2021-11-18T01:51:00.000Z",
        "voteCount": 4,
        "content": "you should create the condition before the policy\nhttps://www.red-gate.com/simple-talk/blogs/sql-server-policy-based-management-creating-a-custom-condition/"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "5"
  },
  {
    "topic": 5,
    "index": 12,
    "url": "https://www.examtopics.com/discussions/microsoft/view/62637-exam-dp-300-topic-5-question-12-discussion/",
    "body": "You have an Azure SQL managed instance named SQLMI1 that hosts 10 databases.<br>You need to implement alerts by using Azure Monitor. The solution must meet the following requirements:<br>\u2711 Minimize costs.<br>\u2711 Aggregate Intelligent Insights telemetry from each database.<br>What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tFrom the Diagnostic settings of each database, select Send to Log Analytics.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tFrom the Diagnostic settings of each database, select Stream to an event hub.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tFrom the Diagnostic settings of SQLMI1, select Send to Log Analytics.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tFrom the Diagnostic settings of SQLMI1, select Stream to an event hub."
    ],
    "answer": "A",
    "answerDescription": "Databases in Azure SQL Managed Instance<br>You can set up an instance database resource to collect the following diagnostic telemetry:<br>To enable streaming of diagnostic telemetry for an instance database, follow these steps:<br>1. Go to instance database resource within managed instance.<br>2. Select Diagnostics settings.<br>3. Select Turn on diagnostics if no previous settings exist, or select Edit setting to edit a previous setting.<br>4. Etc.<br>5. Repeat the above steps for each instance database you want to monitor.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/azure-sql/database/metrics-diagnostic-telemetry-logging-streaming-export-configure?tabs=azure-portal#configure-the- streaming-export-of-diagnostic-telemetry",
    "votes": [
      {
        "answer": "A",
        "count": 1,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-04-07T08:52:00.000Z",
        "voteCount": 5,
        "content": "The answer is C.\n\nC. From the Diagnostic settings of SQLMI1, select Send to Log Analytics.\n\nTo implement alerts by using Azure Monitor, the best approach is to send diagnostic data from the Azure SQL managed instance to Log Analytics. This approach meets both requirements, as it aggregates telemetry data from each database and minimizes costs. With Log Analytics, you can centralize and analyze diagnostic data from different sources, including Azure SQL Managed Instances, and set up alerts based on specific conditions.\n\nOption A would require setting up diagnostic settings for each database individually, which can be time-consuming and difficult to manage. Option B would require creating an event hub for each database, which could result in increased costs and complexity."
      },
      {
        "date": "2024-01-31T09:12:00.000Z",
        "voteCount": 5,
        "content": "Everyone should be careful about U_C, he always provides wrong answers randomly."
      },
      {
        "date": "2024-06-29T08:17:00.000Z",
        "voteCount": 1,
        "content": "He has pasted most of the generative AI, Chat GPT etc content only."
      },
      {
        "date": "2023-04-26T03:23:00.000Z",
        "voteCount": 5,
        "content": "Yes, but: \nTo configure streaming of diagnostic telemetry for managed instance and instance databases, you will need to separately configure each:\n\nEnable streaming of diagnostic telemetry for managed instance\nEnable streaming of diagnostic telemetry for each instance database\nThe managed instance container has its own telemetry separate from each instance database's telemetry.\n\nSo, we need to do both. In that case for me the best answer is A as is needed.\nhttps://learn.microsoft.com/en-us/azure/azure-sql/database/metrics-diagnostic-telemetry-logging-streaming-export-configure?tabs=azure-portal&amp;view=azuresql#configure-the-streaming-export-of-diagnostic-telemetry"
      },
      {
        "date": "2024-09-20T17:55:00.000Z",
        "voteCount": 1,
        "content": "I think the answer actually within the question \n\"Aggregate Intelligent Insights telemetry from EACH database\"\nIn addition I do agree with OBIJUAN88 comment."
      },
      {
        "date": "2023-09-14T17:31:00.000Z",
        "voteCount": 1,
        "content": "You can use the Diagnostics settings menu in the Azure portal to enable and configure streaming of diagnostic telemetry. \n\nAdditionally, you can use PowerShell, the Azure CLI, the REST API, and Resource Manager templates to configure streaming of diagnostic telemetry. \n\nYou can set the following destinations to stream the diagnostic telemetry: Azure Storage, Azure Event Hubs, and Azure Monitor logs.\n\nhttps://learn.microsoft.com/en-us/azure/azure-sql/database/metrics-diagnostic-telemetry-logging-streaming-export-configure?view=azuresql&amp;tabs=azure-portal#configure-the-streaming-export-of-diagnostic-telemetry"
      },
      {
        "date": "2023-08-29T02:15:00.000Z",
        "voteCount": 2,
        "content": "https://learn.microsoft.com/en-us/azure/azure-sql/database/metrics-diagnostic-telemetry-logging-streaming-export-configure?tabs=azure-portal&amp;view=azuresql#configure-the-streaming-export-of-diagnostic-telemetry\n\"To configure streaming of diagnostic telemetry for managed instance and instance databases, you need to separately configure each:\n\nEnable streaming of diagnostic telemetry for managed instance\nEnable streaming of diagnostic telemetry for each instance database\nThe managed instance container has its own telemetry separate from each instance database's telemetry.\" - so the provided answer is correct, we need to do it for each database."
      },
      {
        "date": "2023-03-01T06:32:00.000Z",
        "voteCount": 1,
        "content": "To configure streaming of diagnostic telemetry for managed instance and instance databases, you will need to separately configure each:\n\nEnable streaming of diagnostic telemetry for managed instance\nEnable streaming of diagnostic telemetry for each instance database\nThe managed instance container has its own telemetry separate from each instance database's telemetry."
      },
      {
        "date": "2021-09-23T15:36:00.000Z",
        "voteCount": 3,
        "content": "https://docs.microsoft.com/en-us/azure/azure-sql/database/metrics-diagnostic-telemetry-logging-streaming-export-configure?tabs=azure-portal#configure-the-streaming-export-of-diagnostic-telemetry"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "5"
  },
  {
    "topic": 5,
    "index": 13,
    "url": "https://www.examtopics.com/discussions/microsoft/view/65791-exam-dp-300-topic-5-question-13-discussion/",
    "body": "You have an Azure SQL managed instance that hosts multiple databases.<br>You need to configure alerts for each database based on the diagnostics telemetry of the database.<br>What should you use?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure SQL Analytics alerts based on metrics",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSQL Health Check alerts based on diagnostics logs",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSQL Health Check alerts based on metrics",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure SQL Analytics alerts based on diagnostics logs"
    ],
    "answer": "D",
    "answerDescription": "You can use Azure SQL Analytics for monitoring and alerting.<br>You can easily create alerts with the data coming from Azure SQL Database resources. Here are some useful log queries that you can use with a log alert:<br>Example, HIGH CPU:<br><br>AzureMetrics -<br>| where ResourceProvider==\"MICROSOFT.SQL\"<br>| where ResourceId contains \"/DATABASES/\"<br>| where MetricName==\"cpu_percent\"<br>| summarize AggregatedValue = max(Maximum) by bin(TimeGenerated, 5m)<br>| render timechart<br>Note: Azure Monitor Logs is based on Azure Data Explorer, and log queries are written using the same Kusto query language (KQL).<br>Reference:<br>https://docs.microsoft.com/en-us/azure/azure-sql/database/metrics-diagnostic-telemetry-logging-streaming-export-configure?tabs=azure-portal#configure-the- streaming-export-of-diagnostic-telemetry",
    "votes": [],
    "comments": [
      {
        "date": "2023-02-23T02:00:00.000Z",
        "voteCount": 3,
        "content": "D. Azure SQL Analytics alerts based on diagnostics logs"
      },
      {
        "date": "2023-01-07T07:27:00.000Z",
        "voteCount": 1,
        "content": "For the standard, event-based monitoring experience, select the following check boxes for database diagnostics log telemetry: SQLInsights, AutomaticTuning, QueryStoreRuntimeStatistics, QueryStoreWaitStatistics, Errors, DatabaseWaitStatistics, Timeouts, Blocks, and Deadlocks.\n\nhttps://learn.microsoft.com/en-us/azure/azure-sql/database/metrics-diagnostic-telemetry-logging-streaming-export-configure?view=azuresql&amp;tabs=azure-portal"
      },
      {
        "date": "2021-11-10T11:27:00.000Z",
        "voteCount": 3,
        "content": "looks good, what do you think?"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "5"
  },
  {
    "topic": 5,
    "index": 14,
    "url": "https://www.examtopics.com/discussions/microsoft/view/78665-exam-dp-300-topic-5-question-14-discussion/",
    "body": "You have an Azure SQL managed instance.<br>You need to enable SQL Agent Job email notifications.<br>What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse the Agent XPs option.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEnable the SQL Server Agent.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRun the sp_configure command.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRun the sp_set_agent_properties command."
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 8,
        "isMostVoted": true
      },
      {
        "answer": "B",
        "count": 3,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2024-04-20T01:28:00.000Z",
        "voteCount": 2,
        "content": "C is correct.\nhttps://learn.microsoft.com/en-us/sql/ssms/agent/configure-sql-server-agent?source=recommendations&amp;view=sql-server-ver16\nOn Sql Server Managed Instance SqlAgent is always running so B is not possible."
      },
      {
        "date": "2023-09-03T13:22:00.000Z",
        "voteCount": 1,
        "content": "in SQL MI, user doesnot have control to stop OR start SQL Agent and SQL agent in MI always is in running state so, next step in the process of job alert notification is to enable DB mail by running Sp_configure so, C is correct answer, configure DB mail using Exec Sp_configure"
      },
      {
        "date": "2023-09-03T13:21:00.000Z",
        "voteCount": 1,
        "content": "in SQL MI, user doesnot have control to stop OR start SQL Agent and SQL agent in MI always is in running state so, next step in the process of job alert notification is to enable DB mail by running exec Sp_configure so, C is correct answer, configure DB mail using Exec Sp_configure"
      },
      {
        "date": "2023-04-26T04:26:00.000Z",
        "voteCount": 2,
        "content": "If it isn't already enabled, first you would need to configure the Database Mail feature on SQL Managed Instance:\n\nSQL\n\nCopy\nGO\nEXEC sp_configure 'show advanced options', 1;\nGO\nRECONFIGURE;\nGO\nEXEC sp_configure 'Database Mail XPs', 1;\nGO\nRECONFIGURE\n\nhttps://learn.microsoft.com/en-us/azure/azure-sql/managed-instance/job-automation-managed-instance?view=azuresql"
      },
      {
        "date": "2023-04-14T09:39:00.000Z",
        "voteCount": 1,
        "content": "i think C is correct, since you cannot enable/disable sql agent on MI(only can do it on sql server)"
      },
      {
        "date": "2023-04-07T09:13:00.000Z",
        "voteCount": 2,
        "content": "ChatGPT doesn't provide the correct answer on this question. The Database Mail feature is independent of the SQL Server Agent and can be configured and used without enabling the SQL Server Agent. Usually we enable Database Mail feature first before enabling SQL Agent."
      },
      {
        "date": "2024-04-16T08:47:00.000Z",
        "voteCount": 1,
        "content": "Which is why we shouldn't take answers from it and stick to contributions from real users!"
      },
      {
        "date": "2023-04-07T09:15:00.000Z",
        "voteCount": 1,
        "content": "The answer C is correct."
      },
      {
        "date": "2023-03-19T06:12:00.000Z",
        "voteCount": 1,
        "content": "Enable the SQL Server Agent"
      },
      {
        "date": "2023-04-24T05:10:00.000Z",
        "voteCount": 1,
        "content": "Enabling and disabling SQL Server Agent is currently not supported in SQL Managed Instance. SQL Agent is always running in SQLMI"
      },
      {
        "date": "2023-04-24T05:11:00.000Z",
        "voteCount": 2,
        "content": "https://learn.microsoft.com/en-us/sql/ssms/agent/configure-sql-server-agent?source=recommendations&amp;view=sql-server-ver16"
      },
      {
        "date": "2024-04-20T01:27:00.000Z",
        "voteCount": 1,
        "content": "Thanks for provided documentation. So the answer C is correct"
      },
      {
        "date": "2023-03-02T23:55:00.000Z",
        "voteCount": 2,
        "content": "B. Enable the SQL Server Agent.\n\nExplanation:\nTo enable SQL Agent Job email notifications, you need to enable the SQL Server Agent. The SQL Server Agent is a component of the SQL Server Database Engine that can execute scheduled administrative tasks, such as executing SQL Agent jobs. SQL Agent jobs can be configured to send email notifications based on job status. To enable the SQL Server Agent, you can use SQL Server Management Studio or Transact-SQL commands. Once the SQL Server Agent is enabled, you can configure email notifications for SQL Agent jobs in the SQL Server Agent properties."
      },
      {
        "date": "2022-10-24T04:12:00.000Z",
        "voteCount": 3,
        "content": "In this page: \nhttps://learn.microsoft.com/en-us/azure/azure-sql/managed-instance/job-automation-managed-instance?view=azuresql\nthey use sp_configure option."
      },
      {
        "date": "2022-08-31T03:54:00.000Z",
        "voteCount": 1,
        "content": "Are you sure this is the answer? I think A"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "5"
  },
  {
    "topic": 5,
    "index": 15,
    "url": "https://www.examtopics.com/discussions/microsoft/view/86324-exam-dp-300-topic-5-question-15-discussion/",
    "body": "You have four Azure subscriptions. Each subscription contains multiple Azure SQL databases.<br>You need to update the column and index statistics for the databases.<br>What should you use?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tan Azure Automation runbook\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ta SQL Agent job",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure SQL Analytics",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tautomatic tuning in Azure SQL Database"
    ],
    "answer": "A",
    "answerDescription": "You can create a runbook for index maintenance in an Azure SQL database.<br>Reference:<br>https://www.sqlshack.com/automate-azure-sql-database-indexes-and-statistics-maintenance/",
    "votes": [
      {
        "answer": "A",
        "count": 2,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-03-01T06:38:00.000Z",
        "voteCount": 6,
        "content": "A. an Azure Automation runbook    CORRECT\nB. a SQL Agent job  - AZURE SQL Database doesn't have SQL Agent, only elastic jobs.\nC. Azure SQL Analytics - Not related with statistics\nD. automatic tuning in Azure SQL Database  - Not related with statistics, only execution plan and indexes."
      },
      {
        "date": "2024-04-16T08:52:00.000Z",
        "voteCount": 1,
        "content": "good catch - though I fail to see why the question has to make the point about 4 subscriptions."
      },
      {
        "date": "2023-04-24T05:20:00.000Z",
        "voteCount": 1,
        "content": "thanks"
      },
      {
        "date": "2023-09-03T13:23:00.000Z",
        "voteCount": 2,
        "content": "Automation runbook is correct answer"
      },
      {
        "date": "2022-10-24T04:15:00.000Z",
        "voteCount": 1,
        "content": "https://www.sqlshack.com/azure-sql-index-tables-using-azure-automation/"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "5"
  },
  {
    "topic": 5,
    "index": 16,
    "url": "https://www.examtopics.com/discussions/microsoft/view/28723-exam-dp-300-topic-5-question-16-discussion/",
    "body": "DRAG DROP -<br>You have SQL Server on an Azure virtual machine named SQL1.<br>SQL1 has an agent job to back up all databases.<br>You add a user named dbadmin1 as a SQL Server Agent operator.<br>You need to ensure that dbadmin1 receives an email alert if a job fails.<br>Which three actions should you perform in sequence? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.<br>Select and Place:<br><img src=\"/assets/media/exam-media/04275/0024800001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04275/0024900001.png\" class=\"in-exam-image\">",
    "answerDescription": "Step 1: Enable Database Mail -<br>Database Mail must be enabled.<br>Step 2: Enable the email settings for the SQL Server Agent.<br>To send a notification in response to an alert, you must first configure SQL Server Agent to send mail.<br>Step 3: Create a job notification<br>Example:<br>-- adds an e-mail notification for the specified alert (Test Alert)<br>-- This example assumes that Test Alert already exists<br>-- and that Fran\u05b3\u00a7ois Ajenstat is a valid operator name.<br>USE msdb ;<br><br>GO -<br><br>EXEC dbo.sp_add_notification -<br>@alert_name = N'Test Alert',<br>@operator_name = N'Fran\u05b3\u00a7ois Ajenstat',<br>@notification_method = 1 ;<br><br>GO -<br>Reference:<br>https://docs.microsoft.com/en-us/sql/ssms/agent/notify-an-operator-of-job-status https://docs.microsoft.com/en-us/sql/ssms/agent/assign-alerts-to-an-operator",
    "votes": [],
    "comments": [
      {
        "date": "2020-08-20T04:12:00.000Z",
        "voteCount": 42,
        "content": "C - D -B"
      },
      {
        "date": "2020-08-24T05:18:00.000Z",
        "voteCount": 20,
        "content": "the answer is C - D -B, to send an email for a failed job you need: 1) one operator , 2) database mail feature on,  3) sql job set to use the email profile created in 2) , and last a notification sending the email to the operator created in 1), by the way in the options there is no choice for one operator, so C - D - B."
      },
      {
        "date": "2021-02-10T06:14:00.000Z",
        "voteCount": 1,
        "content": "The question has it: \"You add a user named dbadmin1 as a SQL Server Agent operator.\""
      },
      {
        "date": "2021-04-08T17:48:00.000Z",
        "voteCount": 2,
        "content": "first database mail then sql agent, last the notification."
      },
      {
        "date": "2023-04-24T05:25:00.000Z",
        "voteCount": 1,
        "content": "Thanks"
      },
      {
        "date": "2021-03-18T19:25:00.000Z",
        "voteCount": 2,
        "content": "correct answer: enable database mail, enable mail setting for sQL agent, create noification"
      },
      {
        "date": "2021-03-03T12:27:00.000Z",
        "voteCount": 2,
        "content": "C,D,B....operator is already added, and alert is not required. \nenable database mail (basic requirement)\nSQL Server Agent configuration to use mail (basic requirement)\nCreate notification(basic requirement)"
      },
      {
        "date": "2021-01-25T23:45:00.000Z",
        "voteCount": 3,
        "content": "C. Enable Database Mail\nd. eNABLE THE EMAIL SETTINGS \nB. Create a job notification"
      },
      {
        "date": "2021-01-10T23:34:00.000Z",
        "voteCount": 9,
        "content": "1 Enable mail\n2 Enable mail setting in SQL Agent\n3 Enable mail in notification tab in a job"
      },
      {
        "date": "2021-01-07T08:39:00.000Z",
        "voteCount": 1,
        "content": "Wyxh is 100% correct for the stated reasons."
      },
      {
        "date": "2020-08-26T14:39:00.000Z",
        "voteCount": 1,
        "content": "which is correct answer?"
      },
      {
        "date": "2020-08-28T21:32:00.000Z",
        "voteCount": 12,
        "content": "CDB is the correct order."
      },
      {
        "date": "2020-08-16T07:00:00.000Z",
        "voteCount": 3,
        "content": "The answer is A, D, B\nSee https://solutioncenter.apexsql.com/how-to-set-up-email-notifications-for-backup-jobs-in-sql-server/"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "5"
  },
  {
    "topic": 5,
    "index": 17,
    "url": "https://www.examtopics.com/discussions/microsoft/view/46064-exam-dp-300-topic-5-question-17-discussion/",
    "body": "DRAG DROP -<br>You need to apply 20 built-in Azure Policy definitions to all new and existing Azure SQL Database deployments in an Azure subscription. The solution must minimize administrative effort.<br>Which three actions should you perform in sequence? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.<br>Select and Place:<br><img src=\"/assets/media/exam-media/04275/0025000001.jpg\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04275/0025100001.jpg\" class=\"in-exam-image\">",
    "answerDescription": "Step 1: Create an Azure Policy Initiative<br>The first step in enforcing compliance with Azure Policy is to assign a policy definition. A policy definition defines under what condition a policy is enforced and what effect to take.<br>With an initiative definition, you can group several policy definitions to achieve one overarching goal. An initiative evaluates resources within scope of the assignment for compliance to the included policies.<br>Step 2: Create an Azure Policy Initiative assignment<br>Assign the initiative definition you created in the previous step.<br>Step 3: Run Azure Policy remediation tasks<br>To apply the Policy Initiative to the existing SQL databases.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/governance/policy/tutorials/create-and-manage",
    "votes": [],
    "comments": [
      {
        "date": "2024-01-13T10:44:00.000Z",
        "voteCount": 1,
        "content": "correct"
      },
      {
        "date": "2021-03-07T18:39:00.000Z",
        "voteCount": 4,
        "content": "correct."
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "5"
  },
  {
    "topic": 5,
    "index": 18,
    "url": "https://www.examtopics.com/discussions/microsoft/view/39365-exam-dp-300-topic-5-question-18-discussion/",
    "body": "You have an Azure SQL Database managed instance named SQLMI1. A Microsoft SQL Server Agent job runs on SQLMI1.<br>You need to ensure that an automatic email notification is sent once the job completes.<br>What should you include in the solution?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tFrom SQL Server Configuration Manager (SSCM), enable SQL Server Agent",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tFrom SQL Server Management Studio (SSMS), run sp_set_sqlagent_properties",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tFrom SQL Server Management Studio (SSMS), create a Database Mail profile\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tFrom the Azure portal, create an Azure Monitor action group that has an Email/SMS/Push/Voice action"
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 5,
        "isMostVoted": true
      },
      {
        "answer": "D",
        "count": 3,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2020-12-28T18:25:00.000Z",
        "voteCount": 13,
        "content": "Answer is correct. You have to create Database Mail Profile. Luke97 is referring to the profile name. -- Create a Database Mail profile \nEXECUTE msdb.dbo.sysmail_add_profile_sp \n@profile_name = 'AzureManagedInstance_dbmail_profile', \n@description = '...' ; \nReference - https://techcommunity.microsoft.com/t5/azure-sql/sending-emails-in-azure-sql-managed-instance/ba-p/386235"
      },
      {
        "date": "2020-12-09T03:22:00.000Z",
        "voteCount": 7,
        "content": "If you want to send e-mail using SQL Agent jobs, there should be a profile that must be called 'AzureManagedInstance_dbmail_profile'. Otherwise, Managed Instance will be unable to send emails via SQL Agent."
      },
      {
        "date": "2020-12-28T20:39:00.000Z",
        "voteCount": 3,
        "content": "Reference: https://techcommunity.microsoft.com/t5/azure-sql/sending-emails-in-azure-sql-managed-instance/ba-p/386235\n\n\"The important thing is that you can use any name for the DbMail profile (and you can have several db Mail profiles) for Db Mail procedures. However, if you want to send e-mail using SQL Agent jobs, there should be a profile that must be called 'AzureManagedInstance_dbmail_profile'. Otherwise, Managed Instance will be unable to send emails via SQL Agent. If you are using one  profile in your instance and you want to use it both for classic emails and SQL Agent, rename the profile to 'AzureManagedInstance_dbmail_profile' so it can be used on both places.\""
      },
      {
        "date": "2024-04-20T02:12:00.000Z",
        "voteCount": 2,
        "content": "C is the correct answer. Managed Instance need  a profile named 'AzureManagedInstance_dbmail_profile'"
      },
      {
        "date": "2024-02-27T22:16:00.000Z",
        "voteCount": 2,
        "content": "Answer C. From SQL Server Management Studio (SSMS), create a Database Mail profile"
      },
      {
        "date": "2023-09-14T17:46:00.000Z",
        "voteCount": 1,
        "content": "Should be D\n\nMicrosoft article below explains how to create an action group through the Azure portal.\n\nhttps://learn.microsoft.com/en-us/azure/azure-sql/managed-instance/alerts-create?view=azuresql"
      },
      {
        "date": "2023-07-22T17:58:00.000Z",
        "voteCount": 3,
        "content": "C is correct"
      },
      {
        "date": "2023-07-01T07:24:00.000Z",
        "voteCount": 3,
        "content": "C, creating a Database Mail profile, is also not applicable to Azure SQL Database Managed Instance. Database Mail is not supported in Azure SQL Database Managed Instance, so you cannot use it to send email notifications."
      },
      {
        "date": "2024-01-16T01:06:00.000Z",
        "voteCount": 2,
        "content": "This is wrong\nPlease refer to https://learn.microsoft.com/en-us/azure/azure-sql/managed-instance/job-automation-managed-instance?view=azuresql"
      },
      {
        "date": "2022-01-21T13:29:00.000Z",
        "voteCount": 3,
        "content": "Answer  is correct"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "5"
  },
  {
    "topic": 5,
    "index": 19,
    "url": "https://www.examtopics.com/discussions/microsoft/view/65800-exam-dp-300-topic-5-question-19-discussion/",
    "body": "You need to trigger an Azure Data Factory pipeline when a file arrives in an Azure Data Lake Storage Gen2 container.<br>Which resource provider should you enable?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tMicrosoft.EventHub",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tMicrosoft.EventGrid\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tMicrosoft.Sql",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tMicrosoft.Automation"
    ],
    "answer": "B",
    "answerDescription": "Event-driven architecture (EDA) is a common data integration pattern that involves production, detection, consumption, and reaction to events. Data integration scenarios often require Data Factory customers to trigger pipelines based on events happening in storage account, such as the arrival or deletion of a file in Azure<br>Blob Storage account. Data Factory natively integrates with Azure Event Grid, which lets you trigger pipelines on such events.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/data-factory/how-to-create-event-trigger",
    "votes": [
      {
        "answer": "B",
        "count": 1,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2022-09-18T09:53:00.000Z",
        "voteCount": 7,
        "content": "This question is for DP-203 exam (Data Engineering on Microsoft Azure)."
      },
      {
        "date": "2022-04-30T18:24:00.000Z",
        "voteCount": 1,
        "content": "Data Factory natively integrates with Azure Event Grid, which lets you trigger pipelines on such events."
      },
      {
        "date": "2022-04-01T06:53:00.000Z",
        "voteCount": 4,
        "content": "DP-203"
      },
      {
        "date": "2021-11-10T11:54:00.000Z",
        "voteCount": 1,
        "content": "looks correct"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "5"
  },
  {
    "topic": 5,
    "index": 20,
    "url": "https://www.examtopics.com/discussions/microsoft/view/105556-exam-dp-300-topic-5-question-20-discussion/",
    "body": "You deploy an instance of SQL Server on Azure Virtual Machines named VM1.<br><br>You need to create a SQL Server Agent job that will rebuild indexes of the databases hosted on VM1. The solution must use the principle of least privilege.<br><br>What should you create first?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ta local Windows account",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ta user-assigned managed identity in Azure AD",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ta system-assigned managed identity in Azure AD\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tan Elastic Job agent"
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 2,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-09-10T16:58:00.000Z",
        "voteCount": 1,
        "content": "least privilege it's a user-asigned"
      },
      {
        "date": "2024-07-13T08:31:00.000Z",
        "voteCount": 1,
        "content": "See Dalamain\u2019s comment and article.  I choose C"
      },
      {
        "date": "2024-04-16T09:11:00.000Z",
        "voteCount": 1,
        "content": "Some info here: https://learn.microsoft.com/en-us/entra/identity/managed-identities-azure-resources/overview#managed-identity-types"
      },
      {
        "date": "2024-01-01T08:12:00.000Z",
        "voteCount": 3,
        "content": "A. local Windows account\nThe question does not say if tenant has Azure AD or is joined to domain, and also I don't see how SQL Agent needs system-assigned or user-assigned managed identity to run jobs on SQL Server ?\nI can see how local windows account is needed for SQL Agent service to run"
      },
      {
        "date": "2024-08-20T06:05:00.000Z",
        "voteCount": 1,
        "content": "Agree. As the target is just resources on the VM itself (analogy of on-prem), there should be no need to involve Azure managed identities which are meant to be used to access Azure resources. You can grant the local account its privileges for the intended purpose only."
      },
      {
        "date": "2023-10-31T23:36:00.000Z",
        "voteCount": 1,
        "content": "C. Create a system-assigned managed identity in Azure AD.\nA system-assigned managed identity enables an Azure resource to identify itself to Azure AD. It can be used to access Azure resources and services without typically storing usernames and passwords in the code."
      },
      {
        "date": "2023-09-14T17:50:00.000Z",
        "voteCount": 2,
        "content": "Careful guys,\n\nWhile a user-assigned identity is convenient as far as being able to assign it to multiple resources, this questions specifically refers to a SINGLE sql server on a SINGLE virtual machine. If this question was asking about how to rebuild indexes on multiple sql vm servers, then yes it would be better to leverage a user-assigned identity. \n\nMy answer is C."
      },
      {
        "date": "2023-08-29T02:52:00.000Z",
        "voteCount": 1,
        "content": "should be user assigned managed identity.\n\"User-assigned managed identities are more efficient in a broader range of scenarios than system-assigned managed identities. See the table below for some scenarios and the recommendations for user-assigned or system-assigned.\n\nUser-assigned identities can be used by multiple resources, and their life cycles are decoupled from the resources\u2019 life cycles with which they\u2019re associated. Read which resources support managed identities.\"\nhttps://learn.microsoft.com/en-us/azure/active-directory/managed-identities-azure-resources/managed-identity-best-practice-recommendations"
      },
      {
        "date": "2023-08-12T16:32:00.000Z",
        "voteCount": 1,
        "content": "I think it should be user-assigned managed identity."
      },
      {
        "date": "2023-04-07T17:37:00.000Z",
        "voteCount": 4,
        "content": "The answer is correct.\n\nC. a system-assigned managed identity in Azure AD should be created first to implement the principle of least privilege when creating a SQL Server Agent job that will rebuild indexes of the databases hosted on VM1.\n\nWith a system-assigned managed identity, Azure automatically creates an identity in Azure AD that is tied to the Azure VM instance. This allows you to grant the identity permissions to the specific resources that it requires, without having to manage credentials or rotate passwords.\n\nUsing a managed identity ensures that only the necessary permissions are granted to the job, which is in line with the principle of least privilege. The job can then use this managed identity to perform the required actions, such as rebuilding indexes."
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "5"
  },
  {
    "topic": 5,
    "index": 21,
    "url": "https://www.examtopics.com/discussions/microsoft/view/97202-exam-dp-300-topic-5-question-21-discussion/",
    "body": "HOTSPOT<br> -<br><br>You need to deploy an Azure SQL Database elastic pool by using a Bicep template.<br><br>How should you complete the template? To answer, select the appropriate options in the answer area.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/dp-300/image249.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/dp-300/image250.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2023-01-29T23:42:00.000Z",
        "voteCount": 8,
        "content": "Server\nminCapacity\n\nhttps://learn.microsoft.com/en-us/azure/templates/microsoft.sql/servers/databases?pivots=deployment-language-bicep"
      },
      {
        "date": "2024-06-29T09:20:00.000Z",
        "voteCount": 1,
        "content": "Servers and Min Capacity"
      },
      {
        "date": "2023-07-15T15:31:00.000Z",
        "voteCount": 3,
        "content": "https://learn.microsoft.com/en-us/azure/templates/microsoft.sql/servers/elasticpools?pivots=deployment-language-bicep\nminCapacity\tMinimal capacity that serverless pool will not shrink below, if not paused"
      },
      {
        "date": "2023-02-22T23:32:00.000Z",
        "voteCount": 3,
        "content": "correct"
      },
      {
        "date": "2023-01-29T23:39:00.000Z",
        "voteCount": 2,
        "content": "Declare the resource type for the elastic pool in the template, which should be Microsoft.Sql/servers/elasticPools."
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "5"
  },
  {
    "topic": 5,
    "index": 22,
    "url": "https://www.examtopics.com/discussions/microsoft/view/107578-exam-dp-300-topic-5-question-22-discussion/",
    "body": "You have an Azure AD tenant and a logical Microsoft SQL server named SQL1 that hosts several Azure SQL databases.<br><br>You plan to assign Azure AD users permissions to the databases automatically by using Azure Automation.<br><br>You need to create the required Automation accounts.<br><br>Which two accounts should you create? Each correct answer presents part of the solution.<br><br>NOTE: Each correct selection is worth one point.",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tFrom the Azure Active Directory admin center create a service principal.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tFrom the Azure Active Directory admin center, create a user-assigned managed identity for SQL1.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tOn SQL1, create a SQL user in the databases.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tOn SQL1, create a SQL login.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tFrom the Azure Active Directory admin center, create an external identity."
    ],
    "answer": "AC",
    "answerDescription": "",
    "votes": [
      {
        "answer": "AC",
        "count": 4,
        "isMostVoted": true
      },
      {
        "answer": "BC",
        "count": 3,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2024-10-11T17:47:00.000Z",
        "voteCount": 1,
        "content": "\u2018 You can now configure Automation accounts to use a managed identity, which is the default option when you create an Automation account. With this feature, an Automation account can authenticate to Azure resources without the need to exchange any credentials. A managed identity removes the overhead of renewing the certificate or managing the service principal.\u2019\nhttps://learn.microsoft.com/en-us/azure/automation/migrate-run-as-accounts-managed-identity?tabs=sa-managed-identity"
      },
      {
        "date": "2024-05-27T19:38:00.000Z",
        "voteCount": 2,
        "content": "See guide here that talks about a user-assigned managed entity. There is no mention about service principal. So B and C should be correct. \nhttps://learn.microsoft.com/en-us/azure/automation/quickstarts/create-azure-automation-account-portal"
      },
      {
        "date": "2024-06-04T11:52:00.000Z",
        "voteCount": 1,
        "content": "Thank you"
      },
      {
        "date": "2023-04-26T06:11:00.000Z",
        "voteCount": 4,
        "content": "Seems correct\nhttps://learn.microsoft.com/en-us/azure/azure-sql/database/authentication-aad-service-principal-tutorial?view=azuresql"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "5"
  },
  {
    "topic": 5,
    "index": 23,
    "url": "https://www.examtopics.com/discussions/microsoft/view/97203-exam-dp-300-topic-5-question-23-discussion/",
    "body": "You have an Azure subscription.<br><br>You plan to deploy an instance of SQL Server on Azure Virtual Machines by using an Azure Marketplace image.<br><br>You need to register the SQL Server IaaS Agent extension (SqlIaasExtension). The solution must meet the following requirements:<br><br>\u2022\tInstall critical updates for SQL Server automatically.<br>\u2022\tMinimize performance impact on the virtual machine.<br><br>Which management mode should you select?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tfull\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tlightweight",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tNoAgent"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 3,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-02-22T23:29:00.000Z",
        "voteCount": 6,
        "content": "B. lightweight"
      },
      {
        "date": "2023-08-21T04:20:00.000Z",
        "voteCount": 5,
        "content": "It seems that this question is now obsolete. Since April 2023 there are no management  modes for the agent. \n\n\"Going forward, customers register with the SQL IaaS Agent extension and enable the required features they would like for their SQL Server on Azure virtual machines. Based on the features selected, the SQL IaaS agent extension would assume only the permissions required on the SQL Server to enable those features. \" Source: https://techcommunity.microsoft.com/t5/sql-server-blog/announcement-new-features-and-changes-to-sql-iaas-agent/ba-p/3791548"
      },
      {
        "date": "2023-07-10T15:07:00.000Z",
        "voteCount": 1,
        "content": "Answer is correct. \nLightweight mode: in this mode, the extension binary files are copied to the virtual machine, but no agent is installed and the SQL Server service running on the VM is not restarted. By adopting this mode, you can only change the type of license and the edition of SQL Server, in addition to having a limited set of management options. This is the default management mode when using the automatic registration feature which can be activated from the Azure portal or through manual registration."
      },
      {
        "date": "2023-04-14T00:00:00.000Z",
        "voteCount": 3,
        "content": "https://youtu.be/ckSvoe6Ho3g"
      },
      {
        "date": "2023-04-26T06:32:00.000Z",
        "voteCount": 3,
        "content": "God Saves King Savill in our path through the Azure desert."
      },
      {
        "date": "2023-01-29T23:46:00.000Z",
        "voteCount": 4,
        "content": "Lightweight mode is recommended for the SQL Server IaaS Agent extension (SqlIaasExtension) in order to meet the requirements of automatically installing critical updates for SQL Server and minimizing performance impact on the virtual machine."
      },
      {
        "date": "2023-01-29T23:44:00.000Z",
        "voteCount": 2,
        "content": "Looks correct. \n\"Full mode installs the SQL IaaS Agent to the VM to deliver full functionality. Use it for managing a SQL Server VM with a single instance. Full mode installs two Windows services that have a minimal impact to memory and CPU\"\nhttps://learn.microsoft.com/en-us/azure/azure-sql/virtual-machines/windows/sql-server-iaas-agent-extension-automate-management?view=azuresql&amp;tabs=azure-powershell#management-modes"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "5"
  },
  {
    "topic": 5,
    "index": 24,
    "url": "https://www.examtopics.com/discussions/microsoft/view/115303-exam-dp-300-topic-5-question-24-discussion/",
    "body": "You have an Azure subscription that contains 20 Azure SQL databases.<br><br>You create a Transact-SQL statement to perform index maintenance on a database.<br>You need to schedule the statement to run once daily against each database by using Transact-SQL commands.<br><br>What should you use to schedule the statement?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tan Azure function",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ta SQL Server Agent Job",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tan elastic job\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure Automation"
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 5,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-04-20T02:31:00.000Z",
        "voteCount": 1,
        "content": "The correct answer is C. Elastic Job allow to execute only T-SQL command scheduled for a set of target databases"
      },
      {
        "date": "2023-11-11T06:50:00.000Z",
        "voteCount": 1,
        "content": "C. Elastic jobs\nhttps://learn.microsoft.com/en-us/azure/azure-sql/database/elastic-jobs-overview?view=azuresql"
      },
      {
        "date": "2023-11-11T06:52:00.000Z",
        "voteCount": 1,
        "content": "At this moment this feature is in preview and free"
      },
      {
        "date": "2023-10-31T23:48:00.000Z",
        "voteCount": 1,
        "content": "The correct answer is (B).\nAn SQL Server Agent job is the best option for these requirements. With an SQL Server Agent job, you can execute Transact-SQL statements regularly.\nAn Azure Function is a good option if you want to create a custom solution. However, creating and managing an Azure Function can be more complex than an SQL Server Agent job.\nAn Elastic Job is a good option if you need a solution for multiple Azure resources. However, creating and managing an Elastic Job can be more complex than an SQL Server Agent job.\nAzure Automation is a good option if you want to create a custom solution. However, creating and managing Azure Automation can be more complex than an SQL Server Agent job."
      },
      {
        "date": "2023-11-04T07:29:00.000Z",
        "voteCount": 7,
        "content": "An Azure SQL database has no associated SQL Agent, so this can't be correct"
      },
      {
        "date": "2023-08-25T03:17:00.000Z",
        "voteCount": 3,
        "content": "the sad part is both Elastic Job and Azure Automation are valid responses (both can run T-SQL commands). I will go with Elastic Job for the sole reason that is free (as of 2023) and Azure Automation seems overkill for the task at hand - not only that, but it seems that it cannot reindex multiple DBs at once, for example.\nProof that Azure Automation can also run reindex jobs: https://learn.microsoft.com/en-us/azure/automation/overview: \"Common scenarios\nAzure Automation supports management throughout the lifecycle of your infrastructure and applications. Common scenarios include: Periodic maintenance - to execute tasks that need to be performed at set timed intervals like purging stale or old data, or reindex a SQL database\""
      },
      {
        "date": "2023-08-15T07:58:00.000Z",
        "voteCount": 2,
        "content": "On Azure SQL Database elastic jobs is a replacement for SQL Server Agent. Elastic Jobs can do TSQL scheduled jobs.\nhttps://learn.microsoft.com/en-us/azure/azure-sql/database/job-automation-overview?view=azuresql"
      },
      {
        "date": "2023-07-30T21:43:00.000Z",
        "voteCount": 1,
        "content": "Answer is C"
      },
      {
        "date": "2023-07-15T15:45:00.000Z",
        "voteCount": 2,
        "content": "Azure Automation uses PowerShell.\nWith Azure Automation, you can manage databases in Azure SQL Database by using the latest Az PowerShell cmdlets that are available in Azure Az PowerShell. \nElastic jobs would use T-SQL. https://learn.microsoft.com/en-us/azure/azure-sql/database/elastic-jobs-tsql-create-manage?view=azuresql-db"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "5"
  },
  {
    "topic": 5,
    "index": 25,
    "url": "https://www.examtopics.com/discussions/microsoft/view/115304-exam-dp-300-topic-5-question-25-discussion/",
    "body": "HOTSPOT<br> -<br><br>You have an Azure subscription.<br><br>You need to deploy a logical SQL server by using an Azure Resource Manager (ARM) template. The solution must ensure that the server will allow inbound connectivity from any Azure resource.<br><br>How should you complete the template? To answer, select the appropriate options in the answer area.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/dp-300/image289.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/dp-300/image290.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-04-26T12:21:00.000Z",
        "voteCount": 1,
        "content": "Correct, 0.0.0.0 for both startipaddress and endipaddress"
      },
      {
        "date": "2023-07-15T15:47:00.000Z",
        "voteCount": 3,
        "content": "https://learn.microsoft.com/en-us/azure/templates/microsoft.sql/servers/firewallrules?pivots=deployment-language-bicep\nstartIpAddress\tThe start IP address of the firewall rule. Must be IPv4 format. Use value '0.0.0.0' for all Azure-internal IP addresses."
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "5"
  },
  {
    "topic": 5,
    "index": 26,
    "url": "https://www.examtopics.com/discussions/microsoft/view/132136-exam-dp-300-topic-5-question-26-discussion/",
    "body": "HOTSPOT<br> -<br><br>You have an instance of SQL Server on Azure Virtual Machines named VM1.<br><br>You need to use an Azure Automation runbook to initiate a SQL Server database backup on VM1.<br><br>How should you complete the command? To answer, select the appropriate options in the answer area.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/dp-300/image295.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/dp-300/image296.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-04-26T12:24:00.000Z",
        "voteCount": 1,
        "content": "Correct. https://learn.microsoft.com/en-us/powershell/module/az.automation/start-azautomationrunbook?view=azps-11.5.0"
      },
      {
        "date": "2024-01-25T07:12:00.000Z",
        "voteCount": 1,
        "content": "that is correct"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "5"
  },
  {
    "topic": 5,
    "index": 27,
    "url": "https://www.examtopics.com/discussions/microsoft/view/139672-exam-dp-300-topic-5-question-27-discussion/",
    "body": "You manage 100 Azure SQL managed instances located across 10 Azure regions.<br><br>You need to receive voice message notifications when a maintenance event affects any of the 10 regions. The solution must minimize administrative effort.<br><br>What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tFrom the Azure portal, create a service health alert.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tFrom the Azure portal, create an Azure Advisor operational excellence alert.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tFrom the Azure portal, configure an activity log alert.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tFrom Microsoft SQL Server Management Studio (SSMS), configure a SQL Server agent job."
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 2,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-04-26T12:28:00.000Z",
        "voteCount": 2,
        "content": "Service Health is correct. https://www.mssqltips.com/sqlservertip/5751/configure-service-health-alerts-using-azure-service-health-part-2/"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "5"
  },
  {
    "topic": 5,
    "index": 28,
    "url": "https://www.examtopics.com/discussions/microsoft/view/141409-exam-dp-300-topic-5-question-28-discussion/",
    "body": "HOTSPOT<br> -<br><br>You plan to deploy three instances of SQL Server on Azure Virtual Machines that will each contain 20 databases.<br><br>You need to recommend a solution that meets the following requirements:<br><br>\u2022\tEnsures that the deployment is highly available<br>\u2022\tMinimizes administrative effort to manage users, logins, permissions, and SQL Server Agent jobs across the instances<br><br>What should you include in the recommendation? To answer, select the appropriate options in the answer area.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/dp-300/image322.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/dp-300/image323.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-10-11T18:04:00.000Z",
        "voteCount": 1,
        "content": "Contained\n2022\n\nhttps://learn.microsoft.com/en-us/sql/database-engine/availability-groups/windows/contained-availability-groups-overview?view=sql-server-ver16"
      },
      {
        "date": "2024-10-11T18:06:00.000Z",
        "voteCount": 1,
        "content": "As Vitos25 already mentioned."
      },
      {
        "date": "2024-09-11T15:20:00.000Z",
        "voteCount": 1,
        "content": "Seems like answer is wrong \nIt should be contained 2022"
      },
      {
        "date": "2024-09-11T15:22:00.000Z",
        "voteCount": 2,
        "content": "Here is the source \nhttps://learn.microsoft.com/en-us/sql/database-engine/availability-groups/windows/contained-availability-groups-overview?view=sql-server-ver16"
      },
      {
        "date": "2024-05-27T20:44:00.000Z",
        "voteCount": 4,
        "content": "The minimum SQL version for SQL on Azure VM is 2016 that supports Availability Groups. There for the answer should be \"Always On\" and \"2017\""
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "5"
  },
  {
    "topic": 5,
    "index": 29,
    "url": "https://www.examtopics.com/discussions/microsoft/view/139690-exam-dp-300-topic-5-question-29-discussion/",
    "body": "You have two Azure virtual machines named Server1 and Server2 that run Windows Server 2022 and are joined to an Active Directory Domain Services (AD DS) domain named contoso.com.<br><br>Both virtual machines have a default instance of Microsoft SQL Server 2019 installed. Server1 is configured as a master server, and Server2 is configured as a target server.<br><br>On Server1, you create a proxy account named contoso\\sqlproxy.<br><br>You need to ensure that the SQL Server Agent job steps can be downloaded from Server1 and run on Server2.<br><br>Which two actions should you perform? Each correct answer presents part of the solution.<br><br>NOTE: Each correct selection is worth one point.",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tOn Server2, grant the contoso\\sqlproxy account the Impersonate a client after authentication user right.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tOn Server2, grant the contoso\\sqlproxy account the Access this computer from the network user right.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tOn Server2, create a proxy account.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tOn Server1, set the AllowDownloadedJobsToMatchProxyName registry entry to 1.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tOn Server2, set the AllowDownloadedJobsToMatchProxyName registry entry to 1."
    ],
    "answer": "CD",
    "answerDescription": "",
    "votes": [
      {
        "answer": "CD",
        "count": 6,
        "isMostVoted": true
      },
      {
        "answer": "DE",
        "count": 2,
        "isMostVoted": false
      },
      {
        "answer": "AE",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2024-08-11T11:28:00.000Z",
        "voteCount": 3,
        "content": "The answer is C and D.\nhttps://learn.microsoft.com/en-us/sql/ssms/agent/make-a-target-server?view=sql-server-ver16"
      },
      {
        "date": "2024-08-03T16:39:00.000Z",
        "voteCount": 2,
        "content": "C,E\nDistributed jobs that have steps which are associated with a proxy run under the context of the proxy account on the target server. Make sure that the following conditions are met or job steps that are associated with a proxy will not be downloaded from the master server to the target:\n\nThe master server registry subkey \\HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Microsoft SQL Server\\&lt;*instance_name*&gt;\\SQL Server Agent\\AllowDownloadedJobsToMatchProxyName (REG_DWORD) is set to 1 (true). By default, this subkey is set to 0 (false).\n\nA proxy account exists on the target server that has the same name as the master server proxy account under which the job step runs."
      },
      {
        "date": "2024-06-22T12:49:00.000Z",
        "voteCount": 2,
        "content": "D. On Server1, set the AllowDownloadedJobsToMatchProxyName registry entry to 1.\n\nThis registry entry allows SQL Server Agent jobs on Server1 to use the proxy account name (contoso\\sqlproxy) when executing on Server2. This is essential for ensuring that the job steps are executed with the appropriate permissions on Server2.\nE. On Server2, set the AllowDownloadedJobsToMatchProxyName registry entry to 1.\n\nSimilarly, on Server2, setting this registry entry ensures that the downloaded job steps from Server1 can be executed using the proxy account (contoso\\sqlproxy). This step ensures compatibility and security when job steps are executed on the target server (Server2).\nTherefore, the correct actions to perform are D and E:\n\nD. On Server1, set the AllowDownloadedJobsToMatchProxyName registry entry to 1.\nE. On Server2, set the AllowDownloadedJobsToMatchProxyName registry entry to 1.\nThese actions ensure that the SQL Server Agent jobs from Server1 can be downloaded and executed on Server2 using the specified proxy account, contoso\\sqlproxy, while maintaining security and compatibility between the servers."
      },
      {
        "date": "2024-05-27T20:58:00.000Z",
        "voteCount": 3,
        "content": "ChatGPT suggests C and D:\n\nTherefore, the correct answers are:\n\nC. On Server2, create a proxy account.\nD. On Server1, set the AllowDownloadedJobsToMatchProxyName registry entry to 112.\nThese actions will ensure successful execution of SQL Server Agent job steps between Server1 and Server2."
      },
      {
        "date": "2024-04-27T04:50:00.000Z",
        "voteCount": 1,
        "content": "I think it's A,E"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "5"
  },
  {
    "topic": 5,
    "index": 30,
    "url": "https://www.examtopics.com/discussions/microsoft/view/139674-exam-dp-300-topic-5-question-30-discussion/",
    "body": "You have an Azure subscription. The subscription contains an instance of SQL Server on Azure Virtual Machines named SQL1 and an Azure Automation account named account1.<br><br>You need to configure account1 to restart the SQL Server Agent service if the service stops.<br><br>Which setting should you configure?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tStart/Stop VM",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tChange tracking",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUpdate management",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tState configuration (DSC)\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 1,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-04-26T12:45:00.000Z",
        "voteCount": 1,
        "content": "Use DSC to restart services."
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "5"
  },
  {
    "topic": 5,
    "index": 31,
    "url": "https://www.examtopics.com/discussions/microsoft/view/149406-exam-dp-300-topic-5-question-33-discussion/",
    "body": "You have 25 Azure SQL databases.<br><br>You need to implement a centralized database management solution that uses Transact-SQL.<br><br>What should you include in the solution?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\telastic jobs",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tan Azure Automation runbook",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure Functions",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure Logic Apps"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-10-14T07:40:00.000Z",
        "voteCount": 1,
        "content": "A - elastic jobs - Elastic jobs are designed specifically for managing multiple Azure SQL databases using Transact-SQL in a centralized manner. They allow you to automate and schedule tasks like index maintenance, statistics updates, or query executions across multiple databases, which is exactly what is required in this scenario.\n\nElastic jobs can target multiple databases in an Azure SQL Database environment, which makes them ideal for managing the 25 Azure SQL databases centrally"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "5"
  }
]