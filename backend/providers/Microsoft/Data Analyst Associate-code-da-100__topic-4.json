[
  {
    "topic": 4,
    "index": 1,
    "url": "https://www.examtopics.com/discussions/microsoft/view/33580-exam-da-100-topic-4-question-1-discussion/",
    "body": "DRAG DROP -<br>You have the line chart shown in the exhibit. (Click the Exhibit tab.)<br><img src=\"/assets/media/exam-media/04207/0013200001.png\" class=\"in-exam-image\"><br>You need to modify the chart to meet the following requirements:<br>\u2711 Identify months that have order counts above the mean.<br>\u2711 Display the mean monthly order count.<br>Which three actions should you perform in sequence? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.<br>Select and Place:<br><img src=\"/assets/media/exam-media/04207/0013300001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04207/0013300002.png\" class=\"in-exam-image\">",
    "answerDescription": "Step 1: Create a 12-month...<br>You can use calculated measure to get the expected result.<br>1. Create a calculated column for the date.<br>2. Create a measure for 12 months moving average.<br>3. Drag the Line Chart into your canvas as below. (step 2 below)<br><img src=\"/assets/media/exam-media/04207/0013400001.jpg\" class=\"in-exam-image\"><br><br>Step 2: Select the line chart -<br>Step 3: From the Analytics pane, add a Median line<br>Reference:<br>https://community.powerbi.com/t5/Desktop/Moving-Average/td-p/43041",
    "votes": [],
    "comments": [
      {
        "date": "2020-10-06T13:17:00.000Z",
        "voteCount": 342,
        "content": "My Ans:-\n1. Select the line chart\n2. Add the average line\n3. Turn on Data Label"
      },
      {
        "date": "2021-07-09T21:14:00.000Z",
        "voteCount": 7,
        "content": "9 months later, this still holds true\n\n(tested it locally)"
      },
      {
        "date": "2020-11-15T08:25:00.000Z",
        "voteCount": 15,
        "content": "Mean = Average. Mean is NOT Median ;)"
      },
      {
        "date": "2021-05-01T12:03:00.000Z",
        "voteCount": 1,
        "content": "correct"
      },
      {
        "date": "2021-10-13T02:46:00.000Z",
        "voteCount": 1,
        "content": "Does the aggregation has anything to do with this? Doing the average line over that line wouldn't take the daily average and not the monthly? I assume doing the 12 moths rolling means you take the monthly value as source for the new monthly average line. Or is it the same?"
      },
      {
        "date": "2020-10-04T03:02:00.000Z",
        "voteCount": 35,
        "content": "My Ans:-\n1. Select the line chart\n2. Add the Median line\n3. Turn on Data Label ( Display the mean monthly order count)"
      },
      {
        "date": "2020-12-11T11:50:00.000Z",
        "voteCount": 37,
        "content": "Be careful, Median is not the mean/average"
      },
      {
        "date": "2021-05-01T08:05:00.000Z",
        "voteCount": 4,
        "content": "Median not mean"
      },
      {
        "date": "2021-07-09T18:21:00.000Z",
        "voteCount": 16,
        "content": "how is this highly voted"
      },
      {
        "date": "2021-12-07T00:38:00.000Z",
        "voteCount": 3,
        "content": "median not equal to mean"
      },
      {
        "date": "2022-08-14T23:54:00.000Z",
        "voteCount": 1,
        "content": "WHY select Line Chart its already line chart. Add average line for 1st requirement. 12month roll avg and add labels for new line for 2nd requirement. THATS IT! khaby lame style."
      },
      {
        "date": "2022-08-04T22:19:00.000Z",
        "voteCount": 1,
        "content": "1. Select the line chart\n2. Add average line\n3. Turn on Data labels"
      },
      {
        "date": "2022-07-28T06:34:00.000Z",
        "voteCount": 3,
        "content": "yes confirm\n1. Select the line chart\n2. Add the average line\n3. Turn on Data Label"
      },
      {
        "date": "2022-06-09T17:40:00.000Z",
        "voteCount": 3,
        "content": "The right order of answere would be:\n1.Create 12 month moving average\n2.Turn on the data lable for new line.\n3. From the analytics pane ,add an average line."
      },
      {
        "date": "2022-05-28T03:11:00.000Z",
        "voteCount": 2,
        "content": "Create a measure for 12 months moving average.\nSelect the line chart \n From the Analytics pane, add a Median line"
      },
      {
        "date": "2021-12-29T13:55:00.000Z",
        "voteCount": 1,
        "content": "In exam 30/12/21"
      },
      {
        "date": "2021-12-07T07:10:00.000Z",
        "voteCount": 1,
        "content": "What\u2019s the correct answer?"
      },
      {
        "date": "2021-12-06T04:25:00.000Z",
        "voteCount": 1,
        "content": "A measure will give a single value? \nI think there is typo it should have been turn on data labels for the line (not the new line)"
      },
      {
        "date": "2021-11-22T21:34:00.000Z",
        "voteCount": 2,
        "content": "My Ans:-\n1. Select the line chart\n2. Add the average line\n3. Turn on Data Label"
      },
      {
        "date": "2021-07-26T13:12:00.000Z",
        "voteCount": 9,
        "content": "Correct Ans is Create 12 month rolling avg, select line chart, display data labels. There is one important point that we forget here, the question asks to display monthly across every month on the line chart. Adding a average line will just display average line data label and not monthly, so that option wont work."
      },
      {
        "date": "2021-07-15T05:47:00.000Z",
        "voteCount": 4,
        "content": "Requirement is \"Display Monthly Mean\" . Mean equals Average but Monthly Average does not equal Rolling Monthly Average."
      },
      {
        "date": "2021-07-05T07:10:00.000Z",
        "voteCount": 1,
        "content": "what does the \"Select the line chart\" even mean or do? Am I the only one who don't get the answer?"
      },
      {
        "date": "2021-08-24T07:01:00.000Z",
        "voteCount": 2,
        "content": "If you don\u00b4t select the Line Chart visual you do not have Analytics options available"
      },
      {
        "date": "2021-07-01T14:38:00.000Z",
        "voteCount": 1,
        "content": "So what is the answer if this comes in the exam? 1. Select 2. Average line 3. Data label?"
      },
      {
        "date": "2021-06-25T08:24:00.000Z",
        "voteCount": 1,
        "content": "When testing, if first creating and adding 12 months rolling average the chart is already selected, then add the average line and turn data labels on for the line. But if the option was given I'd add the data labels for the chart at first, then the avg line and data labels for it"
      },
      {
        "date": "2021-06-18T01:24:00.000Z",
        "voteCount": 1,
        "content": "select\ncreate\nturn on label one the new line"
      }
    ],
    "examNameCode": "da-100",
    "topicNumber": "4"
  },
  {
    "topic": 4,
    "index": 2,
    "url": "https://www.examtopics.com/discussions/microsoft/view/33440-exam-da-100-topic-4-question-2-discussion/",
    "body": "DRAG DROP -<br>You have a query named Customer that imports CSV files from a data lake. The query contains 50,000 rows as shown in the exhibit. (Click the Exhibit tab.)<br><img src=\"/assets/media/exam-media/04207/0013500001.jpg\" class=\"in-exam-image\"><br>Each file contains deltas of any new or modified rows from each load to the data lake. Multiple files can have the same customer ID.<br>You need to keep only the last modified row for each customer ID.<br>Which three actions should you perform in sequence? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.<br>Select and Place:<br><img src=\"/assets/media/exam-media/04207/0013600001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04207/0013700001.png\" class=\"in-exam-image\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2020-10-04T02:47:00.000Z",
        "voteCount": 252,
        "content": "I think:-\n1. Duplicate the query\n2. Group the query to find the max modified date\n3. Merge the query on inner join"
      },
      {
        "date": "2021-04-22T12:03:00.000Z",
        "voteCount": 1,
        "content": "Be careful, cos Person X can have repeated modified date. So a inner join will remain the duplicate (wrongly)...\nThat\u2019s why the \u201cremove duplicated ID\u201d is present.\nIn other words, Inner join will return duplicate if the same customer ID have the same modified date 2 or more times"
      },
      {
        "date": "2022-03-20T10:49:00.000Z",
        "voteCount": 2,
        "content": "No, modified date is datetime format. using the max you will always get a unique customer id"
      },
      {
        "date": "2021-05-14T07:04:00.000Z",
        "voteCount": 16,
        "content": "if you group by ID you doesn't have duplicate id anymore"
      },
      {
        "date": "2022-11-03T15:35:00.000Z",
        "voteCount": 1,
        "content": "Maue is correct that duplicates of Customer + Modified Date would not work with the inner join. The Datetime format appears not to use the time part, so duplicates could exist theoretically and even Datetime when fully used would not guarantee uniqueness. However the name of the files in combination with different Modified Dates seems to be unique per file and also does not contain dates before the date of the name of the file, so suggests enough uniqueness. Even so, removing duplicates in the Customer ID column would not solve this. It would have to be removing duplicates in the combined Customer Id + Date Modified Date columns, which is not an option. My assumption here would be that the question does not expect this to occur.\nI would thus go with the answer given by VR1."
      },
      {
        "date": "2021-05-01T12:23:00.000Z",
        "voteCount": 4,
        "content": "correct"
      },
      {
        "date": "2022-03-13T11:49:00.000Z",
        "voteCount": 3,
        "content": "Explaination by Lhouss:-\n1) Duplicate Customer query\n2) Group by CustId by Max ModifiedDate (only 2 columns to keep)\n3) Merge two queries on CustId and ModifiedDate inner join (to retreive other customer informations related to latest Date)"
      },
      {
        "date": "2020-10-04T09:37:00.000Z",
        "voteCount": 55,
        "content": "I thin\nduplicate query\ngroup data on customer id and max date\nmerge two on inner join"
      },
      {
        "date": "2020-10-15T06:40:00.000Z",
        "voteCount": 6,
        "content": "Its correct"
      },
      {
        "date": "2022-08-04T22:38:00.000Z",
        "voteCount": 1,
        "content": "Answer:\n1. Duplicate\n2. Group max date\n3. Merge inner join"
      },
      {
        "date": "2022-03-17T08:32:00.000Z",
        "voteCount": 2,
        "content": "I got it on my exam 03/17/2022. 90-95% questions were from here. 61 questions in 100 min. All 3 case studies that appeared in exam, where from here."
      },
      {
        "date": "2022-05-21T22:39:00.000Z",
        "voteCount": 12,
        "content": "To every question you have replied the same"
      },
      {
        "date": "2021-12-10T08:05:00.000Z",
        "voteCount": 1,
        "content": "on exam 12/10/2021"
      },
      {
        "date": "2021-11-11T13:24:00.000Z",
        "voteCount": 4,
        "content": "on exam - Nov 11, 2021. \nmy answers:\nDuplicate the customer query\nGroup the CustomerGrouped\nMerge 2 query using a inner join"
      },
      {
        "date": "2021-10-14T07:17:00.000Z",
        "voteCount": 1,
        "content": "On exam 10/14/21"
      },
      {
        "date": "2021-09-01T19:39:00.000Z",
        "voteCount": 2,
        "content": "I think the answer should be\n1. Duplicate the query\n2. Filter the query on Modified date is latest\n3. Merge 2 queries on Customer ID and Modified date by inner join"
      },
      {
        "date": "2021-06-22T23:26:00.000Z",
        "voteCount": 2,
        "content": "Tested and confused what the correct answer to this \n \n1. Duplicate the Query\n2. Group the Query to find the max modified date \n3. Merge with inner Join\nHere is the best part when I expand the columns I start seeing duplicates \n4. Remove the duplicates ?"
      },
      {
        "date": "2021-06-14T02:21:00.000Z",
        "voteCount": 1,
        "content": "It says \"You need to keep only the last modified row for each customer ID.\"\nThe WHOLE row. If you 'group by' WITHOUT then performing an inner join merge, you are only left with 2 columns, but they require the whole row. Therefore you need to:\n1. Duplicate the Query\n2. Group the query by Customer ID, outputting max date\n3. THEN merge using inner join"
      },
      {
        "date": "2021-05-20T08:20:00.000Z",
        "voteCount": 2,
        "content": "I don't understand why people think you need any kind of join here. Because the question clearly states: \"You need to keep only the last modified row for each customer ID.\" \nPerforming an inner join or a left outer join will result in a table that will still have multiple rows per CustomerID. And the whole idea is that you only keep the last modified row for each CustomerID right?"
      },
      {
        "date": "2021-05-24T08:47:00.000Z",
        "voteCount": 3,
        "content": "An inner join achieves the goald of unique CustomerID rows with the latest modified rows, a left outer join leaves you with multiple rows per customerID."
      },
      {
        "date": "2021-05-10T13:22:00.000Z",
        "voteCount": 3,
        "content": "I have some doubts reading the others answer but my choice:\n1.- Duplicate Query\n2.- Group the query to find the max modified date per Customer ID\n3.- Inner join"
      },
      {
        "date": "2021-04-13T08:13:00.000Z",
        "voteCount": 6,
        "content": "I used a dataset with the same structure to test. The result is as same as VR1:\n1. Duplicate the query\n2. Group the query by CustomerID and MAX Modified Date\n3. Merge the queries based on the grouped one, join kind is \"Inner\".\nThis question is a bit tricky that, one option is based on the original query to left join. That's wrong. But if you based on the new grouped query to left join, will get the same outcomes as an inner join. \nI realized the wording was trying to confuse us after reading it carefully."
      },
      {
        "date": "2021-03-02T15:06:00.000Z",
        "voteCount": 2,
        "content": "Better answer?\n1. Sort by customer ID ascending and modification date descending.\n2. Remove duplicates based on customer ID."
      },
      {
        "date": "2021-04-06T19:54:00.000Z",
        "voteCount": 1,
        "content": "This alone dosnt work in power query , You need to Add a Table.Buffer() between the two steps to preserve the sort order before the duplicates are dropped  . So inner join is the correct answer here"
      },
      {
        "date": "2021-02-22T04:08:00.000Z",
        "voteCount": 5,
        "content": "Tested: (not need remove duplicate because Inner join)\n1-duplicate query\n2-group by max  on date column\n3-merge - inner join"
      },
      {
        "date": "2021-02-20T10:34:00.000Z",
        "voteCount": 1,
        "content": "Vr1 is correct"
      },
      {
        "date": "2021-02-11T06:45:00.000Z",
        "voteCount": 5,
        "content": "I have tried this on power bi desktop.\n1. Duplicate Query\n2. GroupBy CustomerID to find max modified date\n3. Remove Duplicates"
      },
      {
        "date": "2021-05-06T15:32:00.000Z",
        "voteCount": 1,
        "content": "I have tried too and it worked"
      },
      {
        "date": "2021-05-20T08:16:00.000Z",
        "voteCount": 3,
        "content": "But if you GroupBy CustomerID, then why do you need to remove duplicates? Because after GroupBy you don't have any duplicates anymore right?"
      }
    ],
    "examNameCode": "da-100",
    "topicNumber": "4"
  },
  {
    "topic": 4,
    "index": 3,
    "url": "https://www.examtopics.com/discussions/microsoft/view/33842-exam-da-100-topic-4-question-3-discussion/",
    "body": "HOTSPOT -<br>You view a query named Transactions as shown in the following exhibit.<br><img src=\"/assets/media/exam-media/04207/0013800001.jpg\" class=\"in-exam-image\"><br>The query gets CSV files from a folder.<br>Use the drop-down menus to select the answer choice that completes each statement based on the information presented in the graphic.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04207/0013900001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04207/0014000001.png\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: 9 -<br>9 distinct CSV files.<br><br>Box 2: 10 -<br>10 distinct dates.",
    "votes": [],
    "comments": [
      {
        "date": "2020-10-07T23:41:00.000Z",
        "voteCount": 176,
        "content": "answer is correct"
      },
      {
        "date": "2021-12-18T23:45:00.000Z",
        "voteCount": 1,
        "content": "For 2nd Question remove duplicates: \n\nhttps://docs.microsoft.com/en-us/power-query/working-with-duplicates#remove-duplicates-from-a-single-column"
      },
      {
        "date": "2021-10-17T06:42:00.000Z",
        "voteCount": 2,
        "content": "how is it possible to have 90 rows by 9 files?"
      },
      {
        "date": "2021-10-17T07:06:00.000Z",
        "voteCount": 1,
        "content": "Unless they are appended"
      },
      {
        "date": "2021-10-25T10:26:00.000Z",
        "voteCount": 1,
        "content": "Filenames have spaces at the beginning (see Source.Name column)."
      },
      {
        "date": "2022-08-05T04:37:00.000Z",
        "voteCount": 1,
        "content": "you have right, the correct answer is 9, 10. For first area the answer is 9 because we need to look at the column Source.Name and we can see 9 distinct, 0 unique. For second area the answer is 10 because it is selected &lt;Column Profile&gt; for column Date (View meniu) and also we can identify the same answer with &lt;Column Distribution&gt;."
      },
      {
        "date": "2021-12-20T08:51:00.000Z",
        "voteCount": 9,
        "content": "This is not correct. The 'Count' is showing 90 rows (meaning csv files). 'Distinct' shows 10. So the answer is: 90 &amp; 10."
      },
      {
        "date": "2022-06-23T01:54:00.000Z",
        "voteCount": 1,
        "content": "90 rows are shown for Date column, not for csv files. See the highlighted column"
      },
      {
        "date": "2022-01-01T22:51:00.000Z",
        "voteCount": 4,
        "content": "The source.name has 9 distinct values. That's why I think there are 9 files."
      },
      {
        "date": "2020-10-19T17:22:00.000Z",
        "voteCount": 67,
        "content": "I think the answer should be Box1:90 and Box2:10.\nEach row in the table is one CSV file. The answer for Box1 is about the number of rows(which includes duplicates), not the distinct values of a column. This Count can be found under the Column stats below the table as COUNT 90.\nThe second box is distinct count based on the Date Column which is 10."
      },
      {
        "date": "2020-10-20T08:26:00.000Z",
        "voteCount": 2,
        "content": "Column stats is shown for Date column, not file name"
      },
      {
        "date": "2020-11-04T02:08:00.000Z",
        "voteCount": 1,
        "content": "yup, even the date column count says 90"
      },
      {
        "date": "2021-01-26T13:00:00.000Z",
        "voteCount": 3,
        "content": "I think this is wrong. The correct one is the answer above by Morti42"
      },
      {
        "date": "2020-12-24T09:44:00.000Z",
        "voteCount": 24,
        "content": "But those 90 are ROWs not FILEs. It states in the question they are coming from a folder. You can't have two files with the same name in a folder, so its 9. \nI personally agree with the answer."
      },
      {
        "date": "2022-09-16T07:13:00.000Z",
        "voteCount": 1,
        "content": "The answer is 90. \nHow can you get 90 rows from a folder if there are only 9 files? doesnt make sense.\nIt could be that the files are from different subfolders, but they have the same name. regardless, they are still separate files, with same name, on different folders."
      },
      {
        "date": "2022-08-04T22:55:00.000Z",
        "voteCount": 1,
        "content": "Answer\n1. 9 files\n2. 10 rows"
      },
      {
        "date": "2022-06-10T16:12:00.000Z",
        "voteCount": 1,
        "content": "The answer is correct"
      },
      {
        "date": "2022-05-22T07:10:00.000Z",
        "voteCount": 3,
        "content": "There can't be 9 CSV files for the simple fact that the date is a refresh date happening at different intervals. So every refresh will generate another CSV file. The answer is 90."
      },
      {
        "date": "2022-03-01T11:34:00.000Z",
        "voteCount": 1,
        "content": "on exam 3/1/2022"
      },
      {
        "date": "2022-02-28T02:35:00.000Z",
        "voteCount": 1,
        "content": "So what's the correct answer here ? Is it 90 and 10 or 9 and 10 distinctive dates ?"
      },
      {
        "date": "2021-12-29T13:56:00.000Z",
        "voteCount": 2,
        "content": "In exam 30/12/21"
      },
      {
        "date": "2021-12-24T02:28:00.000Z",
        "voteCount": 3,
        "content": "9 &amp; 10"
      },
      {
        "date": "2021-12-24T02:22:00.000Z",
        "voteCount": 1,
        "content": "My Answer is 10 &amp; 90::\n1) For each day / date two file (8am &amp; 6pm) - for 5 days min is 2018-01-01 8:00:00AM &amp; max is 2018-05-01 6:00:00 PM (Observe the bar in the columns profile) - each file contains the 9 transactions \n\n2) Date columns (Data type - date/Time) - this filed doesn't have duplicate values - if you use the option to remove duplicate against this columns will not Impact the count\n\nTested"
      },
      {
        "date": "2021-12-02T02:59:00.000Z",
        "voteCount": 2,
        "content": "the answer is wrong for box 1. I think it should be 90"
      },
      {
        "date": "2021-11-20T08:21:00.000Z",
        "voteCount": 3,
        "content": "Since the total count is 90 and as per value distribution it is uniform for all dates so answer would be 90/10= 9 and removing duplicates would result in 10 distinct values"
      },
      {
        "date": "2021-11-11T13:24:00.000Z",
        "voteCount": 5,
        "content": "on exam - Nov 11, 2021. \nmy answers:\n9\n10"
      },
      {
        "date": "2021-11-11T10:36:00.000Z",
        "voteCount": 2,
        "content": "perhpas the csv files are located in a subfolder inside a folder in which case they can have the same name"
      },
      {
        "date": "2021-10-16T03:12:00.000Z",
        "voteCount": 1,
        "content": "why not 10 files as there are 10 distinct id"
      },
      {
        "date": "2021-09-17T03:56:00.000Z",
        "voteCount": 4,
        "content": "Correct asnwer is 90 and 10"
      }
    ],
    "examNameCode": "da-100",
    "topicNumber": "4"
  },
  {
    "topic": 4,
    "index": 4,
    "url": "https://www.examtopics.com/discussions/microsoft/view/33414-exam-da-100-topic-4-question-4-discussion/",
    "body": "Your company has employees in 10 states.<br>The company recently decided to associate each state to one of the following three regions: East, West, and North.<br>You have a data model that contains employee information by state. The model does NOT include region information.<br>You have a report that shows the employees by state.<br>You need to view the employees by region as quickly as possible.<br>What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a new aggregation that summarizes by employee.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a new group on the state column and set the Group type to List.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a new group on the state column and set the Group type to Bin.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a new aggregation that summarizes by state."
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 4,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2020-10-02T01:31:00.000Z",
        "voteCount": 191,
        "content": "Correct answer is - \n\nB. Because List is used to create string groups. Bin is used to create numeric groups."
      },
      {
        "date": "2021-05-01T12:31:00.000Z",
        "voteCount": 6,
        "content": "B is correct, as the values are string."
      },
      {
        "date": "2020-10-04T02:54:00.000Z",
        "voteCount": 32,
        "content": "Ans is B - It should be Group and List. Bin is for numeric and Dates"
      },
      {
        "date": "2022-08-04T22:58:00.000Z",
        "voteCount": 1,
        "content": "Answer is B"
      },
      {
        "date": "2022-07-11T10:36:00.000Z",
        "voteCount": 1,
        "content": "answer was B on exam 7/11/22 passed"
      },
      {
        "date": "2022-07-07T03:36:00.000Z",
        "voteCount": 1,
        "content": "This is definitely B"
      },
      {
        "date": "2022-06-03T22:34:00.000Z",
        "voteCount": 2,
        "content": "correct answer is B , group by Bin is applicable to numerical values."
      },
      {
        "date": "2022-03-17T08:32:00.000Z",
        "voteCount": 1,
        "content": "I got it on my exam 03/17/2022. 90-95% questions were from here. 61 questions in 100 min. All 3 case studies that appeared in exam, where from here."
      },
      {
        "date": "2022-07-27T01:29:00.000Z",
        "voteCount": 1,
        "content": "I think this user is a robot :)  same response but switching dates haha online business"
      },
      {
        "date": "2022-03-17T08:32:00.000Z",
        "voteCount": 1,
        "content": "Answered:B"
      },
      {
        "date": "2021-12-10T08:06:00.000Z",
        "voteCount": 2,
        "content": "on exam 12/10/2021"
      },
      {
        "date": "2021-11-11T13:25:00.000Z",
        "voteCount": 3,
        "content": "on exam - Nov 11, 2021. \nmy answer:\nCreate a new group on the state column and set the Group type to List."
      },
      {
        "date": "2021-10-14T07:17:00.000Z",
        "voteCount": 2,
        "content": "On exam 10/14/21"
      },
      {
        "date": "2021-10-16T00:50:00.000Z",
        "voteCount": 2,
        "content": "Me too 16/10"
      },
      {
        "date": "2021-04-25T04:16:00.000Z",
        "voteCount": 1,
        "content": "The argument to defend the provided answer contradicts the answer given."
      },
      {
        "date": "2021-04-13T06:27:00.000Z",
        "voteCount": 4,
        "content": "B.\nAs for the string type data (region), there is only one option \"List\". You can't set the group as \"bin\"."
      },
      {
        "date": "2021-04-11T06:57:00.000Z",
        "voteCount": 1,
        "content": "the answer is B. the field type is string not numeric or date (You can set the bin size for numerical and time fields in Power BI Desktop.)\nhttps://docs.microsoft.com/en-us/power-bi/create-reports/desktop-grouping-and-binning"
      },
      {
        "date": "2021-04-08T00:09:00.000Z",
        "voteCount": 1,
        "content": "B is the Correct Answer"
      },
      {
        "date": "2021-04-07T05:30:00.000Z",
        "voteCount": 1,
        "content": "The correct answer is B"
      },
      {
        "date": "2021-04-01T20:41:00.000Z",
        "voteCount": 3,
        "content": "B. Create a new group on the state column and set the Group type to List.\n\nMy Power BI instructor confirms that B is the correct answer without any doubt."
      },
      {
        "date": "2021-03-23T09:13:00.000Z",
        "voteCount": 2,
        "content": "Answer is B  because you are going to group strings, not numbers nor dates"
      }
    ],
    "examNameCode": "da-100",
    "topicNumber": "4"
  },
  {
    "topic": 4,
    "index": 5,
    "url": "https://www.examtopics.com/discussions/microsoft/view/51483-exam-da-100-topic-4-question-5-discussion/",
    "body": "HOTSPOT -<br>You are creating a Microsoft Power BI imported data model to perform basket analysis. The goal of the analysis is to identify which products are usually bought together in the same transaction across and within sales territories.<br>You import a fact table named Sales as shown in the exhibit. (Click the Exhibit tab.)<br><img src=\"/assets/media/exam-media/04207/0014200001.jpg\" class=\"in-exam-image\"><br>The related dimension tables are imported into the model.<br>Sales contains the data shown in the following table.<br><img src=\"/assets/media/exam-media/04207/0014300001.png\" class=\"in-exam-image\"><br>You are evaluating how to optimize the model.<br>For each of the following statements, select Yes if the statement is true. Otherwise, select No.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04207/0014400001.jpg\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04207/0014400002.jpg\" class=\"in-exam-image\">",
    "answerDescription": "Reference:<br>https://finance-bi.com/power-bi-basket-analysis/",
    "votes": [],
    "comments": [
      {
        "date": "2021-05-01T19:57:00.000Z",
        "voteCount": 113,
        "content": "The Answer is: \nYES\nNO\nNO\nBecause the only columns needed for that \"Basket analysis\" is Product, Transaction (Order) and Territory."
      },
      {
        "date": "2021-05-04T12:53:00.000Z",
        "voteCount": 12,
        "content": "Yes\nNo\nNo"
      },
      {
        "date": "2021-05-27T16:22:00.000Z",
        "voteCount": 1,
        "content": "how are we gonna know if two items are bought together if we don't have the order date ?"
      },
      {
        "date": "2021-06-06T17:14:00.000Z",
        "voteCount": 5,
        "content": "Only eithhttps://www.examtopics.com/exams/microsoft/da-100/view/17/#er OrderDate or OrderDateKey is required, NOT both, since there is no time data in OrderDate column (these columns are essentially the same).  YES NO NO is the answer"
      },
      {
        "date": "2021-06-24T02:36:00.000Z",
        "voteCount": 8,
        "content": "Bought together means they are within the same order, so the SalesOrderNumber is good enough to identify it."
      },
      {
        "date": "2022-01-21T01:11:00.000Z",
        "voteCount": 1,
        "content": "2 different orders in the same day doesnt count, so date is unnecessary"
      },
      {
        "date": "2021-12-25T03:30:00.000Z",
        "voteCount": 3,
        "content": "how come the anser of A is Yes because sales row id is the index column n you cant delete this"
      },
      {
        "date": "2022-06-09T23:03:00.000Z",
        "voteCount": 1,
        "content": "Because SalesRowID is a row ID of unique combination of SalesOrderNumber and SalesOrderLineNumber. \nAuditID is the ID of the data load process in which identifies the updated row. \nRemoving these columns will not impact the overall goal, which is to identify which products are bought together in same transaction in same territories. Basically, this will be identifying the regional trend."
      },
      {
        "date": "2021-05-01T21:09:00.000Z",
        "voteCount": 10,
        "content": "YES\nNO\n\nNO"
      },
      {
        "date": "2022-08-04T23:07:00.000Z",
        "voteCount": 1,
        "content": "Answer\nYes\nNo\nNo"
      },
      {
        "date": "2022-04-28T05:27:00.000Z",
        "voteCount": 1,
        "content": "Question in the 27/04/2022 exam"
      },
      {
        "date": "2022-03-01T11:35:00.000Z",
        "voteCount": 1,
        "content": "on exam 3/1/2022"
      },
      {
        "date": "2021-12-29T13:56:00.000Z",
        "voteCount": 2,
        "content": "In exam 30/12/21"
      },
      {
        "date": "2021-11-11T13:26:00.000Z",
        "voteCount": 4,
        "content": "on exam - Nov 11, 2021. \nmy answers:\nyes\nno\nno"
      },
      {
        "date": "2021-10-17T02:16:00.000Z",
        "voteCount": 1,
        "content": "The answers are correct:\n_ Y: not related\n_ N: At the first time, I thought it was a Y, because the combination of OrderDate and SalesOrderNumber will be used to distinguish with OrderNumber on other dates (some systems reset the SalesOrderNumber daily). However, taking a closer look at OrderDate and SalesOrderNumber, they are parallelly incremented. Thus, SalesOrderNumber has enough information.\n_ N: not related"
      },
      {
        "date": "2021-09-23T02:35:00.000Z",
        "voteCount": 5,
        "content": "question in exam on 18th September"
      },
      {
        "date": "2021-10-16T00:50:00.000Z",
        "voteCount": 2,
        "content": "Same 16/10"
      },
      {
        "date": "2021-08-15T02:32:00.000Z",
        "voteCount": 3,
        "content": "Got this in the exam - Aug 15, 2021."
      },
      {
        "date": "2021-07-19T07:57:00.000Z",
        "voteCount": 1,
        "content": "OrderDateKey is useless for own case. Yes, NO, NO."
      },
      {
        "date": "2021-06-12T10:02:00.000Z",
        "voteCount": 1,
        "content": "Ouch,  how I was tricked with the first statement after reading next ones)) Of course YES they can be removed!))"
      },
      {
        "date": "2021-05-05T08:12:00.000Z",
        "voteCount": 3,
        "content": "Yes\nNo\nNo"
      },
      {
        "date": "2021-05-02T04:13:00.000Z",
        "voteCount": 3,
        "content": "I believe it should be NO, NO, NO."
      },
      {
        "date": "2021-05-05T06:10:00.000Z",
        "voteCount": 7,
        "content": "Nope, that's just what she said."
      },
      {
        "date": "2021-05-15T02:25:00.000Z",
        "voteCount": 1,
        "content": "How, How How?"
      },
      {
        "date": "2021-05-23T15:51:00.000Z",
        "voteCount": 2,
        "content": "Please read the question carefully and check your answers. Dont get confused."
      },
      {
        "date": "2021-05-20T14:51:00.000Z",
        "voteCount": 1,
        "content": "Can you read it well?"
      },
      {
        "date": "2021-05-01T21:13:00.000Z",
        "voteCount": 1,
        "content": "Are orderDateKet and OrderDate Necessary in this case? There is no requirement for date analysis is that so?"
      },
      {
        "date": "2021-05-02T16:30:00.000Z",
        "voteCount": 2,
        "content": "Date is not required for the Basket analysis mentioned"
      },
      {
        "date": "2021-07-07T00:18:00.000Z",
        "voteCount": 1,
        "content": "Nevertheless you can use one or the other date column and do not need to keep both. The OrderDateKey is a valid Date Format (easily test it yourself using enter data to create a table, enter 20101229 in row 1 and change Type to date)"
      }
    ],
    "examNameCode": "da-100",
    "topicNumber": "4"
  },
  {
    "topic": 4,
    "index": 6,
    "url": "https://www.examtopics.com/discussions/microsoft/view/51355-exam-da-100-topic-4-question-6-discussion/",
    "body": "HOTSPOT -<br>You are enhancing a Power BI model that has DAX calculations.<br>You need to create a measure that returns the year-to-date total sales from the same date of the previous calendar year.<br>Which DAX functions should you use? To answer, select the appropriate options in the answer area.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04207/0014600001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04207/0014700001.png\" class=\"in-exam-image\">",
    "answerDescription": "Reference:<br>https://www.kasperonbi.com/get-the-ytd-of-the-same-period-last-year/<br>Deploy and Maintain Deliverables",
    "votes": [],
    "comments": [
      {
        "date": "2021-05-01T00:15:00.000Z",
        "voteCount": 64,
        "content": "The answer is correct. CALCULATE and DATEBETWEEN"
      },
      {
        "date": "2021-05-01T21:17:00.000Z",
        "voteCount": 5,
        "content": "I think so too"
      },
      {
        "date": "2021-05-22T09:24:00.000Z",
        "voteCount": 18,
        "content": "Shouldn't there be a SUM before Sales[Sales] ?"
      },
      {
        "date": "2021-07-29T09:56:00.000Z",
        "voteCount": 1,
        "content": "If summarisation is set to sum standard for the sales measure it is not necessary."
      },
      {
        "date": "2022-08-04T23:10:00.000Z",
        "voteCount": 1,
        "content": "Answer\nCalculate \nDatesbetween"
      },
      {
        "date": "2022-07-16T08:24:00.000Z",
        "voteCount": 1,
        "content": "correct answer : CALCULATE and DATEBETWEEN. \nThe first argument of  calculate Sales[sales] it might be a measure that's why it does not need a function for the first argument."
      },
      {
        "date": "2022-07-11T10:38:00.000Z",
        "voteCount": 1,
        "content": "7/11/22 was on exam calculate and datebetween"
      },
      {
        "date": "2021-12-29T13:57:00.000Z",
        "voteCount": 1,
        "content": "In exam 30/12/21"
      },
      {
        "date": "2021-12-06T09:45:00.000Z",
        "voteCount": 2,
        "content": "Could someone explain why sameperiod won't work?"
      },
      {
        "date": "2021-12-13T04:36:00.000Z",
        "voteCount": 2,
        "content": "https://docs.microsoft.com/en-us/dax/sameperiodlastyear-function-dax\nit only takes one argument"
      },
      {
        "date": "2021-10-18T10:50:00.000Z",
        "voteCount": 1,
        "content": "Had this question on today\u2019s exam 18 Oct, \nQuestion been modified to three answers"
      },
      {
        "date": "2021-10-28T06:01:00.000Z",
        "voteCount": 2,
        "content": "What options were given?"
      },
      {
        "date": "2021-07-25T11:37:00.000Z",
        "voteCount": 1,
        "content": "Calculate and datebetween\nBecause they already calculated the corresponding date of last year"
      },
      {
        "date": "2021-06-29T14:37:00.000Z",
        "voteCount": 5,
        "content": "VAR startyear =\n    STARTOFYEAR ( \u2018Calendar'[Date] ) \u2013 365\nVAR enddate =\n    LASTDATE ( Sales[Date] ) \u2013 365\nRETURN\n    CALCULATE (\n        SUM ( Sales[sales] ),\n        DATESBETWEEN ( \u2018Calendar'[Date], startyear, enddate )\n    )"
      },
      {
        "date": "2021-10-13T11:39:00.000Z",
        "voteCount": 1,
        "content": "Correct, tested it and it only works with the sum"
      },
      {
        "date": "2021-12-16T15:55:00.000Z",
        "voteCount": 2,
        "content": "No.\nIn a DAX formula of PBI, the \"Sales[sales]\" could be refering to a measure not a column Which will then work perfectly."
      },
      {
        "date": "2021-12-30T13:34:00.000Z",
        "voteCount": 2,
        "content": "But how do you know/assume \"Sales[Sales]\" is a measure instead of a column in this context?"
      },
      {
        "date": "2021-06-13T09:23:00.000Z",
        "voteCount": 4,
        "content": "Based on the options provided, it has to be CALCULATE and DATESBETWEEN.\n\nThe DAX syntax is a bit confusing here because 'Sales'[Sales] looks like a fully qualified column reference but it could also be a measure reference. I assume that it's a measure reference because the SUM function alone doesn't allow other arguments beyond the column reference, so we wouldn't even have to ability to add in additional parameters or  functions. \n\nUsing CALCULATE with the measure reference ('Sales'[Sales]) then allows you to modify the calculation in a filter context with DATESBETWEEN the date range between the two variables."
      },
      {
        "date": "2021-06-10T22:48:00.000Z",
        "voteCount": 1,
        "content": "Sum and Datebetween"
      },
      {
        "date": "2021-05-24T12:31:00.000Z",
        "voteCount": 7,
        "content": "There must be a sum function to calculate the total sales. \nCALCULATE( sum(sales), datesbetween(start, end))"
      },
      {
        "date": "2021-06-26T08:06:00.000Z",
        "voteCount": 2,
        "content": "Agree! Sum is missing from this question."
      },
      {
        "date": "2021-05-09T00:13:00.000Z",
        "voteCount": 1,
        "content": "it should be calculate and sameperiolat year"
      },
      {
        "date": "2021-05-06T23:46:00.000Z",
        "voteCount": 2,
        "content": "I thank too"
      },
      {
        "date": "2021-05-05T00:20:00.000Z",
        "voteCount": 1,
        "content": "answer is wrong calculate , sameperiodlastyear , no specified period exist example: last year till today"
      },
      {
        "date": "2021-05-07T06:53:00.000Z",
        "voteCount": 2,
        "content": "but in the answer we have already the variables..."
      },
      {
        "date": "2021-05-24T11:58:00.000Z",
        "voteCount": 2,
        "content": "We have variables start and enddates. please take note"
      },
      {
        "date": "2021-05-01T21:18:00.000Z",
        "voteCount": 2,
        "content": "Correct Answer"
      }
    ],
    "examNameCode": "da-100",
    "topicNumber": "4"
  }
]