[
  {
    "topic": 1,
    "index": 1,
    "url": "https://www.examtopics.com/discussions/microsoft/view/41948-exam-dp-300-topic-1-question-1-discussion/",
    "body": "You have 20 Azure SQL databases provisioned by using the vCore purchasing model.<br>You plan to create an Azure SQL Database elastic pool and add the 20 databases.<br>Which three metrics should you use to size the elastic pool to meet the demands of your workload? Each correct answer presents part of the solution.<br>NOTE: Each correct selection is worth one point.<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ttotal size of all the databases\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tgeo-replication support",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tnumber of concurrently peaking databases * peak CPU utilization per database\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tmaximum number of concurrent sessions for all the databases",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ttotal number of databases * average CPU utilization per database\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "ACE",
    "answerDescription": "",
    "votes": [
      {
        "answer": "ACE",
        "count": 7,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-02-06T18:50:00.000Z",
        "voteCount": 23,
        "content": "answer is correct"
      },
      {
        "date": "2024-09-25T23:12:00.000Z",
        "voteCount": 2,
        "content": "The given answer is correct based on the Microsoft Learn documentation.\nhttps://learn.microsoft.com/en-us/azure/azure-sql/database/elastic-pool-overview?view=azuresql#how-do-i-choose-the-correct-pool-size"
      },
      {
        "date": "2023-12-18T07:54:00.000Z",
        "voteCount": 3,
        "content": "ACE is the correct response."
      },
      {
        "date": "2023-09-07T18:55:00.000Z",
        "voteCount": 1,
        "content": "Correct answer : ACE"
      },
      {
        "date": "2023-06-26T09:07:00.000Z",
        "voteCount": 1,
        "content": "Correct answer : ACE"
      },
      {
        "date": "2023-03-16T16:58:00.000Z",
        "voteCount": 2,
        "content": "ACE same question in MS practice exam"
      },
      {
        "date": "2022-02-26T07:38:00.000Z",
        "voteCount": 2,
        "content": "ACE is the correct Answer"
      },
      {
        "date": "2022-02-02T14:36:00.000Z",
        "voteCount": 2,
        "content": "Given answer is correct. A,C and E\nhttps://docs.microsoft.com/en-us/azure/azure-sql/database/elastic-pool-overview\nSection: How do I choose the correct pool size."
      },
      {
        "date": "2021-12-26T01:48:00.000Z",
        "voteCount": 1,
        "content": "Answer: A, D, E"
      },
      {
        "date": "2022-03-12T03:08:00.000Z",
        "voteCount": 2,
        "content": "D is not correct. The database sessions are not mentioned anywhere in the documentation for elastic pool cost-effectiveness calculations.\n\nEach database counts as one. The number of sessions within the databases doesn't matter."
      },
      {
        "date": "2021-09-01T05:34:00.000Z",
        "voteCount": 4,
        "content": "ACE for the vCore - https://docs.microsoft.com/en-us/azure/azure-sql/database/elastic-pool-overview"
      },
      {
        "date": "2021-08-13T18:52:00.000Z",
        "voteCount": 1,
        "content": "The Correct Answer is A, D &amp; E."
      },
      {
        "date": "2021-10-17T19:40:00.000Z",
        "voteCount": 3,
        "content": "I meant A,C.E"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 2,
    "url": "https://www.examtopics.com/discussions/microsoft/view/44361-exam-dp-300-topic-1-question-2-discussion/",
    "body": "DRAG DROP -<br>You have SQL Server 2019 on an Azure virtual machine that contains an SSISDB database.<br>A recent failure causes the master database to be lost.<br>You discover that all Microsoft SQL Server integration Services (SSIS) packages fail to run on the virtual machine.<br>Which four actions should you perform in sequence to resolve the issue? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct.<br>Select and Place:<br><img src=\"/assets/media/exam-media/04275/0002300001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04275/0002400001.png\" class=\"in-exam-image\">",
    "answerDescription": "Step 1: Attach the SSISDB database<br>Step 2: Turn on the TRUSTWORTHY property and the CLR property<br>If you are restoring the SSISDB database to an SQL Server instance where the SSISDB catalog was never created, enable common language runtime (clr)<br>Step 3: Open the master key for the SSISDB database<br>Restore the master key by this method if you have the original password that was used to create SSISDB. open master key decryption by password = 'LS1Setup!' --'Password used when creating SSISDB'<br>Alter Master Key Add encryption by Service Master Key<br>Step 4: Encrypt a copy of the master key by using the service master key<br>Reference:<br>https://docs.microsoft.com/en-us/sql/integration-services/catalog/ssis-catalog",
    "votes": [],
    "comments": [
      {
        "date": "2023-05-29T04:55:00.000Z",
        "voteCount": 6,
        "content": "1. Attach the SSISDB database (E)\n2. Open the master key for the SSISDB database (F)\n3. Encrypt a copy of the master key by using the service master key \u00a9\n4. Turn on the TRUSTWORTHY property and the CLR property (D)\n\nturning on the TRUSTWORTHY property and the CLR property (D) should be done after opening the master key for the SSISDB database (F) and encrypting a copy of the master key by using the service master key \u00a9. This is because the TRUSTWORTHY property and CLR property are related to security and encryption, so it\u2019s important to ensure that the master key is properly encrypted before enabling these properties."
      },
      {
        "date": "2024-09-16T15:06:00.000Z",
        "voteCount": 1,
        "content": "Isn't this the right order?\nTurn on the TRUSTWORTHY property and the CLR property\nAttach the SSISDB database\nOpen the master key for the SSISDB database\nEncrypt a copy of the master key by using the service master key"
      },
      {
        "date": "2022-08-09T23:47:00.000Z",
        "voteCount": 1,
        "content": "I believe this question should refer to the SSISDB being restored to another SQL Server as part of the answer is \"Turn on trustworthy property and CLR property\""
      },
      {
        "date": "2021-11-08T00:38:00.000Z",
        "voteCount": 4,
        "content": "The correct url iss:\nhttps://docs.microsoft.com/en-us/sql/integration-services/catalog/ssis-catalog?view=sql-server-ver15#to-restore-the-ssis-database"
      },
      {
        "date": "2021-09-29T07:27:00.000Z",
        "voteCount": 1,
        "content": "What would be the correct order?"
      },
      {
        "date": "2021-09-08T00:36:00.000Z",
        "voteCount": 2,
        "content": "It means master database lost with relevant information also lost so recreate a new SSIS catalog?"
      },
      {
        "date": "2021-05-21T19:34:00.000Z",
        "voteCount": 3,
        "content": "Odd question."
      },
      {
        "date": "2021-03-09T05:03:00.000Z",
        "voteCount": 4,
        "content": "This is such a weird question, it doesn't address the problem at hand which is a failure causing the master table being deleted. Why would that even happen? I would want to figure that out"
      },
      {
        "date": "2021-03-16T14:02:00.000Z",
        "voteCount": 1,
        "content": "It doesn't say deleted; it says lost. Could be corruption + lost backups."
      },
      {
        "date": "2021-02-21T05:17:00.000Z",
        "voteCount": 3,
        "content": "Attaching the database and enabling CLR can be done at any order.\nIn this MS documentation, they first enable CLR, then attach/restore the database:\nhttps://docs.microsoft.com/en-us/sql/integration-services/catalog/ssis-catalog?view=sql-server-ver15"
      },
      {
        "date": "2021-02-09T07:21:00.000Z",
        "voteCount": 3,
        "content": "Link is 404, this is a correct one https://docs.microsoft.com/en-us/sql/integration-services/catalog/ssis-catalog"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 3,
    "url": "https://www.examtopics.com/discussions/microsoft/view/63218-exam-dp-300-topic-1-question-3-discussion/",
    "body": "You have an Azure SQL database that contains a table named factSales. FactSales contains the columns shown in the following table.<br><img src=\"/assets/media/exam-media/04275/0002500001.png\" class=\"in-exam-image\"><br>FactSales has 6 billion rows and is loaded nightly by using a batch process. You must provide the greatest reduction in space for the database and maximize performance.<br>Which type of compression provides the greatest space reduction for the database?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tpage compression",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\trow compression",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tcolumnstore compression",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tcolumnstore archival compression\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 15,
        "isMostVoted": true
      },
      {
        "answer": "C",
        "count": 6,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2024-09-20T00:19:00.000Z",
        "voteCount": 7,
        "content": "it is D\n\nMS Docs : \nFor columnstore tables and indexes, all columnstore tables and indexes always use \ncolumnstore compression and this is not user configurable. Use columnstore archival compression to further reduce the data size for situations when you can afford extra time and CPU resources to store and retrieve the data. You can configure columnstore archival compression."
      },
      {
        "date": "2024-09-20T00:19:00.000Z",
        "voteCount": 6,
        "content": "Question may have been changed recently and now requires \"...and maximize performance.\"\nOnly columnstore compression can achieve both \"...greatest reduction in database space and maximize performance.\"\n\"Columnstore compression typically achieves 10x better compression rates over rowstore indexes. It is the standard compression method for columnstore indexes and enables fast query performance.\" https://docs.microsoft.com/en-us/sql/relational-databases/indexes/columnstore-indexes-design-guidance?view=sql-server-ver16.\nTherefore C. appears to be a better answer than D."
      },
      {
        "date": "2022-07-04T17:42:00.000Z",
        "voteCount": 9,
        "content": "Continued in the same article is this...\n\"Additionally, with a columnstore index, you use partitioning to:\nSave an additional 30% in storage costs. You can compress older partitions with the COLUMNSTORE_ARCHIVE compression options. The data will be slower for query performance, which is acceptable if the partition is queries infrequently.\" \n\nTherefore the correct answer is D. The question is weird and should probably not include performance...but this is a nightly process where performance probably doesn't matter much."
      },
      {
        "date": "2024-09-25T23:13:00.000Z",
        "voteCount": 1,
        "content": "https://learn.microsoft.com/en-us/sql/relational-databases/data-compression/data-compression?view=sql-server-ver16\n\n\"When you compress columnstore indexes with archival compression, this causes the index to perform slower than columnstore indexes that don't have the archival compression. Use archival compression only when you can afford to use extra time and CPU resources to compress and retrieve the data.\n\nThe benefit of archival compression is reduced storage, which is useful for data that isn't accessed frequently. For example, if you have a partition for each month of data, and most of your activity is for the most recent months, you could archive older months to reduce the storage requirements\""
      },
      {
        "date": "2024-04-09T09:27:00.000Z",
        "voteCount": 1,
        "content": "The answer is D"
      },
      {
        "date": "2024-04-09T08:41:00.000Z",
        "voteCount": 1,
        "content": "The question info statement makes the point that you must provide the greatest reduction in space for the database and maximise performance. But the actual \"question\" is asking you to state \"which type of compress provides the greatest space reduction for the database?\" ... its an awful question setup by Microsoft, but based on the interpretation it's D"
      },
      {
        "date": "2024-04-03T11:55:00.000Z",
        "voteCount": 1,
        "content": "D. Question is for maximum compression; not which compression meets the requirements."
      },
      {
        "date": "2024-01-24T19:26:00.000Z",
        "voteCount": 2,
        "content": "Columnstore with archive not give performance, while they asked for maxim compression with performance, Hence (C) option is the best suit."
      },
      {
        "date": "2024-01-27T06:28:00.000Z",
        "voteCount": 2,
        "content": "From microsoft documentation:\n==========================\nWhen you compress columnstore indexes with archival compression, this causes the index to perform slower than columnstore indexes that don't have the archival compression. Use archival compression only when you can afford to use extra time and CPU resources to compress and retrieve the data."
      },
      {
        "date": "2024-01-07T19:10:00.000Z",
        "voteCount": 1,
        "content": "D. columnstore archival compression"
      },
      {
        "date": "2023-06-26T09:10:00.000Z",
        "voteCount": 1,
        "content": "Correct answer D, because it provides the greatest space reduction."
      },
      {
        "date": "2023-06-27T20:49:00.000Z",
        "voteCount": 2,
        "content": "But archive is not the best performance"
      },
      {
        "date": "2023-04-30T17:19:00.000Z",
        "voteCount": 5,
        "content": "It seems they added \u201cand maximise performance\u201d to the question, so it should be C?"
      },
      {
        "date": "2023-02-16T16:58:00.000Z",
        "voteCount": 1,
        "content": "Where mentioned that is column store or row store table?"
      },
      {
        "date": "2022-12-28T10:03:00.000Z",
        "voteCount": 3,
        "content": "it is C to reduce space usage and improve performance."
      },
      {
        "date": "2022-05-27T23:58:00.000Z",
        "voteCount": 2,
        "content": "it is D"
      },
      {
        "date": "2022-03-21T03:36:00.000Z",
        "voteCount": 3,
        "content": "it is D"
      },
      {
        "date": "2022-03-03T02:40:00.000Z",
        "voteCount": 2,
        "content": "Think it\u00b4s D\nColumnstore tables and indexes are always stored with columnstore compression. You can further reduce the size of columnstore data by configuring an additional compression called archival compression.\nhttps://docs.microsoft.com/en-us/sql/relational-databases/data-compression/data-compression?view=sql-server-ver15"
      },
      {
        "date": "2022-02-18T17:48:00.000Z",
        "voteCount": 2,
        "content": "D is the right answer because the question is asking 'Which type of compression provides the greatest space reduction for the database'"
      },
      {
        "date": "2022-02-17T11:49:00.000Z",
        "voteCount": 1,
        "content": "archival compression"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 4,
    "url": "https://www.examtopics.com/discussions/microsoft/view/60884-exam-dp-300-topic-1-question-4-discussion/",
    "body": "You have a Microsoft SQL Server 2019 database named DB1 that uses the following database-level and instance-level features.<br>\u2711 Clustered columnstore indexes<br>\u2711 Automatic tuning<br>\u2711 Change tracking<br>\u2711 PolyBase<br>You plan to migrate DB1 to an Azure SQL database.<br>What feature should be removed or replaced before DB1 can be migrated?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tClustered columnstore indexes",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tPolyBase\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tChange tracking",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAutomatic tuning"
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 12,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2022-03-14T09:09:00.000Z",
        "voteCount": 9,
        "content": "B is correct.\n\nPolyBase is not supported by Azure SQL Database according to https://docs.microsoft.com/en-us/sql/relational-databases/polybase/polybase-versioned-feature-summary"
      },
      {
        "date": "2022-07-14T16:07:00.000Z",
        "voteCount": 2,
        "content": "Polybase has many features and installs differently on different variants of SQL server. The table shows that SQL Database supports one of the features meaning it does partially supports Polybase. Probably, the issue here is that Azure SQL Database has its own Polybase which is different than on-premises Polybase and this could create some errors during migration"
      },
      {
        "date": "2022-04-14T02:26:00.000Z",
        "voteCount": 3,
        "content": "B is correct"
      },
      {
        "date": "2021-10-03T10:11:00.000Z",
        "voteCount": 3,
        "content": "looks correct according to the pic above"
      },
      {
        "date": "2021-09-29T07:33:00.000Z",
        "voteCount": 4,
        "content": "for me this is correct"
      },
      {
        "date": "2021-08-27T19:05:00.000Z",
        "voteCount": 1,
        "content": "No comments?"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 5,
    "url": "https://www.examtopics.com/discussions/microsoft/view/63219-exam-dp-300-topic-1-question-5-discussion/",
    "body": "You have a Microsoft SQL Server 2019 instance in an on-premises datacenter. The instance contains a 4-TB database named DB1.<br>You plan to migrate DB1 to an Azure SQL Database managed instance.<br>What should you use to minimize downtime and data loss during the migration?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tdistributed availability groups",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tdatabase mirroring",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAlways On Availability Group",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure Database Migration Service\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "Azure Database Migration Service can do online migrations with minimal downtime.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/dms/dms-overview",
    "votes": [
      {
        "answer": "D",
        "count": 2,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-11-08T01:29:00.000Z",
        "voteCount": 10,
        "content": "D is correct.\nWhen you migrate databases to Azure by using Azure Database Migration Service, you can do an offline or an online migration. With an offline migration, application downtime starts when the migration starts. With an online migration, downtime is limited to the time to cut over at the end of migration. We suggest that you test an offline migration to determine whether the downtime is acceptable; if not, do an online migration.\n\nhttps://docs.microsoft.com/en-us/azure/dms/tutorial-sql-server-to-managed-instance"
      },
      {
        "date": "2024-09-03T14:34:00.000Z",
        "voteCount": 1,
        "content": "My vote goes to Managed link feature if you are using 2022 SQL server. I know is not an option, but it should be in near future"
      },
      {
        "date": "2022-05-16T00:12:00.000Z",
        "voteCount": 1,
        "content": "D is the correct option"
      },
      {
        "date": "2022-05-02T18:46:00.000Z",
        "voteCount": 1,
        "content": "Azure Database Migration Service"
      },
      {
        "date": "2021-11-04T06:40:00.000Z",
        "voteCount": 3,
        "content": "yes, its the correct answer!"
      },
      {
        "date": "2021-11-04T02:10:00.000Z",
        "voteCount": 1,
        "content": "it is not the matter of support migration, but need to reduce the downtime?"
      },
      {
        "date": "2021-12-14T09:39:00.000Z",
        "voteCount": 1,
        "content": "yes, you are correct"
      },
      {
        "date": "2021-10-03T10:15:00.000Z",
        "voteCount": 3,
        "content": "looks correct .\nazure SQL Mi support up to 8tb dbs as of today"
      },
      {
        "date": "2021-10-01T13:20:00.000Z",
        "voteCount": 2,
        "content": "I think this is correct since this is managed instance that supports Azure Database Migration Service and Native RESTORE DATABASE FROM URL"
      },
      {
        "date": "2021-09-29T07:35:00.000Z",
        "voteCount": 1,
        "content": "is it correct?"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 6,
    "url": "https://www.examtopics.com/discussions/microsoft/view/98419-exam-dp-300-topic-1-question-6-discussion/",
    "body": "HOTSPOT -<br>You have an on-premises Microsoft SQL Server 2016 server named Server1 that contains a database named DB1.<br>You need to perform an online migration of DB1 to an Azure SQL Database managed instance by using Azure Database Migration Service.<br>How should you configure the backup of DB1? To answer, select the appropriate options in the answer area.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04275/0002900001.jpg\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04275/0003000001.jpg\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: Full and log backups only<br>Make sure to take every backup on a separate backup media (backup files). Azure Database Migration Service doesn't support backups that are appended to a single backup file. Take full backup and log backups to separate backup files.<br><br>Box 2: WITH CHECKSUM -<br>Azure Database Migration Service uses the backup and restore method to migrate your on-premises databases to SQL Managed Instance. Azure Database<br>Migration Service only supports backups created using checksum.<br>Incorrect Answers:<br>NOINIT Indicates that the backup set is appended to the specified media set, preserving existing backup sets. If a media password is defined for the media set, the password must be supplied. NOINIT is the default.<br><br>UNLOAD -<br>Specifies that the tape is automatically rewound and unloaded when the backup is finished. UNLOAD is the default when a session begins.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/dms/known-issues-azure-sql-db-managed-instance-online",
    "votes": [],
    "comments": [
      {
        "date": "2024-09-24T03:53:00.000Z",
        "voteCount": 1,
        "content": "Given answer correct. For an online migration, DMS requires you to provide both a full backup and log backups to allow continuous synchronization and minimize downtime."
      },
      {
        "date": "2024-02-24T11:52:00.000Z",
        "voteCount": 1,
        "content": "I cannot see any option for taking backup in DMS. It's all about setting up project, setting up source and destination and finally start cutover and update the connection string. Where do you see the taking backups?"
      },
      {
        "date": "2023-05-03T09:16:00.000Z",
        "voteCount": 3,
        "content": "According to the documentation \"Take full, differential and log backups to separate backup files.\" as part of the requirements."
      },
      {
        "date": "2023-03-28T18:57:00.000Z",
        "voteCount": 1,
        "content": "How can you make a full backup without logs, which are included automatically?\nThe question is incorrect"
      },
      {
        "date": "2023-03-07T19:41:00.000Z",
        "voteCount": 1,
        "content": "Full backup only. Why do you need the log backup?"
      },
      {
        "date": "2023-02-08T04:15:00.000Z",
        "voteCount": 3,
        "content": "Backup type: Full backup only\nBackup option: WITH CHECKSUM"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 7,
    "url": "https://www.examtopics.com/discussions/microsoft/view/41947-exam-dp-300-topic-1-question-7-discussion/",
    "body": "DRAG DROP -<br>You have a resource group named App1Dev that contains an Azure SQL Database server named DevServer1. DevServer1 contains an Azure SQL database named DB1. The schema and permissions for DB1 are saved in a Microsoft SQL Server Data Tools (SSDT) database project.<br>You need to populate a new resource group named App1Test with the DB1 database and an Azure SQL Server named TestServer1. The resources in App1Test must have the same configurations as the resources in App1Dev.<br>Which four actions should you perform in sequence? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.<br>Select and Place:<br><img src=\"/assets/media/exam-media/04275/0003100001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04275/0003200001.png\" class=\"in-exam-image\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2021-01-09T22:55:00.000Z",
        "voteCount": 18,
        "content": "the answer is corrected"
      },
      {
        "date": "2021-09-28T09:30:00.000Z",
        "voteCount": 2,
        "content": "Thank you"
      },
      {
        "date": "2022-06-09T07:11:00.000Z",
        "voteCount": 5,
        "content": "Re-Write answer here FYI.\n1. From the Azure Portal, export the Azure Resource Manager templates.\n2. Change the server name and related variables in the templates.\n3. From the Azure portal, deploy the templates.\n4. From the database project, deply the database schema and permissions."
      },
      {
        "date": "2022-05-02T18:50:00.000Z",
        "voteCount": 2,
        "content": "the answer is corrected"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 8,
    "url": "https://www.examtopics.com/discussions/microsoft/view/60328-exam-dp-300-topic-1-question-8-discussion/",
    "body": "HOTSPOT -<br>You have an Azure Synapse Analytics dedicated SQL pool named Pool1 and an Azure Data Lake Storage Gen2 account named Account1.<br>You plan to access the files in Account1 by using an external table.<br>You need to create a data source in Pool1 that you can reference when you create the external table.<br>How should you complete the Transact-SQL statement? To answer, select the appropriate options in the answer area.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04275/0003300001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04275/0003400001.png\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: dfs -<br>For Azure Data Lake Store Gen 2 used the following syntax:<br>http[s]    &lt;storage_account&gt;.dfs.core.windows.net/&lt;container&gt;/subfolders<br>Incorrect:<br>Not blob: blob is used for Azure Blob Storage. Syntax:<br>http[s]    &lt;storage_account&gt;.blob.core.windows.net/&lt;container&gt;/subfolders<br><br>Box 2: TYPE = HADOOP -<br>Syntax for CREATE EXTERNAL DATA SOURCE.<br>External data sources with TYPE=HADOOP are available only in dedicated SQL pools.<br>CREATE EXTERNAL DATA SOURCE &lt;data_source_name&gt;<br><br>WITH -<br>(    LOCATION         = '&lt;prefix&gt;://&lt;path&gt;'<br>[, CREDENTIAL = &lt;database scoped credential&gt; ]<br>, TYPE = HADOOP<br>)<br>[;]<br>Reference:<br>https://docs.microsoft.com/en-us/azure/synapse-analytics/sql/develop-tables-external-tables",
    "votes": [],
    "comments": [
      {
        "date": "2021-08-22T23:57:00.000Z",
        "voteCount": 25,
        "content": "dfs\nhadoop"
      },
      {
        "date": "2021-09-01T07:47:00.000Z",
        "voteCount": 2,
        "content": "Why \"dfs\"? For the reference in the answer seems that the first answer is \"blob\"."
      },
      {
        "date": "2021-10-11T12:54:00.000Z",
        "voteCount": 2,
        "content": "You are right:\n\nCREATE EXTERNAL DATA SOURCE YellowTaxi\nWITH ( LOCATION = 'https://azureopendatastorage.blob.core.windows.net/nyctlc/yellow/',\n       TYPE = HADOOP)"
      },
      {
        "date": "2021-10-11T12:55:00.000Z",
        "voteCount": 2,
        "content": "-- Please note the abfss endpoint when your account has secure transfer enabled\n  ( LOCATION = 'abfss://data@newyorktaxidataset.dfs.core.windows.net' ,\n    CREDENTIAL = ADLS_credential ,\n    TYPE = HADOOP\n  ) ;"
      },
      {
        "date": "2021-12-27T17:35:00.000Z",
        "voteCount": 5,
        "content": "datalake gen2 is dfs. \nhttps://docs.microsoft.com/en-us/azure/synapse-analytics/sql/develop-tables-external-tables?tabs=hadoop#create-external-data-source"
      },
      {
        "date": "2022-03-06T03:59:00.000Z",
        "voteCount": 5,
        "content": "datalake gen2 is dfs.\nhttps://docs.microsoft.com/en-us/azure/synapse-analytics/sql/develop-tables-external-tables?tabs=hadoop#create-external-data-source"
      },
      {
        "date": "2021-12-15T04:26:00.000Z",
        "voteCount": 2,
        "content": "dfs - gen2\ndatalakestorage - gen1\nblob - blob storage"
      },
      {
        "date": "2021-12-13T01:55:00.000Z",
        "voteCount": 2,
        "content": "https://docs.microsoft.com/en-us/azure/synapse-analytics/sql/develop-tables-external-tables?tabs=hadoop\nAzure Data Lake Storage Gen2  ===&gt; dfs\n\nTYPE = HADOOP"
      },
      {
        "date": "2021-10-11T13:04:00.000Z",
        "voteCount": 1,
        "content": "-- Creates a Hadoop external data source in dedicated SQL pool\nCREATE EXTERNAL DATA SOURCE AzureDataLakeStore\nWITH\n  ( LOCATION = 'abfss://data@newyorktaxidataset.dfs.core.windows.net' ,\n    CREDENTIAL = ADLS_credential ,\n    TYPE = HADOOP\n  ) \n\n\n-- Creates an external data source for Azure Data Lake Gen2\nCREATE EXTERNAL DATA SOURCE YellowTaxi\nWITH \n  ( LOCATION = 'https://azureopendatastorage.blob.core.windows.net/nyctlc/yellow/',\n    TYPE = HADOOP\n  )\n\nThe question asks to create a data source in Pool1. So the answer is dfs &amp; HADOOP."
      },
      {
        "date": "2021-10-08T17:24:00.000Z",
        "voteCount": 1,
        "content": "dfs and hadoop.\nAzure Data Lake Store Gen 2\thttp[s]\t&lt;storage_account&gt;.dfs.core.windows.net/&lt;container&gt;/subfolders"
      },
      {
        "date": "2021-10-03T10:19:00.000Z",
        "voteCount": 2,
        "content": "Azure Data Lake Store Gen 2  =dfs\n\nhttps://docs.microsoft.com/en-us/azure/synapse-analytics/sql/develop-tables-external-tables?tabs=hadoop#:~:text=Azure%20Data%20Lake%20Store%20Gen%202"
      },
      {
        "date": "2021-09-05T16:52:00.000Z",
        "voteCount": 3,
        "content": "'dfs' is required to access data files with a DLS Gen2 storage account"
      },
      {
        "date": "2021-08-28T10:28:00.000Z",
        "voteCount": 1,
        "content": "https://docs.microsoft.com/en-us/azure/synapse-analytics/sql/develop-tables-external-tables?tabs=hadoop"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 9,
    "url": "https://www.examtopics.com/discussions/microsoft/view/60365-exam-dp-300-topic-1-question-9-discussion/",
    "body": "HOTSPOT -<br>You plan to develop a dataset named Purchases by using Azure Databricks. Purchases will contain the following columns:<br>\u2711 ProductID<br>\u2711 ItemPrice<br>\u2711 LineTotal<br>\u2711 Quantity<br>\u2711 StoreID<br>\u2711 Minute<br>\u2711 Month<br>\u2711 Hour<br>\u2711 Year<br>\u2711 Day<br>You need to store the data to support hourly incremental load pipelines that will vary for each StoreID. The solution must minimize storage costs.<br>How should you complete the code? To answer, select the appropriate options in the answer area.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04275/0003600001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04275/0003700001.png\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: .partitionBy -<br>Example:<br>df.write.partitionBy(\"y\",\"m\",\"d\")<br>.mode(SaveMode.Append)<br>.parquet(\"/data/hive/warehouse/db_name.db/\" + tableName)<br>Box 2: (\"Year\",\"Month\",\"Day\",\"Hour\",\"StoreID\")<br>Box 3: .parquet(\"/Purchases\")<br>Reference:<br>https://intellipaat.com/community/11744/how-to-partition-and-write-dataframe-in-spark-without-deleting-partitions-with-no-new-data",
    "votes": [],
    "comments": [
      {
        "date": "2021-08-23T04:18:00.000Z",
        "voteCount": 18,
        "content": "Question FOR DP-203 , Not For DBA (DP-300)"
      },
      {
        "date": "2021-09-28T09:32:00.000Z",
        "voteCount": 2,
        "content": "Is it correct then?"
      },
      {
        "date": "2022-04-14T02:49:00.000Z",
        "voteCount": 4,
        "content": "Answer should be (\"StoreID\",\"Year\",\"Month\",\"Day\",\"Hour\") and this indeed a question from DP-203 (recently passed this one)"
      },
      {
        "date": "2022-06-23T10:10:00.000Z",
        "voteCount": 5,
        "content": ".partitionBy\n\n(\"StoreID\", \"Year\",\"Month\",\"Day\",\"Hour\") or (\"StoreID\", \"Hour\")\n\n.parquet(\"/Purchases\")\n\n\n// The problem is that (\"StoreID\", \"Year\",\"Month\",\"Day\",\"Hour\") and (\"Year\",\"Month\",\"Day\",\"Hour\", \"StoreID\") are basically the same\n\n//  (\"StoreID\", \"Hour\") or even better (\"StoreID\") (not on the list) are also good. The problem is that you would have to keep offset of the last read\n\n// I would choose (\"StoreID\", \"Year\",\"Month\",\"Day\",\"Hour\")  because it is the cleanest"
      },
      {
        "date": "2022-03-08T02:12:00.000Z",
        "voteCount": 2,
        "content": ".partitionBy\n(\"Year\",\"Month\",\"Day\",\"Hour\",\"StoreID\")\n.parquet(\"/Purchases\")\n\nCorrect at the expectation is incremental load pipelines so the smallest partition will be achieved by \ndf.write.partitionBy (\"Year\",\"Month\",\"Day\",\"Hour\",\"StoreID\")\n.mode(\"append\")\n.parquet(\"/Purchases\") as parquet has the least data footprint"
      },
      {
        "date": "2022-01-25T23:29:00.000Z",
        "voteCount": 2,
        "content": "IMHO, as far as hourly load should vary by Store, it should be \"StoreID, Year, Month, Day, Hour\"."
      },
      {
        "date": "2021-10-19T20:14:00.000Z",
        "voteCount": 3,
        "content": "answer is correct.\n\nReference:\nhttps://stackoverflow.com/questions/59278835/pyspark-how-to-write-dataframe-partition-by-year-month-day-hour-sub-directory"
      },
      {
        "date": "2021-10-17T19:50:00.000Z",
        "voteCount": 2,
        "content": "The given answer is correct."
      },
      {
        "date": "2021-09-30T11:48:00.000Z",
        "voteCount": 1,
        "content": "is the answer correct?"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 10,
    "url": "https://www.examtopics.com/discussions/microsoft/view/60366-exam-dp-300-topic-1-question-10-discussion/",
    "body": "You are designing a streaming data solution that will ingest variable volumes of data.<br>You need to ensure that you can change the partition count after creation.<br>Which service should you use to ingest the data?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure Event Hubs Standard",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure Stream Analytics",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure Data Factory",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure Event Hubs Dedicated\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 5,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-08-23T04:19:00.000Z",
        "voteCount": 24,
        "content": "Question FOR DP-203 , Not For DBA (DP-300)"
      },
      {
        "date": "2024-09-25T23:15:00.000Z",
        "voteCount": 5,
        "content": "The number of partitions is specified at creation and must be between 1 and 32. The partition count isn't changeable in all tiers except the dedicated tier, so you should consider long-term scale when setting partition count.\nhttps://docs.microsoft.com/en-us/azure/event-hubs/event-hubs-faq"
      },
      {
        "date": "2023-01-29T22:29:00.000Z",
        "voteCount": 1,
        "content": "Correct: D\n\nhttps://learn.microsoft.com/en-us/azure/event-hubs/event-hubs-quotas"
      },
      {
        "date": "2021-09-30T11:48:00.000Z",
        "voteCount": 1,
        "content": "is the answer correct?"
      },
      {
        "date": "2021-11-21T16:47:00.000Z",
        "voteCount": 5,
        "content": "The answer looks right"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 11,
    "url": "https://www.examtopics.com/discussions/microsoft/view/60367-exam-dp-300-topic-1-question-11-discussion/",
    "body": "HOTSPOT -<br>You are building a database in an Azure Synapse Analytics serverless SQL pool.<br>You have data stored in Parquet files in an Azure Data Lake Storage Gen2 container.<br>Records are structured as shown in the following sample.<br><img src=\"/assets/media/exam-media/04275/0003900001.png\" class=\"in-exam-image\"><br>The records contain two applicants at most.<br>You need to build a table that includes only the address fields.<br>How should you complete the Transact-SQL statement? To answer, select the appropriate options in the answer area.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04275/0004000001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04275/0004100001.png\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: CREATE EXTERNAL TABLE -<br>An external table points to data located in Hadoop, Azure Storage blob, or Azure Data Lake Storage. External tables are used to read data from files or write data to files in Azure Storage. With Synapse SQL, you can use external tables to read external data using dedicated SQL pool or serverless SQL pool.<br>Syntax:<br>CREATE EXTERNAL TABLE { database_name.schema_name.table_name | schema_name.table_name | table_name }<br>( &lt;column_definition&gt; [ ,...n ] )<br>WITH (<br>LOCATION = 'folder_or_filepath',<br>DATA_SOURCE = external_data_source_name,<br>FILE_FORMAT = external_file_format_name<br><br>Box 2. OPENROWSET -<br>When using serverless SQL pool, CETAS is used to create an external table and export query results to Azure Storage Blob or Azure Data Lake Storage Gen2.<br>Example:<br><br>AS -<br>SELECT decennialTime, stateName, SUM(population) AS population<br><br>FROM -<br>OPENROWSET(BULK 'https://azureopendatastorage.blob.core.windows.net/censusdatacontainer/release/us_population_county/year=*/*.parquet',<br>FORMAT='PARQUET') AS [r]<br>GROUP BY decennialTime, stateName<br><br>GO -<br>Reference:<br>https://docs.microsoft.com/en-us/azure/synapse-analytics/sql/develop-tables-external-tables",
    "votes": [],
    "comments": [
      {
        "date": "2024-09-20T00:21:00.000Z",
        "voteCount": 6,
        "content": "The Given answer is correct."
      },
      {
        "date": "2023-02-09T02:35:00.000Z",
        "voteCount": 1,
        "content": "CREATE TABLE\nOPENROWSET"
      },
      {
        "date": "2022-11-12T10:12:00.000Z",
        "voteCount": 1,
        "content": "Azure Synapse Analytics questions are not part of the DP-300 exam."
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 12,
    "url": "https://www.examtopics.com/discussions/microsoft/view/60368-exam-dp-300-topic-1-question-12-discussion/",
    "body": "You have an Azure Synapse Analytics Apache Spark pool named Pool1.<br>You plan to load JSON files from an Azure Data Lake Storage Gen2 container into the tables in Pool1. The structure and data types vary by file.<br>You need to load the files into the tables. The solution must maintain the source data types.<br>What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tLoad the data by using PySpark.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tLoad the data by using the OPENROWSET Transact-SQL command in an Azure Synapse Analytics serverless SQL pool.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse a Get Metadata activity in Azure Data Factory.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse a Conditional Split transformation in an Azure Synapse data flow."
    ],
    "answer": "A",
    "answerDescription": "Synapse notebooks support four Apache Spark languages:<br>PySpark (Python)<br>Spark (Scala)<br><br>Spark SQL -<br>.NET Spark (C#)<br>Note: Bring data to a notebook.<br>You can load data from Azure Blob Storage, Azure Data Lake Store Gen 2, and SQL pool as shown in the code samples below.<br>Read a CSV from Azure Data Lake Store Gen2 as a Spark DataFrame. from pyspark.sql import SparkSession from pyspark.sql.types import * account_name = \"Your account name\" container_name = \"Your container name\" relative_path = \"Your path\" adls_path = 'abfss://%s@%s.dfs.core.windows.net/%s' % (container_name, account_name, relative_path) df1 = spark.read.option('header', 'true') \\<br>.option('delimiter', ',') \\<br>.csv(adls_path + '/Testfile.csv')<br>Reference:<br>https://docs.microsoft.com/en-us/azure/synapse-analytics/spark/apache-spark-development-using-notebooks",
    "votes": [],
    "comments": [
      {
        "date": "2021-08-23T04:20:00.000Z",
        "voteCount": 32,
        "content": "Question FOR DP-203 , Not For DBA (DP-300)"
      },
      {
        "date": "2021-09-01T03:42:00.000Z",
        "voteCount": 20,
        "content": "we get it ,you've made your point..... no need to have the same comment for every question ."
      },
      {
        "date": "2021-11-02T18:34:00.000Z",
        "voteCount": 2,
        "content": "ya right, why keeps on commenting for every question. lol"
      },
      {
        "date": "2021-11-20T05:07:00.000Z",
        "voteCount": 8,
        "content": "Maybe to indicate that this exact question is for other exam?"
      },
      {
        "date": "2021-12-07T05:37:00.000Z",
        "voteCount": 3,
        "content": "it is not from other exam. These questions are on dp-300..........."
      },
      {
        "date": "2022-06-07T15:07:00.000Z",
        "voteCount": 5,
        "content": "Thanks HichemZe! I was about to have a panic attack regarding several of these questions before seeing your very helpful response!"
      },
      {
        "date": "2022-06-23T05:20:00.000Z",
        "voteCount": 8,
        "content": "Answer is A\n\nIf you want to load into Spark pool then use Spark itself\nOPENROWSET is for the source, here the issue is the target  meaning Spark"
      },
      {
        "date": "2022-10-29T09:13:00.000Z",
        "voteCount": 3,
        "content": "Azure Sinapse Analytics is out of scope of the DP-300 exam."
      },
      {
        "date": "2021-09-27T05:45:00.000Z",
        "voteCount": 3,
        "content": "How using a serverless SQL pool can be the right answer if the question states to \"have an Azure Synapse Analytics Apache Spark pool named Pool1.\"? Yes, It can be copied from serverless to Apache Spark pool but that's a heck of speculation. I am going to stick with PySpark (https://docs.microsoft.com/en-us/azure/synapse-analytics/spark/apache-spark-development-using-notebooks?tabs=classical#set-a-primary-language)"
      },
      {
        "date": "2021-11-21T16:55:00.000Z",
        "voteCount": 1,
        "content": "Is the A correct?  what do you think?"
      },
      {
        "date": "2021-12-15T04:29:00.000Z",
        "voteCount": 3,
        "content": "A is correct, when you create native parquet tables in spark they are automaticly available in serverless sql pools as tables"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 13,
    "url": "https://www.examtopics.com/discussions/microsoft/view/60055-exam-dp-300-topic-1-question-13-discussion/",
    "body": "You are designing a date dimension table in an Azure Synapse Analytics dedicated SQL pool. The date dimension table will be used by all the fact tables.<br>Which distribution type should you recommend to minimize data movement?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tHASH",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tREPLICATE\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tROUND_ROBIN"
    ],
    "answer": "B",
    "answerDescription": "A replicated table has a full copy of the table available on every Compute node. Queries run fast on replicated tables since joins on replicated tables don't require data movement. Replication requires extra storage, though, and isn't practical for large tables.<br>Incorrect Answers:<br>C: A round-robin distributed table distributes table rows evenly across all distributions. The assignment of rows to distributions is random. Unlike hash-distributed tables, rows with equal values are not guaranteed to be assigned to the same distribution.<br>As a result, the system sometimes needs to invoke a data movement operation to better organize your data before it can resolve a query.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/synapse-analytics/sql-data-warehouse/sql-data-warehouse-tables-distribute",
    "votes": [
      {
        "answer": "B",
        "count": 1,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-08-20T06:38:00.000Z",
        "voteCount": 40,
        "content": "It's a question for DP-203 !!"
      },
      {
        "date": "2021-12-06T13:45:00.000Z",
        "voteCount": 6,
        "content": "okay we get it no need to say the same thing over and over"
      },
      {
        "date": "2023-08-29T14:10:00.000Z",
        "voteCount": 7,
        "content": "No, it's actually useful to confirm for each question that THIS ONE is not part of the actual DP-300 curriculum. My time is precious and I would rather not prepare for a different exam than the one I intend to take lol"
      },
      {
        "date": "2023-03-07T03:52:00.000Z",
        "voteCount": 10,
        "content": "I think it's okay to tag the question as one from DP-203 - we don't have time to waste on questions that are not part of DP-300 objectives."
      },
      {
        "date": "2022-08-21T06:08:00.000Z",
        "voteCount": 1,
        "content": "Thanks for sharing that. ;)"
      },
      {
        "date": "2021-10-28T17:02:00.000Z",
        "voteCount": 6,
        "content": "minimize data movement = replicate"
      },
      {
        "date": "2023-05-22T17:57:00.000Z",
        "voteCount": 1,
        "content": "Replicate seems like the only logical answer."
      },
      {
        "date": "2022-12-23T07:15:00.000Z",
        "voteCount": 1,
        "content": "base on the following the Correct ANswer is ... ==&gt; B.Replicate\n\nCheat sheet for dedicated SQL pool (formerly SQL DW) in Azure Synapse Analytics\n\tUse the following strategies, depending on the table properties:\n\tType: Replicated\n\tGreat fit for\u2026: Small dimension tables in a star schema with less than 2 GB of storage after compression (~5x compression) \n\n\nhttps://learn.microsoft.com/en-us/azure/synapse-analytics/sql-data-warehouse/cheat-sheet#distributed-or-replicated-tables"
      },
      {
        "date": "2022-10-25T10:45:00.000Z",
        "voteCount": 1,
        "content": "HASH is correct, please fix!"
      },
      {
        "date": "2022-10-19T08:27:00.000Z",
        "voteCount": 2,
        "content": "B. Replicated is correct"
      },
      {
        "date": "2022-10-18T05:20:00.000Z",
        "voteCount": 3,
        "content": "Never seen dimension tables or Synapse Analytics in MeasureUp test practice for the DP-300 exam."
      },
      {
        "date": "2021-12-19T12:08:00.000Z",
        "voteCount": 6,
        "content": "A replicated table has a full copy of the table available on every Compute node"
      },
      {
        "date": "2021-12-12T06:48:00.000Z",
        "voteCount": 5,
        "content": "understand that these questions are going to be on dp 300, just stop saying that the website needs a fix. this is not a problem from website but from microsoft"
      },
      {
        "date": "2021-10-27T04:28:00.000Z",
        "voteCount": 1,
        "content": "Please fix this......"
      },
      {
        "date": "2021-09-01T18:13:00.000Z",
        "voteCount": 3,
        "content": "They should fix this ASAP"
      },
      {
        "date": "2021-08-30T07:00:00.000Z",
        "voteCount": 3,
        "content": "They should fix this ASAP"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 14,
    "url": "https://www.examtopics.com/discussions/microsoft/view/60133-exam-dp-300-topic-1-question-14-discussion/",
    "body": "HOTSPOT -<br>From a website analytics system, you receive data extracts about user interactions such as downloads, link clicks, form submissions, and video plays.<br>The data contains the following columns:<br><img src=\"/assets/media/exam-media/04275/0004400001.png\" class=\"in-exam-image\"><br>You need to design a star schema to support analytical queries of the data. The star schema will contain four tables including a date dimension.<br>To which table should you add each column? To answer, select the appropriate options in the answer area.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04275/0004500001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04275/0004600001.png\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: DimEvent -<br><br>Box 2: DimChannel -<br>Dimension tables describe business entities \u05d2\u20ac\" the things you model. Entities can include products, people, places, and concepts including time itself. The most consistent table you'll find in a star schema is a date dimension table. A dimension table contains a key column (or columns) that acts as a unique identifier, and descriptive columns.<br><br>Box 3: FactEvents -<br>Fact tables store observations or events, and can be sales orders, stock balances, exchange rates, temperatures, etc.<br>Reference:<br>https://docs.microsoft.com/en-us/power-bi/guidance/star-schema",
    "votes": [],
    "comments": [
      {
        "date": "2021-09-14T17:00:00.000Z",
        "voteCount": 29,
        "content": "Dimension tables support filtering and grouping, Fact tables support summarization, so the correct answer is: DimEvent, DimChannel, FactEvents."
      },
      {
        "date": "2021-08-23T11:13:00.000Z",
        "voteCount": 11,
        "content": "Answer is incorrect. The correct answer is: DimEvent, DimChannel, FactEvents"
      },
      {
        "date": "2024-06-30T16:08:00.000Z",
        "voteCount": 1,
        "content": "Now its correct but, its DP 203"
      },
      {
        "date": "2022-11-12T10:08:00.000Z",
        "voteCount": 3,
        "content": "OLAP questions are not part of the DP-300 exam."
      },
      {
        "date": "2022-06-08T05:03:00.000Z",
        "voteCount": 2,
        "content": "It's part of dp 300"
      },
      {
        "date": "2022-02-07T23:57:00.000Z",
        "voteCount": 9,
        "content": "This is a DP-203 question."
      },
      {
        "date": "2021-12-19T12:12:00.000Z",
        "voteCount": 1,
        "content": "Box 1: FactEvents - \nBox 2: DimChannel - \n \nReference: https://docs.microsoft.com/en-us/power-bi/guidance/star-schema"
      },
      {
        "date": "2021-12-17T10:13:00.000Z",
        "voteCount": 3,
        "content": "Its not a DP-300 Question !!"
      },
      {
        "date": "2021-11-18T16:20:00.000Z",
        "voteCount": 1,
        "content": "is part of DP-300???"
      },
      {
        "date": "2021-10-27T04:30:00.000Z",
        "voteCount": 3,
        "content": "Another, can this be fixed please."
      },
      {
        "date": "2021-08-23T00:05:00.000Z",
        "voteCount": 5,
        "content": "DimEvent\nDimChannel\nFactEvents"
      },
      {
        "date": "2021-08-21T03:32:00.000Z",
        "voteCount": 4,
        "content": "From my opinion 1 and 3 are opposite - Fact is number of events and Event category is DimEvent."
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 15,
    "url": "https://www.examtopics.com/discussions/microsoft/view/60921-exam-dp-300-topic-1-question-15-discussion/",
    "body": "DRAG DROP -<br>You plan to create a table in an Azure Synapse Analytics dedicated SQL pool.<br>Data in the table will be retained for five years. Once a year, data that is older than five years will be deleted.<br>You need to ensure that the data is distributed evenly across partitions. The solutions must minimize the amount of time required to delete old data.<br>How should you complete the Transact-SQL statement? To answer, drag the appropriate values to the correct targets. Each value may be used once, more than once, or not at all.<br>You may need to drag the split bar between panes or scroll to view content.<br>NOTE: Each correct selection is worth one point.<br>Select and Place:<br><img src=\"/assets/media/exam-media/04275/0004800001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04275/0004800002.png\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: HASH -<br><br>Box 2: OrderDateKey -<br>In most cases, table partitions are created on a date column.<br>A way to eliminate rollbacks is to use Metadata Only operations like partition switching for data management. For example, rather than execute a DELETE statement to delete all rows in a table where the order_date was in October of 2001, you could partition your data early. Then you can switch out the partition with data for an empty partition from another table.<br>Reference:<br>https://docs.microsoft.com/en-us/sql/t-sql/statements/create-table-azure-sql-data-warehouse https://docs.microsoft.com/en-us/azure/synapse-analytics/sql/best-practices-dedicated-sql-pool",
    "votes": [],
    "comments": [
      {
        "date": "2024-09-20T00:21:00.000Z",
        "voteCount": 10,
        "content": "The provided answer is correct."
      },
      {
        "date": "2024-09-25T23:16:00.000Z",
        "voteCount": 5,
        "content": "I agree.\n\nHere is an example from MS:\n\nCREATE TABLE myTable (  \n    l_orderkey      bigint,\n    l_partkey       bigint,\n    l_suppkey       bigint,\n    l_shipinstruct  char(25),  \n    l_shipmode      char(10),  \n    l_comment       varchar(44))  \nWITH\n  (\n    DISTRIBUTION = HASH (l_orderkey),  \n    CLUSTERED COLUMNSTORE INDEX,  \n    PARTITION ( l_shipdate  RANGE RIGHT FOR VALUES\n      (  \n        '1992-01-01','1992-02-01','1992-03-01','1992-04-01','1992-05-01',\n        '1992-06-01','1992-07-01','1992-08-01','1992-09-01','1992-10-01',\n        '1992-11-01','1992-12-01','1993-01-01','1993-02-01','1993-03-01'\n      ))\n  );"
      },
      {
        "date": "2021-10-11T15:37:00.000Z",
        "voteCount": 4,
        "content": "FYI\n\nDISTRIBUTION = HASH ( distribution_column_name ) Assigns each row to one distribution by hashing the value stored in distribution_column_name. The algorithm is deterministic, which means it always hashes the same value to the same distribution. The distribution column should be defined as NOT NULL because all rows that have NULL are assigned to the same distribution.\n\nDISTRIBUTION = ROUND_ROBIN Distributes the rows evenly across all the distributions in a round-robin fashion. This behavior is the default for Azure Synapse Analytics.\n\nDISTRIBUTION = REPLICATE Stores one copy of the table on each Compute node. For Azure Synapse Analytics the table is stored on a distribution database on each Compute node. For Analytics Platform System (PDW), the table is stored in a SQL Server filegroup that spans the Compute node. This behavior is the default for Analytics Platform System (PDW)."
      },
      {
        "date": "2021-08-28T11:11:00.000Z",
        "voteCount": 6,
        "content": "DISTRIBUTION = ROUND_ROBIN Distributes the rows evenly across all the distributions in a round-robin fashion. This behavior is the default for Azure Synapse Analytics."
      },
      {
        "date": "2021-12-06T09:22:00.000Z",
        "voteCount": 2,
        "content": "distribution in a column just in hash"
      },
      {
        "date": "2021-11-18T16:20:00.000Z",
        "voteCount": 3,
        "content": "is part of DP-300?"
      },
      {
        "date": "2021-10-28T17:03:00.000Z",
        "voteCount": 2,
        "content": "from what i read \nfact = hash\ndimensions = round robin"
      },
      {
        "date": "2021-09-27T05:51:00.000Z",
        "voteCount": 5,
        "content": "(distribution_column_name) is only available in HASH\nhttps://docs.microsoft.com/en-us/sql/t-sql/statements/create-table-azure-sql-data-warehouse?view=aps-pdw-2016-au7"
      },
      {
        "date": "2021-09-14T19:03:00.000Z",
        "voteCount": 1,
        "content": "By default, tables are Round Robin distributed. This default makes it easy for users to start creating tables without having to decide how their tables should be distributed. Round Robin tables may perform sufficiently for some workloads. But, in most cases, a distribution column provides better performance.\n\nThe most common example of a table distributed by a column outperforming a Round Robin table is when two large fact tables are joined."
      },
      {
        "date": "2021-09-14T18:13:00.000Z",
        "voteCount": 1,
        "content": "A round-robin distributed table distributes table rows evenly across all distributions. The assignment of rows to distributions is random. Unlike hash-distributed tables, rows with equal values are not guaranteed to be assigned to the same distribution."
      },
      {
        "date": "2021-08-30T07:06:00.000Z",
        "voteCount": 5,
        "content": "Is this a DP-300 question?"
      },
      {
        "date": "2021-11-18T16:17:00.000Z",
        "voteCount": 2,
        "content": "I would say no, what do you think?"
      },
      {
        "date": "2021-08-30T06:43:00.000Z",
        "voteCount": 3,
        "content": "The question requires to distribute evenly across \"partitions\". So it should be HASH."
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 16,
    "url": "https://www.examtopics.com/discussions/microsoft/view/63441-exam-dp-300-topic-1-question-16-discussion/",
    "body": "You have an Azure Synapse Analytics workspace named WS1 that contains an Apache Spark pool named Pool1.<br>You plan to create a database named DB1 in Pool1.<br>You need to ensure that when tables are created in DB1, the tables are available automatically as external tables to the built-in serverless SQL pool.<br>Which format should you use for the tables in DB1?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tJSON",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCSV",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tParquet\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tORC"
    ],
    "answer": "C",
    "answerDescription": "Serverless SQL pool can automatically synchronize metadata from Apache Spark. A serverless SQL pool database will be created for each database existing in serverless Apache Spark pools.<br>For each Spark external table based on Parquet and located in Azure Storage, an external table is created in a serverless SQL pool database. As such, you can shut down your Spark pools and still query Spark external tables from serverless SQL pool.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/synapse-analytics/sql/develop-storage-files-spark-tables",
    "votes": [
      {
        "answer": "C",
        "count": 2,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-10-05T01:54:00.000Z",
        "voteCount": 11,
        "content": "Azure Synapse is not part of DP-300"
      },
      {
        "date": "2023-08-01T05:07:00.000Z",
        "voteCount": 1,
        "content": "To ensure that tables created in DB1 are available automatically as external tables to the built-in serverless SQL pool in Azure Synapse Analytics, you should use format C. Parquet.\n\nParquet is a columnar storage file format that is well-suited for big data processing frameworks like Apache Spark and is natively supported by Azure Synapse Analytics. When you create tables in DB1 using the Parquet format, the data can be directly accessed by the serverless SQL pool without requiring additional data movement or conversion.\n\nBy using Parquet as the format, you enable seamless integration between the Apache Spark pool (Pool1) and the serverless SQL pool, allowing both to work with the same data without any extra configuration or manual steps.\n\nOption A (JSON), Option B (CSV), and Option D (ORC) are valid file formats, but for the given scenario where you want to automatically access data from DB1 in the serverless SQL pool, Parquet is the most appropriate choice due to its native support in Azure Synapse Analytics."
      },
      {
        "date": "2023-05-22T17:59:00.000Z",
        "voteCount": 1,
        "content": "Parquet"
      },
      {
        "date": "2022-06-23T06:06:00.000Z",
        "voteCount": 2,
        "content": "Actually , both  B/CSV and C/Parquet are correct, because for each Spark external table based on Parquet or CSV and located in Azure Storage, an external table is created in a serverless SQL pool database."
      },
      {
        "date": "2021-12-01T12:09:00.000Z",
        "voteCount": 2,
        "content": "For each Spark external table based on Parquet or CSV and located in Azure Storage, an external table is created in a serverless SQL pool database. As such, you can shut down your Spark pools and still query Spark external tables from serverless SQL pool."
      },
      {
        "date": "2021-10-27T04:37:00.000Z",
        "voteCount": 1,
        "content": "Again Please fix this...."
      },
      {
        "date": "2021-10-01T13:03:00.000Z",
        "voteCount": 1,
        "content": "Is it correct?"
      },
      {
        "date": "2021-10-05T21:43:00.000Z",
        "voteCount": 5,
        "content": "Yes, The Answer is correct."
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 17,
    "url": "https://www.examtopics.com/discussions/microsoft/view/60371-exam-dp-300-topic-1-question-17-discussion/",
    "body": "You are designing an anomaly detection solution for streaming data from an Azure IoT hub. The solution must meet the following requirements:<br>\u2711 Send the output to an Azure Synapse.<br>\u2711 Identify spikes and dips in time series data.<br>\u2711 Minimize development and configuration effort.<br>Which should you include in the solution?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure SQL Database",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure Databricks",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure Stream Analytics\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "C",
    "answerDescription": "Anomalies can be identified by routing data via IoT Hub to a built-in ML model in Azure Stream Analytics<br>Reference:<br>https://docs.microsoft.com/en-us/learn/modules/data-anomaly-detection-using-azure-iot-hub/ https://docs.microsoft.com/en-us/azure/stream-analytics/azure-synapse-analytics-output",
    "votes": [
      {
        "answer": "C",
        "count": 1,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-08-23T04:27:00.000Z",
        "voteCount": 20,
        "content": "Question FOR DP-203 , Not For DBA (DP-300)"
      },
      {
        "date": "2023-05-22T18:07:00.000Z",
        "voteCount": 1,
        "content": "See gt002's explaination."
      },
      {
        "date": "2022-04-09T17:21:00.000Z",
        "voteCount": 2,
        "content": "a lot of questions are not for DP-300.  More for Data Engineer or Data Analytics"
      },
      {
        "date": "2021-12-20T23:01:00.000Z",
        "voteCount": 4,
        "content": "ANSWER CORRECT:  Azure Stream Analytics\n\nAzure Stream Analytics Job - To create an Azure Stream Analytics job, follow the steps in the Get started using Azure Stream Analytics tutorial to:\n\nCreate an Event Hub input\nConfigure and start event generator application\nProvision a Stream Analytics job\nSpecify job input and query\nDedicated SQL pool - To create a new dedicated SQL pool, follow the steps in the Quickstart: Create a dedicated SQL pool.\nSpecify streaming output to point to your dedicated SQL pool"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 18,
    "url": "https://www.examtopics.com/discussions/microsoft/view/60372-exam-dp-300-topic-1-question-18-discussion/",
    "body": "You are creating a new notebook in Azure Databricks that will support R as the primary language but will also support Scala and SQL.<br>Which switch should you use to switch between languages?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\\\\[&lt;language&gt;]",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t%&lt;language&gt;\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\\\\[&lt;language&gt;]",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t@&lt;language&gt;"
    ],
    "answer": "B",
    "answerDescription": "You can override the default language by specifying the language magic command %&lt;language&gt; at the beginning of a cell. The supported magic commands are:<br>%python, %r, %scala, and %sql.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/databricks/notebooks/notebooks-use",
    "votes": [
      {
        "answer": "B",
        "count": 1,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-08-23T04:28:00.000Z",
        "voteCount": 22,
        "content": "Question FOR DP-203 , Not For DBA (DP-300)"
      },
      {
        "date": "2021-11-07T07:13:00.000Z",
        "voteCount": 7,
        "content": "Answer is  %&lt;language&gt;"
      },
      {
        "date": "2023-05-22T18:08:00.000Z",
        "voteCount": 1,
        "content": "%&lt;language&gt;"
      },
      {
        "date": "2022-07-08T05:58:00.000Z",
        "voteCount": 3,
        "content": "Are we sure that these questions do not appear in DP-300?"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 19,
    "url": "https://www.examtopics.com/discussions/microsoft/view/63470-exam-dp-300-topic-1-question-19-discussion/",
    "body": "DRAG DROP -<br>You are creating a managed data warehouse solution on Microsoft Azure.<br>You must use PolyBase to retrieve data from Azure Blob storage that resides in parquet format and load the data into a large table called FactSalesOrderDetails.<br>You need to configure Azure Synapse Analytics to receive the data.<br>Which four actions should you perform in sequence? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.<br>Select and Place:<br><img src=\"/assets/media/exam-media/04275/0005200001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04275/0005300001.png\" class=\"in-exam-image\">",
    "answerDescription": "To query the data in your Hadoop data source, you must define an external table to use in Transact-SQL queries. The following steps describe how to configure the external table.<br>Step 1: Create a master key on database.<br>1. Create a master key on the database. The master key is required to encrypt the credential secret.<br>(Create a database scoped credential for Azure blob storage.)<br>Step 2: Create an external data source for Azure Blob storage.<br>2. Create an external data source with CREATE EXTERNAL DATA SOURCE..<br>Step 3: Create an external file format to map the parquet files.<br>3. Create an external file format with CREATE EXTERNAL FILE FORMAT.<br>Step 4. Create an external table FactSalesOrderDetails<br>4. Create an external table pointing to data stored in Azure storage with CREATE EXTERNAL TABLE.<br>Reference:<br>https://docs.microsoft.com/en-us/sql/relational-databases/polybase/polybase-configure-azure-blob-storage",
    "votes": [],
    "comments": [
      {
        "date": "2022-11-13T04:04:00.000Z",
        "voteCount": 7,
        "content": "Question not for DP-300 exam."
      },
      {
        "date": "2022-09-01T02:15:00.000Z",
        "voteCount": 4,
        "content": "answer is correct. \n\nbelow video illustrate that:\nhttps://youtu.be/-DjOsJsIlA4?t=1266"
      },
      {
        "date": "2022-07-12T17:38:00.000Z",
        "voteCount": 1,
        "content": "The sequence is not complete\n\nWhat is the point of step #1 to create master key if there is no step #2 to create a credential?\n\nThe external data source requires a credential and not master key\nWithout the credential, the list does not make sense\n\nThe list Create a master key on the database\n\n\nCREATE DATABASE SCOPED CREDENTIAL AzureStorageCredential\nWITH IDENTITY = 'user', Secret = '&lt;azure_storage_account_key&gt;';"
      },
      {
        "date": "2022-02-08T00:02:00.000Z",
        "voteCount": 2,
        "content": "This is a DP-203 question."
      },
      {
        "date": "2021-10-02T04:45:00.000Z",
        "voteCount": 1,
        "content": "Is it correct?"
      },
      {
        "date": "2021-11-03T03:32:00.000Z",
        "voteCount": 3,
        "content": "Why dont you find out for yourself, and let us know."
      },
      {
        "date": "2021-10-11T18:28:00.000Z",
        "voteCount": 1,
        "content": "I think it is correct."
      },
      {
        "date": "2021-11-21T17:22:00.000Z",
        "voteCount": 4,
        "content": "its correct."
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 20,
    "url": "https://www.examtopics.com/discussions/microsoft/view/63471-exam-dp-300-topic-1-question-20-discussion/",
    "body": "HOTSPOT -<br>You configure version control for an Azure Data Factory instance as shown in the following exhibit.<br><img src=\"/assets/media/exam-media/04275/0005500001.png\" class=\"in-exam-image\"><br>Use the drop-down menus to select the answer choice that completes each statement based on the information presented in the graphic.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04275/0005600001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04275/0005600002.png\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: adf_publish -<br>By default, data factory generates the Resource Manager templates of the published factory and saves them into a branch called adf_publish. To configure a custom publish branch, add a publish_config.json file to the root folder in the collaboration branch. When publishing, ADF reads this file, looks for the field publishBranch, and saves all Resource Manager templates to the specified location. If the branch doesn't exist, data factory will automatically create it. And example of what this file looks like is below:<br>{<br>\"publishBranch\": \"factory/adf_publish\"<br>}<br>Box 2: /dwh_barchlet/ adf_publish/contososales<br>RepositoryName: Your Azure Repos code repository name. Azure Repos projects contain Git repositories to manage your source code as your project grows. You can create a new repository or use an existing repository that's already in your project.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/data-factory/source-control",
    "votes": [],
    "comments": [
      {
        "date": "2021-10-02T04:46:00.000Z",
        "voteCount": 1,
        "content": "Is it correct?"
      },
      {
        "date": "2021-11-02T08:03:00.000Z",
        "voteCount": 9,
        "content": "Yea it is, I checked the reference!"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 21,
    "url": "https://www.examtopics.com/discussions/microsoft/view/60855-exam-dp-300-topic-1-question-21-discussion/",
    "body": "You plan to build a structured streaming solution in Azure Databricks. The solution will count new events in five-minute intervals and report only events that arrive during the interval.<br>The output will be sent to a Delta Lake table.<br>Which output mode should you use?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tcomplete",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tappend\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tupdate"
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 8,
        "isMostVoted": true
      },
      {
        "answer": "A",
        "count": 4,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2024-09-24T07:56:00.000Z",
        "voteCount": 1,
        "content": "\u2022\tAppend Mode: Outputs only the new rows added during each trigger (i.e., each 5-minute interval in this case). This is ideal when you're continuously adding new records to the destination (e.g., a Delta Lake table) without updating existing data."
      },
      {
        "date": "2022-09-01T02:29:00.000Z",
        "voteCount": 1,
        "content": "In question not mentioned that we need to keep old data.  so the correct answer should be A"
      },
      {
        "date": "2023-05-25T17:29:00.000Z",
        "voteCount": 1,
        "content": "Why would you use a data lake if you do not want to keep old data?"
      },
      {
        "date": "2022-08-26T01:23:00.000Z",
        "voteCount": 2,
        "content": "The answer is append"
      },
      {
        "date": "2022-07-21T20:17:00.000Z",
        "voteCount": 3,
        "content": "Solution is 'Complete'. The Question stated - \"will count new events in five-minute intervals and report only events that arrive during the interval. - Says 'NEW' events and 'ONLY ARRIVE DURING THE 5min INTERVAL' - so it can't be append because that would just add new data to the old data."
      },
      {
        "date": "2023-07-12T06:52:00.000Z",
        "voteCount": 1,
        "content": "This is correct. Only events that arrive during the 5 minutes interval are kept. A is correct."
      },
      {
        "date": "2022-04-28T13:54:00.000Z",
        "voteCount": 2,
        "content": "The preceding example continuously updates a table that contains the aggregate number of events by customer."
      },
      {
        "date": "2022-03-12T01:58:00.000Z",
        "voteCount": 1,
        "content": "Complete - The question doesn't state we need to keep existing data, only that we need from the given interval."
      },
      {
        "date": "2022-02-20T15:38:00.000Z",
        "voteCount": 2,
        "content": "Append"
      },
      {
        "date": "2022-01-30T20:11:00.000Z",
        "voteCount": 2,
        "content": "Append is the answer"
      },
      {
        "date": "2021-12-14T01:44:00.000Z",
        "voteCount": 1,
        "content": "I think append"
      },
      {
        "date": "2021-12-07T08:58:00.000Z",
        "voteCount": 2,
        "content": "complete - You can also use Structured Streaming to replace the entire table with every batch. One example use case is to compute a summary using aggregation\n\nhttps://docs.databricks.com/delta/delta-streaming.html"
      },
      {
        "date": "2021-12-05T01:24:00.000Z",
        "voteCount": 1,
        "content": "https://docs.microsoft.com/en-us/azure/databricks/getting-started/spark/streaming\nAppend Mode: Only new rows appended in the result table since the last trigger are written to external storage. This is applicable only for the queries where existing rows in the Result Table are not expected to change\nThen must be complete. append is if the table is static, with few changes."
      },
      {
        "date": "2021-11-18T08:56:00.000Z",
        "voteCount": 2,
        "content": "it should be append"
      },
      {
        "date": "2021-12-07T08:50:00.000Z",
        "voteCount": 1,
        "content": "why?  it should be complete because you just want to report events that happen in those 5 five minute intervals, you dont want data from the window of 10 minutes ago neither 15 minutes ago. so you replace the entire table to achieve that and it is more straight forward"
      },
      {
        "date": "2021-09-14T23:58:00.000Z",
        "voteCount": 4,
        "content": "The answer is correct."
      },
      {
        "date": "2021-09-01T07:57:00.000Z",
        "voteCount": 1,
        "content": "Which is the correct answer? I think complete as the question do not ask to add new recrods."
      },
      {
        "date": "2021-08-30T07:03:00.000Z",
        "voteCount": 2,
        "content": "compete mode is correct. It requires count but not add a new record."
      },
      {
        "date": "2021-08-27T06:00:00.000Z",
        "voteCount": 1,
        "content": "Correc answer is B - Append"
      },
      {
        "date": "2021-12-07T08:51:00.000Z",
        "voteCount": 1,
        "content": "why? it should be complete because you just want to report events that happen in those 5 minute intervals, you dont want data from the window of 10 minutes ago neither 15 minutes ago. so you replace the entire table to achieve that and it is more straight forward"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 22,
    "url": "https://www.examtopics.com/discussions/microsoft/view/60331-exam-dp-300-topic-1-question-22-discussion/",
    "body": "HOTSPOT -<br>You are performing exploratory analysis of bus fare data in an Azure Data Lake Storage Gen2 account by using an Azure Synapse Analytics serverless SQL pool.<br>You execute the Transact-SQL query shown in the following exhibit.<br><img src=\"/assets/media/exam-media/04275/0005800001.png\" class=\"in-exam-image\"><br>Use the drop-down menus to select the answer choice that completes each statement based on the information presented in the graphic.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04275/0005900001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04275/0005900002.png\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: CSV files that have file named beginning with \"tripdata_2020\"<br><br>Box 2: a header -<br>FIRSTROW = 'first_row'<br>Specifies the number of the first row to load. The default is 1 and indicates the first row in the specified data file. The row numbers are determined by counting the row terminators. FIRSTROW is 1-based.<br>Example: Option firstrow is used to skip the first row in the CSV file that represents header in this case (firstrow=2). select top 10 * from openrowset( bulk 'https://pandemicdatalake.blob.core.windows.net/public/curated/covid-19/ecdc_cases/latest/ecdc_cases.csv', format = 'csv', parser_version = '2.0', firstrow = 2 ) as rows<br>Reference:<br>https://docs.microsoft.com/en-us/azure/synapse-analytics/sql/develop-openrowset https://docs.microsoft.com/en-us/azure/synapse-analytics/sql/query-single-csv-file",
    "votes": [],
    "comments": [
      {
        "date": "2022-02-08T00:03:00.000Z",
        "voteCount": 10,
        "content": "This is a DP-203 question."
      },
      {
        "date": "2021-09-18T20:22:00.000Z",
        "voteCount": 9,
        "content": "The provided answer is correct."
      },
      {
        "date": "2022-10-13T08:20:00.000Z",
        "voteCount": 1,
        "content": "Exam DP-203: Data Engineering on Microsoft Azure"
      },
      {
        "date": "2022-10-18T13:04:00.000Z",
        "voteCount": 1,
        "content": "if it is a DP-203 question, is a question like this still on the DP-300 Exam?"
      },
      {
        "date": "2022-11-30T10:51:00.000Z",
        "voteCount": 1,
        "content": "Azure Data Lake Storage questions are not present in the MeasureUp practice test, and also in the DP-300 documentation."
      },
      {
        "date": "2022-08-02T03:28:00.000Z",
        "voteCount": 1,
        "content": "The answer is correct"
      },
      {
        "date": "2021-12-04T12:08:00.000Z",
        "voteCount": 1,
        "content": "I would go with header. In all examples I've seen from ms they use first_row=2 when there is a header row, which is not used.\nhttps://docs.microsoft.com/en-us/azure/synapse-analytics/sql/query-single-csv-file"
      },
      {
        "date": "2021-11-18T16:07:00.000Z",
        "voteCount": 1,
        "content": "2da- a data, \nits ok?"
      },
      {
        "date": "2021-08-23T00:13:00.000Z",
        "voteCount": 1,
        "content": "2nd one should be a data\nhttps://docs.microsoft.com/en-us/sql/t-sql/functions/openrowset-transact-sql?view=sql-server-ver15"
      },
      {
        "date": "2021-08-24T01:50:00.000Z",
        "voteCount": 2,
        "content": "the query stated to start from 2nd row, so the first row should be header (and therefore discarded) and 2nd the data - just my opinion"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 23,
    "url": "https://www.examtopics.com/discussions/microsoft/view/60273-exam-dp-300-topic-1-question-23-discussion/",
    "body": "You have a SQL pool in Azure Synapse that contains a table named dbo.Customers. The table contains a column name Email.<br>You need to prevent nonadministrative users from seeing the full email addresses in the Email column. The users must see values in a format of aXXX@XXXX.com instead.<br>What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tFrom the Azure portal, set a mask on the Email column.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tFrom the Azure portal, set a sensitivity classification of Confidential for the Email column.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tFrom Microsoft SQL Server Management Studio, set an email mask on the Email column.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tFrom Microsoft SQL Server Management Studio, grant the SELECT permission to the users for all the columns in the dbo.Customers table except Email."
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 23,
        "isMostVoted": true
      },
      {
        "answer": "C",
        "count": 3,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2021-11-26T01:09:00.000Z",
        "voteCount": 14,
        "content": "correct answer is A: you need to mask the email."
      },
      {
        "date": "2023-01-30T00:19:00.000Z",
        "voteCount": 2,
        "content": "https://learn.microsoft.com/en-us/azure/azure-sql/database/dynamic-data-masking-overview?view=azuresql"
      },
      {
        "date": "2021-09-15T01:08:00.000Z",
        "voteCount": 7,
        "content": "The correct answer is A"
      },
      {
        "date": "2021-11-04T04:17:00.000Z",
        "voteCount": 7,
        "content": "Yep A\nYou set up a dynamic data masking policy in the Azure portal by selecting the Dynamic Data Masking blade under Security in your SQL Database configuration pane. This feature cannot be set using portal for SQL Managed Instance. For more information, see Dynamic Data Masking.\nhttps://docs.microsoft.com/en-us/azure/azure-sql/database/dynamic-data-masking-overview"
      },
      {
        "date": "2023-09-15T08:43:00.000Z",
        "voteCount": 2,
        "content": "reference: https://www.examtopics.com/discussions/microsoft/view/36123-exam-dp-200-topic-3-question-4-discussion/\nThe answer should be C. The key word is \"a SQL pool in Azure Synapse\". Dynamic data masking does not apply to it. (So we can't achieve this  from the Azure portal.)"
      },
      {
        "date": "2023-08-29T14:16:00.000Z",
        "voteCount": 4,
        "content": "This is a DP-203 question. Azure Synapse Analytics is not part of the DP-300 curriculum."
      },
      {
        "date": "2023-08-03T08:24:00.000Z",
        "voteCount": 1,
        "content": "The correct option is A. From the Azure portal, set a mask on the Email column.\n\nBy setting a mask on the Email column, you can control the way sensitive data is displayed to non-administrative users. The mask allows you to show a modified version of the data while keeping the original data secure. In this case, you can configure the mask to display the email addresses in the format of aXXX@XXXX.com as required.\n\nOption B, setting a sensitivity classification of Confidential for the Email column, is not the most appropriate choice for this scenario. While sensitivity classifications can be used to label data and apply policies, they do not directly handle the masking of data for display purposes.\n\nOptions C and D, setting an email mask from Microsoft SQL Server Management Studio or granting SELECT permission to users for all columns except Email, are not correct because they both involve implementing security measures at the database level, but they do not specifically address the data masking requirement for displaying the email addresses in the desired format."
      },
      {
        "date": "2023-04-25T10:09:00.000Z",
        "voteCount": 2,
        "content": "according to this article you can do it in portal.  so my take is A\nhttps://www.sqlshack.com/dynamic-data-masking-in-azure-synapse-analytics/"
      },
      {
        "date": "2023-01-12T01:15:00.000Z",
        "voteCount": 2,
        "content": "Dynamic Masking"
      },
      {
        "date": "2023-01-12T00:40:00.000Z",
        "voteCount": 2,
        "content": "A and B can both work, however, I would select C since A doesn't describe the type of mask. It needs to be email mask on the email column.\nIf you apply dynamic data from Azure portal, and you don\u00b4t specify the type of mask, it will detect the type of the column to apply the mask, so in this case, it applies the default mask for a column type as varchar therefore it is not applying  an email mask  type"
      },
      {
        "date": "2023-01-08T05:19:00.000Z",
        "voteCount": 1,
        "content": "Dynamic Data Masking in the Azure portal is support for SQL DB and Synapse Analytics, just not for Managed Instance.\n\nhttps://www.sqlshack.com/dynamic-data-masking-in-azure-synapse-analytics/"
      },
      {
        "date": "2023-01-08T03:26:00.000Z",
        "voteCount": 2,
        "content": "C is not supported for Azure Synapse."
      },
      {
        "date": "2022-11-12T02:49:00.000Z",
        "voteCount": 1,
        "content": "You set up a dynamic data masking policy in the Azure portal by selecting the Dynamic Data Masking blade under Security in your SQL Database configuration pane. This feature cannot be set using portal for SQL Managed Instance."
      },
      {
        "date": "2022-07-21T20:32:00.000Z",
        "voteCount": 2,
        "content": "A - set a mask"
      },
      {
        "date": "2022-07-08T20:35:00.000Z",
        "voteCount": 1,
        "content": "The question is on masking the data."
      },
      {
        "date": "2022-07-08T06:21:00.000Z",
        "voteCount": 1,
        "content": "Correct answer is A. The question is on masking not classifying."
      },
      {
        "date": "2022-06-28T02:42:00.000Z",
        "voteCount": 2,
        "content": "This question is play on words as they want to know HOW you will PREVENT NONADMINISTRATIVE USERS from SEEING the ENAIL COLOMB and not how to hide the email colomb data itself."
      },
      {
        "date": "2022-05-20T01:11:00.000Z",
        "voteCount": 3,
        "content": "More specific than A"
      },
      {
        "date": "2022-02-25T07:47:00.000Z",
        "voteCount": 1,
        "content": "verified in AZ"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 24,
    "url": "https://www.examtopics.com/discussions/microsoft/view/66307-exam-dp-300-topic-1-question-24-discussion/",
    "body": "You have an Azure Databricks workspace named workspace1 in the Standard pricing tier. Workspace1 contains an all-purpose cluster named cluster1.<br>You need to reduce the time it takes for cluster1 to start and scale up. The solution must minimize costs.<br>What should you do first?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUpgrade workspace1 to the Premium pricing tier.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure a global init script for workspace1.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a pool in workspace1.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a cluster policy in workspace1."
    ],
    "answer": "C",
    "answerDescription": "You can use Databricks Pools to Speed up your Data Pipelines and Scale Clusters Quickly.<br>Databricks Pools, a managed cache of virtual machine instances that enables clusters to start and scale 4 times faster.<br>Reference:<br>https://databricks.com/blog/2019/11/11/databricks-pools-speed-up-data-pipelines.html",
    "votes": [],
    "comments": [
      {
        "date": "2022-10-13T08:34:00.000Z",
        "voteCount": 6,
        "content": "Exam DP-203: Data Engineering on Microsoft Azure"
      },
      {
        "date": "2021-11-18T14:19:00.000Z",
        "voteCount": 4,
        "content": "looks correct"
      },
      {
        "date": "2021-11-21T17:26:00.000Z",
        "voteCount": 1,
        "content": "its correct."
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 25,
    "url": "https://www.examtopics.com/discussions/microsoft/view/66264-exam-dp-300-topic-1-question-25-discussion/",
    "body": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.<br>After you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.<br>You have an Azure Synapse Analytics dedicated SQL pool that contains a table named Table1.<br>You have files that are ingested and loaded into an Azure Data Lake Storage Gen2 container named container1.<br>You plan to insert data from the files into Table1 and transform the data. Each row of data in the files will produce one row in the serving layer of Table1.<br>You need to ensure that when the source data files are loaded to container1, the DateTime is stored as an additional column in Table1.<br>Solution: In an Azure Synapse Analytics pipeline, you use a Get Metadata activity that retrieves the DateTime of the files.<br>Does this meet the goal?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tYes\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tNo"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 6,
        "isMostVoted": true
      },
      {
        "answer": "B",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2022-02-08T01:20:00.000Z",
        "voteCount": 11,
        "content": "This is a DP-203 question."
      },
      {
        "date": "2024-06-30T16:21:00.000Z",
        "voteCount": 1,
        "content": "Its DP 203. Though answer will be NO. I got this question and passed with very very high score."
      },
      {
        "date": "2022-02-23T12:28:00.000Z",
        "voteCount": 6,
        "content": "Yes, Get Metadata can be used to retrieve the DateTime of the files and allow you to use this data. The question is to add it to Table1, not to an external table."
      },
      {
        "date": "2024-09-24T08:07:00.000Z",
        "voteCount": 1,
        "content": "No - , retrieving the DateTime alone doesn't meet the goal unless the DateTime is also incorporated into the process that inserts the data into the table"
      },
      {
        "date": "2024-06-04T16:28:00.000Z",
        "voteCount": 1,
        "content": "Agree with B, seems incomplete"
      },
      {
        "date": "2023-04-09T19:18:00.000Z",
        "voteCount": 1,
        "content": "Using a Get Metadata activity in an Azure Synapse Analytics pipeline to retrieve the DateTime of the files will not directly ensure that the DateTime is stored as an additional column in Table1. The Get Metadata activity only retrieves metadata information about the files, such as their names, size, and date created or modified.\n\nTo achieve the goal of storing the DateTime as an additional column in Table1, you would need to use other pipeline activities, such as a Data Flow or a Copy activity, to extract data from the files, transform it as necessary, and load it into Table1. During this process, you could use derived columns or mappings to add the DateTime column and populate it with the appropriate values.\n\nTherefore, B is the correct answer."
      },
      {
        "date": "2022-10-13T08:36:00.000Z",
        "voteCount": 1,
        "content": "Exam DP-203: Data Engineering on Microsoft Azure"
      },
      {
        "date": "2022-06-23T06:48:00.000Z",
        "voteCount": 4,
        "content": "Get Metadata activity retrieves the DateTime of the files but it does not create a column in Table1, so answer is B"
      },
      {
        "date": "2022-05-29T08:58:00.000Z",
        "voteCount": 1,
        "content": "Not sure if the answer is Yes. However, the explanation makes absolutely no sense. \n\nWe want to load data into our SQL Pools, why would we load the data in our SQL serverless pools? :-/ \n\nUsing metadata activity might be PART of a solution but in itself does not give a complete indication of what the solution should be."
      },
      {
        "date": "2021-11-17T17:08:00.000Z",
        "voteCount": 3,
        "content": "Answer looks correct"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 26,
    "url": "https://www.examtopics.com/discussions/microsoft/view/66265-exam-dp-300-topic-1-question-26-discussion/",
    "body": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.<br>After you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.<br>You have an Azure Synapse Analytics dedicated SQL pool that contains a table named Table1.<br>You have files that are ingested and loaded into an Azure Data Lake Storage Gen2 container named container1.<br>You plan to insert data from the files into Table1 and transform the data. Each row of data in the files will produce one row in the serving layer of Table1.<br>You need to ensure that when the source data files are loaded to container1, the DateTime is stored as an additional column in Table1.<br>Solution: You use an Azure Synapse Analytics serverless SQL pool to create an external table that has an additional DateTime column.<br>Does this meet the goal?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tYes",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tNo\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 3,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-11-17T17:08:00.000Z",
        "voteCount": 5,
        "content": "Answer looks correct"
      },
      {
        "date": "2022-10-13T08:38:00.000Z",
        "voteCount": 3,
        "content": "Exam DP-203: Data Engineering on Microsoft Azure"
      },
      {
        "date": "2022-09-12T00:02:00.000Z",
        "voteCount": 1,
        "content": "Answer is A\n\n\"An external table points to data located in Hadoop, Azure Storage blob, or Azure Data Lake Storage. External tables are used to read data from files or write data to files in Azure Storage. With Synapse SQL, you can use external tables to read external data using dedicated SQL pool or serverless SQL pool.\"\nhttps://docs.microsoft.com/en-us/azure/synapse-analytics/sql/develop-tables-external-tables?tabs=hadoop"
      },
      {
        "date": "2022-06-23T07:01:00.000Z",
        "voteCount": 1,
        "content": "Answer B\n\n\n\"The column definitions, including the data types and number of columns, must match the data in the external files. If there's a mismatch, the file rows will be rejected when querying the actual data\"\n\nhttps://docs.microsoft.com/en-us/sql/t-sql/statements/create-external-table-transact-sql?view=azure-sqldw-latest&amp;preserve-view=true&amp;tabs=dedicated"
      },
      {
        "date": "2022-05-02T18:16:00.000Z",
        "voteCount": 2,
        "content": "this is not for DP-300 exam"
      },
      {
        "date": "2022-02-23T12:28:00.000Z",
        "voteCount": 3,
        "content": "No, Get Metadata can be used to retrieve the DateTime of the files and allow you to use this data. The question is to add it to Table1, not to an external table."
      },
      {
        "date": "2022-02-08T01:20:00.000Z",
        "voteCount": 3,
        "content": "This is a DP-203 question."
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 27,
    "url": "https://www.examtopics.com/discussions/microsoft/view/63619-exam-dp-300-topic-1-question-27-discussion/",
    "body": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.<br>After you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.<br>You have an Azure Synapse Analytics dedicated SQL pool that contains a table named Table1.<br>You have files that are ingested and loaded into an Azure Data Lake Storage Gen2 container named container1.<br>You plan to insert data from the files into Table1 and transform the data. Each row of data in the files will produce one row in the serving layer of Table1.<br>You need to ensure that when the source data files are loaded to container1, the DateTime is stored as an additional column in Table1.<br>Solution: You use a dedicated SQL pool to create an external table that has an additional DateTime column.<br>Does this meet the goal?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tYes",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tNo"
    ],
    "answer": "B",
    "answerDescription": "Instead, in an Azure Synapse Analytics pipeline, you use a Get Metadata activity that retrieves the DateTime of the files.<br>Note: You can use the Get Metadata activity to retrieve the metadata of any data in Azure Data Factory or a Synapse pipeline. You can use the output from the<br>Get Metadata activity in conditional expressions to perform validation, or consume the metadata in subsequent activities.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/data-factory/control-flow-get-metadata-activity",
    "votes": [],
    "comments": [
      {
        "date": "2021-10-05T02:02:00.000Z",
        "voteCount": 13,
        "content": "Azure Synapse Analytics  is NOT part of DP-300"
      },
      {
        "date": "2022-03-31T10:39:00.000Z",
        "voteCount": 3,
        "content": "Exactly. Too many questions here are for DP-203"
      },
      {
        "date": "2022-10-13T08:39:00.000Z",
        "voteCount": 2,
        "content": "Exam DP-203: Data Engineering on Microsoft Azure"
      },
      {
        "date": "2022-06-23T07:09:00.000Z",
        "voteCount": 1,
        "content": "Answer B\n\nCannot be done in serverless or dedicated, for the same reason\n\n\n\"The column definitions, including the data types and number of columns, must match the data in the external files. If there's a mismatch, the file rows will be rejected when querying the actual data\"\n\nhttps://docs.microsoft.com/en-us/sql/t-sql/statements/create-external-table-transact-sql?view=azure-sqldw-latest&amp;preserve-view=true&amp;tabs=dedicated"
      },
      {
        "date": "2021-11-21T18:25:00.000Z",
        "voteCount": 3,
        "content": "The answer looks right"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 28,
    "url": "https://www.examtopics.com/discussions/microsoft/view/60475-exam-dp-300-topic-1-question-28-discussion/",
    "body": "HOTSPOT -<br>You are provisioning an Azure SQL database in the Azure portal as shown in the following exhibit.<br><img src=\"/assets/media/exam-media/04275/0006400001.jpg\" class=\"in-exam-image\"><br>Use the drop-down menus to select the answer choice that completes each statement based on the information presented in the graphic.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04275/0006500001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04275/0006500002.png\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: no extra time -<br>Auto Pause is not checked in the exhibit.<br>Note: If Auto Pause is checked the correct answer is: up to one minute<br>Box 2: intermittent and unpredictable<br>Reference:<br>https://docs.microsoft.com/en-us/azure/azure-sql/database/serverless-tier-overview",
    "votes": [],
    "comments": [
      {
        "date": "2021-08-28T12:30:00.000Z",
        "voteCount": 28,
        "content": "Should be No Extra Time, screenshot shows Enable Auto Pause is unchecked.. so there is no pausing at all.  On idle, server will run at min vcore setting.  Second option is intermittent load as indicated by max and min vcore settings which is only available on serverless compute option."
      },
      {
        "date": "2021-09-27T13:25:00.000Z",
        "voteCount": 1,
        "content": "Thank you."
      },
      {
        "date": "2023-08-29T14:23:00.000Z",
        "voteCount": 10,
        "content": "This one is a DP-300 question. Yes it's real! :D"
      },
      {
        "date": "2022-03-07T20:57:00.000Z",
        "voteCount": 1,
        "content": "No Extra Time"
      },
      {
        "date": "2021-12-30T05:21:00.000Z",
        "voteCount": 9,
        "content": "Just done exam and auto pause delay was checked"
      },
      {
        "date": "2021-12-16T19:27:00.000Z",
        "voteCount": 1,
        "content": "The latency to auto-resume and auto-pause a serverless database is generally order of 1 minute to auto-resume and 1-10 minutes after the expiration of the delay period to auto-pause."
      },
      {
        "date": "2021-11-16T09:34:00.000Z",
        "voteCount": 2,
        "content": "Should be up to 10 mins. \n\n\"The latency to auto-resume and auto-pause a serverless database is generally order of 1 minute to auto-resume and 1-10 minutes after the expiration of the delay period to auto-pause.\" \nhttps://docs.microsoft.com/en-us/azure/azure-sql/database/serverless-tier-overview\n\nThe default value for Autopause is 60 mins. In this scenario, auto-pause is not enabled -&gt; default. After 4 hrs of inactivity, the database require \"up to 10 mins\" to resume operations for new activities.\n\nAzure SQL Database serverless is a compute tier that will automatically scale up or down the resources for a given database based on demand. If the workload no longer requires compute resources, the database will become \u201cpaused\u201d and you will not be charged during the period when the database is in this state. When a connection attempt is made, the database will \u201cresume\u201d and become available. Resuming the database is not instantaneous."
      },
      {
        "date": "2024-07-28T06:49:00.000Z",
        "voteCount": 1,
        "content": "If to assume that the checkbox is ticked, according to link that you provided it will take 1 min to resume the database.\n10 minutes is what it takes to pause the database when 4 hours of idle happen. Dont mix these two"
      },
      {
        "date": "2021-12-03T09:30:00.000Z",
        "voteCount": 5,
        "content": "Pls ignore. Should be No Extra Time."
      },
      {
        "date": "2021-09-15T01:21:00.000Z",
        "voteCount": 4,
        "content": "The correct answer is no extra time"
      },
      {
        "date": "2021-08-28T12:45:00.000Z",
        "voteCount": 9,
        "content": "Auto-pause is not enabled in this case:\nThe latency to auto-resume and auto-pause a serverless database is generally order of 1 minute to auto-resume and 1-10 minutes after the expiration of the delay period to auto-pause."
      },
      {
        "date": "2021-08-24T01:57:00.000Z",
        "voteCount": 4,
        "content": "The database resumes when activity occurs, why isn't the correct answer the first (no extra time)?"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 29,
    "url": "https://www.examtopics.com/discussions/microsoft/view/77350-exam-dp-300-topic-1-question-29-discussion/",
    "body": "You plan to deploy an app that includes an Azure SQL database and an Azure web app. The app has the following requirements:<br>\u2711 The web app must be hosted on an Azure virtual network.<br>\u2711 The Azure SQL database must be assigned a private IP address.<br>\u2711 The Azure SQL database must allow connections only from a specific virtual network.<br>You need to recommend a solution that meets the requirements.<br>What should you include in the recommendation?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure Private Link\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ta network security group (NSG)",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ta database-level firewall",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ta server-level firewall"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 3,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-09-24T08:21:00.000Z",
        "voteCount": 1,
        "content": "yup , A for sure"
      },
      {
        "date": "2024-08-02T13:30:00.000Z",
        "voteCount": 2,
        "content": "A is correct\nB NSG is used to control in and out traffic for Azure resources, not the private stuff\nC and D have nothing to do with controlling virtual networks"
      },
      {
        "date": "2023-06-19T17:41:00.000Z",
        "voteCount": 1,
        "content": "Private Link is the only option that meets all of the requirements."
      },
      {
        "date": "2022-10-13T08:44:00.000Z",
        "voteCount": 2,
        "content": "A is correct."
      },
      {
        "date": "2022-07-07T00:09:00.000Z",
        "voteCount": 3,
        "content": "Is this the correct answer?"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 30,
    "url": "https://www.examtopics.com/discussions/microsoft/view/62887-exam-dp-300-topic-1-question-30-discussion/",
    "body": "You are planning a solution that will use Azure SQL Database. Usage of the solution will peak from October 1 to January 1 each year.<br>During peak usage, the database will require the following:<br>\u2711 24 cores<br>\u2711 500 GB of storage<br>\u2711 124 GB of memory<br>\u2711 More than 50,000 IOPS<br>During periods of off-peak usage, the service tier of Azure SQL Database will be set to Standard.<br>Which service tier should you use during peak usage?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tBusiness Critical\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tPremium",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tHyperscale"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 10,
        "isMostVoted": true
      },
      {
        "answer": "B",
        "count": 6,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2021-10-07T23:24:00.000Z",
        "voteCount": 21,
        "content": "Correct answer Business critical"
      },
      {
        "date": "2023-08-29T14:29:00.000Z",
        "voteCount": 11,
        "content": "This is a question for DP-300 \ud83d\udc4d I hope we're good for the next questions now lol"
      },
      {
        "date": "2024-04-11T03:32:00.000Z",
        "voteCount": 2,
        "content": "Just a Note that while swapping between v-Core and DTU is permitted, it is not possible if the tier is using Hyperscale:\n\nhttps://learn.microsoft.com/en-us/azure/azure-sql/database/migrate-dtu-to-vcore?view=azuresql&amp;tabs=azure-portal#:~:text=A%20database%20migrated%20to%20the%20vCore%2Dbased%20purchasing%20model%20can%20be%20migrated%20back%20to%20the%20DTU%2Dbased%20purchasing%20model%20at%20any%20time%20using%20the%20same%20steps%2C%20except%20for%20databases%20migrated%20to%20the%20Hyperscale%20service%20tier.\n\nAnswer is correct, Business Critical"
      },
      {
        "date": "2023-08-31T10:49:00.000Z",
        "voteCount": 3,
        "content": "Answer is business Critical.  Requirements in question has specific CPU, memory and Storage during peak season and the ONLY option that meets this requirement is Vcore purchasing model --&gt; \"Business Critical Service Tier\". I know question says Azure database will be switched to \"Standard tier\" (DTU purchasing model) during OFF peak season. Its easy to swap between V core and DTU purchasing models without any downtime to Azure sql database, which meets requirements and makes the service tier change easy between Peak and OFF peak seasons. I Strongly agree the answer is \"Business Critical\". \nREASON I say \"Premium\" CANNOT be answer is because it is part of DTU purchasing model which makes it challenging to accommodate the requirement of specific CPU, memory and storage need during peak season because DTU model comes with resources that can be adjusted with predefined configuration which DOESNOT meet asked requirements in the question about CPU, RAM and Storage"
      },
      {
        "date": "2023-08-31T10:45:00.000Z",
        "voteCount": 2,
        "content": "as requirement has specific CPU, memory and Storage during peak hours, only option that meets this requirement is Vcore purchasing model --&gt; \"Business Critical Service Tier\". I know question says \"Standard tier\" (DTU purchasing model) when OFF peak season and as it's easy to swap between V core and DTU purchasing models without any downtime to Azure sql database, which meets requirements. I Strongly agree the answer is \"Business Critical\".   REASON I say \"Premium\" CANNOT  be answer is because it is part of DTU purchasing model which makes it challenging to accommodate the requirement of specific CPU, memory and storage need during peak season because DTU model comes with resources that can be adjusted with predefined configuration which DOESNOT meet asked requirements in question about CPU, RAM and Storage"
      },
      {
        "date": "2023-08-10T12:01:00.000Z",
        "voteCount": 2,
        "content": "In DTU option you can't choose vCores and memory. You can do that in Business Critical option only. Here you can see 24vCores and 124GB of RAM: https://azure.microsoft.com/en-us/pricing/details/azure-sql-database/single/"
      },
      {
        "date": "2023-08-08T02:59:00.000Z",
        "voteCount": 1,
        "content": "Business Critical is a feature of Premium tier. so correct answer is Premium."
      },
      {
        "date": "2023-07-17T20:05:00.000Z",
        "voteCount": 1,
        "content": "Since we can switch from vCore to DTU, any choice can be valid. Based on configuration, I think the service tier is Business Critical with minimum BC_Gen5_24"
      },
      {
        "date": "2023-07-17T20:06:00.000Z",
        "voteCount": 1,
        "content": "Also the peak time is not clear, but I assume the usage is 3 month (Oct - Jan) so vCore is better option than DTU"
      },
      {
        "date": "2023-06-12T05:52:00.000Z",
        "voteCount": 1,
        "content": "https://learn.microsoft.com/en-us/azure/azure-sql/database/service-tiers-dtu?view=azuresql"
      },
      {
        "date": "2023-04-25T10:24:00.000Z",
        "voteCount": 3,
        "content": "i think answer is correct, because only with vcore you can separately configure compute,storage etc(and here we have specific requirements for each resource). and you can easily switch between dtu and vcore back and forth"
      },
      {
        "date": "2023-02-10T02:26:00.000Z",
        "voteCount": 1,
        "content": "I think A"
      },
      {
        "date": "2022-09-10T09:40:00.000Z",
        "voteCount": 6,
        "content": "I believe that correct answer is A (Business critical in vCore purchasing model) because we have request to scale up and down not only in compute resources but also a storage which is available only vCore purchasing model. Hyperscale is not suits us well as well because it is reversable only within 45 days of the original migration to Hyperscale. Links https://docs.microsoft.com/en-us/azure/azure-sql/database/service-tiers-dtu?view=azuresql and https://docs.microsoft.com/en-us/azure/azure-sql/database/service-tier-hyperscale?view=azuresql"
      },
      {
        "date": "2022-07-08T20:38:00.000Z",
        "voteCount": 3,
        "content": "The answer is A"
      },
      {
        "date": "2022-07-08T06:37:00.000Z",
        "voteCount": 1,
        "content": "Migrate a database\nMigrating a database from the DTU-based purchasing model to the vCore-based purchasing model is similar to scaling between service objectives in the Basic, Standard, and Premium service tiers, with similar duration and a minimal downtime at the end of the migration process. A database migrated to the vCore-based purchasing model can be migrated back to the DTU-based purchasing model at any time in the same fashion, with the exception of databases migrated to the Hyperscale service tier.\n\nhttps://docs.microsoft.com/en-us/azure/azure-sql/database/migrate-dtu-to-vcore?view=azuresql"
      },
      {
        "date": "2022-01-28T03:58:00.000Z",
        "voteCount": 2,
        "content": "Business Critical tier is called Premium in the DTU purchasing model."
      },
      {
        "date": "2022-01-18T05:22:00.000Z",
        "voteCount": 5,
        "content": "U_C is correct. Answer is Premium."
      },
      {
        "date": "2022-01-28T03:58:00.000Z",
        "voteCount": 1,
        "content": "Business Critical tier is called Premium in the DTU purchasing model."
      },
      {
        "date": "2021-12-30T09:34:00.000Z",
        "voteCount": 9,
        "content": "I think the answer should be Premium which is in the DTU Purchase Model with \"Standard\". Business Critical is with General Purpose in vCore Purchase Model."
      },
      {
        "date": "2022-12-30T13:07:00.000Z",
        "voteCount": 3,
        "content": "Well, you can still change your service tier and select Business Critical."
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 31,
    "url": "https://www.examtopics.com/discussions/microsoft/view/62149-exam-dp-300-topic-1-question-31-discussion/",
    "body": "HOTSPOT -<br>You have an Azure subscription.<br>You need to deploy an Azure SQL resource that will support cross database queries by using an Azure Resource Manager (ARM) template.<br>How should you complete the ARM template? To answer, select the appropriate options in the answer area.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04275/0006800001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04275/0006900001.png\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: Microsoft.Sql/managedInstances<br>The Managed Instance depends on the Virtual Network.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/azure-sql/managed-instance/create-template-quickstart?tabs=azure-powershell",
    "votes": [],
    "comments": [
      {
        "date": "2022-03-07T03:05:00.000Z",
        "voteCount": 6,
        "content": "The answer is correct.\n\n{\n      \"type\": \"Microsoft.Sql/managedInstances\",\n      \"apiVersion\": \"2020-02-02-preview\",\n      \"name\": \"[parameters('managedInstanceName')]\",\n      \"location\": \"[parameters('location')]\",\n      \"dependsOn\": [\n        \"[resourceId('Microsoft.Network/virtualNetworks', parameters('virtualNetworkName'))]\"\n      ]\n    }"
      },
      {
        "date": "2022-03-09T00:31:00.000Z",
        "voteCount": 2,
        "content": "Box 1: Microsoft.Sql/managedInstances\nBox 2: \"[variables('networkSecurityGroupName')],\n\nBox 1 is Microsoft.Sql/managedInstances because there is a need to support cross database queries\nBix 2 has two options based on what follows:\n\n\"dependsOn\": [\n \"[resourceId('Microsoft.Network/networkSecurityGroups', variables('networkSecurityGroupName'))]\",\n \"[resourceId('Microsoft.Network/routeTables', variables('routeTableName'))]\""
      },
      {
        "date": "2022-03-09T00:36:00.000Z",
        "voteCount": 8,
        "content": "I retract the statement and have a correction :\nBox 2: parameters('virtualNetworkName')\n\n      \"dependsOn\": [\n        \"[resourceId('Microsoft.Network/virtualNetworks', parameters('virtualNetworkName'))]\"\n\nThe key is parameters vs variables ..."
      },
      {
        "date": "2021-11-21T18:28:00.000Z",
        "voteCount": 1,
        "content": "its ok?"
      },
      {
        "date": "2021-10-17T04:18:00.000Z",
        "voteCount": 1,
        "content": "it should be NetworkSecurityGroupName for 2nd drop down"
      },
      {
        "date": "2022-02-28T11:53:00.000Z",
        "voteCount": 4,
        "content": "The managedInstances has a dependency on the virtualNetworkName\nThe virtualNetwork has a dependency on the NetworkSecurityGroupName"
      },
      {
        "date": "2021-09-15T21:50:00.000Z",
        "voteCount": 3,
        "content": "Why the virtualNetworkname?"
      },
      {
        "date": "2021-09-23T02:57:00.000Z",
        "voteCount": 8,
        "content": "because virtual network has to be deployed before"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 32,
    "url": "https://www.examtopics.com/discussions/microsoft/view/63048-exam-dp-300-topic-1-question-32-discussion/",
    "body": "HOTSPOT -<br>You have the following Azure Resource Manager template.<br><img src=\"/assets/media/exam-media/04275/0007000001.png\" class=\"in-exam-image\"><br>For each of the following statements, select Yes if the statement is true. Otherwise, select No.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04275/0007100001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04275/0007100002.png\" class=\"in-exam-image\">",
    "answerDescription": "Reference:<br>https://docs.microsoft.com/en-us/azure/azure-sql/database/purchasing-models https://docs.microsoft.com/en-us/azure/azure-sql/database/single-database-create-arm-template-quickstart",
    "votes": [],
    "comments": [
      {
        "date": "2021-09-28T01:41:00.000Z",
        "voteCount": 13,
        "content": "Answer is correct"
      },
      {
        "date": "2022-03-24T17:44:00.000Z",
        "voteCount": 1,
        "content": "https://docs.microsoft.com/en-us/azure/azure-sql/database/single-database-create-arm-template-quickstart"
      },
      {
        "date": "2021-12-29T07:52:00.000Z",
        "voteCount": 9,
        "content": "The SKU type of Standard is only available in DTU pricing model"
      },
      {
        "date": "2023-11-02T09:55:00.000Z",
        "voteCount": 2,
        "content": "No, the pricing tier specified in the provided template snippet is not based on DTUs (Database Transaction Units), but instead it's based on vCores. This is evident from the `sku` block in the snippet:\n\n```json\n\"sku\" : {\n\"name\": \"Standard\",\n\"tier\": \"Standard\",\n\"capacity\": 10\n}\n```\n\nIn this block, the `capacity` property is set to `10`, which in the context of a vCore-based purchasing model would indicate the number of vCores. In a DTU-based model, the `tier` and `name` properties would typically be used to specify a performance level that includes a predefined number of DTUs, and you might see values like `Basic`, `Standard`, or `Premium` for the `name` property, along with a specific DTU count or range.\n\nIn summary, the template is utilizing a vCore-based pricing model, not a DTU-based pricing model."
      },
      {
        "date": "2023-07-13T13:18:00.000Z",
        "voteCount": 1,
        "content": "Managed instance uses a different resource type:\nhttps://learn.microsoft.com/en-us/azure/azure-sql/managed-instance/create-template-quickstart?view=azuresql-mi&amp;tabs=azure-powershell\ntype\": \"Microsoft.Sql/managedInstances\",\n      \"apiVersion\": \"2021-11-01-preview\",\n      \"name\": \"[parameters('managedInstanceName')]\",\n      \"location\": \"[parameters('location')]\","
      },
      {
        "date": "2023-05-14T05:40:00.000Z",
        "voteCount": 2,
        "content": "all answers are correct. The first one is tricky which looks like correct but it is not. The keyword is \"serverless\" which is not available in DTU purchasing option."
      },
      {
        "date": "2023-02-15T14:27:00.000Z",
        "voteCount": 3,
        "content": "The selected sku is Standard which means the pricing model chosen is DTU and DTU does not support serverless."
      },
      {
        "date": "2022-03-14T06:45:00.000Z",
        "voteCount": 1,
        "content": "I think that it should be Yes, No, Yes, because the ARM template deploys a serverless SQL Database. Please correct me if I am wrong. Thanks"
      },
      {
        "date": "2022-04-11T00:11:00.000Z",
        "voteCount": 2,
        "content": "The provided answer is correct, because the tier is Standard and the DTU is 10. It was my mistake."
      },
      {
        "date": "2022-05-02T19:16:00.000Z",
        "voteCount": 1,
        "content": "so? I just created Azure SQL on Standard DDUs = 10"
      },
      {
        "date": "2023-05-28T03:20:00.000Z",
        "voteCount": 1,
        "content": "The key word is to understand that DTU(we know its DTU because the service tier specified in the question is standard)pricing model supports only provisioned computers. While Vcore supports both Serverless and provisioned."
      },
      {
        "date": "2021-10-28T17:13:00.000Z",
        "voteCount": 1,
        "content": "i cant find why is this DTU ..."
      },
      {
        "date": "2021-11-09T01:12:00.000Z",
        "voteCount": 4,
        "content": "the  value of \"capacity\" = 10"
      },
      {
        "date": "2023-05-24T13:30:00.000Z",
        "voteCount": 1,
        "content": "In my opion can because the  value of tier is \"standard\" (sku/tier=\"standard\")."
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 33,
    "url": "https://www.examtopics.com/discussions/microsoft/view/62882-exam-dp-300-topic-1-question-33-discussion/",
    "body": "HOTSPOT -<br>You have an on-premises Microsoft SQL Server 2019 instance that hosts a database named DB1.<br>You plan to perform an online migration of DB1 to an Azure SQL managed instance by using the Azure Database Migration Service.<br>You need to create a backup of DB1 that is accessible to the Azure Database Migration Service.<br>What should you run for the backup and where should you store the backup? To answer, select the appropriate options in the answer area.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04275/0007200001.jpg\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04275/0007300001.jpg\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: ..with CHECKSUM option -<br>Azure Database Migration Service does not initiate any backups, and instead uses existing backups, which you may already have as part of your disaster recovery plan, for the migration. Be sure that you take backups using the WITH CHECKSUM option.<br><br>Box 2: An SMB share -<br>For online migrations from SQL Server to SQL Managed Instance using Azure Database Migration Service, you must provide the full database backup and subsequent log backups in the SMB network share that the service can use to migrate your databases.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/dms/tutorial-sql-server-managed-instance-online",
    "votes": [],
    "comments": [
      {
        "date": "2022-03-24T17:53:00.000Z",
        "voteCount": 7,
        "content": "Answer is correct\nhttps://docs.microsoft.com/en-us/azure/dms/tutorial-sql-server-managed-instance-online"
      },
      {
        "date": "2021-09-27T12:59:00.000Z",
        "voteCount": 7,
        "content": "Absolutely right. Files must be separate."
      },
      {
        "date": "2024-09-26T01:31:00.000Z",
        "voteCount": 1,
        "content": "Blob storage is better answer , it is more seamless migration offering with DMS , whereas smb is total nightmare for this type of migration - possible , but way sub-optimal.Other comments below support this."
      },
      {
        "date": "2023-09-19T07:32:00.000Z",
        "voteCount": 1,
        "content": "The local SMB network share or Azure file share that contains the full database backup files and transaction log backup files that Azure Database Migration Service can use for migration. \nThe service account running the source SQL Server instance must have read\\write privileges on this network share. \nProvide an FQDN or IP addresses of the server in the network share, for example, '\\\\servername.domainname.com\\backupfolder' or '\\\\IP address\\backupfolder'. \nFor improved performance, it's recommended to use separate folder for each database to be migrated. \nYou can provide the database level file share path by using the Advanced Settings option. \n\nhttps://learn.microsoft.com/en-us/azure/dms/tutorial-sql-server-managed-instance-online"
      },
      {
        "date": "2023-08-21T05:42:00.000Z",
        "voteCount": 5,
        "content": "I will go with the Blob Storage Account, since I used it quite a number of times in past projects. As already quoted here, SMB share is a bit of an administrative nightmare - the integration runtime does not work quite well."
      },
      {
        "date": "2023-07-25T08:59:00.000Z",
        "voteCount": 1,
        "content": "Neste caso existem duas respostas possiveis?"
      },
      {
        "date": "2023-02-15T14:35:00.000Z",
        "voteCount": 2,
        "content": "When doing an online migration to Managed Instance you can store the backups in blob storage without needing to have an SMB share and the integration runtime running. https://learn.microsoft.com/en-us/azure/dms/tutorial-sql-server-managed-instance-online-ads"
      },
      {
        "date": "2022-07-22T09:44:00.000Z",
        "voteCount": 4,
        "content": "Correct answer: Using Azure Database Migration Service, you must provide the full database backup and subsequent log backups in the SMB network share that the service can use to migrate your databases. Be sure that you take backups using the WITH CHECKSUM option"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 34,
    "url": "https://www.examtopics.com/discussions/microsoft/view/74584-exam-dp-300-topic-1-question-34-discussion/",
    "body": "HOTSPOT -<br>You have an Azure subscription.<br>You plan to deploy an Azure SQL database by using an Azure Resource Manager template.<br>How should you complete the template? To answer, select the appropriate options in the answer area.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04275/0007400001.jpg\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04275/0007500001.jpg\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: \"Microsoft.Sql/servers\"<br>Example:<br>\"resources\": [<br>{<br>\"type\": \"Microsoft.Sql/servers\",<br>\"apiVersion\": \"2021-08-01-preview\",<br>\"name\": \"[parameters('serverName')]\",<br>\"location\": \"[parameters('location')]\",<br>\"properties\": {<br>\"administratorLogin\": \"[parameters('administratorLogin')]\",<br>\"administratorLoginPassword\": \"[parameters('administratorLoginPassword')]\"<br>}<br>},<br>{<br>\"type\": \"Microsoft.Sql/servers/databases\",<br>\"apiVersion\": \"2021-08-01-preview\",<br>\"name\": \"[format('{0}/{1}', parameters('serverName'), parameters('sqlDBName'))]\",<br>\"location\": \"[parameters('location')]\",<br>\"sku\": {<br>\"name\": \"Standard\",<br>\"tier\": \"Standard\"<br>},<br>\"dependsOn\": [<br>\"[resourceId('Microsoft.Sql/servers', parameters('serverName'))]\"<br>]<br>}<br>Box 2: \"dependsOn\": [<br>Reference:<br>https://docs.microsoft.com/en-us/azure/azure-sql/database/single-database-create-arm-template-quickstart",
    "votes": [],
    "comments": [
      {
        "date": "2022-04-26T06:02:00.000Z",
        "voteCount": 7,
        "content": "type\": \"Microsoft.Sql/servers/databases\""
      },
      {
        "date": "2022-05-02T20:39:00.000Z",
        "voteCount": 3,
        "content": "correct"
      },
      {
        "date": "2023-10-04T06:01:00.000Z",
        "voteCount": 1,
        "content": "https://learn.microsoft.com/en-us/azure/azure-sql/database/single-database-create-arm-template-quickstart?view=azuresql"
      },
      {
        "date": "2022-07-05T04:12:00.000Z",
        "voteCount": 3,
        "content": "I think the given answer is right if we see the docs link page provided with the answer"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 35,
    "url": "https://www.examtopics.com/discussions/microsoft/view/74711-exam-dp-300-topic-1-question-35-discussion/",
    "body": "You have an on-premises Microsoft SQL Server 2019 server that hosts a database named DB1.<br>You have an Azure subscription that contains an Azure SQL managed instance named SQLMI1 and a virtual network named VNET1. SQLMI1 resides on VNET1.<br>The on-premises network connects to VNET1 by using an ExpressRoute connection.<br>You plan to migrate DB1 to SQLMI1 by using Azure Database Migration Service.<br>You need to configure VNET1 to support the migration.<br>What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure service endpoints.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure virtual network peering.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDeploy an Azure firewall.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure network security groups (NSGs)."
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 5,
        "isMostVoted": true
      },
      {
        "answer": "D",
        "count": 3,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2022-04-27T19:15:00.000Z",
        "voteCount": 5,
        "content": "During virtual network setup, if you use ExpressRoute with network peering to Microsoft, add the following service endpoints to the subnet in which the service will be provisioned:\nhttps://docs.microsoft.com/en-us/azure/dms/tutorial-sql-server-to-managed-instance"
      },
      {
        "date": "2024-09-26T01:45:00.000Z",
        "voteCount": 1,
        "content": "Answer is D - NSGs control traffic in and out of the virtual network and can allow or block specific ports and protocols needed for the migration (such as SQL Server ports) - it is not A  - Service endpoints are used to extend VNet access to certain Azure services (like Azure SQL Database, Azure Storage), but they're not needed here because Azure SQL Managed Instance resides fully inside the VNet, and an ExpressRoute connection is used for connectivity from on-premises."
      },
      {
        "date": "2024-08-14T04:59:00.000Z",
        "voteCount": 1,
        "content": "A is correct"
      },
      {
        "date": "2024-02-03T02:32:00.000Z",
        "voteCount": 3,
        "content": "A. Configure service endpoints:\nService endpoints provide secure and direct connectivity to Azure services over the Azure backbone network. They are not typically used for connectivity between on-premises environments and Azure services.\nB. Configure virtual network peering:\nVirtual network peering is used to connect two Azure virtual networks seamlessly. Since your scenario involves an on-premises network and not another Azure virtual network, peering is not applicable.\nC. Deploy an Azure firewall:\nAn Azure firewall is a network security service that protects Azure Virtual Network resources. It could be used to govern the traffic between your on-premises environment and the Azure SQL Managed Instance, but it is not the primary tool for enabling connectivity.\nD. Configure network security groups (NSGs):\nNetwork Security Groups are used to control inbound and outbound traffic to network interfaces (NIC), VMs, and subnets. By creating and applying NSG rules, you can ensure that traffic from the on-premises network can reach SQLMI1 over the ExpressRoute connection."
      },
      {
        "date": "2022-04-27T19:34:00.000Z",
        "voteCount": 4,
        "content": "A is correct"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 36,
    "url": "https://www.examtopics.com/discussions/microsoft/view/74710-exam-dp-300-topic-1-question-36-discussion/",
    "body": "You have an on-premises Microsoft SQL server that uses the FileTables and Filestream features.<br>You plan to migrate to Azure SQL.<br>Which service should you use?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure SQL Database",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSQL Server on an Azure Virtual Machine\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure SQL Managed Instance",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure Database for MySQL"
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 10,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2022-04-27T19:14:00.000Z",
        "voteCount": 10,
        "content": "https://docs.microsoft.com/en-us/azure/azure-sql/migration-guides/database/sql-server-to-sql-database-overview?view=azuresql\n\nIf one of the following conditions applies to your business, consider moving to a SQL Server virtual machine (VM) instead:\nYou have strict dependency on features that are still not supported, such as FileStream/FileTable, PolyBase, and cross-instance transactions."
      },
      {
        "date": "2024-09-26T05:11:00.000Z",
        "voteCount": 1,
        "content": "I would say B - Azure SQL Database and Azure SQL Managed Instance do not support these specific features."
      },
      {
        "date": "2023-07-04T20:50:00.000Z",
        "voteCount": 1,
        "content": "Your business might have requirements that make SQL Server on Azure Virtual Machines a more suitable target than Azure SQL Database.\nYou require direct access to the operating system or file system, such as to install third-party or custom agents on the same virtual machine with SQL Server.\nYou have strict dependency on features that are still not supported, such as FileStream/FileTable, PolyBase, and cross-instance transactions.\nYou need to stay at a specific version of SQL Server (2012, for example).\nYour compute requirements are much lower than a managed instance offers (one vCore, for example), and database consolidation is not an acceptable option."
      },
      {
        "date": "2023-06-29T02:02:00.000Z",
        "voteCount": 2,
        "content": "It\u00b4s tricky because it mentions \u00a8migrate to Azure SQL\u00a8 instead of \u00a8migrate to Azure\u00a8."
      },
      {
        "date": "2023-10-01T11:29:00.000Z",
        "voteCount": 1,
        "content": "yes but as the answer explains, if you need to maintain the use of FileTable + Filestream in azure, it has to be on an SQL Server, wich has to ve on a VM(only possible setup to run SQL Server on azure). Azure sql or sql managed does't support it."
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 37,
    "url": "https://www.examtopics.com/discussions/microsoft/view/74712-exam-dp-300-topic-1-question-37-discussion/",
    "body": "You need to migrate an on-premises Microsoft SQL Server database to Azure SQL Database. The solution must minimize downtime.<br>What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure Transaction Log Shipping.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tImplement Always On availability groups.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure transactional replication.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tImport a BACPAC."
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 4,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2022-06-03T17:08:00.000Z",
        "voteCount": 10,
        "content": "Ans : C\nThere are two primary methods for migrating a SQL Server 2005 or later database to Azure SQL Database. The first method is simpler but requires some, possibly substantial, downtime during the migration. The second method is more complex, but substantially eliminates downtime during the migration.\nMethod 1: Migration with downtime during the migration\nMethod 2: Use Transactional Replication\nRef : https://docs.microsoft.com/en-us/azure/azure-sql/database/migrate-to-database-from-sql-server?view=azuresql#method-1-migration-with-downtime-during-the-migration"
      },
      {
        "date": "2024-06-04T16:45:00.000Z",
        "voteCount": 1,
        "content": "C is correct from study material on Microsoft site."
      },
      {
        "date": "2023-07-04T20:59:00.000Z",
        "voteCount": 1,
        "content": "Transactional replication\uff1a\n- Setup is relatively complex compared to other migration options.\n- Provides a continuous replication option to migrate data (without taking the databases offline).\n- Transactional replication has limitations to consider when you're setting up the publisher on the source SQL Server instance. See Limitations on publishing objects to learn more.\n- It's possible to monitor replication activity."
      },
      {
        "date": "2022-07-22T10:01:00.000Z",
        "voteCount": 4,
        "content": "Answer = C: Migration with minimal downtime will always be - use Replication"
      },
      {
        "date": "2022-07-10T07:37:00.000Z",
        "voteCount": 2,
        "content": "Answer is C"
      },
      {
        "date": "2022-04-27T19:39:00.000Z",
        "voteCount": 1,
        "content": "D is correct. Because the question is minimize the downtime. Rather than using DMA, you can also use a BACPAC file. See Import a BACPAC file to a new database in Azure SQL Database.   \nUse Transactional Replication will be no down time."
      },
      {
        "date": "2022-05-02T20:55:00.000Z",
        "voteCount": 3,
        "content": ")))\n\nIt is worth mentioning explicitly that the amount of downtime required to create, upload, and import a bacpac of a large database may be prohibitively large in the context of an actual production application migration. In those cases, the migration approach using transactional replication, which significantly reduces the necessary downtime at the cost of added complexity, may be a feasible solution."
      },
      {
        "date": "2022-05-03T03:34:00.000Z",
        "voteCount": 1,
        "content": "I agree with you. I think the quetion is too tricky and confusing."
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 38,
    "url": "https://www.examtopics.com/discussions/microsoft/view/86065-exam-dp-300-topic-1-question-38-discussion/",
    "body": "You have an Azure SQL database named DB1.<br>You have a table name Table1 that has 20 columns of type CHAR(400). Row compression for Table1 is enabled.<br>During a database audit, you discover that none of the fields contain more than 150 characters.<br>You need to ensure that you can apply page compression to Table1.<br>What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure the columns as sparse.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tChange the column type to NVARCHAR(MAX).",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tChange the column type to VARCHAR(MAX).",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tChange the column type to VARCHAR(200).\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "We reduce the max length of the column from 400 to 200.<br>Incorrect:<br>Not A: Sparse column is useful when there are many null columns.<br>The SQL Server Database Engine uses the SPARSE keyword in a column definition to optimize the storage of values in that column. Therefore, when the column value is NULL for any row in the table, the values require no storage.<br>Not B, Not C: SQL Server 2005 got around the limitation of 8KB storage size and provided a workaround with varchar(max). It is a non-Unicode large variable- length character data type and can store a maximum of 2^31-1 bytes (2 GB) of non-Unicode characters.<br>Reference:<br>https://www.sqlshack.com/sql-varchar-data-type-deep-dive/<br>https://36chambers.wordpress.com/2020/06/18/nvarchar-everywhere-a-thought-experiment/",
    "votes": [
      {
        "answer": "D",
        "count": 2,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-09-26T05:20:00.000Z",
        "voteCount": 2,
        "content": "D for sure - Changing the column type to VARCHAR(200) adjusts the column to a variable-length data type. Since the data never exceeds 150 characters, you can safely reduce the maximum length to 200."
      },
      {
        "date": "2023-05-26T16:35:00.000Z",
        "voteCount": 2,
        "content": "D is the only option that would shrink the column and still allow for a little additional characters."
      },
      {
        "date": "2022-10-20T12:49:00.000Z",
        "voteCount": 2,
        "content": "looks currect"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 39,
    "url": "https://www.examtopics.com/discussions/microsoft/view/87354-exam-dp-300-topic-1-question-39-discussion/",
    "body": "You have an on-premises Microsoft SQL Server named SQL1 that hosts five databases.<br>You need to migrate the databases to an Azure SQL managed instance. The solution must minimize downtime and prevent data loss.<br>What should you use?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAlways On availability groups",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tBackup and Restore\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tlog shipping",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDatabase Migration Assistant"
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 21,
        "isMostVoted": true
      },
      {
        "answer": "D",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2023-01-09T23:05:00.000Z",
        "voteCount": 13,
        "content": "DMA does not support database migrations to Azure SQL Managed Instance. Recommendation is to use the Azure SQL migration extension for Azure Data Studio, which supports both online and offline database migrations to Azure SQL Managed Instance, but here we don\u00b4t have the option \"Azure SQL migration extension for Azure Data Studio\".\nhttps://learn.microsoft.com/en-us/sql/dma/dma-overview?view=sql-server-ver16#capabilities\n\nRegarding log shipping to Managed Instance is not possible; it only supports the restore of full backups.\nhttps://dba.stackexchange.com/questions/232332/is-it-possible-to-log-ship-from-on-premise-sql-server-to-azure-sql-managed-insta\n\nSo the only option that we can use is Backup and Restore"
      },
      {
        "date": "2024-07-30T05:58:00.000Z",
        "voteCount": 1,
        "content": "this is not true anymore. Even within the link you provided:\n\"Assess on-premises SQL Server instances migrating to Azure SQL Database or Azure SQL Managed Instance.\""
      },
      {
        "date": "2024-10-11T09:23:00.000Z",
        "voteCount": 1,
        "content": "Must be A, according to the 'Hybrid data synchronization' paragraph and the 'Migration by platform' table:\nhttps://learn.microsoft.com/en-us/azure/azure-sql/database/sql-data-sync-retirement-migration?view=azuresql"
      },
      {
        "date": "2024-09-26T05:26:00.000Z",
        "voteCount": 1,
        "content": "A - B and D do not minimise downtime - only the always on Av Groups can meet the requirements"
      },
      {
        "date": "2024-09-23T15:18:00.000Z",
        "voteCount": 1,
        "content": "I'm kind of agree that the correct answer is D.\nHere is my guess as to why.\nIn the question it saying \"You need to migrate the databases to an Azure SQL managed instance. The solution must minimize downtime and prevent data loss.\"\nI think who ever asking this, actually looking for more solution to minimize downtime and prevent data loss.\nBy using DMA you have an option to evaluate if migration will be successful. \nmodern data platform by detecting compatibility issues.\nI can't simply take DB and migrate it, Right? \nFirst evaluation then actual Migration.\nI'm personally choosing D."
      },
      {
        "date": "2024-05-11T11:13:00.000Z",
        "voteCount": 2,
        "content": "Hi everyone, \nwhy can't use the Always on availability group?"
      },
      {
        "date": "2024-04-21T09:58:00.000Z",
        "voteCount": 1,
        "content": "https://learn.microsoft.com/en-us/sql/dma/dma-overview?view=sql-server-ver16"
      },
      {
        "date": "2024-04-22T00:02:00.000Z",
        "voteCount": 3,
        "content": "Sorry, my bad, but the Microsoft documentation is misleading.\nIt says: \"The Data Migration Assistant (DMA) helps you upgrade to a modern data platform by detecting compatibility issues that can impact database functionality when you:\n\nupgrade to a new version of SQL Server\nmigrate to Azure SQL Database\nmigrate to Azure SQL Managed Instance\"\n\nbut below there is an alert\n\"DMA does not support database migrations to Azure SQL Managed Instance. Use the Azure SQL migration extension for Azure Data Studio instead, which supports both online and offline database migrations to Azure SQL Managed Instance.\"\nSo I suppose the only possible answer is B"
      },
      {
        "date": "2024-02-09T10:03:00.000Z",
        "voteCount": 2,
        "content": "Changing my mind on this - Believe answer is B after reviewing. Migration Service is different from Migration Assistant. Migration Assistant only assesses databases for migration"
      },
      {
        "date": "2024-02-09T09:56:00.000Z",
        "voteCount": 1,
        "content": "I believe answer is correct - D. Database Migration Service is used to restore backups for the migration. See Question 33 for details (2nd line in question)"
      },
      {
        "date": "2024-09-23T15:08:00.000Z",
        "voteCount": 1,
        "content": "Database Migration Service \nIn our case Database Migration Assistant"
      },
      {
        "date": "2024-01-06T00:14:00.000Z",
        "voteCount": 1,
        "content": "DMA does not support database migrations to Azure SQL Managed Instance. Use the Azure SQL migration extension for Azure Data Studio instead, which supports both online and offline database migrations to Azure SQL Managed Instance."
      },
      {
        "date": "2023-12-14T05:56:00.000Z",
        "voteCount": 3,
        "content": "Answer A: Always On availability groups. Why? The clue is: \"The solution must minimize downtime and prevent data loss.\"\nFor reference see: https://learn.microsoft.com/en-us/azure/azure-sql/migration-guides/managed-instance/sql-server-to-managed-instance-overview?view=azuresql#compare-migration-options\n\nMigration option: Link feature for Azure SQL Managed Instance"
      },
      {
        "date": "2023-08-31T12:13:00.000Z",
        "voteCount": 1,
        "content": "Answer is B (Backup and Restore) because that's the ONLY viable option in the provided multiple choices for DB migration from ONprem to Azure SQL MI\nBelow shown is a statement from Microsoft URL (highlighted in purple in website): \nDMA (data migration assistant) does not support database migrations to Azure SQL Managed Instance. \nUse the Azure SQL migration extension for Azure Data Studio instead, which supports both online and offline database migrations to Azure SQL Managed Instance.\nhttps://learn.microsoft.com/en-us/sql/dma/dma-overview?view=sql-server-ver16"
      },
      {
        "date": "2023-10-01T15:09:00.000Z",
        "voteCount": 1,
        "content": "You can achieve minimal downtine with Log Replay Service..... wich uses log shipping technology. ( it uses full and differential backup first, and then apply logs that we send to blob storage).\nWith only backup and restore you would have downtime."
      },
      {
        "date": "2023-08-30T01:32:00.000Z",
        "voteCount": 2,
        "content": "DMA does not support migration to MI"
      },
      {
        "date": "2023-08-10T12:22:00.000Z",
        "voteCount": 2,
        "content": "Backup and restore is for now only option from given."
      },
      {
        "date": "2023-08-08T03:08:00.000Z",
        "voteCount": 1,
        "content": "DMA DOES support migration to SQL MI (SMB share), so answer is correct."
      },
      {
        "date": "2023-08-10T12:21:00.000Z",
        "voteCount": 1,
        "content": "DMA DOES NOT support migration to SQL MI yet. it only support assesment to SQL MI: https://learn.microsoft.com/en-us/sql/dma/dma-overview?view=sql-server-ver16"
      },
      {
        "date": "2023-08-21T05:51:00.000Z",
        "voteCount": 1,
        "content": "you are correct, my bad. the ONLY option is backup and restore."
      },
      {
        "date": "2023-04-25T11:39:00.000Z",
        "voteCount": 3,
        "content": "DMA does not support database migrations to Azure SQL Managed Instance. Recommendation is to use the Azure SQL migration extension for Azure Data Studio, which supports both online and offline database migrations to Azure SQL Managed Instance.\nhttps://learn.microsoft.com/en-us/sql/dma/dma-overview?view=sql-server-ver16"
      },
      {
        "date": "2023-04-02T14:20:00.000Z",
        "voteCount": 1,
        "content": "DMA only supports the assessment of Azure SQL Managed Instance, not the real migration. So the correct anwser is B, Backup and Restore"
      },
      {
        "date": "2023-02-23T05:18:00.000Z",
        "voteCount": 2,
        "content": "answer is correct. https://www.bing.com/ck/a?!&amp;&amp;p=c8e730966a3cda75JmltdHM9MTY3NzExMDQwMCZpZ3VpZD0yNDk2ZTQwNi0zZjY0LTZhNjYtMzA3MC1mNjc1M2VmOTZiNTMmaW5zaWQ9NTQ0MA&amp;ptn=3&amp;hsh=3&amp;fclid=2496e406-3f64-6a66-3070-f6753ef96b53&amp;psq=dma+to+azure+managed+instance&amp;u=a1aHR0cHM6Ly9sZWFybi5taWNyb3NvZnQuY29tL2VuLXVzL2F6dXJlL2F6dXJlLXNxbC9taWdyYXRpb24tZ3VpZGVzL21hbmFnZWQtaW5zdGFuY2Uvc3FsLXNlcnZlci10by1tYW5hZ2VkLWluc3RhbmNlLWd1aWRlP3ZpZXc9YXp1cmVzcWwjOn46dGV4dD1UbyUyMG1pZ3JhdGUlMjB5b3VyJTIwU1FMJTIwU2VydmVyJTIwdG8lMjBBenVyZSUyMFNRTCx0byUyMGFjY2VzcyUyMGJvdGglMjBzb3VyY2UlMjBhbmQlMjB0YXJnZXQuJTIwTW9yZSUyMGl0ZW1z&amp;ntb=1"
      },
      {
        "date": "2023-02-23T05:19:00.000Z",
        "voteCount": 1,
        "content": "sorry pasre the wrong link. here is the correct one - https://learn.microsoft.com/en-us/azure/azure-sql/migration-guides/managed-instance/sql-server-to-managed-instance-guide?view=azuresql"
      },
      {
        "date": "2023-03-07T03:51:00.000Z",
        "voteCount": 1,
        "content": "Your link shows that it is answer B \"Backup and Restore\""
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 40,
    "url": "https://www.examtopics.com/discussions/microsoft/view/98777-exam-dp-300-topic-1-question-40-discussion/",
    "body": "You have an Azure subscription that contains an Azure SQL database. The database contains a table named tablet that uses partitioned columnstores.<br><br>You need to configure table1 to meet the following requirements:<br><br>\u2022\tEach partition must be compressed.<br>\u2022\tThe compression ratio must be maximized.<br>\u2022\tYou must be able to index the compressed data.<br><br>What should you use?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tpage compression",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tcolumnstore compression\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tGZIP compression",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tcolumnstore archival compression"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 2,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-09-26T05:29:00.000Z",
        "voteCount": 2,
        "content": "D -Columnstore archival compression is a feature of Azure SQL Database and SQL Server that allows for maximum compression of columnstore index data. It is specifically designed for large datasets and is ideal for read-heavy workloads where maximizing compression is crucial."
      },
      {
        "date": "2024-08-14T05:22:00.000Z",
        "voteCount": 1,
        "content": "The correct Answer is B\nA clustered columnstore index (CCI) will compress your data and maximize the compression ratio. It also allows you to index the compressed data."
      },
      {
        "date": "2024-05-11T11:19:00.000Z",
        "voteCount": 1,
        "content": "I think the B. columnstore compression is better answer, who is sure about this answer ?"
      },
      {
        "date": "2024-01-06T00:21:00.000Z",
        "voteCount": 1,
        "content": "Columnstore tables and indexes are always stored with columnstore compression \u00b9. You can further reduce the size of columnstore data by configuring an additional compression called archival compression. To perform archival compression, SQL Server runs the Microsoft XPRESS compression algorithm on the data \u00b9. \n\nHowever, it is important to note that archival compression is not an indexing technique. \n\nImportant (Only when you can afford extra time and CPU)\nArchival compression is a data compression technique that can be used to further reduce the size of columnstore data for situations when you can afford extra time and CPU resources to store and retrieve the data."
      },
      {
        "date": "2023-02-22T02:09:00.000Z",
        "voteCount": 3,
        "content": "While columnstore archival compression can be used to compress columnstore data in a way that minimizes storage costs, it is not optimized for query performance, as it is designed for long-term storage of cold data.\n\nIn this scenario, the requirement is to maximize compression ratio while still being able to perform index operations on the compressed data. Columnstore archival compression is not optimized for indexing, and as such, it would not meet this requirement.\n\nTherefore, the correct answer is B. columnstore compression."
      },
      {
        "date": "2023-06-29T02:14:00.000Z",
        "voteCount": 2,
        "content": "The questions only asks to achieve max compression. It doesn\u00b4t ask for any query or index Optimization. So IMHO, it\u00b4s Archival."
      },
      {
        "date": "2023-08-31T09:02:00.000Z",
        "voteCount": 1,
        "content": "Yeah I agree"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 41,
    "url": "https://www.examtopics.com/discussions/microsoft/view/99770-exam-dp-300-topic-1-question-41-discussion/",
    "body": "You have an Azure subscription linked to an Azure Active Directory (Azure AD) tenant. The subscription contains 10 virtual machines that run Windows Server 2019 and host Microsoft SQL Server 2019 instances.<br><br>You need to ensure that you can manage the SQL Server instances by using a single user account.<br><br>What should you do first?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEnable a user-assigned managed identity on each virtual machine.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDeploy an Azure Active Directory Domain Services (Azure AD DS) domain and join the virtual machines to the domain.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEnable a system-assigned managed identity on each virtual machine.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tJoin the virtual machines to the Azure AD tenant."
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 9,
        "isMostVoted": true
      },
      {
        "answer": "A",
        "count": 8,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2024-09-26T06:02:00.000Z",
        "voteCount": 1,
        "content": "All things considered I would go for B"
      },
      {
        "date": "2024-06-04T16:56:00.000Z",
        "voteCount": 2,
        "content": "Chat gpt indicates managed identities are not used for server 2019, so B would be the better answer, imho."
      },
      {
        "date": "2024-07-01T08:55:00.000Z",
        "voteCount": 1,
        "content": "This may just be a horrible question with no good documentation.  I've found 2 articles.  One definitely indicates it can happen in Sql 2022, but the other document indicates no limitation here at all, even with 2019.  I'm not sure where the article is that says it's NOT supported in 2019, as I can't seem to find it anymore.\n\nhttps://learn.microsoft.com/en-us/azure/azure-sql/database/authentication-azure-ad-user-assigned-managed-identity?view=azuresql\n\nhttps://learn.microsoft.com/en-us/azure/azure-sql/virtual-machines/windows/configure-azure-ad-authentication-for-sql-vm?view=azuresql&amp;tabs=azure-portal \n\nI may change my answer to A..."
      },
      {
        "date": "2024-01-11T19:06:00.000Z",
        "voteCount": 2,
        "content": "To manage SQL Server instances on multiple Azure virtual machines using a single user account, you should first deploy an Azure Active Directory Domain Services (Azure AD DS) domain and join the virtual machines to the domain (Option B)12.\n\nAzure Active Directory Domain Services provides managed domain services such as domain join, group policy, LDAP, and Kerberos/NTLM authentication. By joining the virtual machines to the Azure AD DS domain, you can centralize the management of user accounts, which simplifies the process of managing SQL Server instances across multiple virtual machines."
      },
      {
        "date": "2024-01-06T00:33:00.000Z",
        "voteCount": 1,
        "content": "Answer B.\n\nEnabling a user-assigned managed identity on each virtual machine is not required to solve the above scenario. User-assigned managed identities are used to authenticate to services that support Azure AD authentication, such as Azure Key Vault, without requiring the use of credentials in your code.\n\nAdd Azure Active Directory User to Azure SQL Database. https://stackoverflow.com/questions/45044760/add-azure-active-directory-user-to-azure-sql-database.\n\nAdd an existing Azure subscription to your tenant - Microsoft Entra .... https://learn.microsoft.com/en-us/entra/fundamentals/how-subscriptions-associated-directory."
      },
      {
        "date": "2023-08-31T12:34:00.000Z",
        "voteCount": 3,
        "content": "As per below Microsoft URL, I believe answer is A - Enable user Assigned managed Identity....... .   \nIs Azure Active Directory Domain Services (Azure AD DS) supported with SQL Server on Azure VMs?\nNo. Using Azure Active Directory Domain Services (Azure AD DS) isn't currently supported with SQL Server on Azure VMs. Use an Active Directory domain account instead.\nhttps://learn.microsoft.com/en-us/azure/azure-sql/virtual-machines/windows/frequently-asked-questions-faq?view=azuresql"
      },
      {
        "date": "2024-08-19T04:53:00.000Z",
        "voteCount": 1,
        "content": "Then it's kind of funny. See the question 41 {SQLVM1 and Server1 are joined to an Active Directory Domain Services (AD DS) domain;  while SQLVM1 is an instance of SQL Server on Azure Virtual Machines}. \nHopefully this question won't appear in the exam."
      },
      {
        "date": "2024-08-20T01:14:00.000Z",
        "voteCount": 1,
        "content": "Sorry, I meant the Question 60 (Topic 1)."
      },
      {
        "date": "2023-08-28T01:44:00.000Z",
        "voteCount": 2,
        "content": "I will go with B.\nhttps://learn.microsoft.com/en-us/azure/active-directory/managed-identities-azure-resources/overview - check the video, it shows what is the purpose of Managed Identity - basically to get rid of passwords in code (among other things), so it has nothing to do with server management."
      },
      {
        "date": "2023-08-11T05:16:00.000Z",
        "voteCount": 1,
        "content": "According to the article below we can use managed identity on azure vm only on SQL Server 2022. In the question is 2019, so the answer is B.\nhttps://learn.microsoft.com/en-us/azure/azure-sql/virtual-machines/windows/configure-azure-ad-authentication-for-sql-vm?view=azuresql&amp;tabs=azure-portal"
      },
      {
        "date": "2023-08-31T09:12:00.000Z",
        "voteCount": 1,
        "content": "no mention of \"Active Directory Domain Services (Azure AD DS)\" on this page though"
      },
      {
        "date": "2023-05-29T23:36:00.000Z",
        "voteCount": 1,
        "content": "deploy an Azure Active Directory Domain Services (Azure AD DS) domain and join the virtual machines to the domain . This will allow you to use a single domain user account to manage the SQL Server instances on all of the virtual machines.\n\na user-assigned managed identity can be associated with more than one Azure resource. However, in this scenario, the goal is to manage the SQL Server instances using a single user account. While using a user-assigned managed identity would allow you to authenticate to Azure resources using a single identity, it would not provide a way to manage the SQL Server instances using a single user account."
      },
      {
        "date": "2023-05-03T02:48:00.000Z",
        "voteCount": 2,
        "content": "The same user-assigned managed identity can be associated with more than one Azure resource."
      },
      {
        "date": "2023-04-22T23:54:00.000Z",
        "voteCount": 1,
        "content": "I think it is B, because of this: \"by using a single user account\"."
      },
      {
        "date": "2023-03-08T04:19:00.000Z",
        "voteCount": 2,
        "content": "Correct ans. B"
      },
      {
        "date": "2023-03-07T07:20:00.000Z",
        "voteCount": 3,
        "content": "I thing Answer A is correct because of this link: \nhttps://learn.microsoft.com/en-us/azure/active-directory/managed-identities-azure-resources/overview"
      },
      {
        "date": "2023-02-18T02:50:00.000Z",
        "voteCount": 4,
        "content": "B is correct"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 42,
    "url": "https://www.examtopics.com/discussions/microsoft/view/96909-exam-dp-300-topic-1-question-42-discussion/",
    "body": "DRAG DROP<br> -<br><br>You have an Azure subscription.<br><br>You plan to deploy a new Azure virtual machine that will host a Microsoft SQL Server instance.<br><br>You need to configure the disks on the virtual machine. The solution must meet the following requirements:<br><br>\u2022\tMinimize latency for transaction logs.<br>\u2022\tMinimize the impact on IO throughput of the virtual machine.<br><br>Which type of disk should you use for each workload? To answer, drag the appropriate disk types to the correct workloads. Each disk type may be used once, more than once, or not at all. You may need to drag the split bar between panes or scroll to view content.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/dp-300/image218.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/dp-300/image219.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2023-01-26T04:54:00.000Z",
        "voteCount": 9,
        "content": "According this article:\nhttps://learn.microsoft.com/en-us/azure/azure-sql/virtual-machines/windows/performance-guidelines-best-practices-storage?view=azuresql\n\"For the log drive ...  If submillisecond storage latency is required, use Azure ultra disk\" - so the answer is correct\n\"Place tempdb on the local ephemeral SSD (default D:\\) drive for most SQL Server workloads\" - thus the answer should be perhaps \"local\" ?"
      },
      {
        "date": "2024-09-26T06:10:00.000Z",
        "voteCount": 1,
        "content": "I agree with Licna - Ulta Disk for logs is straightforward , and in the strictest sense of the questions terms , local disk will provide lowest latency - there are no other requirements"
      },
      {
        "date": "2024-07-28T07:23:00.000Z",
        "voteCount": 1,
        "content": "Using a local disk for TempDB can minimize the impact on IO throughput of the virtual machine by offloading the I/O operations of TempDB from the primary managed disk to the local disk. \n    Dedicated I/O Path: Local disks typically have a separate I/O path from the managed disks (such as Premium SSDs or Standard SSDs) attached to the VM. By using the local disk for TempDB, you can leverage this dedicated path, reducing the load on the managed disk I/O.\n    High IOPS and Low Latency: Local disks provide high IOPS and low latency because they are directly attached to the VM's physical host. This high performance is particularly beneficial for TempDB, which handles a lot of temporary data and requires fast read/write operations."
      },
      {
        "date": "2023-11-06T12:08:00.000Z",
        "voteCount": 1,
        "content": "TempDB: This database is heavily used for temporary objects and should be on the fastest storage available to minimize latency. In this case, the best choice would typically be either Premium SSDs or Ultra Disks, depending on the performance requirements. Ultra Disks offer the highest throughput and lowest latency, but they are also more expensive.\nTransaction Logs: The transaction log records all transactions and the database modifications made by each transaction. The performance of transaction logs can be critical for write-intensive applications. Therefore, low latency is very important. Premium SSDs are generally a good choice for transaction logs because they provide a balance between cost and performance. However, for workloads that require the lowest latency possible, Ultra Disks would be the preferred choice."
      },
      {
        "date": "2023-07-18T10:37:00.000Z",
        "voteCount": 1,
        "content": "Tempdb should be local."
      },
      {
        "date": "2023-07-13T15:20:00.000Z",
        "voteCount": 1,
        "content": "https://learn.microsoft.com/en-us/training/modules/deploy-iaas-solutions-with-azure-sql/4-explore-performance-and-security\nThe best practices for SQL Server on Azure recommend using Premium Disks pooled for increased IOPs and storage capacity. Data files should be stored in their own pool with read-caching on the Azure disks.\n\nTransaction log files won't benefit from this caching, so those files should go into their own pool without caching. TempDB can optionally go into its own pool, or using the VM\u2019s temporary disk, which offers low latency since it's physically attached to the physical server where the VMs are running. Properly configured Premium SSD will see latency in single digit milliseconds. For mission critical workloads that require latency lower than that, you should consider Ultra SSD."
      },
      {
        "date": "2023-06-26T09:55:00.000Z",
        "voteCount": 3,
        "content": "correct\nIf possible, use Write Acceleration over ultra disks for the transaction log disk. For VMs that don't support Write Acceleration but require low latency to the transaction log, use Azure ultra disks."
      },
      {
        "date": "2023-04-30T18:26:00.000Z",
        "voteCount": 2,
        "content": "Tempdb should be local. Not sure about the other one, but I guess if we are minimising latency, it must be Ultra Disk?"
      },
      {
        "date": "2023-03-04T05:10:00.000Z",
        "voteCount": 4,
        "content": "which one  is correct option?\nI think, Tempdb should be local and transaction log should be premium"
      },
      {
        "date": "2023-02-22T23:51:00.000Z",
        "voteCount": 1,
        "content": "correct"
      },
      {
        "date": "2023-01-27T06:49:00.000Z",
        "voteCount": 4,
        "content": "Yes I agree, the tempdb should be on a local drive"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 43,
    "url": "https://www.examtopics.com/discussions/microsoft/view/105032-exam-dp-300-topic-1-question-43-discussion/",
    "body": "You have an Azure SQL Database elastic pool that contains 10 databases.<br><br>You receive the following alert.<br><br>Msg 1132, Level 16, state 1, Line 1<br>The elastic pool has reached its storage limit. The storage used for the elastic pool cannot exceed (76800) MBs.<br><br>You need to resolve the alert. The solution must minimize administrative effort.<br><br>Which three actions can you perform? Each correct answer presents a complete solution.<br><br>NOTE: Each correct selection is worth one point.",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tIncrease the maximum storage of the elastic pool.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDelete data from a database.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRemove a database from the pool.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEnable data compression.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tShrink individual databases.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "ADE",
    "answerDescription": "",
    "votes": [
      {
        "answer": "ADE",
        "count": 4,
        "isMostVoted": true
      },
      {
        "answer": "ACD",
        "count": 3,
        "isMostVoted": false
      },
      {
        "answer": "ACE",
        "count": 3,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2023-11-06T12:33:00.000Z",
        "voteCount": 5,
        "content": "To resolve the storage limit alert for your Azure SQL Database elastic pool, you can:\n\nA. Increase the maximum storage limit of the elastic pool through Azure's management tools, which is a quick fix requiring minimal administrative effort.\n\nD. Enable data compression to reduce the storage size of tables and indexes, which can provide space savings without data loss.\n\nE. Shrink individual databases to release unused space back to the pool, although this should be done carefully to avoid performance issues due to fragmentation.\n\nOptions B and C are less desirable as they involve deleting data or databases, which requires more effort and could impact your applications. Always consider the long-term implications and monitor storage after making changes to prevent future issues."
      },
      {
        "date": "2024-03-21T05:25:00.000Z",
        "voteCount": 1,
        "content": "The answer D is wrong. For enable data compression, you need additional space. \"The disk space requirements for enabling or disabling row or page compression are the same as for creating or rebuilding an index.\" https://learn.microsoft.com/en-us/sql/relational-databases/data-compression/data-compression?view=sql-server-ver16"
      },
      {
        "date": "2024-09-26T06:35:00.000Z",
        "voteCount": 1,
        "content": "ACD  -  A and D are fairly obvious , E is fraught with potential problems , B involves losing data the way the question is phrased , which must be undesirable"
      },
      {
        "date": "2024-07-16T19:07:00.000Z",
        "voteCount": 1,
        "content": "C is not valid as in A, you already increased pool size."
      },
      {
        "date": "2024-06-04T17:01:00.000Z",
        "voteCount": 3,
        "content": "ACD, study the free material on the MS site."
      },
      {
        "date": "2024-04-11T07:00:00.000Z",
        "voteCount": 1,
        "content": "Answer looks good - don't forget all these options could work but the question mentions the solutions must be the ones of \"least administrative effort\". For example option B Deleting data isn't as simple as it seems, you'd need to discover what data can be deleted, get permission from compliance teams on whether you can delete the \"old/unused\" data etc."
      },
      {
        "date": "2023-12-14T06:13:00.000Z",
        "voteCount": 4,
        "content": "I agree with chandlermonica833"
      },
      {
        "date": "2023-10-24T08:54:00.000Z",
        "voteCount": 1,
        "content": "Isn't taking a DB out of the pool the same fix as deleting data?"
      },
      {
        "date": "2023-07-11T11:56:00.000Z",
        "voteCount": 1,
        "content": "https://stackoverflow.com/questions/52496146/azure-sql-server-error-the-elastic-pool-has-reached-its-storage-limit-the-sto\nhttps://learn.microsoft.com/en-us/azure/azure-sql/database/file-space-manage?view=azuresql-db\nincrease resource size\nshrink database\nmove a database to another tier"
      },
      {
        "date": "2023-05-26T16:42:00.000Z",
        "voteCount": 3,
        "content": "A,C,E are the only options that will resolve the issue with elastic DB pools."
      },
      {
        "date": "2024-06-02T17:39:00.000Z",
        "voteCount": 1,
        "content": "https://learn.microsoft.com/en-us/azure/azure-sql/database/elastic-pool-resource-management?view=azuresql\n\nData compression is valid per the above article.  Scroll a little ways down."
      },
      {
        "date": "2023-04-03T17:26:00.000Z",
        "voteCount": 1,
        "content": "If we need to directly resolve the alert, I think the answer is correct."
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 44,
    "url": "https://www.examtopics.com/discussions/microsoft/view/108788-exam-dp-300-topic-1-question-44-discussion/",
    "body": "You have an Azure subscription.<br><br>You need to deploy a new Azure SQL database by using Azure Command-Line Interface (CLI).<br><br>Which three parameters are required?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t--name, --edition, and --capacity",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t--name, --tier, and --min-capacity",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t--name, --resource-group, and --server\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t--name, --licence-type, and --capacity"
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 11,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-05-29T23:46:00.000Z",
        "voteCount": 7,
        "content": "correct answer... very less discussion on DP 300 ... so i had to comment lol"
      },
      {
        "date": "2024-05-02T17:22:00.000Z",
        "voteCount": 1,
        "content": "C is correct, from Microsoft Learn:\nhttps://learn.microsoft.com/en-us/cli/azure/sql/db?view=azure-cli-latest#az-sql-db-create-required-parameters\n\nRequired Parameters\n--name -n\nName of the Azure SQL Database.\n\n--resource-group -g\nName of resource group. You can configure the default group using az configure --defaults group=&lt;name&gt;.\n\n--server -s\nName of the Azure SQL Server. You can configure the default using az configure --defaults sql-server=&lt;name&gt;."
      },
      {
        "date": "2023-09-11T16:02:00.000Z",
        "voteCount": 2,
        "content": "Answer is correct. \n\nWhen deploying the resource, obviously it needs a name. You must also define where to deploy it (resource group). And you also need to define the \"type\" of SQL resource (--server)"
      },
      {
        "date": "2023-07-04T22:59:00.000Z",
        "voteCount": 3,
        "content": "resource group is needed\nso it is correct"
      },
      {
        "date": "2023-05-09T01:20:00.000Z",
        "voteCount": 3,
        "content": "C. - Correct answer"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 45,
    "url": "https://www.examtopics.com/discussions/microsoft/view/105034-exam-dp-300-topic-1-question-45-discussion/",
    "body": "HOTSPOT<br> -<br><br>You have an Azure subscription.<br><br>You plan to migrate 10 on-premises Microsoft SQL Server instances to Azure.<br><br>You need to ensure that the migrated environment can be managed by using multiserver administration and supports master/target (MSX/TSX) jobs.<br><br>The solution must minimize administrative effort.<br><br>Which SQL deployment options should you select as the master server (MSX) and the target server (TSX)? To answer, select the appropriate options in the answer area.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/dp-300/image259.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/dp-300/image260.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2023-10-22T17:24:00.000Z",
        "voteCount": 5,
        "content": "Most, but not all, SQL Server Agent features are currently supported on Azure SQL Managed Instance. \n\nThe Multi Server Administration feature is not supported on Azure SQL Managed Instance.\n\nhttps://learn.microsoft.com/en-us/sql/ssms/agent/create-a-multiserver-environment?view=sql-server-ver16"
      },
      {
        "date": "2024-09-26T06:48:00.000Z",
        "voteCount": 1,
        "content": "SQL Virtual Machines for both.do not natively support MSX/TSX jobs (master/target job server configurations). The MSX/TSX job feature is primarily supported by SQL Server running on virtual machines (SQL on Azure VMs)"
      },
      {
        "date": "2024-08-22T07:10:00.000Z",
        "voteCount": 1,
        "content": "Virtual Machines is my answer as according to https://learn.microsoft.com/en-us/sql/ssms/agent/create-a-multiserver-environment?view=sql-server-ver16 the Multiserver Envirnment is not supported on SQL Managed Instances"
      },
      {
        "date": "2024-04-06T06:41:00.000Z",
        "voteCount": 3,
        "content": "Answer : MSX : Virtual Machines and TSX : SQL Managed Intanecs"
      },
      {
        "date": "2024-06-03T16:59:00.000Z",
        "voteCount": 1,
        "content": "Seems like answer is correct based on the ChatGPT \nChatGPT\nTo ensure that the migrated environment can be managed by using multiserver administration and supports master/target (MSX/TSX) jobs while minimizing administrative effort, you should select the following SQL deployment options:\n\nMaster Server (MSX): Azure SQL Managed Instance\nTarget Server (TSX): Azure SQL Managed Instance\n\nExplanation:\n\nAzure SQL Managed Instance provides a fully managed SQL Server instance in the cloud, offering compatibility with on-premises SQL Server features, including multiserver administration and support for master/target (MSX/TSX) jobs.\nBy selecting Azure SQL Managed Instance as both the master server (MSX) and the target server (TSX), you ensure that the migrated environment can be managed using multiserver administration and supports MSX/TSX jobs while minimizing administrative effort.\nTherefore, the correct options are:\n\nMaster Server (MSX): Azure SQL Managed Instance\nTarget Server (TSX): Azure SQL Managed Instance"
      },
      {
        "date": "2024-01-14T16:09:00.000Z",
        "voteCount": 4,
        "content": "Most, but not all, SQL Server Agent features are currently supported on Azure SQL Managed Instance. The Multi Server Administration feature is not supported on Azure SQL Managed Instance."
      },
      {
        "date": "2023-11-06T12:38:00.000Z",
        "voteCount": 2,
        "content": "For the scenario you've described where you need multiserver administration with master/target (MSX/TS) jobs in Azure and want to minimize administrative effort, the deployment options would be:\n\nMSX (Master Server): SQL Managed Instances\nTSX (Target Server): SQL Managed Instances\n\nAzure SQL Managed Instances provide a version of SQL Server that supports SQL Agent and multiserver management, which is necessary for setting up and managing MSX/TS jobs. This would allow you to migrate your on-premises SQL Server instances to Azure with full support for SQL Server Agent jobs, minimizing the changes and administrative effort required in transitioning to the cloud. Azure SQL Database does not support SQL Server Agent, which is required for MSX/TS jobs. SQL Virtual Machines could also support this, but it would not minimize administrative effort as much as managed instances since it would be like managing another on-premises server."
      },
      {
        "date": "2024-04-06T06:44:00.000Z",
        "voteCount": 3,
        "content": "SQL managed Instances : The Multi Server Administration feature for master/target (MSX/TSX) jobs aren't supported. So TSX is possible on Managed Instances for  MSX : we need Virtual Server machines to manage MSX/TSX"
      },
      {
        "date": "2023-09-02T14:45:00.000Z",
        "voteCount": 4,
        "content": "On Azure SQL Managed Instance, The Multi Server Administration feature for master/target (MSX/TSX) jobs are not supported.\nas per info from below Microsoft URL. SO, I think answer is Azure Virtual machines for MSX and TSX setup.\n\nhttps://learn.microsoft.com/en-us/sql/ssms/agent/create-a-multiserver-environment?view=sql-server-ver16\n\nhttps://learn.microsoft.com/en-us/azure/azure-sql/managed-instance/transact-sql-tsql-differences-sql-server?view=azuresql"
      },
      {
        "date": "2023-09-02T14:45:00.000Z",
        "voteCount": 4,
        "content": "On Azure SQL Managed Instance, The Multi Server Administration feature for master/target (MSX/TSX) jobs are not supported.\nas per info from below Microsoft URL. SO, I think answer is Azure Virtual machines for MSX\n\nhttps://learn.microsoft.com/en-us/sql/ssms/agent/create-a-multiserver-environment?view=sql-server-ver16\nhttps://learn.microsoft.com/en-us/azure/azure-sql/managed-instance/transact-sql-tsql-differences-sql-server?view=azuresql"
      },
      {
        "date": "2023-08-09T02:10:00.000Z",
        "voteCount": 4,
        "content": "https://learn.microsoft.com/en-us/azure/azure-sql/managed-instance/transact-sql-tsql-differences-sql-server?view=azuresql#sql-server-agent\nThe Multi Server Administration feature for master/target (MSX/TSX) jobs are not supported.\nSQLVM only in both cases :("
      },
      {
        "date": "2023-06-21T20:23:00.000Z",
        "voteCount": 1,
        "content": "Multiserver administration only applies to Managed Instance and SQL Server. Check this: https://learn.microsoft.com/en-us/sql/ssms/agent/create-a-multiserver-environment?view=sql-server-ver16"
      },
      {
        "date": "2023-08-03T21:59:00.000Z",
        "voteCount": 8,
        "content": "But what I see is \"The Multi Server Administration feature is not supported on Azure SQL Managed Instance.\""
      },
      {
        "date": "2023-04-03T17:36:00.000Z",
        "voteCount": 4,
        "content": "The Master Server (MSX) and Target Server (TSX) are SQL Server concepts used for managing multiple servers at once.\n\nThe Master Server (MSX) is the central server that manages one or more Target Servers (TSX). By using MSX, you can manage multiple SQL Server instances as if they were a single entity. MSX simplifies the administration tasks of managing multiple servers by allowing you to execute tasks on multiple servers at once, such as backing up databases or running queries.\n\nThe Target Server (TSX) is a SQL Server instance that is managed by the Master Server (MSX). TSX instances can be located on the same physical server as the MSX instance or on a different server.\n\nMSX/TSX can also be used for managing SQL Server Agent jobs, where you can define jobs at the master server and then distribute them to the target servers. This feature helps in centrally managing and scheduling SQL Server Agent jobs across multiple servers."
      },
      {
        "date": "2023-04-03T17:33:00.000Z",
        "voteCount": 1,
        "content": "The answer is correct."
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 46,
    "url": "https://www.examtopics.com/discussions/microsoft/view/106882-exam-dp-300-topic-1-question-46-discussion/",
    "body": "You have two on-premises Microsoft SQL Server 2019 instances named SQL1 and SQL2.<br><br>You need to migrate the databases hosted on SQL1 to Azure. The solution must meet the following requirements:<br><br>\u2022\tThe service that hosts the migrated databases must be able to communicate with SQL2 by using linked server connections.<br>\u2022\tAdministrative effort must be minimized.<br><br>What should you use to host the databases?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ta single Azure SQL database",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSQL Server on Azure Virtual Machines",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure SQL Managed Instance\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tan Azure SQL Database elastic pool"
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 8,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-04-20T22:42:00.000Z",
        "voteCount": 7,
        "content": "C is correct, Azure SQL Managed Instance.\n\nLinked servers are available in SQL Server Database Engine and Azure SQL Managed Instance. They are not enabled in Azure SQL Database singleton and elastic pools. \nhttps://learn.microsoft.com/en-us/sql/relational-databases/linked-servers/linked-servers-database-engine?view=sql-server-2017"
      },
      {
        "date": "2024-09-26T06:53:00.000Z",
        "voteCount": 1,
        "content": "Agree C is obvious and other answers are not suitable for reasons stated by others"
      },
      {
        "date": "2024-01-06T00:59:00.000Z",
        "voteCount": 1,
        "content": "1. Linked servers are NOT available in Azure SQL Database.\n2. Also Less Administration."
      },
      {
        "date": "2023-08-29T22:13:00.000Z",
        "voteCount": 2,
        "content": "i think C is correct because Administrative effort must be minimized."
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 47,
    "url": "https://www.examtopics.com/discussions/microsoft/view/107389-exam-dp-300-topic-1-question-47-discussion/",
    "body": "HOTSPOT<br> -<br><br>You have an on-premises Microsoft SQL Server 2016 instance that hosts a database named db1. You have an Azure subscription that contains an Azure SQL managed instance named MI1.<br><br>You plan to perform an online migration of db1 to MI1 by using Azure Database Migration Service.<br><br>You need to create the backups for the migration. The solution must minimize the number of backup files created.<br><br>Which type of backups should you create, and how should you store the backups? To answer, select the appropriate options in the answer area.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/dp-300/image261.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/dp-300/image262.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2023-04-24T22:49:00.000Z",
        "voteCount": 6,
        "content": "The given answer is correct as Azure Database Migration Service cannot use backups appended to a single file.\n\nReference: https://www.examtopics.com/exams/microsoft/dp-300/view/10/"
      },
      {
        "date": "2023-04-24T22:50:00.000Z",
        "voteCount": 4,
        "content": "Correct reference link: https://learn.microsoft.com/en-us/azure/dms/known-issues-azure-sql-db-managed-instance-online"
      },
      {
        "date": "2024-04-06T06:55:00.000Z",
        "voteCount": 2,
        "content": "You need to create the backups for the migration. The solution must minimize the number of backup files created. In order to minimize the number of files , we need to perform a full and a differnetial backup(s)"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 48,
    "url": "https://www.examtopics.com/discussions/microsoft/view/105036-exam-dp-300-topic-1-question-48-discussion/",
    "body": "You have a SQL Server on Azure Virtual Machines instance named SQLVM1 that was deployed by using an Azure Marketplace SQL Server 2019 Enterprise image.<br><br>You need to change the Microsoft SQL Server instance on SQLVM1 to the Standard edition. The solution must ensure licensing compliance.<br><br>What should you do first?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tFrom the SQL Server Installation Center on SQLVM1, run the Edition Upgrade wizard.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tFrom SQLVM1, uninstall the SQL Server instance.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tFrom the SQL Server Installation Center on SQLVM1, run the Repair wizard.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tFrom the Azure portal, reconfigure SQLVM1."
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2023-04-03T17:50:00.000Z",
        "voteCount": 10,
        "content": "The answer looks right.\n\nNo, you cannot use the Edition Upgrade wizard to change from the Enterprise edition to the Standard edition of SQL Server. The Edition Upgrade wizard is used to upgrade to a higher edition of SQL Server, not to downgrade to a lower edition. In this case, since you want to change from the Enterprise edition (a higher edition) to the Standard edition (a lower edition), you need to uninstall the Enterprise edition of SQL Server from the virtual machine and then install the Standard edition."
      },
      {
        "date": "2024-09-26T07:24:00.000Z",
        "voteCount": 1,
        "content": "good call , you cannot downgrade using edition upgrade wizard to must uninstall"
      },
      {
        "date": "2023-07-05T07:09:00.000Z",
        "voteCount": 1,
        "content": "B is correct \nhttps://learn.microsoft.com/en-us/azure/azure-sql/virtual-machines/windows/change-sql-server-edition?view=azuresql&amp;tabs=azure-portal"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 49,
    "url": "https://www.examtopics.com/discussions/microsoft/view/110539-exam-dp-300-topic-1-question-49-discussion/",
    "body": "Your on-premises network contains a Microsoft SQL Server 2016 server that hosts a database named db1.<br><br>You have an Azure subscription.<br><br>You plan to migrate db1 to an Azure SQL managed instance.<br><br>You need to create the SQL managed instance. The solution must minimize the disk latency of the instance.<br><br>Which service tier should you use?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tBusiness Critical\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tHyperscale",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tGeneral Purpose",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tPremium"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 9,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-07-05T07:19:00.000Z",
        "voteCount": 9,
        "content": "General purpose has disk latency, Business critical puts the logs on SSD, Premium is a DTU offering which is not supported on Azure SQL MI, Hyperscale is not on Managed Instance"
      },
      {
        "date": "2023-05-30T05:18:00.000Z",
        "voteCount": 4,
        "content": "ChatGPT confirms correct answer is A."
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 50,
    "url": "https://www.examtopics.com/discussions/microsoft/view/106451-exam-dp-300-topic-1-question-50-discussion/",
    "body": "You have an Azure subscription.<br><br>You need to deploy an Azure SQL database. The solution must meet the following requirements:<br><br>\u2022\tDynamically scale CPU resources.<br>\u2022\tEnsure that the database can be paused to reduce costs.<br><br>What should you use?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tthe Business Critical service tier",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tthe serverless compute tier\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tan elastic pool",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tthe General Purpose service tier"
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 4,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-06-24T22:59:00.000Z",
        "voteCount": 2,
        "content": "B. Serverless compute tier is correct as it allows for auto pause"
      },
      {
        "date": "2023-11-07T07:41:00.000Z",
        "voteCount": 1,
        "content": "For the requirements you've outlined, you should use:\n\nB. the serverless compute tier\n\nHere's how it aligns with your requirements:\n\nDynamically scale CPU resources: The serverless tier automatically scales compute resources based on workload demand, and you only pay for the compute resources you use.\nEnsure that the database can be paused to reduce costs: One of the key features of the serverless tier is the ability to automatically pause the database during inactive periods to save costs, and then automatically resume when activity picks up again."
      },
      {
        "date": "2023-04-16T19:04:00.000Z",
        "voteCount": 4,
        "content": "B is correct, \n\nServerless is a compute tier for single databases in Azure SQL Database that automatically scales compute based on workload demand and bills for the amount of compute used per second. The serverless compute tier also automatically pauses databases during inactive periods when only storage is billed and automatically resumes databases when activity returns. The serverless compute tier is available in the General Purpose service tier and currently in preview in the Hyperscale service tier.\n\n\nabove statements from below link\n\nhttps://learn.microsoft.com/en-us/azure/azure-sql/database/serverless-tier-overview?view=azuresql&amp;tabs=general-purpose"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 51,
    "url": "https://www.examtopics.com/discussions/microsoft/view/106452-exam-dp-300-topic-1-question-51-discussion/",
    "body": "HOTSPOT<br> -<br><br>You have an Azure subscription.<br><br>You need to deploy an Azure SQL managed instance that meets the following requirements:<br><br>\u2022\tOptimize latency.<br>\u2022\tMaximize the memory-to-vCore ratio.<br><br>Which service tier and hardware generation should you use? To answer, select the appropriate options in the answer area.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/dp-300/image263.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/dp-300/image264.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2023-04-16T19:18:00.000Z",
        "voteCount": 5,
        "content": "the Answer given is correct\n\nBusiness Critical service tier on Premium Series Memory-Optimized\n\nThe Business Critical service tier is built for applications with high I/O requirements. It offers the highest resilience to failures using several isolated replicas.\n\nhttps://learn.microsoft.com/en-us/azure/azure-sql/managed-instance/sql-managed-instance-paas-overview?view=azuresql#business-critical-service-tier"
      },
      {
        "date": "2023-11-07T07:51:00.000Z",
        "voteCount": 2,
        "content": "Service tier:\nBusiness Critical\n\nHardware generation:\nPremium-series - memory optimized\n\nHere's why these selections meet the requirements:\n\nBusiness Critical tier: This service tier is optimized for latency-sensitive workloads and provides the lowest latency due to its use of local SSD storage. It also offers a higher memory-to-vCore ratio compared to other tiers.\nPremium-series - memory optimized: This hardware generation provides the most memory per vCore, which maximizes the memory-to-vCore ratio. This is suitable for high-performance database workloads that require more memory for in-memory operations."
      },
      {
        "date": "2023-07-05T07:22:00.000Z",
        "voteCount": 2,
        "content": "Given Answer is correct\n\nBusiness critical optimises latency"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 52,
    "url": "https://www.examtopics.com/discussions/microsoft/view/115081-exam-dp-300-topic-1-question-52-discussion/",
    "body": "You have a Microsoft SQL Server 2017 server.<br><br>You need to migrate the server to Azure. The solution must meet the following requirements:<br><br>\u2022\tEnsure that the latest version of SQL Server is used.<br>\u2022\tSupport the SQL Server Agent service.<br>\u2022\tMinimize administrative effort.<br><br>What should you use?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tan Azure SQL Database elastic pool",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure SQL Database",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSQL Server on Azure Virtual Machines",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure SQL Managed Instance\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 14,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-01-06T01:20:00.000Z",
        "voteCount": 5,
        "content": "Common solution from all 3 requirements is Azure SQL Managed Instance.\n\nEnsure that the latest version of SQL Server is used - Possible solutions - both MI and Azure SQL DB\n\u2022 Support the SQL Server Agent service - Possible solutions - both MI and VM\n\u2022 Minimize administrative effort - Possible solutions - both MI and Azure SQL DB"
      },
      {
        "date": "2024-09-17T23:27:00.000Z",
        "voteCount": 1,
        "content": "SO if everyone is saying D, then what's the actual correct answer then?"
      },
      {
        "date": "2024-06-03T17:06:00.000Z",
        "voteCount": 1,
        "content": "Answer is C ( Chat GPT)\n\nTo migrate your Microsoft SQL Server 2017 server to Azure while meeting the specified requirements, including ensuring the latest version of SQL Server is used, supporting the SQL Server Agent service, and minimizing administrative effort, you should use:\n\nC. SQL Server on Azure Virtual Machines\n\nExplanation:\n\nSQL Server on Azure Virtual Machines allows you to run SQL Server in a virtualized environment hosted in Azure, providing full control over the SQL Server instance, including the ability to install and manage SQL Server Agent service.\nWith SQL Server on Azure Virtual Machines, you can choose the SQL Server version you want to deploy, ensuring that the latest version is used.\nThis option provides the closest compatibility to an on-premises SQL Server environment while minimizing administrative effort compared to other options like managing individual databases in Azure SQL Database or Azure SQL Managed Instance.\nTherefore, the correct choice is option C. SQL Server on Azure Virtual Machines."
      },
      {
        "date": "2024-07-01T09:13:00.000Z",
        "voteCount": 2,
        "content": "This is wrong.  It(ChatGPT) says that a SQL Server on Azure VM is less administrative effort than a SQL Managed Instance?  A full SQL VM is far more overhead.  This is very flawed and ChatGPT often gets confused.   Read the free training material online.  Answer is D."
      },
      {
        "date": "2024-04-12T01:38:00.000Z",
        "voteCount": 3,
        "content": "This needs correcting please, answer is D - Managed Instance"
      },
      {
        "date": "2024-04-09T22:08:00.000Z",
        "voteCount": 2,
        "content": "The correct answer is D. \nManaged Instance ensure the latest version of SQL Server, because offload you to managed patches and update.\nManaged Instance support SQL Server Agent and minimize administrative effort compared to manage a VM with SQL Server installed"
      },
      {
        "date": "2024-01-20T14:12:00.000Z",
        "voteCount": 1,
        "content": "MI as it minimizes admin effort"
      },
      {
        "date": "2023-11-07T07:53:00.000Z",
        "voteCount": 3,
        "content": "D. Azure SQL Managed Instance\n\nHere's why this option fits your requirements:\n\nEnsure that the latest version of SQL Server is used: Azure SQL Managed Instance runs the latest stable version of SQL Server and is automatically updated, so you do not need to manually upgrade SQL Server.\nSupport the SQL Server Agent service: Azure SQL Managed Instance supports SQL Server Agent, which allows you to schedule jobs and automate tasks just like you would in an on-premises SQL Server environment.\nMinimize administrative effort: Azure SQL Managed Instance provides a fully managed database service that reduces administrative overhead. It handles most of the management functions such as upgrading, patching, backups, and monitoring without user intervention."
      },
      {
        "date": "2023-10-30T08:18:00.000Z",
        "voteCount": 1,
        "content": "D is ok."
      },
      {
        "date": "2023-10-05T21:22:00.000Z",
        "voteCount": 2,
        "content": "\u2022 Ensure that the latest version of SQL Server is used.  MI has / SQL on VM has not\n\u2022 Support the SQL Server Agent service. MI has / SQL on VM has \n\u2022 Minimize administrative effort.  MI wins over SQL on VM"
      },
      {
        "date": "2023-10-01T06:40:00.000Z",
        "voteCount": 1,
        "content": "Latest version available in MI"
      },
      {
        "date": "2023-08-17T23:39:00.000Z",
        "voteCount": 1,
        "content": "Latest version available in MI"
      },
      {
        "date": "2023-08-08T03:40:00.000Z",
        "voteCount": 1,
        "content": "Managed Instance - latest version (also Azure SQL) plus support for SQL Agent jobs."
      },
      {
        "date": "2023-08-04T06:26:00.000Z",
        "voteCount": 2,
        "content": "Latest version available in MI"
      },
      {
        "date": "2023-07-29T05:34:00.000Z",
        "voteCount": 2,
        "content": "The answer is D. Because: ensure that the latest version of SQL Server is used.\nOnly SQL MI is always in latest version. SQL on VM can be in previus version."
      },
      {
        "date": "2023-07-18T07:08:00.000Z",
        "voteCount": 2,
        "content": "For administrative efforts to be minimized, Azure SQL Managed Instance is the correct answer."
      },
      {
        "date": "2023-07-14T02:19:00.000Z",
        "voteCount": 3,
        "content": "Answer D \nhttps://learn.microsoft.com/en-us/sql/ssms/agent/set-service-startup-account-sql-server-agent-sql-server-configuration-manager?view=sql-server-ver16 \nApplies to:  SQL Server and Azure SQL Managed Instance"
      },
      {
        "date": "2023-07-14T00:36:00.000Z",
        "voteCount": 4,
        "content": "In my opinion, both VM and MI ensure the latest version and support Agent service. MI requires less administrative effort so it should be the correct answer. Correct me if I am wrong."
      },
      {
        "date": "2023-08-31T17:15:00.000Z",
        "voteCount": 1,
        "content": "no you are right"
      },
      {
        "date": "2023-09-19T09:12:00.000Z",
        "voteCount": 1,
        "content": "100% right. SQL M.I is a (PaaS) database engine that handles most database management functions such as upgrading, patching, backups, and monitoring without user involvement.\n\nhttps://learn.microsoft.com/en-us/azure/azure-sql/managed-instance/sql-managed-instance-paas-overview?view=azuresql"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 53,
    "url": "https://www.examtopics.com/discussions/microsoft/view/115082-exam-dp-300-topic-1-question-53-discussion/",
    "body": "HOTSPOT<br> -<br><br>You have a Microsoft SQL Server 2017 server that hosts five databases.<br><br>You plan to migrate the databases to Azure.<br><br>You need to recommend a solution that meets the following requirements:<br><br>\u2022\tAutomatically scales compute based on the workload demand<br>\u2022\tProvides per-second billing<br><br>What should you include in the recommendation? To answer, select the appropriate options in the answer area.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/dp-300/image277.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/dp-300/image278.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2023-10-17T10:39:00.000Z",
        "voteCount": 7,
        "content": "We have five bds, SQL Database in serverless compute tier is for single databases.... so we would need no a single serverless SQL Databases... but five.\n\nWe need to automatically scale compute based on workload, and be billed by the second...For five databses we would create an elastic pool ( with  fixed min and max resources for automatic compute scaling of the bds), using vCore model, with provisioned compute tier so we are charged by the second(DTU model charges by hour).\nvCore model has General Purpose, Business Critical, and Hyperscale.... we would use GEneral purpose.\n\nServerless compute tier es for single databases... so we would need five servers SQL Databases.... not \"a single Azure SQL databases in the serverless compute tier\"."
      },
      {
        "date": "2024-07-25T00:33:00.000Z",
        "voteCount": 1,
        "content": "On the other hand, you won't meet the \"per-second billing\" requirement unless you choose Serverless compute tier. Looks like another question with ambiguous answers, but I would vote \"Single Azure database in the serverless compute tier\" per each migrated database :)."
      },
      {
        "date": "2023-11-07T07:59:00.000Z",
        "voteCount": 5,
        "content": "In the answer area, you should choose:\n\nAzure service:\nA single Azure SQL database in the serverless compute tier\n\nService tier:\nGeneral Purpose\n\nHere\u2019s the explanation:\n\nA single Azure SQL database in the serverless compute tier: This service automatically scales compute based on the workload demand, which is one of your requirements. Additionally, the serverless tier offers per-second billing, allowing you to pay only for the compute you use.\nGeneral Purpose service tier: This tier is typically available with the serverless compute model and offers a balanced and scalable compute and storage options suitable for most business workloads."
      },
      {
        "date": "2024-09-23T13:30:00.000Z",
        "voteCount": 1,
        "content": "Azure Service: Serveless computer tier\nService Tier: General Purpose\nthe key word is \"per second billing\" , serveless is the option to use, and General Purpose Service Tier works with it"
      },
      {
        "date": "2024-04-09T22:24:00.000Z",
        "voteCount": 2,
        "content": "The question talk about five database, so the answer \"A single serverless SQL Database\" must be to exclude.\nThe only possible is the elastic pool ( with fixed min and max resources for automatic compute scaling). The tier must be a vCore one, because DTU is charged by hour, so the second answer is General Puropse"
      },
      {
        "date": "2023-07-13T16:17:00.000Z",
        "voteCount": 3,
        "content": "https://azure.microsoft.com/en-us/pricing/details/azure-sql-database/single/\nServerless compute tier also mentioned here."
      },
      {
        "date": "2023-07-13T16:13:00.000Z",
        "voteCount": 2,
        "content": "https://learn.microsoft.com/en-us/azure/azure-sql/database/serverless-tier-overview?view=azuresql-db&amp;tabs=general-purpose\nServerless is a compute tier for single databases in Azure SQL Database that automatically scales compute based on workload demand and bills for the amount of compute used per second."
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 54,
    "url": "https://www.examtopics.com/discussions/microsoft/view/117596-exam-dp-300-topic-1-question-54-discussion/",
    "body": "You have an on-premises Microsoft SQL Server 2019 database named SQL1 that uses merge replication.<br><br>You need to migrate SQL1 to Azure.<br><br>Which service should you use?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure SQL Edge",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure SQL Database",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSQL Server on Azure Virtual Machines",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure SQL Managed Instance"
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-04-12T01:59:00.000Z",
        "voteCount": 2,
        "content": "I agree its C - Azure VM. Careful on this one - Azure SQL MI does support \"transactional replication\", however it does not support the subset feature of \"merge replication\":\n\nhttps://learn.microsoft.com/en-us/azure/azure-sql/database/replication-to-sql-database?view=azuresql#types-of-replication"
      },
      {
        "date": "2023-11-07T08:05:00.000Z",
        "voteCount": 1,
        "content": "C. SQL Server on Azure Virtual Machines\n\nHere's why this option is suitable:\n\nSQL Server on Azure Virtual Machines: This option is essentially IaaS (Infrastructure as a Service), which means you get a full virtual machine with full control over the SQL Server instance. It supports SQL Server features just like an on-premises server would, including merge replication. This allows for a smoother migration of databases that rely on specific SQL Server features that are not supported by PaaS (Platform as a Service) options.\nThe other options have limitations regarding merge replication:\n\nA. Azure SQL Edge: This service is designed for edge computing scenarios and IoT devices, not for general database hosting.\nB. Azure SQL Database: This is a PaaS offering that does not support SQL Server's merge replication.\nD. Azure SQL Managed Instance: While it is the PaaS offering that comes closest to the full capabilities of SQL Server, it still does not support merge replication as of my last update in April 2023."
      },
      {
        "date": "2023-08-08T03:45:00.000Z",
        "voteCount": 3,
        "content": "https://learn.microsoft.com/en-us/azure/azure-sql/database/replication-to-sql-database?view=azuresql-db#supported-configurations.\n\"Peer-to-peer transactional replication and merge replication are not supported\" - so the answer is correct, we need to use VMs"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 55,
    "url": "https://www.examtopics.com/discussions/microsoft/view/115049-exam-dp-300-topic-1-question-55-discussion/",
    "body": "You have an on-premises datacenter that contains a 2-TB Microsoft SQL Server 2019 database named DB1.<br><br>You need to recommend a solution to migrate DB1 to an Azure SQL managed instance. The solution must minimize downtime and administrative effort.<br><br>What should you include in the recommendation?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tLog Replay Service (LRS)",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tlog shipping",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ttransactional replication",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSQL Data Sync"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-09-26T10:02:00.000Z",
        "voteCount": 1,
        "content": "A - Log Replay Service is correct - Claude - While transactional replication is a solid, mature option, Log Replay Service (LRS) is becoming a popular choice for minimizing downtime and administrative effort when migrating large databases to Azure SQL Managed Instance, particularly when log-based migrations are desired. Since LRS is built specifically for this use case, it can indeed be the right choice for your scenario"
      },
      {
        "date": "2023-11-07T08:09:00.000Z",
        "voteCount": 4,
        "content": "A. Log Replay Service (LRS)\n\nHere's why LRS is suitable for your scenario:\n\nLog Replay Service: This service, also known as Azure Database Migration Service (DMS), supports online migrations with minimal downtime. It allows you to continuously replicate data (with active transaction log replay) from your on-premises SQL Server to an Azure SQL Managed Instance until you decide to perform the final cutover, thereby minimizing downtime."
      },
      {
        "date": "2024-08-02T14:19:00.000Z",
        "voteCount": 1,
        "content": "The answer is correct, however\n\"Log Replay Service: This service, also known as Azure Database Migration Service (DMS), \"\nthis is not true, they are different tools"
      },
      {
        "date": "2023-11-07T08:09:00.000Z",
        "voteCount": 3,
        "content": "B. Log shipping: While log shipping could be used for migration and would involve less administrative effort than some other methods, it typically incurs more downtime during the cutover to the new environment because it is not as seamless as LRS.\nC. Transactional replication: Transactional replication is generally used for keeping data synchronized across SQL Server instances. It is not designed for one-time database migrations and can be complex to set up for this purpose.\nD. SQL Data Sync: This service is used to synchronize data across multiple SQL databases and is not optimized for one-time migrations of large databases, as it can be slower and less reliable than LRS for this use case."
      },
      {
        "date": "2023-07-18T07:17:00.000Z",
        "voteCount": 4,
        "content": "Answer A.\nThe Log Replay service LRS is only used with Azure SQL Managed Instance.\nhttps://learn.microsoft.com/en-us/azure/azure-sql/managed-instance/log-replay-service-migrate?view=azuresql-mi&amp;tabs=sas-token"
      },
      {
        "date": "2023-07-14T09:29:00.000Z",
        "voteCount": 3,
        "content": "Answer A.\nLess administrative effort compared to transactional replication\nhttps://learn.microsoft.com/en-us/azure/azure-sql/managed-instance/log-replay-service-migrate?view=azuresql&amp;tabs=sas-token"
      },
      {
        "date": "2023-07-13T06:44:00.000Z",
        "voteCount": 1,
        "content": "C seems right"
      },
      {
        "date": "2023-08-08T03:46:00.000Z",
        "voteCount": 3,
        "content": "it is A, I've done this a couple of times."
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 56,
    "url": "https://www.examtopics.com/discussions/microsoft/view/115177-exam-dp-300-topic-1-question-56-discussion/",
    "body": "You have an Azure subscription.<br><br>You plan to deploy an instance of SQL Server on Azure Virtual Machines that supports Write Accelerator.<br><br>Which virtual machine series should you use?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tE-series",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tG-series",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tH-series",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tM-series"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2023-11-07T08:13:00.000Z",
        "voteCount": 3,
        "content": "D. M-series\n\nWrite Accelerator is a feature designed to improve write performance on Azure Managed Disks attached to certain VM series that are optimized for large in-memory database workloads, like the M-series. The M-series VMs are memory-optimized virtual machines suitable for SQL Server workloads, and they support the Write Accelerator feature when used with M-series VMs that are provisioned with Premium Storage."
      },
      {
        "date": "2023-09-11T16:33:00.000Z",
        "voteCount": 2,
        "content": "Write Acceleration is a disk feature that is only available for the M-Series Virtual Machines (VMs). \n\nThe purpose of write acceleration is to improve the I/O latency of writes against Azure Premium Storage when you need single digit I/O latency due to high volume mission critical OLTP workloads or data warehouse environments.\n\nhttps://learn.microsoft.com/en-us/azure/azure-sql/virtual-machines/windows/storage-configuration?view=azuresql&amp;tabs=windows2016"
      },
      {
        "date": "2023-08-28T18:14:00.000Z",
        "voteCount": 1,
        "content": "Answer D is correct.   \nhttps://azure.microsoft.com/en-us/blog/write-accelerator-for-m-series-virtual-machines-now-generally-available/"
      },
      {
        "date": "2023-07-14T09:32:00.000Z",
        "voteCount": 1,
        "content": "Answer D\nhttps://learn.microsoft.com/en-us/azure/virtual-machines/how-to-enable-write-accelerator"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 57,
    "url": "https://www.examtopics.com/discussions/microsoft/view/120251-exam-dp-300-topic-1-question-57-discussion/",
    "body": "You have an on-premises Microsoft SQL Server 2019 instance that hosts a database named DB1.<br><br>You have an Azure subscription that contains an Azure SQL database named SQLDB1.<br><br>You need to replicate DB1 to SQLDB1.<br><br>Which type of replication should you use?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ttransactional\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tpeer-to-peer",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tsnapshot",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tmerge"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 2,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-11-07T08:47:00.000Z",
        "voteCount": 1,
        "content": "A. Transactional Replication would be the closest match, with the understanding that Azure SQL Database can only act as a subscriber and the replication would be one-way from your on-premises SQL Server to Azure SQL Database."
      },
      {
        "date": "2023-10-01T08:29:00.000Z",
        "voteCount": 1,
        "content": "A is correct"
      },
      {
        "date": "2023-09-17T05:53:00.000Z",
        "voteCount": 1,
        "content": "Yes, the correct answer is A. \nSnapshot Replication Applies to:  SQL Server  Azure SQL Managed Instance. So it's not correct.\nhttps://learn.microsoft.com/en-us/sql/relational-databases/replication/snapshot-replication?view=sql-server-ver16"
      },
      {
        "date": "2023-09-11T16:36:00.000Z",
        "voteCount": 1,
        "content": "Transactional replication typically starts with a snapshot of the publication database objects and data. \n\nAs soon as the initial snapshot is taken, subsequent data changes and schema modifications made at the Publisher are usually delivered to the Subscriber as they occur (in near real time). \n\nThe data changes are applied to the Subscriber in the same order and within the same transaction boundaries as they occurred at the Publisher; therefore, within a publication, transactional consistency is guaranteed.\n\nhttps://learn.microsoft.com/en-us/sql/relational-databases/replication/transactional/transactional-replication?view=sql-server-ver16"
      },
      {
        "date": "2023-09-11T16:35:00.000Z",
        "voteCount": 3,
        "content": "You can configure an Azure SQL Database as the push subscriber in a one-way transactional or snapshot replication topology.\n\nhttps://learn.microsoft.com/en-us/azure/azure-sql/database/replication-to-sql-database?view=azuresql"
      },
      {
        "date": "2023-09-08T02:40:00.000Z",
        "voteCount": 1,
        "content": "A or C, only possible. \"Snapshot and one-way transactional replication are supported. Peer-to-peer transactional replication and merge replication are not supported.\"\n\nBut definitely, A is the best option according to the statement."
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 58,
    "url": "https://www.examtopics.com/discussions/microsoft/view/115083-exam-dp-300-topic-1-question-58-discussion/",
    "body": "HOTSPOT<br> -<br><br>You have two on-premises servers that run Windows Server 2019 and host a Microsoft SQL server 2017 Always On availability group named AG1. AG1 contains a single database named DB1.<br><br>You have an Azure subscription. The subscription contains a virtual machine named VM1 that runs Linux.<br><br>You need to migrate DB1 to a SQL Server 2019 instance on VM1. The solution must minimize the downtime of DB1 during the migration.<br><br>What should you do? To answer, select the appropriate options in the answer area.<br><br>NOTE: Each correct selection is worth one-point.<br><br><img src=\"https://img.examtopics.com/dp-300/image279.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/dp-300/image280.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2023-09-05T07:15:00.000Z",
        "voteCount": 10,
        "content": "Disregard my previous discussion, Answer that makes sense here is 1) Create a SQL 2019 AG on VM1 and then use 2) Distributed availability group for actual cutover/migration"
      },
      {
        "date": "2024-04-10T07:09:00.000Z",
        "voteCount": 3,
        "content": "https://learn.microsoft.com/en-us/sql/database-engine/availability-groups/windows/distributed-availability-groups?view=sql-server-ver16\n\"A distributed Availability group is a special type of availability group that spans two separate availability groups. The availability groups that partecipate don't need to be in the same location. They can be phisical, virtual on-permises, in the public cloud or anywhere. \nThis includes cross-domain and even cross-platform\".\n\nSo the answers will be\n1.  Create a SQL 2019 AG on VM1\n2. Distributed availability group"
      },
      {
        "date": "2024-08-01T05:36:00.000Z",
        "voteCount": 1,
        "content": "also from the link sca88 posted, regarding different version of sql server in the same or distributed availbility groups - \n\"Distributed availability groups in SQL Server 2017 or later can mix major versions of SQL Server in the same distributed availability group. The AG containing read/write primary can be the same version or lower than the other AGs participating in the distributed AG. The other AGs can be the same version or higher. This scenario is targeted to upgrade and migration scenarios. \" \n\nthat also emphasize why the answer in the comment above me is the correct one.\nwhich hints that the those are the two correct answe"
      },
      {
        "date": "2023-11-07T08:55:00.000Z",
        "voteCount": 3,
        "content": "To prepare for the migration, you should upgrade the on-premises SQL servers to SQL Server 2019 and add a secondary replica to AG1. This will ensure that the on-premises servers are compatible with the SQL Server 2019 instance on VM1 and that AG1 can support cross-platform migration.\n\nTo perform the migration, you should use a distributed availability group. This is a feature that allows you to create a distributed availability group that spans two availability groups, one on Windows and one on Linux. You can then perform a manual failover of the distributed availability group to VM1 and remove the on-premises replicas. This will minimize the downtime of DB1 during the migration."
      },
      {
        "date": "2023-10-30T08:54:00.000Z",
        "voteCount": 1,
        "content": "Step 1: Create a new SQL Server 2019 instance on VM1.\nYou can create a new SQL Server 2019 instance on VM1 by using the Azure portal, the Azure CLI, or the Azure PowerShell modules.\nStep 2: Use the Azure SQL Migration extension for Azure Data Studio to migrate DB1 to the new SQL Server 2019 instance on VM1."
      },
      {
        "date": "2023-08-31T13:00:00.000Z",
        "voteCount": 3,
        "content": "Add a secondary replica to Ag1 and Azure migrate are correct answers basing on sql version supportability in distributed AG in below url \nhttps://learn.microsoft.com/en-us/sql/database-engine/availability-groups/windows/distributed-availability-groups?view=sql-server-ver16"
      },
      {
        "date": "2023-08-28T03:24:00.000Z",
        "voteCount": 2,
        "content": "upgrade the onprem to SQL 2019, then distributed availability group. \nhttps://learn.microsoft.com/en-us/azure/azure-sql/migration-guides/virtual-machines/sql-server-distributed-availability-group-complete-migration?view=azuresql"
      },
      {
        "date": "2023-08-07T17:58:00.000Z",
        "voteCount": 2,
        "content": "And upgrade of the on-premises sql server?"
      },
      {
        "date": "2023-07-13T16:56:00.000Z",
        "voteCount": 2,
        "content": "https://learn.microsoft.com/en-us/azure/azure-sql/migration-guides/virtual-machines/sql-server-to-sql-on-azure-vm-migration-overview?view=azuresql-vm\nA distributed availability group is a special type of availability group that spans two separate availability groups. The availability groups that participate in a distributed availability group don't need to be in the same location and include cross-domain support.\n\nThis method minimizes downtime, use when you have an availability group configured on-premises."
      },
      {
        "date": "2023-07-13T16:52:00.000Z",
        "voteCount": 1,
        "content": "https://learn.microsoft.com/en-us/azure/azure-sql/migration-guides/virtual-machines/sql-server-to-sql-on-azure-vm-migration-overview?view=azuresql-vm\nAzure Migrate\nThe source server remains online and services requests while the source and destination server synchronize data allowing for an almost seamless migration."
      },
      {
        "date": "2023-07-13T16:46:00.000Z",
        "voteCount": 1,
        "content": "Azure Migrate and other migration tools - https://learn.microsoft.com/en-us/training/modules/evaluate-strategies-for-migrating-to-azure-sql/4-describe-azure-database-migration-options"
      },
      {
        "date": "2023-07-13T16:38:00.000Z",
        "voteCount": 1,
        "content": "Availability groups - distributed\nhttps://learn.microsoft.com/en-us/training/modules/deploy-iaas-solutions-with-azure-sql/5-explain-high-availability-and-disaster-recovery-options\nAlways On availability groups can be implemented between two or more (up to a maximum of nine) SQL Server instances running on Azure virtual machines or across an on-premises data center and Azure. \nhttps://learn.microsoft.com/en-us/sql/database-engine/availability-groups/windows/distributed-availability-groups?view=sql-server-ver16"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 59,
    "url": "https://www.examtopics.com/discussions/microsoft/view/115092-exam-dp-300-topic-1-question-59-discussion/",
    "body": "DRAG DROP<br> -<br><br>You have an Azure SQL database named DB1.<br><br>You need to create a partitioned table in DB1.<br><br>Which three objects should you create in sequence? To answer, move the appropriate objects from the list of objects to the answer area and arrange them in the correct order.<br><br><img src=\"https://img.examtopics.com/dp-300/image281.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/dp-300/image282.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2023-07-17T23:54:00.000Z",
        "voteCount": 16,
        "content": "A partition function\nA partition scheme\nA table"
      },
      {
        "date": "2024-04-12T02:42:00.000Z",
        "voteCount": 1,
        "content": "Last option needs correcting, it should be \"table\" - the question clearly states \"create a partitioned table\"."
      },
      {
        "date": "2023-09-17T07:33:00.000Z",
        "voteCount": 4,
        "content": "Reference:\nhttps://learn.microsoft.com/en-us/sql/relational-databases/partitions/create-partitioned-tables-and-indexes?view=sql-server-ver16\nObviously, the answer is: A partition function =&gt; A partition scheme =&gt; A table"
      },
      {
        "date": "2023-08-28T18:40:00.000Z",
        "voteCount": 2,
        "content": "A partition function\nA partition scheme\nA table.\nI think you need to have partioned table created before creating an aligned index. As its Azure sql database, it DOESNOT support multiple filegroup's. I believe above is the correct sequence"
      },
      {
        "date": "2023-08-06T17:39:00.000Z",
        "voteCount": 4,
        "content": "A filegroup\nPartition Function\nPartition Scheme"
      },
      {
        "date": "2023-08-06T17:41:00.000Z",
        "voteCount": 2,
        "content": "Since this is Azure SQL DB, we cannot create filegroup and hence given answer is correct"
      },
      {
        "date": "2023-08-08T03:53:00.000Z",
        "voteCount": 2,
        "content": "you cannot create an aligned index without having the table first."
      },
      {
        "date": "2023-07-13T17:00:00.000Z",
        "voteCount": 3,
        "content": "https://learn.microsoft.com/en-us/sql/relational-databases/partitions/partitioned-tables-and-indexes?view=sql-server-ver16"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 60,
    "url": "https://www.examtopics.com/discussions/microsoft/view/125498-exam-dp-300-topic-1-question-60-discussion/",
    "body": "DRAG DROP<br> -<br><br>You have an Azure subscription that contains an instance of SQL Server on Azure Virtual Machines named SQLVM1 and a virtual machine named Server1 that runs Windows Server. SQLVM1 and Server1 are joined to an Active Directory Domain Services (AD DS) domain. Server1 hosts a file share named Share1.<br><br>You need to ensure that a SOL Server Agent job step on SQLVM1 can access the files in Share1. The solution must use the principle of least privilege.<br><br>Which three actions should you perform in sequence? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.<br><br><img src=\"https://img.examtopics.com/dp-300/image291.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/dp-300/image292.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-01-07T06:55:00.000Z",
        "voteCount": 2,
        "content": "Check limitations:\nhttps://learn.microsoft.com/en-us/sql/ssms/agent/create-a-sql-server-agent-proxy?view=sql-server-ver16"
      },
      {
        "date": "2024-04-10T07:42:00.000Z",
        "voteCount": 1,
        "content": "thanks!"
      },
      {
        "date": "2023-12-20T20:39:00.000Z",
        "voteCount": 1,
        "content": "Someone has a link for this?"
      },
      {
        "date": "2023-11-06T00:54:00.000Z",
        "voteCount": 1,
        "content": "Correct."
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 61,
    "url": "https://www.examtopics.com/discussions/microsoft/view/124072-exam-dp-300-topic-1-question-61-discussion/",
    "body": "You have an Azure subscription.<br><br>You need to deploy an instance of SQL Server on Azure Virtual Machines. The solution must meet the following requirements:<br><br>\u2022\tCustom performance configuration, such as IOPS, capacity, and throughout, must be supported.<br>\u2022\tCosts must be minimized.<br><br>Which type of disk should you include in the solution?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tPremium SSD v2\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tPremium SSD",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tStandard SSD",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUltra SSD"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 6,
        "isMostVoted": true
      },
      {
        "answer": "D",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2023-10-20T07:34:00.000Z",
        "voteCount": 6,
        "content": "Answer B, Ultra disk and Premium SSD v2 cannot be used as OS disk."
      },
      {
        "date": "2024-04-10T07:52:00.000Z",
        "voteCount": 3,
        "content": "Yes, but the question doesn't talk about OS disk"
      },
      {
        "date": "2024-09-26T13:09:00.000Z",
        "voteCount": 1,
        "content": "Answer A , its cheaper than Ultra"
      },
      {
        "date": "2024-04-10T07:53:00.000Z",
        "voteCount": 4,
        "content": "https://learn.microsoft.com/en-us/azure/virtual-machines/disks-types\n\nPremium SSD v2 are powerfull and cheaper than Premium SSD and Ultra Disk, and are fully configurable."
      },
      {
        "date": "2024-07-01T09:32:00.000Z",
        "voteCount": 1,
        "content": "This seems the most correct, even though B is upvoted the most.  A, Premium SSD v2,  is what I will choose."
      },
      {
        "date": "2024-04-03T12:22:00.000Z",
        "voteCount": 1,
        "content": "A. Premium SSD v2 provides custom values and is cheaper than both Premium SSD and Ultra disk. - Premium SSD provides numerous value options but not allow custom values."
      },
      {
        "date": "2024-01-06T01:52:00.000Z",
        "voteCount": 2,
        "content": "https://learn.microsoft.com/en-us/azure/virtual-machines/disks-types\n\nperformance-sensitive workloads that consistently require low latency and high IOPS and throughput and less cost than Ultra disk is Premium SSD v2.\n\nAlso, ultra disk is mostly for IO-intensive workloads."
      },
      {
        "date": "2023-10-30T10:49:00.000Z",
        "voteCount": 1,
        "content": "On virtual machines two disks are used. One for the operating system, and the other for data. In the first case, the answer is B. In the second case, the answer is D."
      },
      {
        "date": "2023-10-25T18:01:00.000Z",
        "voteCount": 1,
        "content": "Ultra SSD is most suitable."
      },
      {
        "date": "2023-10-19T13:56:00.000Z",
        "voteCount": 3,
        "content": "Ultra disk is the correct answers \nMicrosoft documentation link\nhttps://learn.microsoft.com/en-us/azure/virtual-machines/disks-types"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 62,
    "url": "https://www.examtopics.com/discussions/microsoft/view/124416-exam-dp-300-topic-1-question-62-discussion/",
    "body": "You have an on-premises datacenter that contains a 14-TB Microsoft SQL Server database.<br><br>You plan to create an Azure SQL managed instance and migrate the on-premises database to the new instance.<br><br>Which three service tiers support the SQL managed instance? Each correct answer presents a complete solution.<br><br>NOTE: Each correct selection is worth one point.",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tGeneral Purpose Standard\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tBusiness Critical Memory Optimized Premium\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tGeneral Purpose Premium\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tBusiness Critical Premium",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tBusiness Critical Standard"
    ],
    "answer": "ABC",
    "answerDescription": "",
    "votes": [
      {
        "answer": "ABC",
        "count": 3,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-08-13T08:20:00.000Z",
        "voteCount": 1,
        "content": "I have two SQL MI - one at West US 2 and one at West US 3.\n\nGeneral purpose are all up to 16 GB: \n- standard (up to 16 TB)\n- premium (up to 16 TB)\n- premium memory optimized (up to 16 TB)\n\nBusiness Critical show different limits, depending on region:\n\nWest US 2:\n\nBusiness Critical \n- standard (up to 4 TB)\n- premium (up to 16 TB)\n- premium memory optimized (up to 16 TB)\n\n\nWest US 3:\n\nBusiness Critical \n- standard (up to 4 TB)\n- premium (up to 5.5 TB)\n- premium memory optimized (up to 5.5 TB)\n\n\nIt means at West US 2 answer is: A, B, C, D\nAnd at West US 3 answer is:  A, C\n\nBad job by Microsoft on such question.\nHope won't get it at exam."
      },
      {
        "date": "2024-08-02T14:38:00.000Z",
        "voteCount": 3,
        "content": "By today, Business Critical Premium non-optimized is also supporting up to 16TB (I can literally see it in my Azure account UI). I hope they do not include this question in exam anymore, because hardware specs seem to grow more and more with time flow"
      },
      {
        "date": "2024-03-30T10:19:00.000Z",
        "voteCount": 3,
        "content": "Answer is correct.\nOnly Memory optimized premium-series in Business Critical tier supports up to 16TB, unlike all three series for General Purpose.\nhttps://learn.microsoft.com/en-us/sql/ssms/agent/create-a-sql-server-agent-proxy?view=sql-server-ver16"
      },
      {
        "date": "2024-02-01T08:29:00.000Z",
        "voteCount": 1,
        "content": "These service tiers do not have the \"Standard\" or \"Premium\" distinction that is common with other Azure SQL offerings like Azure SQL Database."
      },
      {
        "date": "2023-12-28T10:58:00.000Z",
        "voteCount": 4,
        "content": "answer is perfect\nhttps://learn.microsoft.com/en-us/azure/azure-sql/managed-instance/resource-limits?view=azuresql"
      },
      {
        "date": "2024-04-12T23:56:00.000Z",
        "voteCount": 1,
        "content": "Thanks for sharing this documentation link!"
      },
      {
        "date": "2023-10-22T17:42:00.000Z",
        "voteCount": 3,
        "content": "Answer is correct, you can confirm this with the Azure cost calculator. \n\nhttps://azure.microsoft.com/en-us/pricing/calculator/\n\nSQL MI supports:\n\nService Tier:\n1. General Purpose\n2. Business Critical\n\nHardware Type:\n1. Standard-series\n2. Premium-series\n3. Premium-series, memory optimized"
      },
      {
        "date": "2023-10-28T06:31:00.000Z",
        "voteCount": 2,
        "content": "that makes no sense. I suspect the question is referring to an obsolete storage limit, as mentioned in: https://techcommunity.microsoft.com/t5/azure-sql-blog/increased-storage-limit-to-16-tb-for-sql-managed-instance/ba-p/2421443"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 63,
    "url": "https://www.examtopics.com/discussions/microsoft/view/144511-exam-dp-300-topic-1-question-63-discussion/",
    "body": "SIMULATION<br> -<br><br>You need to configure db1 to pause automatically after one hour of inactivity.<br><br>To complete this task, sign in to the virtual machine. You may need to use SQL Server Management Studio and the Azure portal.",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/dp-300/image299.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-07-25T02:27:00.000Z",
        "voteCount": 2,
        "content": "I believe an SQL elastic pool can't be configured to use the serverless compute tier. Nevertheless, the approach can bu used for a single database."
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 64,
    "url": "https://www.examtopics.com/discussions/microsoft/view/144987-exam-dp-300-topic-1-question-64-discussion/",
    "body": "SIMULATION<br> -<br><br>You need to ensure that any enhancements made to the Query Optimizer through patches are available to db1 and db2 on sql12345678.<br><br>To complete this task, sign in to the virtual machine. You may need to use SQL Server Management Studio and the Azure portal.",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/dp-300/image300.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-08-04T05:13:00.000Z",
        "voteCount": 1,
        "content": "if you forget syntax, you can use \nSELECT * FROM sys.database_scoped_configurations\nand then filter the one which says HOTFIX\nSELECT * FROM sys.database_scoped_configurations WHERE name LIKE '%HOTFIX%'\nit will give you name of parameter - QUERY_OPTIMIZER_HOTFIXES"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 65,
    "url": "https://www.examtopics.com/discussions/microsoft/view/140888-exam-dp-300-topic-1-question-68-discussion/",
    "body": "SIMULATION<br> -<br><br>You need to add an Azure AD user named user2-12345678@examusers.com to db1. User2-12345678 must be able to read data from all the tables in db1 without being able to modify the data.<br><br>To complete this task, sign in to the virtual machine. You may need to use SQL Server Management Studio and the Azure portal.",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/dp-300/image304.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-05-19T20:28:00.000Z",
        "voteCount": 1,
        "content": "Could also grant the user the db_datareader fixed database role which would allow all tables to be read without the ability to modify the data."
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 66,
    "url": "https://www.examtopics.com/discussions/microsoft/view/140005-exam-dp-300-topic-1-question-70-discussion/",
    "body": "HOTSPOT<br> -<br><br><br>Case study<br> -<br><br>This is a case study. Case studies are not timed separately. You can use as much exam time as you would like to complete each case. However, there may be additional case studies and sections on this exam. You must manage your time to ensure that you are able to complete all questions included on this exam in the time provided.<br><br>To answer the questions included in a case study, you will need to reference information that is provided in the case study. Case studies might contain exhibits and other resources that provide more information about the scenario that is described in the case study. Each question is independent of the other questions in this case study.<br><br>At the end of this case study, a review screen will appear. This screen allows you to review your answers and to make changes before you move to the next section of the exam. After you begin a new section, you cannot return to this section.<br><br><br>To start the case study<br> -<br><br>To display the first question in this case study, click the Next button. Use the buttons in the left pane to explore the content of the case study before you answer the questions. Clicking these buttons displays information such as business requirements, existing environment, and problem statements. If the case study has an All Information tab, note that the information displayed is identical to the information displayed on the subsequent tabs. When you are ready to answer a question, click the Question button to return to the question.<br><br><br>Overview<br> -<br><br>ADatum Corporation is a financial services company that has a main office in New York City.<br><br>Existing Environment. Licensing Agreement<br><br>ADatum has a Microsoft Volume Licensing agreement that includes Software Assurance.<br><br>Existing Environment. Network Infrastructure<br><br>ADatum has an on-premises datacenter and an Azure subscription named Sub1.<br><br>Sub1 contains a virtual network named Network1 in the East US Azure region.<br><br>The datacenter is connected to Network1 by using a Site-to-Site (S2S) VPN.<br><br>Existing Environment. Identity Environment<br><br>The on-premises network contains an Active Directory Domain Services (AD DS) forest.<br><br>The forest contains a single domain named corp.adatum.com.<br><br>The corp.adatum.com domain syncs with a Microsoft Entra tenant named adatum.com.<br><br>Existing Environment. Database Environment<br><br>The datacenter contains the servers shown in the following table.<br><br><img src=\"https://img.examtopics.com/dp-300/image306.png\"><br><br>DB1 and DB2 are used for transactional and analytical workloads by an application named App1.<br><br>App1 runs on Microsoft Entra hybrid joined servers that run Windows Server 2022. App1 uses Kerberos authentication.<br><br>DB3 stores compliance data used by two applications named App2 and App3.<br><br>DB3 performance is monitored by using Extended Events sessions, with the event_file target set to a file share on a local disk of SVR3.<br><br>Resource allocation for DB3 is managed by using Resource Governor.<br><br><br>Requirements. Planned Changes<br> -<br><br>ADatum plans to implement the following changes:<br><br>\u2022\tDeploy an Azure SQL managed instance named Instance1 to Network1.<br>\u2022\tMigrate DB1 and DB2 to Instance1.<br>\u2022\tMigrate DB3 to Azure SQL Database.<br>\u2022\tFollowing the migration of DB1 and DB2, hand over database development to remote developers who use Microsoft Entra joined Windows 11 devices.<br>\u2022\tFollowing the migration of DB3, configure the database to be part of an auto-failover group.<br><br>Requirements. Availability Requirements<br><br>ADatum identifies the following post-migration availability requirements:<br><br>\u2022\tFor DB1 and DB2, offload analytical workloads to a read-only database replica in the same Azure region.<br>\u2022\tEnsure that if a regional disaster occurs, DB1 and DB2 can be recovered from backups.<br>\u2022\tAfter the migration, App1 must maintain access to DB1 and DB2.<br>\u2022\tFor DB3, manage potential performance issues caused by resource demand changes by App2 and App3.<br>\u2022\tEnsure that DB3 will still be accessible following a planned failover.<br>\u2022\tEnsure that DB3 can be restored if the logical server is deleted.<br>\u2022\tMinimize downtime during the migration of DB1 and DB2.<br><br>Requirements. Security Requirements<br><br>ADatum identifies the following security requirements for after the migration:<br><br>\u2022\tEnsure that only designated developers who use Microsoft Entra joined Windows 11 devices can access DB1 and DB2 remotely.<br>\u2022\tEnsure that all changes to DB3, including ones within individual transactions, are audited and recorded.<br><br>Requirements. Management Requirements<br><br>ADatum identifies the following post-migration management requirements:<br><br>\u2022\tContinue using Extended Events to monitor DB3.<br>\u2022\tIn Azure SQL Database, automate the management of DB3 by using elastic jobs that have database-scoped credentials.<br><br>Requirements. Business Requirements<br><br>ADatum identifies the following business requirements:<br><br>\u2022\tMinimize costs whenever possible, without affecting other requirements.<br>\u2022\tMinimize administrative effort.<br><br><br>You need to recommend which service and target endpoint to use when migrating the databases from SVR1 to Instance1. The solution must meet the availability requirements.<br><br>What should you recommend? To answer, select the appropriate options in the answer area.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/dp-300/image307.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/dp-300/image308.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-08-14T14:21:00.000Z",
        "voteCount": 1,
        "content": "As of time of this post's writing, SQL Managed Instance Link feature is available for:\nSQL Server 2016, 2019, 2022.\nNote that it is not available for 2017."
      },
      {
        "date": "2024-05-04T18:04:00.000Z",
        "voteCount": 3,
        "content": "Answer is correct:\nThe link feature also facilitates migrating from SQL Server to SQL Managed Instance, which enables:\n\nThe most performant, minimal downtime migration, compared to all other solutions available today.\nTrue online migration to SQL Managed Instance in any service tier.\nhttps://learn.microsoft.com/en-us/azure/azure-sql/managed-instance/managed-instance-link-feature-overview?view=azuresql#migrate-to-azure\n\nOnly VNet-local endpoint is supported to establish a link with SQL Managed Instance.\nhttps://learn.microsoft.com/en-us/azure/azure-sql/managed-instance/managed-instance-link-feature-overview?view=azuresql#limitations"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 67,
    "url": "https://www.examtopics.com/discussions/microsoft/view/140006-exam-dp-300-topic-1-question-71-discussion/",
    "body": "HOTSPOT<br> -<br><br><br>Case study<br> -<br><br>This is a case study. Case studies are not timed separately. You can use as much exam time as you would like to complete each case. However, there may be additional case studies and sections on this exam. You must manage your time to ensure that you are able to complete all questions included on this exam in the time provided.<br><br>To answer the questions included in a case study, you will need to reference information that is provided in the case study. Case studies might contain exhibits and other resources that provide more information about the scenario that is described in the case study. Each question is independent of the other questions in this case study.<br><br>At the end of this case study, a review screen will appear. This screen allows you to review your answers and to make changes before you move to the next section of the exam. After you begin a new section, you cannot return to this section.<br><br><br>To start the case study<br> -<br><br>To display the first question in this case study, click the Next button. Use the buttons in the left pane to explore the content of the case study before you answer the questions. Clicking these buttons displays information such as business requirements, existing environment, and problem statements. If the case study has an All Information tab, note that the information displayed is identical to the information displayed on the subsequent tabs. When you are ready to answer a question, click the Question button to return to the question.<br><br><br>Overview<br> -<br><br>ADatum Corporation is a financial services company that has a main office in New York City.<br><br>Existing Environment. Licensing Agreement<br><br>ADatum has a Microsoft Volume Licensing agreement that includes Software Assurance.<br><br>Existing Environment. Network Infrastructure<br><br>ADatum has an on-premises datacenter and an Azure subscription named Sub1.<br><br>Sub1 contains a virtual network named Network1 in the East US Azure region.<br><br>The datacenter is connected to Network1 by using a Site-to-Site (S2S) VPN.<br><br>Existing Environment. Identity Environment<br><br>The on-premises network contains an Active Directory Domain Services (AD DS) forest.<br><br>The forest contains a single domain named corp.adatum.com.<br><br>The corp.adatum.com domain syncs with a Microsoft Entra tenant named adatum.com.<br><br>Existing Environment. Database Environment<br><br>The datacenter contains the servers shown in the following table.<br><br><img src=\"https://img.examtopics.com/dp-300/image306.png\"><br><br>DB1 and DB2 are used for transactional and analytical workloads by an application named App1.<br><br>App1 runs on Microsoft Entra hybrid joined servers that run Windows Server 2022. App1 uses Kerberos authentication.<br><br>DB3 stores compliance data used by two applications named App2 and App3.<br><br>DB3 performance is monitored by using Extended Events sessions, with the event_file target set to a file share on a local disk of SVR3.<br><br>Resource allocation for DB3 is managed by using Resource Governor.<br><br><br>Requirements. Planned Changes<br> -<br><br>ADatum plans to implement the following changes:<br><br>\u2022\tDeploy an Azure SQL managed instance named Instance1 to Network1.<br>\u2022\tMigrate DB1 and DB2 to Instance1.<br>\u2022\tMigrate DB3 to Azure SQL Database.<br>\u2022\tFollowing the migration of DB1 and DB2, hand over database development to remote developers who use Microsoft Entra joined Windows 11 devices.<br>\u2022\tFollowing the migration of DB3, configure the database to be part of an auto-failover group.<br><br>Requirements. Availability Requirements<br><br>ADatum identifies the following post-migration availability requirements:<br><br>\u2022\tFor DB1 and DB2, offload analytical workloads to a read-only database replica in the same Azure region.<br>\u2022\tEnsure that if a regional disaster occurs, DB1 and DB2 can be recovered from backups.<br>\u2022\tAfter the migration, App1 must maintain access to DB1 and DB2.<br>\u2022\tFor DB3, manage potential performance issues caused by resource demand changes by App2 and App3.<br>\u2022\tEnsure that DB3 will still be accessible following a planned failover.<br>\u2022\tEnsure that DB3 can be restored if the logical server is deleted.<br>\u2022\tMinimize downtime during the migration of DB1 and DB2.<br><br>Requirements. Security Requirements<br><br>ADatum identifies the following security requirements for after the migration:<br><br>\u2022\tEnsure that only designated developers who use Microsoft Entra joined Windows 11 devices can access DB1 and DB2 remotely.<br>\u2022\tEnsure that all changes to DB3, including ones within individual transactions, are audited and recorded.<br><br>Requirements. Management Requirements<br><br>ADatum identifies the following post-migration management requirements:<br><br>\u2022\tContinue using Extended Events to monitor DB3.<br>\u2022\tIn Azure SQL Database, automate the management of DB3 by using elastic jobs that have database-scoped credentials.<br><br>Requirements. Business Requirements<br><br>ADatum identifies the following business requirements:<br><br>\u2022\tMinimize costs whenever possible, without affecting other requirements.<br>\u2022\tMinimize administrative effort.<br><br><br>You need to recommend a service tier and a method to offload analytical workloads for the databases migrated from SVR1. The solution must meet the availability and business requirements.<br><br>What should you recommend? To answer, select the appropriate options in the answer area.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/dp-300/image309.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/dp-300/image310.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-08-15T10:45:00.000Z",
        "voteCount": 1,
        "content": "DB1 and DB2 are from SVR1 server, migrated to Azure SQL Managed Instance.\n\nManaged Instance supports Failover Groups, FG has a requirement for replicas to be in different regions. Here in availability requirements, we have \"For DB1 and DB2, offload analytical workloads to a read-only database replica in the SAME Azure region\".\n\nIt means Failover Group won't work here. \nAlso, SQL MI doesn't support Geo-replication for selected databases (Geo-replication could have a replica in the same region), like Azure SQL DB does.\n\nThe only option left is to use Business Critical service tier for SQL MI, where one of \"internal\" replicas that single SQL MI has, can be accessed for read-only queries. So I would go with:\n\nBusiness Critical\nRead scale-out"
      },
      {
        "date": "2024-05-19T20:41:00.000Z",
        "voteCount": 2,
        "content": "Service Tier: Premium - minimize costs wherever possible. Both Premium and Business tiers support Read scale-out.\nMethod: Read scale-out"
      },
      {
        "date": "2024-05-04T18:14:00.000Z",
        "voteCount": 4,
        "content": "The answer is: \nService Tier: Business Critical \nMethod: Read scale-out\n\nThe read scale-out feature allows you to offload read-only workloads using the compute capacity of one of the read-only replicas, instead of running them on the read-write replica.\n\nRead scale-out is always enabled in the Business Critical service tier of SQL Managed Instance, and for Hyperscale databases with at least one secondary replica.\n\nhttps://learn.microsoft.com/en-us/azure/azure-sql/database/read-scale-out?view=azuresql"
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 68,
    "url": "https://www.examtopics.com/discussions/microsoft/view/149694-exam-dp-300-topic-1-question-73-discussion/",
    "body": "DRAG DROP<br> -<br><br>You have two on-premises Microsoft SQL Server instances named SQL1 and SQL2.<br><br>You have an Azure subscription.<br><br>You need to sync a subset of tables between the databases hosted on SQL1 and SQL2 by using SQL Data Sync.<br><br>Which five actions should you perform in sequence? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.<br><br><img src=\"https://img.examtopics.com/dp-300/image339.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/dp-300/image340.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-10-17T10:42:00.000Z",
        "voteCount": 1,
        "content": "To sync the tables between on-premises Microsoft SQL Server instances using Azure SQL Data Sync, the correct order of actions is:\n\nDeploy an Azure SQL database - This is necessary as the Azure SQL database acts as the hub database for synchronization.\nCreate a sync group - This will define the synchronization topology, which includes the hub and member databases.\nConfigure the sync group - Set up the parameters for the sync group, including the sync direction and the specific tables or columns to sync.\nInstall and configure the Client Sync Agent app on SQL1 and SQL2 - The Client Sync Agent enables on-premises SQL Servers to sync with Azure.\nSync the metadata database configuration - This completes the sync configuration by syncing the metadata that describes the sync relationships.\nThis sequence ensures that the necessary components are set up for Azure SQL Data Sync."
      }
    ],
    "examNameCode": "dp-300",
    "topicNumber": "1"
  }
]