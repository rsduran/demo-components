[
  {
    "topic": 5,
    "index": 1,
    "url": "https://www.examtopics.com/discussions/microsoft/view/81139-exam-dp-203-topic-5-question-1-discussion/",
    "body": "HOTSPOT -<br>You need to design a data storage structure for the product sales transactions. The solution must meet the sales transaction dataset requirements.<br>What should you include in the solution? To answer, select the appropriate options in the answer area.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04259/0000400004.jpg\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04259/0000500001.jpg\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: Hash -<br>Scenario:<br>Ensure that queries joining and filtering sales transaction records based on product ID complete as quickly as possible.<br>A hash distributed table can deliver the highest query performance for joins and aggregations on large tables.<br>Box 2: Set the distribution column to the sales date.<br>Scenario: Partition data that contains sales transaction records. Partitions must be designed to provide efficient loads by month. Boundary values must belong to the partition on the right.<br>Reference:<br>https://rajanieshkaushikk.com/2020/09/09/how-to-choose-right-data-distribution-strategy-for-azure-synapse/",
    "votes": [],
    "comments": [
      {
        "date": "2023-01-25T06:57:00.000Z",
        "voteCount": 54,
        "content": "This case study was in my exam and I scored 970. I chose productid."
      },
      {
        "date": "2023-06-12T06:36:00.000Z",
        "voteCount": 8,
        "content": "Good Job, Congrats!"
      },
      {
        "date": "2024-01-05T11:32:00.000Z",
        "voteCount": 3,
        "content": "Congrats! The answer is productid, since ms documentation states NOT to distribute by a date column. When doing so, all data for a given date is partitioned into one distribution. When processing, this hinders parallelism."
      },
      {
        "date": "2022-09-08T23:20:00.000Z",
        "voteCount": 21,
        "content": "Id choose product id as well since it will be used in joins \"Ensure that queries joining and filtering sales transaction records based on product ID complete as quickly as possible.\""
      },
      {
        "date": "2022-10-31T05:19:00.000Z",
        "voteCount": 1,
        "content": "Why not sales date for distribution column ?\nPartition data that contains sales transaction records. Partitions must be designed to provide efficient loads by month. Boundary values must belong to the partition on the right..."
      },
      {
        "date": "2022-11-17T07:03:00.000Z",
        "voteCount": 16,
        "content": "because it's asking about distribution, not partition. The requirements say \"ensure that queries joining and filtering sales transaction records based on product ID complete as quikly as possible\". The best way to do so is hash distrinuting on product ID, this way all rows with the same product id will be on the same node and there will be no data shuffling, hence fast queries"
      },
      {
        "date": "2024-08-01T14:41:00.000Z",
        "voteCount": 2,
        "content": "I'll repeat advice I read from another question:  NEVER set distribution on a DATE column.  However, partition on DATE is good."
      },
      {
        "date": "2023-08-31T23:54:00.000Z",
        "voteCount": 3,
        "content": "Hash and Distrubution on Product ID"
      },
      {
        "date": "2022-12-04T17:48:00.000Z",
        "voteCount": 8,
        "content": "In MS's own documentation, it is not recommended to use a date column for distribution. Therefore, the second option should be ProductID"
      },
      {
        "date": "2023-05-28T14:18:00.000Z",
        "voteCount": 3,
        "content": "So then why this guy is misleading us?? I find lot of answers misleading us."
      },
      {
        "date": "2022-11-29T06:44:00.000Z",
        "voteCount": 12,
        "content": "Hash and Distrubution on Product ID, never make distribution on Date.:\nhttps://learn.microsoft.com/en-us/azure/synapse-analytics/sql-data-warehouse/sql-data-warehouse-tables-distribute#choose-a-distribution-column-with-data-that-distributes-evenly\nPartition on Date as explained here:\nhttps://learn.microsoft.com/en-us/azure/synapse-analytics/sql-data-warehouse/sql-data-warehouse-tables-partition"
      },
      {
        "date": "2023-04-07T02:53:00.000Z",
        "voteCount": 2,
        "content": "True! ! !"
      },
      {
        "date": "2022-10-26T22:54:00.000Z",
        "voteCount": 5,
        "content": "Partition column: date, distribution column: ProductID"
      },
      {
        "date": "2022-10-04T10:00:00.000Z",
        "voteCount": 3,
        "content": "I think so, Set distribution to Product ID"
      },
      {
        "date": "2022-09-08T02:01:00.000Z",
        "voteCount": 9,
        "content": "Why not Set distribution to Product ID? With the date as the distribution column we lose the advantage of using all 60 nodes, right?"
      }
    ],
    "examNameCode": "dp-203",
    "topicNumber": "5"
  },
  {
    "topic": 5,
    "index": 2,
    "url": "https://www.examtopics.com/discussions/microsoft/view/83272-exam-dp-203-topic-5-question-2-discussion/",
    "body": "DRAG DROP -<br>You need to ensure that the Twitter feed data can be analyzed in the dedicated SQL pool. The solution must meet the customer sentiment analytics requirements.<br>Which three Transact-SQL DDL commands should you run in sequence? To answer, move the appropriate commands from the list of commands to the answer area and arrange them in the correct order.<br>NOTE: More than one order of answer choices is correct. You will receive credit for any of the correct orders you select.<br>Select and Place:<br><img src=\"/assets/media/exam-media/04259/0000600001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04259/0000600002.png\" class=\"in-exam-image\">",
    "answerDescription": "Scenario: Allow Contoso users to use PolyBase in an Azure Synapse Analytics dedicated SQL pool to query the content of the data records that host the Twitter feeds. Data must be protected by using row-level security (RLS). The users must be authenticated by using their own Azure AD credentials.<br>Box 1: CREATE EXTERNAL DATA SOURCE<br>External data sources are used to connect to storage accounts.<br>Box 2: CREATE EXTERNAL FILE FORMAT<br>CREATE EXTERNAL FILE FORMAT creates an external file format object that defines external data stored in Azure Blob Storage or Azure Data Lake Storage.<br>Creating an external file format is a prerequisite for creating an external table.<br>Box 3: CREATE EXTERNAL TABLE AS SELECT<br>When used in conjunction with the CREATE TABLE AS SELECT statement, selecting from an external table imports data into a table within the SQL pool. In addition to the COPY statement, external tables are useful for loading data.<br>Incorrect Answers:<br><br>CREATE EXTERNAL TABLE -<br>The CREATE EXTERNAL TABLE command creates an external table for Synapse SQL to access data stored in Azure Blob Storage or Azure Data Lake Storage.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/synapse-analytics/sql/develop-tables-external-tables",
    "votes": [],
    "comments": [
      {
        "date": "2022-12-20T16:13:00.000Z",
        "voteCount": 27,
        "content": "Given answers are correct\nBox 1: CREATE EXTERNAL DATA SOURCE\nBox 2: CREATE EXTERNAL FILE FORMAT\nBox 3: CREATE EXTERNAL TABLE AS SELECT\n\nRequirements: Allow Contoso users to use PolyBase in an Azure Synapse Analytics dedicated SQL pool to query the content of the data records that host the Twitter feeds. Data must be protected by using row-level security (RLS). The users must be authenticated by using their own Azure AD credentials.\n\nWhy CREAT DATABSE SCOPED CREDENTIAL is not required?\nRequirement: The users must be authenticated by using their own Azure AD credentials\n\nWhy not CREATE EXTERNAL TABLE?\nRequirement: Allow Contoso users to use PolyBase ... to query ...\nPolyBase has limitations. CREATE EXTERNAL TABLE AS SELECT stored the data within the SQL pool and avoids those limitations.\nhttps://learn.microsoft.com/en-us/sql/relational-databases/polybase/polybase-versioned-feature-summary?view=sql-server-ver16"
      },
      {
        "date": "2022-12-27T11:15:00.000Z",
        "voteCount": 2,
        "content": "CETAS is not available in dedicated SQL pool"
      },
      {
        "date": "2022-12-31T15:06:00.000Z",
        "voteCount": 3,
        "content": "Please see below.\nCREATE TABLE AS SELECT (Azure Synapse Analytics)\nhttps://learn.microsoft.com/en-us/sql/t-sql/statements/create-table-as-select-azure-sql-data-warehouse?view=aps-pdw-2016-au7"
      },
      {
        "date": "2022-12-31T15:09:00.000Z",
        "voteCount": 2,
        "content": "Also this one.\n\nCREATE EXTERNAL TABLE AS SELECT (Transact-SQL)\nApplies to:  SQL Server 2022 (16.x) and later,  Azure Synapse Analytics,  Analytics Platform System (PDW)\n\nhttps://learn.microsoft.com/en-us/sql/t-sql/statements/create-external-table-as-select-transact-sql?view=aps-pdw-2016-au7"
      },
      {
        "date": "2023-08-18T02:14:00.000Z",
        "voteCount": 2,
        "content": "https://learn.microsoft.com/en-us/azure/synapse-analytics/sql/develop-tables-external-tables?tabs=hadoop external tables are supported in both SQL pools"
      },
      {
        "date": "2023-02-15T07:01:00.000Z",
        "voteCount": 3,
        "content": "are you sure we can create EXTERNAL DATA SOURCE without DATABSE SCOPED CREDENTIAL?"
      },
      {
        "date": "2023-06-21T17:50:00.000Z",
        "voteCount": 4,
        "content": "It  is not necessary if the users are already authenticated by using their own Azure AD credentials."
      },
      {
        "date": "2022-09-23T00:05:00.000Z",
        "voteCount": 8,
        "content": "1. Scoped Database Credencial\n2. External Data Source\n3 External File Format"
      },
      {
        "date": "2022-12-05T14:41:00.000Z",
        "voteCount": 4,
        "content": "Scoped Database Credencial is a DCL command, not DDL"
      },
      {
        "date": "2022-11-29T06:46:00.000Z",
        "voteCount": 2,
        "content": "Correct"
      },
      {
        "date": "2024-07-17T05:07:00.000Z",
        "voteCount": 2,
        "content": "Here is the correct order:\n\nCREATE EXTERNAL DATA SOURCE\nCREATE EXTERNAL FILE FORMAT\nCREATE EXTERNAL TABLE"
      },
      {
        "date": "2024-07-10T02:52:00.000Z",
        "voteCount": 2,
        "content": "I think that the correct order is : \ncreate external data source \ncreate external file format \ncreate external table \n\nwe don't need to create database scoped credential, since the users are already using an AAD to authenticate to the storage, if there were no mention of AAD usage then we should have created the scoped credential to specify a type of authentication \n\nAlso here there is no mention of applying transformation on the data, we are only required to read the tweeter data, so create table an external table, CETAS is used to create an external table by exporting the result of a SELECT statement to an external data source, which is not the case here"
      },
      {
        "date": "2024-02-17T09:35:00.000Z",
        "voteCount": 2,
        "content": "Create external data source.\nCreate external file format.\nUse CETAS statement\n\nhttps://learn.microsoft.com/en-us/training/modules/use-azure-synapse-serverless-sql-pools-for-transforming-data-lake/2-transform-data-using-create-external-table-select-statement"
      },
      {
        "date": "2023-11-22T05:26:00.000Z",
        "voteCount": 1,
        "content": "twitter feeds are going to be stored in azure storage which also going to need data life cycle management. If we are not storing the data in the dedicated sql pool table then we do not use CETAS we only create an external table to query the data in the azure storage."
      },
      {
        "date": "2023-08-31T23:56:00.000Z",
        "voteCount": 1,
        "content": "DS,format,CETAS"
      },
      {
        "date": "2023-08-20T01:59:00.000Z",
        "voteCount": 5,
        "content": "According to Microsoft documentation:\n\nYou can create external tables in Synapse SQL pools via the following steps:\n\nCREATE EXTERNAL DATA SOURCE to reference an external Azure storage and specify the credential that should be used to access the storage.\nCREATE EXTERNAL FILE FORMAT to describe format of CSV or Parquet files.\nCREATE EXTERNAL TABLE on top of the files placed on the data source with the same file format.\n\nhttps://learn.microsoft.com/en-us/azure/synapse-analytics/sql/develop-tables-external-tables?tabs=hadoop#external-tables-in-dedicated-sql-pool-and-serverless-sql-pool"
      },
      {
        "date": "2023-08-18T02:23:00.000Z",
        "voteCount": 1,
        "content": "Answer should CET - RLS is supported on external tables and you do not need CETAS to implement RLS refer https://learn.microsoft.com/en-us/sql/relational-databases/security/row-level-security?view=sql-server-ver16"
      },
      {
        "date": "2023-08-18T02:18:00.000Z",
        "voteCount": 2,
        "content": "https://learn.microsoft.com/en-us/answers/questions/739341/rowlevelsecurity-on-external-table. RLS is not supported on an external table, then how CETAS be an answer"
      },
      {
        "date": "2023-08-10T23:24:00.000Z",
        "voteCount": 1,
        "content": "Concerning not needing CREATE DATABASE SCOPED CREDENTIAL for CREATE EXTERNAL DATA SOURCE: \"External data source without credential can access public storage account or use the caller's Azure AD identity to access files on Azure storage.\"\nRef: https://learn.microsoft.com/en-us/sql/t-sql/statements/create-external-data-source-transact-sql?view=azure-sqldw-latest&amp;tabs=dedicated"
      },
      {
        "date": "2023-04-25T21:29:00.000Z",
        "voteCount": 8,
        "content": "Box 1: CREATE EXTERNAL DATA SOURCE\nBox 2: CREATE EXTERNAL FILE FORMAT\nBox 3: CREATE EXTERNAL TABLE"
      },
      {
        "date": "2023-03-31T05:06:00.000Z",
        "voteCount": 2,
        "content": "The reason you use CTAS is that you must implement row level security."
      },
      {
        "date": "2023-01-24T18:44:00.000Z",
        "voteCount": 5,
        "content": "Starting with SQL Server 2022 (16.x), Create External Table as Select (CETAS) is supported to create an external table and then export, in parallel, the result of a Transact-SQL SELECT statement to Azure Data Lake Storage (ADLS) Gen2, Azure Storage Account V2, and S3-compatible object storage.\nSo shouldnt third be Create External TABLE ?\nWe dont want to write data  to ADLS. We want to read.\nhttps://learn.microsoft.com/en-us/sql/t-sql/statements/create-external-table-as-select-transact-sql?view=azure-sqldw-latest&amp;preserve-view=true"
      },
      {
        "date": "2023-05-11T11:28:00.000Z",
        "voteCount": 1,
        "content": "You are right. The question is asking to \"read\" the tweeter feed stored as parquet file in ADLS via PolyBase. This is supported with CREATE EXTERNAL TABLE - which in turn reads data from ADLS. Please refer https://learn.microsoft.com/en-us/sql/t-sql/statements/create-external-table-transact-sql?view=sql-server-ver16&amp;tabs=dedicated\nIt is mentioned - \"This command creates an external table for PolyBase to access data stored in a Hadoop cluster or Azure Blob Storage PolyBase external table that references data stored in a Hadoop cluster or Azure Blob Storage.\""
      },
      {
        "date": "2023-01-19T20:43:00.000Z",
        "voteCount": 1,
        "content": "PolyBase is a technology that accesses external data stored in Azure Blob storage or Azure Data Lake Store via the T-SQL language. So no need to copy table into Dedicated SQL Pool."
      },
      {
        "date": "2022-12-11T20:44:00.000Z",
        "voteCount": 1,
        "content": "why use CETAS instead of Create External Table?"
      },
      {
        "date": "2022-12-13T03:45:00.000Z",
        "voteCount": 2,
        "content": "https://learn.microsoft.com/en-us/sql/t-sql/statements/create-table-as-select-azure-sql-data-warehouse?toc=%2Fazure%2Fsynapse-analytics%2Fsql-data-warehouse%2Ftoc.json&amp;bc=%2Fazure%2Fsynapse-analytics%2Fsql-data-warehouse%2Fbreadcrumb%2Ftoc.json&amp;view=azure-sqldw-latest&amp;preserve-view=true#examples-using-ctas-to-replace-sql-server-code"
      },
      {
        "date": "2022-12-27T11:20:00.000Z",
        "voteCount": 1,
        "content": "your link points to CTAS, which is a different topic"
      },
      {
        "date": "2022-12-11T13:50:00.000Z",
        "voteCount": 1,
        "content": "CREATE DATABASE SCOPED CREDENTIALS should be run before all other steps in the given answer"
      }
    ],
    "examNameCode": "dp-203",
    "topicNumber": "5"
  },
  {
    "topic": 5,
    "index": 3,
    "url": "https://www.examtopics.com/discussions/microsoft/view/86790-exam-dp-203-topic-5-question-3-discussion/",
    "body": "HOTSPOT -<br>You need to design the partitions for the product sales transactions. The solution must meet the sales transaction dataset requirements.<br>What should you include in the solution? To answer, select the appropriate options in the answer area.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04259/0000800001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04259/0000900001.png\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: Sales date -<br>Scenario: Contoso requirements for data integration include:<br>\u2711 Partition data that contains sales transaction records. Partitions must be designed to provide efficient loads by month. Boundary values must belong to the partition on the right.<br>Box 2: An Azure Synapse Analytics Dedicated SQL pool<br>Scenario: Contoso requirements for data integration include:<br>\u2711 Ensure that data storage costs and performance are predictable.<br>The size of a dedicated SQL pool (formerly SQL DW) is determined by Data Warehousing Units (DWU).<br>Dedicated SQL pool (formerly SQL DW) stores data in relational tables with columnar storage. This format significantly reduces the data storage costs, and improves query performance.<br>Synapse analytics dedicated sql pool<br>Reference:<br>https://docs.microsoft.com/en-us/azure/synapse-analytics/sql-data-warehouse/sql-data-warehouse-overview-what-is",
    "votes": [],
    "comments": [
      {
        "date": "2023-01-23T17:41:00.000Z",
        "voteCount": 18,
        "content": "Partition is different than distribution. Distribution=ProductID and partition by Date. \nDistribution: \nWhen you store a table on Azure DW you are storing it amongst 60 nodes. Your table data is distributed across these nodes (using Hash distribution or Round Robin distribution depending on your needs). You can also choose to have your table (preferably a very small table) replicated across these nodes.\n\nParitition : Partitioning is completely divorced from this concept of distribution. When we partition a table we decide which rows belong into which partitions based on some scheme ( like date in this case) Chunk of records for that date range gets its own space in the backend behind the scenes. we can partition data based on anything as long as we know how the data is in our system.\n\nAnd when we put both in use together, all the partitions are horizontally partitioned so that the incoming data is divided into  60 nodes to provide extreme parallelization to the queries.\n\nhttps://www.linkedin.com/pulse/partitioning-distribution-azure-synapse-analytics-swapnil-mule"
      },
      {
        "date": "2023-09-14T23:18:00.000Z",
        "voteCount": 2,
        "content": "Load the sales transaction dataset to Azure Synapse Analytics---HERE you have the answer on where to store the \"transactional\"data---ONLY POSSIBILITY is Azure Synapse Analytics Dedicated SQL Pool."
      },
      {
        "date": "2023-08-31T23:59:00.000Z",
        "voteCount": 3,
        "content": "Partition by date &amp;dedicated pool"
      },
      {
        "date": "2022-11-05T05:04:00.000Z",
        "voteCount": 2,
        "content": "As far as I see it, we need to distribute the fact table accross the 60 distributions of a dedicated sql pool which means using NO date key (because of MPP) so using the productId key and within each distribution we need to partition the data by the date column so that data can quickly be deleted and queried by all 60 distributions at once"
      },
      {
        "date": "2023-01-24T10:06:00.000Z",
        "voteCount": 3,
        "content": "First question is partition not distribution. So Date is correct"
      },
      {
        "date": "2022-11-01T05:45:00.000Z",
        "voteCount": 1,
        "content": "I would partition by ProductID since joins and filtering must be optimized for that column"
      },
      {
        "date": "2022-12-11T13:56:00.000Z",
        "voteCount": 4,
        "content": "don't confuse partitions and distribution for hash-distributed table"
      },
      {
        "date": "2022-11-02T02:21:00.000Z",
        "voteCount": 16,
        "content": "Partition data that contains sales transaction records. Partitions must be designed to provide efficient loads by month. Boundary values must belong to the partition on the right.\nAlso we will delete data using sales date\nI think distribution = ProductID , Partition = Sales_date"
      },
      {
        "date": "2023-01-05T05:28:00.000Z",
        "voteCount": 7,
        "content": "Correct. Forget above statement. Partition should be Sales Date!!"
      }
    ],
    "examNameCode": "dp-203",
    "topicNumber": "5"
  },
  {
    "topic": 5,
    "index": 4,
    "url": "https://www.examtopics.com/discussions/microsoft/view/80136-exam-dp-203-topic-5-question-4-discussion/",
    "body": "You need to implement the surrogate key for the retail store table. The solution must meet the sales transaction dataset requirements.<br>What should you create?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ta table that has an IDENTITY property\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ta system-versioned temporal table",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ta user-defined SEQUENCE object",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ta table that has a FOREIGN KEY constraint"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 18,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-06-22T15:29:00.000Z",
        "voteCount": 5,
        "content": "A surrogate key is a system-generated unique identifier that is used as a substitute for a natural key. In this case, the surrogate key will be used to account for changes to the retail store addresses.\n\nBy creating a table with an IDENTITY property, you can ensure that a unique surrogate key is automatically generated for each row inserted into the table. The IDENTITY property assigns a unique value to the column automatically, incrementing by one for each new row.\n\nUsing an IDENTITY column as the surrogate key will provide an efficient way to join and filter sales transaction records based on product ID, as required by the sales transaction dataset requirements."
      },
      {
        "date": "2024-07-17T05:08:00.000Z",
        "voteCount": 1,
        "content": "CREATE TABLE RetailStore (\n    StoreID INT IDENTITY(1,1) PRIMARY KEY,\n    StoreName NVARCHAR(100),\n    Location NVARCHAR(100)\n);"
      },
      {
        "date": "2023-09-01T00:00:00.000Z",
        "voteCount": 2,
        "content": "is correct"
      },
      {
        "date": "2023-05-03T02:51:00.000Z",
        "voteCount": 2,
        "content": "Given answer is correct"
      },
      {
        "date": "2022-12-06T12:37:00.000Z",
        "voteCount": 3,
        "content": "Identity should be used."
      },
      {
        "date": "2022-12-01T01:54:00.000Z",
        "voteCount": 3,
        "content": "Correct"
      },
      {
        "date": "2022-09-04T13:24:00.000Z",
        "voteCount": 4,
        "content": "A is the correct Answer !"
      }
    ],
    "examNameCode": "dp-203",
    "topicNumber": "5"
  },
  {
    "topic": 5,
    "index": 5,
    "url": "https://www.examtopics.com/discussions/microsoft/view/80996-exam-dp-203-topic-5-question-5-discussion/",
    "body": "HOTSPOT -<br>You need to design an analytical storage solution for the transactional data. The solution must meet the sales transaction dataset requirements.<br>What should you include in the solution? To answer, select the appropriate options in the answer area.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04259/0001100001.jpg\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04259/0001200001.jpg\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: Round-robin -<br>Round-robin tables are useful for improving loading speed.<br>Scenario: Partition data that contains sales transaction records. Partitions must be designed to provide efficient loads by month.<br><br>Box 2: Hash -<br>Hash-distributed tables improve query performance on large fact tables.<br>Scenario:<br>\u2711 You plan to create a promotional table that will contain a promotion ID. The promotion ID will be associated to a specific product. The product will be identified by a product ID. The table will be approximately 5 GB.<br>\u2711 Ensure that queries joining and filtering sales transaction records based on product ID complete as quickly as possible.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/synapse-analytics/sql-data-warehouse/sql-data-warehouse-tables-distribute",
    "votes": [],
    "comments": [
      {
        "date": "2022-10-07T14:48:00.000Z",
        "voteCount": 50,
        "content": "replicated\nhash"
      },
      {
        "date": "2023-01-24T10:10:00.000Z",
        "voteCount": 20,
        "content": "Data is more than 100GB : hash\nDimension data less than 2GB: replicated\nStaging table data less than 5Gb:Round Robin\n\nSo replicated and Hash"
      },
      {
        "date": "2024-04-26T06:48:00.000Z",
        "voteCount": 1,
        "content": "Replicated\nRound Robin - because data is short lived only while campaign"
      },
      {
        "date": "2023-09-07T03:44:00.000Z",
        "voteCount": 1,
        "content": "replicated &amp; hash"
      },
      {
        "date": "2023-09-06T06:36:00.000Z",
        "voteCount": 1,
        "content": "Replicated --&gt; Because is not a staging table and is moreless 2GB\nHash --&gt; Because is 200GB"
      },
      {
        "date": "2023-09-01T00:02:00.000Z",
        "voteCount": 1,
        "content": "replicated ,hash tables are best for queries with joins and\naggregations."
      },
      {
        "date": "2023-08-01T06:27:00.000Z",
        "voteCount": 1,
        "content": "In the text it says that the table is 200GB, so hash. In the answer explanation it suddenly is only 5 GB"
      },
      {
        "date": "2023-07-28T02:07:00.000Z",
        "voteCount": 4,
        "content": "Box1: (clearly) replicated\nBox2: I can see why someone would say round-robin since it is not uncommon for large dim_tables  (and that is what this promotions table will essentially be) to use this distribution BUT  per Microsoft doc below using round-robin makes sense in situation tht simply do not apply here:\n- When getting started as a simple starting point since it is the default --&gt; NOT THE CASE\n- If there is no obvious joining key --&gt; THERE IS, product id which will be present in the fact transactions table as well\nIf there is no good candidate column for hash distributing the table - THERE IS, PromotionID\n- If the table does not share a common join key with other tables - IT DOES, ProductID\n- If the join is less significant than other joins in the query - NO INF on this\n- When the table is a temporary staging table - IT IS NOT\nsource: https://learn.microsoft.com/en-us/azure/synapse-analytics/sql-data-warehouse/sql-data-warehouse-tables-distribute\ntherefore, box2: Hash"
      },
      {
        "date": "2023-06-27T04:34:00.000Z",
        "voteCount": 4,
        "content": "Retail Store contains info about store (like address), it's clearly a dimension table, by the consequence it is REPLICATED.\nThe second is correct: HASH."
      },
      {
        "date": "2023-05-28T19:06:00.000Z",
        "voteCount": 3,
        "content": "So on which answer we should reply on??????? Why this web site guy is guiding us all wrong answers?????"
      },
      {
        "date": "2023-01-17T10:27:00.000Z",
        "voteCount": 2,
        "content": "Box1: Replicated \nBox2: Hash. Since, the Retail store table, will be used in queries and there is no mention of data loads to this table. It should be replicated and not Round-Robin."
      },
      {
        "date": "2022-12-29T20:56:00.000Z",
        "voteCount": 2,
        "content": "1st is Replicated"
      },
      {
        "date": "2022-12-03T20:38:00.000Z",
        "voteCount": 1,
        "content": "Box1: Replicated. As the Retail Store is going to be replicated in each distribution to facilitate SQL queries.\n\nBox2: Hash for large fact tables"
      },
      {
        "date": "2022-09-25T10:06:00.000Z",
        "voteCount": 2,
        "content": "replicated\nHAsh"
      },
      {
        "date": "2022-09-23T00:17:00.000Z",
        "voteCount": 3,
        "content": "-Replicated\n-Hash"
      },
      {
        "date": "2022-09-08T19:18:00.000Z",
        "voteCount": 5,
        "content": "Looks like \"Retail Store\" is a dimension table with 2MB  size.\nSo, Replicated should be better option in my opinion,"
      },
      {
        "date": "2022-09-08T01:11:00.000Z",
        "voteCount": 2,
        "content": "Agree with you Julia01, Replicated would be more reasonable for a 2MB table"
      }
    ],
    "examNameCode": "dp-203",
    "topicNumber": "5"
  },
  {
    "topic": 5,
    "index": 6,
    "url": "https://www.examtopics.com/discussions/microsoft/view/81127-exam-dp-203-topic-5-question-6-discussion/",
    "body": "HOTSPOT -<br>You need to implement an Azure Synapse Analytics database object for storing the sales transactions data. The solution must meet the sales transaction dataset requirements.<br>What should you do? To answer, select the appropriate options in the answer area.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04259/0001300001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04259/0001300002.jpg\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: Create table -<br>Scenario: Load the sales transaction dataset to Azure Synapse Analytics<br><br>Box 2: RANGE RIGHT FOR VALUES -<br>Scenario: Partition data that contains sales transaction records. Partitions must be designed to provide efficient loads by month. Boundary values must belong to the partition on the right.<br>RANGE RIGHT: Specifies the boundary value belongs to the partition on the right (higher values).<br>FOR VALUES ( boundary_value [,...n] ): Specifies the boundary values for the partition.<br>Scenario: Load the sales transaction dataset to Azure Synapse Analytics.<br>Contoso identifies the following requirements for the sales transaction dataset:<br>\u2711 Partition data that contains sales transaction records. Partitions must be designed to provide efficient loads by month. Boundary values must belong to the partition on the right.<br>\u2711 Ensure that queries joining and filtering sales transaction records based on product ID complete as quickly as possible.<br>\u2711 Implement a surrogate key to account for changes to the retail store addresses.<br>\u2711 Ensure that data storage costs and performance are predictable.<br>\u2711 Minimize how long it takes to remove old records.<br>Reference:<br>https://docs.microsoft.com/en-us/sql/t-sql/statements/create-table-azure-sql-data-warehouse",
    "votes": [],
    "comments": [
      {
        "date": "2022-12-04T17:53:00.000Z",
        "voteCount": 12,
        "content": "Its funny cause in the scenario, there is a BIG hint on what to use for box 2. Read it up."
      },
      {
        "date": "2023-03-22T20:37:00.000Z",
        "voteCount": 11,
        "content": "Hint as per XiltroX:\nContoso identifies the following requirements for the sales transaction dataset:\nPartition data that contains sales transaction records. Partitions must be designed to provide efficient loads by month. Boundary values must belong to the partition on the right."
      },
      {
        "date": "2023-12-16T03:27:00.000Z",
        "voteCount": 1,
        "content": "can someone help me with on first one, why is it create table and not external table?"
      },
      {
        "date": "2024-01-05T22:33:00.000Z",
        "voteCount": 4,
        "content": "External table is used when using an external data source such as data stored in Azure Data Lake Storage Gen2. In this case, as seen in a previous question, the data will be stored in the columnar store of the dedicated SQL pool."
      },
      {
        "date": "2024-01-01T13:07:00.000Z",
        "voteCount": 1,
        "content": "as far as i see, syntax only belongs to create table\nhttps://learn.microsoft.com/en-us/sql/t-sql/statements/create-table-azure-sql-data-warehouse?view=aps-pdw-2016-au7#PartitionedTable"
      },
      {
        "date": "2023-10-15T12:35:00.000Z",
        "voteCount": 2,
        "content": "Why create table and not create external table ?"
      },
      {
        "date": "2023-09-01T00:11:00.000Z",
        "voteCount": 2,
        "content": "https://learn.microsoft.com/en-us/sql/t-sql/statements/create-table-azure-sql-data-warehouse?view=aps-pdw-2016-au7#ExTablePartitions"
      },
      {
        "date": "2023-09-09T02:41:00.000Z",
        "voteCount": 2,
        "content": "create table ,right"
      },
      {
        "date": "2022-10-19T08:29:00.000Z",
        "voteCount": 2,
        "content": "agreed"
      },
      {
        "date": "2022-09-08T01:13:00.000Z",
        "voteCount": 2,
        "content": "correct"
      }
    ],
    "examNameCode": "dp-203",
    "topicNumber": "5"
  },
  {
    "topic": 5,
    "index": 7,
    "url": "https://www.examtopics.com/discussions/microsoft/view/87183-exam-dp-203-topic-5-question-7-discussion/",
    "body": "You need to design a data retention solution for the Twitter feed data records. The solution must meet the customer sentiment analytics requirements.<br>Which Azure Storage functionality should you include in the solution?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tchange feed",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tsoft delete",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ttime-based retention",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tlifecycle management\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 19,
        "isMostVoted": true
      },
      {
        "answer": "C",
        "count": 4,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2023-01-25T11:32:00.000Z",
        "voteCount": 8,
        "content": "Given answer is correct. \nTime bases retention is to retain data for a specific time. it wont delete the data. The requirement is to deleted the data after 2 Years. Which can be accomplished by Data life cycle management. \nA time-based retention policy stores blob data in a Write-Once, Read-Many (WORM) format for a specified interval. When a time-based retention policy is set, clients can create and read blobs, but can't modify or delete them. After the retention interval has expired, blobs can be deleted but not overwritten.\nhttps://learn.microsoft.com/en-us/azure/storage/blobs/immutable-time-based-retention-policy-overview"
      },
      {
        "date": "2023-01-27T16:39:00.000Z",
        "voteCount": 2,
        "content": "A time-based retention policy protects against deletion of blob while it is in effect. Note that it will not automatically delete the blob after the retention period."
      },
      {
        "date": "2024-07-17T04:51:00.000Z",
        "voteCount": 1,
        "content": "D. lifecycle management\nHere's why lifecycle management is the best choice:\n\nAutomated data management: Lifecycle management allows you to automatically move or delete data based on predefined rules and schedules.\nCost optimization: It helps in managing storage costs by transitioning older or less frequently accessed data to cooler storage tiers.\nCompliance: It can help meet data retention policies by automatically deleting data after a specified period.\nFlexibility: You can create custom policies based on factors like last modified date, which is ideal for managing social media data like Twitter feeds.\nIntegration: It works well with Azure Data Lake Storage Gen2, which is commonly used for big data analytics scenarios like sentiment analysis."
      },
      {
        "date": "2023-12-25T11:50:00.000Z",
        "voteCount": 1,
        "content": "Chatgpt say d\nBased on the case study information provided, the best Azure Storage functionality to include in the solution for data retention of Twitter feed data records is:\n\nD. Lifecycle Management\n\nThis feature enables the creation of rules to manage the lifecycle of the data stored in Azure Blob Storage. It can automate the process of purging Twitter feed data records that are older than two years, aligning with the requirement for minimal administrative effort and ensuring compliance with the data retention policy."
      },
      {
        "date": "2023-09-01T00:11:00.000Z",
        "voteCount": 1,
        "content": "is correct"
      },
      {
        "date": "2023-06-22T15:36:00.000Z",
        "voteCount": 2,
        "content": "Azure Storage provides a feature called lifecycle management, which allows you to define rules to manage the retention and deletion of data in your storage account. Lifecycle management enables you to automatically transition, delete, or take other actions on objects in your storage account based on specified conditions."
      },
      {
        "date": "2023-04-04T01:12:00.000Z",
        "voteCount": 3,
        "content": "Answer is D"
      },
      {
        "date": "2023-02-27T08:30:00.000Z",
        "voteCount": 1,
        "content": "do the research. it is C time-based retention"
      },
      {
        "date": "2023-06-21T18:41:00.000Z",
        "voteCount": 3,
        "content": "Time-based retention is a feature of Azure Blob storage that allows you to automatically delete blobs that have reached a certain age. While this feature can be useful for automatically deleting old data, it is not the most appropriate solution for the scenario you described because it only applies to block blobs and append blobs, and it is not available for other types of data in Azure Storage, such as files or tables.\n\nIn contrast, lifecycle management is a more comprehensive solution that allows you to define rules to automatically transition data to different access tiers or expire data at the end of its lifecycle. This functionality applies to block blobs, append blobs, and versioned block blobs, and it provides more flexibility in defining data retention policies."
      },
      {
        "date": "2023-06-30T12:35:00.000Z",
        "voteCount": 2,
        "content": "Time-based retention enables users to store business-critical data in a WORM (Write Once, Read Many) state. While in a WORM state, data cannot be modified or deleted for a user-specified interval."
      },
      {
        "date": "2023-03-04T04:13:00.000Z",
        "voteCount": 4,
        "content": "You are wrong. As it was said few times. Time-based retention will protect the data during set period from deletion but it won't delete it automatically after set time."
      },
      {
        "date": "2023-01-19T11:30:00.000Z",
        "voteCount": 1,
        "content": "Sim_al explanation is correct"
      },
      {
        "date": "2023-01-18T00:54:00.000Z",
        "voteCount": 2,
        "content": "C: time-based retention"
      },
      {
        "date": "2023-01-03T04:17:00.000Z",
        "voteCount": 3,
        "content": "C: time-based retention \nBased on the customer sentiment analytics requirements, you should include time-based retention in the data retention solution for the Twitter feed data records. Time-based retention allows you to specify a retention period for data in Azure Storage and ensures that data is not deleted before its retention period expires. This functionality can be used to meet the requirement to purge Twitter feed data records that are older than two years.\n\nOption A (change feed) is a feature of Azure Table Storage and Azure Cosmos DB that provides a stream of change events on a table or container.\n\nOption B (soft delete) is a feature of Azure Table Storage and Azure Cosmos DB that allows you to mark an entity as deleted without permanently deleting it. This allows you to recover deleted data if necessary.\n\nOption D (lifecycle management) is a feature of Azure Blob Storage that allows you to specify policies for automatically transitioning blobs to different storage tiers or deleting them based on their age or access patterns."
      },
      {
        "date": "2023-01-27T16:40:00.000Z",
        "voteCount": 4,
        "content": "Time bases retention is not the correct answer.\nA time-based retention policy protects against deletion of blob while it is in effect. Note that it will not automatically delete the blob after the retention period."
      },
      {
        "date": "2022-11-08T14:38:00.000Z",
        "voteCount": 3,
        "content": "Agreed."
      }
    ],
    "examNameCode": "dp-203",
    "topicNumber": "5"
  }
]