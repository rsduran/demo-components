[
  {
    "topic": 8,
    "index": 1,
    "url": "https://www.examtopics.com/discussions/microsoft/view/29410-exam-dp-100-topic-7-question-1-discussion/",
    "body": "HOTSPOT -<br>You need to replace the missing data in the AccessibilityToHighway columns.<br>How should you configure the Clean Missing Data module? To answer, select the appropriate options in the answer area.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04274/0033900001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04274/0034100001.png\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: Replace using MICE -<br>Replace using MICE: For each missing value, this option assigns a new value, which is calculated by using a method described in the statistical literature as<br>\"Multivariate Imputation using Chained Equations\" or \"Multiple Imputation by Chained Equations\". With a multiple imputation method, each variable with missing data is modeled conditionally using the other variables in the data before filling in the missing values.<br>Scenario: The AccessibilityToHighway column in both datasets contains missing values. The missing data must be replaced with new data so that it is modeled conditionally using the other variables in the data before filling in the missing values.<br><br>Box 2: Propagate -<br>Cols with all missing values indicate if columns of all missing values should be preserved in the output.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/clean-missing-data",
    "votes": [],
    "comments": [
      {
        "date": "2020-08-28T11:01:00.000Z",
        "voteCount": 7,
        "content": "I think it is in MICE definition. This method is imputing values that need to be distributed into empty column, instead of removing the columns and affecting dimensionality"
      },
      {
        "date": "2020-08-23T20:42:00.000Z",
        "voteCount": 6,
        "content": "Cols with all missing data has default value of Remove. That is the correct answer to me. Not sure why Propagate?"
      }
    ],
    "examNameCode": "dp-100",
    "topicNumber": "7"
  },
  {
    "topic": 8,
    "index": 2,
    "url": "https://www.examtopics.com/discussions/microsoft/view/20907-exam-dp-100-topic-7-question-2-discussion/",
    "body": "DRAG DROP -<br>You need to produce a visualization for the diagnostic test evaluation according to the data visualization requirements.<br>Which three modules should you recommend be used in sequence? To answer, move the appropriate modules from the list of modules to the answer area and arrange them in the correct order.<br>Select and Place:<br><img src=\"/assets/media/exam-media/04274/0034300001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04274/0034400001.png\" class=\"in-exam-image\">",
    "answerDescription": "Step 1: Sweep Clustering -<br>Start by using the \"Tune Model Hyperparameters\" module to select the best sets of parameters for each of the models we're considering.<br>One of the interesting things about the \"Tune Model Hyperparameters\" module is that it not only outputs the results from the Tuning, it also outputs the Trained<br>Model.<br><br>Step 2: Train Model -<br><br>Step 3: Evaluate Model -<br>Scenario: You need to provide the test results to the Fabrikam Residences team. You create data visualizations to aid in presenting the results.<br>You must produce a Receiver Operating Characteristic (ROC) curve to conduct a diagnostic test evaluation of the model. You need to select appropriate methods for producing the ROC curve in Azure Machine Learning Studio to compare the Two-Class Decision Forest and the Two-Class Decision Jungle modules with one another.<br>Reference:<br>http://breaking-bi.blogspot.com/2017/01/azure-machine-learning-model-evaluation.html",
    "votes": [],
    "comments": [
      {
        "date": "2020-06-09T11:33:00.000Z",
        "voteCount": 35,
        "content": "Agree with the comments above. I think it should be:\n1. Load Trained Model\n2. Evaluate Model\n3. Score Model"
      },
      {
        "date": "2021-03-25T11:36:00.000Z",
        "voteCount": 13,
        "content": "how can it be possible to evaluate before scoring?"
      },
      {
        "date": "2020-07-27T01:14:00.000Z",
        "voteCount": 87,
        "content": "Why not this sequence?\n1. Load Trained Model\n2. Score Model \n3. Evaluate Model"
      },
      {
        "date": "2020-08-10T03:56:00.000Z",
        "voteCount": 23,
        "content": "1. Load Trained Model 2. Score Model  3. Evaluate Model"
      },
      {
        "date": "2021-08-29T07:03:00.000Z",
        "voteCount": 3,
        "content": "correct answer might be \nTrain &gt; score &gt; evaluate"
      },
      {
        "date": "2020-12-11T02:30:00.000Z",
        "voteCount": 10,
        "content": "Creating the Experiment\nAdd the following modules to your workspace in Azure Machine Learning Studio (classic):\n\nAdult Census Income Binary Classification dataset\nTwo-Class Logistic Regression\nTrain Model\nScore Model\nEvaluate Model\n\nso --&gt;  Train Model,  Score Model, Evaluate Model\n\nhttps://docs.microsoft.com/en-us/azure/machine-learning/classic/evaluate-model-performance"
      },
      {
        "date": "2020-07-28T05:41:00.000Z",
        "voteCount": 1,
        "content": "It seems that there's no module for Loading Trained Model in the designer, but one in the studio. Maybe that's why the first should be Load Trained Model.\nhttps://docs.microsoft.com/en-us/azure/machine-learning/algorithm-module-reference/module-reference"
      },
      {
        "date": "2020-05-20T01:56:00.000Z",
        "voteCount": 3,
        "content": "Why not 'Score Model' instead of 'Train Model'? References show that 'Train Model' is not necessary here."
      },
      {
        "date": "2020-05-18T21:34:00.000Z",
        "voteCount": 4,
        "content": "Two-Class Decision Jungle and Two-Class Decision Forest are classification Models\ncant use sweep clustering module which is for clustering"
      }
    ],
    "examNameCode": "dp-100",
    "topicNumber": "7"
  },
  {
    "topic": 8,
    "index": 3,
    "url": "https://www.examtopics.com/discussions/microsoft/view/25731-exam-dp-100-topic-7-question-3-discussion/",
    "body": "You need to visually identify whether outliers exist in the Age column and quantify the outliers before the outliers are removed.<br>Which three Azure Machine Learning Studio modules should you use? Each correct answer presents part of the solution.<br>NOTE: Each correct selection is worth one point.<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate Scatterplot\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSummarize Data\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tClip Values\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tReplace Discrete Values",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tBuild Counting Transform"
    ],
    "answer": "ABC",
    "answerDescription": "B: To have a global view, the summarize data module can be used. Add the module and connect it to the data set that needs to be visualized.<br>A: One way to quickly identify Outliers visually is to create scatter plots.<br>C: The easiest way to treat the outliers in Azure ML is to use the Clip Values module. It can identify and optionally replace data values that are above or below a specified threshold.<br>You can use the Clip Values module in Azure Machine Learning Studio, to identify and optionally replace data values that are above or below a specified threshold. This is useful when you want to remove outliers or replace them with a mean, a constant, or other substitute value.<br>Reference:<br>https://blogs.msdn.microsoft.com/azuredev/2017/05/27/data-cleansing-tools-in-azure-machine-learning/ https://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/clip-values",
    "votes": [
      {
        "answer": "ABC",
        "count": 1,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2020-07-14T08:10:00.000Z",
        "voteCount": 13,
        "content": "Option C is a method to fix outliers, not visualize them"
      },
      {
        "date": "2022-03-18T05:19:00.000Z",
        "voteCount": 2,
        "content": "That's not a problem, the combination of the 3 answers are supposed to do the required actions, not every option doing everything."
      },
      {
        "date": "2023-02-25T15:49:00.000Z",
        "voteCount": 1,
        "content": "The \"Clip Values\" module in Azure Machine Learning Studio is used to limit the values in a column to a specified range. This can be useful in cases where there are extreme values that need to be limited to a certain threshold. However, this module does not identify or quantify outliers in a dataset. Therefore, it would not be useful for the task of identifying and quantifying outliers in the \"Age\" column."
      },
      {
        "date": "2023-02-25T15:48:00.000Z",
        "voteCount": 2,
        "content": "The three Azure Machine Learning Studio modules that should be used to visually identify and quantify outliers in the Age column before they are removed are:\n\nA. Create Scatterplot: This module can be used to create a scatter plot of the data, which allows for visual identification of outliers.\n\nB. Summarize Data: This module can be used to calculate basic statistics for the Age column, such as mean, median, standard deviation, and quartiles, which can help to identify outliers.\n\nE. Build Counting Transform: This module can be used to create a frequency distribution of the Age column, which can help to identify outliers that occur with low frequency.\n\nTherefore, the correct answers are A, B, and E. The modules C and D are not relevant for identifying and quantifying outliers in the Age column."
      },
      {
        "date": "2023-01-15T05:35:00.000Z",
        "voteCount": 1,
        "content": "Each correct answer presents part of the solution.  Therefore, the question asks to visualize before removing. Since A &amp; B are visualizations, and C does the removing, all 3 answers are part of the solution.  But we need to do A &amp; B before we utilize C.  Answer is correct.\n\nThis brings up a good point with Microsoft tests.  Make sure to understand sequencing questions vs. questions that say each answer PRESENTS part of the solution."
      },
      {
        "date": "2022-01-21T22:37:00.000Z",
        "voteCount": 1,
        "content": "The give answer seems to be right, below text from documentation regarding clip values module - \nhttps://docs.microsoft.com/en-us/previous-versions/azure/machine-learning/studio-module-reference/clip-values\n\nModule overview\nThis article describes how to use the Clip Values module in Machine Learning Studio (classic), to identify and optionally replace data values that are above or below a specified threshold. This is useful when you want to remove outliers or replace them with a mean, a constant, or other substitute value"
      },
      {
        "date": "2021-09-19T07:09:00.000Z",
        "voteCount": 4,
        "content": "ans: A,B,E"
      },
      {
        "date": "2021-08-30T06:39:00.000Z",
        "voteCount": 3,
        "content": ". Create Scatterplot\n.Summarize Data\n.Build Counting Transform"
      },
      {
        "date": "2021-05-23T03:04:00.000Z",
        "voteCount": 2,
        "content": "QUESTION \"You need to visually identify whether outliers exist in the Age column and quantify the outliers BEFORE the outliers are removed.\"\n\nThus answer C is part of the answer"
      },
      {
        "date": "2020-09-19T22:30:00.000Z",
        "voteCount": 2,
        "content": "question is only about visualization, so option c is incorrect."
      },
      {
        "date": "2020-11-20T19:02:00.000Z",
        "voteCount": 8,
        "content": "solution is correct\n1. visually identify whether outliers exist in the Age column and\n2. quantify the outliers before \n3. the outliers are removed."
      },
      {
        "date": "2021-03-25T11:38:00.000Z",
        "voteCount": 1,
        "content": "I agree"
      },
      {
        "date": "2021-03-27T10:19:00.000Z",
        "voteCount": 1,
        "content": "They ask to identify and visualize the outliers. Removing them is not asked. Therefore it's only A and B"
      },
      {
        "date": "2021-03-28T04:52:00.000Z",
        "voteCount": 3,
        "content": "Seems like it cannot be only A and B as the question ask THREE modules not two. Then I must agree with C. Question is ambiguous"
      }
    ],
    "examNameCode": "dp-100",
    "topicNumber": "7"
  },
  {
    "topic": 8,
    "index": 4,
    "url": "https://www.examtopics.com/discussions/microsoft/view/73872-exam-dp-100-topic-7-question-4-discussion/",
    "body": "HOTSPOT -<br>You need to identify the methods for dividing the data according to the testing requirements.<br>Which properties should you select? To answer, select the appropriate options in the answer area.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04274/0034700001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04274/0034900001.png\" class=\"in-exam-image\">",
    "answerDescription": "Scenario: Testing -<br>You must produce multiple partitions of a dataset based on sampling using the Partition and Sample module in Azure Machine Learning Studio.<br><br>Box 1: Assign to folds -<br>Use Assign to folds option when you want to divide the dataset into subsets of the data. This option is also useful when you want to create a custom number of folds for cross-validation, or to split rows into several groups.<br>Not Head: Use Head mode to get only the first n rows. This option is useful if you want to test a pipeline on a small number of rows, and don't need the data to be balanced or sampled in any way.<br>Not Sampling: The Sampling option supports simple random sampling or stratified random sampling. This is useful if you want to create a smaller representative sample dataset for testing.<br><br>Box 2: Partition evenly -<br>Specify the partitioner method: Indicate how you want data to be apportioned to each partition, using these options:<br>\u2711 Partition evenly: Use this option to place an equal number of rows in each partition. To specify the number of output partitions, type a whole number in the<br>Specify number of folds to split evenly into text box.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/machine-learning/algorithm-module-reference/partition-and-sample",
    "votes": [],
    "comments": [
      {
        "date": "2022-12-23T08:39:00.000Z",
        "voteCount": 1,
        "content": "\"You must create three equal partitions for cross-validation. You must also configure the cross-validation process so that the rows in the test and training datasets are divided evenly by properties that are near each city's main river. You must complete this task before the data goes through the sampling process.\"\n\nConsidering \"divided evenly by properties that are near each city's main river\", shouldn't the sampling process be stratified? \n\nThat would make the correct answer \"Partition with custom partitions\"?"
      },
      {
        "date": "2023-02-23T00:44:00.000Z",
        "voteCount": 1,
        "content": "Makes sense, but there doesn't seem to be an option for custom partitioning based on a value a certain field value. Custom partition only allows us to play with the proportions in each split. \n\nStratified Split is not selectable in the question (not sure why)... \n\nFrom Microsoft's reference: \n\nPartition with customized proportions: Use this option to specify the size of each partition as a comma-separated list.\n\nFor example, assume that you want to create three partitions. The first partition will contain 50 percent of the data. The remaining two partitions will each contain 25 percent of the data. In the List of proportions separated by comma box, enter these numbers: .5, .25, .25."
      },
      {
        "date": "2022-04-19T18:53:00.000Z",
        "voteCount": 2,
        "content": "Partition evenly: Use this option to place an equal number of rows in each partition. To specify the number of output partitions, enter a whole number in the Specify number of folds to split evenly into box.\n\nhttps://docs.microsoft.com/en-us/azure/machine-learning/component-reference/partition-and-sample#split-data-into-partitions"
      }
    ],
    "examNameCode": "dp-100",
    "topicNumber": "7"
  },
  {
    "topic": 8,
    "index": 5,
    "url": "https://www.examtopics.com/discussions/microsoft/view/20896-exam-dp-100-topic-7-question-5-discussion/",
    "body": "HOTSPOT -<br>You need to configure the Edit Metadata module so that the structure of the datasets match.<br>Which configuration options should you select? To answer, select the appropriate options in the answer area.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04274/0035100001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04274/0035300001.png\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: Floating point -<br>Need floating point for Median values.<br>Scenario: An initial investigation shows that the datasets are identical in structure apart from the MedianValue column. The smaller Paris dataset contains the<br>MedianValue in text format, whereas the larger London dataset contains the MedianValue in numerical format.<br><br>Box 2: Unchanged -<br>Note: Select the Categorical option to specify that the values in the selected columns should be treated as categories.<br>For example, you might have a column that contains the numbers 0,1 and 2, but know that the numbers actually mean \"Smoker\", \"Non smoker\" and \"Unknown\". In that case, by flagging the column as categorical you can ensure that the values are not used in numeric calculations, only to group data.",
    "votes": [],
    "comments": [
      {
        "date": "2020-05-20T02:09:00.000Z",
        "voteCount": 17,
        "content": "MedianValue should be made uncategorical to be consistent as the original formats are in text and numeric."
      },
      {
        "date": "2020-08-11T16:22:00.000Z",
        "voteCount": 8,
        "content": "I think the answer should be floating and make uncategorical, becuase it's a regression model and MedianValue is the target column. Uncategorical would make sense."
      },
      {
        "date": "2023-02-25T16:34:00.000Z",
        "voteCount": 1,
        "content": "For the configuration options in the Edit Metadata module, you should select:\n\nLaunch column selector:\nInteger\nUnchanged: This will ensure that the MedianValue column in both datasets is recognized as an integer type and is not modified."
      },
      {
        "date": "2021-11-04T23:24:00.000Z",
        "voteCount": 3,
        "content": "Should it not be 'Integer'? The value is in $1000s."
      },
      {
        "date": "2022-10-14T14:40:00.000Z",
        "voteCount": 1,
        "content": "good observation. I totally agree with you."
      },
      {
        "date": "2021-05-28T08:29:00.000Z",
        "voteCount": 3,
        "content": "if your source dataset has numbers handled as text, you must change them to a numeric data type before using math operations.\nThe supported data types are String, Integer, Double, Boolean, and DateTime.\nFloating point and time span is not an option\n\nFor example, you might have a column that contains the numbers 0, 1, and 2, but know that the numbers actually mean \"Smoker,\" \"Non-smoker,\" and \"Unknown.\" In that case, by flagging the column as categorical you ensure that the values are used only to group data and not in numeric calculations.\n\nSince it is numeric the option should be either \"unchanged\" or \"make uncategorical\". \n\nThe original data is text so it should be made uncategorical"
      },
      {
        "date": "2021-04-07T02:19:00.000Z",
        "voteCount": 2,
        "content": "if you google \"make uncategorical\" + edit metadata, you only get references to this particular exam question... I'm not convinced that \"make uncategorical\" even exists."
      },
      {
        "date": "2021-03-27T10:24:00.000Z",
        "voteCount": 3,
        "content": "Integer and uncategorical as the MedianValue is written in 1000 (no decimal point) and it's a regression model so must be numeric."
      },
      {
        "date": "2021-02-03T03:47:00.000Z",
        "voteCount": 3,
        "content": "The table that shows types indicate MedianValue is in the $1000s. It's an integer. Where did Floating Point come from? Also, the Paris data must be noncategorical, too, like the London data."
      },
      {
        "date": "2021-02-15T08:28:00.000Z",
        "voteCount": 1,
        "content": "Read the text. One MedianValue is text and the other is numerical."
      },
      {
        "date": "2021-07-12T23:31:00.000Z",
        "voteCount": 3,
        "content": "in 1000 means you can have value 4.5 in the column ($4500)"
      },
      {
        "date": "2021-01-21T06:19:00.000Z",
        "voteCount": 4,
        "content": "I don't think it is necessary to make it uncategorical as text data is not categorical in this case which we have to make uncategorical. Answer is correct."
      },
      {
        "date": "2021-05-16T15:53:00.000Z",
        "voteCount": 1,
        "content": "What text data? The case study states that The MedianValue and AvgRoomsInHouse columns both hold data in numeric format."
      },
      {
        "date": "2021-01-09T23:11:00.000Z",
        "voteCount": 7,
        "content": "there is no floating point.\n\nSelect the Data type option if you need to assign a different data type to the selected columns. You might need to change the data type for certain operations. For example, if your source dataset has numbers handled as text, you must change them to a numeric data type before using math operations.\n\nThe supported data types are String, Integer, Double, Boolean, and DateTime.\n\nIf you select multiple columns, you must apply the metadata changes to all selected columns. For example, let's say you choose two or three numeric columns. You can change them all to a string data type and rename them in one operation. However, you can't change one column to a string data type and another column from a float to an integer.\n\nIf you don't specify a new data type, the column metadata is unchanged.\n\nThe column type and values will change after you perform the Edit Metadata operation. You can recover the original data type at any time by using Edit Metadata to reset the column data type."
      },
      {
        "date": "2020-12-31T06:51:00.000Z",
        "voteCount": 2,
        "content": "I dont think there is such a thing as make uncategorical. Since the string version of the MedianValue we had is already not categorical we do not need to switch the MedianValue, thus leaving it unchanged would leave us with a non categorical Median integer value..maybe"
      },
      {
        "date": "2020-07-17T03:04:00.000Z",
        "voteCount": 2,
        "content": "The answer is Floating point, Make Categorical"
      },
      {
        "date": "2021-01-20T00:43:00.000Z",
        "voteCount": 1,
        "content": "To make 'MedianValues' categorical, do you mean turning values into bins of 'MedianValues'?"
      },
      {
        "date": "2020-07-05T02:52:00.000Z",
        "voteCount": 3,
        "content": "as the Paris dataset needs to match London dataset types and London has numerical data types in MoedianValues columns, shouldn't the answer be 'Integer' and 'Make Uncategorical'?"
      },
      {
        "date": "2020-06-25T13:06:00.000Z",
        "voteCount": 5,
        "content": "\"You must ensure that the datatype of the MedianValue column of the Paris dataset matches the structure of the London dataset.\"\nIf we run Summary on the data, it might end up as Categorical due to the nature of data.\nThat said \"Unchanged\" might do it here."
      },
      {
        "date": "2020-05-23T03:53:00.000Z",
        "voteCount": 1,
        "content": "yes, I too agree with Yong2020."
      },
      {
        "date": "2020-05-18T14:44:00.000Z",
        "voteCount": 1,
        "content": "Correct me if I'm wrong, but I believe the answer should be \"Make Categorical\" if you don't want the MedianValue column to be numerical calculated."
      },
      {
        "date": "2021-03-25T11:48:00.000Z",
        "voteCount": 3,
        "content": "An initial investigation shows that the datasets are identical in structure apart from the MedianValue column. The smaller Paris dataset contains the MedianValue in text format, whereas the larger London dataset contains the MedianValue in numerical format\nso the answer is :\n\nfloating and uncategorical"
      }
    ],
    "examNameCode": "dp-100",
    "topicNumber": "7"
  },
  {
    "topic": 8,
    "index": 6,
    "url": "https://www.examtopics.com/discussions/microsoft/view/20778-exam-dp-100-topic-7-question-6-discussion/",
    "body": "HOTSPOT -<br>You need to configure the Permutation Feature Importance module for the model training requirements.<br>What should you do? To answer, select the appropriate options in the dialog box in the answer area.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04274/0035500001.jpg\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04274/0035600001.jpg\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: 500 -<br>For Random seed, type a value to use as seed for randomization. If you specify 0 (the default), a number is generated based on the system clock.<br>A seed value is optional, but you should provide a value if you want reproducibility across runs of the same experiment.<br>Here we must replicate the findings.<br><br>Box 2: Mean Absolute Error -<br>Scenario: Given a trained model and a test dataset, you must compute the Permutation Feature Importance scores of feature variables. You need to set up the<br>Permutation Feature Importance module to select the correct metric to investigate the model's accuracy and replicate the findings.<br>Regression. Choose one of the following: Precision, Recall, Mean Absolute Error, Root Mean Squared Error, Relative Absolute Error, Relative Squared Error,<br><br>Coefficient of Determination -<br>Reference:<br>https://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/permutation-feature-importance",
    "votes": [],
    "comments": [
      {
        "date": "2020-07-08T07:59:00.000Z",
        "voteCount": 22,
        "content": "RMSE indicates the absolute fit of the model to the data\u2013how close the observed data points are to the model's predicted values. Whereas R-squared is a relative measure of fit, RMSE is an absolute measure of fit. See: \"You must be determined the absolute fit of the model\"."
      },
      {
        "date": "2020-05-17T11:02:00.000Z",
        "voteCount": 16,
        "content": "Mean Absolute Error , Root Mean Squared Error, r- squared are all correct."
      },
      {
        "date": "2022-10-14T14:44:00.000Z",
        "voteCount": 2,
        "content": "MAE seems like the best choice since RMSE is more sensitive to outlier."
      },
      {
        "date": "2022-05-01T19:56:00.000Z",
        "voteCount": 5,
        "content": "MAE is correct. RMSE has the benefit of penalizing large errors more so can be more appropriate in some cases, for example, if being off by 10 is more than twice as bad as being off by 5. But if being off by 10 is just twice as bad as being off by 5, then MAE is more appropriate.\nFrom an interpretation standpoint, MAE is clearly the winner. RMSE does not describe average error alone and has other implications that are more difficult to tease out and understand.\nOn the other hand, one distinct advantage of RMSE over MAE is that RMSE avoids the use of taking the absolute value, which is undesirable in many mathematical calculations."
      },
      {
        "date": "2023-01-15T06:10:00.000Z",
        "voteCount": 1,
        "content": "Excellent evaluation and I concur.  Going with MAE."
      },
      {
        "date": "2021-02-24T09:36:00.000Z",
        "voteCount": 2,
        "content": "Should be RMSE. \nhttps://www.theanalysisfactor.com/assessing-the-fit-of-regression-models/"
      },
      {
        "date": "2020-07-05T03:47:00.000Z",
        "voteCount": 2,
        "content": "if the findings should be replicated, than the seed should be 0\nalso another question for this case study had r-squared as correct evaluation method for regression model..."
      },
      {
        "date": "2020-12-03T12:59:00.000Z",
        "voteCount": 10,
        "content": "If it is 0, the seed is generated by the system clock meaning that it won't be replicable and keep changing like the time, hence would be 500?"
      },
      {
        "date": "2023-08-09T11:05:00.000Z",
        "voteCount": 1,
        "content": "where does it ask to be replicable?"
      }
    ],
    "examNameCode": "dp-100",
    "topicNumber": "7"
  },
  {
    "topic": 8,
    "index": 7,
    "url": "https://www.examtopics.com/discussions/microsoft/view/41151-exam-dp-100-topic-7-question-7-discussion/",
    "body": "You need to select a feature extraction method.<br>Which method should you use?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tMutual information",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tPearson's correlation",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSpearman correlation",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tFisher Linear Discriminant Analysis"
    ],
    "answer": "C",
    "answerDescription": "Spearman's rank correlation coefficient assesses how well the relationship between two variables can be described using a monotonic function.<br>Note: Both Spearman's and Kendall's can be formulated as special cases of a more general correlation coefficient, and they are both appropriate in this scenario.<br>Scenario: The MedianValue and AvgRoomsInHouse columns both hold data in numeric format. You need to select a feature selection algorithm to analyze the relationship between the two columns in more detail.<br>Incorrect Answers:<br>B: The Spearman correlation between two variables is equal to the Pearson correlation between the rank values of those two variables; while Pearson's correlation assesses linear relationships, Spearman's correlation assesses monotonic relationships (whether linear or not).<br>Reference:<br>https://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/feature-selection-modules",
    "votes": [],
    "comments": [
      {
        "date": "2021-01-01T12:15:00.000Z",
        "voteCount": 7,
        "content": "how could 2 same questions get a different answer? bad quality"
      },
      {
        "date": "2021-01-20T01:44:00.000Z",
        "voteCount": 1,
        "content": "Maybe microsoft jumbles up the possible responses/answers which could appear for each test taker."
      },
      {
        "date": "2021-02-17T12:45:00.000Z",
        "voteCount": 2,
        "content": "They even coment that both Pearson and Kendall  are correct answers"
      },
      {
        "date": "2021-09-19T07:02:00.000Z",
        "voteCount": 2,
        "content": "Correlation analysis provides a quantitative means of measuring the strength of a linear relationship between two vectors of data. Mutual information is essentially the measure of how much \u201cknowledge\u201d one can gain of a certain variable by knowing the value of another variable so it can't be mututal information  spearman is the right answer"
      },
      {
        "date": "2022-10-14T14:49:00.000Z",
        "voteCount": 6,
        "content": "This can be a tricky question if you did not read the case study. It says in the case study that relationship between features should be assess using non-parametric statistics. Thus, the reason for using the spearman's rank correlation."
      },
      {
        "date": "2023-01-15T05:47:00.000Z",
        "voteCount": 1,
        "content": "Thanks for the evaluation.  Correct."
      },
      {
        "date": "2024-02-12T19:02:00.000Z",
        "voteCount": 1,
        "content": "The answer is definitely not D. But I am confused between three even after reading all the comments below. help!"
      },
      {
        "date": "2023-02-25T16:41:00.000Z",
        "voteCount": 1,
        "content": "The question mentions \"feature extraction,\" but the given answer choices are all feature selection methods. If the question is about feature extraction, some commonly used methods are Principal Component Analysis (PCA), Independent Component Analysis (ICA), and Non-negative Matrix Factorization (NMF).\n\nIf the question is about feature selection, then the most appropriate method depends on the specific characteristics of the data and the problem at hand. Without more information about the specific characteristics of the data and the problem at hand, it is not possible to determine which method is the best choice."
      },
      {
        "date": "2021-09-19T06:59:00.000Z",
        "voteCount": 5,
        "content": "Answer is correct : they asked a non parametric \n pearson and  fisher are  parametric"
      },
      {
        "date": "2021-09-19T07:02:00.000Z",
        "voteCount": 1,
        "content": "Correlation analysis provides a quantitative means of measuring the strength of a linear relationship between two vectors of data. Mutual information is essentially the measure of how much \u201cknowledge\u201d one can gain of a certain variable by knowing the value of another variable so it can't be mututal information spearman is the right answer"
      },
      {
        "date": "2021-06-22T23:23:00.000Z",
        "voteCount": 2,
        "content": "Note: Both Spearman's and Kendall's can be formulated as special cases of a more general correlation coefficient, and they are both appropriate in this scenario."
      },
      {
        "date": "2021-05-29T18:44:00.000Z",
        "voteCount": 1,
        "content": "pearson's correlation is not a non-parametric method"
      },
      {
        "date": "2021-05-29T18:44:00.000Z",
        "voteCount": 2,
        "content": "MY BAD, IT'S SPEARMAN"
      },
      {
        "date": "2021-05-28T11:06:00.000Z",
        "voteCount": 1,
        "content": "Pearson is linear while spearman  and kendall are monotonic.  Pearson does not work well with outliers but there is not indication that the medianvalue and AvgRoomsInHouse  columns have outliers.\n\nFisher linear discriminant (FLD) analysis is not a valid option (fisher score is) \nSee links for difference\nhttps://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/fisher-linear-discriminant-analysis\n\nhttps://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/filter-based-feature-selection\n\nThe answer I think is Pearson's correlation."
      },
      {
        "date": "2021-03-05T09:02:00.000Z",
        "voteCount": 3,
        "content": "The answer should be Fisher Linear Discriminant Analysis, as this is the only method in the given options, that is used for extracting features in low dimensions."
      },
      {
        "date": "2024-02-12T19:00:00.000Z",
        "voteCount": 1,
        "content": "Fisher LDA is definitely not the answer as it is used in classification problems not regression."
      }
    ],
    "examNameCode": "dp-100",
    "topicNumber": "7"
  },
  {
    "topic": 8,
    "index": 8,
    "url": "https://www.examtopics.com/discussions/microsoft/view/22676-exam-dp-100-topic-7-question-8-discussion/",
    "body": "HOTSPOT -<br>You need to set up the Permutation Feature Importance module according to the model training requirements.<br>Which properties should you select? To answer, select the appropriate options in the answer area.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04274/0035900001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04274/0036000001.png\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: Accuracy -<br>Scenario: You want to configure hyperparameters in the model learning process to speed the learning phase by using hyperparameters. In addition, this configuration should cancel the lowest performing runs at each evaluation interval, thereby directing effort and resources towards models that are more likely to be successful.<br>Box 2: R-Squared",
    "votes": [],
    "comments": [
      {
        "date": "2020-07-05T03:39:00.000Z",
        "voteCount": 18,
        "content": "because it is required to produce ROC curve, I think f-score is the correct answer for the classification task"
      },
      {
        "date": "2021-11-12T00:49:00.000Z",
        "voteCount": 1,
        "content": "yes but why R2 as measure of performance?"
      },
      {
        "date": "2020-06-09T11:45:00.000Z",
        "voteCount": 6,
        "content": "Why would we select Accuracy? This is a regression problem and not a classification problem, I would have thought we only need to select one of the answers in the regression box only."
      },
      {
        "date": "2021-03-20T05:42:00.000Z",
        "voteCount": 1,
        "content": "this is indeed classification. check option again"
      },
      {
        "date": "2023-02-25T16:46:00.000Z",
        "voteCount": 1,
        "content": "For the Permutation Feature Importance module, the following metrics should be selected for measuring performance:\n\nMetric for measuring performance for classification:\n\nA) F-Score\nMetric for measuring performance for regression:\n\nD) MAE or A) RMSE (depending on the specific requirements of the model training)"
      },
      {
        "date": "2021-11-23T01:34:00.000Z",
        "voteCount": 3,
        "content": "why not RMSE?"
      },
      {
        "date": "2021-01-21T13:09:00.000Z",
        "voteCount": 4,
        "content": "Completely weird options as for classification we can use precision, recall and F score and Accuracy. Any option is not wrong."
      },
      {
        "date": "2020-11-12T01:18:00.000Z",
        "voteCount": 1,
        "content": "why not precision for classifications?"
      },
      {
        "date": "2020-09-04T04:38:00.000Z",
        "voteCount": 1,
        "content": "Isn't MAE a continous metric, hence not applicable here?"
      }
    ],
    "examNameCode": "dp-100",
    "topicNumber": "7"
  },
  {
    "topic": 8,
    "index": 9,
    "url": "https://www.examtopics.com/discussions/microsoft/view/30225-exam-dp-100-topic-7-question-9-discussion/",
    "body": "HOTSPOT -<br>You need to configure the Feature Based Feature Selection module based on the experiment requirements and datasets.<br>How should you configure the module properties? To answer, select the appropriate options in the dialog box in the answer area.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04274/0036200001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04274/0036300001.png\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: Mutual Information.<br>The mutual information score is particularly useful in feature selection because it maximizes the mutual information between the joint distribution and target variables in datasets with many dimensions.<br><br>Box 2: MedianValue -<br>MedianValue is the feature column, , it is the predictor of the dataset.<br>Scenario: The MedianValue and AvgRoomsinHouse columns both hold data in numeric format. You need to select a feature selection algorithm to analyze the relationship between the two columns in more detail.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/filter-based-feature-selection",
    "votes": [],
    "comments": [
      {
        "date": "2021-09-19T07:48:00.000Z",
        "voteCount": 3,
        "content": "You must prioritize the columns of data for predicting the outcome(The mutual information score measures the contribution of a variable towards reducing uncertainty about the value of another variable: namely, the label). You must use non-parametric statistics to measure relationships. i think asnwer is Mutual information"
      },
      {
        "date": "2021-05-06T16:16:00.000Z",
        "voteCount": 1,
        "content": "Fisher test is better, it is similar to Chi squared but fisher is more exact, choose Fisher score"
      },
      {
        "date": "2021-09-19T07:37:00.000Z",
        "voteCount": 1,
        "content": "fisher is parmametric"
      },
      {
        "date": "2021-09-19T07:38:00.000Z",
        "voteCount": 1,
        "content": "and chi squared also is parapetric theay asked for non parametric"
      },
      {
        "date": "2021-03-19T04:58:00.000Z",
        "voteCount": 3,
        "content": "I think the answer is Fisher Score \n\nFisher Score:\tLabel can be text or numeric but features must be numeric.\nMutual Information: Labels and features can be text or numeric. Use this method for computing feature importance for two categorical columns.\nChi Squared: Labels and features can be text or numeric. Use this method for computing feature importance for two categorical columns."
      },
      {
        "date": "2021-01-21T13:21:00.000Z",
        "voteCount": 2,
        "content": "Since both MedianValue and Averagenumber of house is numerical variable, we should use Fisher Price"
      },
      {
        "date": "2020-11-22T19:33:00.000Z",
        "voteCount": 4,
        "content": "The answer should be Fisher Score since the label and the features are numeric values. Chi Squared and Mutual information for categorical values."
      },
      {
        "date": "2020-11-12T01:27:00.000Z",
        "voteCount": 2,
        "content": "By the definition of Mutual Information, a low value should mean that one feature does not give me information about the other and by the definition of Chi Square, a low value of Chi Square means that the two features must be independent.\n\nHence i guess Chi square is not used and mutual information is used"
      },
      {
        "date": "2020-08-31T21:12:00.000Z",
        "voteCount": 2,
        "content": "The answer is counts. Chi square and mutual information applies to categorical data.\nSince there is only 1 feature we looking at meaning there's only one dataset it cannot be Fisher.\nhttps://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/filter-based-feature-selection"
      },
      {
        "date": "2020-09-30T10:50:00.000Z",
        "voteCount": 1,
        "content": "Target column is MedianValue is contious variables, so I don't see any reason to use Chi Square. In addion, Fisher test and Chi Sqaure can be exchanged with each other."
      },
      {
        "date": "2020-11-22T19:38:00.000Z",
        "voteCount": 2,
        "content": "Count don't require label, so it cannot be"
      }
    ],
    "examNameCode": "dp-100",
    "topicNumber": "7"
  },
  {
    "topic": 8,
    "index": 10,
    "url": "https://www.examtopics.com/discussions/microsoft/view/37579-exam-dp-100-topic-7-question-10-discussion/",
    "body": "You need to select a feature extraction method.<br>Which method should you use?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tMutual information",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tMood's median test",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tKendall correlation\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tPermutation Feature Importance"
    ],
    "answer": "C",
    "answerDescription": "In statistics, the Kendall rank correlation coefficient, commonly referred to as Kendall's tau coefficient (after the Greek letter \u05bf\u201e), is a statistic used to measure the ordinal association between two measured quantities.<br>It is a supported method of the Azure Machine Learning Feature selection.<br>Note: Both Spearman's and Kendall's can be formulated as special cases of a more general correlation coefficient, and they are both appropriate in this scenario.<br>Scenario: The MedianValue and AvgRoomsInHouse columns both hold data in numeric format. You need to select a feature selection algorithm to analyze the relationship between the two columns in more detail.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/feature-selection-modules",
    "votes": [
      {
        "answer": "C",
        "count": 2,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2020-11-22T19:49:00.000Z",
        "voteCount": 8,
        "content": "Linear regression module -\nWhen you train a Linear Regression module, you must determine the best features to use in a model. You can choose standard metrics provided to measure performance before and after the feature importance process completes. \n\nSo the answer should be permutation feature importance"
      },
      {
        "date": "2020-12-03T12:56:00.000Z",
        "voteCount": 4,
        "content": "\"In this module, feature values are randomly shuffled, one column at a time, and the performance of the model is measured before and after. You can choose one of the standard metrics provided to measure performance.\"\n\nhttps://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/permutation-feature-importance"
      },
      {
        "date": "2023-10-11T20:31:00.000Z",
        "voteCount": 2,
        "content": "Feature extraction method: \n1) Pearson's correlation\n2) Kendall's rank correlation\n3) Spearman's rank correlation\n\nhttps://www.phdata.io/blog/data-science-stats-review/\n\nThe question given 4 choices, has one choice for \"Kendall correlation\" --&gt; Choose C - Kendall correaltion for FEATURE EXTRACTION METHOD."
      },
      {
        "date": "2023-02-25T16:54:00.000Z",
        "voteCount": 1,
        "content": "Mutual information is a widely used feature extraction method in machine learning, especially in the context of feature selection. It is a statistical method that measures the amount of information that one feature provides about the other.\n\nThe main advantage of mutual information is that it can capture non-linear dependencies between variables, making it a powerful technique for extracting relevant features from complex data sets. It is also a computationally efficient method, which can handle high-dimensional data sets.\n\nOn the other hand, Mood's median test, Kendall correlation, and Permutation Feature Importance are not feature extraction methods, but rather statistical tests or feature importance measures that can be used in the context of feature selection. They do not provide a direct way of extracting features from the data, but rather help in identifying the most relevant features for a given problem.\n\nTherefore, in this case, the best option is to choose Mutual information as a feature extraction method."
      }
    ],
    "examNameCode": "dp-100",
    "topicNumber": "7"
  },
  {
    "topic": 8,
    "index": 11,
    "url": "https://www.examtopics.com/discussions/microsoft/view/53079-exam-dp-100-topic-7-question-11-discussion/",
    "body": "DRAG DROP -<br>You need to implement an early stopping criteria policy for model training.<br>Which three code segments should you use to develop the solution? To answer, move the appropriate code segments from the list of code segments to the answer area and arrange them in the correct order.<br>NOTE: More than one order of answer choices is correct. You will receive credit for any of the correct orders you select.<br>Select and Place:<br><img src=\"/assets/media/exam-media/04274/0036500001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04274/0036600001.png\" class=\"in-exam-image\">",
    "answerDescription": "You need to implement an early stopping criterion on models that provides savings without terminating promising jobs.<br>Truncation selection cancels a given percentage of lowest performing runs at each evaluation interval. Runs are compared based on their performance on the primary metric and the lowest X% are terminated.<br>Example:<br>from azureml.train.hyperdrive import TruncationSelectionPolicy early_termination_policy = TruncationSelectionPolicy(evaluation_interval=1, truncation_percentage=20, delay_evaluation=5)<br>Incorrect Answers:<br>Bandit is a termination policy based on slack factor/slack amount and evaluation interval. The policy early terminates any runs where the primary metric is not within the specified slack factor / slack amount with respect to the best performing training run.<br>Example:<br>from azureml.train.hyperdrive import BanditPolicy<br>early_termination_policy = BanditPolicy(slack_factor = 0.1, evaluation_interval=1, delay_evaluation=5<br>Reference:<br>https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-tune-hyperparameters",
    "votes": [],
    "comments": [
      {
        "date": "2023-10-11T20:46:00.000Z",
        "voteCount": 1,
        "content": "Code snippet in structure with 3 steps:\n1) from ...\n2) import ...\n3) call method\n\nHas only \"from....\" from choices list --&gt; choose \"from azureml.train.hyperdrive\" without any afraid. Next, \"BanditPolicy\" or \"\"TruncationSelectionPolicy\"? all of two for \"early termination policy\".\n\nhttps://learn.microsoft.com/en-us/python/api/azureml-train-core/azureml.train.hyperdrive.banditpolicy?view=azure-ml-py\n\nhttps://learn.microsoft.com/en-us/python/api/azureml-train-core/azureml.train.hyperdrive.truncationselectionpolicy?view=azure-ml-py\n\nKeywords in the question \"must implement an early stopping criterion on models that provides savings without terminating promising jobs.\" SAVING WITHOUT TERMINATING PROMISSING JOBS. See comparig from Google Bard https://g.co/bard/share/09f818b51866 . Choose TruncationSeclectionPloicy"
      },
      {
        "date": "2023-02-25T18:19:00.000Z",
        "voteCount": 2,
        "content": "from azureml.train.hyperdrive, import BanditPolicy, early_termination_policy= BanditPolicy().\n\nTruncationSelectionPolicy does have an option to cancel the lowest performing runs. However, this policy does not take into account the performance of previous runs, so it may not be the most effective early stopping policy. The policy simply cancels runs if their performance falls below a certain threshold.\n\nIn contrast, the BanditPolicy considers the performance of previous runs when deciding which runs to stop early. It uses a Bayesian approach to estimate the best performing configuration and stops runs that are unlikely to perform better than the current best configuration. This makes it a more effective early stopping policy in many cases.\n\nSo while the TruncationSelectionPolicy may be a valid option for some situations, the BanditPolicy is generally a better choice for implementing an effective early stopping policy."
      },
      {
        "date": "2021-05-18T23:37:00.000Z",
        "voteCount": 1,
        "content": "Could anyone explain why the correct answer is Truncation instead of Bandit policy?"
      },
      {
        "date": "2021-08-05T22:32:00.000Z",
        "voteCount": 4,
        "content": "Because question says \"this configuration should cancel the lowest performing runs\", which only happens in truncation"
      },
      {
        "date": "2022-11-21T19:58:00.000Z",
        "voteCount": 1,
        "content": "You're right. This phrase was mentioned in the section Hyperparameter."
      },
      {
        "date": "2023-06-29T08:49:00.000Z",
        "voteCount": 1,
        "content": "wdym? Bandit Policy cancels runs whose best results fall below a certain mark (related with the goal and the slack factor), so it also does that. \n\nBesides that, Truncation will stop runs that fall below a certain threshold right away, going against the requirement of the case study which reinforces that promising runs should not be terminated"
      },
      {
        "date": "2023-06-29T08:52:00.000Z",
        "voteCount": 1,
        "content": "PS - I understand that the main core of Truncation is canceling the lowest performing runs per se, my point is just that Bandit Policy also does it but \"less blindly\" if this makes sense, so the possible solution can be either imo"
      },
      {
        "date": "2021-05-28T11:59:00.000Z",
        "voteCount": 3,
        "content": "For a conservative policy that provides savings without terminating promising jobs, consider a Median Stopping Policy with evaluation_interval 1 and delay_evaluation 5. These are conservative settings, that can provide approximately 25%-35% savings with no loss on primary metric (based on our evaluation data).\nFor more aggressive savings, use Bandit Policy with a smaller allowable slack or Truncation Selection Policy with a larger truncation percentage."
      },
      {
        "date": "2022-04-04T01:08:00.000Z",
        "voteCount": 2,
        "content": "it says \"NOTE: More than one order of answer choices is correct.\" considering there's really only two combinations that would work we can assume both are correct"
      }
    ],
    "examNameCode": "dp-100",
    "topicNumber": "7"
  },
  {
    "topic": 8,
    "index": 12,
    "url": "https://www.examtopics.com/discussions/microsoft/view/46080-exam-dp-100-topic-7-question-12-discussion/",
    "body": "DRAG DROP -<br>You need to implement early stopping criteria as stated in the model training requirements.<br>Which three code segments should you use to develop the solution? To answer, move the appropriate code segments from the list of code segments to the answer area and arrange them in the correct order.<br>NOTE: More than one order of answer choices is correct. You will receive the credit for any of the correct orders you select.<br>Select and Place:<br><img src=\"/assets/media/exam-media/04274/0036800001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04274/0036900001.png\" class=\"in-exam-image\">",
    "answerDescription": "Step 1: from azureml.train.hyperdrive<br>Step 2: Import TruncationCelectionPolicy<br>Truncation selection cancels a given percentage of lowest performing runs at each evaluation interval. Runs are compared based on their performance on the primary metric and the lowest X% are terminated.<br>Scenario: You must configure hyperparameters in the model learning process to speed the learning phase. In addition, this configuration should cancel the lowest performing runs at each evaluation interval, thereby directing effort and resources towards models that are more likely to be successful.<br>Step 3: early_terminiation_policy = TruncationSelectionPolicy..<br>Example:<br>from azureml.train.hyperdrive import TruncationSelectionPolicy early_termination_policy = TruncationSelectionPolicy(evaluation_interval=1, truncation_percentage=20, delay_evaluation=5)<br>In this example, the early termination policy is applied at every interval starting at evaluation interval 5. A run will be terminated at interval 5 if its performance at interval 5 is in the lowest 20% of performance of all runs at interval 5.<br>Incorrect Answers:<br>Median:<br>Median stopping is an early termination policy based on running averages of primary metrics reported by the runs. This policy computes running averages across all training runs and terminates runs whose performance is worse than the median of the running averages.<br>Slack:<br>Bandit is a termination policy based on slack factor/slack amount and evaluation interval. The policy early terminates any runs where the primary metric is not within the specified slack factor / slack amount with respect to the best performing training run.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-tune-hyperparameters",
    "votes": [],
    "comments": [
      {
        "date": "2023-10-11T20:56:00.000Z",
        "voteCount": 1,
        "content": "Question's keyword \"Therefore, must implement an early stopping criterion on models that provides savings without terminating promising jobs.\" So choose 2nd block what is \"TruncationSelectionPolicy\" ."
      },
      {
        "date": "2023-02-25T18:34:00.000Z",
        "voteCount": 1,
        "content": "In this case, the Bandit policy would be the more appropriate selection. The Bandit policy is designed to balance exploration (trying out different hyperparameters) and exploitation (using the best hyperparameters found so far) while taking into account the efficiency of resource utilization. The Bandit policy is suitable when there are limited computational resources available and when there is a need to terminate low-performing runs early."
      },
      {
        "date": "2022-03-16T07:46:00.000Z",
        "voteCount": 1,
        "content": "Super long question for a simple problem. All you need to know is this:\nYou must configure hyperparameters in the model learning process to speed the learning phase. In addition, this configuration should cancel the lowest performing runs at each evaluation interval, thereby directing effort and resources towards models that are more likely to be successful.\nYou are concerned that the model might not efficiently use compute resources in hyperparameter tuning. You also are concerned that the model might prevent an increase in the overall tuning time. Therefore, must implement an early stopping criterion on models that provides savings without terminating promising jobs.\nAnswer: Selection Truncation policy.  As delay_evaluation is already set in all 3 answers, that's not a factor."
      },
      {
        "date": "2021-10-11T06:45:00.000Z",
        "voteCount": 1,
        "content": "has anyone seen such question recently in exam"
      },
      {
        "date": "2021-06-20T18:43:00.000Z",
        "voteCount": 4,
        "content": "The case study is about cancel the lowest performing runs at each evaluation interval (Hyperparameters). So, using \"Truncation selection policy\" is correct answer"
      },
      {
        "date": "2021-05-18T23:44:00.000Z",
        "voteCount": 1,
        "content": "I agree with medianStopping as referred to the answer's link"
      },
      {
        "date": "2021-03-08T05:53:00.000Z",
        "voteCount": 4,
        "content": "I think, the policy should be the MedianTerminationPolicy,\n\nFor a conservative policy that provides savings without terminating promising jobs, consider a Median Stopping Policy with evaluation_interval 1 and delay_evaluation 5. These are conservative settings, that can provide approximately 25%-35% savings with no loss on primary metric (based on our evaluation data)."
      },
      {
        "date": "2022-04-04T01:11:00.000Z",
        "voteCount": 1,
        "content": "the question states that \"NOTE: More than one order of answer choices is correct. \" so that can be true simulatenous with TruncationSelectionPolicy"
      }
    ],
    "examNameCode": "dp-100",
    "topicNumber": "7"
  }
]