[
  {
    "topic": 10,
    "index": 1,
    "url": "https://www.examtopics.com/discussions/microsoft/view/60716-exam-dp-203-topic-10-question-1-discussion/",
    "body": "What should you do to improve high availability of the real-time data processing solution?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDeploy a High Concurrency Databricks cluster.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDeploy an Azure Stream Analytics job and use an Azure Automation runbook to check the status of the job and to start the job if it stops.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSet Data Lake Storage to use geo-redundant storage (GRS).",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDeploy identical Azure Stream Analytics jobs to paired regions in Azure.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 12,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-08-26T04:17:00.000Z",
        "voteCount": 12,
        "content": "There is a request 'Minimize number of Azure services'. With https://docs.microsoft.com/en-us/azure/event-hubs/event-hubs-capture-overview Event capture, data can be stored in DL without using Stream Analytics.  In this case just Reional redundancy for DL would be needed."
      },
      {
        "date": "2023-09-18T20:44:00.000Z",
        "voteCount": 9,
        "content": "I passed today.. 820.. Thoughts.. 80% of exam questions were in Examtopics. Other 20% were not difficult. I got the Contoso case study... Good Luck."
      },
      {
        "date": "2021-09-24T03:58:00.000Z",
        "voteCount": 1,
        "content": "NB : it's an asynchronous copy."
      },
      {
        "date": "2021-09-17T01:45:00.000Z",
        "voteCount": 1,
        "content": "Agree, they also want a stage on data lake 2.\n\"Stage Inventory data in Azure Data Lake Storage Gen2\"\nwe don't need Stream Analytics to do that. Event Hub enables you to automatically capture the streaming data in Event Hubs in an Azure Blob storage or Azure Data Lake Storage Gen 1 or Gen 2 account of your choice, with the added flexibility of specifying a time or size interval."
      },
      {
        "date": "2021-09-17T01:51:00.000Z",
        "voteCount": 9,
        "content": "Please desconsidere my answer!\nEvent Hub can capture data to Data Lake and Blob. But I think the key word in the question is: eal-time data PROCESSING solution azure. Event hub is just for capture. Stream Analytics do the processing so I'm going with answer D"
      },
      {
        "date": "2021-09-17T15:43:00.000Z",
        "voteCount": 8,
        "content": "I agree, Regional redundancy will be great for data but the processing would be lost. We need a solution for High Availability for PROCESSING and DATA."
      },
      {
        "date": "2022-01-29T15:54:00.000Z",
        "voteCount": 2,
        "content": "The question is asking \"improve high availability of the real-time data processing solution\" and not high availability of data. Hence the correct answer is D"
      },
      {
        "date": "2023-09-01T00:49:00.000Z",
        "voteCount": 1,
        "content": "should be D"
      },
      {
        "date": "2023-06-22T16:23:00.000Z",
        "voteCount": 2,
        "content": "By deploying identical Azure Stream Analytics jobs to paired regions in Azure, you ensure redundancy and fault tolerance for the real-time data processing solution. Paired regions in Azure are geographically separated and designed to provide resilience and data protection in the event of a regional outage or failure. If one region becomes unavailable, the other paired region can seamlessly take over the processing workload, ensuring continuous availability of the real-time data processing solution."
      },
      {
        "date": "2022-08-13T07:51:00.000Z",
        "voteCount": 4,
        "content": "answer D is correct"
      },
      {
        "date": "2022-06-27T22:25:00.000Z",
        "voteCount": 3,
        "content": "Answer is correct"
      },
      {
        "date": "2022-01-29T15:54:00.000Z",
        "voteCount": 3,
        "content": "D is correct.\nThe question is asking \"improve high availability of the real-time data processing solution\" and not high availability of data. Hence the correct answer is"
      },
      {
        "date": "2022-01-25T00:21:00.000Z",
        "voteCount": 2,
        "content": "I go with D and info provided by Canary_2021 is correct."
      },
      {
        "date": "2022-01-08T09:15:00.000Z",
        "voteCount": 2,
        "content": "guys, the correct answer is A. It says to limit the amount of different services to use. Databricks is being used as a analytical tool for the datascientist already, so it can also be used for processing jobs."
      },
      {
        "date": "2022-06-24T21:52:00.000Z",
        "voteCount": 1,
        "content": "You are right, but HC doesn't improve one shot processing, this would work better with multiple users"
      },
      {
        "date": "2021-12-29T19:16:00.000Z",
        "voteCount": 2,
        "content": "I think the answer is correct!"
      },
      {
        "date": "2021-12-29T17:52:00.000Z",
        "voteCount": 4,
        "content": "The answer should be D if the real time data load solution to move data from Azure Data Lake Storage Gen2 to Data Lake Gen2 to Azure SQL DB or Synapse Analytics as analytical data store. \nIf this way, Power BI and Azure Databricks notebooks will run query against Azure SQL DB or Synapse Analytics.\n\n\u2022\tDaily inventory data comes from a Microsoft SQL server located on a private network.\n\u2022\tStage Inventory data in Azure Data Lake Storage Gen2 before loading the data into the analytical data store.\n\u2022\tSee inventory levels across the stores. Data must be updated as close to real time as possible.\n\u2022\tLitware employs business analysts who prefer to analyze data by using Microsoft Power BI, and data scientists who prefer analyzing data in Azure Databricks notebooks."
      },
      {
        "date": "2021-12-19T09:05:00.000Z",
        "voteCount": 4,
        "content": "I think the answer C is correct, high availability of \"the real-time data processing\", not high availability of \"the data storage\""
      },
      {
        "date": "2021-12-20T16:25:00.000Z",
        "voteCount": 3,
        "content": "sorry, typo, right answer is D"
      },
      {
        "date": "2021-11-25T12:05:00.000Z",
        "voteCount": 2,
        "content": "What is the correct answer?"
      }
    ],
    "examNameCode": "dp-203",
    "topicNumber": "10"
  }
]