[
  {
    "topic": 3,
    "index": 1,
    "url": "https://www.examtopics.com/discussions/microsoft/view/55511-exam-ai-102-topic-3-question-1-discussion/",
    "body": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.<br>After you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.<br>You build a language model by using a Language Understanding service. The language model is used to search for information on a contact list by using an intent named FindContact.<br>A conversational expert provides you with the following list of phrases to use for training.<br>\u2711 Find contacts in London.<br>\u2711 Who do I know in Seattle?<br>\u2711 Search for contacts in Ukraine.<br>You need to implement the phrase list in Language Understanding.<br>Solution: You create a new pattern in the FindContact intent.<br>Does this meet the goal?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tYes\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tNo\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 24,
        "isMostVoted": true
      },
      {
        "answer": "A",
        "count": 24,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-06-30T11:00:00.000Z",
        "voteCount": 30,
        "content": "Using a pattern could be a good solution IMHO... \n\u2711 Find contacts in London.\n\u2711 Who do I know in Seattle?\n\u2711 Search for contacts in Ukraine.\n\nLike\nWhere is {FormName}[?]\nWho authored {FormName}[?]\n{FormName} is published in French[?]\n(taken from https://docs.microsoft.com/en-us/azure/cognitive-services/luis/luis-concept-patterns)\n\nwe could do:\n\u2711 Find contacts in {CityOrCountry}.\n\u2711 Who do I know in {CityOrCountry}[?]\n\u2711 Search for contacts in {CityOrCountry}[?].\n\nSo, to me a pattern is a Solution (A)"
      },
      {
        "date": "2021-07-27T02:10:00.000Z",
        "voteCount": 2,
        "content": "Agree, but Entity is also good https://docs.microsoft.com/bs-cyrl-ba/azure/cognitive-services/luis/luis-concept-intent#intent-compared-to-entity"
      },
      {
        "date": "2022-09-18T03:16:00.000Z",
        "voteCount": 1,
        "content": "I agree. The intent here is \"search for contact\", for example. The location is an entity type \"location\", as you can see in the example  What's the weather like in Seattle tomorrow? on the link given by  @YipingRuan"
      },
      {
        "date": "2022-09-20T01:21:00.000Z",
        "voteCount": 10,
        "content": "According to MS learn, answer should be yes (A)\n\nhttps://learn.microsoft.com/en-us/training/modules/create-language-understanding-app/5-use-patterns-to-differentiate-similar-utterances\n\nThis is a FindContact intent with a location entity pattern"
      },
      {
        "date": "2024-09-30T06:06:00.000Z",
        "voteCount": 1,
        "content": "Th answer would be to add example utterances that trains the model to recognize similar phrases"
      },
      {
        "date": "2024-09-05T09:34:00.000Z",
        "voteCount": 1,
        "content": "Phrases are like synonyms. Here it is about entities (location to be specific) that is required along with the intent to do the action. Unless of course there are some hidden tricks to make people who know how it is used fail. This (certification) department in the dysfunctional microsoft is about making more money in that department (and missing the bigger picture). Intra company fights is microsoft"
      },
      {
        "date": "2024-09-05T09:43:00.000Z",
        "voteCount": 1,
        "content": "Wait a minute, of course there is a catch. It is a trap. They do not talk about entities, which will come to mind. The question is formulated in a complex way I can't make out what breakfast the creator of this marvellous question ate. \n\nI have to say no because it is just creating the pattern, and not creating the phrase and in the phrase the pattern. But god knows what is the intent of this question. Microsoft !!"
      },
      {
        "date": "2024-08-29T22:39:00.000Z",
        "voteCount": 1,
        "content": "**Answer: B. No**\n\nCreating a new pattern in the FindContact intent is not the correct approach. Patterns in Language Understanding services are used to match specific sentence structures rather than training the model with example phrases. To properly implement the phrase list for training, you should add these phrases as example utterances within the FindContact intent. This way, the model learns to recognize different ways users might ask to find contacts.\n\nSo, the correct approach would be to add these phrases as example utterances, not just creating a new pattern."
      },
      {
        "date": "2024-06-23T01:26:00.000Z",
        "voteCount": 1,
        "content": "No. Find contacts in {Location} where location is an entity"
      },
      {
        "date": "2024-06-21T08:37:00.000Z",
        "voteCount": 1,
        "content": "I say A is correct! HipHop!"
      },
      {
        "date": "2024-06-15T08:03:00.000Z",
        "voteCount": 1,
        "content": "This issue is not working because everyone's opinion is 50-50. I don't know the correct answer, so I will be staring at MS Learn when this question comes up on the real exam.Examtopic should scrutinize and post the correct answer."
      },
      {
        "date": "2024-06-15T08:02:00.000Z",
        "voteCount": 1,
        "content": "This issue is not working because everyone's opinion is 50-50. I don't know the correct answer, so I will be staring at MS Learn when this question comes up on the real exam.Examtopic should scrutinize and post the correct answer."
      },
      {
        "date": "2024-06-13T03:03:00.000Z",
        "voteCount": 2,
        "content": "While creating a pattern might seem like a solution, it's not the most suitable approach for this scenario.\n\nHere's why:\n\nPatterns: Patterns in Language Understanding (LUIS) are designed to capture specific structures in utterances and often involve labeling entities within those structures. They wouldn't be ideal for capturing synonyms or similar phrasings like \"Find\", \"Who do I know\", and \"Search for\".\n\nPhrase Lists: A better approach for this situation is to utilize Phrase Lists in LUIS. Phrase lists allow you to define a set of synonyms or related phrases that the LUIS model can recognize as equivalent when encountering them in user queries.\n\nTherefore, to implement the provided phrases effectively, you should create a Phrase List containing synonyms like \"Find\", \"Who do I know\", and \"Search for\" and associate it with the FindContact intent."
      },
      {
        "date": "2024-06-08T05:45:00.000Z",
        "voteCount": 2,
        "content": "ChatGPT says not enough, Copilot says yes. I stay with Copilot"
      },
      {
        "date": "2024-08-18T19:37:00.000Z",
        "voteCount": 1,
        "content": "copied entire question to Copilot, and Copilot says YES."
      },
      {
        "date": "2024-05-24T08:21:00.000Z",
        "voteCount": 1,
        "content": "It MUST be A."
      },
      {
        "date": "2024-05-24T08:19:00.000Z",
        "voteCount": 1,
        "content": "After all, would you choose Yes or No to be correct?"
      },
      {
        "date": "2024-04-07T09:15:00.000Z",
        "voteCount": 1,
        "content": "A is correct"
      },
      {
        "date": "2024-03-30T06:23:00.000Z",
        "voteCount": 1,
        "content": "Yes, creating a new pattern in the FindContact intent with the provided phrases can help train the Language Understanding model to better recognize when the user is trying to find contacts in a specific location. This would meet the goal of implementing the phrase list in Language Understanding."
      },
      {
        "date": "2024-03-28T16:41:00.000Z",
        "voteCount": 2,
        "content": "This same question (topic 3, question 18) seems to be indicated by the community that this question has two affirmative answers. I'm not sure if this is correct, normally in this type of question there is only one affirmative answer and the rest are negative. Is anyone clear on the real answer to this question?"
      },
      {
        "date": "2024-01-21T05:29:00.000Z",
        "voteCount": 4,
        "content": "B. No\n\nThe proposed solution of creating a new pattern in the FindContact intent does not fully meet the goal of implementing a phrase list in Language Understanding (often referred to as LUIS - Language Understanding Intelligent Service in Azure).\n\nIn Azure LUIS, patterns are used to identify specific sentence structures that indicate intents, and they are indeed a valuable part of intent recognition. However, patterns alone are not the same as a phrase list. A phrase list in LUIS is a feature that allows you to define a list of related words or phrases which can be used across various intents and utterances. It's more about providing synonyms or variations of words that help the model understand different ways a user might express the same concept."
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 2,
    "url": "https://www.examtopics.com/discussions/microsoft/view/56451-exam-ai-102-topic-3-question-2-discussion/",
    "body": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.<br>After you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.<br>You develop an application to identify species of flowers by training a Custom Vision model.<br>You receive images of new flower species.<br>You need to add the new images to the classifier.<br>Solution: You add the new images, and then use the Smart Labeler tool.<br>Does this meet the goal?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tYes",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tNo\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 17,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-07-03T09:46:00.000Z",
        "voteCount": 15,
        "content": "The answer is correct."
      },
      {
        "date": "2023-10-10T19:49:00.000Z",
        "voteCount": 10,
        "content": "The answer is B is because the limitations of the smart labeler: You should only request suggested tags for images whose tags have already been trained on once. Don't get suggestions for a new tag that you're just beginning to train. You are given new images of species that have not been seen by the model how can you expect it to suggest what they are? Also you can train the model right in the smart labeler: check the workflow and the limitations in the doc. https://learn.microsoft.com/en-us/azure/ai-services/custom-vision-service/suggested-tags"
      },
      {
        "date": "2023-11-04T07:31:00.000Z",
        "voteCount": 1,
        "content": "Answer and explanation are correct.\nhttps://learn.microsoft.com/en-us/azure/ai-services/custom-vision-service/suggested-tags"
      },
      {
        "date": "2023-08-18T07:58:00.000Z",
        "voteCount": 1,
        "content": "Smart Labeler for suggestion https://learn.microsoft.com/en-us/azure/ai-services/custom-vision-service/suggested-tags"
      },
      {
        "date": "2023-06-29T03:20:00.000Z",
        "voteCount": 1,
        "content": "B is the answer.\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/suggested-tags\nSmart Labeler will generate suggested tags for images. This lets you label a large number of images more quickly when you're training a Custom Vision model.\n\nWhen you tag images for a Custom Vision model, the service uses the latest trained iteration of the model to predict the labels of new images. It shows these predictions as suggested tags, based on the selected confidence threshold and prediction uncertainty. You can then either confirm or change the suggestions, speeding up the process of manually tagging the images for training."
      },
      {
        "date": "2023-05-15T00:24:00.000Z",
        "voteCount": 2,
        "content": "chat gpt \"\nChatGPT\nA. Yes.\n\nUsing the Smart Labeler tool is a valid way to train a Custom Vision model with new images. It allows the user to label images more efficiently by using an active learning approach that selects images that will have the highest impact on the model's performance.\""
      },
      {
        "date": "2022-08-07T10:53:00.000Z",
        "voteCount": 1,
        "content": "retrain model so answer is B"
      },
      {
        "date": "2022-07-18T07:00:00.000Z",
        "voteCount": 4,
        "content": "B is correct answer : No.\n\nInstead the model need to be extended and retrained (Udemy answer)."
      },
      {
        "date": "2022-03-01T06:02:00.000Z",
        "voteCount": 1,
        "content": "answer is correct"
      },
      {
        "date": "2022-01-05T16:00:00.000Z",
        "voteCount": 2,
        "content": "Label + Retrain"
      },
      {
        "date": "2021-06-30T11:07:00.000Z",
        "voteCount": 5,
        "content": "correct! retraining is necesary!"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 3,
    "url": "https://www.examtopics.com/discussions/microsoft/view/56452-exam-ai-102-topic-3-question-3-discussion/",
    "body": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.<br>After you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.<br>You develop an application to identify species of flowers by training a Custom Vision model.<br>You receive images of new flower species.<br>You need to add the new images to the classifier.<br>Solution: You add the new images and labels to the existing model. You retrain the model, and then publish the model.<br>Does this meet the goal?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tYes\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tNo"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 4,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-06-30T11:09:00.000Z",
        "voteCount": 18,
        "content": "Correct!\nuploading, tagging, retraining and publishing the model"
      },
      {
        "date": "2022-06-07T05:29:00.000Z",
        "voteCount": 5,
        "content": "Was on exam 7 Jun 2022"
      },
      {
        "date": "2024-06-21T08:38:00.000Z",
        "voteCount": 1,
        "content": "\"add the new images and labels to the existing model. You retrain the model, and then publish the model.\" is correct. HipHop!"
      },
      {
        "date": "2023-11-04T07:32:00.000Z",
        "voteCount": 1,
        "content": "correct answer"
      },
      {
        "date": "2023-08-18T08:01:00.000Z",
        "voteCount": 1,
        "content": "add the new images and labels to the existing model. \n\nYou retrain the model, \n\nand then publish the model.\n\n--&gt; Perfect."
      },
      {
        "date": "2022-07-18T07:01:00.000Z",
        "voteCount": 1,
        "content": "A is correct answer : Yes\n\nInstead the model need to be extended and retrained (Udemy answer). \nNote: Use Smart Labeler to generate suggested tags for images. This lets you label a large number of images more quickly when training a Custom Vision model."
      },
      {
        "date": "2022-07-07T04:46:00.000Z",
        "voteCount": 1,
        "content": "Looks good to me!"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 4,
    "url": "https://www.examtopics.com/discussions/microsoft/view/56454-exam-ai-102-topic-3-question-4-discussion/",
    "body": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.<br>After you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.<br>You develop an application to identify species of flowers by training a Custom Vision model.<br>You receive images of new flower species.<br>You need to add the new images to the classifier.<br>Solution: You create a new model, and then upload the new images and labels.<br>Does this meet the goal?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tYes",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tNo\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 5,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-06-01T09:36:00.000Z",
        "voteCount": 4,
        "content": "To pass this exam, you will need to separate and memorise each of the following categories: \u2018Yes/No questions that are presented in sequence and cannot be reversed once a decision has been made\u2019, \u2018Yes/No three-choice questions\u2019, \u2018Drag and Drop drop drop-down selection questions\u2019 and \u2018Drag and Drop sorting questions\u2019. Do your best. I did that, memorized all the questions and passed."
      },
      {
        "date": "2023-11-04T07:33:00.000Z",
        "voteCount": 2,
        "content": "Correct. Instead you need to add the new images and labels to the existing model. You retrain the model, and then publish the model"
      },
      {
        "date": "2023-10-10T19:47:00.000Z",
        "voteCount": 1,
        "content": "The answer is B is because the limitations of the smart labeler: You should only request suggested tags for images whose tags have already been trained on once. Don't get suggestions for a new tag that you're just beginning to train. You are given new images of species that have not been seen by the model how can you expect it to suggest what they are? Also you can train the model right in the smart labeler: check the workflow and the limitations in the doc. https://learn.microsoft.com/en-us/azure/ai-services/custom-vision-service/suggested-tags"
      },
      {
        "date": "2023-10-10T19:49:00.000Z",
        "voteCount": 1,
        "content": "Oops I meant to answer the question 2 above this one."
      },
      {
        "date": "2023-08-18T08:04:00.000Z",
        "voteCount": 1,
        "content": "Need training. Correct answer: No"
      },
      {
        "date": "2022-07-18T07:02:00.000Z",
        "voteCount": 1,
        "content": "B is correct answer : No.\n\nThe model needs to be extended and retrained. (Udemy answer)\n\nNote: Use Smart Labeler to generate suggested tags for images. This lets you label a large number of images more quickly when training a Custom Vision model."
      },
      {
        "date": "2021-09-22T02:05:00.000Z",
        "voteCount": 4,
        "content": "Answer is correct, no need to create a new model, the existing one should be extended and retrained"
      },
      {
        "date": "2021-07-04T09:11:00.000Z",
        "voteCount": 1,
        "content": "You don't need to retrain because you created a brand new model"
      },
      {
        "date": "2021-07-23T04:10:00.000Z",
        "voteCount": 6,
        "content": "No. If \"You create a new model, and then upload the new images and labels.\" your model lacks previous images of other flowers. So the answer is correct."
      },
      {
        "date": "2021-07-27T02:24:00.000Z",
        "voteCount": 1,
        "content": "If must, Create and upload the new model,  not upload the image.."
      },
      {
        "date": "2021-06-30T11:09:00.000Z",
        "voteCount": 3,
        "content": "correct!\nresponse lacks the model retraining..."
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 5,
    "url": "https://www.examtopics.com/discussions/microsoft/view/56455-exam-ai-102-topic-3-question-5-discussion/",
    "body": "HOTSPOT -<br>You are developing a service that records lectures given in English (United Kingdom).<br>You have a method named AppendToTranscriptFile that takes translated text and a language identifier.<br>You need to develop code that will provide transcripts of the lectures to attendees in their respective language. The supported languages are English, French,<br>Spanish, and German.<br>How should you complete the code? To answer, select the appropriate options in the answer area.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04271/0013100001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04271/0013200001.png\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: {\"fr\", \"de\", \"es\"}<br>A common task of speech translation is to specify target translation languages, at least one is required but multiples are supported. The following code snippet sets both French and German as translation language targets. static async Task TranslateSpeechAsync()<br>{<br>var translationConfig =<br>SpeechTranslationConfig.FromSubscription(SPEECH__SUBSCRIPTION__KEY, SPEECH__SERVICE__REGION); translationConfig.SpeechRecognitionLanguage = \"it-IT\";<br><br>// Translate to languages. See, https://aka.ms/speech/sttt-languages translationConfig.AddTargetLanguage(\"fr\"); translationConfig.AddTargetLanguage(\"de\");<br>}<br><br>Box 2: TranslationRecognizer -<br>After you've created a SpeechTranslationConfig, the next step is to initialize a TranslationRecognizer.<br>Example code:<br>static async Task TranslateSpeechAsync()<br>{<br>var translationConfig =<br>SpeechTranslationConfig.FromSubscription(SPEECH__SUBSCRIPTION__KEY, SPEECH__SERVICE__REGION); var fromLanguage = \"en-US\"; var toLanguages = new List&lt;string&gt; { \"it\", \"fr\", \"de\" }; translationConfig.SpeechRecognitionLanguage = fromLanguage; toLanguages.ForEach(translationConfig.AddTargetLanguage); using var recognizer = new TranslationRecognizer(translationConfig);<br>}",
    "votes": [],
    "comments": [
      {
        "date": "2021-06-30T11:11:00.000Z",
        "voteCount": 15,
        "content": "Correct!"
      },
      {
        "date": "2021-07-04T12:08:00.000Z",
        "voteCount": 8,
        "content": "Seems correct\nhttps://docs.microsoft.com/en-us/dotnet/api/microsoft.cognitiveservices.speech.translation.translationrecognizer?view=azure-dotnet"
      },
      {
        "date": "2024-09-06T06:30:00.000Z",
        "voteCount": 2,
        "content": "So, they want to make it a trick by asking for english language as well, but it does not need to be passed. So, one point for the person who remembers it does not have to be passed? That knowledge proves they know Azure-AI?"
      },
      {
        "date": "2024-06-21T23:35:00.000Z",
        "voteCount": 3,
        "content": "was on exam 20.06.24"
      },
      {
        "date": "2024-02-24T14:20:00.000Z",
        "voteCount": 1,
        "content": "correct\nhttps://learn.microsoft.com/en-us/azure/ai-services/speech-service/how-to-translate-speech?tabs=terminal&amp;pivots=programming-language-csharp"
      },
      {
        "date": "2023-11-04T07:39:00.000Z",
        "voteCount": 2,
        "content": "correct answer\nhttps://docs.microsoft.com/en-us/dotnet/api/microsoft.cognitiveservices.speech.translation.translationrecognizer?view=azure-dotnet"
      },
      {
        "date": "2023-10-04T02:59:00.000Z",
        "voteCount": 5,
        "content": "Correct,got this in Oct2023 exam"
      },
      {
        "date": "2022-07-18T07:09:00.000Z",
        "voteCount": 6,
        "content": "Answer is correct.\n\n(\"fr\",  \"de\",  \"es\")\nTranslationRecognizer"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 6,
    "url": "https://www.examtopics.com/discussions/microsoft/view/60473-exam-ai-102-topic-3-question-6-discussion/",
    "body": "DRAG DROP -<br>You train a Custom Vision model used in a mobile app.<br>You receive 1,000 new images that do not have any associated data.<br>You need to use the images to retrain the model. The solution must minimize how long it takes to retrain the model.<br>Which three actions should you perform in the Custom Vision portal? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.<br>Select and Place:<br><img src=\"/assets/media/exam-media/04271/0013400001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04271/0013400002.png\" class=\"in-exam-image\">",
    "answerDescription": "Reference:<br>https://docs.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/getting-started-build-a-classifier",
    "votes": [],
    "comments": [
      {
        "date": "2021-08-24T01:51:00.000Z",
        "voteCount": 132,
        "content": "The given answer is incorrect. The question emphasizes two things - 1) the model has already been trained 2) the solution should be expedient. The given answer will be very slow to manually tag 1,000 images. instead:\n\n1.) upload all the images\n2.) Get suggested tags\n3.) Review the suggestions and confirm the tags\n\nreference:\n\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/suggested-tags"
      },
      {
        "date": "2021-09-13T14:17:00.000Z",
        "voteCount": 3,
        "content": "Thank you."
      },
      {
        "date": "2021-10-20T00:15:00.000Z",
        "voteCount": 3,
        "content": "When you tag images for a Custom Vision model, the service uses the latest trained iteration of the model to predict the labels of untagged images\nwe need latest trained to predict the labels, but this isn NOT HAVE ANY ASSOCIATED DATA"
      },
      {
        "date": "2023-11-04T07:43:00.000Z",
        "voteCount": 3,
        "content": "Exactly. Here we need to use Smart Labeler instead.\nhttps://learn.microsoft.com/en-us/azure/ai-services/custom-vision-service/suggested-tags"
      },
      {
        "date": "2022-09-20T01:44:00.000Z",
        "voteCount": 9,
        "content": "Answer is correct.\n\nWhen uploading all images from a same folder, you can tag all of them with the same value at the same time.\nThen you wont tag all 1000 images one by one, but only once by category (which is time saving as the question ask for).\n\nAlso, even if model is already trained, images are uploaded to workspace, and not to specific trained iteration.\nYou then cannot get tag suggestion when importing an image. There is none, that feature simply does not exist.\n\nTry by yourself :\nhttps://learn.microsoft.com/en-us/training/modules/classify-images/5-exercise-custom-vision"
      },
      {
        "date": "2022-09-22T01:36:00.000Z",
        "voteCount": 12,
        "content": "my bad the feature is real :\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/suggested-tags\n\nso right answer is\n- Upload all\n- Get suggested tags\n- Review and confirm tags"
      },
      {
        "date": "2024-09-22T15:26:00.000Z",
        "voteCount": 1,
        "content": "1) Smart Labeler (Suggested Tags):\n\nThe Smart Labeler functionality uses the latest trained iteration of the model to predict labels for new images. Therefore, even if the images are new, as long as they share similarities with what the model has already seen, the suggested tags feature can save time and effort.\n\nOfficial Documentation: The Azure documentation clearly states that the Smart Labeler can automatically suggest tags for uploaded images, provided they are similar in context to previously trained data.\n\n2) Uploading All Images:\n\nBulk uploading images is the most time-efficient method. There is no need to manually categorize or upload by folder.\n\nThe official Azure documentation supports SuperPetey's reasoning"
      },
      {
        "date": "2024-07-15T11:59:00.000Z",
        "voteCount": 1,
        "content": "1.) upload all the images\n2.) Get suggested tags\n3.) Review the suggestions and confirm the tags"
      },
      {
        "date": "2024-07-08T11:01:00.000Z",
        "voteCount": 1,
        "content": "Can't be correct. You wanna tell me people should manually tag 1000 images?\nAnd how do you categorize them in folders when they have no association? Seems dumb\nIt has to be\n1. Upload all the Images\n2. Get suggested tags\n3. Review the suggested Tags and confirm"
      },
      {
        "date": "2024-05-24T08:10:00.000Z",
        "voteCount": 1,
        "content": "Group\nUpload category\nTag"
      },
      {
        "date": "2024-04-30T17:20:00.000Z",
        "voteCount": 1,
        "content": "This question was asked in the actual exam on April 30, 2024 (+9:00, Japan). I think SuperPetey's answer is CORRECT, because I passed the AI-102 exam with a score of 917/1000. Thank you very much."
      },
      {
        "date": "2024-05-24T08:12:00.000Z",
        "voteCount": 1,
        "content": "So questions registered in 2021 will still be on the exam in April 2024? Japan is a scary country."
      },
      {
        "date": "2024-03-28T01:06:00.000Z",
        "voteCount": 2,
        "content": "Final Answer\n- Upload all\n- Get suggested tags\n- Review and confirm tags"
      },
      {
        "date": "2024-02-16T15:59:00.000Z",
        "voteCount": 4,
        "content": "To minimize the time required for retraining the model, the correct three steps are:\n\nUpload all images: First, you need to bulk upload the 1000 new images to the Custom Vision service. This is the foundational step for preparing the data.\n\nGet suggested tags: Utilize Custom Vision's functionality to automatically suggest tags for the uploaded images. This can significantly reduce the workload of manual tagging.\n\nReview and confirm suggested tags: Finally, manually review and confirm the tags suggested by the system to ensure their accuracy. Then, use these tagged images to retrain the model.\n\nThis process leverages the automation tools provided by Custom Vision to streamline and expedite the data preparation process, particularly effective when dealing with a large number of untagged images."
      },
      {
        "date": "2023-11-29T04:39:00.000Z",
        "voteCount": 1,
        "content": "Well, it's a bit confusing. In both cases (ET answers and SuperPetey suggestion) - we  will have to walk through the pictures manually if there is no info about them. IF they are stored in class folders - the ET answer is less time consuming, if not - it's not possible to tell if separating them manually or manual check of suggested tags will take less time."
      },
      {
        "date": "2023-10-10T21:10:00.000Z",
        "voteCount": 2,
        "content": "The answer is correct - there is no magic here. You can\u2019t suggest any new tags based on the model you currently have. Read the limitations of the smart labeler carefully: When to use Smart Labeler\nKeep the following limitations in mind:\nYou should only request suggested tags for images whose tags have already been trained on once. Don't get suggestions for a new tag that you're just beginning to train."
      },
      {
        "date": "2024-01-19T10:26:00.000Z",
        "voteCount": 3,
        "content": "\"When you tag images for a Custom Vision model, the service uses the latest trained iteration of the model to predict the labels of new images\"\n\nsource: https://learn.microsoft.com/en-us/azure/ai-services/custom-vision-service/suggested-tags"
      },
      {
        "date": "2022-07-18T07:19:00.000Z",
        "voteCount": 3,
        "content": "Answer given would be only option IF model had not already been trained with images, so...\nI agree with SuperPetey et al...\n\nUpload\nGet suggested tags\nReview and confirm tags"
      },
      {
        "date": "2022-05-27T02:25:00.000Z",
        "voteCount": 4,
        "content": "I agree with SuperPetey. The answer should be\n\n1.) upload all the images\n2.) Get suggested tags\n3.) Review the suggestions and confirm the tags\n\nReason being that using the tools(suggested tags) would still applied to the new 1000 images item, even if those 1000 images doesn't associate with the original data pool. So, that means tagging even 1 less images using the suggested tags would still be faster than manually tagging them. \nhttps://docs.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/suggested-tags"
      },
      {
        "date": "2022-03-01T04:48:00.000Z",
        "voteCount": 1,
        "content": "1.) Upload all the images\n2.) Get suggested tags\n3.) Review the suggestions and confirm the tags\n\nIf an image does not have any associated TAG, we can add a new one while reviewing\n\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/getting-started-improving-your-classifier"
      },
      {
        "date": "2021-11-27T18:30:00.000Z",
        "voteCount": 2,
        "content": "Was on exam 27/11/2021"
      },
      {
        "date": "2021-09-20T03:47:00.000Z",
        "voteCount": 3,
        "content": "@superpetey, kindly read through the article in the link you shared, I just did and confirmed from it that the provided answer by the platform is correct."
      },
      {
        "date": "2022-01-19T06:31:00.000Z",
        "voteCount": 4,
        "content": "I disagree, the images are unlabeled, but there is nothing in the text of the question mentioning that there are new tags. I agree with SuperPetey."
      },
      {
        "date": "2021-09-30T12:23:00.000Z",
        "voteCount": 3,
        "content": "\"You should only request suggested tags for images whose content has already been trained once. Don't get suggestions for a new tag that you're just beginning to train.\" And the question says RETRAINING of an existing model to which we are adding new images. So the response is actually wrong and @superpetey is correct"
      },
      {
        "date": "2021-09-30T12:25:00.000Z",
        "voteCount": 5,
        "content": "AHHHH but the key word is 'DO NOT HAVE ANY ASSOCIATED DATA'. So the content of images is brand new!!! Therefore we cant use suggester and the response is correct!"
      },
      {
        "date": "2024-03-26T22:35:00.000Z",
        "voteCount": 2,
        "content": "The point of machine learning is that a model eventually LEARNS how to do things independently. Even though there is no associated data, there is previous learning done and existing labels can be used. I am not sure why we would need ML if we still have to do things manually all the time?"
      },
      {
        "date": "2022-01-13T09:02:00.000Z",
        "voteCount": 1,
        "content": "I support your highlighted point to the right point. So the given answer should be correct."
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 7,
    "url": "https://www.examtopics.com/discussions/microsoft/view/80186-exam-ai-102-topic-3-question-7-discussion/",
    "body": "You are building a Conversational Language Understanding model for an e-commerce chatbot. Users can speak or type their billing address when prompted by the chatbot.<br>You need to construct an entity to capture billing addresses.<br>Which entity type should you use?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tmachine learned\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRegex",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tlist",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tPattern.any"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 41,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2022-09-04T21:00:00.000Z",
        "voteCount": 19,
        "content": "The link provided mentions addresses under 'ML Entities with Structure'. Will be hard to identify all possible international addresses with RegEx."
      },
      {
        "date": "2022-09-18T03:34:00.000Z",
        "voteCount": 9,
        "content": "A - MAchine Learned\n\nin documentation\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/LUIS/concepts/entities#ml-entity-with-structure\n\n- ML Entity with Structure\nAn ML entity can be composed of smaller sub-entities, each of which can have its own properties. For example, an Address entity could have the following structure:\n    Address: 4567 Main Street, NY, 98052, USA\n    Building Number: 4567\n    Street Name: Main Street\n    State: NY\n    Zip Code: 98052\n    Country: USA"
      },
      {
        "date": "2024-09-17T02:54:00.000Z",
        "voteCount": 1,
        "content": "Azure bot service no longer part of the exam, no need to revise this topic - https://trainingsupport.microsoft.com/en-us/mcp/forum/all/azure-ai102-chatbots-service/798c0cfa-3475-474e-b4ec-8ab7fc790e81#:~:text=Yes%2C%20Julian%20is%20correct%2C%20based,not%20appear%20in%20the%20exam."
      },
      {
        "date": "2024-06-25T21:25:00.000Z",
        "voteCount": 1,
        "content": "For me e GPT 3.5: machine learned"
      },
      {
        "date": "2024-06-12T08:26:00.000Z",
        "voteCount": 1,
        "content": "I know you don't know what I'm talking about, but if you think as Crossroads leads you, the answer is A."
      },
      {
        "date": "2024-05-29T06:26:00.000Z",
        "voteCount": 1,
        "content": "OK. Now I use A."
      },
      {
        "date": "2024-05-24T10:57:00.000Z",
        "voteCount": 1,
        "content": "As per Gemini chatbot, the answer is B. Regex. The following is the explanation it gives:\nRegex offers a powerful and efficient way to define patterns for capturing specific text formats, making it ideal for structured data like billing addresses. You can design a regex pattern to capture elements like street address, city, state, zip code, and potentially country code.\n\n; and why the answer is not 'machine learned':\nWhile machine learning can be powerful for complex entity recognition, it might be overkill for a well-defined structure like billing addresses. Training a machine learning model could be time-consuming and resource-intensive compared to a simpler solution."
      },
      {
        "date": "2024-05-24T07:56:00.000Z",
        "voteCount": 1,
        "content": "It must be A."
      },
      {
        "date": "2024-05-24T03:36:00.000Z",
        "voteCount": 2,
        "content": "on exam, I selected machine learned"
      },
      {
        "date": "2024-03-26T22:43:00.000Z",
        "voteCount": 4,
        "content": "Regex would be a good solution if the addresses were in a specific area (e.g, USA). But since that information is not given, you have to assume any type of address. So the correct answer in this case is A."
      },
      {
        "date": "2023-11-04T07:48:00.000Z",
        "voteCount": 2,
        "content": "https://learn.microsoft.com/en-us/azure/ai-services/luis/concepts/entities#ml-entity-with-structure"
      },
      {
        "date": "2023-08-12T16:18:00.000Z",
        "voteCount": 4,
        "content": "all but literally all answers are deliberately false in here, thanks for having the discussions folks!"
      },
      {
        "date": "2022-09-18T05:23:00.000Z",
        "voteCount": 2,
        "content": "it should be A"
      },
      {
        "date": "2022-09-09T12:54:00.000Z",
        "voteCount": 2,
        "content": "A. machine learned"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 8,
    "url": "https://www.examtopics.com/discussions/microsoft/view/60238-exam-ai-102-topic-3-question-8-discussion/",
    "body": "You are building an Azure WebJob that will create knowledge bases from an array of URLs.<br>You instantiate a QnAMakerClient object that has the relevant API keys and assign the object to a variable named client.<br>You need to develop a method to create the knowledge bases.<br>Which two actions should you include in the method? Each correct answer presents part of the solution.<br>NOTE: Each correct selection is worth one point.<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a list of FileDTO objects that represents data from the WebJob.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCall the client.Knowledgebase.CreateAsync method.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a list of QnADTO objects that represents data from the WebJob.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a CreateKbDTO object.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "BD",
    "answerDescription": "",
    "votes": [
      {
        "answer": "BD",
        "count": 18,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-08-22T05:25:00.000Z",
        "voteCount": 34,
        "content": "It should be BD."
      },
      {
        "date": "2021-08-24T01:59:00.000Z",
        "voteCount": 7,
        "content": "Correct - see code example here: https://docs.microsoft.com/en-us/azure/cognitive-services/qnamaker/quickstarts/quickstart-sdk?tabs=v1%2Cversion-1&amp;pivots=programming-language-csharp"
      },
      {
        "date": "2023-11-04T07:58:00.000Z",
        "voteCount": 3,
        "content": "agree with you. thank you for the provided documentation"
      },
      {
        "date": "2021-10-20T00:31:00.000Z",
        "voteCount": 3,
        "content": "A knowledge base stores question and answer pairs for the CreateKbDTO object from three sources:\n\n- For editorial content, use the QnADTO object.\nTo use metadata and follow-up prompts, use the editorial context, because this data is added at the individual QnA pair level.\n- For files, use the FileDTO object. The FileDTO includes the filename as well as the public URL to reach the file.\n- For URLs, use a list of strings to represent publicly available URLs.\nSo I beleive A and C correct"
      },
      {
        "date": "2022-03-01T15:26:00.000Z",
        "voteCount": 6,
        "content": "Answer :: B &amp; D\n\nA. Create a list of FileDTO objects that represents data from the WebJob.\nNO - as it is from URL - so optional\nB. Call the client.Knowledgebase.CreateAsync method.\nYES - Mandatory to Call the Method\nC. Create a list of QnADTO objects that represents data from the WebJob.\nNO - as it is from URL - so optional\nD. Create a CreateKbDTO object.\nYES - Mandatory to Create\n\nGo through the lines starting line 92 at below URL:\nhttps://github.com/Azure-Samples/cognitive-services-qnamaker-csharp/blob/master/documentation-samples/quickstarts/Knowledgebase_Quickstart/Program.cs"
      },
      {
        "date": "2022-08-13T14:25:00.000Z",
        "voteCount": 3,
        "content": "I agreed.\nYou are building an Azure WebJob that will create knowledge bases from an array of ##URLs##.\nYou could use FileDTO, QnADTO or urls to create the CreateKbDTO. Hence, FileDTO is not mandatory. \n\nCode snippet from the link provided by reachmymind:\n            var createKbDto = new CreateKbDTO\n            {\n                Name = \"QnA Maker FAQ from c# quickstart\",\n                QnaList = new List&lt;QnADTO&gt; { qna1 },\n                //Files = new List&lt;FileDTO&gt; { file1 },\n                Urls = urls\n            };"
      },
      {
        "date": "2023-02-28T13:33:00.000Z",
        "voteCount": 1,
        "content": "DTO is data transfer object. You can use CreateKbDTO to create a knowledge base data transfer object that contains URLs and then call the client.Knowledgebase.CreateAsync method to create a knowledge base."
      },
      {
        "date": "2024-06-22T00:29:00.000Z",
        "voteCount": 1,
        "content": "I say this answer is B and D."
      },
      {
        "date": "2024-06-12T08:25:00.000Z",
        "voteCount": 1,
        "content": "BD is answer."
      },
      {
        "date": "2024-05-24T08:15:00.000Z",
        "voteCount": 1,
        "content": "client.Knowledgebase.CreateAsync and CreateKbDTO."
      },
      {
        "date": "2024-02-16T16:02:00.000Z",
        "voteCount": 2,
        "content": "Create a CreateKbDTO object: First, you need to create a CreateKbDTO object, which contains the necessary information for creating a knowledge base, such as an array of URLs and the name of the knowledge base.\n\nCall the client.Knowledgebase.CreateAsync method: Then, use the Knowledgebase.CreateAsync method of the QnAMakerClient object, passing in the previously created CreateKbDTO object, to asynchronously create the knowledge base."
      },
      {
        "date": "2023-11-04T07:59:00.000Z",
        "voteCount": 2,
        "content": "https://learn.microsoft.com/en-us/azure/ai-services/qnamaker/quickstarts/quickstart-sdk?tabs=v1%2Cversion-1&amp;pivots=programming-language-csharp"
      },
      {
        "date": "2023-10-21T11:41:00.000Z",
        "voteCount": 1,
        "content": "It should be BD\n\nCreateKbDTO holds list of FileDto, QnADto. In given question, knowledge base accepts URLs which is one of the properties of FileDto. Hence, FileDtos will be created for each returned file URL from WebJob which can be used to create and hold within CreateKbDTO\n\nhttps://azuresdkdocs.blob.core.windows.net/$web/dotnet/Microsoft.Azure.CognitiveServices.Knowledge.QnAMaker/3.0.0-preview.1/api/Microsoft.Azure.CognitiveServices.Knowledge.QnAMaker.Models/Microsoft.Azure.CognitiveServices.Knowledge.QnAMaker.Models.CreateKbDTO.html"
      },
      {
        "date": "2023-10-18T05:49:00.000Z",
        "voteCount": 1,
        "content": "The client creates a knowledgebase from a CreateKbDTO  object using the CreateAsync method.  This object contains a list of FileDTOs and/or a list of QnADTOs.  In this scenario we don't know which to use, but we definitely need the CreateAsync and the CreateKbDTO object."
      },
      {
        "date": "2023-10-10T21:24:00.000Z",
        "voteCount": 3,
        "content": "You can not even create QnA Maker resource any more. Just read though the code, memorize the answers, and then move on."
      },
      {
        "date": "2024-09-06T06:40:00.000Z",
        "voteCount": 1,
        "content": "Isn't it sad that we have to do this with our time? Why do people buy software from Microsoft"
      },
      {
        "date": "2023-06-16T08:00:00.000Z",
        "voteCount": 1,
        "content": "ANSWER : B &amp; D\n\nThe options A and C are not necessary for creating knowledge bases using the QnAMakerClient object. They mention creating a list of FileDTO and QnADTO objects, which could potentially be used for populating the knowledge base with data, but they are not directly related to the process of creating the knowledge base itself."
      },
      {
        "date": "2023-05-22T07:02:00.000Z",
        "voteCount": 1,
        "content": "B. Call the client.Knowledgebase.CreateAsync method.\nD. Create a CreateKbDTO object.\n\nTo create a knowledge base using the QnAMakerClient, you would need to create a CreateKbDTO object that contains the details of the knowledge base to be created. This object would include information such as the name of the knowledge base and the URLs of the documents to be included in the knowledge base.\n\nAfter creating the CreateKbDTO object, you would then call the client.Knowledgebase.CreateAsync method, passing in the CreateKbDTO object as a parameter. This method would create the knowledge base and return a response that includes the ID of the newly created knowledge base."
      },
      {
        "date": "2022-12-11T11:04:00.000Z",
        "voteCount": 1,
        "content": "B &amp; D is the correct answers."
      },
      {
        "date": "2022-09-24T05:19:00.000Z",
        "voteCount": 1,
        "content": "It should be BD."
      },
      {
        "date": "2022-07-24T07:50:00.000Z",
        "voteCount": 2,
        "content": "I agree with Eltooth &amp; czmiel\n\ncode from MS: \nvar createOp = await client.Knowledgebase.CreateAsync(createKbDto);\n\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/qnamaker/quickstarts/quickstart-sdk?tabs=v1%2Cversion-1&amp;pivots=programming-language-csharp#create-a-knowledge-base"
      },
      {
        "date": "2022-07-18T10:05:00.000Z",
        "voteCount": 1,
        "content": "B and D are correct answers. \n\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/qnamaker/quickstarts/quickstart-sdk?tabs=v1%2Cversion-1&amp;pivots=programming-language-csharp#create-a-knowledge-base"
      },
      {
        "date": "2021-10-20T07:53:00.000Z",
        "voteCount": 1,
        "content": "should  be  bcd options based on\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/qnamaker/quickstarts/quickstart-sdk?tabs=v1%2Cversion-1&amp;pivots=programming-language-csharp#create-a-knowledge-base"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 9,
    "url": "https://www.examtopics.com/discussions/microsoft/view/60311-exam-ai-102-topic-3-question-9-discussion/",
    "body": "HOTSPOT -<br>You are developing an application that includes language translation.<br>The application will translate text retrieved by using a function named getTextToBeTranslated. The text can be in one of many languages. The content of the text must remain within the Americas Azure geography.<br>You need to develop code to translate the text to a single language.<br>How should you complete the code? To answer, select the appropriate options in the answer area.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04271/0013700001.jpg\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04271/0013800001.jpg\" class=\"in-exam-image\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2022-01-19T08:42:00.000Z",
        "voteCount": 26,
        "content": "Wrong , correct answer is both last option. \napi-nam.cognitive.microsofttranslator.com\n '?to=en'"
      },
      {
        "date": "2023-09-11T23:13:00.000Z",
        "voteCount": 12,
        "content": "Box 1: api-nam/translate : https://docs.microsoft.com/en-us/azure/cognitive-services/translator/reference/v3-0-reference#base-urls\nBox 2: \"?to=en\";"
      },
      {
        "date": "2024-09-19T20:17:00.000Z",
        "voteCount": 1,
        "content": "var endpoint = \"https://api-nam.cognitive.microsofttranslator.com/translate\";\nvar apiKey = \"FF956C68B83821838691ABD200A4C606\";\nvar text = getTextToBeTranslated();\nvar body = '[{\"Text\":\"' + text + '\"}]';\nvar client = new HttpClient();\nclient.DefaultRequestHeaders.Add(\"Ocp-Apim-Subscription-Key\", apiKey);\nvar uri = endpoint + \"?to=en\";\nHttpResponseMessage response;\nvar content = new StringContent(body, Encoding.UTF8, \"application/json\");\nresponse = await client.PutAsync(uri, content);"
      },
      {
        "date": "2024-05-24T08:14:00.000Z",
        "voteCount": 2,
        "content": "api-nam/translate\nto=en"
      },
      {
        "date": "2024-05-24T03:37:00.000Z",
        "voteCount": 1,
        "content": "on exam, /translate and to=en"
      },
      {
        "date": "2024-03-26T04:55:00.000Z",
        "voteCount": 1,
        "content": "Final Answer\n1. /translate\n2. to=en"
      },
      {
        "date": "2024-02-10T04:40:00.000Z",
        "voteCount": 7,
        "content": "insane way to ask a question"
      },
      {
        "date": "2024-07-02T19:18:00.000Z",
        "voteCount": 1,
        "content": "Hhahhahha"
      },
      {
        "date": "2023-10-18T05:52:00.000Z",
        "voteCount": 2,
        "content": "api-nam....../translate\n?to=en"
      },
      {
        "date": "2023-07-01T09:52:00.000Z",
        "voteCount": 7,
        "content": "1. api-nam.cognitive.microsofttranslator.com\n2. ?to=en'\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/Translator/reference/v3-0-reference#base-urls\nRequests to Translator are, in most cases, handled by the datacenter that is closest to where the request originated. If there's a datacenter failure when using the global endpoint, the request may be routed outside of the geography.\n\nTo force the request to be handled within a specific geography, use the desired geographical endpoint. All requests are processed among the datacenters within the geography.\n- United States\napi-nam.cognitive.microsofttranslator.com\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/translator/reference/rest-api-guide\n- translate\nTranslate specified source language text into the target language text."
      },
      {
        "date": "2023-03-15T06:00:00.000Z",
        "voteCount": 1,
        "content": "var endpoint = \"https://api-nam.cognitive.microsofttranslator.com/translate\";\nvar apiKey = \"FF956C68883821838691A8D200A4C606\";\nvar text = getTextToBeTranslated();\nvar body = \"[{\\\"Text\\\":\\\"\" + text + \"\\\"}]\";\nvar client = new HttpClient();\nclient.DefaultRequestHeaders.Add(\"Ocp-Apim-Subscription-Key\", apiKey);\nvar uri = endpoint + \"?to=en\";\nvar content = new StringContent(body, Encoding.UTF8, \"application/json\");\nHttpResponseMessage response = await client.PutAsync(uri, content);\nstring translatedText = await response.Content.ReadAsStringAsync();"
      },
      {
        "date": "2022-07-18T10:33:00.000Z",
        "voteCount": 1,
        "content": "Box 1: api-nam/translate : https://docs.microsoft.com/en-us/azure/cognitive-services/translator/reference/v3-0-reference#base-urls\n\nBox 2: \"?to=en\";"
      },
      {
        "date": "2022-06-07T05:30:00.000Z",
        "voteCount": 2,
        "content": "Was on exam 7 Jun 2022"
      },
      {
        "date": "2021-11-27T18:30:00.000Z",
        "voteCount": 4,
        "content": "Was on exam 27/11/2021"
      },
      {
        "date": "2021-10-27T04:14:00.000Z",
        "voteCount": 3,
        "content": "SuperPetey is correct.\n\nref:\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/translator/reference/v3-0-reference#base-urls"
      },
      {
        "date": "2021-08-22T20:51:00.000Z",
        "voteCount": 7,
        "content": "wrong for first choice\uff0cshould be   API.cognitive\u2026\u2026./tanslate"
      },
      {
        "date": "2021-08-24T02:07:00.000Z",
        "voteCount": 42,
        "content": "incorrect - the question specifies it should be routed to the Americas region. The correct answer for box 1 is api-nam.cognitive.microsofttranslator.com/translate according to doc @\n\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/translator/reference/v3-0-reference#base-urls\n\nI agree second drop-down is '?to=en'"
      },
      {
        "date": "2023-11-04T08:02:00.000Z",
        "voteCount": 1,
        "content": "agree with you. thanks for the provided reference"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 10,
    "url": "https://www.examtopics.com/discussions/microsoft/view/75998-exam-ai-102-topic-3-question-10-discussion/",
    "body": "You are building a conversational language understanding model.<br>You need to enable active learning.<br>What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAdd show-all-intents=true to the prediction endpoint query.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEnable speech priming.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAdd log=true to the prediction endpoint query.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEnable sentiment analysis."
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 21,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2022-07-18T10:41:00.000Z",
        "voteCount": 12,
        "content": "C is the correct answer.\n\n\"To enable active learning, you must log user queries. This is accomplished by calling the endpoint query with the log=true query string parameter and value.\"\n\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/LUIS/how-to/improve-application#log-user-queries-to-enable-active-learning"
      },
      {
        "date": "2024-09-06T08:06:00.000Z",
        "voteCount": 1,
        "content": "Really?!! log=true is that how active learning is enabled? That's a very bad choice and asking that in a certification exam shows courage LOL"
      },
      {
        "date": "2024-06-12T08:24:00.000Z",
        "voteCount": 1,
        "content": "C is answer."
      },
      {
        "date": "2024-05-29T06:45:00.000Z",
        "voteCount": 1,
        "content": "C is right answer. log=true"
      },
      {
        "date": "2024-05-24T08:04:00.000Z",
        "voteCount": 1,
        "content": "Add  log=true"
      },
      {
        "date": "2024-02-21T22:19:00.000Z",
        "voteCount": 1,
        "content": "C is correct"
      },
      {
        "date": "2023-11-04T08:06:00.000Z",
        "voteCount": 1,
        "content": "correct answer and reference\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/luis/luis-how-to-review-endpoint-utterances#log-user-queries-to-enable-active-learning"
      },
      {
        "date": "2023-06-29T03:09:00.000Z",
        "voteCount": 4,
        "content": "C is the answer.\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/LUIS/how-to/improve-application#log-user-queries-to-enable-active-learning\nTo enable active learning, you must log user queries. This is accomplished by calling the endpoint query with the log=true query string parameter and value."
      },
      {
        "date": "2023-07-08T07:04:00.000Z",
        "voteCount": 4,
        "content": "Gotten this in Jul 2023 exam."
      },
      {
        "date": "2023-03-13T04:39:00.000Z",
        "voteCount": 1,
        "content": "Log user queries to enable active learning\nTo enable active learning, you must log user queries. This is accomplished by calling the endpoint query with the log=true query string parameter and value.\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/LUIS/how-to/improve-application"
      },
      {
        "date": "2023-02-21T03:31:00.000Z",
        "voteCount": 1,
        "content": "To enable active learning in a conversational language understanding model, you should add show-all-intents=true to the prediction endpoint query. This will allow you to see all the intents that the model is predicting, including the None intent.[0] This information can be used to improve the model by adding more training data for the None intent or other intents that are not being predicted accurately."
      },
      {
        "date": "2022-05-21T03:22:00.000Z",
        "voteCount": 1,
        "content": "Correct.\n\nReference: https://docs.microsoft.com/en-us/azure/cognitive-services/LUIS/how-to/improve-application"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 11,
    "url": "https://www.examtopics.com/discussions/microsoft/view/80189-exam-ai-102-topic-3-question-11-discussion/",
    "body": "HOTSPOT -<br>You run the following command.<br><img src=\"/assets/media/exam-media/04271/0013900001.png\" class=\"in-exam-image\"><br>For each of the following statements, select Yes if the statement is true. Otherwise, select No.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04271/0014000001.jpg\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04271/0014000002.jpg\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: Yes -<br>http://localhost:5000/status : Also requested with GET, this verifies if the api-key used to start the container is valid without causing an endpoint query.<br><br>Box 2: Yes -<br>The command saves container and LUIS logs to output mount at C:\\output, located on container host<br><br>Box 3: Yes -<br>http://localhost:5000/swagger    : The container provides a full set of documentation for the endpoints and a Try it out feature. With this feature, you can enter your settings into a web-based HTML form and make the query without having to write any code. After the query returns, an example CURL command is provided to demonstrate the HTTP headers and body format that's required.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/cognitive-services/luis/luis-container-howto",
    "votes": [],
    "comments": [
      {
        "date": "2022-09-04T21:15:00.000Z",
        "voteCount": 30,
        "content": "Yes\nNo\nYes\n\nLog location is not mounted. The ET answer relates to an example provided on the given website which DOES mount a log location."
      },
      {
        "date": "2023-07-01T09:48:00.000Z",
        "voteCount": 11,
        "content": "YNY is the answer.\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/language-service/text-analytics-for-health/how-to/use-containers?tabs=language#validate-that-a-container-is-running\n- http://localhost:5000/status\nAlso requested with GET, this URL verifies if the api-key used to start the container is valid without causing an endpoint query. This request can be used for Kubernetes liveness and readiness probes.\n- http://localhost:5000/swagger\nThe container provides a full set of documentation for the endpoints and a Try it out feature. With this feature, you can enter your settings into a web-based HTML form and make the query without having to write any code. After the query returns, an example CURL command is provided to demonstrate the HTTP headers and body format that's required."
      },
      {
        "date": "2024-07-15T12:02:00.000Z",
        "voteCount": 1,
        "content": "YNY is the answer."
      },
      {
        "date": "2024-05-24T07:55:00.000Z",
        "voteCount": 1,
        "content": "Yes No Yes"
      },
      {
        "date": "2024-05-24T03:37:00.000Z",
        "voteCount": 1,
        "content": "on exam, YNY"
      },
      {
        "date": "2024-03-26T05:01:00.000Z",
        "voteCount": 2,
        "content": "Fintal Answer:\nYes\nNo \nYes"
      },
      {
        "date": "2024-01-26T18:28:00.000Z",
        "voteCount": 4,
        "content": "Going to http://localhost:5000/status will query the Azure endpoint to verify whether the API key used to start the container is valid.\n\nYes. Typically, Azure Cognitive Services containers provide a /status endpoint that can be used to check the status of the service, including the validity of the API key. Since the service is mapped to localhost:5000, accessing this URL should provide the status of the containerized service, including the API key's validity.\n\nThe container logging provider will write log data.\n\nNo (Assuming). This statement is somewhat ambiguous and depends on the configuration of the Docker container and the Azure Cognitive Services container. \n\nGoing to http://localhost:5000/swagger will provide the details to access the documentation for the available endpoints.\n\nYes. It is a common practice for web services and APIs, including those provided by Azure Cognitive Services, to offer a Swagger UI at a /swagger endpoint."
      },
      {
        "date": "2023-12-20T16:27:00.000Z",
        "voteCount": 4,
        "content": "A modified version of this was in the exam today."
      },
      {
        "date": "2023-11-04T08:16:00.000Z",
        "voteCount": 4,
        "content": "No --&gt; Also requested with GET, this URL verifies if the api-key used to start the container is valid without causing an endpoint query. https://learn.microsoft.com/en-us/azure/ai-services/language-service/text-analytics-for-health/how-to/use-containers?tabs=language#validate-that-a-container-is-running\n\nNo -- there isn't any Log location mounted (same link as above)\n\nYes --&gt; correct, swagger show a full set of documentation for the endpoints\n\nYes."
      },
      {
        "date": "2023-11-12T21:48:00.000Z",
        "voteCount": 2,
        "content": "sorry the last yes is a typo"
      },
      {
        "date": "2023-09-01T05:36:00.000Z",
        "voteCount": 3,
        "content": "No (\"without causing an endpoint query\"), No, Yes"
      },
      {
        "date": "2023-09-11T23:27:00.000Z",
        "voteCount": 3,
        "content": "Agree with you: \n- http://localhost:5000/status\n\"Also requested with GET, this URL verifies if the api-key used to start the container is valid WITHOUT CAUSING AN ENDPOINT QUERY.\" (According to documentation)"
      },
      {
        "date": "2023-05-31T06:08:00.000Z",
        "voteCount": 4,
        "content": "1 and 3, is true: https://learn.microsoft.com/es-es/azure/cognitive-services/language-service/sentiment-opinion-mining/how-to/use-containers#validate-that-a-container-is-running\n\n2, i think, is yes... (by docker settings)"
      },
      {
        "date": "2023-04-19T18:16:00.000Z",
        "voteCount": 1,
        "content": "I think the first one is YES\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/language-service/text-analytics-for-health/how-to/use-containers?tabs=language#validate-that-a-container-is-running"
      },
      {
        "date": "2023-04-07T08:36:00.000Z",
        "voteCount": 7,
        "content": "Documentation says it will NOT cause an endpoint query, so I think the first one should be NO"
      },
      {
        "date": "2023-09-11T23:27:00.000Z",
        "voteCount": 1,
        "content": "Correct!"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 12,
    "url": "https://www.examtopics.com/discussions/microsoft/view/54402-exam-ai-102-topic-3-question-12-discussion/",
    "body": "You are building a Language Understanding model for an e-commerce platform.<br>You need to construct an entity to capture billing addresses.<br>Which entity type should you use for the billing address?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tmachine learned\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRegex",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tgeographyV2",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tPattern.any",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tlist"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 30,
        "isMostVoted": true
      },
      {
        "answer": "B",
        "count": 5,
        "isMostVoted": false
      },
      {
        "answer": "C",
        "count": 2,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2021-06-08T06:04:00.000Z",
        "voteCount": 38,
        "content": "My guess is A.\n\nAn ML entity can be composed of smaller sub-entities, each of which can have its own properties. For example, Address could have the following structure:\n\nAddress: 4567 Main Street, NY, 98052, USA\nBuilding Number: 4567\nStreet Name: Main Street\nState: NY\nZip Code: 98052\nCountry: USA"
      },
      {
        "date": "2024-07-04T15:17:00.000Z",
        "voteCount": 1,
        "content": "I agree it is clear that is ML entity, the sample above is on the URL\nhttps://learn.microsoft.com/en-us/azure/ai-services/LUIS/concepts/entities"
      },
      {
        "date": "2021-06-13T10:25:00.000Z",
        "voteCount": 10,
        "content": "ML. Answer is A"
      },
      {
        "date": "2021-06-30T08:32:00.000Z",
        "voteCount": 10,
        "content": "Right! (the correct response is A, Machine Learned)\nSee \nhttps://docs.microsoft.com/en-us/azure/cognitive-services/luis/luis-concept-entity-types\nIt is a Machine Learned Entity (check ML Entity with Structure in the link, as it is an Address example\u2026 )"
      },
      {
        "date": "2024-09-13T14:30:00.000Z",
        "voteCount": 1,
        "content": "Correct answer is D as per ChatGPT. Here is the response, \"For capturing billing addresses in a Language Understanding model, the best choice would be Pattern.any (Option D). This is because billing addresses can vary greatly in format and content, and using Pattern.any allows for the flexibility needed to capture this variability effectively.\""
      },
      {
        "date": "2024-07-14T11:36:00.000Z",
        "voteCount": 1,
        "content": "Selected Answer: A"
      },
      {
        "date": "2024-06-22T00:28:00.000Z",
        "voteCount": 1,
        "content": "I say this answer is A."
      },
      {
        "date": "2024-06-14T03:16:00.000Z",
        "voteCount": 1,
        "content": "Copilot says Pattern.any\n\nThe Pattern.any entity type is designed to capture free-form text, which makes it suitable for capturing billing addresses that can come in various formats. It uses pattern matching to predict and extract data."
      },
      {
        "date": "2024-06-12T08:24:00.000Z",
        "voteCount": 1,
        "content": "I know you don't know what I'm talking about, but if you think as Crossroads leads you, the answer is A."
      },
      {
        "date": "2024-05-29T07:00:00.000Z",
        "voteCount": 2,
        "content": "ML Entity with Structure\nAn ML entity can be composed of smaller sub-entities, each of which can have its own properties. For example, an Address entity could have the following structure:\n\nAddress: 4567 Main Street, NY, 98052, USA\nBuilding Number: 4567\nStreet Name: Main Street\nState: NY\nZip Code: 98052\nCountry: USA"
      },
      {
        "date": "2024-05-24T08:23:00.000Z",
        "voteCount": 1,
        "content": "A is right answer."
      },
      {
        "date": "2024-01-26T19:43:00.000Z",
        "voteCount": 1,
        "content": "Given these options, A. Machine Learned is the most appropriate choice for capturing billing addresses. Billing addresses are complex entities with a lot of variability in their format and structure. A machine-learned entity is capable of understanding and extracting such complex information from natural language inputs, which makes it suitable for this purpose. It can learn from examples and capture the billing address as an entity based on the context in which it appears, which is essential for handling the wide range of ways in which addresses can be presented."
      },
      {
        "date": "2023-11-04T08:18:00.000Z",
        "voteCount": 1,
        "content": "duplicated question\nhttps://learn.microsoft.com/en-us/azure/ai-services/LUIS/concepts/entities"
      },
      {
        "date": "2023-10-05T08:03:00.000Z",
        "voteCount": 1,
        "content": "ML Entity with Structure\nAn ML entity can be composed of smaller sub-entities, each of which can have its own properties. For example, an Address entity could have the following structure:\n\nAddress: 4567 Main Street, NY, 98052, USA\nBuilding Number: 4567\nStreet Name: Main Street\nState: NY\nZip Code: 98052\nCountry: USA"
      },
      {
        "date": "2023-09-11T23:33:00.000Z",
        "voteCount": 1,
        "content": "Correct answer is A"
      },
      {
        "date": "2023-06-29T03:11:00.000Z",
        "voteCount": 1,
        "content": "Same as Question 7.\nhttps://www.examtopics.com/discussions/microsoft/view/60239-exam-ai-102-topic-3-question-7-discussion"
      },
      {
        "date": "2023-06-29T03:07:00.000Z",
        "voteCount": 1,
        "content": "A is the answer.\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/LUIS/concepts/entities#machine-learned-ml-entity\nMachine learned entity uses context to extract entities based on labeled examples. It is the preferred entity for building LUIS applications. It relies on machine-learning algorithms and requires labeling to be tailored to your application successfully. Use an ML entity to identify data that isn\u2019t always well formatted but have the same meaning.\n\nAn ML entity can be composed of smaller sub-entities, each of which can have its own properties. For example, an Address entity could have the following structure:\n\nAddress: 4567 Main Street, NY, 98052, USA\nBuilding Number: 4567\nStreet Name: Main Street\nState: NY\nZip Code: 98052\nCountry: USA"
      },
      {
        "date": "2023-06-14T07:53:00.000Z",
        "voteCount": 2,
        "content": "C. geographyV2\nThe geographyV2 prebuilt entity in Language Understanding (LUIS) is designed to recognize and label entities that are geographical locations, such as city, state, or country. This would be suitable for capturing billing addresses in an e-commerce platform."
      },
      {
        "date": "2023-09-01T05:54:00.000Z",
        "voteCount": 2,
        "content": "https://learn.microsoft.com/en-us/azure/ai-services/luis/luis-reference-prebuilt-geographyv2?tabs=V3\n\nThe prebuilt geographyV2 entity detects places. \nThe geographical locations have subtypes:\npoi\tpoint of interest\ncity\tname of city\ncountryRegion\tname of country or region\ncontinent\tname of continent\nstate\tname of state or province\n\nI guess you could charge a bill for the Statue of Liberty on Ellis Island as a (fixed) \u201cpoi\u201d, but a more generalized rule would rather look for an Address entity with sub-entities (variable) as an ML Entity with Structure type"
      },
      {
        "date": "2023-01-17T12:35:00.000Z",
        "voteCount": 4,
        "content": "Wherever it is address it is ML"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 13,
    "url": "https://www.examtopics.com/discussions/microsoft/view/77612-exam-ai-102-topic-3-question-13-discussion/",
    "body": "You need to upload speech samples to a Speech Studio project for use in training.<br>How should you upload the samples?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCombine the speech samples into a single audio file in the .wma format and upload the file.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUpload a .zip file that contains a collection of audio files in the .wav format and a corresponding text transcript file.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUpload individual audio files in the FLAC format and manually upload a corresponding transcript in Microsoft Word format.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUpload individual audio files in the .wma format."
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 20,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-01-26T19:46:00.000Z",
        "voteCount": 8,
        "content": ", the best option is B. Upload a .zip file that contains a collection of audio files in the .wav format and a corresponding text transcript file. This method provides a balance of audio quality (with .wav files) and organization (having audio and transcripts together), which is essential for efficient and accurate training of speech recognition models."
      },
      {
        "date": "2023-12-20T16:28:00.000Z",
        "voteCount": 6,
        "content": "A modified version of this was in the exam today."
      },
      {
        "date": "2024-06-12T08:23:00.000Z",
        "voteCount": 1,
        "content": "B is answer."
      },
      {
        "date": "2024-06-04T21:09:00.000Z",
        "voteCount": 1,
        "content": "For me and ChatGPT: B"
      },
      {
        "date": "2024-05-24T08:01:00.000Z",
        "voteCount": 1,
        "content": "wav zip"
      },
      {
        "date": "2024-05-24T03:38:00.000Z",
        "voteCount": 1,
        "content": "B is correct"
      },
      {
        "date": "2023-12-11T22:13:00.000Z",
        "voteCount": 2,
        "content": "Answer is correct"
      },
      {
        "date": "2023-11-04T08:22:00.000Z",
        "voteCount": 2,
        "content": "Answer is correct:\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/speech-service/how-to-custom-voice-training-data#types-of-training-data"
      },
      {
        "date": "2023-10-04T03:01:00.000Z",
        "voteCount": 3,
        "content": "B is the Answer. Got this in Oct2023 exam"
      },
      {
        "date": "2023-10-05T23:53:00.000Z",
        "voteCount": 3,
        "content": "just want to confirm, theres no labs included right?"
      },
      {
        "date": "2023-06-29T03:14:00.000Z",
        "voteCount": 1,
        "content": "Same as Question 2.\nhttps://www.examtopics.com/discussions/microsoft/view/55251-exam-ai-102-topic-3-question-2-discussion"
      },
      {
        "date": "2023-06-29T03:01:00.000Z",
        "voteCount": 3,
        "content": "B is the answer.\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/speech-service/how-to-custom-voice-training-data#types-of-training-data\nA voice training dataset includes audio recordings, and a text file with the associated transcriptions. Each audio file should contain a single utterance (a single sentence or a single turn for a dialog system), and be less than 15 seconds long.\n\n- Individual utterances + matching transcript\nA collection (.zip) of audio files (.wav) as individual utterances. Each audio file should be 15 seconds or less in length, paired with a formatted transcript (.txt)."
      },
      {
        "date": "2023-11-04T08:22:00.000Z",
        "voteCount": 1,
        "content": "thanks for explanation"
      },
      {
        "date": "2022-07-18T11:10:00.000Z",
        "voteCount": 1,
        "content": "B is correct answer.\n\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/speech-service/how-to-custom-speech-test-and-train"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 14,
    "url": "https://www.examtopics.com/discussions/microsoft/view/77617-exam-ai-102-topic-3-question-14-discussion/",
    "body": "You are developing a method for an application that uses the Translator API.<br>The method will receive the content of a webpage, and then translate the content into Greek (el). The result will also contain a transliteration that uses the Roman alphabet.<br>You need to create the URI for the call to the Translator API.<br>You have the following URI.<br>https://api.cognitive.microsofttranslator.com/translate?api-version=3.0<br>Which three additional query parameters should you include in the URI? Each correct answer presents part of the solution.<br>NOTE: Each correct selection is worth one point.<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ttoScript=Cyrl",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tfrom=el",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ttextType=html\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tto=el\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ttextType=plain",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"F\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tF.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ttoScript=Latn\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "CDF",
    "answerDescription": "",
    "votes": [
      {
        "answer": "CDF",
        "count": 20,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-06-27T23:38:00.000Z",
        "voteCount": 6,
        "content": "THIS WAS ON EXAM 28/06"
      },
      {
        "date": "2022-07-18T22:59:00.000Z",
        "voteCount": 5,
        "content": "C, D and F are correct answers. \ntextType=html\nto=el\ntoScript=Latn\n\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/translator/reference/v3-0-translate#translate-with-transliteration"
      },
      {
        "date": "2024-09-06T08:21:00.000Z",
        "voteCount": 2,
        "content": "wow, microsoft wants me to know webpage is html, roman=latn. \nAlthough I never understood why microsoft expects people to remember the .net class names or method names or api parameter names. But this knowledge is beyond anything. I'm guessing the people creating the questions are not from this area. They just look at the documentation and think what can I ask so that the people cannot remember what is the right answer."
      },
      {
        "date": "2024-06-12T08:22:00.000Z",
        "voteCount": 1,
        "content": "I'll bump it up, so CDF is the answer."
      },
      {
        "date": "2024-05-24T08:01:00.000Z",
        "voteCount": 1,
        "content": "textType=html\nto=el\ntoScript=Latn"
      },
      {
        "date": "2024-05-24T03:39:00.000Z",
        "voteCount": 1,
        "content": "correct answer"
      },
      {
        "date": "2024-01-26T19:51:00.000Z",
        "voteCount": 4,
        "content": "https://api.cognitive.microsofttranslator.com/translate?api-version=3.0&amp;textType=html&amp;to=el&amp;toScript=Latn"
      },
      {
        "date": "2023-11-04T08:26:00.000Z",
        "voteCount": 3,
        "content": "correct answer and explanation"
      },
      {
        "date": "2023-06-29T03:16:00.000Z",
        "voteCount": 2,
        "content": "Same as Question 3.\nhttps://www.examtopics.com/discussions/microsoft/view/56391-exam-ai-102-topic-3-question-3-discussion"
      },
      {
        "date": "2023-06-28T22:38:00.000Z",
        "voteCount": 2,
        "content": "CDF is the answer.\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/translator/reference/v3-0-translate\n- to\nSpecifies the language of the output text. The target language must be one of the supported languages included in the translation scope. For example, use to=de to translate to German.\nIt's possible to translate to multiple languages simultaneously by repeating the parameter in the query string. For example, use to=de&amp;to=it to translate to German and Italian.\n- textType\nDefines whether the text being translated is plain text or HTML text. Any HTML needs to be a well-formed, complete element. Possible values are: plain (default) or html."
      },
      {
        "date": "2022-11-25T01:18:00.000Z",
        "voteCount": 1,
        "content": "Correct!"
      },
      {
        "date": "2022-07-24T07:55:00.000Z",
        "voteCount": 2,
        "content": "Agreed"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 15,
    "url": "https://www.examtopics.com/discussions/microsoft/view/75236-exam-ai-102-topic-3-question-15-discussion/",
    "body": "You have a chatbot that was built by using the Microsoft Bot Framework.<br>You need to debug the chatbot endpoint remotely.<br>Which two tools should you install on a local computer? Each correct answer presents part of the solution.<br>NOTE: Each correct selection is worth one point.<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tFiddler",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tBot Framework Composer",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tBot Framework Emulator\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tBot Framework CLI",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tngrok\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"F\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tF.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tnginx"
    ],
    "answer": "CE",
    "answerDescription": "",
    "votes": [
      {
        "answer": "CE",
        "count": 17,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-01-26T19:53:00.000Z",
        "voteCount": 7,
        "content": "C. Bot Framework Emulator: This is an essential tool for debugging Microsoft Bot Framework bots. It allows you to test and debug your bots on your local machine by emulating the Bot Framework's channels and activities. It can be very helpful in a local development environment but is less suited for remote debugging.\nE. ngrok: ngrok is a tool that creates a secure tunnel to your localhost. This is very useful for remote debugging because it allows you to expose your local development server to the internet, which is necessary for testing and debugging interactions with services like the Microsoft Bot Framework."
      },
      {
        "date": "2024-08-06T15:58:00.000Z",
        "voteCount": 1,
        "content": "Bot framework is no longer part of the exam"
      },
      {
        "date": "2024-06-12T08:22:00.000Z",
        "voteCount": 1,
        "content": "CE is answer."
      },
      {
        "date": "2024-05-29T06:46:00.000Z",
        "voteCount": 1,
        "content": "C. Bot Framework Emulator\nE. ngrok"
      },
      {
        "date": "2024-05-24T08:08:00.000Z",
        "voteCount": 1,
        "content": "Bot Framework Emulator takedajuku ngrok are right answer."
      },
      {
        "date": "2023-11-04T08:34:00.000Z",
        "voteCount": 2,
        "content": "correct answers\n\nhttps://learn.microsoft.com/en-us/azure/bot-service/bot-service-debug-channel-ngrok?view=azure-bot-service-4.0"
      },
      {
        "date": "2023-06-29T03:13:00.000Z",
        "voteCount": 3,
        "content": "Same as Question 4.\nhttps://www.examtopics.com/discussions/microsoft/view/56390-exam-ai-102-topic-3-question-4-discussion"
      },
      {
        "date": "2023-06-28T22:30:00.000Z",
        "voteCount": 1,
        "content": "CE is the answer.\n\nhttps://learn.microsoft.com/en-us/azure/bot-service/bot-service-debug-emulator?view=azure-bot-service-4.0&amp;tabs=csharp\nBot Framework Emulator is a desktop application that allows bot developers to test and debug bots, either locally or remotely. Using the Emulator, you can chat with your bot and inspect the messages that your bot sends and receives. The Emulator displays messages as they would appear in a web chat UI and logs JSON requests and responses as you exchange messages with your bot. Before you deploy your bot to the cloud, run it locally and test it using the Emulator. You can test your bot using the Emulator even if you haven't yet created it with Azure Bot Service or configured it to run on any channels."
      },
      {
        "date": "2023-06-28T22:30:00.000Z",
        "voteCount": 1,
        "content": "https://learn.microsoft.com/en-us/azure/bot-service/bot-service-debug-channel-ngrok?view=azure-bot-service-4.0\nWhile your bot is in development, you can use an IDE and the Bot Framework Emulator to chat with your bot locally and inspect the messages your bot sends and receives. If your bot is in production, you can debug your bot from any channel using ngrok. The seamless connection of your bot to multiple channels is a key feature available in the Bot Framework."
      },
      {
        "date": "2022-07-18T23:00:00.000Z",
        "voteCount": 2,
        "content": "C and E are correct answers."
      },
      {
        "date": "2022-05-06T08:04:00.000Z",
        "voteCount": 2,
        "content": "Answer is correct.\nhttps://docs.microsoft.com/en-us/azure/bot-service/bot-service-debug-emulator?view=azure-bot-service-4.0&amp;tabs=csharp"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 16,
    "url": "https://www.examtopics.com/discussions/microsoft/view/77618-exam-ai-102-topic-3-question-16-discussion/",
    "body": "DRAG DROP -<br>You are building a retail chatbot that will use a QnA Maker service.<br>You upload an internal support document to train the model. The document contains the following question: \"What is your warranty period?\"<br>Users report that the chatbot returns the default QnA Maker answer when they ask the following question: \"How long is the warranty coverage?\"<br>The chatbot returns the correct answer when the users ask the following question: 'What is your warranty period?\"<br>Both questions should return the same answer.<br>You need to increase the accuracy of the chatbot responses.<br>Which three actions should you perform in sequence? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.<br>Select and Place:<br><img src=\"/assets/media/exam-media/04271/0014700001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04271/0014700002.png\" class=\"in-exam-image\">",
    "answerDescription": "Step 1: Add alternative phrasing to the question and answer (QnA) pair.<br>Add alternate questions to an existing QnA pair to improve the likelihood of a match to a user query.<br>Step 2: Retrain the model.<br>Periodically select Save and train after making edits to avoid losing changes.<br><br>Step 3: Republish the model -<br>Note: A knowledge base consists of question and answer (QnA) pairs. Each pair has one answer and a pair contains all the information associated with that answer.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/cognitive-services/qnamaker/how-to/edit-knowledge-base",
    "votes": [],
    "comments": [
      {
        "date": "2023-07-01T09:42:00.000Z",
        "voteCount": 23,
        "content": "1. Add alternative phrasing to the QnA pair.\n2. Retrain model.\n3. Republish model.\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/qnamaker/how-to/edit-knowledge-base#question-and-answer-pairs\nThe optional settings for a pair include:\n- Alternate forms of the question\nthis helps QnA Maker return the correct answer for a wider variety of question phrasings"
      },
      {
        "date": "2024-01-26T19:59:00.000Z",
        "voteCount": 5,
        "content": "1: Add alternate phrasings as follow-up prompts or as additional questions in the QnA pair:\n2: Train the QnA Maker model: \n3: Publish the updated QnA Maker model:"
      },
      {
        "date": "2024-07-15T12:03:00.000Z",
        "voteCount": 1,
        "content": "1. Add alternative phrasing to the QnA pair.\n2. Retrain model.\n3. Republish model."
      },
      {
        "date": "2024-05-24T07:59:00.000Z",
        "voteCount": 2,
        "content": "Add alternative QnA\nRetrain\nRepublish"
      },
      {
        "date": "2024-02-22T22:49:00.000Z",
        "voteCount": 1,
        "content": "correct answer"
      },
      {
        "date": "2023-12-20T16:29:00.000Z",
        "voteCount": 4,
        "content": "A modified version of this was in the exam today."
      },
      {
        "date": "2023-11-04T08:39:00.000Z",
        "voteCount": 2,
        "content": "correct answer and explanation"
      },
      {
        "date": "2023-07-01T09:54:00.000Z",
        "voteCount": 1,
        "content": "Same as Question 5.\nhttps://www.examtopics.com/discussions/microsoft/view/55309-exam-ai-102-topic-3-question-5-discussion"
      },
      {
        "date": "2022-07-23T16:08:00.000Z",
        "voteCount": 4,
        "content": "Correct"
      },
      {
        "date": "2022-07-18T23:10:00.000Z",
        "voteCount": 4,
        "content": "Answer looks correct. \n\nAdd alternative phrasing\nRetrain\nRepublish"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 17,
    "url": "https://www.examtopics.com/discussions/microsoft/view/54520-exam-ai-102-topic-3-question-18-discussion/",
    "body": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.<br>After you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.<br>You build a language model by using a Language Understanding service. The language model is used to search for information on a contact list by using an intent named FindContact.<br>A conversational expert provides you with the following list of phrases to use for training.<br>\u2711 Find contacts in London.<br>\u2711 Who do I know in Seattle?<br>\u2711 Search for contacts in Ukraine.<br>You need to implement the phrase list in Language Understanding.<br>Solution: You create a new intent for location.<br>Does this meet the goal?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tYes",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tNo\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 12,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-06-04T04:54:00.000Z",
        "voteCount": 33,
        "content": "This should be \"No\""
      },
      {
        "date": "2021-07-04T09:07:00.000Z",
        "voteCount": 7,
        "content": "I think the answer should be 'No' too. The intent is for FindContact, not location really."
      },
      {
        "date": "2021-09-16T03:40:00.000Z",
        "voteCount": 12,
        "content": "The answer should be NO.\nAn utterance having wo intents? This is illogical.\nThe model should have an Entity \"Location\"  that will help in finding the contacts.\n\nReference: https://docs.microsoft.com/en-us/azure/cognitive-services/luis/luis-concept-intent"
      },
      {
        "date": "2024-09-06T08:54:00.000Z",
        "voteCount": 1,
        "content": "And for the other question about whether patterns are enough: \nDo not expect to see improved entity prediction if you collapse multiple utterances into a single pattern. For simple entities to be utilized by your app, you need to add utterances or use list entities."
      },
      {
        "date": "2024-08-06T16:06:00.000Z",
        "voteCount": 1,
        "content": "Simply 'location' is an entity not an intent"
      },
      {
        "date": "2024-06-21T08:37:00.000Z",
        "voteCount": 1,
        "content": "I say B is correct! HipHop!"
      },
      {
        "date": "2024-06-15T08:02:00.000Z",
        "voteCount": 1,
        "content": "This issue is not working because everyone's opinion is 50-50. I don't know the correct answer, so I will be staring at MS Learn when this question comes up on the real exam.Examtopic should scrutinize and post the correct answer."
      },
      {
        "date": "2024-06-15T08:02:00.000Z",
        "voteCount": 1,
        "content": "This issue is not working because everyone's opinion is 50-50. I don't know the correct answer, so I will be staring at MS Learn when this question comes up on the real exam.Examtopic should scrutinize and post the correct answer."
      },
      {
        "date": "2024-01-26T20:47:00.000Z",
        "voteCount": 2,
        "content": "The ANSWER is NO \uff01\nInstead of creating a new intent for location, you should:\nAdd these phrases to the \"FindContact\" intent: This helps the model understand that these are different ways a user might express the intent to find contacts.\n\nUse Entities for Locations: In addition to training the intent with these phrases, you should use entities to capture the location information within the phrases. In LUIS, you can define an entity (like \"Location\") and then annotate locations in your training phrases. This way, the model learns to recognize and extract location details from user inputs.\n\nBy combining a well-trained \"FindContact\" intent with a location entity, your language model will be better equipped to understand and process user queries about finding contacts in specific locations."
      },
      {
        "date": "2023-11-04T08:43:00.000Z",
        "voteCount": 3,
        "content": "IMHO is NO, you don't need to create an intent for each location. The intent is always the same: FindContact"
      },
      {
        "date": "2023-06-24T03:00:00.000Z",
        "voteCount": 1,
        "content": "Location should be for entity not for Intent"
      },
      {
        "date": "2023-06-05T16:15:00.000Z",
        "voteCount": 1,
        "content": "Should be NO. An intent represents a task or action the user wants to perform. It is a purpose or goal expressed in a user's utterance. In this case, the Intent is to find the Contact. And it is already created.\n\nThe utterances specified have the same Intent which is to find/search for contacts. Hence they should be added to the list and an Entity should be created to capture location."
      },
      {
        "date": "2023-02-22T02:25:00.000Z",
        "voteCount": 3,
        "content": "Think its Yes, creating a new intent for location would meet the goal of implementing the phrase list in Language Understanding. You can add the phrases to the new intent and label the location entity in each phrase. This will help the language model understand the user's intent to search for contacts in a specific location."
      },
      {
        "date": "2023-01-17T12:51:00.000Z",
        "voteCount": 1,
        "content": "This is \"NO\""
      },
      {
        "date": "2022-07-22T05:07:00.000Z",
        "voteCount": 2,
        "content": "B is correct answer. \n\nNeeds Entity/type for location instead."
      },
      {
        "date": "2022-05-05T12:15:00.000Z",
        "voteCount": 1,
        "content": "Definitely no."
      },
      {
        "date": "2022-01-11T10:50:00.000Z",
        "voteCount": 2,
        "content": "This should be No."
      },
      {
        "date": "2022-01-05T15:10:00.000Z",
        "voteCount": 2,
        "content": "intent (means what task we need to perform) - So here task is same i.e. Find Contacts. So No need to add an new intent.\n\nBut need to add type/entity : location"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 18,
    "url": "https://www.examtopics.com/discussions/microsoft/view/74742-exam-ai-102-topic-3-question-19-discussion/",
    "body": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.<br>After you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.<br>You build a language model by using a Language Understanding service. The language model is used to search for information on a contact list by using an intent named FindContact.<br>A conversational expert provides you with the following list of phrases to use for training.<br>\u2711 Find contacts in London.<br>\u2711 Who do I know in Seattle?<br>Search for contacts in Ukraine.<br><img src=\"/assets/media/exam-media/04271/0015000006.png\" class=\"in-exam-image\"><br>You need to implement the phrase list in Language Understanding.<br>Solution: You create a new entity for the domain.<br>Does this meet the goal?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tYes\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tNo"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 18,
        "isMostVoted": true
      },
      {
        "answer": "B",
        "count": 14,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2022-04-28T02:19:00.000Z",
        "voteCount": 19,
        "content": "Wrong! We create a new location entity for domain to keep the location of FindContact intent."
      },
      {
        "date": "2023-12-09T21:01:00.000Z",
        "voteCount": 9,
        "content": "B. No\n\nCreating a new entity for the domain does not directly address the goal of implementing the provided phrase list for the \"FindContact\" intent. Entities are typically used to extract specific pieces of information from user input, like names, locations, etc. In this case, the goal is to improve the understanding of the intent \"FindContact\" by providing training phrases related to searching for contacts in specific locations. Instead of creating a new entity, you should focus on training the language model within the existing \"FindContact\" intent and include the provided phrases to enhance its ability to recognize and understand user queries related to finding contacts in different locations."
      },
      {
        "date": "2024-10-09T03:22:00.000Z",
        "voteCount": 1,
        "content": "B. it should be phrase list. https://learn.microsoft.com/en-us/azure/ai-services/luis/concepts/patterns-features"
      },
      {
        "date": "2024-09-23T08:04:00.000Z",
        "voteCount": 2,
        "content": "NO - you need a pattern"
      },
      {
        "date": "2024-09-13T18:56:00.000Z",
        "voteCount": 1,
        "content": "ChatGPT answer is B. No, here is the explanation:\nCreating a new entity for the domain does not meet the goal. To implement the phrase list in Language Understanding, you should add these phrases as example utterances for the FindContact intent. This helps the model recognize the intent based on similar phrases."
      },
      {
        "date": "2024-09-10T05:46:00.000Z",
        "voteCount": 2,
        "content": "the answer is a pattern"
      },
      {
        "date": "2024-07-12T08:30:00.000Z",
        "voteCount": 1,
        "content": "Selected Answer: A"
      },
      {
        "date": "2024-06-21T08:36:00.000Z",
        "voteCount": 2,
        "content": "\"create a new entity for the domain.\" is not \"to implement the phrase list\".\nI say B is correct! HipHop!"
      },
      {
        "date": "2024-06-15T08:02:00.000Z",
        "voteCount": 1,
        "content": "This issue is not working because everyone's opinion is 50-50. I don't know the correct answer, so I will be staring at MS Learn when this question comes up on the real exam.Examtopic should scrutinize and post the correct answer."
      },
      {
        "date": "2024-06-15T08:02:00.000Z",
        "voteCount": 1,
        "content": "This issue is not working because everyone's opinion is 50-50. I don't know the correct answer, so I will be staring at MS Learn when this question comes up on the real exam.Examtopic should scrutinize and post the correct answer."
      },
      {
        "date": "2024-05-29T06:28:00.000Z",
        "voteCount": 1,
        "content": "ET should not rely on discussion, but should scrutinize and place the correct responses."
      },
      {
        "date": "2024-03-28T16:37:00.000Z",
        "voteCount": 3,
        "content": "This same question (topic 3, question 1) seems to be indicated by the community that this question has two affirmative answers. I'm not sure if this is correct, normally in this type of question there is only one affirmative answer and the rest are negative. Is anyone clear on the real answer to this question?"
      },
      {
        "date": "2024-04-27T05:25:00.000Z",
        "voteCount": 1,
        "content": "Indeed !!"
      },
      {
        "date": "2024-03-13T18:59:00.000Z",
        "voteCount": 1,
        "content": "must be B"
      },
      {
        "date": "2024-03-08T00:06:00.000Z",
        "voteCount": 2,
        "content": "The question says\n\"You need to implement the phrase list in Language Understanding.\nSolution: You create a new entity for the domain.\nDoes this meet the goal?\"\n\nCreating an entity is not implementing a phrase list, so I vote NO."
      },
      {
        "date": "2024-01-26T20:48:00.000Z",
        "voteCount": 4,
        "content": "The ANSWER is NO \uff01\nInstead of creating a new intent for location, you should:\nAdd these phrases to the \"FindContact\" intent: This helps the model understand that these are different ways a user might express the intent to find contacts.\n\nUse Entities for Locations: In addition to training the intent with these phrases, you should use entities to capture the location information within the phrases. In LUIS, you can define an entity (like \"Location\") and then annotate locations in your training phrases. This way, the model learns to recognize and extract location details from user inputs.\n\nBy combining a well-trained \"FindContact\" intent with a location entity, your language model will be better equipped to understand and process user queries about finding contacts in specific locations."
      },
      {
        "date": "2023-11-04T08:51:00.000Z",
        "voteCount": 2,
        "content": "https://learn.microsoft.com/en-us/azure/ai-services/luis/concepts/entities"
      },
      {
        "date": "2023-06-28T20:25:00.000Z",
        "voteCount": 1,
        "content": "Same as Question 8.\nhttps://www.examtopics.com/discussions/microsoft/view/60466-exam-ai-102-topic-3-question-8-discussion"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 19,
    "url": "https://www.examtopics.com/discussions/microsoft/view/76239-exam-ai-102-topic-3-question-20-discussion/",
    "body": "You are training a Language Understanding model for a user support system.<br>You create the first intent named GetContactDetails and add 200 examples.<br>You need to decrease the likelihood of a false positive.<br>What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEnable active learning.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAdd a machine learned entity.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAdd additional examples to the GetContactDetails intent.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAdd examples to the None intent.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 27,
        "isMostVoted": true
      },
      {
        "answer": "A",
        "count": 4,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2022-05-24T01:54:00.000Z",
        "voteCount": 31,
        "content": "I would say is D) as per the following: https://docs.microsoft.com/en-us/azure/cognitive-services/language-service/conversational-language-understanding/concepts/none-intent#adding-examples-to-the-none-intent"
      },
      {
        "date": "2022-09-07T22:57:00.000Z",
        "voteCount": 5,
        "content": "Agreed, as stated in the link:\n\"You should also consider adding false positive examples to the None intent.\""
      },
      {
        "date": "2023-11-04T09:00:00.000Z",
        "voteCount": 2,
        "content": "agree with you, thanks for the provided documentation"
      },
      {
        "date": "2024-01-26T20:50:00.000Z",
        "voteCount": 7,
        "content": "False positive means =&gt;\nThe model needs examples of what it should not classify as \"GetContactDetails,\" which is the role of the \"None\" intent.\nTherefore, the most effective approach is to add a diverse range of examples to the \"None\" intent, covering various phrases and queries that are outside the scope of \"GetContactDetails.\" This helps create a clear boundary for the model, reducing the likelihood of it mistakenly classifying unrelated inputs as belonging to the \"GetContactDetails\" intent."
      },
      {
        "date": "2024-06-22T00:27:00.000Z",
        "voteCount": 1,
        "content": "I say this answer is D."
      },
      {
        "date": "2024-06-12T08:21:00.000Z",
        "voteCount": 1,
        "content": "D is answer."
      },
      {
        "date": "2024-06-04T21:11:00.000Z",
        "voteCount": 1,
        "content": "For me and ChatGPT: d"
      },
      {
        "date": "2024-05-29T06:44:00.000Z",
        "voteCount": 1,
        "content": "D. Add examples to the None intent."
      },
      {
        "date": "2024-05-24T08:04:00.000Z",
        "voteCount": 1,
        "content": "It must be D."
      },
      {
        "date": "2024-01-23T21:08:00.000Z",
        "voteCount": 3,
        "content": "The correct option to decrease the likelihood of a false positive in the Language Understanding model is to add additional None intent examples.\n\nOption D is correct. By adding more varied examples that do not map to a valid intent to the None intent, the model can better learn when an utterance does not apply and avoid falsely matching invalid queries to a valid intent.\n\nOptions A, B, and C may improve the model in certain ways, but they do not directly address reducing false positives. Only adding additional out-of-scope examples to the None intent will help the model better distinguish when new utterances do not match any existing intent's patterns.\n\nSo out of the options, adding examples to the None intent is the way to decrease the likelihood of false positives."
      },
      {
        "date": "2023-11-04T09:01:00.000Z",
        "voteCount": 2,
        "content": "to me the answer is D. Non intents have the purpose to reduce false positive too.\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/language-service/conversational-language-understanding/concepts/none-intent#adding-examples-to-the-none-intent"
      },
      {
        "date": "2023-08-18T07:15:00.000Z",
        "voteCount": 1,
        "content": "200 sample data. --&gt; much false positive. --&gt; Increase number of training data. --&gt; Add example to the None intent, not active learning in this context."
      },
      {
        "date": "2023-06-28T22:22:00.000Z",
        "voteCount": 2,
        "content": "D is the answer.\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/language-service/conversational-language-understanding/concepts/none-intent#adding-examples-to-the-none-intent\nThe None intent is also treated like any other intent in your project. If there are utterances that you want predicted as None, consider adding similar examples to them in your training data. For example, if you would like to categorize utterances that are not important to your project as None, such as greetings, yes and no answers, responses to questions such as providing a number, then add those utterances to your intent.\n\nYou should also consider adding false positive examples to the None intent. For example, in a flight booking project it is likely that the utterance \"I want to buy a book\" could be confused with a Book Flight intent. Adding \"I want to buy a book\" or \"I love reading books\" as None training utterances helps alter the predictions of those types of utterances towards the None intent instead of Book Flight."
      },
      {
        "date": "2023-06-12T17:00:00.000Z",
        "voteCount": 1,
        "content": "A. Enable active learning.\n\nBy enabling active learning, the model can actively request feedback from users when it encounters uncertain or ambiguous queries. This feedback loop helps improve the model's understanding and reduces false positives by incorporating user input into its training process. Option A (Enable active learning) is the correct choice to decrease the likelihood of false positives."
      },
      {
        "date": "2023-06-11T08:13:00.000Z",
        "voteCount": 3,
        "content": "You should also consider adding false positive examples to the None intent. For example, in a flight booking project it is likely that the utterance \"I want to buy a book\" could be confused with a Book Flight intent. Adding \"I want to buy a book\" or \"I love reading books\" as None training utterances helps alter the predictions of those types of utterances towards the None intent instead of Book Flight.\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/language-service/conversational-language-understanding/concepts/none-intent#adding-examples-to-the-none-intent"
      },
      {
        "date": "2023-06-08T17:44:00.000Z",
        "voteCount": 1,
        "content": "You should also consider adding false positive examples to the None intent. For example, in a flight booking project it is likely that the utterance \"I want to buy a book\" could be confused with a Book Flight intent. Adding \"I want to buy a book\" or \"I love reading books\" as None training utterances helps alter the predictions of those types of utterances towards the None intent instead of Book Flight.\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/language-service/conversational-language-understanding/concepts/none-intent#adding-examples-to-the-none-intent"
      },
      {
        "date": "2023-02-22T02:30:00.000Z",
        "voteCount": 2,
        "content": "To decrease the likelihood of a false positive, you can add additional examples to the GetContactDetails intent. This will help the model to better understand the intent and reduce the likelihood of false positive predictions."
      },
      {
        "date": "2023-05-17T01:56:00.000Z",
        "voteCount": 1,
        "content": "Nope, 20-30 examples per intent is recommended. See https://learn.microsoft.com/en-us/azure/cognitive-services/LUIS/concepts/application-design#create-example-utterances-for-each-intent"
      },
      {
        "date": "2023-01-17T12:52:00.000Z",
        "voteCount": 4,
        "content": "As explained in MS Document\n\"false positive\" = None intent"
      },
      {
        "date": "2023-01-16T16:50:00.000Z",
        "voteCount": 2,
        "content": "Add examples to \"None\" intent"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 20,
    "url": "https://www.examtopics.com/discussions/microsoft/view/77006-exam-ai-102-topic-3-question-21-discussion/",
    "body": "DRAG DROP -<br>You are building a Language Understanding model for purchasing tickets.<br>You have the following utterance for an intent named PurchaseAndSendTickets.<br>Purchase [2 audit business] tickets to [Paris] [next Monday] and send tickets to [email@domain.com]<br>You need to select the entity types. The solution must use built-in entity types to minimize training data whenever possible.<br>Which entity type should you use for each label? To answer, drag the appropriate entity types to the correct labels. Each entity type may be used once, more than once, or not at all.<br>You may need to drag the split bar between panes or scroll to view content.<br>Select and Place:<br><img src=\"/assets/media/exam-media/04271/0015300001.jpg\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04271/0015400001.jpg\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: GeographyV2 -<br>The prebuilt geographyV2 entity detects places. Because this entity is already trained, you do not need to add example utterances containing GeographyV2 to the application intents.<br><br>Box 2: Email -<br>Email prebuilt entity for a LUIS app: Email extraction includes the entire email address from an utterance. Because this entity is already trained, you do not need to add example utterances containing email to the application intents.<br><br>Box 3: Machine learned -<br>The machine-learning entity is the preferred entity for building LUIS applications.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/cognitive-services/luis/luis-reference-prebuilt-geographyv2 https://docs.microsoft.com/en-us/azure/cognitive-services/luis/luis-reference-prebuilt-email https://docs.microsoft.com/en-us/azure/cognitive-services/luis/reference-entity-machine-learned-entity",
    "votes": [],
    "comments": [
      {
        "date": "2023-06-27T23:40:00.000Z",
        "voteCount": 10,
        "content": "THIS WAS ON EXAM 28/06"
      },
      {
        "date": "2023-11-04T09:07:00.000Z",
        "voteCount": 5,
        "content": "correct answer"
      },
      {
        "date": "2024-05-24T08:02:00.000Z",
        "voteCount": 1,
        "content": "Paris: GeographyV2\nemail@domain.com: Email\n2 audit business: Machine learned"
      },
      {
        "date": "2024-01-23T21:16:00.000Z",
        "voteCount": 3,
        "content": "The answer is correct"
      },
      {
        "date": "2023-07-01T09:36:00.000Z",
        "voteCount": 4,
        "content": "1. GeographyV2 \n2. Email\n3. Machine learned\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/luis/luis-reference-prebuilt-geographyv2?tabs=V3\nThe prebuilt geographyV2 entity detects places. Because this entity is already trained, you do not need to add example utterances containing GeographyV2 to the application intents.\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/luis/luis-reference-prebuilt-email?tabs=V3\nEmail extraction includes the entire email address from an utterance. Because this entity is already trained, you do not need to add example utterances containing email to the application intents."
      },
      {
        "date": "2022-07-19T00:25:00.000Z",
        "voteCount": 4,
        "content": "Answer is correct : \nGeography v2 : \nhttps://docs.microsoft.com/en-us/azure/cognitive-services/luis/luis-reference-prebuilt-geographyv2?tabs=V3\n\nEmail : \nhttps://docs.microsoft.com/en-us/azure/cognitive-services/luis/luis-reference-prebuilt-email?tabs=V3-verbose \n\nMachine Learned :\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/luis/reference-entity-machine-learned-entity?tabs=V3\n\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/luis/concepts/entities"
      },
      {
        "date": "2022-06-22T01:18:00.000Z",
        "voteCount": 2,
        "content": "Correct.\nhttps://docs.microsoft.com/en-us/azure/cognitive-services/luis/luis-reference-prebuilt-email?tabs=V3"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 21,
    "url": "https://www.examtopics.com/discussions/microsoft/view/75322-exam-ai-102-topic-3-question-22-discussion/",
    "body": "You have the following C# method.<br><img src=\"/assets/media/exam-media/04271/0015500001.png\" class=\"in-exam-image\"><br>You need to deploy an Azure resource to the East US Azure region. The resource will be used to perform sentiment analysis.<br>How should you call the method?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tcreate_resource(\"res1\", \"ContentModerator\", \"S0\", \"eastus\")",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tcreate_resource(\"res1\", \"TextAnalytics\", \"S0\", \"eastus\")\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tcreate_resource(\"res1\", \"ContentModerator\", \"Standard\", \"East US\")",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tcreate_resource(\"res1\", \"TextAnalytics\", \"Standard\", \"East US\")"
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 13,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-05-29T06:45:00.000Z",
        "voteCount": 2,
        "content": "B is right answer. TextAnalytics is justice."
      },
      {
        "date": "2024-05-24T08:06:00.000Z",
        "voteCount": 1,
        "content": "SKU is S0.\nRegion is eastus. \nSentiment analysis uses TextAnalytics"
      },
      {
        "date": "2024-01-26T20:51:00.000Z",
        "voteCount": 3,
        "content": "free tier==&gt;S0, region eastus not East US, sentiment analysis=&gt;TextAnalytics"
      },
      {
        "date": "2024-01-23T21:17:00.000Z",
        "voteCount": 1,
        "content": "region has to be in format of: eastus\nContentModerator cannot do sentimental Analsysis"
      },
      {
        "date": "2023-11-05T01:52:00.000Z",
        "voteCount": 1,
        "content": "https://learn.microsoft.com/en-us/azure/synapse-analytics/machine-learning/tutorial-text-analytics-use-mmlspark"
      },
      {
        "date": "2023-10-16T14:50:00.000Z",
        "voteCount": 2,
        "content": "Is there any way to get this entire Q &amp; A for free? I'm unable to go past page #23, even though I've signed up for an account."
      },
      {
        "date": "2023-12-12T11:51:00.000Z",
        "voteCount": 1,
        "content": "@SaviB, did you found a solution? Accessed more than page #23?"
      },
      {
        "date": "2023-06-28T22:20:00.000Z",
        "voteCount": 1,
        "content": "B is the answer.\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/language-service/sentiment-opinion-mining/overview\nSentiment analysis and opinion mining are features offered by Azure Cognitive Service for Language, a collection of machine learning and AI algorithms in the cloud for developing intelligent applications that involve written language. These features help you find out what people think of your brand or topic by mining text for clues about positive or negative sentiment, and can associate them with specific aspects of the text."
      },
      {
        "date": "2023-01-16T16:53:00.000Z",
        "voteCount": 1,
        "content": "B is correct"
      },
      {
        "date": "2022-07-19T00:34:00.000Z",
        "voteCount": 3,
        "content": "Correct answer is B. \ncreate_resource(\"res1\", \"TextAnalytics\", \"S0\", \"eastus\")\n\nNote TextAnalysis will be rebranded into Cognitive Services for Language Service"
      },
      {
        "date": "2022-06-07T05:30:00.000Z",
        "voteCount": 2,
        "content": "Was on exam 7 Jun 2022"
      },
      {
        "date": "2022-05-08T22:45:00.000Z",
        "voteCount": 3,
        "content": "Answer is correct"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 22,
    "url": "https://www.examtopics.com/discussions/microsoft/view/85823-exam-ai-102-topic-3-question-23-discussion/",
    "body": "You build a Conversational Language Understanding model by using the Language Services portal.<br>You export the model as a JSON file as shown in the following sample.<br><img src=\"/assets/media/exam-media/04271/0015600001.png\" class=\"in-exam-image\"><br>To what does the Weather.Historic entity correspond in the utterance?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tby month\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tchicago",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\train",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tlocation"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 15,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-09-06T09:13:00.000Z",
        "voteCount": 1,
        "content": "It should be \"last year\". Does the question creators get extra time to make these questions because english is not their native language?"
      },
      {
        "date": "2024-08-09T09:05:00.000Z",
        "voteCount": 1,
        "content": "by month, basic math"
      },
      {
        "date": "2024-05-29T06:20:00.000Z",
        "voteCount": 1,
        "content": "by month"
      },
      {
        "date": "2024-05-24T07:47:00.000Z",
        "voteCount": 2,
        "content": "23 to 30 is by month."
      },
      {
        "date": "2024-05-24T03:39:00.000Z",
        "voteCount": 2,
        "content": "on exam, by month"
      },
      {
        "date": "2024-02-25T00:13:00.000Z",
        "voteCount": 1,
        "content": "\"by month\" seems correct"
      },
      {
        "date": "2024-01-26T20:52:00.000Z",
        "voteCount": 2,
        "content": "by month means to check history in the past by each month, no doubt answer is A"
      },
      {
        "date": "2024-01-23T21:21:00.000Z",
        "voteCount": 1,
        "content": "No doubt, A checked by different AI: chatgpt, claude 2 and Google bard"
      },
      {
        "date": "2023-11-05T01:54:00.000Z",
        "voteCount": 1,
        "content": "correct"
      },
      {
        "date": "2023-10-26T07:05:00.000Z",
        "voteCount": 2,
        "content": "correct answer"
      },
      {
        "date": "2022-10-18T11:52:00.000Z",
        "voteCount": 2,
        "content": "correct"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 23,
    "url": "https://www.examtopics.com/discussions/microsoft/view/87857-exam-ai-102-topic-3-question-24-discussion/",
    "body": "You are examining the Text Analytics output of an application.<br>The text analyzed is: `Our tour guide took us up the Space Needle during our trip to Seattle last week.`<br>The response contains the data shown in the following table.<br><img src=\"/assets/media/exam-media/04271/0015700001.png\" class=\"in-exam-image\"><br>Which Text Analytics API is used to analyze the text?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEntity Linking",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tNamed Entity Recognition\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSentiment Analysis",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tKey Phrase Extraction"
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 17,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-06-12T08:20:00.000Z",
        "voteCount": 2,
        "content": "B is answer."
      },
      {
        "date": "2024-05-29T06:19:00.000Z",
        "voteCount": 1,
        "content": "Named Entity Recognition a.k.a NER."
      },
      {
        "date": "2024-05-24T07:45:00.000Z",
        "voteCount": 1,
        "content": "NER is OK."
      },
      {
        "date": "2024-01-26T21:01:00.000Z",
        "voteCount": 4,
        "content": "B. Named Entity Recognition\n\nNamed Entity Recognition (NER) is a process in natural language processing that identifies and classifies named entities mentioned in text into predefined categories such as the names of persons, organizations, locations, expressions of times, quantities, monetary values, percentages, etc.\n\nEntity Linking typically involves linking entities to knowledge bases.\nSentiment Analysis is used to determine the sentiment expressed in the text.\nKey Phrase Extraction identifies the main points or topics in a text but does not categorize them into entity types like NER does."
      },
      {
        "date": "2023-11-05T01:57:00.000Z",
        "voteCount": 2,
        "content": "https://learn.microsoft.com/en-us/azure/ai-services/language-service/named-entity-recognition/overview"
      },
      {
        "date": "2023-08-18T07:12:00.000Z",
        "voteCount": 2,
        "content": "Title \"What is Named Entity Recognition (NER) in Azure AI Language?\" at https://learn.microsoft.com/en-us/azure/ai-services/language-service/named-entity-recognition/overview . NER"
      },
      {
        "date": "2023-06-28T22:15:00.000Z",
        "voteCount": 2,
        "content": "B is the answer.\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/language-service/named-entity-recognition/overview\nNamed Entity Recognition (NER) is one of the features offered by Azure Cognitive Service for Language, a collection of machine learning and AI algorithms in the cloud for developing intelligent applications that involve written language. The NER feature can identify and categorize entities in unstructured text. For example: people, places, organizations, and quantities."
      },
      {
        "date": "2023-01-16T16:55:00.000Z",
        "voteCount": 1,
        "content": "B is correct"
      },
      {
        "date": "2022-11-17T19:31:00.000Z",
        "voteCount": 2,
        "content": "From the link in the answer: \"The NER feature can identify and categorize entities in unstructured text. For example: people, places, organizations, and quantities.\""
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 24,
    "url": "https://www.examtopics.com/discussions/microsoft/view/147102-exam-ai-102-topic-3-question-24-discussion/",
    "body": "SIMULATION -<br>You need to configure and publish bot12345678 to support task management. The intent must be named TaskReminder. The LUDown for the intent is in the C:<br>\\Resources\\LU folder.<br>To complete this task, use the Microsoft Bot Framework Composer.<br>",
    "options": [],
    "answer": "See explanation below.",
    "answerDescription": "Step 1: Open Microsoft Bot Framework Composer<br>Step 2: Select the bot bot12345678<br>Step 3: Select Import existing resources. Read the instructions on the right side of the screen and select Next.<br><img src=\"/assets/media/exam-media/04271/0015900001.jpg\" class=\"in-exam-image\"><br>Step 4: Browse to the C:\\Resources\\LU folder and select the available .lu file<br>Step 5: In the pop-up window Importing existing resources, modify the JSON file content based on your resources information: Name the intent TaskReminder<br>Step 6: Select Publish from the Composer menu. In the Publish your bots pane, select the bot to publish (bot12345678), then select a publish profile from the<br>Publish target drop-down list.<br><img src=\"/assets/media/exam-media/04271/0016000001.jpg\" class=\"in-exam-image\"><br>Reference:<br>https://docs.microsoft.com/en-us/composer/how-to-publish-bot",
    "votes": [],
    "comments": [
      {
        "date": "2024-09-06T09:14:00.000Z",
        "voteCount": 1,
        "content": "bot is out of syllabus"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 25,
    "url": "https://www.examtopics.com/discussions/microsoft/view/88019-exam-ai-102-topic-3-question-26-discussion/",
    "body": "SIMULATION -<br>You need to configure bot12345678 support the French (FR-FR) language.<br>Export the bot to C:\\Resources\\Bot\\Bot1.zip.<br>To complete this task, use the Microsoft Bot Framework Composer.<br>",
    "options": [],
    "answer": "See explanation below.",
    "answerDescription": "Step 1: Open Microsoft Bot Framework Composer<br>Step 2: Select the bot bot12345678<br>Step 3: Select Configure.<br>Step 4: Select the Azure Language Understanding tab<br>Step 5: Select the Set up Language Understanding button. The Set up Language Understanding window will appear, shown below:<br><img src=\"/assets/media/exam-media/04271/0016200001.png\" class=\"in-exam-image\"><br>Step 6: Select Use existing resources and then select Next at the bottom of the window.<br>Step 7: Now select the Azure directory, Azure subscription, and Language Understanding resource name (French).<br>Step 8: Select Next on the bottom. Your Key and Region will appear on the next on the next window, shown below:<br><img src=\"/assets/media/exam-media/04271/0016400001.png\" class=\"in-exam-image\"><br><br>Step 9. Select Done -<br>Reference:<br>https://docs.microsoft.com/en-us/composer/concept-language-understanding https://docs.microsoft.com/en-us/composer/how-to-add-luis",
    "votes": [],
    "comments": [
      {
        "date": "2024-06-12T08:27:00.000Z",
        "voteCount": 2,
        "content": "I saw in the Microsoft question and answer that this question will not be asked, Mr. Big Tits."
      },
      {
        "date": "2024-05-29T06:18:00.000Z",
        "voteCount": 1,
        "content": "Simulation question will not appear on the actual exam as of May 29, 2024. Sonata Arctica"
      },
      {
        "date": "2023-06-08T18:33:00.000Z",
        "voteCount": 4,
        "content": "Select the Configure page from the left and then select the Localization tab. Select Manage bot language to choose your bot's languages."
      },
      {
        "date": "2022-11-19T19:06:00.000Z",
        "voteCount": 3,
        "content": "The answer is incorrect. The instructions in the following link should be used to add multi-language support to a bot:\nhttps://learn.microsoft.com/en-us/composer/how-to-use-multiple-language?tabs=v2x#update-language-settings"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 26,
    "url": "https://www.examtopics.com/discussions/microsoft/view/88194-exam-ai-102-topic-3-question-28-discussion/",
    "body": "You need to measure the public perception of your brand on social media by using natural language processing.<br>Which Azure service should you use?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tLanguage service\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tContent Moderator",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tComputer Vision",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tForm Recognizer"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 14,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-08-06T16:28:00.000Z",
        "voteCount": 2,
        "content": "Language Service to detect the sentiment"
      },
      {
        "date": "2024-06-12T08:19:00.000Z",
        "voteCount": 1,
        "content": "The answer is A, although it may not make sense for a moment. Please read the explanation carefully."
      },
      {
        "date": "2024-05-24T07:45:00.000Z",
        "voteCount": 1,
        "content": "It must be A."
      },
      {
        "date": "2024-02-27T10:04:00.000Z",
        "voteCount": 1,
        "content": "A the only meaningful"
      },
      {
        "date": "2024-01-23T22:25:00.000Z",
        "voteCount": 3,
        "content": "no doubt A"
      },
      {
        "date": "2023-11-05T03:25:00.000Z",
        "voteCount": 2,
        "content": "correct, sentiment analysis is the feature to use in this case\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/language-service/sentiment-opinion-mining/overview"
      },
      {
        "date": "2023-06-28T22:13:00.000Z",
        "voteCount": 2,
        "content": "A is the answer.\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/language-service/sentiment-opinion-mining/overview\nSentiment analysis and opinion mining are features offered by Azure Cognitive Service for Language, a collection of machine learning and AI algorithms in the cloud for developing intelligent applications that involve written language. These features help you find out what people think of your brand or topic by mining text for clues about positive or negative sentiment, and can associate them with specific aspects of the text."
      },
      {
        "date": "2022-11-21T06:13:00.000Z",
        "voteCount": 2,
        "content": "Text Analytics, sentiment analysis: https://azure.microsoft.com/en-us/products/cognitive-services/text-analytics/#features"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 27,
    "url": "https://www.examtopics.com/discussions/microsoft/view/83483-exam-ai-102-topic-3-question-29-discussion/",
    "body": "HOTSPOT -<br>You are developing an application that includes language translation.<br>The application will translate text retrieved by using a function named get_text_to_be_translated. The text can be in one of many languages. The content of the text must remain within the Americas Azure geography.<br>You need to develop code to translate the text to a single language.<br>How should you complete the code? To answer, select the appropriate options in the answer area.<br>NOTE: Each correct selection is worth one point.<br>Hot Area:<br><img src=\"/assets/media/exam-media/04271/0016800001.png\" class=\"in-exam-image\"><br>",
    "options": [],
    "answer": "<img src=\"/assets/media/exam-media/04271/0016900001.png\" class=\"in-exam-image\">",
    "answerDescription": "Box 1: (\"api-nam.cognitive.microsofttranslator.com\")<br>Geography USA: api-nam.cognitive.microsofttranslator.com<br>Datacenters: East US, South Central US, West Central US, and West US 2<br>Box 2: \"/translate?to=en\"<br>Must specify the language which it is being translated to. The 'to' parameter is required<br>Reference:<br>https://docs.microsoft.com/en-us/azure/cognitive-services/translator/reference/v3-0-reference https://docs.microsoft.com/en-us/azure/cognitive-services/translator/reference/v3-0-translate",
    "votes": [],
    "comments": [
      {
        "date": "2023-07-01T09:33:00.000Z",
        "voteCount": 18,
        "content": "1.api-nam.cognitive.microsofttranslator.com\n2. /translate?to=en\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/Translator/reference/v3-0-reference#base-urls\nRequests to Translator are, in most cases, handled by the datacenter that is closest to where the request originated. If there's a datacenter failure when using the global endpoint, the request may be routed outside of the geography.\n\nTo force the request to be handled within a specific geography, use the desired geographical endpoint. All requests are processed among the datacenters within the geography.\n- United States\napi-nam.cognitive.microsofttranslator.com\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/translator/reference/rest-api-guide\n- translate\nTranslate specified source language text into the target language text."
      },
      {
        "date": "2023-11-05T03:28:00.000Z",
        "voteCount": 4,
        "content": "agree with you, answer is correct"
      },
      {
        "date": "2024-07-14T11:38:00.000Z",
        "voteCount": 1,
        "content": "1.api-nam.cognitive.microsofttranslator.com\n2. /translate?to=en"
      },
      {
        "date": "2024-05-24T07:48:00.000Z",
        "voteCount": 2,
        "content": "api-nam.cognitive.microsofttranslator.com\ntranslate?to=en"
      },
      {
        "date": "2024-01-23T22:31:00.000Z",
        "voteCount": 3,
        "content": "\"api-apc.cognitive.microsofttranslator.com\" refers to the Asia Pacific endpoint. Using this endpoint will route requests to Azure data centers located in Asia Pacific for processing.\n\n\"api-nam.cognitive.microsofttranslator.com\" refers to the North America endpoint. Using this endpoint will route requests to Azure data centers located in North America for processing.\n\nSo in summary:\n\n\"api-apc.cognitive.microsofttranslator.com\" - Asia Pacific endpoint\n\"api-nam.cognitive.microsofttranslator.com\" - North America endpoint"
      },
      {
        "date": "2023-12-20T16:30:00.000Z",
        "voteCount": 2,
        "content": "A modified version of this was in the exam today."
      },
      {
        "date": "2023-08-22T02:08:00.000Z",
        "voteCount": 2,
        "content": "I feel like the second one should be /detect?to=en since the input can be multiple unspecified languages."
      },
      {
        "date": "2023-06-10T17:09:00.000Z",
        "voteCount": 1,
        "content": "answer is correct"
      },
      {
        "date": "2022-09-24T18:05:00.000Z",
        "voteCount": 4,
        "content": "The answer seems correct to me. api.nam would keep it within the US."
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 28,
    "url": "https://www.examtopics.com/discussions/microsoft/view/88196-exam-ai-102-topic-3-question-30-discussion/",
    "body": "You have the following data sources:<br>\u2711 Finance: On-premises Microsoft SQL Server database<br>\u2711 Sales: Azure Cosmos DB using the Core (SQL) API<br>\u2711 Logs: Azure Table storage<br>\u2711 HR: Azure SQL database<br>You need to ensure that you can search all the data by using the Azure Cognitive Search REST API.<br>What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tMigrate the data in HR to Azure Blob storage.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tMigrate the data in HR to the on-premises SQL server.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tExport the data in Finance to Azure Data Lake Storage.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tIngest the data in Logs into Azure Sentinel."
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 17,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-06-28T22:09:00.000Z",
        "voteCount": 8,
        "content": "C is the answer.\n\nhttps://learn.microsoft.com/en-us/azure/search/search-data-sources-gallery"
      },
      {
        "date": "2023-06-28T22:10:00.000Z",
        "voteCount": 5,
        "content": "https://learn.microsoft.com/en-us/azure/search/search-indexer-overview#supported-data-sources\nIndexers crawl data stores on Azure and outside of Azure.\n- Azure Blob Storage\n- Azure Cosmos DB\n- Azure Data Lake Storage Gen2\n- Azure SQL Database\n- Azure Table Storage\n- Azure SQL Managed Instance\n- SQL Server on Azure Virtual Machines\n- Azure Files (in preview)\n- Azure MySQL (in preview)\n- SharePoint in Microsoft 365 (in preview)\n- Azure Cosmos DB for MongoDB (in preview)\n- Azure Cosmos DB for Apache Gremlin (in preview)"
      },
      {
        "date": "2023-11-05T03:36:00.000Z",
        "voteCount": 1,
        "content": "thanks for the reference"
      },
      {
        "date": "2024-06-12T08:18:00.000Z",
        "voteCount": 1,
        "content": "C is answer."
      },
      {
        "date": "2024-05-24T03:41:00.000Z",
        "voteCount": 1,
        "content": "on exam, C is correct."
      },
      {
        "date": "2024-03-26T23:30:00.000Z",
        "voteCount": 3,
        "content": "Trick question, make sure you read it well. All of the data but that from Finance is already in the cloud."
      },
      {
        "date": "2024-01-23T22:36:00.000Z",
        "voteCount": 2,
        "content": "Finance data stays on-premises now, it has to be migrated to Azure Cloud first in order to be indexed and searchable by Cognitive Service"
      },
      {
        "date": "2023-12-20T16:30:00.000Z",
        "voteCount": 1,
        "content": "A modified version of this was in the exam today."
      },
      {
        "date": "2023-11-05T03:37:00.000Z",
        "voteCount": 1,
        "content": "https://learn.microsoft.com/en-us/azure/search/search-indexer-overview#supported-data-sources"
      },
      {
        "date": "2022-11-21T06:19:00.000Z",
        "voteCount": 3,
        "content": "https://learn.microsoft.com/en-us/azure/search/search-indexer-overview"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 29,
    "url": "https://www.examtopics.com/discussions/microsoft/view/111617-exam-ai-102-topic-3-question-30-discussion/",
    "body": "SIMULATION -<br>Use the following login credentials as needed:<br>To enter your username, place your cursor in the Sign in box and click on the username below.<br>To enter your password, place your cursor in the Enter password box and click on the password below.<br><br>Azure Username: admin@abc.com -<br><br>Azure Password: XXXXXXXXXXXX -<br>The following information is for technical support purposes only:<br><br>Lab Instance: 12345678 -<br><br>Task -<br>You need to create and publish a Language Understanding (classic) model named 1u12345678. The model will contain an intent of Travel that has an utterance of<br>Boat.<br>To complete this task, sign in to the Language Understanding portal at httptc//www.luis-ai/.<br>",
    "options": [],
    "answer": "See explanation below.",
    "answerDescription": "Create your LUIS model -<br>1. You should navigate to your LUIS.ai management portal and create a new application. In the portal create a model.<br><br>Model name: 1u12345678 -<br>2. Define one intent as \u05d2\u20acTravel\u05d2\u20ac and add an example utterances of Boat.<br><img src=\"/assets/media/exam-media/04271/0017200001.jpg\" class=\"in-exam-image\"><br>3. Publish the model<br>In order to use your model, you have to publish it. This is as easy as hitting the Publish tab, selecting between the production or staging environments, and hitting<br>Publish. As you can see from this page, you can also choose to enable sentiment analysis, speech priming to improve speech recognition, or the spell checker.<br>For now, you can leave those unchecked.<br>Reference:<br>https://docs.microsoft.com/en-us/azure/health-bot/language_model_howto https://www.codemag.com/article/1809021/Natural-Language-Understanding-with-LUIS",
    "votes": [],
    "comments": [
      {
        "date": "2024-06-12T08:27:00.000Z",
        "voteCount": 2,
        "content": "I saw in the Microsoft question and answer that this question will not be asked, Mr. Big Tits."
      },
      {
        "date": "2024-05-29T05:51:00.000Z",
        "voteCount": 1,
        "content": "Simulation question will not appear on the actual exam as of May 29, 2024."
      },
      {
        "date": "2024-05-22T08:14:00.000Z",
        "voteCount": 1,
        "content": "If the simulation question is not on the actual exam, delete this question."
      },
      {
        "date": "2023-12-14T05:58:00.000Z",
        "voteCount": 2,
        "content": "will we get simulation questions in exam -ai-102"
      },
      {
        "date": "2024-01-16T03:44:00.000Z",
        "voteCount": 2,
        "content": "End of Dec 2023, no simulations in the exam"
      },
      {
        "date": "2023-11-24T04:44:00.000Z",
        "voteCount": 2,
        "content": "will / is this querstion updated? Since LUIS is deprecating and already encouraging users to begin using CLU rather when accessing https://www.luis.ai/."
      },
      {
        "date": "2023-06-08T19:57:00.000Z",
        "voteCount": 3,
        "content": "1. go to https://language.cognitive.azure.com/\n2. create an intent Travel\n3. create sample utterances with boat\n4. train, test, deploy"
      },
      {
        "date": "2023-11-05T03:44:00.000Z",
        "voteCount": 1,
        "content": "agree with you"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 30,
    "url": "https://www.examtopics.com/discussions/microsoft/view/102570-exam-ai-102-topic-3-question-32-discussion/",
    "body": "You have a Language service resource that performs the following:<br><br>\u2022 Sentiment analysis<br>\u2022 Named Entity Recognition (NER)<br>\u2022 Personally Identifiable Information (PII) identification<br><br>You need to prevent the resource from persisting input data once the data is analyzed.<br><br>Which query parameter in the Language service API should you configure?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tmodel-version",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tpiiCategories",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tshowStats",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tloggingOptOut\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 13,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-03-14T04:31:00.000Z",
        "voteCount": 8,
        "content": "The LoggingOptOut parameter is true by default for the PII and health feature endpoints.\nReference https://learn.microsoft.com/en-us/legal/cognitive-services/language-service/data-privacy"
      },
      {
        "date": "2023-03-16T04:12:00.000Z",
        "voteCount": 3,
        "content": "ChatGPT confirms : \nTo prevent the resource from persisting input data once the data is analyzed, you should configure the loggingOptOut query parameter in the Language service API. Setting the value of loggingOptOut to true will prevent the service from logging or storing the input data after analysis.\n\nTherefore, the correct answer is D. loggingOptOut."
      },
      {
        "date": "2024-09-09T11:36:00.000Z",
        "voteCount": 1,
        "content": "Another of the Microsoft greatness in naming conventions. loggingOutput=false means it will keep the data, if it is true it will not keep the data. Now make sense of that. \nhttps://learn.microsoft.com/en-us/legal/cognitive-services/language-service/data-privacy#how-is-data-retained-and-what-customer-controls-are-available\n\n\"By default, this parameter is set to false for Language Detection, Key Phrase Extraction, Sentiment Analysis and Named Entity Recognition endpoints\""
      },
      {
        "date": "2024-06-12T08:18:00.000Z",
        "voteCount": 1,
        "content": "D is answer."
      },
      {
        "date": "2024-05-24T07:41:00.000Z",
        "voteCount": 1,
        "content": "loggingOptOut Yes"
      },
      {
        "date": "2024-02-02T23:59:00.000Z",
        "voteCount": 2,
        "content": "no doubt answer is D"
      },
      {
        "date": "2023-12-20T16:30:00.000Z",
        "voteCount": 1,
        "content": "A modified version of this was in the exam today."
      },
      {
        "date": "2023-12-22T18:21:00.000Z",
        "voteCount": 2,
        "content": "Hi @Gavlli, May  know how many simulation questions comes in AI 102 exam? also read through all the ET questions should be enough to clear  the exam?"
      },
      {
        "date": "2023-11-05T03:50:00.000Z",
        "voteCount": 1,
        "content": "Answer is correct\nhttps://learn.microsoft.com/en-us/legal/cognitive-services/language-service/data-privacy#how-is-data-retained-and-what-customer-controls-are-available"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 31,
    "url": "https://www.examtopics.com/discussions/microsoft/view/102571-exam-ai-102-topic-3-question-33-discussion/",
    "body": "You have an Azure Cognitive Services model named Model1 that identifies the intent of text input.<br><br>You develop an app in C# named App1.<br><br>You need to configure App1 to use Model1.<br><br>Which package should you add to App1?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUniversal.Microsoft.CognitiveServices.Speech",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSpeechServicesToolkit",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure.AI.Language.Conversations\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tXamarin.Cognitive.Speech"
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 26,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-02-03T00:02:00.000Z",
        "voteCount": 8,
        "content": "Azure Conversational Language Understanding is part of Azure Cognitive Services and is designed to understand the intent of text input. The Azure.AI.Language.Conversations package provides C# developers with the client libraries needed to interact with these services, enabling you to send text to models and receive the results of intent and entity recognition.\nExplanation of other options:\n\nA. Universal.Microsoft.CognitiveServices.Speech is primarily used for speech services such as speech-to-text conversion, and not specifically for text intent recognition."
      },
      {
        "date": "2024-06-22T00:25:00.000Z",
        "voteCount": 1,
        "content": "I say this answer is C."
      },
      {
        "date": "2024-06-12T08:17:00.000Z",
        "voteCount": 1,
        "content": "C is answer."
      },
      {
        "date": "2024-05-24T07:40:00.000Z",
        "voteCount": 1,
        "content": "C is right answer.\nXamarin is done."
      },
      {
        "date": "2023-11-05T03:53:00.000Z",
        "voteCount": 2,
        "content": "https://learn.microsoft.com/en-us/dotnet/api/overview/azure/ai.language.conversations-readme?view=azure-dotnet"
      },
      {
        "date": "2023-06-28T22:05:00.000Z",
        "voteCount": 4,
        "content": "C is the answer.\n\nhttps://learn.microsoft.com/en-us/dotnet/api/overview/azure/ai.language.conversations-readme?view=azure-dotnet\nConversational Language Understanding - aka CLU for short - is a cloud-based conversational AI service which provides many language understanding capabilities like:\n- Conversation App: It's used in extracting intents and entities in conversations\n\nStart by importing the namespace for the ConversationAnalysisClient and related class:\n- using Azure.AI.Language.Conversations;"
      },
      {
        "date": "2023-05-25T06:27:00.000Z",
        "voteCount": 2,
        "content": "C. Azure.AI.Language.Conversations\n\nThe Azure.AI.Language.Conversations package is part of the Azure SDK for .NET and is used for interacting with Azure Cognitive Services' Language Understanding (LUIS) models, which are used to identify the intent of text input. This makes it the correct choice for integrating Model1 into App1."
      },
      {
        "date": "2023-04-24T03:33:00.000Z",
        "voteCount": 4,
        "content": "ChatGPT: The package you should add to App1 to use Model1 is C. Azure.AI.Language.Conversations.\n\nAzure.AI.Language.Conversations is a package that provides the Language Understanding (LUIS) service, which can be used to identify the intent of text input. This package contains classes for authenticating with the LUIS service and sending text to the service to obtain intent and entity information."
      },
      {
        "date": "2023-03-16T04:13:00.000Z",
        "voteCount": 2,
        "content": "ChatGPT says the correct answer isn't even listed  : \nTo configure App1 to use Model1, you should add the Azure.AI.TextAnalytics package to the project. This package provides the necessary libraries and functionality to integrate with Azure Cognitive Services text analytics models such as Model1.\n\nTherefore, the correct answer is not listed among the options. The correct answer is Azure.AI.TextAnalytics."
      },
      {
        "date": "2023-03-14T04:35:00.000Z",
        "voteCount": 3,
        "content": "The question is about the intent of text input. It has nothing to do with speech.\nTherefore the Azure.AI.Language.Conversations is the answer : \nConversation Analysis is a cloud-based conversational AI service that applies custom machine-learning intelligence to a user's conversational, natural language text to predict overall meaning, and pull out relevant, detailed information.\nReference : https://learn.microsoft.com/en-us/samples/azure/azure-sdk-for-net/azureailanguageconversations-samples/"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 32,
    "url": "https://www.examtopics.com/discussions/microsoft/view/102572-exam-ai-102-topic-3-question-34-discussion/",
    "body": "HOTSPOT<br> -<br><br>You are building content for a video training solution.<br><br>You need to create narration to accompany the video content. The solution must use Custom Neural Voice.<br><br>What should you use to create a custom neural voice, and which service should you use to generate the narration? To answer, select the appropriate options in the answer area.<br><br>NOTE: Each correct answer is worth one point.<br><br><img src=\"https://img.examtopics.com/ai-102/image9.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/ai-102/image10.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2023-07-01T09:28:00.000Z",
        "voteCount": 19,
        "content": "1. Speech Studio portal\n2. Text-to-speech\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/speech-service/custom-neural-voice#how-does-it-work\nTo create a custom neural voice, use Speech Studio to upload the recorded audio and corresponding scripts, train the model, and deploy the voice to a custom endpoint.\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/speech-service/text-to-speech\nText to speech enables your applications, tools, or devices to convert text into humanlike synthesized speech. The text to speech capability is also known as speech synthesis. Use humanlike prebuilt neural voices out of the box, or create a custom neural voice that's unique to your product or brand."
      },
      {
        "date": "2023-11-05T03:59:00.000Z",
        "voteCount": 2,
        "content": "thanks for exaplanation"
      },
      {
        "date": "2024-07-14T11:39:00.000Z",
        "voteCount": 1,
        "content": "1. Speech Studio portal\n2. Text-to-speech"
      },
      {
        "date": "2024-05-29T06:14:00.000Z",
        "voteCount": 3,
        "content": "1. The Speech Studio portal\n2. Text-to-speech"
      },
      {
        "date": "2024-05-24T07:37:00.000Z",
        "voteCount": 2,
        "content": "The Speech Studio portal\nText-to-speech"
      },
      {
        "date": "2024-02-28T23:11:00.000Z",
        "voteCount": 2,
        "content": "Absolutely correct"
      },
      {
        "date": "2024-02-02T21:39:00.000Z",
        "voteCount": 4,
        "content": "For Creating a Custom Neural Voice:\nUse: The Speech Studio Portal\nExplanation: The Speech Studio portal is part of Microsoft Azure's Cognitive Services and is specifically designed for speech-related applications, including the creation of Custom Neural Voices. \n\nFor Generating Narration:\nUse: Text-to-Speech (TTS) Service\nExplanation: Once you have created a Custom Neural Voice model in the Speech Studio portal, you can use Azure's Text-to-Speech service to generate narration. The Text-to-Speech service converts written text into spoken words in a natural-sounding voice, leveraging the custom voice model you've created."
      },
      {
        "date": "2023-03-14T04:38:00.000Z",
        "voteCount": 2,
        "content": "The answer is correct. Speech Studio and text to speech."
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 33,
    "url": "https://www.examtopics.com/discussions/microsoft/view/111618-exam-ai-102-topic-3-question-35-discussion/",
    "body": "HOTSPOT<br> -<br><br>You are building a call handling system that will receive calls from French-speaking and German-speaking callers. The system must perform the following tasks:<br><br>\u2022\tCapture inbound voice messages as text.<br>\u2022\tReplay messages in English on demand.<br><br>Which Azure Cognitive Services services should you use? To answer, select the appropriate options in the answer area.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/ai-102/image11.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/ai-102/image12.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2023-07-01T09:25:00.000Z",
        "voteCount": 18,
        "content": "1. Speech-to-text\n2. Text-to-speech and Translator\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/speech-service/speech-to-text\nWith real-time speech to text, the audio is transcribed as speech is recognized from a microphone or file.\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/speech-service/text-to-speech\next to speech enables your applications, tools, or devices to convert text into humanlike synthesized speech. The text to speech capability is also known as speech synthesis. Use humanlike prebuilt neural voices out of the box, or create a custom neural voice that's unique to your product or brand."
      },
      {
        "date": "2023-11-05T04:01:00.000Z",
        "voteCount": 2,
        "content": "agree. The answer is correct"
      },
      {
        "date": "2024-07-14T11:39:00.000Z",
        "voteCount": 1,
        "content": "1. Speech-to-text\n2. Text-to-speech and Translator"
      },
      {
        "date": "2024-05-29T05:50:00.000Z",
        "voteCount": 3,
        "content": "1. Speech-to-text\n2. Text-to-speech and Translator"
      },
      {
        "date": "2024-05-22T08:11:00.000Z",
        "voteCount": 2,
        "content": "Speech-to-text\nText-to-speech and Translator"
      },
      {
        "date": "2023-12-20T16:31:00.000Z",
        "voteCount": 2,
        "content": "A modified version of this was in the exam today."
      },
      {
        "date": "2023-06-08T20:31:00.000Z",
        "voteCount": 3,
        "content": "answer is correct"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 34,
    "url": "https://www.examtopics.com/discussions/microsoft/view/102574-exam-ai-102-topic-3-question-36-discussion/",
    "body": "You are building a social media extension that will convert text to speech. The solution must meet the following requirements:<br><br>\u2022\tSupport messages of up to 400 characters.<br>\u2022\tProvide users with multiple voice options.<br>\u2022\tMinimize costs.<br><br>You create an Azure Cognitive Services resource.<br><br>Which Speech API endpoint provides users with the available voice options?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\thttps://uksouth.api.cognitive.microsoft.com/speechtotext/v3.0/models/base",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\thttps://uksouth.customvoice.api.speech.microsoft.com/api/texttospeech/v3.0/longaudiosynthesis/voices",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\thttps://uksouth.tts.speech.microsoft.com/cognitiveservices/voices/list\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\thttps://uksouth.voice.speech.microsoft.com/cognitiveservices/v1?deploymentId={deploymentId}"
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 28,
        "isMostVoted": true
      },
      {
        "answer": "B",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2023-03-14T04:48:00.000Z",
        "voteCount": 14,
        "content": "The correct answer is C\nThe question is about providing users with all the available voice options.\nGet a list of voices\nYou can use the tts.speech.microsoft.com/cognitiveservices/voices/list endpoint to get a full list of voices for a specific region or endpoint.\nReference : https://learn.microsoft.com/en-us/azure/cognitive-services/speech-service/rest-text-to-speech?tabs=streaming"
      },
      {
        "date": "2023-05-16T00:35:00.000Z",
        "voteCount": 2,
        "content": "Agreeing, as the only important question is: Which Speech API endpoint provides users with the available voice options? \n\nTherefor answer C should be correct for this one"
      },
      {
        "date": "2023-06-28T22:40:00.000Z",
        "voteCount": 7,
        "content": "C is the answer.\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/speech-service/rest-text-to-speech?tabs=streaming#get-a-list-of-voices\nou can use the tts.speech.microsoft.com/cognitiveservices/voices/list endpoint to get a full list of voices for a specific region or endpoint. Prefix the voices list endpoint with a region to get a list of voices for that region. For example, to get a list of voices for the westus region, use the https://westus.tts.speech.microsoft.com/cognitiveservices/voices/list endpoint."
      },
      {
        "date": "2023-07-08T07:05:00.000Z",
        "voteCount": 4,
        "content": "Gotten this in Jul 2023 exam."
      },
      {
        "date": "2024-10-01T03:44:00.000Z",
        "voteCount": 1,
        "content": "Not A: endpoint has speechtotext, but we need text sto speech \nNot B: Customvoice.api, but we need to minimize costs \nNot D: does not provide users with multiple voice options \n--&gt; C is the only reasonable answer"
      },
      {
        "date": "2024-07-14T11:40:00.000Z",
        "voteCount": 1,
        "content": "Selected Answer: C"
      },
      {
        "date": "2024-06-22T00:25:00.000Z",
        "voteCount": 1,
        "content": "I say this answer is C."
      },
      {
        "date": "2024-06-12T08:17:00.000Z",
        "voteCount": 1,
        "content": "C is answer."
      },
      {
        "date": "2024-05-29T06:12:00.000Z",
        "voteCount": 1,
        "content": "Why C?"
      },
      {
        "date": "2024-05-24T07:36:00.000Z",
        "voteCount": 1,
        "content": "C is right answer."
      },
      {
        "date": "2024-02-03T00:08:00.000Z",
        "voteCount": 1,
        "content": "only C meets demand of minimum cost and support 400 characters with voice options"
      },
      {
        "date": "2023-12-20T16:31:00.000Z",
        "voteCount": 3,
        "content": "A modified version of this was in the exam today."
      },
      {
        "date": "2023-11-05T04:16:00.000Z",
        "voteCount": 1,
        "content": "C is the correct answer\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/speech-service/rest-text-to-speech?tabs=streaming"
      },
      {
        "date": "2023-08-18T02:25:00.000Z",
        "voteCount": 1,
        "content": "The answer is very clear at here https://learn.microsoft.com/en-us/azure/ai-services/speech-service/rest-text-to-speech?tabs=streaming#get-a-list-of-voices\n\nYou can use the tts.speech.microsoft.com/cognitiveservices/voices/list endpoint\n\n For example, to get a list of voices for the westus region, use the https://westus.tts.speech.microsoft.com/cognitiveservices/voices/list endpoint.\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/speech-service/regions\n\nEurope - UK South - uksouth"
      },
      {
        "date": "2023-04-24T03:35:00.000Z",
        "voteCount": 1,
        "content": "ChatGPT: The Speech API endpoint that provides users with the available voice options is B."
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 35,
    "url": "https://www.examtopics.com/discussions/microsoft/view/102802-exam-ai-102-topic-3-question-37-discussion/",
    "body": "You develop a custom question answering project in Azure Cognitive Service for Language. The project will be used by a chatbot.<br><br>You need to configure the project to engage in multi-turn conversations.<br><br>What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAdd follow-up prompts.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEnable active learning.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAdd alternate questions.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEnable chit-chat."
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 19,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-06-28T21:58:00.000Z",
        "voteCount": 10,
        "content": "A is the answer.\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/language-service/question-answering/overview#multi-turn-conversations\nQuestion answering provides multi-turn prompts and active learning to help you improve your basic question and answer pairs.\n\nMulti-turn prompts give you the opportunity to connect question and answer pairs. This connection allows the client application to provide a top answer and provides more questions to refine the search for a final answer."
      },
      {
        "date": "2024-09-06T13:22:00.000Z",
        "voteCount": 1,
        "content": "How does the quoted text point to follow-up-prompt. It could be active learning"
      },
      {
        "date": "2023-07-08T07:06:00.000Z",
        "voteCount": 4,
        "content": "Gotten this in Jul 2023 exam."
      },
      {
        "date": "2024-09-06T13:25:00.000Z",
        "voteCount": 1,
        "content": "The expected answer of Microsoft is active-learning. Not follow-up prompt. Chatgpt is not correct and it is going for the literal meaning of follow-up prompt and that is not right"
      },
      {
        "date": "2024-09-09T11:41:00.000Z",
        "voteCount": 1,
        "content": "I'm wrong as per Microsoft documentation:\n\"Use follow-up prompts to create multiple turns of a conversation\"\nAnswer is follow-up prompts"
      },
      {
        "date": "2024-07-14T11:40:00.000Z",
        "voteCount": 1,
        "content": "Selected Answer: A"
      },
      {
        "date": "2024-06-24T17:02:00.000Z",
        "voteCount": 2,
        "content": "Got this in the exam, Jun 2024."
      },
      {
        "date": "2024-06-22T00:23:00.000Z",
        "voteCount": 1,
        "content": "I say this answer is A. The rising of the shield hero."
      },
      {
        "date": "2024-06-12T08:16:00.000Z",
        "voteCount": 1,
        "content": "A is answer."
      },
      {
        "date": "2024-05-29T06:12:00.000Z",
        "voteCount": 1,
        "content": "A. Add follow-up prompts."
      },
      {
        "date": "2024-05-24T07:32:00.000Z",
        "voteCount": 1,
        "content": "A is right answer."
      },
      {
        "date": "2024-02-03T00:08:00.000Z",
        "voteCount": 1,
        "content": "no doubt answer is A"
      },
      {
        "date": "2024-01-28T20:34:00.000Z",
        "voteCount": 1,
        "content": "no doubt follow up prompt"
      },
      {
        "date": "2024-01-26T21:35:00.000Z",
        "voteCount": 1,
        "content": "Multi-turn conversations in the context of chatbots or conversational AI refer to interactions where the dialogue between the user and the bot extends beyond a single question and response. In these conversations, the bot and the user exchange multiple messages, and the bot's responses are contextually dependent on the previous parts of the conversation."
      },
      {
        "date": "2023-11-05T04:21:00.000Z",
        "voteCount": 1,
        "content": "To configure a project for multi-turn conversations in Azure Cognitive Services for Language, you should:\n\nA. Add follow-up prompts.\n\nAdding follow-up prompts allows your question answering model to engage in multi-turn conversations by providing responses and asking for clarifications or additional information when a user's query is ambiguous or incomplete. This is a key feature for enabling conversational interactions with the chatbot. (ChatGPT)"
      },
      {
        "date": "2024-09-06T13:24:00.000Z",
        "voteCount": 1,
        "content": "another evidence chatgpt cannot make sense of the bad naming from Microsoft. \"follow-up prompt\" is not a follow up. It is just additional details for a prompt. For example a \"see also\"."
      },
      {
        "date": "2023-03-31T01:24:00.000Z",
        "voteCount": 2,
        "content": "Ref: https://learn.microsoft.com/en-us/azure/cognitive-services/qnamaker/how-to/multi-turn"
      },
      {
        "date": "2023-03-16T04:16:00.000Z",
        "voteCount": 1,
        "content": "ChatGPT confirms :\nTo configure the project to engage in multi-turn conversations, you should add follow-up prompts. Follow-up prompts are a way to ask additional questions or provide more information to help the user clarify their intent. By adding follow-up prompts, the chatbot can engage in a back-and-forth conversation with the user to gather additional information and ultimately provide a better answer.\n\nTherefore, the correct answer is A. Add follow-up prompts."
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 36,
    "url": "https://www.examtopics.com/discussions/microsoft/view/104894-exam-ai-102-topic-3-question-38-discussion/",
    "body": "HOTSPOT<br> -<br><br>You are building a solution that students will use to find references for essays.<br><br>You use the following code to start building the solution.<br><br><img src=\"https://img.examtopics.com/ai-102/image13.png\"><br><br>For each of the following statements, select Yes is the statement is true. Otherwise, select No.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/ai-102/image14.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/ai-102/image15.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2023-07-01T09:21:00.000Z",
        "voteCount": 22,
        "content": "NNY is the answer.\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/language-service/entity-linking/overview\nEntity linking is one of the features offered by Azure Cognitive Service for Language, a collection of machine learning and AI algorithms in the cloud for developing intelligent applications that involve written language. Entity linking identifies and disambiguates the identity of entities found in text. For example, in the sentence \"We went to Seattle last week.\", the word \"Seattle\" would be identified, with a link to more information on Wikipedia."
      },
      {
        "date": "2024-09-06T13:42:00.000Z",
        "voteCount": 1,
        "content": "Big search is NO\nNext is whether the language is detected in code. That is another trick on the language but shows just sloppiness of this org. The language is detected because it is not sent in the code, but it is not used in the \"shown code\". So, how much intelligence should I attribute to the question creator??\nI might answer Yes, assuming the question creator read the documentation"
      },
      {
        "date": "2024-09-09T12:09:00.000Z",
        "voteCount": 1,
        "content": "The code will not detect the language. There is no language set in the code and for that reason the language is set as \"en\", that is not \"detecting\" the language. \n\nFinal answer:\n N\n N\n Y"
      },
      {
        "date": "2023-04-02T10:54:00.000Z",
        "voteCount": 14,
        "content": "Y \nN\nY\n\nhttps://learn.microsoft.com/en-us/rest/api/cognitiveservices-textanalytics/3.0/entities-linking/entities-linking?tabs=HTTP"
      },
      {
        "date": "2023-06-23T17:52:00.000Z",
        "voteCount": 3,
        "content": "Agreed. The json file consists of language attributes indicating the detected language.\nFor the second statement, it's not always Bing search link."
      },
      {
        "date": "2024-09-08T05:33:00.000Z",
        "voteCount": 1,
        "content": "N Y Y is correct\nFirst N - there should be additional code shown like \"response.doc.primary_language.name\". It is not shown (the language detection is available though)\nSecond Y -\nThird Y - \n \"LinkedEntity contains a link to the well-known recognized entity in text. The link comes from a data source like Wikipedia or Bing. It additionally includes all of the matches of this entity found in the document.\""
      },
      {
        "date": "2024-08-26T09:40:00.000Z",
        "voteCount": 2,
        "content": "i dont know what image you guys are referring to but this doesnt make sense at all."
      },
      {
        "date": "2024-09-06T13:34:00.000Z",
        "voteCount": 1,
        "content": "I have not seen many questions that make sense. First time I thought these questions are wrong. But you will be surprised how accurate this is with the real exam. Absolutely no sense"
      },
      {
        "date": "2024-08-12T21:09:00.000Z",
        "voteCount": 1,
        "content": "NNY - LinkedEntity.Url normally contains a link to wikipedia"
      },
      {
        "date": "2024-05-29T06:01:00.000Z",
        "voteCount": 3,
        "content": "No\nNo\nYes"
      },
      {
        "date": "2024-05-24T07:29:00.000Z",
        "voteCount": 3,
        "content": "No No Yes"
      },
      {
        "date": "2024-05-19T13:27:00.000Z",
        "voteCount": 2,
        "content": "While the MS Learn specifically mention Wikipedia, the Class Doc for LinkedEnty refers to Bing. https://learn.microsoft.com/en-us/java/api/com.azure.ai.textanalytics.models.linkedentity?view=azure-java-stable\n\nSo Bing answers are correct.\n=&gt; NYY"
      },
      {
        "date": "2024-05-19T13:21:00.000Z",
        "voteCount": 3,
        "content": "The code will detect the language of documents.\nNo. The provided code doesn't include any language detection functionality. Azure Text Analytics does have separate language detection capabilities, but they aren't used in this snippet.\nThe url attribute returned for each linked entity will be a Bing search link.\nNo. The RecognizeLinkedEntities function in Azure Text Analytics usually returns links to more authoritative sources like Wikipedia, not general Bing search results.\nThe matches attribute returned for each linked entity will provide the location in a document where the entity is referenced.\nYes. The matches attribute within the response from RecognizeLinkedEntities provides details about where each recognized entity occurs in the input text. This includes information like character offsets, allowing you to locate the entity within the original text."
      },
      {
        "date": "2024-03-30T11:05:00.000Z",
        "voteCount": 1,
        "content": "No, the code you provided does not detect the language of documents. It uses the RecognizeLinkedEntities method of the TextAnalyticsClient to identify and link entities in the text to more information on the web.\n\nYes, the url attribute returned for each linked entity will be a Bing search link. This link provides more information about the entity.\n\nYes, the matches attribute returned for each linked entity will provide the location in the document where the entity is referenced. It includes the text of the entity, its offset (the number of characters from the beginning of the document to the start of the entity), and its length (the number of characters of the entity)."
      },
      {
        "date": "2024-03-27T00:37:00.000Z",
        "voteCount": 1,
        "content": "Final Answer:\nN\nN \nY"
      },
      {
        "date": "2024-02-28T09:24:00.000Z",
        "voteCount": 3,
        "content": "NNY\nTried out and the response does not detect language. it just returns the language code sent in the request and only english and Spanish is supported.\nThe version 3.1 returns Bing ID however all links returned are only wiki links"
      },
      {
        "date": "2024-02-03T00:19:00.000Z",
        "voteCount": 1,
        "content": "The code will detect the language of documents\n\n**No**. The provided code uses the RecognizeLinkedEntities method, which recognizes and classifies named entities in a document and links them to more information on the web. \n\nYes. The RecognizeLinkedEntities method returns a list of recognized entities linked to more information on the web, typically in the form of a Bing search URL. \n\nYes. For each linked entity recognized by the RecognizeLinkedEntities method, the matches attribute contains information about occurrences of that entity within the input text."
      },
      {
        "date": "2024-02-08T05:05:00.000Z",
        "voteCount": 1,
        "content": "the question says \"will\", and not \"typically\". The question wants to know if it will ALWAYS be a bing link."
      },
      {
        "date": "2024-01-28T07:36:00.000Z",
        "voteCount": 2,
        "content": "Incorrect image is displayed for me"
      },
      {
        "date": "2023-11-26T05:40:00.000Z",
        "voteCount": 3,
        "content": "N\nN\nY\nhe language that the document is written in. If unspecified, this value will be set to the default language in DefaultLanguage in the request sent to the service. If set to an empty string, the service will apply a model where the language is explicitly set to \"None\"."
      },
      {
        "date": "2023-11-05T04:29:00.000Z",
        "voteCount": 1,
        "content": "YNY\nhttps://learn.microsoft.com/en-us/dotnet/api/azure.ai.textanalytics.linkedentity?view=azure-dotnet"
      },
      {
        "date": "2023-09-12T03:45:00.000Z",
        "voteCount": 1,
        "content": "Properties of the Linked entity are: https://learn.microsoft.com/en-us/dotnet/api/azure.ai.textanalytics.linkedentity?view=azure-dotnet"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 37,
    "url": "https://www.examtopics.com/discussions/microsoft/view/110101-exam-ai-102-topic-3-question-39-discussion/",
    "body": "You train a Conversational Language Understanding model to understand the natural language input of users.<br><br>You need to evaluate the accuracy of the model before deploying it.<br><br>What are two methods you can use? Each correct answer presents a complete solution.<br><br>NOTE: Each correct selection is worth one point.",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tFrom the language authoring REST endpoint, retrieve the model evaluation summary.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tFrom Language Studio, enable Active Learning, and then validate the utterances logged for review.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tFrom Language Studio, select Model performance.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tFrom the Azure portal, enable log collection in Log Analytics, and then analyze the logs."
    ],
    "answer": "AC",
    "answerDescription": "",
    "votes": [
      {
        "answer": "AC",
        "count": 26,
        "isMostVoted": true
      },
      {
        "answer": "BC",
        "count": 3,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2023-06-10T17:22:00.000Z",
        "voteCount": 10,
        "content": "agree with SmallFire:\nActive Learning cannot be initiated prior to the deployment of the model. The primary purpose of the 'Active Learning' feature is to leverage actual user interaction data to enhance the model's understanding capabilities. This is a continuous learning and optimization process that takes place after the model has been deployed and put into actual use.\nso the answer is AC."
      },
      {
        "date": "2024-08-14T08:05:00.000Z",
        "voteCount": 1,
        "content": "A-C\nChatGPT still think that B is better than A, but this time I'm not agree"
      },
      {
        "date": "2024-06-22T04:37:00.000Z",
        "voteCount": 1,
        "content": "REST endpoint\nselect Model performance"
      },
      {
        "date": "2024-06-22T00:25:00.000Z",
        "voteCount": 1,
        "content": "I say this answer is A and C."
      },
      {
        "date": "2024-06-12T08:16:00.000Z",
        "voteCount": 1,
        "content": "AC is answer."
      },
      {
        "date": "2024-05-22T08:16:00.000Z",
        "voteCount": 2,
        "content": "REST and model performance."
      },
      {
        "date": "2024-01-27T00:35:00.000Z",
        "voteCount": 3,
        "content": "A. From the language authoring REST endpoint, retrieve the model evaluation summary.\nThis summary typically includes metrics like precision, recall, and accuracy, which are crucial for evaluating the effectiveness of a language understanding model.\nC. From Language Studio, select Model performance.\nIn Language Studio, the Model performance section typically provides detailed analytics about the model's performance, including various metrics and possibly confusion matrices."
      },
      {
        "date": "2023-11-05T04:41:00.000Z",
        "voteCount": 2,
        "content": "IMHO correct answers are:\nA. --&gt; https://learn.microsoft.com/en-us/rest/api/language/conversational-analysis-authoring/get-model-evaluation-summary?view=rest-language-2023-04-01&amp;tabs=HTTP\n\nC. --&gt; https://learn.microsoft.com/en-us/azure/ai-services/language-service/conversational-language-understanding/how-to/view-model-evaluation?tabs=Language-studio%2Cmodel-performance"
      },
      {
        "date": "2023-10-14T10:52:00.000Z",
        "voteCount": 1,
        "content": "If you look closely, you can see that the Model performance feature in Language Studio is about evaluating the performance of the model using test data as opposed to active learning which is using the real data from users\u2019 interactions, which you couldn\u2019t do prior to the deployment. My only pet peeve is that rest endpoint never works for me - always giving me the 404 no matter what."
      },
      {
        "date": "2023-09-12T19:25:00.000Z",
        "voteCount": 2,
        "content": "AC are correct - https://learn.microsoft.com/en-us/rest/api/language/2022-10-01-preview/text-analysis-authoring/get-model-evaluation-summary?tabs=HTTP"
      },
      {
        "date": "2023-06-28T21:55:00.000Z",
        "voteCount": 4,
        "content": "AC is the answer.\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/language-service/conversational-language-understanding/how-to/view-model-evaluation?tabs=Language-studio%2Cmodel-performance"
      },
      {
        "date": "2023-06-14T08:26:00.000Z",
        "voteCount": 2,
        "content": "B. Active Learning in Language Studio is a feature that helps improve the performance of your model by suggesting utterances for you to review and label. This can help you evaluate the accuracy of your model by seeing how it performs on these suggested utterances.\n\nC. The Model performance feature in Language Studio provides a detailed report on the performance of your model, including precision, recall, and F1 score. This can give you a good indication of the accuracy of your model.\n\nOption A is incorrect because the language authoring REST endpoint does not provide a model evaluation summary."
      },
      {
        "date": "2023-08-21T02:29:00.000Z",
        "voteCount": 2,
        "content": "B is not correct as you cant not do active learning on a model that is not yet deployed"
      },
      {
        "date": "2023-05-30T23:12:00.000Z",
        "voteCount": 4,
        "content": "Active Learning cannot be initiated prior to the deployment of the model. The primary purpose of the 'Active Learning' feature is to leverage actual user interaction data to enhance the model's understanding capabilities. This is a continuous learning and optimization process that takes place after the model has been deployed and put into actual use.\nso the answer is AC."
      },
      {
        "date": "2023-05-24T02:39:00.000Z",
        "voteCount": 1,
        "content": "Google Bard Answer : Sure, here are two methods you can use to evaluate the accuracy of a Conversational Language Understanding model before deploying it:\n\nFrom Language Studio, select Model performance. This will show you a summary of the model's performance, including the F1 score, precision, and recall.\nFrom Language Studio, enable Active Learning, and then validate the utterances logged for review. This will allow you to manually review utterances that the model has misclassified, and then retrain the model with the corrected data.\nHere are the correct answers to your question:\n\nC. From Language Studio, select Model performance.\nB. From Language Studio, enable Active Learning, and then validate the utterances logged for review."
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 38,
    "url": "https://www.examtopics.com/discussions/microsoft/view/108982-exam-ai-102-topic-3-question-40-discussion/",
    "body": "DRAG DROP<br> -<br><br>You develop an app in C# named App1 that performs speech-to-speech translation.<br><br>You need to configure App1 to translate English to German.<br><br>How should you complete the SpeechTranslationConfig object? To answer, drag the appropriate values to the correct targets. Each value may be used once, more than once, or not at all. You may need to drag the split bar between panes or scroll to view content.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/ai-102/image33.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/ai-102/image34.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2023-05-16T00:44:00.000Z",
        "voteCount": 25,
        "content": "Agreeing with @WinzigWeich\n\nAnswer should be:\n\n1) SpeechRecognitionLanguage\n2) AddTargetLanguage"
      },
      {
        "date": "2023-06-06T01:58:00.000Z",
        "voteCount": 12,
        "content": "1) SpeechRecognitionLanguage\n2) AddTargetLanguage\n\nin the exercise of AI-102 online learning"
      },
      {
        "date": "2024-10-10T14:08:00.000Z",
        "voteCount": 1,
        "content": "In this scenario, addTargetLanguage is not the best choice because you are configuring speech-to-speech translation with Azure Speech Translation API, and you need to set both the speech recognition language (input) and the speech synthesis language (output). If we were working with text translation, addTargetLanguage would be relevant. Because of this the correct answers are: speechRecognitionLanguage to \"en-US\" and speechSynthesisLanguage to \"de\""
      },
      {
        "date": "2024-09-06T14:06:00.000Z",
        "voteCount": 1,
        "content": "Wait a minute, Microsoft did it again. They made the first one an assignment and the second one a method call and gave the SpeechSynthesizer as an option. That's e v i l. I would just not notice that trick. How else can you explain that. Just to make the person who knows what SpeechSynthesis and with a time pressure fail."
      },
      {
        "date": "2024-07-14T11:41:00.000Z",
        "voteCount": 1,
        "content": "1. SpeechRecognitionLanguage\n2. AddTargetLanguage"
      },
      {
        "date": "2024-06-21T08:59:00.000Z",
        "voteCount": 1,
        "content": "1. speech_recognition_language\n2. add_target_language"
      },
      {
        "date": "2024-05-29T05:55:00.000Z",
        "voteCount": 1,
        "content": "1. SpeechRecognitionLanguage\n2. AddTargetLanguage"
      },
      {
        "date": "2024-05-22T08:17:00.000Z",
        "voteCount": 2,
        "content": "SpeechRecognitionLanguage\nAddTargetLanguage"
      },
      {
        "date": "2023-11-27T03:57:00.000Z",
        "voteCount": 1,
        "content": "1) SpeechRecognitionLanguage\n2) AddTargetLanguage\n\nhttps://learn.microsoft.com/en-us/dotnet/api/microsoft.cognitiveservices.speech.speechtranslationconfig?view=azure-dotnet"
      },
      {
        "date": "2023-07-01T09:10:00.000Z",
        "voteCount": 7,
        "content": "1. SpeechRecognitionLanguage\n2. AddTargetLanguage\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/speech-service/how-to-translate-speech?tabs=terminal&amp;pivots=programming-language-csharp#change-the-source-language\nOne common task of speech translation is specifying the input (or source) language. In your code, interact with the SpeechTranslationConfig instance by assigning it to the SpeechRecognitionLanguage property:\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/speech-service/how-to-translate-speech?tabs=terminal&amp;pivots=programming-language-csharp#add-a-translation-language\nAnother common task of speech translation is to specify target translation languages. At least one is required, but multiples are supported. With every call to AddTargetLanguage, a new target translation language is specified. In other words, when speech is recognized from the source language, each target translation is available as part of the resulting translation operation."
      },
      {
        "date": "2023-11-05T04:44:00.000Z",
        "voteCount": 2,
        "content": "thanks for explanation and the provided relevant documentation"
      },
      {
        "date": "2023-05-11T09:58:00.000Z",
        "voteCount": 6,
        "content": "https://microsoftlearning.github.io/AI-102-AIEngineer.de-de/Instructions/08-translate-speech.html\nC# Part \ntranslationConfig.SpeechRecognitionLanguage\ntranslationConfig.AddTargetLanguage"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 39,
    "url": "https://www.examtopics.com/discussions/microsoft/view/111850-exam-ai-102-topic-3-question-41-discussion/",
    "body": "You have an Azure subscription that contains an Azure Cognitive Service for Language resource.<br><br>You need to identify the URL of the REST interface for the Language service.<br><br>Which blade should you use in the Azure portal?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tIdentity",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tKeys and Endpoint\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tNetworking",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tProperties"
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 17,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-06-10T17:08:00.000Z",
        "voteCount": 9,
        "content": "It is B."
      },
      {
        "date": "2024-06-22T00:24:00.000Z",
        "voteCount": 1,
        "content": "I say this answer is B."
      },
      {
        "date": "2024-06-12T08:16:00.000Z",
        "voteCount": 1,
        "content": "B is answer."
      },
      {
        "date": "2024-05-22T08:11:00.000Z",
        "voteCount": 1,
        "content": "B is right answer."
      },
      {
        "date": "2024-02-03T02:38:00.000Z",
        "voteCount": 3,
        "content": "B. Keys and Endpoint blade in the Azure portal.\n\nThis blade provides the endpoint URL needed to access the Cognitive Services API, along with the keys required for authentication. The endpoint URL is essential for making API calls to the service, including those for Language features such as sentiment analysis, key phrase extraction, named entity recognition, and more."
      },
      {
        "date": "2023-11-05T06:11:00.000Z",
        "voteCount": 1,
        "content": "correct"
      },
      {
        "date": "2023-10-26T18:41:00.000Z",
        "voteCount": 1,
        "content": "ans correct"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 40,
    "url": "https://www.examtopics.com/discussions/microsoft/view/111851-exam-ai-102-topic-3-question-42-discussion/",
    "body": "DRAG DROP<br> -<br><br>You are building a transcription service for technical podcasts.<br><br>Testing reveals that the service fails to transcribe technical terms accurately.<br><br>You need to improve the accuracy of the service.<br><br>Which five actions should you perform in sequence? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.<br><br><img src=\"https://img.examtopics.com/ai-102/image35.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/ai-102/image36.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2023-07-01T09:06:00.000Z",
        "voteCount": 25,
        "content": "1. Create Custom Speech project\n2. Create speech-to-text model\n3. Upload training datasets\n4. Train model\n5. Deploy model"
      },
      {
        "date": "2023-07-01T09:06:00.000Z",
        "voteCount": 8,
        "content": "https://learn.microsoft.com/en-us/azure/cognitive-services/speech-service/custom-speech-overview#how-does-it-work\nWith Custom Speech, you can upload your own data, test and train a custom model, compare accuracy between models, and deploy a model to a custom endpoint.\n- Create a project and choose a model. Use a Speech resource that you create in the Azure portal. If you will train a custom model with audio data, choose a Speech resource region with dedicated hardware for training audio data.\n- Upload test data. Upload test data to evaluate the speech to text offering for your applications, tools, and products.\n- Train a model. Provide written transcripts and related text, along with the corresponding audio data. Testing a model before and after training is optional but recommended.\n- Deploy a model. Once you're satisfied with the test results, deploy the model to a custom endpoint. With the exception of batch transcription, you must deploy a custom endpoint to use a Custom Speech model."
      },
      {
        "date": "2023-11-05T06:16:00.000Z",
        "voteCount": 3,
        "content": "thanks for the provided references"
      },
      {
        "date": "2024-08-14T20:34:00.000Z",
        "voteCount": 1,
        "content": "Given answer is correct"
      },
      {
        "date": "2024-07-15T12:08:00.000Z",
        "voteCount": 1,
        "content": "1. Create Custom Speech project\n2. Create speech-to-text model\n3. Upload training datasets\n4. Train model\n5. Deploy model"
      },
      {
        "date": "2024-05-29T05:48:00.000Z",
        "voteCount": 2,
        "content": "1. Create Custom Speech project\n2. Create speech-to-text model\n3. Upload training datasets\n4. Train model\n5. Deploy model"
      },
      {
        "date": "2024-03-28T17:10:00.000Z",
        "voteCount": 2,
        "content": "1. Create a Custom Voice Project\n2. Create a speech-to-text model\n3. Upload Training Datasets\n4. Training Model\n5. Implementation model"
      },
      {
        "date": "2024-03-28T17:08:00.000Z",
        "voteCount": 1,
        "content": "According to the answer, then data should not be uploaded to train the model? Seriously? So how do you plan to train yourself if they're supposed to be technical words. I agree with zellck"
      },
      {
        "date": "2023-11-05T06:15:00.000Z",
        "voteCount": 1,
        "content": "correct answer"
      },
      {
        "date": "2023-06-10T17:15:00.000Z",
        "voteCount": 3,
        "content": "It is true."
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 41,
    "url": "https://www.examtopics.com/discussions/microsoft/view/108161-exam-ai-102-topic-3-question-43-discussion/",
    "body": "You are building a retail kiosk system that will use a custom neural voice.<br><br>You acquire audio samples and consent from the voice talent.<br><br>You need to create a voice talent profile.<br><br>What should you upload to the profile?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ta .zip file that contains 10-second .wav files and the associated transcripts as .txt files",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ta five-minute .flac audio file and the associated transcript as a .txt file",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ta .wav or .mp3 file of the voice talent consenting to the creation of a synthetic version of their voice\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ta five-minute .wav or .mp3 file of the voice talent describing the kiosk system"
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 39,
        "isMostVoted": true
      },
      {
        "answer": "A",
        "count": 12,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2023-12-01T00:16:00.000Z",
        "voteCount": 5,
        "content": "The question is about the profile, not data."
      },
      {
        "date": "2024-09-27T09:23:00.000Z",
        "voteCount": 1,
        "content": "uploaded testing data must be A collection (.zip) of either .wave +.txt (if samples and transcripts are available)or .wave/.mp3 (if samples only available)\nin both cases must be .zip"
      },
      {
        "date": "2024-10-03T13:28:00.000Z",
        "voteCount": 1,
        "content": "wrong answer \nas per https://learn.microsoft.com/en-us/azure/ai-services/speech-service/professional-voice-create-consent?pivots=speech-studio\nfile should be .wave or .mp3"
      },
      {
        "date": "2024-09-11T07:40:00.000Z",
        "voteCount": 1,
        "content": "anwser is C, see here - https://learn.microsoft.com/en-us/azure/ai-services/speech-service/professional-voice-create-consent?pivots=speech-studio"
      },
      {
        "date": "2024-08-14T08:06:00.000Z",
        "voteCount": 1,
        "content": "Both me and ChatGPT agree with A"
      },
      {
        "date": "2024-08-04T00:02:00.000Z",
        "voteCount": 1,
        "content": "a .zip file that contains 10-second .wav files and the associated transcripts as .txt files"
      },
      {
        "date": "2024-06-22T00:24:00.000Z",
        "voteCount": 2,
        "content": "I say this answer is C."
      },
      {
        "date": "2024-06-12T08:15:00.000Z",
        "voteCount": 2,
        "content": "C is answer."
      },
      {
        "date": "2024-05-29T05:56:00.000Z",
        "voteCount": 3,
        "content": "C is correct answer."
      },
      {
        "date": "2024-04-07T14:31:00.000Z",
        "voteCount": 2,
        "content": "C is the correct answer"
      },
      {
        "date": "2024-02-05T12:19:00.000Z",
        "voteCount": 2,
        "content": "https://learn.microsoft.com/en-us/azure/ai-services/speech-service/how-to-custom-voice-talent"
      },
      {
        "date": "2024-02-03T04:48:00.000Z",
        "voteCount": 2,
        "content": "Based on the Azure AI documentation, the correct option for creating a voice talent profile for a custom neural voice is:\n\nC. a .wav or .mp3 file of the voice talent consenting to the creation of a synthetic version of their voice.\n\nThis is because the documentation specifies the need for a recording of the voice talent's consent statement, acknowledging the use of their voice recordings by a specified company to create and use a synthetic version of their voice"
      },
      {
        "date": "2023-11-30T06:26:00.000Z",
        "voteCount": 2,
        "content": "C is the correct answer as only wav &amp; mp3 formats are allowed. Zip is not allowed."
      },
      {
        "date": "2023-11-05T07:14:00.000Z",
        "voteCount": 1,
        "content": "here we are requested to add a new voice talent profile. So a consent statement is needed.\nhttps://learn.microsoft.com/en-us/azure/ai-services/speech-service/how-to-custom-voice-talent"
      },
      {
        "date": "2023-10-19T00:21:00.000Z",
        "voteCount": 1,
        "content": "I initially thought A, but now think it is C\nhttps://learn.microsoft.com/en-us/azure/ai-services/speech-service/how-to-custom-voice-talent"
      },
      {
        "date": "2023-10-03T06:54:00.000Z",
        "voteCount": 3,
        "content": "zip is not allowed. only wav &amp; mp3.\nAnd made synthetic. =C\nhttps://learn.microsoft.com/en-us/azure/ai-services/speech-service/how-to-custom-voice-talent\nfollow the pictures very carefully."
      },
      {
        "date": "2023-09-12T04:10:00.000Z",
        "voteCount": 1,
        "content": "The correct answer is A! From the documentation: https://learn.microsoft.com/en-us/azure/ai-services/speech-service/how-to-custom-voice-training-data\n\nFollow these guidelines when preparing audio.\nProperty\tValue\nFile format\tRIFF (.wav), grouped into a .zip file\nFile name\tFile name characters supported by Windows OS, with .wav extension.\nThe characters \\ / : * ? \" &lt; &gt; | aren't allowed.\nIt can't start or end with a space, and can't start with a dot.\nNo duplicate file names are allowed.\nSampling rate\tWhen creating a custom neural voice, 24,000 Hz is required.\nSample format\tPCM, at least 16-bit\nAudio length\tShorter than 15 seconds\nArchive format\t.zip\nMaximum archive size\t2048 MB"
      },
      {
        "date": "2023-09-02T03:23:00.000Z",
        "voteCount": 1,
        "content": "In Q#13 (How should you upload the samples?), the selected answer as option B (for speech samples to be used in training) corresponds to this Q#43\u2019s option A.\n\nQ#43 (What should you upload to the profile?) though, refers specifically to the voice talent\u2019s profile, that should contain an audio sample of the given consent, and hereto \u201cOnly .wav and .mp3 files are accepted\u201d (at the bottom of the screenshot provided in the link).\nhttps://learn.microsoft.com/en-us/azure/ai-services/speech-service/how-to-custom-voice-talent#add-voice-talent"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 42,
    "url": "https://www.examtopics.com/discussions/microsoft/view/111250-exam-ai-102-topic-3-question-44-discussion/",
    "body": "DRAG DROP<br> -<br><br>You have a Language Understanding solution that runs in a Docker container.<br><br>You download the Language Understanding container image from the Microsoft Container Registry (MCR).<br><br>You need to deploy the container image to a host computer.<br><br>Which three actions should you perform in sequence? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.<br><br><img src=\"https://img.examtopics.com/ai-102/image37.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/ai-102/image38.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2023-07-01T09:00:00.000Z",
        "voteCount": 42,
        "content": "1. From portal, export solution as package file.\n2. From host computer, move package file to Docker input directory.\n3. From host computer, run container and specify input directory.\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/luis/luis-container-howto?tabs=v3#how-to-use-the-container\n- Export package for container from LUIS portal or LUIS APIs.\n- Move package file into the required input directory on the host computer. Do not rename, alter, overwrite, or decompress the LUIS package file.\n- Run the container, with the required input mount and billing settings."
      },
      {
        "date": "2023-09-02T03:42:00.000Z",
        "voteCount": 19,
        "content": "@zellck: You\u2019re a role model for contributing to community discussions, love this style! Well-documented answers, plus the corresponding links to follow-up and form an opinion independently!"
      },
      {
        "date": "2023-11-05T07:15:00.000Z",
        "voteCount": 3,
        "content": "thanks for explanation"
      },
      {
        "date": "2024-05-22T08:15:00.000Z",
        "voteCount": 3,
        "content": "export\nmove\nrun"
      },
      {
        "date": "2024-02-03T04:52:00.000Z",
        "voteCount": 1,
        "content": "Export the LUIS application as a package file from the Azure portal: This involves downloading the LUIS model you've developed and want to run locally in a container.\n\nMove the exported package file to the Docker input directory on the host computer: This step involves transferring the downloaded LUIS application package to a specific directory that the Docker container will use as its input source.\n\nRun the Docker container and specify the input directory: This involves using Docker commands to start the container with the necessary parameters, including the location of the LUIS application package file in the input directory.\n\nRetraining the model is not mentioned as a step for deploying the container image to a host computer because the model should already be trained and exported from the LUIS portal before deployment."
      },
      {
        "date": "2023-06-25T22:02:00.000Z",
        "voteCount": 2,
        "content": "The answer seems correct.\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/luis/luis-container-howto?tabs=v3"
      },
      {
        "date": "2023-06-10T17:27:00.000Z",
        "voteCount": 1,
        "content": "No.\nExport,Docker,Output directory."
      },
      {
        "date": "2023-06-06T02:12:00.000Z",
        "voteCount": 3,
        "content": "answer is correct"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 43,
    "url": "https://www.examtopics.com/discussions/microsoft/view/108985-exam-ai-102-topic-3-question-45-discussion/",
    "body": "HOTSPOT<br> -<br><br>You are building a text-to-speech app that will use a custom neural voice.<br><br>You need to create an SSML file for the app. The solution must ensure that the voice profile meets the following requirements:<br><br>\u2022\tExpresses a calm tone<br>\u2022\tImitates the voice of a young adult female<br><br>How should you complete the code? To answer, select the appropriate options in the answer area.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/ai-102/image39.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/ai-102/image40.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2023-07-01T08:57:00.000Z",
        "voteCount": 20,
        "content": "1. role\n2. style\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/speech-service/speech-synthesis-markup-voice#speaking-styles-and-roles\nBy default, neural voices have a neutral speaking style. You can adjust the speaking style, style degree, and role at the sentence level.\n\nThe following table has descriptions of each supported style attribute.\n- style=\"gentle\"\nExpresses a mild, polite, and pleasant tone, with lower pitch and vocal energy.\n\nThe following table has descriptions of each supported role attribute.\n- role=\"YoungAdultFemale\"\nThe voice imitates a young adult female."
      },
      {
        "date": "2023-05-11T10:47:00.000Z",
        "voteCount": 9,
        "content": "correct https://learn.microsoft.com/en-us/azure/cognitive-services/speech-service/speech-synthesis-markup-voice"
      },
      {
        "date": "2024-07-14T11:42:00.000Z",
        "voteCount": 1,
        "content": "1. role\n2. style"
      },
      {
        "date": "2024-07-14T11:42:00.000Z",
        "voteCount": 1,
        "content": "1. role\n2. style"
      },
      {
        "date": "2024-06-06T06:46:00.000Z",
        "voteCount": 1,
        "content": "1. role\n2. style"
      },
      {
        "date": "2024-05-24T03:42:00.000Z",
        "voteCount": 2,
        "content": "on exam, role and style."
      },
      {
        "date": "2024-05-22T08:17:00.000Z",
        "voteCount": 1,
        "content": "role and style"
      },
      {
        "date": "2023-11-05T07:16:00.000Z",
        "voteCount": 2,
        "content": "correct answer\nhttps://learn.microsoft.com/en-us/azure/ai-services/speech-service/speech-synthesis-markup-voice"
      },
      {
        "date": "2023-08-18T08:42:00.000Z",
        "voteCount": 2,
        "content": "role\n\nstyle\n\nsee role at https://learn.microsoft.com/en-us/azure/ai-services/speech-service/speech-synthesis-markup-voice#role-example . May styles at https://learn.microsoft.com/en-us/azure/ai-services/speech-service/speech-synthesis-markup-voice#speaking-styles-and-roles"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 44,
    "url": "https://www.examtopics.com/discussions/microsoft/view/143420-exam-ai-102-topic-3-question-79-discussion/",
    "body": "You are building an Azure AI Language Understanding solution.<br><br>You discover that many intents have similar utterances containing airport names or airport codes.<br><br>You need to minimize the number of utterances used to train the model.<br><br>Which type of custom entity should you use?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tPattern.any\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tmachine-learning",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tregular expression",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tlist"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 5,
        "isMostVoted": true
      },
      {
        "answer": "D",
        "count": 2,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2024-09-27T05:22:00.000Z",
        "voteCount": 1,
        "content": "USing a list entity allows you to define a set of values and their synonyms which will help minimize the number of utterances needed to train the model.\n\nHence the answer must be:\nD) List"
      },
      {
        "date": "2024-09-11T07:48:00.000Z",
        "voteCount": 1,
        "content": "Pattern, you can use this to summarise multiple utterances into intents"
      },
      {
        "date": "2024-09-09T12:46:00.000Z",
        "voteCount": 1,
        "content": "\"Patterns are designed to improve accuracy when multiple utterances are very similar. A pattern allows you to gain more accuracy for an intent without providing several more utterances.\"\nSo, it has to be pattern. The only one in the list is Pattern.Any. \nLooks like the MIcrosoft guy just read this line and made the question and randomly chose a pattern type"
      },
      {
        "date": "2024-09-09T12:52:00.000Z",
        "voteCount": 1,
        "content": "regular-expression entity is given as an option to trick those who actually read the example for that using flight code. If you did not read much, then you are safe in Microsoft world"
      },
      {
        "date": "2024-08-20T22:07:00.000Z",
        "voteCount": 2,
        "content": "Copied entire question to Copilot, and Copilot says D.\n\nTo minimize the number of utterances used to train the model, you should use a list entity. List entities allow you to define a list of values (such as airport names or codes) and associate them with a single entity. This way, you can handle multiple similar utterances with a single entity reference, making your model more efficient and concise."
      },
      {
        "date": "2024-09-09T12:57:00.000Z",
        "voteCount": 1,
        "content": "it will be hard to list all the possible flight codes and flight names in a list."
      },
      {
        "date": "2024-08-14T08:10:00.000Z",
        "voteCount": 2,
        "content": "Pattern.any according to Copilot"
      },
      {
        "date": "2024-08-06T20:51:00.000Z",
        "voteCount": 2,
        "content": "Answer is A according to ChatGPT"
      },
      {
        "date": "2024-07-09T22:46:00.000Z",
        "voteCount": 4,
        "content": "A. Pattern Any\nFrom: https://learn.microsoft.com/en-us/azure/ai-services/luis/concepts/patterns-features#patternany-entity\n\nFor Airports this means:\nYou can exrpess the Airport Name in Full as \n\"John F. Kennedy International Airport\"\nor in short with the code as\n\"JFK\"\n\nLUIS will have to get both as the same"
      },
      {
        "date": "2024-07-06T07:16:00.000Z",
        "voteCount": 1,
        "content": "as per chat gpt:\nTo minimize the number of utterances used to train the model while dealing with similar utterances containing airport names or airport codes, you should use a custom entity that can generalize the variations of the entities within the utterances.\n\nThe correct choice in this scenario is Pattern.any.\n\nPattern.any is used in Language Understanding (LUIS) to handle cases where you have a specific pattern in the utterances, but the specific instances of an entity (like airport names or codes) can vary widely. By using Pattern.any, you can define a pattern that recognizes and extracts any airport name or code without needing to provide all possible variations in the training data.\n\nTherefore, the most suitable option is:\n\nA. Pattern.any"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 45,
    "url": "https://www.examtopics.com/discussions/microsoft/view/108116-exam-ai-102-topic-3-question-47-discussion/",
    "body": "You have a text-based chatbot.<br><br>You need to enable content moderation by using the Text Moderation API of Content Moderator.<br><br>Which two service responses should you use? Each correct answer presents part of the solution.<br><br>NOTE: Each correct selection is worth one point.",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tpersonal data\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tthe adult classification score",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ttext classification\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\toptical character recognition (OCR)",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tthe racy classification score"
    ],
    "answer": "AC",
    "answerDescription": "",
    "votes": [
      {
        "answer": "AC",
        "count": 26,
        "isMostVoted": true
      },
      {
        "answer": "BE",
        "count": 4,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2023-06-28T21:36:00.000Z",
        "voteCount": 14,
        "content": "AC is the answer.\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/content-moderator/text-moderation-api\nUse Content Moderator's text moderation models to analyze text content, such as chat rooms, discussion boards, chatbots, e-commerce catalogs, and documents.\n\nThe service response includes the following information:\n- Profanity: term-based matching with built-in list of profane terms in various languages\n- Classification: machine-assisted classification into three categories\n- Personal data\n- Auto-corrected text\n- Original text\n- Language"
      },
      {
        "date": "2023-07-08T07:06:00.000Z",
        "voteCount": 3,
        "content": "Gotten this in Jul 2023 exam."
      },
      {
        "date": "2023-09-02T05:08:00.000Z",
        "voteCount": 3,
        "content": "Correct! While A, C belong to Text Moderation\nhttps://learn.microsoft.com/en-us/azure/ai-services/content-moderator/text-moderation-api,\n\nB, E belong to Vision AI\nhttps://learn.microsoft.com/en-us/azure/ai-services/computer-vision/concept-detecting-adult-content#content-flag-definitions"
      },
      {
        "date": "2024-09-09T12:59:00.000Z",
        "voteCount": 1,
        "content": "So, the two product team from Microsoft did not talk to each other and created an inconsistency. Now we have to remember that?!!"
      },
      {
        "date": "2023-05-21T23:12:00.000Z",
        "voteCount": 5,
        "content": "Answer is correct. \nThe reference URL:\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/content-moderator/api-reference"
      },
      {
        "date": "2024-07-14T11:44:00.000Z",
        "voteCount": 1,
        "content": "AC is the answer."
      },
      {
        "date": "2024-06-12T08:15:00.000Z",
        "voteCount": 2,
        "content": "AC is answer."
      },
      {
        "date": "2024-04-26T20:02:00.000Z",
        "voteCount": 2,
        "content": "C. Text classification\nA. Personal data\n\nHere's why these two are important:\n\nText classification: This functionality allows the API to analyze the text for potentially harmful content like hate speech, bullying, threats, etc. This is crucial for ensuring a safe and positive environment in your chatbot.\nPersonal data: This helps identify and potentially mask sensitive information like names, addresses, phone numbers, etc., which users might accidentally or intentionally reveal during conversations. This protects user privacy.\nLet's break down the other options:\n\nB. The adult classification score: This functionality is not available in the Text Moderation API. It's likely part of the Content Moderator's Image Moderation API for identifying inappropriate visuals.\nD. Optical character recognition (OCR): This is not relevant for text-based chatbots as OCR deals with converting images containing text into machine-readable format.\nE. The racy classification score: Similar to adult classification score, this functionality is likely intended for image moderation and not directly applicable to text analysis."
      },
      {
        "date": "2024-02-03T04:58:00.000Z",
        "voteCount": 1,
        "content": "The appropriate service responses for content moderation using the Text Moderation API of Content Moderator are:\n\nA. Personal Data and C. Text Classification.\n\nThese features help identify sensitive information and categorize text content based on its potential appropriateness, including detecting profanity, personal data, and classifying text into categories related to potentially undesired content\u200b\n\nPLEASE DO NOT SELECT A,C!!!"
      },
      {
        "date": "2023-11-05T07:28:00.000Z",
        "voteCount": 1,
        "content": "Based on the official documentation correct answer seems to be AC\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/content-moderator/text-moderation-api"
      },
      {
        "date": "2023-06-10T17:30:00.000Z",
        "voteCount": 3,
        "content": "answer is correct:\nhttps://westus.dev.cognitive.microsoft.com/docs/services/57cf753a3f9b070c105bd2c1/operations/57cf753a3f9b070868a1f66f\n\nrequest parameters: PII and classify"
      },
      {
        "date": "2023-06-06T02:31:00.000Z",
        "voteCount": 2,
        "content": "answer is correct:\nhttps://westus.dev.cognitive.microsoft.com/docs/services/57cf753a3f9b070c105bd2c1/operations/57cf753a3f9b070868a1f66f\n\nrequest parameters: PII and classify"
      },
      {
        "date": "2023-05-31T01:22:00.000Z",
        "voteCount": 4,
        "content": "Based on the information from the official Azure Cognitive Services documentation, it seems that the Text Moderation API indeed returns profanity terms and personal data (A), which can be used for content moderation. It also performs text classification (C), which can be used to categorize and filter content.\n\nSo, the correct answers according to the official Azure documentation are A. personal data and C. text classification."
      },
      {
        "date": "2023-05-29T19:45:00.000Z",
        "voteCount": 1,
        "content": "Image Moderation API\n\nScan images and detect potential adult and racy content by using tags, confidence scores, and other extracted information.\t\n\nText Moderation API\n\nScan text content. Profanity terms and personal data are returned."
      },
      {
        "date": "2023-05-01T06:33:00.000Z",
        "voteCount": 4,
        "content": "B. the adult classification score\nE. the racy classification score\n\nTo enable content moderation in a text-based chatbot using the Text Moderation API of Content Moderator, you should use the adult classification score (B) and the racy classification score (E). These scores will help you determine if the content is adult or racy in nature, enabling you to take appropriate action for moderation purposes."
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 46,
    "url": "https://www.examtopics.com/discussions/microsoft/view/112136-exam-ai-102-topic-3-question-48-discussion/",
    "body": "HOTSPOT<br> -<br><br>You are developing a text processing solution.<br><br>You have the function shown below.<br><br><img src=\"https://img.examtopics.com/ai-102/image52.png\"><br><br>For the second argument, you call the function and specify the following string.<br><br>Our tour of Paris included a visit to the Eiffel Tower<br><br>For each of the following statements, select Yes if the statement is true. Otherwise, select No.<br><br><img src=\"https://img.examtopics.com/ai-102/image53.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/ai-102/image54.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2023-07-17T01:38:00.000Z",
        "voteCount": 26,
        "content": "Should be NYN:\n\nhttps://learn.microsoft.com/en-us/dotnet/api/azure.ai.textanalytics.textanalyticsclient.recognizeentities?view=azure-dotnet\n\nDefinition:\nRuns a predictive model to identify a collection of named entities in the passed-in document, and categorize those entities into types such as person, location, or organization.\n\nThis method does not extract phrases."
      },
      {
        "date": "2023-11-05T07:42:00.000Z",
        "voteCount": 6,
        "content": "Agree with you. Particularly for the last point we are using the RecognizeEntities method that is used for NER purposes. And the we loop in to the list of entities.\nhttps://github.com/Azure/azure-sdk-for-net/blob/main/sdk/textanalytics/Azure.AI.TextAnalytics/samples/Sample4_RecognizeEntities.md\n\nFor Key-Phrase extraction there is another method \"ExtractKeyPhrases\"\nhttps://github.com/Azure/azure-sdk-for-net/blob/main/sdk/textanalytics/Azure.AI.TextAnalytics/samples/Sample3_ExtractKeyPhrases.md\n\nfor key-phrases"
      },
      {
        "date": "2023-09-12T04:37:00.000Z",
        "voteCount": 1,
        "content": "The last one is clear \"Will output all key phrases on the console\" and we have on the example Console.WriteLine($\"\\t{entity.text}\") - With (\\t) tabs"
      },
      {
        "date": "2023-09-02T05:34:00.000Z",
        "voteCount": 3,
        "content": "Correct! Examples:\nOutput NER: trip, Seattle, last week\nhttps://learn.microsoft.com/en-us/azure/ai-services/language-service/named-entity-recognition/quickstart?tabs=ga-api&amp;pivots=programming-language-csharp#output\n\nOutput Key phrase extraction: modern medical office, Dr. Smith, great staff\nhttps://learn.microsoft.com/en-us/azure/ai-services/language-service/key-phrase-extraction/quickstart?pivots=programming-language-csharp#output"
      },
      {
        "date": "2023-07-01T06:51:00.000Z",
        "voteCount": 11,
        "content": "NYY is the answer.\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/language-service/named-entity-recognition/overview\nNamed Entity Recognition (NER) is one of the features offered by Azure Cognitive Service for Language, a collection of machine learning and AI algorithms in the cloud for developing intelligent applications that involve written language. The NER feature can identify and categorize entities in unstructured text. For example: people, places, organizations, and quantities."
      },
      {
        "date": "2024-03-08T21:56:00.000Z",
        "voteCount": 5,
        "content": "But entities are not the same as key phrases. A key phrase here could be 'Tour of Paris' which doesn't coincide with the entities. So I think the last one should be N."
      },
      {
        "date": "2024-04-09T15:09:00.000Z",
        "voteCount": 1,
        "content": "https://learn.microsoft.com/en-us/azure/ai-services/language-service/named-entity-recognition/quickstart?tabs=ga-api&amp;pivots=programming-language-csharp\nExample output shows \"last week\" as text output:\n\nNamed Entities:\n        Text: trip,     Category: Event,        Sub-Category:\n                Score: 0.74,    Length: 4,      Offset: 18\n\n        Text: Seattle,  Category: Location,     Sub-Category: GPE\n                Score: 1.00,    Length: 7,      Offset: 26\n\n        Text: **last week**,        Category: DateTime,     Sub-Category: DateRange"
      },
      {
        "date": "2024-09-09T13:08:00.000Z",
        "voteCount": 1,
        "content": "I'm not sure if it is going to be Eiffel and Tower or just \"Eiffel Tower\""
      },
      {
        "date": "2024-09-09T13:15:00.000Z",
        "voteCount": 1,
        "content": "On closer look at this trick (e.v.i.l) question, I will answer No for Eiffel and Tower as separate. \nUnder location there is : \nStructural - Manmade structures - en (supported language)\n\nSo, I assume the question creator read this and thought it can be used to trick people"
      },
      {
        "date": "2024-08-30T09:27:00.000Z",
        "voteCount": 2,
        "content": "I beleive NNN. Second is N because it will output two keys, not three."
      },
      {
        "date": "2024-08-30T09:32:00.000Z",
        "voteCount": 1,
        "content": "i get back to it: You're correct. Based on the given C# code using TextAnalyticsClient and the provided input string, the output would indeed include the words \"Paris\", \"Eiffel\", and \"Tower\". Let's break this down:\n\nThe function getkeywords takes a TextAnalyticsClient and a string as input.\nIt uses the RecognizeEntities method (note: there's a typo in the original code; it should be RecognizeEntities, not RecognizeEntitites) to analyze the text.\nThe input string is: \"Our tour of Paris included a visit to the Eiffel Tower\"\nThe TextAnalyticsClient's entity recognition would identify named entities in this text.\n\"Paris\" is recognized as a location entity.\n\"Eiffel Tower\" is recognized as a landmark entity, which would be split into two separate entities: \"Eiffel\" and \"Tower\"."
      },
      {
        "date": "2024-09-09T13:19:00.000Z",
        "voteCount": 1,
        "content": "Why will they be split. Eiffel tower is identified as a man-made structure under location-structural."
      },
      {
        "date": "2024-08-12T21:20:00.000Z",
        "voteCount": 1,
        "content": "Must be N-Y-N, these are named entities"
      },
      {
        "date": "2024-08-06T19:07:00.000Z",
        "voteCount": 3,
        "content": "It should be NNN\n\nAccording to ChatGPT\n\nKey words:\n\tParis\n\tEiffel Tower"
      },
      {
        "date": "2024-05-29T05:46:00.000Z",
        "voteCount": 3,
        "content": "No\nYes\nNo"
      },
      {
        "date": "2024-05-24T03:44:00.000Z",
        "voteCount": 3,
        "content": "on exam, NYN. For the last one I selected N because the method looks like it's extracting entities, not key phrases."
      },
      {
        "date": "2024-05-22T08:09:00.000Z",
        "voteCount": 2,
        "content": "NYN is right answer."
      },
      {
        "date": "2024-03-30T12:15:00.000Z",
        "voteCount": 2,
        "content": "The function will output all the key phrases from the input string to the console. No, the function will output the recognized entities, not all key phrases. Key phrases could include other important words or phrases in the text that are not necessarily entities. For key phrase extraction, a different method would be used."
      },
      {
        "date": "2024-03-19T06:14:00.000Z",
        "voteCount": 2,
        "content": "For the last choice that seems to be a topic of dicussion \nConsole Output:\nThe code prints the header \u201cKey words:\u201d to the console.\nIt then iterates through the response.Value (presumably a collection of categorized entites"
      },
      {
        "date": "2024-01-08T05:27:00.000Z",
        "voteCount": 2,
        "content": "Agree NYN"
      },
      {
        "date": "2023-10-19T00:41:00.000Z",
        "voteCount": 1,
        "content": "I think NYY.  I could not see where all keywords would be output, but after checking the documentation they would also be identified as entities along with the Eiffel Tower (tour, paris and visit)"
      },
      {
        "date": "2023-06-14T01:05:00.000Z",
        "voteCount": 1,
        "content": "It is true."
      },
      {
        "date": "2024-06-21T23:01:00.000Z",
        "voteCount": 2,
        "content": "not sure why this guy writes 'it is true' for all questions!!!"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 47,
    "url": "https://www.examtopics.com/discussions/microsoft/view/112137-exam-ai-102-topic-3-question-49-discussion/",
    "body": "HOTSPOT<br> -<br><br>You are building an Azure web app named App1 that will translate text from English to Spanish.<br><br>You need to use the Text Translation REST API to perform the translation. The solution must ensure that you have data sovereignty in the United States.<br><br>How should you complete the URI? To answer, select the appropriate options in the answer area.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/ai-102/image55.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/ai-102/image56.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2023-07-01T06:48:00.000Z",
        "voteCount": 28,
        "content": "1. api-nam.cognitive.microsofttranslator.com\n2. translate\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/Translator/reference/v3-0-reference#base-urls\nRequests to Translator are, in most cases, handled by the datacenter that is closest to where the request originated. If there's a datacenter failure when using the global endpoint, the request may be routed outside of the geography.\n\nTo force the request to be handled within a specific geography, use the desired geographical endpoint. All requests are processed among the datacenters within the geography.\n- United States\napi-nam.cognitive.microsofttranslator.com\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/translator/reference/rest-api-guide\n- translate\nTranslate specified source language text into the target language text."
      },
      {
        "date": "2023-11-08T09:42:00.000Z",
        "voteCount": 1,
        "content": "Thank you for your valuable contribution."
      },
      {
        "date": "2023-11-05T07:46:00.000Z",
        "voteCount": 1,
        "content": "thanks for your contribution"
      },
      {
        "date": "2024-06-06T06:44:00.000Z",
        "voteCount": 1,
        "content": "1. api-nam.cognitive.microsofttranslator.com\n2. translate"
      },
      {
        "date": "2024-05-22T08:08:00.000Z",
        "voteCount": 3,
        "content": "api-nam.cognitive.microsofttranslator.com\ntranslate"
      },
      {
        "date": "2024-05-14T02:43:00.000Z",
        "voteCount": 1,
        "content": "Why not api-nam.cognitiveservice.azure.com/translate?"
      },
      {
        "date": "2024-02-03T05:01:00.000Z",
        "voteCount": 3,
        "content": "nam=North America"
      },
      {
        "date": "2023-11-27T07:24:00.000Z",
        "voteCount": 1,
        "content": "The response is correct\n1. api-nam.cognitive.microsofttranslator.com\n2. translate"
      },
      {
        "date": "2023-06-14T01:09:00.000Z",
        "voteCount": 2,
        "content": "It is true."
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 48,
    "url": "https://www.examtopics.com/discussions/microsoft/view/112140-exam-ai-102-topic-3-question-50-discussion/",
    "body": "DRAG DROP<br> -<br><br>You have a Docker host named Host1 that contains a container base image.<br><br>You have an Azure subscription that contains a custom speech-to-text model named model1.<br><br>You need to run model1 on Host1.<br><br>Which three actions should you perform in sequence? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.<br><br><img src=\"https://img.examtopics.com/ai-102/image57.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/ai-102/image58.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2023-07-01T06:44:00.000Z",
        "voteCount": 29,
        "content": "1. Request approval to run container\n2. Export model1 to Host1\n3. Run the container\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/speech-service/speech-container-stt?tabs=container&amp;pivots=programming-language-csharp"
      },
      {
        "date": "2024-03-08T22:15:00.000Z",
        "voteCount": 3,
        "content": "Okay, this link provides more information about the approval step, but approval is only necessary when you run the container in a disconnected environment. So if that is mentioned in a question, choosing this step will make more sense.\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/speech-service/speech-container-overview#request-approval-to-run-the-container"
      },
      {
        "date": "2023-06-14T01:12:00.000Z",
        "voteCount": 8,
        "content": "No.\n1.Export model1 to Host1. \n2.Request approval to run the container. \n3.Run the container."
      },
      {
        "date": "2024-05-29T05:43:00.000Z",
        "voteCount": 3,
        "content": "you are no.\n1. Request approval to run container\n2. Export model1 to Host1\n3. Run the container"
      },
      {
        "date": "2024-09-17T08:13:00.000Z",
        "voteCount": 2,
        "content": "yes you are yes to the no"
      },
      {
        "date": "2024-09-09T13:25:00.000Z",
        "voteCount": 1,
        "content": "Maybe the question creator was in a hurry (they always are) and saw only the documentation that said there needs to be approval (but it was for disconnected and even though this is not disconnected). Or maybe the question from ET missed disconnected keyword."
      },
      {
        "date": "2024-07-15T12:11:00.000Z",
        "voteCount": 1,
        "content": "1. Request approval to run container\n2. Export model1 to Host1\n3. Run the container"
      },
      {
        "date": "2024-06-14T13:39:00.000Z",
        "voteCount": 4,
        "content": "this is the answer from Copilot:\n\nTo run the custom speech-to-text model on your Docker host, you should perform the following actions in sequence:\n\nExport model to Host1: You need to export the model from Azure to your Docker host. This typically involves downloading the model and moving it to the Docker host.\n\nRun the container: Once the model is on the Docker host, you can run the container that uses this model.\n\nConfigure disk logging: After the container is running, configure disk logging to keep track of the container's activities and to troubleshoot any issues that might arise."
      },
      {
        "date": "2024-05-22T08:02:00.000Z",
        "voteCount": 1,
        "content": "Request\nExport\nRun"
      },
      {
        "date": "2023-11-05T07:56:00.000Z",
        "voteCount": 2,
        "content": "Probably here we are requested to run the container in a disconnected environmnet so i think correct answer is :\n\nRequest approval to run container\nExport model1 to Host1\nRun the container\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/containers/disconnected-containers"
      },
      {
        "date": "2023-10-14T16:38:00.000Z",
        "voteCount": 3,
        "content": "You only need to request approval if you plan to run the container in a completely disconnected environment. And you might not get approved at all as there are some requirements. The question does not indicate if we need to run the container in such a environment."
      },
      {
        "date": "2023-10-14T16:46:00.000Z",
        "voteCount": 2,
        "content": "Based on what you can choose here I would say it\u2019s a disconnected environment. For a connected environment using docker run allows you to download the model at the same so there is no need to export the model manually and then copy it to the host. Zellck is right in the choices."
      },
      {
        "date": "2023-09-02T10:19:00.000Z",
        "voteCount": 1,
        "content": "https://learn.microsoft.com/en-us/azure/ai-services/speech-service/speech-container-cstt?tabs=custom-model%2Ccontainer&amp;pivots=programming-language-csharp\nIn this article, you'll learn how to download [from Microsoft Container Registry (MCR)], install, and run a Custom speech to text container.\nGet the model ID (to use as the argument to the ModelId parameter of the docker run command): The custom model has to have been trained by using the Speech Studio.\nN/a so far, excluding A (Retrain the model)."
      },
      {
        "date": "2023-09-02T06:41:00.000Z",
        "voteCount": 2,
        "content": "Run the container with docker run:\nB (Request approval precedes),\nThe docker run command will start the container when all three of the following options are provided with valid values: ApiKey, Billing, EULA\nhttps://learn.microsoft.com/en-us/azure/ai-services/speech-service/speech-container-howto#billing-arguments\n\nD (Run container), C (Get model)\nHere's an example docker run command with placeholder values. \u2026 This command:\n\u2022\tRuns a custom speech to text container from the container image.\n\u2022\tAllocates 4 CPU cores and 8 GB of memory.\n\u2022\tLoads the custom speech to text model from the volume input mount, for example, C:\\CustomSpeech.\n\u2022\tExposes TCP port 5000 and allocates a pseudo-TTY for the container.\n\u2022\tDownloads the model given the ModelId (if not found on the volume mount)."
      },
      {
        "date": "2023-06-25T22:16:00.000Z",
        "voteCount": 1,
        "content": "Not sure.\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/speech-service/speech-container-overview#request-approval-to-run-the-container"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 49,
    "url": "https://www.examtopics.com/discussions/microsoft/view/112141-exam-ai-102-topic-3-question-51-discussion/",
    "body": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.<br><br>After you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.<br><br>You build a language model by using a Conversational Language Understanding. The language model is used to search for information on a contact list by using an intent named FindContact.<br><br>A conversational expert provides you with the following list of phrases to use for training.<br><br>\u2022\tFind contacts in London.<br>\u2022\tWho do I know in Seattle?<br>\u2022\tSearch for contacts in Ukraine.<br><br>You need to implement the phrase list in Conversational Language Understanding.<br><br>Solution: You create a new utterance for each phrase in the FindContact intent.<br><br>Does this meet the goal?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tYes\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tNo"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 15,
        "isMostVoted": true
      },
      {
        "answer": "B",
        "count": 11,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2024-02-03T05:23:00.000Z",
        "voteCount": 10,
        "content": "A. Yes\n\nCreating a new utterance for each phrase in the FindContact intent is a correct approach to implement the phrase list in Conversational Language Understanding. This method trains the language model to recognize variations of how users might express the intent to find contacts in different locations, thereby improving the model's accuracy in identifying the FindContact intent."
      },
      {
        "date": "2024-02-03T05:25:00.000Z",
        "voteCount": 1,
        "content": "Yes, creating a new utterance for each phrase in the FindContact intent aligns with the recommended practice for designing applications in Conversational Language Understanding, as detailed in the documentation. This approach helps in accurately capturing the intent by providing diverse examples of how users might express their request, thus enhancing the model's ability to understand and classify user queries correctly. For more detailed guidelines, refer to the section on creating example utterances for each intent in the documentation"
      },
      {
        "date": "2024-07-12T08:06:00.000Z",
        "voteCount": 2,
        "content": "Selected Answer: B"
      },
      {
        "date": "2024-06-23T02:45:00.000Z",
        "voteCount": 1,
        "content": "A is the correct answer"
      },
      {
        "date": "2024-06-21T23:16:00.000Z",
        "voteCount": 1,
        "content": "it is B"
      },
      {
        "date": "2024-06-15T08:02:00.000Z",
        "voteCount": 2,
        "content": "This issue is not working because everyone's opinion is 50-50. I don't know the correct answer, so I will be staring at MS Learn when this question comes up on the real exam.Examtopic should scrutinize and post the correct answer."
      },
      {
        "date": "2024-06-15T08:02:00.000Z",
        "voteCount": 1,
        "content": "This issue is not working because everyone's opinion is 50-50. I don't know the correct answer, so I will be staring at MS Learn when this question comes up on the real exam. Examtopic should scrutinize and post the correct answer."
      },
      {
        "date": "2024-05-24T08:21:00.000Z",
        "voteCount": 2,
        "content": "It MUST be A."
      },
      {
        "date": "2024-02-07T10:36:00.000Z",
        "voteCount": 3,
        "content": "According to Windows Copilot: B. No\n\nCreating a new utterance for each phrase in the FindContact intent is not the most efficient approach. Instead, you can use phrase lists in Conversational Language Understanding (LUIS) to group similar phrases together. By defining a phrase list, you can handle variations of the same intent more effectively. In this case, you can create a phrase list containing the cities (London, Seattle, Ukraine) and use it within the FindContact intent. This way, LUIS will recognize any variation of these cities as part of the same intent without creating individual utterances for each location. \ud83d\ude0a"
      },
      {
        "date": "2024-06-04T06:25:00.000Z",
        "voteCount": 2,
        "content": "LUIS is deprecated, CLU will handle creating a new utterance for each phrase"
      },
      {
        "date": "2024-02-05T13:19:00.000Z",
        "voteCount": 2,
        "content": "According to ChatGPT:\nB. No\n\nExplanation: While creating a new utterance for each phrase in the FindContact intent is a step in the right direction, it may not be sufficient to fully meet the goal. To effectively implement the phrase list in Conversational Language Understanding, it's essential to consider variations in how users might express the same intent. The provided phrases cover different scenarios (finding contacts in different locations), but there may be additional variations and nuances to consider. Therefore, merely creating a new utterance for each provided phrase might not capture all possible ways users could express the intent to find contacts. A more comprehensive approach to training the language model might involve incorporating synonyms, alternative phrasings, and potential variations that users might use when searching for contacts."
      },
      {
        "date": "2024-01-06T11:35:00.000Z",
        "voteCount": 2,
        "content": "It's \"Yes\" actually, not the more efficient way to do it, but it will work"
      },
      {
        "date": "2023-11-05T08:12:00.000Z",
        "voteCount": 1,
        "content": "B. No\n\nCreating a new utterance for each phrase in the FindContact intent is not the most efficient approach for implementing the provided phrase list. Instead, you should use phrase list features or entities to capture variations of these phrases more effectively.\n\nIn Conversational Language Understanding, you can define a phrase list or entity that includes variations of location names like \"London,\" \"Seattle,\" and \"Ukraine.\" By doing this, you allow the model to recognize these location names as entities, making your intent more flexible and capable of handling variations. This approach is much more scalable and less labor-intensive than creating individual utterances for each location.\n\nThe goal should be met by using phrase lists or entities effectively to capture variations in the input data and improve the model's performance. (ChatGPT)"
      },
      {
        "date": "2024-01-06T11:33:00.000Z",
        "voteCount": 2,
        "content": "It won't be efficient but it will do the job, I would vote for \"Yes\""
      },
      {
        "date": "2023-10-14T17:00:00.000Z",
        "voteCount": 1,
        "content": "I picked B because you need the entity to retrieve the location from the utterances for you app to be able to know which contacts to retrieve from the store."
      },
      {
        "date": "2023-10-14T17:03:00.000Z",
        "voteCount": 1,
        "content": "The utterances provided are different enough. But if your picky and insist that you should have at least 15 utterances that you would pick B anyway."
      },
      {
        "date": "2023-06-28T20:40:00.000Z",
        "voteCount": 3,
        "content": "B is the answer.\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/luis/concepts/application-design#create-example-utterances-for-each-intent\nTo start, avoid creating too many utterances for each intent. Once you have determined the intents you need for your app, create 15 to 30 example utterances per intent. Each utterance should be different from the previously provided utterances. Include a variety of word counts, word choices, verb tenses, and punctuation."
      },
      {
        "date": "2023-06-14T01:13:00.000Z",
        "voteCount": 1,
        "content": "B. Same question."
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 50,
    "url": "https://www.examtopics.com/discussions/microsoft/view/112143-exam-ai-102-topic-3-question-52-discussion/",
    "body": "DRAG DROP<br> -<br><br>You have a question answering project in Azure Cognitive Service for Language.<br><br>You need to move the project to a Language service instance in a different Azure region.<br><br>Which three actions should you perform in sequence? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.<br><br><img src=\"https://img.examtopics.com/ai-102/image59.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/ai-102/image60.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2023-07-01T06:41:00.000Z",
        "voteCount": 29,
        "content": "1. From original instance, export existing project.\n2. From new instance, import the project file.\n3. From new instance, train and publish model.\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/language-service/question-answering/how-to/migrate-knowledge-base"
      },
      {
        "date": "2024-07-15T12:12:00.000Z",
        "voteCount": 1,
        "content": "1. From original instance, export existing project.\n2. From new instance, import the project file.\n3. From new instance, train and publish model."
      },
      {
        "date": "2024-06-24T17:07:00.000Z",
        "voteCount": 2,
        "content": "Got this in the exam, Jun 2024."
      },
      {
        "date": "2024-05-29T05:36:00.000Z",
        "voteCount": 3,
        "content": "1. From original instance, export existing project.\n2. From new instance, import the project file.\n3. From new instance, train and publish model."
      },
      {
        "date": "2024-05-22T07:57:00.000Z",
        "voteCount": 2,
        "content": "original, export existing project.\nnew, import the project file.\nnew, train and publish model."
      },
      {
        "date": "2024-02-03T05:27:00.000Z",
        "voteCount": 1,
        "content": "Answer is correct\nfirst from the source instance, export the source project;\nat the new instance, import the exported source project;\nto deploy, one has to train and publish the model from imported project, the training is needed before the model can work in new project from different Azure region"
      },
      {
        "date": "2023-11-05T08:20:00.000Z",
        "voteCount": 3,
        "content": "the answer seems correct:\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/language-service/question-answering/how-to/migrate-knowledge-base\nhttps://learn.microsoft.com/en-us/azure/ai-services/qnamaker/quickstarts/create-publish-knowledge-base#publish-the-knowledge-base"
      },
      {
        "date": "2023-06-14T01:18:00.000Z",
        "voteCount": 2,
        "content": "It is true."
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 51,
    "url": "https://www.examtopics.com/discussions/microsoft/view/112145-exam-ai-102-topic-3-question-53-discussion/",
    "body": "DRAG DROP<br> -<br><br>You are building a customer support chatbot.<br><br>You need to configure the bot to identify the following:<br><br>\u2022\tCode names for internal product development<br>\u2022\tMessages that include credit card numbers<br><br>The solution must minimize development effort.<br><br>Which Azure Cognitive Service for Language feature should you use for each requirement? To answer, drag the appropriate features to the correct requirements. Each feature may be used once, more than once, or not at all. You may need to drag the split bar between panes or scroll to view content.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/ai-102/image61.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/ai-102/image62.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2023-07-01T06:33:00.000Z",
        "voteCount": 21,
        "content": "1. Custom NER\n2. PII detection\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/language-service/custom-named-entity-recognition/overview\nCustom NER enables users to build custom AI models to extract domain-specific entities from unstructured text, such as contracts or financial documents. By creating a Custom NER project, developers can iteratively label data, train, evaluate, and improve model performance before making it available for consumption. The quality of the labeled data greatly impacts model performance.\n\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/language-service/personally-identifiable-information/overview\nPII detection is one of the features offered by Azure Cognitive Service for Language, a collection of machine learning and AI algorithms in the cloud for developing intelligent applications that involve written language. The PII detection feature can identify, categorize, and redact sensitive information in unstructured text. For example: phone numbers, email addresses, and forms of identification."
      },
      {
        "date": "2023-11-05T08:23:00.000Z",
        "voteCount": 5,
        "content": "thank you for your great contribution"
      },
      {
        "date": "2024-08-14T20:42:00.000Z",
        "voteCount": 1,
        "content": "1. Custom NER\n2. PII detection"
      },
      {
        "date": "2024-07-06T03:28:00.000Z",
        "voteCount": 1,
        "content": "NER + PII"
      },
      {
        "date": "2024-08-14T20:42:00.000Z",
        "voteCount": 1,
        "content": "It's custom NER"
      },
      {
        "date": "2024-06-21T08:59:00.000Z",
        "voteCount": 2,
        "content": "1. Custom NER\n2. PII"
      },
      {
        "date": "2024-05-22T07:55:00.000Z",
        "voteCount": 1,
        "content": "NER and PII."
      },
      {
        "date": "2023-06-16T03:55:00.000Z",
        "voteCount": 2,
        "content": "seems correct.\nhttps://learn.microsoft.com/en-us/azure/cognitive-services/language-service/overview"
      },
      {
        "date": "2023-06-14T01:41:00.000Z",
        "voteCount": 2,
        "content": "It is true."
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 52,
    "url": "https://www.examtopics.com/discussions/microsoft/view/123329-exam-ai-102-topic-3-question-54-discussion/",
    "body": "HOTSPOT<br> -<br><br>You are building an app by using the Speech SDK. The app will translate speech from French to German by using natural language processing.<br><br>You need to define the source language and the output language.<br><br>How should you complete the code? To answer, select the appropriate options in the answer area.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/ai-102/image72.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/ai-102/image73.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-05-29T05:20:00.000Z",
        "voteCount": 9,
        "content": "SpeechRecognitionLanguage = \"fr\"\nAddTargetLanguage.(\"de\")"
      },
      {
        "date": "2024-09-09T13:38:00.000Z",
        "voteCount": 1,
        "content": "e.v.i.l question. \n\nA person who worked with it will go fast and select recognition and synthesis as the answer. But Microsoft made the second one a function call and with their bad naming convention added a new term \"targetLanguage\". Now you have to remember that mistake of Microsoft"
      },
      {
        "date": "2024-06-06T06:43:00.000Z",
        "voteCount": 2,
        "content": "Sample answers are correct."
      },
      {
        "date": "2024-03-29T20:39:00.000Z",
        "voteCount": 2,
        "content": "Las respuestas son B y C"
      },
      {
        "date": "2024-02-04T02:48:00.000Z",
        "voteCount": 2,
        "content": "correct"
      },
      {
        "date": "2023-11-05T08:24:00.000Z",
        "voteCount": 4,
        "content": "correct"
      },
      {
        "date": "2023-10-11T15:17:00.000Z",
        "voteCount": 4,
        "content": "Answer is correct"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 53,
    "url": "https://www.examtopics.com/discussions/microsoft/view/123688-exam-ai-102-topic-3-question-55-discussion/",
    "body": "DRAG DROP<br> -<br><br>You have a collection of Microsoft Word documents and PowerPoint presentations in German.<br><br>You need to create a solution to translate the files to French. The solution must meet the following requirements:<br><br>\u2022\tPreserve the original formatting of the files.<br>\u2022\tSupport the use of a custom glossary.<br><br>You create a blob container for German files and a blob container for French files. You upload the original files to the container for German files.<br><br>Which three actions should you perform in sequence to complete the solution? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.<br><br><img src=\"https://img.examtopics.com/ai-102/image74.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/ai-102/image75.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2023-11-05T08:47:00.000Z",
        "voteCount": 16,
        "content": "IMHO the answer is:\n\n1. Upload a Glossary file to the french files container\n2. Define a document translation specification that has french target\n3. Perform asynchronous translation by using the document specification\n\nAs you can see below the glossary is needed before the translation:\nhttps://learn.microsoft.com/en-us/azure/ai-services/translator/document-translation/how-to-guides/create-use-glossaries\n\nAnd DocumentTranslationInput is the class we can use for the translation:\n\nhttps://learn.microsoft.com/en-us/python/api/azure-ai-translation-document/azure.ai.translation.document.documenttranslationinput?view=azure-python"
      },
      {
        "date": "2024-07-27T11:03:00.000Z",
        "voteCount": 2,
        "content": "15 upvotes and they're all wrong."
      },
      {
        "date": "2024-08-06T19:36:00.000Z",
        "voteCount": 1,
        "content": "1. Upload a Glossary file to the french files container\n2. Define a document translation specification that has french target\n3. Perform asynchronous translation by using the document specification\n\nThis is the answer according to ChatGPT.\nWhy not Glossary file in German container? Glossary contains the specific terms for the TARGET language. French in this case. So it make sense to keep it in French file \ncontainer"
      },
      {
        "date": "2024-06-30T07:04:00.000Z",
        "voteCount": 1,
        "content": "I think that correct is the original response, Because the glossary file is to be in the source language. On the URL : https://learn.microsoft.com/en-us/azure/ai-services/translator/document-translation/how-to-guides/create-use-glossaries gives an example of english to french and in session \nCreate, upload, and use a glossary file says : ... \"The following English-source glossary contains words that can have different meanings depending upon the context in which they're used\". So the glossary needs to be in the source language and not in the target language. So the answer is\n1. Upload a glossary file to the container for German files\n2. Define a document translation specification with French as the target language\n3. Perform an asynchronous translation by using the document translation specification\nPs.: I tested on chatGPT and the response goes to the same."
      },
      {
        "date": "2024-09-09T23:39:00.000Z",
        "voteCount": 1,
        "content": "The glossary file is in both languages, please !!!\nThe question is which container to put it in. It can be in any container and probably in a different container than source or target. If possible contest the question itself if you see this same question"
      },
      {
        "date": "2024-06-21T23:36:00.000Z",
        "voteCount": 1,
        "content": "was on exam 20.06.24"
      },
      {
        "date": "2024-06-13T03:39:00.000Z",
        "voteCount": 1,
        "content": "curl -X POST \"https://&lt;your-region&gt;.cognitiveservices.azure.com/translator/text/batch/v1.1/translator/document/batches?api-version=2024-05-01\" \\\n-H \"Ocp-Apim-Subscription-Key: &lt;your-subscription-key&gt;\" \\\n-H \"Content-Type: application/json\" \\\n-d &lt;insert JSON document here to specific source, target and glossary&gt;"
      },
      {
        "date": "2024-06-13T03:37:00.000Z",
        "voteCount": 2,
        "content": "{\n    \"inputs\": [\n        {\n            \"source\": {\n                \"sourceUrl\": \"https://&lt;your-storage-account&gt;.blob.core.windows.net/german-files\",\n                \"storageSource\": \"AzureBlob\"\n            },\n            \"targets\": [\n                {\n                    \"targetUrl\": \"https://&lt;your-storage-account&gt;.blob.core.windows.net/french-files\",\n                    \"storageSource\": \"AzureBlob\",\n                    \"language\": \"fr\",\n                    \"glossaries\": [\n                        {\n                            \"glossaryUrl\": \"https://&lt;your-storage-account&gt;.blob.core.windows.net/glossaries/de-fr-glossary.tsv\",\n                            \"format\": \"TSV\"\n                        }\n                    ]\n                }\n            ]\n        }\n    ]\n}"
      },
      {
        "date": "2024-09-09T23:40:00.000Z",
        "voteCount": 1,
        "content": "Look, their own example put it in a different container"
      },
      {
        "date": "2024-05-22T14:46:00.000Z",
        "voteCount": 1,
        "content": "Well, reality is that in MS example glossary in own container. But it is also in \"targets\" section of json file, so answer  \"French container\" probably safer."
      },
      {
        "date": "2024-09-09T23:41:00.000Z",
        "voteCount": 1,
        "content": "wow, people working with are very creative finding some logic in this illogical Microsoft question"
      },
      {
        "date": "2024-05-22T07:42:00.000Z",
        "voteCount": 2,
        "content": "1. Upload a Glossary file to the french files container\n2. Define a document translation specification that has french target\n3. Perform asynchronous translation by using the document specification"
      },
      {
        "date": "2024-02-03T17:48:00.000Z",
        "voteCount": 3,
        "content": "The given answer is correct : reason is below \nUpload the terminology list: Begin by uploading a custom terminology list, essential for accurate translations. Ensure it's placed in a location recognized by the translation service.\n\nDefine translation specifications: Specify source (German), target (French), and any special parameters in a translation specification.\n\nExecute asynchronous translation: Initiate the translation process based on the specification, which will preserve original formatting and save translated files in the French document container.\n\nThese three steps form the core of the solution, although practical implementation may require additional configuration and permissions. Ensure the terminology list is uploaded to a location compatible with the translation service's requirements."
      },
      {
        "date": "2024-01-08T06:47:00.000Z",
        "voteCount": 1,
        "content": "You need a French Glossary in the French container - how else can the translator know the French Jargon"
      },
      {
        "date": "2024-09-09T23:42:00.000Z",
        "voteCount": 1,
        "content": "It can be in any container. Why do you need it in any specific container?"
      },
      {
        "date": "2023-10-15T11:07:00.000Z",
        "voteCount": 2,
        "content": "The glossary file can be in this own container and that\u2019s tricky as in theory you can put it anywhere. But since we need probably need have different permissions for the source and the target container putting it in the container where the source files would do. Also pay attention to what a glossary file its content looks like and how to specify the location in a request sent to the endpoint. https://learn.microsoft.com/en-us/azure/ai-services/translator/document-translation/how-to-guides/create-use-glossaries"
      },
      {
        "date": "2023-10-15T11:11:00.000Z",
        "voteCount": 1,
        "content": "Although I can\u2019t find the term translation specification file in the doc, but you don\u2019t need to create a list of files that\u2019s for sure (pay attention to how the target and source are specified in the link I provided above."
      },
      {
        "date": "2023-10-15T13:49:00.000Z",
        "voteCount": 3,
        "content": "I changed my mind the glossary file should be in the target folder. Reason for that is because you can have multiple target languages each with its own glossary files.  Remember the glossary provides the expected translation for each word in the file to help ensure accuracy. In other words, you are providing the translation and should have done so for each target language."
      },
      {
        "date": "2024-09-09T23:33:00.000Z",
        "voteCount": 1,
        "content": "You can change your mind every minute but there is no right answer to this. These questions exist because the question creator is not a subject matter expert in translation or AI, but his expertise is in making-questions. He did not understand what is a glossary and understood something weird from what he read and asking us to guess what he thought glossary is. If I know his background I can guess, but without that it is impossible. \nIf questions like this come, raise objections in the exam itself so that you can get points if someone looks at it. And just hope it is someone who knows the subject."
      },
      {
        "date": "2024-09-09T23:37:00.000Z",
        "voteCount": 1,
        "content": "I will not put the glossary either in the source or target but in another container. Why miss the content with the rules? But the people working with Microsoft are hello-world-programmers"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 54,
    "url": "https://www.examtopics.com/discussions/microsoft/view/123659-exam-ai-102-topic-3-question-56-discussion/",
    "body": "You have the following C# function.<br><br><img src=\"https://img.examtopics.com/ai-102/image76.png\"><br><br>You call the function by using the following code.<br><br><img src=\"https://img.examtopics.com/ai-102/image77.png\"><br><br>Which output will you receive?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tThe quick -<br>The lazy",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tthe quick brown fox jumps over the lazy dog",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tjumps over the",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tquick brown fox<br>lazy dog\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 14,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-12-27T22:59:00.000Z",
        "voteCount": 5,
        "content": "I tried it out. D is correct. Key Phrases:\n        quick brown fox\n        lazy dog"
      },
      {
        "date": "2024-07-14T11:46:00.000Z",
        "voteCount": 1,
        "content": "Selected Answer: D"
      },
      {
        "date": "2024-06-21T23:36:00.000Z",
        "voteCount": 1,
        "content": "was on exam 20.06.24"
      },
      {
        "date": "2024-06-12T08:14:00.000Z",
        "voteCount": 1,
        "content": "D is answer."
      },
      {
        "date": "2024-05-29T05:16:00.000Z",
        "voteCount": 1,
        "content": "quick brown fox lazy dog"
      },
      {
        "date": "2024-05-22T07:47:00.000Z",
        "voteCount": 2,
        "content": "Key Phrases are \"quick brown fox\" and \"lazy dog\"."
      },
      {
        "date": "2024-02-03T17:35:00.000Z",
        "voteCount": 1,
        "content": "because the method is to extract \"key Phrases\" so article \"the\" will not be extracted."
      },
      {
        "date": "2023-11-05T08:49:00.000Z",
        "voteCount": 1,
        "content": "the answer seems correct"
      },
      {
        "date": "2023-10-15T07:11:00.000Z",
        "voteCount": 3,
        "content": "Verified the answer using a simple console program"
      },
      {
        "date": "2023-10-15T11:14:00.000Z",
        "voteCount": 4,
        "content": "Tried a couple examples and seems it will pick up the pattern: adjective + noun"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 55,
    "url": "https://www.examtopics.com/discussions/microsoft/view/124687-exam-ai-102-topic-3-question-57-discussion/",
    "body": "You have the following Python method.<br><br><img src=\"https://img.examtopics.com/ai-102/image78.png\"><br><br>You need to deploy an Azure resource to the East US Azure region. The resource will be used to perform sentiment analysis.<br><br>How should you call the method?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tcreate_resource(\"res1\", \"TextAnalytics\", \"Standard\", \"East US\")",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tcreate_resource(\"res1\", \"ContentModerator\", \"S0\", \"eastus\")",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tcreate_resource(\"res1\", \"ContentModerator\", \"Standard\", \"East US\")",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tcreate_resource(\"res1\", \"TextAnalytics\", \"S0\", \"eastus\")\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 6,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-06-22T00:22:00.000Z",
        "voteCount": 1,
        "content": "ComputerVision, F0.\nTextAnalysis, S0."
      },
      {
        "date": "2024-06-16T03:49:00.000Z",
        "voteCount": 1,
        "content": "The correct answer can be found by a process of elimination: \n\n1.  Need to provide reference to correct service -&gt;  Text Analytics\n2.  Need to provide reference to a correct service tier:  S0 or F0\n3. Need to provide reference to a correct name for a computer region: \nUnited States:\n\nEast US: eastus\nEast US 2: eastus2\nCentral US: centralus\nNorth Central US: northcentralus\nSouth Central US: southcentralus\nWest US: westus\nWest US 2: westus2\n\nD is the only answer that captures all these correctly."
      },
      {
        "date": "2024-06-12T08:13:00.000Z",
        "voteCount": 1,
        "content": "redundant question.\nTextAnalytics, S0, eastus"
      },
      {
        "date": "2024-05-22T07:40:00.000Z",
        "voteCount": 1,
        "content": "D is right answer."
      },
      {
        "date": "2024-02-03T17:24:00.000Z",
        "voteCount": 2,
        "content": "In Azure services, \"S0\" represents a pricing tier or service level. For Azure Cognitive Services, including Text Analytics, the pricing tier determines the service's performance, request rate limits, features, and costs. Each pricing tier offers different service capabilities and quotas, and they come with varying price points."
      },
      {
        "date": "2023-11-05T08:51:00.000Z",
        "voteCount": 2,
        "content": "correct"
      },
      {
        "date": "2023-10-26T19:45:00.000Z",
        "voteCount": 1,
        "content": "correct answer"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 56,
    "url": "https://www.examtopics.com/discussions/microsoft/view/122483-exam-ai-102-topic-3-question-58-discussion/",
    "body": "DRAG DROP<br> -<br><br>You develop a Python app named App1 that performs speech-to-speech translation.<br><br>You need to configure App1 to translate English to German.<br><br>How should you complete the SpeechTranslationConfig object? To answer, drag the appropriate values to the correct targets. Each value may be used once, more than once or not at all. You may need to drag the split bar between panes or scroll to view content.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/ai-102/image79.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/ai-102/image80.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2023-10-04T22:39:00.000Z",
        "voteCount": 26,
        "content": "Pretty sure the second one is add_target_language"
      },
      {
        "date": "2023-12-25T05:01:00.000Z",
        "voteCount": 3,
        "content": "you do speech-to-speech. so your output should be voice, but proposed answer is incomplete. You also need to specify the type of voice for the synthesizer"
      },
      {
        "date": "2024-04-29T12:17:00.000Z",
        "voteCount": 2,
        "content": "Agree, the requirement should changed to translate from speech to text, look at the function name"
      },
      {
        "date": "2024-02-03T17:20:00.000Z",
        "voteCount": 16,
        "content": "The answer is WRONG! \nCorrect Answer is below:\ndef translate_speech_to_text():\n    translation_config = speechsdk.translation.SpeechTranslationConfig(subscription=speech_key, region=service_region)\n    translation_config.speech_recognition_language = \"en-US\"\n    translation_config.add_target_language(\"de\")"
      },
      {
        "date": "2024-10-10T15:22:00.000Z",
        "voteCount": 2,
        "content": "There is a distinction between speech-to-speech translation and speech-to-text-to-speech translation. Some questions refer natural language processing (NLP) and this simple mention changes the approach completely. Based on my experience, speech-to-speech translation requires both SpeechRecognitionLanguage and SpeechSynthesisLanguage. However, when performing speech-to-text-to-speech translation\u2014where NLP is implicitly involved, since the speech is first converted to text before translation\u2014you also need to specify the AddTargetLanguage. In this particular case, the answer would be: SpeechRecognitionLanguage and SpeechSynthesisLanguage because there is no mention to NLP."
      },
      {
        "date": "2024-08-12T21:30:00.000Z",
        "voteCount": 1,
        "content": "Repeated question"
      },
      {
        "date": "2024-07-15T12:15:00.000Z",
        "voteCount": 1,
        "content": "1. speech_recognition_language\n2. add_target_language"
      },
      {
        "date": "2024-06-21T08:59:00.000Z",
        "voteCount": 4,
        "content": "1. speech_recognition_language\n2. add_target_language"
      },
      {
        "date": "2024-05-29T05:33:00.000Z",
        "voteCount": 4,
        "content": "speech_recognition_language\nadd_target_language"
      },
      {
        "date": "2024-05-22T07:54:00.000Z",
        "voteCount": 2,
        "content": "It MUST be translation_config.speech_recognition_language = \"en-US\" and translation_config.add_target_language(\"de\").\nWhat exactly have you studied? Memorization is not enough."
      },
      {
        "date": "2024-01-30T10:23:00.000Z",
        "voteCount": 2,
        "content": "Similar with Question #40 (language is C#, not Python)\nI believe it's\n1.translation_config.speech_recognition_value = \"en-us\"\n2.translation_config.add_target_language(\"de\")\nthe second one is a method, not a property, thus the \"add\""
      },
      {
        "date": "2023-12-01T03:00:00.000Z",
        "voteCount": 3,
        "content": "How is it even possible that ET provides us witth SO MANY wrong answers? I agree with rdemontis and jangotango, the second one is add_target_language"
      },
      {
        "date": "2024-02-08T05:46:00.000Z",
        "voteCount": 2,
        "content": "rdemontis should be getting paid"
      },
      {
        "date": "2023-11-05T08:54:00.000Z",
        "voteCount": 3,
        "content": "The second is wrong. it should be add_target_language\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/speech-service/get-started-speech-translation?tabs=windows%2Cterminal&amp;pivots=programming-language-python#translate-speech-from-a-microphone"
      },
      {
        "date": "2023-10-04T22:42:00.000Z",
        "voteCount": 3,
        "content": "Proof - https://learn.microsoft.com/en-us/azure/ai-services/speech-service/get-started-speech-translation?tabs=windows%2Cterminal&amp;pivots=programming-language-python"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 57,
    "url": "https://www.examtopics.com/discussions/microsoft/view/122496-exam-ai-102-topic-3-question-59-discussion/",
    "body": "HOTSPOT<br> -<br><br>You are developing a streaming Speech to Text solution that will use the Speech SDK and MP3 encoding.<br><br>You need to develop a method to convert speech to text for streaming MP3 data.<br><br>How should you complete the code? To answer, select the appropriate options in the answer area.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/ai-102/image81.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/ai-102/image82.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-02-03T17:06:00.000Z",
        "voteCount": 12,
        "content": "first one has to configure the format as MP3, so \"AudioStreamFormat\" option is chosen. Second, since it is speech to text, the SpeechRecognition option is needed.\nThe answer is CORRECT"
      },
      {
        "date": "2024-07-14T11:52:00.000Z",
        "voteCount": 2,
        "content": "1. AudioStreamFormat\n2. SpeechRecognizer"
      },
      {
        "date": "2024-06-22T17:44:00.000Z",
        "voteCount": 1,
        "content": "Same as question 18 in topic 1"
      },
      {
        "date": "2024-06-06T06:43:00.000Z",
        "voteCount": 2,
        "content": "1. AudioStreamFormat\n2. SpeechRecognizer"
      },
      {
        "date": "2024-05-29T05:28:00.000Z",
        "voteCount": 1,
        "content": "AudioStreamFormat\nSpeechRecognizer"
      },
      {
        "date": "2024-05-22T07:52:00.000Z",
        "voteCount": 2,
        "content": "audio_format = speechsdk.audio.AudioStreamFormat(compressed_stream_format=speechsdk.AudioStreamContainerFormat.MP3)\nrecognizer = speechsdk.SpeechRecognizer(speech_config, audio_config)"
      },
      {
        "date": "2024-01-09T04:31:00.000Z",
        "voteCount": 1,
        "content": "this question is same as Topic 1 Q18 but with different answer, which is correct?"
      },
      {
        "date": "2024-03-10T18:21:00.000Z",
        "voteCount": 3,
        "content": "The answers are the same. Both chosen are AudioStreamFormat and SpeechRecognizer, but in question 18 there is an additional method for AudioStreamFormat (GetCompressedFormat)."
      },
      {
        "date": "2023-11-05T08:57:00.000Z",
        "voteCount": 2,
        "content": "correct"
      },
      {
        "date": "2023-10-05T03:49:00.000Z",
        "voteCount": 4,
        "content": "Answer correct\nhttps://github.com/Azure-Samples/cognitive-services-speech-sdk/blob/master/samples/python/console/speech_sample.py"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 58,
    "url": "https://www.examtopics.com/discussions/microsoft/view/134937-exam-ai-102-topic-3-question-60-discussion/",
    "body": "HOTSPOT<br> -<br><br>You are building a chatbot.<br><br>You need to use the Content Moderator API to identify aggressive and sexually explicit language.<br><br>Which three settings should you configure? To answer, select the appropriate settings in the answer area.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/ai-102/image97.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/ai-102/image98.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-02-29T11:57:00.000Z",
        "voteCount": 18,
        "content": "The answers should be \nResource Name\nclassify\nocp-Apim-Subscription-Key\n\nautocorrect has nothing to do with the question"
      },
      {
        "date": "2024-02-29T11:57:00.000Z",
        "voteCount": 3,
        "content": "https://westus.dev.cognitive.microsoft.com/docs/services/57cf753a3f9b070c105bd2c1/operations/57cf753a3f9b070868a1f66f"
      },
      {
        "date": "2024-04-06T19:30:00.000Z",
        "voteCount": 3,
        "content": "https://learn.microsoft.com/en-us/training/modules/classify-and-moderate-text-with-azure-content-moderator/4-exercise-use-the-api-console"
      },
      {
        "date": "2024-07-14T11:53:00.000Z",
        "voteCount": 1,
        "content": "NagaoShingo 1 month, 1 week ago\n1. Resource name\n2. classify\n3. Ocp-Api-Suscription-Key"
      },
      {
        "date": "2024-06-16T03:58:00.000Z",
        "voteCount": 2,
        "content": "Resource Name: Provide the name of your Content Moderator resource.\nClassify: Set to true to enable classification of content.\nOcp-Apim-Subscription-Key: Provide your subscription key for authentication.\n\nAll other fields are not necessary to set."
      },
      {
        "date": "2024-06-06T06:42:00.000Z",
        "voteCount": 2,
        "content": "1. Resource name\n2. classify\n3. Ocp-Api-Suscription-Key"
      },
      {
        "date": "2024-05-22T07:39:00.000Z",
        "voteCount": 2,
        "content": "Resource name\nclassify\nOcp-Api-Suscription-Key"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 59,
    "url": "https://www.examtopics.com/discussions/microsoft/view/135625-exam-ai-102-topic-3-question-61-discussion/",
    "body": "You are developing an app that will use the Decision and Language APIs.<br><br>You need to provision resources for the app. The solution must ensure that each service is accessed by using a single endpoint and credential.<br><br>Which type of resource should you create?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tLanguage",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSpeech",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure Cognitive Services\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tContent Moderator"
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 8,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-06-22T00:21:00.000Z",
        "voteCount": 1,
        "content": "I say this answer is C."
      },
      {
        "date": "2024-06-12T08:12:00.000Z",
        "voteCount": 1,
        "content": "C is answer."
      },
      {
        "date": "2024-05-28T08:35:00.000Z",
        "voteCount": 2,
        "content": "C is right answer, but now this service name changed \"Azure AI\"."
      },
      {
        "date": "2024-03-31T06:15:00.000Z",
        "voteCount": 1,
        "content": "The correct answer is C. Azure Cognitive Services.\n\nWhen you create an Azure Cognitive Services resource, you get access to a suite of services and APIs, including the Decision and Language APIs, under a single endpoint and credential. This simplifies the management of these services and enhances security by reducing the number of credentials you need to manage. Other options like Language, Speech, and Content Moderator are individual services within Azure Cognitive Services. They do not provide a single endpoint and credential for accessing multiple services. Therefore, they do not meet the requirement specified in the question"
      },
      {
        "date": "2024-03-09T23:29:00.000Z",
        "voteCount": 3,
        "content": "A Cognitive Services multi-service resource allows you to access multiple Azure AI services with a single key and endpoint."
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 60,
    "url": "https://www.examtopics.com/discussions/microsoft/view/135626-exam-ai-102-topic-3-question-62-discussion/",
    "body": "You are building a chatbot.<br><br>You need to ensure that the bot will recognize the names of your company\u2019s products and codenames. The solution must minimize development effort.<br><br>Which Azure Cognitive Service for Language service should you include in the solution?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tcustom text classification",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tentity linking",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tcustom Named Entity Recognition (NER)\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tkey phrase extraction"
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 7,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-06-22T00:20:00.000Z",
        "voteCount": 1,
        "content": "I say this answer is C."
      },
      {
        "date": "2024-06-12T08:12:00.000Z",
        "voteCount": 1,
        "content": "C is answer."
      },
      {
        "date": "2024-06-08T05:37:00.000Z",
        "voteCount": 1,
        "content": "C for me and ChatGPT too"
      },
      {
        "date": "2024-05-22T07:08:00.000Z",
        "voteCount": 1,
        "content": "NER is right answer."
      },
      {
        "date": "2024-03-19T14:51:00.000Z",
        "voteCount": 2,
        "content": "Named Entity Recognition (NER) identifies and categorizes specific names or terms in text, such as names of people, organizations, places, and more. By customizing NER, you can tailor it to recognize your company-specific entities, making it an efficient solution for your chatbot\u2019s needs45.\n\nSo, the correct answer is C. custom Named Entity Recognition (NER)."
      },
      {
        "date": "2024-03-09T23:32:00.000Z",
        "voteCount": 3,
        "content": "C. custom Named Entity Recognition (NER)\nCustom NER allows you to train a model to recognize specific terms relevant to your business, such as product names and codenames. https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/concept-shelf-analysis"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 61,
    "url": "https://www.examtopics.com/discussions/microsoft/view/135943-exam-ai-102-topic-3-question-63-discussion/",
    "body": "You have an Azure subscription that contains an Azure App Service app named App1.<br><br>You provision a multi-service Azure Cognitive Services resource named CSAccount1.<br><br>You need to configure App1 to access CSAccount1. The solution must minimize administrative effort.<br><br>What should you use to configure App1?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ta system-assigned managed identity and an X.509 certificate",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tthe endpoint URI and an OAuth token",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tthe endpoint URI and a shared access signature (SAS) token",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tthe endpoint URI and subscription key\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 7,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-08-30T09:54:00.000Z",
        "voteCount": 2,
        "content": "D is right, but i sure hope that nobody uses keys anymore. its considered bad practice, use managed identities, rbac to do this."
      },
      {
        "date": "2024-08-14T09:00:00.000Z",
        "voteCount": 1,
        "content": "It's 100% D. Confirmed by ChatGPT too"
      },
      {
        "date": "2024-06-22T00:20:00.000Z",
        "voteCount": 1,
        "content": "I say this answer is D. Please hurry up and transport the meat."
      },
      {
        "date": "2024-06-12T08:11:00.000Z",
        "voteCount": 1,
        "content": "D is answer."
      },
      {
        "date": "2024-05-28T08:34:00.000Z",
        "voteCount": 2,
        "content": "D is right answer."
      },
      {
        "date": "2024-04-15T22:11:00.000Z",
        "voteCount": 2,
        "content": "In general, you always need an endpoint and subscription key."
      },
      {
        "date": "2024-03-19T14:54:00.000Z",
        "voteCount": 2,
        "content": "By providing the endpoint URI and subscription key in your application, you can seamlessly connect to CSAccount1 without additional complexities or setup. This approach minimizes administrative overhead and ensures secure communication between your app and the cognitive services.\n\nTherefore, the correct answer is D. the endpoint URI and subscription key."
      },
      {
        "date": "2024-03-13T09:26:00.000Z",
        "voteCount": 3,
        "content": "Answer correct, also what a beautiful night?!"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 62,
    "url": "https://www.examtopics.com/discussions/microsoft/view/134939-exam-ai-102-topic-3-question-64-discussion/",
    "body": "You have an Azure subscription that contains a multi-service Azure Cognitive Services Translator resource named Translator1.<br><br>You are building an app that will translate text and documents by using Translator1.<br><br>You need to create the REST API request for the app.<br><br>Which headers should you include in the request?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tthe access control request, the content type, and the content length",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tthe subscription key and the client trace ID",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tthe resource ID and the content language",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tthe subscription key, the subscription region, and the content type\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 12,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-02-29T12:10:00.000Z",
        "voteCount": 8,
        "content": "Answer is correct\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/translator/reference/v3-0-translate\ncontent-type is required header\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/translator/reference/v3-0-reference\nWhen you use a multi-service secret key, you must include two authentication headers with your request. There are two headers that you need to call the Translator.\nOcp-Apim-Subscription-Key\tThe value is the Azure secret key for your multi-service resource.\nOcp-Apim-Subscription-Region\tThe value is the region of the multi-service resource.\nRegion is required for the multi-service Text API subscription. The region you select is the only region that you can use for text translation when using the multi-service key. It must be the same region you selected when you signed up for your multi-service subscription through the Azure portal.\nD is the only option with both the headers"
      },
      {
        "date": "2024-03-19T14:57:00.000Z",
        "voteCount": 5,
        "content": "To create the REST API request for your app that will translate text and documents using the Azure Cognitive Services Translator resource (Translator1), you should include the following headers:\n\nSubscription Key: This key serves as the authentication token to access the service.\nSubscription Region: The region where your Translator resource is deployed.\nContent Type: Specify the type of content you are sending (e.g., JSON, plain text).\nTherefore, the correct answer is D. the subscription key, the subscription region, and the content type. When making the API request, ensure that you include these headers to connect your application to the Translator service."
      },
      {
        "date": "2024-08-14T09:01:00.000Z",
        "voteCount": 1,
        "content": "D for Copilot too"
      },
      {
        "date": "2024-06-22T00:20:00.000Z",
        "voteCount": 1,
        "content": "I say this answer is D. Please hurry up and transport the meat."
      },
      {
        "date": "2024-06-12T08:11:00.000Z",
        "voteCount": 1,
        "content": "D is answer."
      },
      {
        "date": "2024-05-22T07:36:00.000Z",
        "voteCount": 1,
        "content": "the subscription key, the subscription region, and the content type"
      },
      {
        "date": "2024-05-07T18:44:00.000Z",
        "voteCount": 1,
        "content": "D.\nhttps://learn.microsoft.com/en-us/azure/ai-services/translator/quickstart-text-rest-api?tabs=csharp#headers"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 63,
    "url": "https://www.examtopics.com/discussions/microsoft/view/134971-exam-ai-102-topic-3-question-65-discussion/",
    "body": "You have a file share that contains 5,000 images of scanned invoices.<br><br>You need to analyze the images. The solution must extract the following data:<br><br>\u2022\tInvoice items<br>\u2022\tSales amounts<br>\u2022\tCustomer details<br><br>What should you use?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCustom Vision",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure AI Computer Vision",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure AI Immersive Reader",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure AI Document Intelligence\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 11,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-10-10T03:30:00.000Z",
        "voteCount": 1,
        "content": "D, because invoice model type can \"Extract customer and vendor details\".\n"
      },
      {
        "date": "2024-08-14T09:02:00.000Z",
        "voteCount": 1,
        "content": "I'm pretty sure it's D"
      },
      {
        "date": "2024-06-22T00:19:00.000Z",
        "voteCount": 2,
        "content": "I say this answer is D. Please hurry up and transport the meat."
      },
      {
        "date": "2024-06-18T02:23:00.000Z",
        "voteCount": 1,
        "content": "Copilot says \n\nB. Azure AI Computer Vision\n\nExplanation:\n\nAzure AI Computer Vision's Read API is designed to extract printed and handwritten text from images and documents. It uses Optical Character Recognition (OCR) to extract text and structure from your images, which can be used to extract invoice items, sales amounts, and customer details from the scanned invoices."
      },
      {
        "date": "2024-06-12T08:10:00.000Z",
        "voteCount": 1,
        "content": "You see, \n\n\u2022 Invoice items\n\u2022 Sales amounts\n\u2022 Customer details\n\nso, we use \"Azure AI Document Intelligence \".\nD is answer."
      },
      {
        "date": "2024-05-29T07:14:00.000Z",
        "voteCount": 1,
        "content": "For Azure Document Intelligence, Ability to use pre-built models for specific forms such as invoices, contracts, ID cards, insurance cards, credit cards, business cards, etc.\nAzure AI Computer Vision has similar functionality, but his case we need more sophisticated document analysis, use Azure AI Document Intelligence."
      },
      {
        "date": "2024-05-29T07:13:00.000Z",
        "voteCount": 1,
        "content": "For Azure Document Intelligence, Ability to use pre-built models for specific forms such as invoices, contracts, ID cards, insurance cards, credit cards, business cards, etc.\nAzure AI Computer Vision has similar functionality, but his case we need more sophisticated document analysis, use Azure AI Document Intelligence."
      },
      {
        "date": "2024-05-22T07:34:00.000Z",
        "voteCount": 1,
        "content": "https://learn.microsoft.com/en-us/azure/ai-services/?view=doc-intel-4.0.0\nTo deal with this type of question, it is good to understand Microsoft's AI services in a nutshell. It is tough to do so by rote memorization."
      },
      {
        "date": "2024-03-19T15:00:00.000Z",
        "voteCount": 1,
        "content": "To efficiently extract data from scanned invoices, including invoice items, sales amounts, and customer details, you should use Azure AI Document Intelligence. Therefore, the correct answer is D."
      },
      {
        "date": "2024-03-09T23:37:00.000Z",
        "voteCount": 3,
        "content": "D. Azure AI Document Intelligence\nThis service is specifically designed for tasks like automated invoice processing and can extract key information from documents."
      },
      {
        "date": "2024-03-07T13:06:00.000Z",
        "voteCount": 1,
        "content": "Answer seems to be correct"
      },
      {
        "date": "2024-03-01T01:09:00.000Z",
        "voteCount": 2,
        "content": "Answer is correct"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 64,
    "url": "https://www.examtopics.com/discussions/microsoft/view/135016-exam-ai-102-topic-3-question-66-discussion/",
    "body": "HOTSPOT<br> -<br><br>You are developing a text processing solution.<br><br>You have the function shown below.<br><br><img src=\"https://img.examtopics.com/ai-102/image122.png\"><br><br>For the second argument, you call the function and specify the following string.<br><br>Our tour of Paris included a visit to the Eiffel Tower<br><br>For each of the following statements, select Yes if the statement is true. Otherwise, select No.<br><br><img src=\"https://img.examtopics.com/ai-102/image123.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/ai-102/image124.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-03-01T11:14:00.000Z",
        "voteCount": 17,
        "content": "Should by NYN.\nKey phrases would be (tested with API): Eiffel Tower, tour, Paris, visit\nEntities are: Eiffen Tower, Paris"
      },
      {
        "date": "2024-09-14T12:18:00.000Z",
        "voteCount": 1,
        "content": "Duplicate question. The answer should be NYN."
      },
      {
        "date": "2024-08-06T20:00:00.000Z",
        "voteCount": 3,
        "content": "I ran this in my local, confirmed this is the output,\n\nKey Words:\n        Paris\n        Eiffel Tower\n\nSo it is N N N"
      },
      {
        "date": "2024-05-22T07:31:00.000Z",
        "voteCount": 3,
        "content": "NYN are right answer."
      },
      {
        "date": "2024-04-08T04:08:00.000Z",
        "voteCount": 2,
        "content": "There is a separate function to print key phrase to the console so the answer is NO. They are tricky you into thinking that key phrase is the same thing as key word which its not"
      },
      {
        "date": "2024-03-27T06:11:00.000Z",
        "voteCount": 2,
        "content": "Final Answer:\nN\nY\nN"
      },
      {
        "date": "2024-03-20T10:56:00.000Z",
        "voteCount": 1,
        "content": "The correct answers are NYY. The last one is yes because it will send info to the console as per the code snippet"
      },
      {
        "date": "2024-03-19T04:03:00.000Z",
        "voteCount": 1,
        "content": "Same : Topic 3, Question 48. NYN."
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 65,
    "url": "https://www.examtopics.com/discussions/microsoft/view/135017-exam-ai-102-topic-3-question-67-discussion/",
    "body": "HOTSPOT<br> -<br><br>You are developing a text processing solution.<br><br>You develop the following method.<br><br><img src=\"https://img.examtopics.com/ai-102/image125.png\"><br><br>You call the method by using the following code.<br><br>get_key_phrases(text_analytics_client, \"the cat sat on the mat\")<br><br>For each of the following statements, select Yes if the statement is true. Otherwise, select No.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/ai-102/image126.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/ai-102/image127.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-03-01T19:26:00.000Z",
        "voteCount": 13,
        "content": "Should be YNN\n\nRefer: https://learn.microsoft.com/en-us/azure/ai-services/language-service/key-phrase-extraction/quickstart?pivots=programming-language-csharp"
      },
      {
        "date": "2024-07-14T11:54:00.000Z",
        "voteCount": 2,
        "content": "Should be YNN"
      },
      {
        "date": "2024-05-22T07:27:00.000Z",
        "voteCount": 3,
        "content": "YNN is right answer."
      },
      {
        "date": "2024-03-27T06:10:00.000Z",
        "voteCount": 3,
        "content": "Final Answer :\nYNN"
      },
      {
        "date": "2024-03-26T12:13:00.000Z",
        "voteCount": 2,
        "content": "No se evidencia en el codigo que se muestre la confiabilidad de ninguna manera. YNN."
      },
      {
        "date": "2024-03-21T22:25:00.000Z",
        "voteCount": 2,
        "content": "Y-N-N for sure"
      },
      {
        "date": "2024-03-01T11:16:00.000Z",
        "voteCount": 3,
        "content": "Should by YNN. Seriously, where should the confidence level come from. keyphase is a string"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 66,
    "url": "https://www.examtopics.com/discussions/microsoft/view/136760-exam-ai-102-topic-3-question-68-discussion/",
    "body": "HOTSPOT<br> -<br><br>You are developing a service that records lectures given in English (United Kingdom).<br><br>You have a method named append_to_transcript_file that takes translated text and a language identifier.<br><br>You need to develop code that will provide transcripts of the lectures to attendees in their respective language. The supported languages are English, French, Spanish, and German.<br><br>How should you complete the code? To answer, select the appropriate options in the answer area.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/ai-102/image128.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/ai-102/image129.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-03-20T12:26:00.000Z",
        "voteCount": 7,
        "content": "The given answers are correct"
      },
      {
        "date": "2024-09-15T00:58:00.000Z",
        "voteCount": 1,
        "content": "Why is that language assignment in brackets? \nWhat's Microsoft intending with useless code? Don't they get real python programmers and not re-trained .Net piece of xx"
      },
      {
        "date": "2024-07-14T11:55:00.000Z",
        "voteCount": 2,
        "content": "fr,de,es \nTranslationRecognizer"
      },
      {
        "date": "2024-06-18T17:22:00.000Z",
        "voteCount": 1,
        "content": "The actual exam will choose between C# or Python programming languages; these types of questions, which seem to be duplicates in ET, differ in the programming language used. Please check."
      },
      {
        "date": "2024-06-14T07:50:00.000Z",
        "voteCount": 2,
        "content": "Given answer is correct."
      },
      {
        "date": "2024-05-21T07:27:00.000Z",
        "voteCount": 3,
        "content": "fr,de,es and TranslationRecognizer"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 67,
    "url": "https://www.examtopics.com/discussions/microsoft/view/135068-exam-ai-102-topic-3-question-69-discussion/",
    "body": "You are developing an app that will use the text-to-speech capability of the Azure AI Speech service. The app will be used in motor vehicles.<br><br>You need to optimize the quality of the synthesized voice output.<br><br>Which Speech Synthesis Markup Language (SSML) attribute should you configure?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tthe style attribute of the mstts:express-as element",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tthe effect attribute of the voice element\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tthe pitch attribute of the prosody element",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tthe level attribute of the emphasis element"
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 7,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-03-02T18:02:00.000Z",
        "voteCount": 7,
        "content": "Answer is correct:\n\nThe audio effect processor that's used to optimize the quality of the synthesized speech output for specific scenarios on devices.\n\nFor some scenarios in production environments, the auditory experience might be degraded due to the playback distortion on certain devices. For example, the synthesized speech from a car speaker might sound dull and muffled due to environmental factors such as speaker response, room reverberation, and background noise. The passenger might have to turn up the volume to hear more clearly. To avoid manual operations in such a scenario, the audio effect processor can make the sound clearer by compensating the distortion of playback.\n\nThe following values are supported:\neq_car \u2013 Optimize the auditory experience when providing high-fidelity speech in cars, buses, and other enclosed automobiles.\neq_telecomhp8k \u2013 Optimize the auditory experience for narrowband speech in telecom or telephone scenarios. You should use a sampling rate of 8 kHz. If the sample rate isn't 8 kHz, the auditory quality of the output speech isn't optimized."
      },
      {
        "date": "2024-09-15T01:06:00.000Z",
        "voteCount": 1,
        "content": "Answer is correct\nThe Microsoft guy read the following text:\n\"The audio effect processor that's used to optimize the quality of the synthesized speech output for specific scenarios on devices.\n\nFor some scenarios in production environments, the auditory experience might be degraded due to the playback distortion on certain devices. For example, the synthesized speech from a car speaker might sound dull \""
      },
      {
        "date": "2024-08-14T09:05:00.000Z",
        "voteCount": 1,
        "content": "Copilot:\nTo optimize the quality of the synthesized voice output for an app used in motor vehicles, you should configure B. the effect attribute of the voice element. This attribute allows you to apply audio effects that enhance the auditory experience in specific environments, such as cars, by compensating for playback distortions."
      },
      {
        "date": "2024-07-14T11:55:00.000Z",
        "voteCount": 1,
        "content": "Selected Answer: B"
      },
      {
        "date": "2024-06-20T07:15:00.000Z",
        "voteCount": 1,
        "content": "Copilot says:\n\nA. the style attribute of the mstts:express-as element"
      },
      {
        "date": "2024-06-07T01:11:00.000Z",
        "voteCount": 1,
        "content": "https://learn.microsoft.com/en-us/azure/ai-services/speech-service/speech-synthesis-markup-voice\nThe audio effect processor that's used to optimize the quality of the synthesized speech output for specific scenarios on devices."
      },
      {
        "date": "2024-05-22T07:11:00.000Z",
        "voteCount": 1,
        "content": "voice element"
      },
      {
        "date": "2024-03-02T18:11:00.000Z",
        "voteCount": 3,
        "content": "https://learn.microsoft.com/en-us/azure/ai-services/speech-service/speech-synthesis-markup-voice"
      },
      {
        "date": "2024-03-02T12:47:00.000Z",
        "voteCount": 1,
        "content": "correct\nsource: https://learn.microsoft.com/en-us/azure/ai-services/speech-service/speech-synthesis-markup-voice:\n\"Optimize the auditory experience when providing high-fidelity speech in cars, buses, and other enclosed automobiles.\""
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 68,
    "url": "https://www.examtopics.com/discussions/microsoft/view/135087-exam-ai-102-topic-3-question-70-discussion/",
    "body": "You are designing a content management system.<br><br>You need to ensure that the reading experience is optimized for users who have reduced comprehension and learning differences, such as dyslexia. The solution must minimize development effort.<br><br>Which Azure service should you include in the solution?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure AI Immersive Reader\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure AI Translator",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure AI Document Intelligence",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure AI Language"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 7,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-03-02T18:04:00.000Z",
        "voteCount": 8,
        "content": "https://learn.microsoft.com/en-us/azure/ai-services/immersive-reader/overview"
      },
      {
        "date": "2024-03-19T07:00:00.000Z",
        "voteCount": 2,
        "content": "thanks for the reference!"
      },
      {
        "date": "2024-06-22T00:19:00.000Z",
        "voteCount": 3,
        "content": "Immersive Reader"
      },
      {
        "date": "2024-06-12T08:09:00.000Z",
        "voteCount": 2,
        "content": "A is answer.\ndyslexia user is good to use \"Immersive Reader\"."
      },
      {
        "date": "2024-04-16T20:40:00.000Z",
        "voteCount": 2,
        "content": "Immersive AI improves accessibility."
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 69,
    "url": "https://www.examtopics.com/discussions/microsoft/view/135018-exam-ai-102-topic-3-question-71-discussion/",
    "body": "HOTSPOT<br> -<br><br>You are building an app that will answer customer calls about the status of an order. The app will query a database for the order details and provide the customers with a spoken response.<br><br>You need to identify which Azure AI service APIs to use. The solution must minimize development effort.<br><br>Which object should you use for each requirement? To answer, select the appropriate options in the answer area.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/ai-102/image130.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/ai-102/image131.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-03-01T11:21:00.000Z",
        "voteCount": 14,
        "content": "SpeechRecognizer / SpeechSynthesizer\ndoesn't say anything about translation recognizer, which needs more code"
      },
      {
        "date": "2024-03-01T19:32:00.000Z",
        "voteCount": 5,
        "content": "Agreed\nhttps://learn.microsoft.com/en-us/azure/ai-services/speech-service/get-started-speech-to-text?tabs=windows%2Cterminal&amp;pivots=programming-language-csharp\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/speech-service/how-to-speech-synthesis?tabs=browserjs%2Cterminal&amp;pivots=programming-language-csharp"
      },
      {
        "date": "2024-03-31T06:49:00.000Z",
        "voteCount": 5,
        "content": "To convert customer calls into text queries, you should use the SpeechRecognizer object. This is part of the Speech service in Azure Cognitive Services and it converts spoken language into written text.\n\nTo provide customers with the order details in a spoken response, you should use the SpeechSynthesizer object. This service converts text into lifelike speech, which can be used to deliver information to customers in a more interactive way.\n\nSo, the answer is:\n\nConvert customer calls into text queries: SpeechRecognizer\nProvide customers with the order details: SpeechSynthesizer"
      },
      {
        "date": "2024-07-12T08:12:00.000Z",
        "voteCount": 4,
        "content": "1. SpeechRecognizer\n2. SpeechSynthesizer"
      },
      {
        "date": "2024-06-06T06:40:00.000Z",
        "voteCount": 3,
        "content": "1. SpeechRecognizer\n2. SpeechSynthesizer"
      },
      {
        "date": "2024-05-22T07:25:00.000Z",
        "voteCount": 3,
        "content": "It must be SpeechRecognizer and SpeechSynthesizer."
      },
      {
        "date": "2024-04-02T14:37:00.000Z",
        "voteCount": 3,
        "content": "SpeechRecognizer / SpeechSynthesizer"
      },
      {
        "date": "2024-03-27T06:14:00.000Z",
        "voteCount": 2,
        "content": "Final Answer;\n1. SpeechRecognizer \n2. SpeechSynthesizer"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 70,
    "url": "https://www.examtopics.com/discussions/microsoft/view/135048-exam-ai-102-topic-3-question-72-discussion/",
    "body": "You have an Azure AI service model named Model1 that identifies the intent of text input.<br><br>You develop a Python app named App1.<br><br>You need to configure App1 to use Model1.<br><br>Which package should you add to App1?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tazure-cognitiveservices-language-textanalytics",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tazure-ai-language-conversations\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tazure-mgmt-cognitiveservices",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tazure-cognitiveservices-speech"
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 12,
        "isMostVoted": true
      },
      {
        "answer": "D",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2024-03-02T06:10:00.000Z",
        "voteCount": 10,
        "content": "The correct package for working with Azure AI service for text intent identification, like Model1, is:\n\nA. azure-cognitiveservices-language-textanalytics\n\nTherefore, you should add the azure-cognitiveservices-language-textanalytics package to App1 for configuring it to use Model1. This package provides functionalities for working with the Language API in Azure Cognitive Services, which includes text analytics capabilities, such as identifying language and sentiment, and can be used for processing text input to determine intent."
      },
      {
        "date": "2024-09-15T01:24:00.000Z",
        "voteCount": 1,
        "content": "What an e v i l question from Microsoft. It depends on the text."
      },
      {
        "date": "2024-09-15T01:29:00.000Z",
        "voteCount": 1,
        "content": "The answer they expect is conversational language understanding. But asking the name of the library instead of a service, just an additional step to trip people, \nCLU is all about what you do with the intent. If you are going to map it to an action or decision it is CLU. But for example intent can be used in the context of opinion mining. But do not over think these questions are from Microsoft employees."
      },
      {
        "date": "2024-08-14T09:08:00.000Z",
        "voteCount": 1,
        "content": "Should be B:\nthis package is specifically designed for conversational language understanding, which includes intent recognition."
      },
      {
        "date": "2024-07-14T11:56:00.000Z",
        "voteCount": 1,
        "content": "Selected Answer: B"
      },
      {
        "date": "2024-06-22T00:18:00.000Z",
        "voteCount": 2,
        "content": "I say this answer is B."
      },
      {
        "date": "2024-06-12T23:02:00.000Z",
        "voteCount": 1,
        "content": "azure-cognitiveservices-speech."
      },
      {
        "date": "2024-06-12T08:08:00.000Z",
        "voteCount": 1,
        "content": "B is answer."
      },
      {
        "date": "2024-06-03T11:04:00.000Z",
        "voteCount": 2,
        "content": "Answer is B. Both the text analytics package and the conversations package satisfy the requirement for identifying intent of speech, however Text analytics is more for generic use, not specialised intent recognition.\n\nConversations package is more developed for specialized intent recognition, the package is tailored for tasks involving natural language understanding in conversational contexts, making it more effective and efficient for intent recognition in an app designed to understand and respond to user inputs"
      },
      {
        "date": "2024-05-28T08:39:00.000Z",
        "voteCount": 1,
        "content": "B is right answer."
      },
      {
        "date": "2024-05-22T07:23:00.000Z",
        "voteCount": 1,
        "content": "When identifying text input intent, it is usually aggregated to cognitiveservices. not just Microsoft, but mega cloud products and solutions have too many similar names and should be aggregated."
      },
      {
        "date": "2024-04-27T13:20:00.000Z",
        "voteCount": 1,
        "content": "......................"
      },
      {
        "date": "2024-04-08T04:28:00.000Z",
        "voteCount": 1,
        "content": "B is correct"
      },
      {
        "date": "2024-03-27T20:32:00.000Z",
        "voteCount": 1,
        "content": "Must be B"
      },
      {
        "date": "2024-03-18T00:08:00.000Z",
        "voteCount": 4,
        "content": "answer is B.\n\"Conversation App: It's used in extracting intents and entities in conversations\"\n- https://learn.microsoft.com/ko-kr/python/api/overview/azure/ai-language-conversations-readme?view=azure-python\n\n\"The (Text Analytics) API can be used to analyze unstructured text for tasks such as sentiment analysis, key phrase extraction and language detection.\"\nhttps://learn.microsoft.com/en-us/python/api/azure-cognitiveservices-language-textanalytics/azure.cognitiveservices.language.textanalytics.textanalyticsclient?view=azure-python-previous"
      },
      {
        "date": "2024-04-03T18:20:00.000Z",
        "voteCount": 2,
        "content": "Agree 100%"
      },
      {
        "date": "2024-03-09T23:47:00.000Z",
        "voteCount": 1,
        "content": "B. azure-ai-language-conversations\nThis package is part of the Azure AI SDK for Python and contains functionality for building applications that can understand user intent using language models."
      },
      {
        "date": "2024-03-02T12:51:00.000Z",
        "voteCount": 2,
        "content": "Should be B.\nSource: https://pypi.org/project/azure-ai-language-conversations/\n\"Conversation App: It's used in extracting intents and entities in conversations\""
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 71,
    "url": "https://www.examtopics.com/discussions/microsoft/view/135148-exam-ai-102-topic-3-question-73-discussion/",
    "body": "HOTSPOT<br> -<br><br>You are building an app that will automatically translate speech from English to French, German, and Spanish by using Azure AI service.<br><br>You need to define the output languages and configure the Azure AI Speech service.<br><br>How should you complete the code? To answer, select the appropriate options in the answer area.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/ai-102/image132.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/ai-102/image133.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-06-12T08:07:00.000Z",
        "voteCount": 2,
        "content": "1. fr, de, es\n2. TranslationRecognizer"
      },
      {
        "date": "2024-04-03T18:19:00.000Z",
        "voteCount": 2,
        "content": "Duplicate"
      },
      {
        "date": "2024-03-19T07:11:00.000Z",
        "voteCount": 2,
        "content": "Same Question 68"
      },
      {
        "date": "2024-03-29T09:48:00.000Z",
        "voteCount": 1,
        "content": "The answer options for this question are slightly different from question 68 on topic 3"
      },
      {
        "date": "2024-03-03T22:44:00.000Z",
        "voteCount": 4,
        "content": "Answer seems to be correct."
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 72,
    "url": "https://www.examtopics.com/discussions/microsoft/view/135056-exam-ai-102-topic-3-question-74-discussion/",
    "body": "DRAG DROP<br> -<br><br>You plan to implement an Azure AI Search resource that will use custom skill based on sentiment analysis.<br><br>You need to create a custom model and configure Azure AI Search use the model.<br><br>Which five actions should you perform in sequence? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.<br><br><img src=\"https://img.examtopics.com/ai-102/image134.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/ai-102/image135.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-06-15T10:24:00.000Z",
        "voteCount": 19,
        "content": "1. Create an Azure Machine Learning workspace.\n2. Create and train the model in the Azure Machine Learning studio.\n3. Create an endpoint for the model.\n4. Connect the custom skill to the endpoint.\n5. Rerun the indexer to enrich the index."
      },
      {
        "date": "2024-03-24T07:50:00.000Z",
        "voteCount": 7,
        "content": "https://learn.microsoft.com/en-us/training/modules/build-azure-machine-learn-custom-skill-for-azure-cognitive-search/03-enrich-search-index-use-model\n1.Create an Azure Machine Learning workspace.\n2.Create and train the model in the Azure Machine Learning studio.\n3.Create an endpoint for the model.\n4.Provision an Azure AI Services resource and obtain the endpoint.\n5.Connect the custom skill to the endpoint."
      },
      {
        "date": "2024-05-03T18:18:00.000Z",
        "voteCount": 4,
        "content": "in the link you provided, last step is to update your existing cognitive search that means is to create the search resource first:\n1- Provision an Azure AI Services resource and obtain the endpoint.\n2- Create an Azure Machine Learning workspace.\n3- Create and train the model in the Azure Machine Learning studio.\n4- Create an endpoint for the model.\n6- Connect the custom skill to the endpoint."
      },
      {
        "date": "2024-09-19T07:36:00.000Z",
        "voteCount": 1,
        "content": "that link literally says \"rerun your indexer to enrich your index with the AML model.\" as the last step. The correct sequence from that link is:\n1. Create an Azure Machine Learning workspace.\n2. Create and train the model in the Azure Machine Learning studio.\n3. Create an endpoint for the model.\n4. Connect the custom skill to the endpoint.\n5. Rerun the indexer to enrich the index"
      },
      {
        "date": "2024-08-14T20:52:00.000Z",
        "voteCount": 1,
        "content": "ChatGPT:\n1- Provision an Azure AI Services resource and obtain the endpoint.\n2- Create an Azure Machine Learning workspace.\n3- Create and train the model in the Azure Machine Learning studio.\n4- Create an endpoint for the model.\n6- Connect the custom skill to the endpoint"
      },
      {
        "date": "2024-07-15T12:18:00.000Z",
        "voteCount": 1,
        "content": "1. Create an Azure Machine Learning workspace.\n2. Create and train the model in the Azure Machine Learning studio.\n3. Create an endpoint for the model.\n4. Connect the custom skill to the endpoint.\n5. Rerun the indexer to enrich the index."
      },
      {
        "date": "2024-06-23T04:33:00.000Z",
        "voteCount": 4,
        "content": "Based on the detailed steps provided in the Microsoft Learn documentation, the sequence of actions indeed doesn't require provisioning a separate Azure AI Services resource. Instead, the custom skill is directly connected to the Azure Machine Learning model endpoint.\n\nhttps://learn.microsoft.com/en-us/training/modules/build-azure-machine-learn-custom-skill-for-azure-cognitive-search/03-enrich-search-index-use-model"
      },
      {
        "date": "2024-06-22T05:25:00.000Z",
        "voteCount": 1,
        "content": "1. Create an Azure Machine Learning workspace.\n2. Create and train the model in the Azure Machine Learning studio.\n3. Create an endpoint for the model.\n4. Connect the custom skill to the endpoint.\n5. Rerun the indexer to enrich the index."
      },
      {
        "date": "2024-06-12T23:06:00.000Z",
        "voteCount": 2,
        "content": "Create an Azure Machine Learning workspace.\nCreate and train the model in the Azure Machine Learning studio.\nCreate an endpoint for the model.\nProvision an Azure AI Services resource and obtain the endpoint.\nConnect the custom skill the endpoint."
      },
      {
        "date": "2024-06-01T08:07:00.000Z",
        "voteCount": 3,
        "content": "Create an Azure Machine Learning workspace.\nCreate and train the model in the Azure Machine Learning studio.\nCreate an endpoint for the model.\nConnect the custom skill to the endpoint.\nRerun the indexer to enrich the index."
      },
      {
        "date": "2024-05-22T07:20:00.000Z",
        "voteCount": 3,
        "content": "Create workspace\nProvision\nConnect\nCreate studio\nRerun"
      },
      {
        "date": "2024-03-20T13:17:00.000Z",
        "voteCount": 1,
        "content": "Create an Azure Machine Learning workspace.\nCreate and train the model in the Azure Machine Learning studio.\nCreate an endpoint for the model.\nProvision an Azure AI Services resource and obtain the endpoint.\nConnect the custom skill to the endpoint."
      },
      {
        "date": "2024-03-19T07:34:00.000Z",
        "voteCount": 1,
        "content": "Create an endpoint for the model.\nCreate and train the model in the Azure Machine Learning studio.\nCreate an Azure Machine Learning workspace.\nConnect the custom skill to the endpoint.\n\nso, with the options:\nCreate an Azure Machine Learning\nCreate and train\nProvision an Azure\nCreate an endpoint\nConnect"
      },
      {
        "date": "2024-03-14T21:05:00.000Z",
        "voteCount": 2,
        "content": "Create an Azure Machine Learning workspace.\nCreate and train the model in the Azure Machine Learning studio.\nCreate an endpoint for the model.\nProvision an Azure AI Services resource and obtain the endpoint.\nConnect the custom skill to the endpoint."
      },
      {
        "date": "2024-03-02T08:55:00.000Z",
        "voteCount": 1,
        "content": "According to GPT4:\n\n1. Create an Azure Machine Learning workspace.\n2. Create and train the model in the Azure Machine Learning studio.\n3. Provision an Azure AI Services resource and obtain the endpoint.\n4. Create an endpoint for the model.\nConnect the custom skill to the endpoint.\nRerun the indexer to enrich the index."
      },
      {
        "date": "2024-03-02T08:59:00.000Z",
        "voteCount": 1,
        "content": "My bad, this is wrong information."
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 73,
    "url": "https://www.examtopics.com/discussions/microsoft/view/135062-exam-ai-102-topic-3-question-75-discussion/",
    "body": "HOTSPOT<br> -<br><br>You have a collection of press releases stored as PDF files.<br><br>You need to extract text from the files and perform sentiment analysis.<br><br>Which service should you use for each task? To answer, select the appropriate options in the answer area.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/ai-102/image136.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/ai-102/image137.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-05-22T07:18:00.000Z",
        "voteCount": 8,
        "content": "AI Document Intelligence and AI Language"
      },
      {
        "date": "2024-05-30T18:19:00.000Z",
        "voteCount": 6,
        "content": "Updated version of topic 3 question 46.\nSo according to the discussion in that question the correct answer is:\nAI Vision\nAI Language"
      },
      {
        "date": "2024-09-12T07:23:00.000Z",
        "voteCount": 1,
        "content": "AI Document Intelligence and AI Language"
      },
      {
        "date": "2024-07-14T11:56:00.000Z",
        "voteCount": 1,
        "content": "AI Vision\nAI Language"
      },
      {
        "date": "2024-07-09T08:25:00.000Z",
        "voteCount": 1,
        "content": "It can't be Document Intelligence. We don't know how the Press Releases are going to look like, if they have the same format and we don't need to extract anything specific, just text. And that you can achieve with AI Vision."
      },
      {
        "date": "2024-08-06T20:40:00.000Z",
        "voteCount": 2,
        "content": "Format is not required when using Read API in document intelligence"
      },
      {
        "date": "2024-07-09T08:28:00.000Z",
        "voteCount": 1,
        "content": "nvm you also have to do sentiment analysis and document intelligence has also just OCR"
      },
      {
        "date": "2024-06-12T19:17:00.000Z",
        "voteCount": 5,
        "content": "1. AI Document Intelligence\n2. AI Language"
      },
      {
        "date": "2024-06-06T06:38:00.000Z",
        "voteCount": 2,
        "content": "1. AI Document Intelligence\n2. AI Language"
      },
      {
        "date": "2024-04-23T21:43:00.000Z",
        "voteCount": 3,
        "content": "For extracting text from PDF files, Azure Document Intelligence would be the better choice. It\u2019s specifically optimized for text-heavy documents like PDFs and includes features such as higher-resolution scanning and paragraph detection. In addition, Azure Computer Vision API does not have direct PDF integration, and you would need to convert PDFs to images before text extraction, which adds an extra step to the process."
      },
      {
        "date": "2024-04-08T04:36:00.000Z",
        "voteCount": 1,
        "content": "Sentiment Analysis = AI Language"
      },
      {
        "date": "2024-03-31T07:23:00.000Z",
        "voteCount": 1,
        "content": "the key word to answer this question is press release which implies computer vision"
      },
      {
        "date": "2024-03-20T13:43:00.000Z",
        "voteCount": 2,
        "content": "Extract Text = AI Vision"
      },
      {
        "date": "2024-03-27T20:47:00.000Z",
        "voteCount": 1,
        "content": "Document Intelligence also does text extraction:\n\"Document Intelligence Read Optical Character Recognition (OCR) model runs at a higher resolution than Azure AI Vision Read and extracts print and handwritten text from PDF documents and scanned images.\"\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/concept-read?view=doc-intel-4.0.0"
      },
      {
        "date": "2024-03-22T02:17:00.000Z",
        "voteCount": 1,
        "content": "I disagree, the Computer Vision for text extraction is best suited for unstructured documents\nIDP is the right choice"
      },
      {
        "date": "2024-03-14T10:45:00.000Z",
        "voteCount": 1,
        "content": "Answer seems to be correct."
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 74,
    "url": "https://www.examtopics.com/discussions/microsoft/view/143318-exam-ai-102-topic-3-question-76-discussion/",
    "body": "You are building an internet-based training solution. The solution requires that a user's camera and microphone remain enabled.<br><br>You need to monitor a video stream of the user and verify that the user is alone and is not collaborating with another user. The solution must minimize development effort.<br><br>What should you include in the solution?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tspeech-to-text in the Azure AI Speech service",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tobject detection in Azure AI Custom Vision",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSpatial Analysis in Azure AI Vision\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tobject detection in Azure AI Custom Vision"
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 7,
        "isMostVoted": true
      },
      {
        "answer": "B",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2024-10-11T12:05:00.000Z",
        "voteCount": 1,
        "content": "https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/spatial-analysis-operations\nBelow is the description for cognitiveservices.vision.spatialanalysis-personcount\n\"Counts people in a designated zone in the camera's field of view. The zone must be fully covered by a single camera in order for PersonCount to record an accurate total.\""
      },
      {
        "date": "2024-07-19T10:41:00.000Z",
        "voteCount": 2,
        "content": "ChatGPT, Gemini and Claude is also voting for C."
      },
      {
        "date": "2024-09-15T01:46:00.000Z",
        "voteCount": 3,
        "content": "Risky to use Artificial intelligence on intelligence-free Microsoft questions"
      },
      {
        "date": "2024-09-15T01:49:00.000Z",
        "voteCount": 1,
        "content": "But this is indeed correct. Spatial Analysis is what Microsoft is looking for"
      },
      {
        "date": "2024-09-15T01:50:00.000Z",
        "voteCount": 1,
        "content": "But I wonder why not speech as well, but why over think"
      },
      {
        "date": "2024-07-15T04:57:00.000Z",
        "voteCount": 2,
        "content": "and what if the another person is out of the camera and is talking ?"
      },
      {
        "date": "2024-07-09T08:34:00.000Z",
        "voteCount": 2,
        "content": "\"How does Azure AI Vision analyze people in a physical space? The spatial analysis AI models detect and track movements in the video feed based on algorithms that identify the presence of one or more humans by a body bounding box.\"\n\nAnswer: C. Spatial Analysis"
      },
      {
        "date": "2024-07-09T08:32:00.000Z",
        "voteCount": 1,
        "content": "\"How does Azure AI Vision analyze people in a physical space? The spatial analysis AI models detect and track movements in the video feed based on algorithms that identify the presence of one or more humans by a body bounding box.\""
      },
      {
        "date": "2024-07-08T09:56:00.000Z",
        "voteCount": 1,
        "content": "but why B and D are equal?"
      },
      {
        "date": "2024-07-06T12:59:00.000Z",
        "voteCount": 2,
        "content": "To monitor a video stream of the user and verify that the user is alone and not collaborating with another user, you should include Spatial Analysis in Azure AI Vision in your solution. This service can analyze the spatial relationships between people, movements, and interactions in a physical space using video data. So, the correct answer is:\n\nC. Spatial Analysis in Azure AI Vision"
      },
      {
        "date": "2024-07-06T12:59:00.000Z",
        "voteCount": 2,
        "content": "https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/intro-to-spatial-analysis-public-preview?tabs=sa"
      },
      {
        "date": "2024-07-04T19:57:00.000Z",
        "voteCount": 1,
        "content": "For the specific scenario of monitoring a video stream to verify that a user is alone and not collaborating with another user, object detection using Azure AI Custom Vision is a more suitable choice. Object detection can identify and track objects or people within the video stream, allowing you to determine if multiple individuals are present. It aligns better with your goal and minimizes development effort.\n\nThe selected answer should be B"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 75,
    "url": "https://www.examtopics.com/discussions/microsoft/view/144085-exam-ai-102-topic-3-question-77-discussion/",
    "body": "You are developing an app that will use the Speech and Language APIs.<br><br>You need to provision resources for the app. The solution must ensure that each service is accessed by using a single endpoint and credential.<br><br>Which type of resource should you create?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure AI Language",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure AI Speech",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure AI Services\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAzure AI Content Safety"
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 2,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-07-18T03:15:00.000Z",
        "voteCount": 8,
        "content": "Azure AI Services since more than one services are used"
      },
      {
        "date": "2024-09-15T10:50:00.000Z",
        "voteCount": 1,
        "content": "Selected answer C"
      },
      {
        "date": "2024-09-12T07:26:00.000Z",
        "voteCount": 1,
        "content": "C 1000%"
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  },
  {
    "topic": 3,
    "index": 76,
    "url": "https://www.examtopics.com/discussions/microsoft/view/145783-exam-ai-102-topic-3-question-78-discussion/",
    "body": "HOTSPOT<br> -<br><br>You are building an app that will automatically translate speech from English to French, German, and Spanish by using Azure AI service.<br><br>You need to define the output languages and configure the Azure AI Speech service.<br><br>How should you complete the code? To answer, select the appropriate options in the answer area.<br><br>NOTE: Each correct selection is worth one point.<br><br><img src=\"https://img.examtopics.com/ai-102/image154.png\">",
    "options": [],
    "answer": "<img src=\"https://img.examtopics.com/ai-102/image155.png\">",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-09-14T08:26:00.000Z",
        "voteCount": 1,
        "content": "box1: 3\nbox2: 4"
      },
      {
        "date": "2024-09-12T07:27:00.000Z",
        "voteCount": 1,
        "content": "Correct, rewording of a old question."
      }
    ],
    "examNameCode": "ai-102",
    "topicNumber": "3"
  }
]