[
  {
    "topic": 1,
    "index": 1,
    "url": "https://www.examtopics.com/discussions/databricks/view/141734-exam-certified-machine-learning-associate-topic-1-question-1/",
    "body": "A machine learning engineer has created a Feature Table new_table using Feature Store Client fs. When creating the table, they specified a metadata description with key information about the Feature Table. They now want to retrieve that metadata programmatically.<br>Which of the following lines of code will return the metadata description?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tThere is no way to return the metadata description programmatically.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tfs.create_training_set(\"new_table\")",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tfs.get_table(\"new_table\").description\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tfs.get_table(\"new_table\").load_df()",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tfs.get_table(\"new_table\")"
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 1,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-06-01T10:00:00.000Z",
        "voteCount": 1,
        "content": "C is correct answer."
      }
    ],
    "examNameCode": "certified-machine-learning-associate",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 2,
    "url": "https://www.examtopics.com/discussions/databricks/view/141692-exam-certified-machine-learning-associate-topic-1-question-2/",
    "body": "A data scientist has a Spark DataFrame spark_df. They want to create a new Spark DataFrame that contains only the rows from spark_df where the value in column price is greater than 0.<br>Which of the following code blocks will accomplish this task?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tspark_df[spark_df[\"price\"] &gt; 0]\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tspark_df.filter(col(\"price\") &gt; 0)",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSELECT * FROM spark_df WHERE price &gt; 0",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tspark_df.loc[spark_df[\"price\"] &gt; 0,:]",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tspark_df.loc[:,spark_df[\"price\"] &gt; 0]"
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 2,
        "isMostVoted": false
      },
      {
        "answer": "A",
        "count": 2,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-08-25T09:52:00.000Z",
        "voteCount": 2,
        "content": "spark_df.filter(col(\"price\") &gt; 0)  this is correct answer"
      },
      {
        "date": "2024-06-14T15:06:00.000Z",
        "voteCount": 3,
        "content": "B is correct"
      },
      {
        "date": "2024-05-31T12:24:00.000Z",
        "voteCount": 2,
        "content": "Both A and B are valid ways to filter a Spark DataFrame. You could argue that A is slightly \"more\" correct since option B requires you to import \"pyspark.sql.functions.col\""
      }
    ],
    "examNameCode": "certified-machine-learning-associate",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 3,
    "url": "https://www.examtopics.com/discussions/databricks/view/141735-exam-certified-machine-learning-associate-topic-1-question-3/",
    "body": "A health organization is developing a classification model to determine whether or not a patient currently has a specific type of infection. The organization's leaders want to maximize the number of positive cases identified by the model.<br>Which of the following classification metrics should be used to evaluate the model?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRMSE",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tPrecision",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tArea under the residual operating curve",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAccuracy",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRecall\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "E",
    "answerDescription": "",
    "votes": [
      {
        "answer": "E",
        "count": 1,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-06-01T10:00:00.000Z",
        "voteCount": 1,
        "content": "E is correct answer."
      }
    ],
    "examNameCode": "certified-machine-learning-associate",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 4,
    "url": "https://www.examtopics.com/discussions/databricks/view/141736-exam-certified-machine-learning-associate-topic-1-question-4/",
    "body": "In which of the following situations is it preferable to impute missing feature values with their median value over the mean value?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tWhen the features are of the categorical type",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tWhen the features are of the boolean type",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tWhen the features contain a lot of extreme outliers\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tWhen the features contain no outliers",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tWhen the features contain no missing values"
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 1,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-06-01T10:00:00.000Z",
        "voteCount": 1,
        "content": "C is correct answer."
      }
    ],
    "examNameCode": "certified-machine-learning-associate",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 5,
    "url": "https://www.examtopics.com/discussions/databricks/view/142716-exam-certified-machine-learning-associate-topic-1-question-5/",
    "body": "A data scientist has replaced missing values in their feature set with each respective feature variable\u2019s median value. A colleague suggests that the data scientist is throwing away valuable information by doing this.<br>Which of the following approaches can they take to include as much information as possible in the feature set?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tImpute the missing values using each respective feature variable\u2019s mean value instead of the median value",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRefrain from imputing the missing values in favor of letting the machine learning algorithm determine how to handle them",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRemove all feature variables that originally contained missing values from the feature set",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a binary feature variable for each feature that contained missing values indicating whether each row\u2019s value has been imputed",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a constant feature variable for each feature that contained missing values indicating the percentage of rows from the feature that was originally missing"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-06-19T06:31:00.000Z",
        "voteCount": 1,
        "content": "the answer is D\n\nCreating a binary feature variable (also known as a missing indicator) for each feature that contained missing values is a common technique to retain information about the missingness itself. This approach allows the model to potentially learn patterns related to the missingness of data, which can be informative.\nBenefits of Creating Binary Indicators\nRetains Information: By adding a binary indicator, you preserve the information about which values were originally missing. This can be useful if the fact that a value is missing carries predictive power.\nImproves Model Performance: In some cases, the pattern of missing data can be correlated with the target variable. Including this information can help improve the model's performance.\nFlexibility: This method allows you to impute missing values (e.g., with the median) while still providing the model with additional context about the data."
      }
    ],
    "examNameCode": "certified-machine-learning-associate",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 6,
    "url": "https://www.examtopics.com/discussions/databricks/view/147770-exam-certified-machine-learning-associate-topic-1-question-6/",
    "body": "A data scientist is wanting to explore summary statistics for Spark DataFrame spark_df. The data scientist wants to see the count, mean, standard deviation, minimum, maximum, and interquartile range (IQR) for each numerical feature.<br>Which of the following lines of code can the data scientist run to accomplish the task?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tspark_df.summary ()",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tspark_df.stats()",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tspark_df.describe().head()",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tspark_df.printSchema()",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tspark_df.toPandas()"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-09-16T17:41:00.000Z",
        "voteCount": 2,
        "content": "A is correct answer"
      }
    ],
    "examNameCode": "certified-machine-learning-associate",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 7,
    "url": "https://www.examtopics.com/discussions/databricks/view/142546-exam-certified-machine-learning-associate-topic-1-question-7/",
    "body": "An organization is developing a feature repository and is electing to one-hot encode all categorical feature variables. A data scientist suggests that the categorical feature variables should not be one-hot encoded within the feature repository.<br>Which of the following explanations justifies this suggestion?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tOne-hot encoding is not supported by most machine learning libraries.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tOne-hot encoding is dependent on the target variable\u2019s values which differ for each application.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tOne-hot encoding is computationally intensive and should only be performed on small samples of training sets for individual machine learning problems.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tOne-hot encoding is not a common strategy for representing categorical feature variables numerically.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tOne-hot encoding is a potentially problematic categorical variable strategy for some machine learning algorithms."
    ],
    "answer": "E",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-06-18T04:29:00.000Z",
        "voteCount": 3,
        "content": "It might actually be E. \n\n\nAccording to these docs, this is the reason why the change was introduced \nwas to allow algorithms that expect continuous features, such as logistic regression to use categorical features"
      },
      {
        "date": "2024-06-14T15:39:00.000Z",
        "voteCount": 1,
        "content": "Correct answer B"
      }
    ],
    "examNameCode": "certified-machine-learning-associate",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 8,
    "url": "https://www.examtopics.com/discussions/databricks/view/140813-exam-certified-machine-learning-associate-topic-1-question-8/",
    "body": "A data scientist has created two linear regression models. The first model uses price as a label variable and the second model uses log(price) as a label variable. When evaluating the RMSE of each model by comparing the label predictions to the actual price values, the data scientist notices that the RMSE for the second model is much larger than the RMSE of the first model.<br>Which of the following possible explanations for this difference is invalid?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tThe second model is much more accurate than the first model",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tThe data scientist failed to exponentiate the predictions in the second model prior to computing the RMSE\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tThe data scientist failed to take the log of the predictions in the first model prior to computing the RMSE",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tThe first model is much more accurate than the second model",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tThe RMSE is an invalid evaluation metric for regression problems"
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 6,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-10-13T07:21:00.000Z",
        "voteCount": 1,
        "content": "Needs to bi expon due to the logarithmic transformation before"
      },
      {
        "date": "2024-10-06T15:43:00.000Z",
        "voteCount": 3,
        "content": "The question is Which of the following possible explanations for this difference is INVALID? It would have to be E since RMSE is used for regression frequently. That cannot be the explanation."
      },
      {
        "date": "2024-05-27T10:02:00.000Z",
        "voteCount": 2,
        "content": "The second model uses log(price) as the label variable. If the data scientist directly computes the RMSE on the predicted log values without exponentiating them back to the original price scale, the errors will be much larger, leading to a higher RMSE."
      },
      {
        "date": "2024-05-17T20:21:00.000Z",
        "voteCount": 3,
        "content": "the current answer is wrong.. RMSE is used for regression all the time"
      }
    ],
    "examNameCode": "certified-machine-learning-associate",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 9,
    "url": "https://www.examtopics.com/discussions/databricks/view/142717-exam-certified-machine-learning-associate-topic-1-question/",
    "body": "A data scientist wants to efficiently tune the hyperparameters of a scikit-learn model. They elect to use the Hyperopt library's fmin operation to facilitate this process. Unfortunately, the final model is not very accurate. The data scientist suspects that there is an issue with the objective_function being passed as an argument to fmin.<br>They use the following code block to create the objective_function:<br><img title=\"image2\" src=\"https://img.examtopics.com/certified-machine-learning-associate/image2.png\"><br>Which of the following changes does the data scientist need to make to their objective_function in order to produce a more accurate model?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAdd test set validation process",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAdd a random_state argument to the RandomForestRegressor operation",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRemove the mean operation that is wrapping the cross_val_score operation",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tReplace the r2 return value with -r2",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tReplace the fmin operation with the fmax operation"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-06-19T06:42:00.000Z",
        "voteCount": 2,
        "content": "the answer is D:\nThe fmin function in Hyperopt is designed to minimize the objective function. In the provided code, the objective function returns the R-squared value (r2), which is a measure of how well the model explains the variance in the target variable. Since higher R-squared values indicate better model performance, the goal is to maximize this value. However, fmin minimizes the objective function, so you need to return the negative R-squared value to effectively maximize it."
      }
    ],
    "examNameCode": "certified-machine-learning-associate",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 10,
    "url": "https://www.examtopics.com/discussions/databricks/view/141726-exam-certified-machine-learning-associate-topic-1-question/",
    "body": "A data scientist has defined a Pandas UDF function predict to parallelize the inference process for a single-node model:<br><img title=\"image4\" src=\"https://img.examtopics.com/certified-machine-learning-associate/image4.png\"><br>They have written the following incomplete code block to use predict to score each record of Spark DataFrame spark_df:<br><img title=\"image5\" src=\"https://img.examtopics.com/certified-machine-learning-associate/image5.png\"><br>Which of the following lines of code can be used to complete the code block to successfully complete the task?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tpredict(*spark_df.columns)\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tmapInPandas(predict)",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tpredict(Iterator(spark_df))",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tmapInPandas(predict(spark_df.columns))",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tpredict(spark_df.columns)"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 4,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-09-30T06:42:00.000Z",
        "voteCount": 1,
        "content": "B. mapInPandas(predict): This is the correct choice. mapInPandas is used to apply a Pandas UDF to a Spark DataFrame. This function expects the UDF to take an iterator of Pandas DataFrames and return an iterator of Pandas Series or DataFrames, which matches the signature of the predict function defined."
      },
      {
        "date": "2024-07-04T16:18:00.000Z",
        "voteCount": 1,
        "content": "correct answer is A, Scalar Pandas UDFs work with column names or expressions and\nreturn a column that gets added to the DataFrame. In this particular case, the use of\n*spark_df.columns unpacks the column names, which allows the UDF to operate on all these columns. No other option provides all column names"
      },
      {
        "date": "2024-06-01T06:35:00.000Z",
        "voteCount": 4,
        "content": "mapInPandas is used in pandas api functions and syntax is mapInPandas(predict,schema)"
      }
    ],
    "examNameCode": "certified-machine-learning-associate",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 11,
    "url": "https://www.examtopics.com/discussions/databricks/view/143881-exam-certified-machine-learning-associate-topic-1-question/",
    "body": "A data scientist is using Spark ML to engineer features for an exploratory machine learning project.<br>They decide they want to standardize their features using the following code block:<br><img title=\"image6\" src=\"https://img.examtopics.com/certified-machine-learning-associate/image6.png\"><br>Upon code review, a colleague expressed concern with the features being standardized prior to splitting the data into a training set and a test set.<br>Which of the following changes can the data scientist make to address the concern?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUtilize the MinMaxScaler object to standardize the training data according to global minimum and maximum values",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUtilize the MinMaxScaler object to standardize the test data according to global minimum and maximum values",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUtilize a cross-validation process rather than a train-test split process to remove the need for standardizing data",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUtilize the Pipeline API to standardize the training data according to the test data's summary statistics",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUtilize the Pipeline API to standardize the test data according to the training data's summary statistics"
    ],
    "answer": "E",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-07-14T06:07:00.000Z",
        "voteCount": 1,
        "content": "The concern raised by the colleague is valid. Standardizing the entire dataset before splitting into training and test sets can cause data leakage, where information from the test set influences the training process. To avoid this, the data should be standardized based on the training set statistics only, and then those statistics should be applied to the test set."
      }
    ],
    "examNameCode": "certified-machine-learning-associate",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 12,
    "url": "https://www.examtopics.com/discussions/databricks/view/142552-exam-certified-machine-learning-associate-topic-1-question/",
    "body": "A machine learning engineer is trying to scale a machine learning pipeline by distributing its feature engineering process.<br>Which of the following feature engineering tasks will be the least efficient to distribute?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tOne-hot encoding categorical features",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tTarget encoding categorical features",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tImputing missing feature values with the mean",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tImputing missing feature values with the true median",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreating binary indicator features for missing values"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-09-30T06:49:00.000Z",
        "voteCount": 1,
        "content": "B. Target encoding  involves replacing each category of a categorical variable with a statistic related to the target variable (like the mean of the target for that category)."
      },
      {
        "date": "2024-06-14T16:18:00.000Z",
        "voteCount": 3,
        "content": "would argue that the answer is b - Target encoding (also known as mean encoding) involves replacing each category in a categorical feature with the mean of the target variable for that category. This process is more complex and challenging to distribute efficiently because it requires calculating and applying the mean target value for each category."
      }
    ],
    "examNameCode": "certified-machine-learning-associate",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 13,
    "url": "https://www.examtopics.com/discussions/databricks/view/142711-exam-certified-machine-learning-associate-topic-1-question/",
    "body": "Which of the following is a benefit of using vectorized pandas UDFs instead of standard PySpark UDFs?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tThe vectorized pandas UDFs allow for the use of type hints",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tThe vectorized pandas UDFs process data in batches rather than one row at a time",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tThe vectorized pandas UDFs allow for pandas API use inside of the function",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tThe vectorized pandas UDFs work on distributed DataFrames",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tThe vectorized pandas UDFs process data in memory rather than spilling to disk"
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-10-14T07:11:00.000Z",
        "voteCount": 1,
        "content": "I think the answer should be C"
      }
    ],
    "examNameCode": "certified-machine-learning-associate",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 14,
    "url": "https://www.examtopics.com/discussions/databricks/view/141694-exam-certified-machine-learning-associate-topic-1-question/",
    "body": "A data scientist wants to tune a set of hyperparameters for a machine learning model. They have wrapped a Spark ML model in the objective function objective_function and they have defined the search space search_space.<br>As a result, they have the following code block:<br><img title=\"image7\" src=\"https://img.examtopics.com/certified-machine-learning-associate/image7.png\"><br>Which of the following changes do they need to make to the above code block in order to accomplish the task?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tChange SparkTrials() to Trials()\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tReduce num_evals to be less than 10",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tChange fmin() to fmax()",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRemove the trials=trials argument",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRemove the algo=tpe.suggest argument"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 4,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-05-31T13:36:00.000Z",
        "voteCount": 4,
        "content": "Option A is correct. Trying to use SparkTrials when the objective function itself uses Spark ML would give errors. From Hyperopt documentation \"Since SparkTrials fits and evaluates each model on one Spark worker, it is limited to tuning single-machine ML models and workflows, such as scikit-learn or single-machine TensorFlow. For distributed ML algorithms such as Apache Spark MLlib or Horovod, you can use Hyperopt\u2019s default Trials class.\" https://hyperopt.github.io/hyperopt/scaleout/spark/"
      }
    ],
    "examNameCode": "certified-machine-learning-associate",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 15,
    "url": "https://www.examtopics.com/discussions/databricks/view/147567-exam-certified-machine-learning-associate-topic-1-question/",
    "body": "A machine learning engineer would like to develop a linear regression model with Spark ML to predict the price of a hotel room. They are using the Spark DataFrame train_df to train the model.<br>The Spark DataFrame train_df has the following schema:<br><img title=\"image8\" src=\"https://img.examtopics.com/certified-machine-learning-associate/image8.png\"><br>The machine learning engineer shares the following code block:<br><img title=\"image9\" src=\"https://img.examtopics.com/certified-machine-learning-associate/image9.png\"><br>Which of the following changes does the machine learning engineer need to make to complete the task?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tThey need to call the transform method on train_df",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tThey need to convert the features column to be a vector",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tThey do not need to make any changes",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tThey need to utilize a Pipeline to fit the model",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tThey need to split the features column out into one column for each feature"
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-09-14T15:04:00.000Z",
        "voteCount": 2,
        "content": "Correct Answer: B\nThe features column in Spark ML should be a vector type for the linear regression model to work. If the features column is not already a vector, it needs to be converted.\n\nThis can be done using a VectorAssembler to combine the feature columns into a single vector column, which can then be used as input to the model."
      }
    ],
    "examNameCode": "certified-machine-learning-associate",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 16,
    "url": "https://www.examtopics.com/discussions/databricks/view/141695-exam-certified-machine-learning-associate-topic-1-question/",
    "body": "Which of the following statements describes a Spark ML estimator?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAn estimator is a hyperparameter grid that can be used to train a model",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAn estimator chains multiple algorithms together to specify an ML workflow",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAn estimator is a trained ML model which turns a DataFrame with features into a DataFrame with predictions",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAn estimator is an algorithm which can be fit on a DataFrame to produce a Transformer",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAn estimator is an evaluation tool to assess to the quality of a model"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-06-19T02:55:00.000Z",
        "voteCount": 2,
        "content": "The correct statement is D. An estimator is an algorithm which can be fit on a DataFrame to produce a Transformer\n\nIn Spark MLlib, an estimator is a machine learning algorithm or pipeline stage that is used to fit a model to data. When you call the fit method on an estimator with a DataFrame, it produces a transformer. The transformer can then be used to transform a DataFrame, typically by adding predictions or other derived values."
      }
    ],
    "examNameCode": "certified-machine-learning-associate",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 17,
    "url": "https://www.examtopics.com/discussions/databricks/view/142694-exam-certified-machine-learning-associate-topic-1-question/",
    "body": "A data scientist has been given an incomplete notebook from the data engineering team. The notebook uses a Spark DataFrame spark_df on which the data scientist needs to perform further feature engineering. Unfortunately, the data scientist has not yet learned the PySpark DataFrame API.<br>Which of the following blocks of code can the data scientist run to be able to use the pandas API on Spark?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\timport pyspark.pandas as ps<br>df = ps.DataFrame(spark_df)",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\timport pyspark.pandas as ps<br>df = ps.to_pandas(spark_df)",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tspark_df.to_sql()",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\timport pandas as pd<br>df = pd.DataFrame(spark_df)",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tspark_df.to_pandas()"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-10-01T01:15:00.000Z",
        "voteCount": 1,
        "content": "E. is the closest answer, the correct method name is toPandas().\npyspark.sql.DataFrame.toPandas\nDataFrame.toPandas() \u2192 PandasDataFrameLike"
      },
      {
        "date": "2024-07-04T17:27:00.000Z",
        "voteCount": 1,
        "content": "A is correct"
      },
      {
        "date": "2024-06-18T20:51:00.000Z",
        "voteCount": 2,
        "content": "It's not A.\n\nE. spark_df.to_pandas()\nHere's why:\n\nThe to_pandas() method is a built-in method of the PySpark DataFrame API. It converts a Spark DataFrame to a pandas DataFrame.\nBy calling spark_df.to_pandas(), the data scientist can convert the Spark DataFrame spark_df to a pandas DataFrame, allowing them to use the familiar pandas API for further feature engineering.\nThe resulting pandas DataFrame will be stored in memory on the driver node, so this approach is suitable when the data size is relatively small and can fit in the memory of the driver."
      },
      {
        "date": "2024-07-04T17:27:00.000Z",
        "voteCount": 2,
        "content": "E is not correct as to_pandas would convert into pandas DF, while what is given is a Spark DF"
      }
    ],
    "examNameCode": "certified-machine-learning-associate",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 18,
    "url": "https://www.examtopics.com/discussions/databricks/view/142714-exam-certified-machine-learning-associate-topic-1-question/",
    "body": "A machine learning engineer is converting a decision tree from sklearn to Spark ML. They notice that they are receiving different results despite all of their data and manually specified hyperparameter values being identical.<br>Which of the following describes a reason that the single-node sklearn decision tree and the Spark ML decision tree can differ?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSpark ML decision trees test every feature variable in the splitting algorithm",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSpark ML decision trees automatically prune overfit trees",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSpark ML decision trees test more split candidates in the splitting algorithm",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSpark ML decision trees test a random sample of feature variables in the splitting algorithm",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSpark ML decision trees test binned features values as representative split candidates"
    ],
    "answer": "E",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-06-19T03:00:00.000Z",
        "voteCount": 1,
        "content": "A machine learning engineer is converting a decision tree from sklearn to Spark ML. They notice that they are receiving different results despite all of their data and manually specified hyperparameter values being identical.\nWhich of the following describes a reason that the single-node sklearn decision tree and the Spark ML decision tree can differ?\n\nA. Spark ML decision trees test every feature variable in the splitting algorithm\nB. Spark ML decision trees automatically prune overfit trees\nC. Spark ML decision trees test more split candidates in the splitting algorithm\nD. Spark ML decision trees test a random sample of feature variables in the splitting algorithm\nE. Spark ML decision trees test binned features values as representative split candidates"
      }
    ],
    "examNameCode": "certified-machine-learning-associate",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 19,
    "url": "https://www.examtopics.com/discussions/databricks/view/142664-exam-certified-machine-learning-associate-topic-1-question/",
    "body": "A data scientist is developing a machine learning pipeline using AutoML on Databricks Machine Learning.<br>Which of the following steps will the data scientist need to perform outside of their AutoML experiment?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tModel tuning",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tModel evaluation",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tModel deployment",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tExploratory data analysis"
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-06-17T22:55:00.000Z",
        "voteCount": 3,
        "content": "Exploratory Data Analysis is the correct answer. The data operator is trying to get a feel for the data. If they were doing this in an automated manner, they would not be exploring the data."
      }
    ],
    "examNameCode": "certified-machine-learning-associate",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 20,
    "url": "https://www.examtopics.com/discussions/databricks/view/141714-exam-certified-machine-learning-associate-topic-1-question/",
    "body": "A data scientist is utilizing MLflow Autologging to automatically track their machine learning experiments. After completing a series of runs for the experiment experiment_id, the data scientist wants to identify the run_id of the run with the best root-mean-square error (RMSE).<br>Which of the following lines of code can be used to identify the run_id of the run with the best RMSE in experiment_id?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t<img title=\"image16\" src=\"https://img.examtopics.com/certified-machine-learning-associate/image16.png\">",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t<img title=\"image17\" src=\"https://img.examtopics.com/certified-machine-learning-associate/image17.png\">",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t<img title=\"image18\" src=\"https://img.examtopics.com/certified-machine-learning-associate/image18.png\">\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t<img title=\"image19\" src=\"https://img.examtopics.com/certified-machine-learning-associate/image19.png\">"
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 8,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-07-15T22:28:00.000Z",
        "voteCount": 2,
        "content": "import mlflow\n\n# Search for all runs in the experiment with the specified experiment_id,\n# sorted by RMSE in ascending order\nruns_df = mlflow.search_runs(\n    experiment_ids=[experiment_id],\n    order_by=[\"metrics.rmse ASC\"],\n    max_results=1\n)\n\n# Get the run_id of the run with the best (lowest) RMSE\nbest_run_id = runs_df.iloc[0]['run_id']\n\nprint(f\"The run_id with the best RMSE is: {best_run_id}\")"
      },
      {
        "date": "2024-06-01T06:50:00.000Z",
        "voteCount": 2,
        "content": "rmse being lower is good.\nDefault value in orderby is ASC, option A is showing DESC which mean higher rmse"
      },
      {
        "date": "2024-06-01T03:14:00.000Z",
        "voteCount": 4,
        "content": "I think it should be C, since ordering by RMSE descending would give the run with *highest* RMSE, i.e. the worst run first."
      }
    ],
    "examNameCode": "certified-machine-learning-associate",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 21,
    "url": "https://www.examtopics.com/discussions/databricks/view/148940-exam-certified-machine-learning-associate-topic-1-question/",
    "body": "A machine learning engineer is trying to perform batch model inference. They want to get predictions using the linear regression model saved at the path model_uri for the DataFrame batch_df. batch_df has the following schema: customer_id STRING<br>The machine learning engineer runs the following code block to perform inference on batch_df using the linear regression model at model_uri:<br><img title=\"image20\" src=\"https://img.examtopics.com/certified-machine-learning-associate/image20.png\"><br>In which situation will the machine learning engineer\u2019s code block perform the desired inference?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tWhen the Feature Store feature set was logged with the model at model_uri",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tWhen all of the features used by the model at model_uri are in a Spark DataFrame in the PySpark",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tWhen the model at model_uri only uses customer_id as a feature",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tThis code block will not perform the desired inference in any situation.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tWhen all of the features used by the model at model_uri are in a single Feature Store table"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2024-10-09T09:40:00.000Z",
        "voteCount": 1,
        "content": "This code block will not perform the desired inference in any situation.\n\nExplanation:\nThe issue lies in the fact that the DataFrame (batch_df) only contains one column, customer_id, which is a STRING. Linear regression models typically use numerical or categorical features for training, and it is highly unlikely that a customer_id alone (which is usually an identifier and not a feature) was used to train the model."
      }
    ],
    "examNameCode": "certified-machine-learning-associate",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 22,
    "url": "https://www.examtopics.com/discussions/databricks/view/148562-exam-certified-machine-learning-associate-topic-1-question/",
    "body": "A data scientist is wanting to explore the Spark DataFrame spark_df. The data scientist wants visual histograms displaying the distribution of numeric features to be included in the exploration.<br>Which of the following lines of code can the data scientist run to accomplish the task?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tspark_df.describe()",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tdbutils.data(spark_df).summarize()",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tThis task cannot be accomplished in a single line of code.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tspark_df.summary()",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tdbutils.data.summarize (spark_df)"
    ],
    "answer": "E",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-10-02T06:32:00.000Z",
        "voteCount": 1,
        "content": "C. This task cannot be accomplished in a single line of code."
      }
    ],
    "examNameCode": "certified-machine-learning-associate",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 23,
    "url": "https://www.examtopics.com/discussions/databricks/view/147630-exam-certified-machine-learning-associate-topic-1-question/",
    "body": "A data scientist uses 3-fold cross-validation and the following hyperparameter grid when optimizing model hyperparameters via grid search for a classification problem:<br>Hyperparameter 1: [2, 5, 10]<br>Hyperparameter 2: [50, 100]<br>Which of the following represents the number of machine learning models that can be trained in parallel during this process?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t3",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t5",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t6",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t18"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [],
    "comments": [
      {
        "date": "2024-09-15T15:51:00.000Z",
        "voteCount": 4,
        "content": "Correct Answer: D\nThe number of machine learning models that can be trained in parallel during this process is determined by the total number of hyperparameter combinations.\n\nHyperparameter 1 has 3 values: ([2, 5, 10])\n\nHyperparameter 2 has 2 values: ([50, 100])\n\nThe total number of combinations is (3 \\times 2 = 6).\n\nHowever, because 3-fold cross-validation is used, each combination is evaluated 3 times, resulting in (6 \\times 3 = 18) model evaluations."
      }
    ],
    "examNameCode": "certified-machine-learning-associate",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 24,
    "url": "https://www.examtopics.com/discussions/databricks/view/141715-exam-certified-machine-learning-associate-topic-1-question/",
    "body": "A data scientist has a Spark DataFrame spark_df. They want to create a new Spark DataFrame that contains only the rows from spark_df where the value in column discount is less than or equal 0.<br>Which of the following code blocks will accomplish this task?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tspark_df.loc[:,spark_df[\"discount\"] &lt;= 0]",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tspark_df[spark_df[\"discount\"] &lt;= 0]\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tspark_df.filter (col(\"discount\") &lt;= 0)",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tspark_df.loc(spark_df[\"discount\"] &lt;= 0, :]"
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 2,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-10-01T06:20:00.000Z",
        "voteCount": 2,
        "content": "C., In PySpark, the typical way to filter rows in a DataFrame is by using the filter method (or its alias, where), combined with a column expression."
      },
      {
        "date": "2024-06-01T03:56:00.000Z",
        "voteCount": 2,
        "content": "This is a duplicate question but both option B and C will give the same result."
      }
    ],
    "examNameCode": "certified-machine-learning-associate",
    "topicNumber": "1"
  }
]