[
  {
    "topic": 1,
    "index": 1,
    "url": "https://www.examtopics.com/discussions/google/view/54119-exam-professional-cloud-devops-engineer-topic-1-question-1/",
    "body": "You support a Node.js application running on Google Kubernetes Engine (GKE) in production. The application makes several HTTP requests to dependent applications. You want to anticipate which dependent applications might cause performance issues. What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tInstrument all applications with Stackdriver Profiler.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tInstrument all applications with Stackdriver Trace and review inter-service HTTP requests.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse Stackdriver Debugger to review the execution of logic within each application to instrument all applications.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tModify the Node.js application to log HTTP request and response times to dependent applications. Use Stackdriver Logging to find dependent applications that are performing poorly."
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 12,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-11-08T00:38:00.000Z",
        "voteCount": 11,
        "content": "Answer is B.\n\nThe keyword is \"make several requests to dependent app\". So you need trace for it.\n\nCloud Trace\nFind performance bottlenecks in production.\n\nCloud Profiler\nContinuous CPU and heap profiling to improve performance and reduce costs."
      },
      {
        "date": "2021-06-28T15:26:00.000Z",
        "voteCount": 6,
        "content": "I have submitted B answer"
      },
      {
        "date": "2024-09-26T03:11:00.000Z",
        "voteCount": 4,
        "content": "B. Instrument all applications with Stackdriver Trace and review inter-service HTTP requests.\n\nStackdriver Trace allows you to collect and analyze performance data for all the applications that make up your system, including the applications running on GKE. By instrumenting your application with Stackdriver Trace, you can see detailed performance information for each request, including the time spent in each component of your system, as well as any inter-service HTTP requests. This will allow you to identify which dependent applications might be causing performance issues, so that you can focus on optimizing those services specifically."
      },
      {
        "date": "2024-08-05T03:47:00.000Z",
        "voteCount": 1,
        "content": "correct"
      },
      {
        "date": "2024-05-03T22:59:00.000Z",
        "voteCount": 1,
        "content": "Agree with B"
      },
      {
        "date": "2023-11-02T05:28:00.000Z",
        "voteCount": 3,
        "content": "Right Answer, Cleared the exam yesterday , All the questions were from this study material , Always go with community answers and prepare well."
      },
      {
        "date": "2023-09-11T10:34:00.000Z",
        "voteCount": 1,
        "content": "B is right answer."
      },
      {
        "date": "2023-08-16T02:06:00.000Z",
        "voteCount": 1,
        "content": "Answer is B."
      },
      {
        "date": "2023-07-31T21:41:00.000Z",
        "voteCount": 1,
        "content": "B is correct answer."
      },
      {
        "date": "2023-07-26T07:52:00.000Z",
        "voteCount": 1,
        "content": "B is the answer"
      },
      {
        "date": "2022-12-24T00:06:00.000Z",
        "voteCount": 1,
        "content": "Ans: B\nKeyword: HTTP requests -&gt; Trace"
      },
      {
        "date": "2022-12-06T01:23:00.000Z",
        "voteCount": 1,
        "content": "Submitted B on the exam"
      },
      {
        "date": "2022-10-24T05:47:00.000Z",
        "voteCount": 1,
        "content": "B is the answer.\n\nhttps://cloud.google.com/trace/docs/overview\nCloud Trace, a distributed tracing system for Google Cloud, helps you understand how long it takes your application to handle incoming requests from users or other applications, and how long it takes to complete operations like RPC calls performed when handling the requests."
      },
      {
        "date": "2022-10-23T12:53:00.000Z",
        "voteCount": 1,
        "content": "B is right answer."
      },
      {
        "date": "2022-08-13T06:53:00.000Z",
        "voteCount": 1,
        "content": "The answer is B."
      },
      {
        "date": "2022-04-22T04:18:00.000Z",
        "voteCount": 1,
        "content": "The answer is B."
      },
      {
        "date": "2021-10-19T04:55:00.000Z",
        "voteCount": 4,
        "content": "You need to define Service Level Objectives (SLOs) for a high-traffic multi-region web\napplication. Customers expect the application to always be available and have fast response times.\nCustomers are currently happy with the application performance and availability. Based on current\nmeasurement, you observe that the 90th percentile of latency is 120ms and the 95th percentile of\nlatency is 275ms over a 28-day window. What latency SLO would you recommend to the team to\npublish?\nA. 90th percentile - 100ms\n95th percentile - 250ms\nB. 90th percentile - 120ms\n95th percentile - 275ms\nC. 90th percentile - 150ms\n95th percentile - 300ms\nD. 90th percentile - 250ms\n95th percentile - 400ms"
      },
      {
        "date": "2021-10-28T00:14:00.000Z",
        "voteCount": 1,
        "content": "For selecting SLO target i will select C ( because D it is a too relexed for a SLA), but I'm not sure B could also be a good choice if you want a more challenging SLO"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 2,
    "url": "https://www.examtopics.com/discussions/google/view/54120-exam-professional-cloud-devops-engineer-topic-1-question-2/",
    "body": "You created a Stackdriver chart for CPU utilization in a dashboard within your workspace project. You want to share the chart with your Site Reliability Engineering<br>(SRE) team only. You want to ensure you follow the principle of least privilege. What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tShare the workspace Project ID with the SRE team. Assign the SRE team the Monitoring Viewer IAM role in the workspace project.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tShare the workspace Project ID with the SRE team. Assign the SRE team the Dashboard Viewer IAM role in the workspace project.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tClick \u05d2\u20acShare chart by URL\u05d2\u20ac and provide the URL to the SRE team. Assign the SRE team the Monitoring Viewer IAM role in the workspace project.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tClick \u05d2\u20acShare chart by URL\u05d2\u20ac and provide the URL to the SRE team. Assign the SRE team the Dashboard Viewer IAM role in the workspace project."
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 15,
        "isMostVoted": true
      },
      {
        "answer": "D",
        "count": 4,
        "isMostVoted": false
      },
      {
        "answer": "A",
        "count": 3,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2021-06-07T00:58:00.000Z",
        "voteCount": 18,
        "content": "I think it's C, because dashboard viewer \"Read-only access to dashboard configurations.\"\nSRE team wants to view data, not configurations."
      },
      {
        "date": "2021-06-07T09:36:00.000Z",
        "voteCount": 9,
        "content": "correct there is no such role - \"dashboard viewer\" the correct name is monitoring dashboard configuration viewer (and the permission is - Read-only access to dashboard configurations).\n\nso correct answer should be - C"
      },
      {
        "date": "2021-08-10T12:59:00.000Z",
        "voteCount": 1,
        "content": "but it gives access to all list in monitoring of the project."
      },
      {
        "date": "2022-10-29T13:54:00.000Z",
        "voteCount": 3,
        "content": "C is correct"
      },
      {
        "date": "2023-12-19T16:19:00.000Z",
        "voteCount": 1,
        "content": "There is, but only the single role won't give sufficient access.\nhttps://cloud.google.com/monitoring/access-control?hl=de#monitoring.dashboardViewer"
      },
      {
        "date": "2021-08-29T08:19:00.000Z",
        "voteCount": 12,
        "content": "I did a test and see that:\n\nThe valid roles are: Monitoring Viewer and Monitoring Dashboard Configuration Viewer.\nYou can only share chart by URL using Metrics explorer.\n\n\nWith only Monitoring Dashboard Configuration Viewer role, user cannot see anything in Monitoring page.\n\nI create a custom role from Monitoring Dashboard Configuration Viewer role and add resourcemanager.projects.get permission.\n\nNow user can see list of custom dashboards and the charts in these custom dashboards. User cannot see standard GCP dashboards.\n\nUser cannot see the the chart in Metrics explorer (using the shared URL).\nOpening the URL, user will see errors: \"Invalid resource type\" and \"Invalid metric type\".\n\nSo even if I ignore the typo of Dashboard Viewer role in B and D, they are still incorrect answers.\n\nSo only A and C are valid. But I think C is better because the question is: \"You want to share the chart\" not the whole dashboard."
      },
      {
        "date": "2024-09-26T03:13:00.000Z",
        "voteCount": 5,
        "content": "Ans: C\nthis question is kind of weird because the role is: roles/monitoring.dashboardViewer\t\"Monitoring Dashboard Configuration Viewer\" but monitoring viewer its too much access so I tested in console\n\nhttps://cloud.google.com/iam/docs/understanding-roles\n\nwith Dashboard Viewer I would\u00b4nt be allowed to see the chart URL\nwith monitoring works fine\n\nDashboard Viewer Provides read-only access to get and list information about all monitoring data and configurations."
      },
      {
        "date": "2024-09-26T03:12:00.000Z",
        "voteCount": 1,
        "content": "C \nThere are a number of IAM security roles related to monitoring. The big three are\nviewer, editor, and admin.\nTo create the monitoring Workspace initially, a user will need the Monitoring Editor or\nAdmin role in the Workspace's host project.\nThe Monitoring Viewer can get read-only access to the Monitoring console and API.\nThe Monitoring Editor has read-write access to the Monitoring console and APIs and\ncan write monitoring data and configurations into the Workspace.\nAnd the Monitoring Admin has full access to, and control over, all monitoring\nresources.\nPast these big three roles, monitoring roles exist to provide and limit access to alert\npolicies, dashboards, notification channels, service monitoring, and uptime checks."
      },
      {
        "date": "2024-09-26T03:12:00.000Z",
        "voteCount": 1,
        "content": "The best option in this case would be C. Click \"Share chart by URL\" and provide the URL to the SRE team. Assign the SRE team the Monitoring Viewer IAM role in the workspace project.\nThis option allows you to share the specific chart with the SRE team only, granting them read-only access to the chart's data, this way the team can view the CPU utilization chart and troubleshoot any performance issues related to the chart.\nYou can use the feature of \"Share chart by URL\" to share the specific chart with the SRE team only, and provide a secure URL that can only be access by members of the team. And also giving them the \"Monitoring Viewer\" role, will give them just enough privilege to see the chart and its data but not the ability to make changes to the project, dashboard or other charts."
      },
      {
        "date": "2024-07-03T22:38:00.000Z",
        "voteCount": 1,
        "content": "D) Dashboard viewer follows the principle of least privileges."
      },
      {
        "date": "2024-06-02T18:59:00.000Z",
        "voteCount": 1,
        "content": "My vote is C"
      },
      {
        "date": "2024-05-24T03:15:00.000Z",
        "voteCount": 2,
        "content": "Option A grants the SRE team more access than necessary. The Monitoring Viewer role allows them to view all monitoring data in the project, not just the chart you want to share.\nOption B is a good option, but it is not as secure as option D. The Dashboard Viewer role allows the SRE team to view all dashboards in the project, not just the chart you want to share.\nOption C is not secure. Anyone who has the URL can view the chart, even if they are not a member of the SRE team.\nOption D is the most secure option. It allows the SRE team to view the chart without giving them access to any other data in the project.\nHere are the steps on how to share the chart with the SRE team:"
      },
      {
        "date": "2024-05-24T03:15:00.000Z",
        "voteCount": 1,
        "content": "Open the Stackdriver dashboard that contains the chart you want to share.\nClick the Share button in the top right corner of the dashboard.\nClick Share chart by URL .\nCopy the URL and share it with the SRE team.\nIn the IAM &amp; Admin section of the Google Cloud Console, navigate to the workspace project.\nClick on IAM &amp; Admin &gt; IAM .\nClick Add .\nIn the New members field, enter the email address of the SRE team.\nIn the Select a role dropdown, select Dashboard Viewer .\nClick Save .\nThe SRE team will now be able to view the chart by clicking on the URL you shared with them. They will not have access to any other data in the project."
      },
      {
        "date": "2024-05-24T03:15:00.000Z",
        "voteCount": 1,
        "content": "Additional Considerations\nIt is important to note that the principle of least privilege is not just about security. It is also about efficiency. By giving users only the access they need, you can reduce the risk of errors and make it easier to manage your resources.\n\nHere are some additional tips for following the principle of least privilege:\n\nReview your IAM roles regularly. Make sure that users only have the access they need.\nUse groups to manage access. This can make it easier to grant and revoke access to multiple users at once.\nUse temporary access when possible. This can help to reduce the risk of unauthorized access.\nBy following these tips, you can help to ensure that your Google Cloud resources are secure and efficient."
      },
      {
        "date": "2024-03-07T03:33:00.000Z",
        "voteCount": 1,
        "content": "There is no such role as \"Dashboard Viewer\""
      },
      {
        "date": "2023-11-09T03:16:00.000Z",
        "voteCount": 1,
        "content": "The answer is C because :\nDashboard viewer role not exists , monitor-viewer only\nhttps://cloud.google.com/iam/docs/understanding-roles#monitoring.viewer\nand Cloud Monitoring allows you to share the URL of the individual Dashboard and not of the entire project ID"
      },
      {
        "date": "2023-10-26T19:44:00.000Z",
        "voteCount": 1,
        "content": "It is the right answer"
      },
      {
        "date": "2022-12-24T00:07:00.000Z",
        "voteCount": 2,
        "content": "Ans: C\n\nExam take on 19/12/2022, 50/50 from this dump without buying the full access."
      },
      {
        "date": "2022-12-11T10:44:00.000Z",
        "voteCount": 2,
        "content": "I think is A, because there isn't any button \"Share chart by URL\", and least role is Monitoring Viewer (Dashboard viewer can see only dashboard configurations)"
      },
      {
        "date": "2022-12-06T01:24:00.000Z",
        "voteCount": 1,
        "content": "Decided to go for A on the exam because there is no \"Share chart by URL\" button, it's just \"Share by URL\"."
      },
      {
        "date": "2022-12-11T10:45:00.000Z",
        "voteCount": 1,
        "content": "But \"Share by URL\" is in chart? I remember it's only logging explorer"
      },
      {
        "date": "2022-11-17T18:05:00.000Z",
        "voteCount": 2,
        "content": "i think it is A, i assume add chart into custom/default dashboard is best practice for creating chart and share URL would more like one time trade.\nMetrics Explorer lets you create a chart that you can use to explore a metric. However, the charts created by this tool aren't persistent. When you navigate away from the Metrics Explorer page, the chart is discarded.\n\nTo save a chart you've configured with Metrics Explorer for future reference, add the chart to a custom dashboard or save the chart's URL: \nTo keep a reference to the chart configuration, save the chart URL. Because the chart URL encodes the chart configuration, when you paste this URL into a browser the chart you configured is displayed."
      },
      {
        "date": "2022-11-17T18:08:00.000Z",
        "voteCount": 1,
        "content": "and this is not \" share chart by URL \" option, it is  \" share by URL\""
      },
      {
        "date": "2022-11-08T07:10:00.000Z",
        "voteCount": 2,
        "content": "I have verified this, both A and C do the same thing except C gives you comfort to see the chart directly using the link without having to browse through all the way to the chart."
      },
      {
        "date": "2022-10-24T05:53:00.000Z",
        "voteCount": 1,
        "content": "C is the answer.\n\nhttps://cloud.google.com/monitoring/access-control#mon_roles_desc\nroles/monitoring.viewer\n- Monitoring Viewer Grants read-only access to Monitoring in the Google Cloud console and API."
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 3,
    "url": "https://www.examtopics.com/discussions/google/view/54221-exam-professional-cloud-devops-engineer-topic-1-question-3/",
    "body": "Your organization wants to implement Site Reliability Engineering (SRE) culture and principles. Recently, a service that you support had a limited outage. A manager on another team asks you to provide a formal explanation of what happened so they can action remediations. What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDevelop a postmortem that includes the root causes, resolution, lessons learned, and a prioritized list of action items. Share it with the manager only.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDevelop a postmortem that includes the root causes, resolution, lessons learned, and a prioritized list of action items. Share it on the engineering organization's document portal.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDevelop a postmortem that includes the root causes, resolution, lessons learned, the list of people responsible, and a list of action items for each person. Share it with the manager only.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDevelop a postmortem that includes the root causes, resolution, lessons learned, the list of people responsible, and a list of action items for each person. Share it on the engineering organization's document portal."
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 13,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-06-02T08:10:00.000Z",
        "voteCount": 25,
        "content": "B it could be based on this In order to maintain a healthy postmortem culture within an organization, it\u2019s important to share postmortems as widely as possible."
      },
      {
        "date": "2021-06-03T10:48:00.000Z",
        "voteCount": 6,
        "content": "agree with you for B based on blameless postmortem culture.\nC and D promote blame by adding people responsible."
      },
      {
        "date": "2021-06-28T15:26:00.000Z",
        "voteCount": 6,
        "content": "I have submitted B answer"
      },
      {
        "date": "2024-06-02T19:18:00.000Z",
        "voteCount": 1,
        "content": "Vote on B"
      },
      {
        "date": "2023-10-26T19:46:00.000Z",
        "voteCount": 1,
        "content": "Right answer"
      },
      {
        "date": "2023-01-10T21:07:00.000Z",
        "voteCount": 1,
        "content": "B is the answer"
      },
      {
        "date": "2022-12-24T00:08:00.000Z",
        "voteCount": 1,
        "content": "Ans: B\n\n"
      },
      {
        "date": "2022-12-29T04:57:00.000Z",
        "voteCount": 1,
        "content": "But, it doesn't show answers after 40. Can you please send me the questions list somehow?"
      },
      {
        "date": "2022-12-06T01:25:00.000Z",
        "voteCount": 1,
        "content": "Submitted B"
      },
      {
        "date": "2022-11-26T11:11:00.000Z",
        "voteCount": 1,
        "content": "Ans B. as the application is not writing to STDOUT or STDERR. Source for the answer - https://cloud.google.com/stackdriver/docs/solutions/gke/managing-logs\nExtract from this source relevant for the answer. \nGKE's default logging agent provides a managed solution to deploy and manage the agents that send the logs for your clusters to Cloud Logging. Depending on your GKE cluster master version, either fluentd or fluentbit are used to collect logs. Starting from GKE 1.17, logs are collected using a fluentbit-based agent. GKE clusters using versions prior to GKE 1.17 use a fluentd-based agent. If you want to alter the default behavior of the fluentdagents, then you can run a customized fluentd agent or a customized fluentbit agent.\n\nCommon use cases include:\nremoving sensitive data from your logs\ncollecting additional logs not written to STDOUT or STDERR\nusing specific performance-related settings\ncustomized log formatting"
      },
      {
        "date": "2022-11-26T11:15:00.000Z",
        "voteCount": 1,
        "content": "This response was for Question 4 and not for Question 3. I posted it here by mistake."
      },
      {
        "date": "2022-10-29T13:53:00.000Z",
        "voteCount": 1,
        "content": "B is right answer"
      },
      {
        "date": "2022-10-24T05:54:00.000Z",
        "voteCount": 1,
        "content": "B is the answer."
      },
      {
        "date": "2022-10-23T13:08:00.000Z",
        "voteCount": 1,
        "content": "B is looks perfect"
      },
      {
        "date": "2022-08-11T20:44:00.000Z",
        "voteCount": 3,
        "content": "B is correct.\nC and D is wrong as it is against the SRE policy of Blameless postmortem.\nA is wrong as these actions cannot be shared with just manager"
      },
      {
        "date": "2022-07-23T21:17:00.000Z",
        "voteCount": 2,
        "content": "The answer is B"
      },
      {
        "date": "2022-05-09T09:35:00.000Z",
        "voteCount": 3,
        "content": "Submitted B in the exam. I cleared the exam today"
      },
      {
        "date": "2022-05-07T04:14:00.000Z",
        "voteCount": 1,
        "content": "B should be the right one"
      },
      {
        "date": "2022-03-09T00:50:00.000Z",
        "voteCount": 2,
        "content": "Selected B"
      },
      {
        "date": "2021-12-05T04:51:00.000Z",
        "voteCount": 2,
        "content": "Ans: B"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 4,
    "url": "https://www.examtopics.com/discussions/google/view/54226-exam-professional-cloud-devops-engineer-topic-1-question-4/",
    "body": "You have a set of applications running on a Google Kubernetes Engine (GKE) cluster, and you are using Stackdriver Kubernetes Engine Monitoring. You are bringing a new containerized application required by your company into production. This application is written by a third party and cannot be modified or reconfigured. The application writes its log information to /var/log/app_messages.log, and you want to send these log entries to Stackdriver Logging. What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse the default Stackdriver Kubernetes Engine Monitoring agent configuration.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDeploy a Fluentd daemonset to GKE. Then create a customized input and output configuration to tail the log file in the application's pods and write to Stackdriver Logging.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tInstall Kubernetes on Google Compute Engine (GCE) and redeploy your applications. Then customize the built-in Stackdriver Logging configuration to tail the log file in the application's pods and write to Stackdriver Logging.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tWrite a script to tail the log file within the pod and write entries to standard output. Run the script as a sidecar container with the application's pod. Configure a shared volume between the containers to allow the script to have read access to /var/log in the application container."
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 21,
        "isMostVoted": true
      },
      {
        "answer": "D",
        "count": 12,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2024-09-21T02:35:00.000Z",
        "voteCount": 6,
        "content": "Ans is B\n\nBesides the list of default logs that the Logging agent streams by default, you can customize the Logging agent to send additional logs to Logging or to adjust agent settings by adding input configurations.\nThe configuration definitions in these sections apply to the fluent-plugin-google-cloud output plugin only and specify how logs are transformed and ingested into Cloud Logging.\n"
      },
      {
        "date": "2021-07-24T22:17:00.000Z",
        "voteCount": 6,
        "content": "B is correct.\n"
      },
      {
        "date": "2024-09-26T03:15:00.000Z",
        "voteCount": 4,
        "content": "I believe that is B,\nThis tutorial describes how to customize Fluentd logging for a Google Kubernetes Engine cluster. You'll learn how to host your own configurable Fluentd daemonset to send logs to Cloud Logging, instead of selecting the cloud logging option when creating the Google Kubernetes Engine (GKE) cluster, which does not allow configuration of the Fluentd daemon"
      },
      {
        "date": "2024-09-26T03:15:00.000Z",
        "voteCount": 1,
        "content": "Ans B. as the application is not writing to STDOUT or STDERR. Source for the answer - https://cloud.google.com/stackdriver/docs/solutions/gke/managing-logs\nExtract from this source relevant for the answer.\nGKE's default logging agent provides a managed solution to deploy and manage the agents that send the logs for your clusters to Cloud Logging. Depending on your GKE cluster master version, either fluentd or fluentbit are used to collect logs. Starting from GKE 1.17, logs are collected using a fluentbit-based agent. GKE clusters using versions prior to GKE 1.17 use a fluentd-based agent. If you want to alter the default behavior of the fluentdagents, then you can run a customized fluentd agent or a customized fluentbit agent.\n\nCommon use cases include:\nremoving sensitive data from your logs\ncollecting additional logs not written to STDOUT or STDERR\nusing specific performance-related settings\ncustomized log formatting"
      },
      {
        "date": "2024-09-26T03:15:00.000Z",
        "voteCount": 4,
        "content": "B is the answer.\n\nhttps://cloud.google.com/stackdriver/docs/solutions/gke/managing-logs#custom_agents\nGKE's default logging agent provides a managed solution to deploy and manage the agents that send the logs for your clusters to Cloud Logging. Depending on your GKE cluster master version, either fluentd or fluentbit are used to collect logs. \nCommon use cases include:\n- collecting additional logs not written to STDOUT or STDERR\n- customized log formatting"
      },
      {
        "date": "2024-09-26T03:14:00.000Z",
        "voteCount": 1,
        "content": "B. Deploy a Fluentd daemonset to GKE. Then create a customized input and output configuration to tail the log file in the application's pods and write to Stackdriver Logging.\n\nStackdriver Kubernetes Engine Monitoring provides log collection and analysis for Kubernetes clusters running on GKE out of the box, but the default configuration doesn't include the ability to tail a specific log file. To collect log entries written to /var/log/app_messages.log, you can deploy a Fluentd daemonset to your GKE cluster. Fluentd is a log collector and forwarder that can be configured to tail a specific log file, in this case, /var/log/app_messages.log and send the log entries to Stackdriver Logging.\n\nBy deploying a Fluentd daemonset, you can create a customized input and output configuration, you can use this configuration to tail the log file in the application's pods and write to Stackdriver Logging, this allows you to collect the logs from that specific application, ensuring that the logs are going to stackdriver and can be analyzed later on."
      },
      {
        "date": "2023-01-10T21:21:00.000Z",
        "voteCount": 3,
        "content": "Option D is NOT the ideal choice as it would require creating and maintaining a custom script that would have to be deployed with the application's pod in order to tail the log file and write the entries to standard output. This would mean that you would need to take care of the maintenance of this script on every new deployment, update or scaling of the pod, and also the script would need to handle all the edge cases, errors and permissions issues by your own.\n\nFurthermore, this option doesn't use the Stackdriver Logging service, the script would be writing to standard output, which may not be as reliable and secure as writing to a centralized logging service such as Stackdriver Logging. This would also require additional setup and maintenance to route the standard output to a location where the logs can be analyzed, this would take additional development and maintenance effort that would be redundant when compared to the other options."
      },
      {
        "date": "2024-09-26T03:14:00.000Z",
        "voteCount": 1,
        "content": "Ans. is B.\nThis solution is want to send log msg to the Stackdriver logging. However, C is possible IF we have a third party log collector like FluentD that monitoring STDOUT log from the cluster, but this question does not. \nTherefore, the answer must is B, because any content of container that write in files, we can scrape it in hosted worker node. It store in path /var/containers/* . If we create a customize tail path in the FluentD to monitor any path that store log content, we could use a STAR(*) operator to tell a plugins to find all folders that contain file named app_message.log ."
      },
      {
        "date": "2024-09-21T02:35:00.000Z",
        "voteCount": 2,
        "content": "Sidecar is expected here"
      },
      {
        "date": "2024-05-03T23:39:00.000Z",
        "voteCount": 1,
        "content": "Deploy a Fluentd daemonset to GKE"
      },
      {
        "date": "2023-10-24T20:56:00.000Z",
        "voteCount": 2,
        "content": "To collect log entries from a specific file within each node in your GKE cluster, you can use a DaemonSet, Fluentd is often used as the logging agent for log forwarding in GKE."
      },
      {
        "date": "2023-01-08T15:50:00.000Z",
        "voteCount": 3,
        "content": "The answer is D. Fluent D cannot read logs from files.\nhttps://kubernetes.io/docs/concepts/cluster-administration/logging/#sidecar-container-with-logging-agent\n\nBy having your sidecar containers write to their own stdout and stderr streams, you can take advantage of the kubelet and the logging agent that already run on each node. The sidecar containers read logs from a file, a socket, or journald. Each sidecar container prints a log to its own stdout or stderr stream."
      },
      {
        "date": "2022-12-06T01:25:00.000Z",
        "voteCount": 1,
        "content": "Submitted B"
      },
      {
        "date": "2022-12-04T23:45:00.000Z",
        "voteCount": 1,
        "content": "i will go with B. flentd daemonset cannot collect logs from other pods , it collects logs from host filesystem ( stdout, stderr) https://cloud.google.com/architecture/best-practices-for-operating-containers#use_the_native_logging_mechanisms_of_containers"
      },
      {
        "date": "2022-12-02T06:23:00.000Z",
        "voteCount": 1,
        "content": "I think this should be D instead of B, and here's why:\nInstalling a Fluentd daemonset will not solve your problem, as that logfile is not accessible by the Fluent pods. You'd need a sidecar to make the logfile accessible to another container, which will then be responsible for forwarding the logs to stdout. A daemonset will not do that, but a sidecar tailing the logs will."
      },
      {
        "date": "2022-10-23T13:13:00.000Z",
        "voteCount": 2,
        "content": "B is correct \nhttps://cloud.google.com/architecture/customizing-stackdriver-logs-fluentd"
      },
      {
        "date": "2022-08-15T16:42:00.000Z",
        "voteCount": 2,
        "content": "D - Installing Fluentd is overkill"
      },
      {
        "date": "2022-08-10T03:25:00.000Z",
        "voteCount": 1,
        "content": "GCP is not using fluentBit (and not fluent anymore) and it logs application data via STDOUT and STDERR, meaning you need to tail your app log to see it on CloudLogging. \nhttps://cloud.google.com/stackdriver/docs/solutions/gke/managing-logs#custom_agents"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 5,
    "url": "https://www.examtopics.com/discussions/google/view/54227-exam-professional-cloud-devops-engineer-topic-1-question-5/",
    "body": "You are running an application in a virtual machine (VM) using a custom Debian image. The image has the Stackdriver Logging agent installed. The VM has the cloud-platform scope. The application is logging information via syslog. You want to use Stackdriver Logging in the Google Cloud Platform Console to visualize the logs. You notice that syslog is not showing up in the \"All logs\" dropdown list of the Logs Viewer. What is the first thing you should do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tLook for the agent's test log entry in the Logs Viewer.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tInstall the most recent version of the Stackdriver agent.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tVerify the VM service account access scope includes the monitoring.write scope.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSSH to the VM and execute the following commands on your VM: ps ax | grep fluentd.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 8,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-08-07T20:25:00.000Z",
        "voteCount": 12,
        "content": "Between C and D,  I think D\n\nReason : When an instance is created, we can specify which service account the instance uses when calling Google Cloud APIs. The instance is automatically configured with access scope and one such access scope is monitoring.write  (Link : https://cloud.google.com/compute/docs/access/service- read is to publish metric data and logging.write is to write compute engine logs.\n\nConsidering above, I believe D as the answer (check whether the agent is running)"
      },
      {
        "date": "2021-09-13T03:50:00.000Z",
        "voteCount": 3,
        "content": "Agree. If you check here: https://cloud.google.com/logging/docs/agent/logging/troubleshooting#checklist\nYou will see that first recommended troubleshooting step is to check if the agent is running or not... So it should be D.\n\nAlso if you refer to Google Groups link provided as the answer, you will see that they first checked if the agent is running/installed."
      },
      {
        "date": "2024-04-11T12:06:00.000Z",
        "voteCount": 1,
        "content": "Why nnot Answer A as a starting point?"
      },
      {
        "date": "2023-01-10T21:27:00.000Z",
        "voteCount": 1,
        "content": "Answer is D."
      },
      {
        "date": "2022-12-24T00:09:00.000Z",
        "voteCount": 2,
        "content": "Ans: D\n\n"
      },
      {
        "date": "2022-11-26T10:36:00.000Z",
        "voteCount": 2,
        "content": "D. Check if fluentd is running is the right answer. C is incorrect as monitoring.write scope is for monitoring agent and not logging agent. "
      },
      {
        "date": "2022-10-24T06:14:00.000Z",
        "voteCount": 1,
        "content": "D is the answer.\n\nhttps://cloud.google.com/logging/docs/agent/logging/troubleshooting#checklist\nIf you are having trouble installing or using the Logging agent, here are some things to check:\n- Verify that the agent service is running on your VM instance"
      },
      {
        "date": "2022-07-23T23:03:00.000Z",
        "voteCount": 1,
        "content": "Ans: D"
      },
      {
        "date": "2022-06-17T05:43:00.000Z",
        "voteCount": 1,
        "content": "Ans: D"
      },
      {
        "date": "2022-05-09T09:36:00.000Z",
        "voteCount": 1,
        "content": "Submitted D"
      },
      {
        "date": "2022-04-19T21:34:00.000Z",
        "voteCount": 1,
        "content": "answer is D"
      },
      {
        "date": "2022-02-14T23:47:00.000Z",
        "voteCount": 2,
        "content": "The VM has cloud-platform scope on the VM means Full access if you using the default compute account. I would say answer D is right check is the fluentd daemon running."
      },
      {
        "date": "2022-01-26T02:49:00.000Z",
        "voteCount": 1,
        "content": "https://cloud.google.com/logging/docs/agent/logging/troubleshooting#test-agent"
      },
      {
        "date": "2021-12-05T04:55:00.000Z",
        "voteCount": 2,
        "content": "Ans: D"
      },
      {
        "date": "2021-11-24T06:15:00.000Z",
        "voteCount": 2,
        "content": "C is not good, \u201cmonitoring.write\" is use for metric not log"
      },
      {
        "date": "2021-08-29T09:17:00.000Z",
        "voteCount": 1,
        "content": "https://cloud.google.com/compute/docs/access/service-accounts#associating_a_service_account_to_an_instance\n\nWhen you create an instance using the gcloud command-line tool or the Google Cloud Console, you can specify which service account the instance uses when calling Google Cloud APIs. The instance is automatically configured with the following access scopes:\n\n\n* ...\n\nSo D is better than C."
      },
      {
        "date": "2021-09-30T09:48:00.000Z",
        "voteCount": 1,
        "content": "i don't think so , reason is option-D is looking for fluent d which is specifically for customized logs , also by default the syslog will be captured with default monitoring agent and no need for fluent-d"
      },
      {
        "date": "2021-10-31T07:50:00.000Z",
        "voteCount": 1,
        "content": "https://cloud.google.com/logging/docs/agent/logging/installation\n\nLogging agent is fluentd based (now fluentbit).\n\nThe Logging agent streams logs from your VM instances and from selected third-party software packages to Cloud Logging. It is a best practice to run the Logging agent on all your VM instances.\n\nThe VM images for Compute Engine and Amazon Elastic Compute Cloud (EC2) don't include the Logging agent, so you must complete these steps to install it on those instances. The agent runs under both Linux and Windows.\n\nIf your VMs are running in Google Kubernetes Engine or App Engine, the agent is already included in the VM image, so you can skip this page."
      },
      {
        "date": "2021-06-23T17:02:00.000Z",
        "voteCount": 2,
        "content": "C, first thing to check should be the access scope. There are 3 types of scopes, default, full access and access for each API. Even thought the default scope have the Stackdriver write access, it doesn't mean the instance has the default scope. It could be access for each API. Hence, first thing to check is the scope. After that, you can check the fluentd service in the system. C over D."
      },
      {
        "date": "2021-11-24T06:14:00.000Z",
        "voteCount": 1,
        "content": "Monitoring.write is for metric, so C is not correct. In that case logging.write was the right command. So D is the correct ANS ;)"
      },
      {
        "date": "2021-06-22T02:48:00.000Z",
        "voteCount": 2,
        "content": "Ans C \nhttps://cloud.google.com/logging/docs/agent/logging/troubleshooting"
      },
      {
        "date": "2021-09-27T23:21:00.000Z",
        "voteCount": 2,
        "content": "Sorry Ans is D"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 6,
    "url": "https://www.examtopics.com/discussions/google/view/54228-exam-professional-cloud-devops-engineer-topic-1-question-6/",
    "body": "You use a multiple step Cloud Build pipeline to build and deploy your application to Google Kubernetes Engine (GKE). You want to integrate with a third-party monitoring platform by performing a HTTP POST of the build information to a webhook. You want to minimize the development effort. What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAdd logic to each Cloud Build step to HTTP POST the build information to a webhook.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAdd a new step at the end of the pipeline in Cloud Build to HTTP POST the build information to a webhook.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse Stackdriver Logging to create a logs-based metric from the Cloud Build logs. Create an Alert with a Webhook notification type.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a Cloud Pub/Sub push subscription to the Cloud Build cloud-builds PubSub topic to HTTP POST the build information to a webhook.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 13,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-06-28T15:28:00.000Z",
        "voteCount": 17,
        "content": "I have submitted D answer"
      },
      {
        "date": "2021-06-19T15:38:00.000Z",
        "voteCount": 17,
        "content": "Ans: D \nPub/Sub\n\nA: No becauseThere is not Structure attribute to create a http request in the steps and remember you want minimize the development effort.\nB: The same A\nC: minimize the development effort\nD: Its OK\n\nTo receive messages from push subscriptions, use a webhook and process the POST requests that Pub/Sub sends to the push endpoint. For more information about processing these POST requests in App Engine, see Writing and responding to Pub/Sub messages.\n\nhttps://cloud.google.com/pubsub/docs/push\nhttps://cloud.google.com/build/docs/subscribe-build-notifications"
      },
      {
        "date": "2023-01-10T21:34:00.000Z",
        "voteCount": 1,
        "content": "Answer D"
      },
      {
        "date": "2022-12-24T00:10:00.000Z",
        "voteCount": 2,
        "content": "Ans: D\n\n"
      },
      {
        "date": "2022-10-24T06:17:00.000Z",
        "voteCount": 6,
        "content": "D is the answer.\n\nhttps://cloud.google.com/build/docs/subscribe-build-notifications\nCloud Build publishes messages on a Google Pub/Sub topic when your build's state changes, such as when your build is created, when your build transitions to a working state, and when your build completes.\n\nThe Pub/Sub topic to which Cloud Build publishes these build update messages is called cloud-builds. Each message contains a base64 JSON string representation of your Build resource in the message.data attribute. The build's unique ID and the build's status can be found in the message.attributes field.\n\nYou can use a push or pull model for your Pub/Sub subscriptions.\n\nhttps://cloud.google.com/build/docs/subscribe-build-notifications#push\nPush subscriptions deliver messages to an HTTP endpoint that you define. Messages are delivered as soon as they are published to the topic."
      },
      {
        "date": "2022-10-29T13:59:00.000Z",
        "voteCount": 1,
        "content": "Yes, D is right based on given scenario"
      },
      {
        "date": "2022-07-23T23:04:00.000Z",
        "voteCount": 1,
        "content": "Ans: D"
      },
      {
        "date": "2022-05-09T09:40:00.000Z",
        "voteCount": 1,
        "content": "Submitted D in exam."
      },
      {
        "date": "2022-05-04T01:09:00.000Z",
        "voteCount": 2,
        "content": "Cloud Build -&gt; Pubsub -&gt; HTTP Builder.........SO ans is D"
      },
      {
        "date": "2022-01-26T03:11:00.000Z",
        "voteCount": 3,
        "content": "Not sure on D. Pub/Sub posts into specific format and the actual payload in is message.data.\nThird party system API (where you post status) will have its own POST format. \nI feel B is better - you add a step in CLoud Build to do the POST."
      },
      {
        "date": "2021-12-05T04:56:00.000Z",
        "voteCount": 1,
        "content": "Ans : D"
      },
      {
        "date": "2021-11-25T16:21:00.000Z",
        "voteCount": 1,
        "content": "Its D. Cloud Build -&gt; Pubsub -&gt; HTTP Builder"
      },
      {
        "date": "2021-06-06T18:32:00.000Z",
        "voteCount": 2,
        "content": "D is correct answer \nhttps://cloud.google.com/build/docs/subscribe-build-notifications"
      },
      {
        "date": "2021-06-12T00:51:00.000Z",
        "voteCount": 2,
        "content": "Agree D looks correct to me."
      },
      {
        "date": "2021-06-02T08:35:00.000Z",
        "voteCount": 1,
        "content": "no idea on this"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 7,
    "url": "https://www.examtopics.com/discussions/google/view/54231-exam-professional-cloud-devops-engineer-topic-1-question-7/",
    "body": "You use Spinnaker to deploy your application and have created a canary deployment stage in the pipeline. Your application has an in-memory cache that loads objects at start time. You want to automate the comparison of the canary version against the production version. How should you configure the canary analysis?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCompare the canary with a new deployment of the current production version.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCompare the canary with a new deployment of the previous production version.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCompare the canary with the existing deployment of the current production version.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCompare the canary with the average performance of a sliding window of previous production versions."
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 10,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-06-06T18:38:00.000Z",
        "voteCount": 16,
        "content": "i guess A\n"
      },
      {
        "date": "2021-06-09T17:54:00.000Z",
        "voteCount": 3,
        "content": "A is correct.\nhttps://cloud.google.com/architecture/automated-canary-analysis-kubernetes-engine-spinnaker\nhttps://spinnaker.io/guides/user/canary/best-practices/#compare-canary-against-baseline-not-against-production"
      },
      {
        "date": "2021-06-10T03:29:00.000Z",
        "voteCount": 2,
        "content": "Agree with - A is the correct one.\nhttps://cloud.google.com/architecture/automated-canary-analysis-kubernetes-engine-spinnaker"
      },
      {
        "date": "2021-10-28T00:50:00.000Z",
        "voteCount": 3,
        "content": "Correct in the link: \"You might be tempted to compare the canary deployment against your current production deployment. Instead always compare the canary against an equivalent baseline, deployed at the same time.\""
      },
      {
        "date": "2021-06-19T15:58:00.000Z",
        "voteCount": 10,
        "content": "Ans A\n\nhttps://spinnaker.io/guides/user/canary/best-practices/#compare-canary-against-baseline-not-against-production\nYou might be tempted to compare the canary deployment against your current production deployment. Instead always compare the canary against an equivalent baseline, deployed at the same time.\n\nThe baseline uses the same version and configuration that is currently running in production, but is otherwise identical to the canary:\n\nSame time of deployment\nSame size of deployment\nSame type and amount of traffic\nIn this way, you control for version and configuration only, and you reduce factors that could affect the analysis, like the cache warmup time, the heap size, and so on."
      },
      {
        "date": "2021-11-01T04:16:00.000Z",
        "voteCount": 1,
        "content": "yes correct"
      },
      {
        "date": "2022-10-29T14:01:00.000Z",
        "voteCount": 1,
        "content": "Agree with A"
      },
      {
        "date": "2024-09-26T03:18:00.000Z",
        "voteCount": 1,
        "content": "Explanation taking into account the in-memory cache:\n\nIn-memory Cache Impact:  The in-memory cache loading at start time means that both the canary and the current production version could have different data in their caches. This difference could skew the comparison if you compare the canary directly to the existing production version (Option C).\n\nLeveling the Playing Field:  By deploying a fresh instance of the current production version (Option A), you ensure that both the canary and the comparison baseline have the same starting point in terms of cache data. This makes the comparison more accurate and reliable."
      },
      {
        "date": "2023-01-10T21:37:00.000Z",
        "voteCount": 1,
        "content": "Answer A"
      },
      {
        "date": "2022-12-24T00:10:00.000Z",
        "voteCount": 1,
        "content": "Ans: A\n\n"
      },
      {
        "date": "2022-11-20T19:13:00.000Z",
        "voteCount": 1,
        "content": "and apply \" a new deployment production \" for analysis is against canary test purpose."
      },
      {
        "date": "2022-11-20T19:11:00.000Z",
        "voteCount": 1,
        "content": "i think i will go with D\nthe baseline version must have : \nEnsure that the baseline and production versions of your application are identical.\nDeploy the baseline version at the same time that you deploy the canary.\nEnsure that the baseline deployment (such as the number of application instances and autoscaling policies) matches the canary deployment.\nUse the baseline version to serve the same traffic as the canary.\n\nin this case , the \" new deployment of production\" as a baseline version is violating the third rules ? the new deployment of production is not matching canary deployment"
      },
      {
        "date": "2022-11-12T08:13:00.000Z",
        "voteCount": 1,
        "content": "A is correct"
      },
      {
        "date": "2022-10-30T07:38:00.000Z",
        "voteCount": 2,
        "content": "A is right\nYou might be tempted to compare the canary deployment against your current production deployment. Instead always compare the canary against an equivalent baseline, deployed at the same time.\n\nThe baseline uses the same version and configuration that is currently running in production, but is otherwise identical to the canary:\n\nSame time of deployment\nSame size of deployment\nSame type and amount of traffic\nIn this way, you control for version and configuration only, and you reduce factors that could affect the analysis, like the cache warmup time, the heap size, and so on."
      },
      {
        "date": "2022-10-24T06:22:00.000Z",
        "voteCount": 1,
        "content": "A is the answer.\n\nhttps://cloud.google.com/architecture/application-deployment-and-testing-strategies#canary_test_pattern\nWe recommend that you compare the canary against an equivalent baseline and not the live production environment."
      },
      {
        "date": "2022-10-02T05:01:00.000Z",
        "voteCount": 1,
        "content": "answer is A"
      },
      {
        "date": "2022-07-23T23:37:00.000Z",
        "voteCount": 1,
        "content": "Ans : A"
      },
      {
        "date": "2022-07-07T10:37:00.000Z",
        "voteCount": 1,
        "content": "Correct with most comments here. It must be A."
      },
      {
        "date": "2022-05-28T05:46:00.000Z",
        "voteCount": 1,
        "content": "A is ok"
      },
      {
        "date": "2022-04-19T23:15:00.000Z",
        "voteCount": 1,
        "content": "A is correct!!!"
      },
      {
        "date": "2022-01-03T14:37:00.000Z",
        "voteCount": 1,
        "content": "A is the correct answer"
      },
      {
        "date": "2021-12-05T04:58:00.000Z",
        "voteCount": 1,
        "content": "Ans : A"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 8,
    "url": "https://www.examtopics.com/discussions/google/view/54233-exam-professional-cloud-devops-engineer-topic-1-question-8/",
    "body": "You support a high-traffic web application and want to ensure that the home page loads in a timely manner. As a first step, you decide to implement a Service<br>Level Indicator (SLI) to represent home page request latency with an acceptable page load time set to 100 ms. What is the Google-recommended way of calculating this SLI?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tBucketize the request latencies into ranges, and then compute the percentile at 100 ms.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tBucketize the request latencies into ranges, and then compute the median and 90th percentiles.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCount the number of home page requests that load in under 100 ms, and then divide by the total number of home page requests.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCount the number of home page request that load in under 100 ms, and then divide by the total number of all web application requests."
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 5,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-06-28T15:31:00.000Z",
        "voteCount": 17,
        "content": "I have submitted C answer"
      },
      {
        "date": "2021-08-07T20:49:00.000Z",
        "voteCount": 8,
        "content": "https://sre.google/workbook/implementing-slos/\nIn the SRE principles book, it's recommended treating the SLI as the ratio of two numbers: the number of good events divided by the total number of events. For example:\nNumber of successful HTTP requests / total HTTP requests (success rate)"
      },
      {
        "date": "2022-10-23T21:30:00.000Z",
        "voteCount": 1,
        "content": "C is right"
      },
      {
        "date": "2021-08-29T09:54:00.000Z",
        "voteCount": 9,
        "content": "A, B and D: aren't specific to home page, so they are incorrect.\n\nC is correct."
      },
      {
        "date": "2023-12-21T13:52:00.000Z",
        "voteCount": 1,
        "content": "C is the way to go."
      },
      {
        "date": "2023-01-10T21:42:00.000Z",
        "voteCount": 1,
        "content": "Answer C"
      },
      {
        "date": "2022-12-24T00:11:00.000Z",
        "voteCount": 1,
        "content": "Ans: C\n\nExam passed and taken on 19/12/2022, 50/50 from this dump without buying the full access and looking for 'devops' word here: https://www.examtopics.com/discussions/google/1/"
      },
      {
        "date": "2022-08-13T23:05:00.000Z",
        "voteCount": 3,
        "content": "The correct answer is 'C'"
      },
      {
        "date": "2022-06-08T12:49:00.000Z",
        "voteCount": 1,
        "content": "C is the answer"
      },
      {
        "date": "2021-12-05T04:59:00.000Z",
        "voteCount": 1,
        "content": "Ans: C"
      },
      {
        "date": "2021-06-22T07:05:00.000Z",
        "voteCount": 1,
        "content": "B or C?"
      },
      {
        "date": "2021-06-22T02:56:00.000Z",
        "voteCount": 6,
        "content": "Ans C\n"
      },
      {
        "date": "2021-06-19T18:23:00.000Z",
        "voteCount": 4,
        "content": "Ans is B\nAfter a lot of research i find out this:\n\nThe SLI for availability indicates whether the service is working. The SLI for availability is defined as follows:\nThe proportion of valid requests served successfully. (good request / total request)\n\nThe SLI for latency (sometimes called speed) indicates whether the service is fast enough. \nThe proportion of valid requests served faster than a threshold.\nLatency is commonly measured as a distribution. Given a distribution, you can measure various percentiles. For example, you might measure the number of requests that are slower than the historical 99th percentile. In this case, we consider good events to be events that are faster than this threshold, which was set by examining the historical distribution. You can also set this threshold based on product requirements. You can even set multiple latency SLOs, for example typical latency versus tail latency."
      },
      {
        "date": "2021-07-17T00:40:00.000Z",
        "voteCount": 1,
        "content": "Still not sure about B"
      },
      {
        "date": "2021-06-19T18:24:00.000Z",
        "voteCount": 1,
        "content": "and if this is not enough for you check how google calculate Availability and latency\n\nAvailability\n\nsum(rate(http_requests_total{host=\"api\", status!~\"5..\"}[7d]))\n/\nsum(rate(http_requests_total{host=\"api\"}[7d])\n\nLatency\nhistogram_quantile(0.9, rate(http_request_duration_seconds_bucket[7d]))\nhistogram_quantile(0.99, rate(http_request_duration_seconds_bucket[7d]))\n\nhttps://sre.google/workbook/implementing-slos/\nhttps://cloud.google.com/architecture/adopting-slos/"
      },
      {
        "date": "2022-01-26T03:28:00.000Z",
        "voteCount": 2,
        "content": "The commands shared create a histogram that demonstrates the latency distribution for 90 and 99 % of the requests. Does not define how to measure the SLI."
      },
      {
        "date": "2021-07-18T07:36:00.000Z",
        "voteCount": 3,
        "content": "The correct answer is \"C\", you can confirm it here, https://sre.google/workbook/slo-document/\n\nLatency\n\nThe proportion of sufficiently fast requests, as measured from the load balancer metrics.\n\n\u201cSufficiently fast\u201d is defined as &lt; 400 ms, or &lt; 850 ms.\n\ncount of \"api\" http_requests with\na duration less than or equal to\n\"0.4\" seconds\ndivided by\ncount of all \"api\" http_requests"
      },
      {
        "date": "2021-06-12T01:09:00.000Z",
        "voteCount": 5,
        "content": "Answer -C\n\nSLI = good events/valid events X 100"
      },
      {
        "date": "2021-06-12T01:08:00.000Z",
        "voteCount": 4,
        "content": "Answer -C\n\nSLI = good events/good events X 100"
      },
      {
        "date": "2021-06-02T08:46:00.000Z",
        "voteCount": 5,
        "content": "answer C"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 9,
    "url": "https://www.examtopics.com/discussions/google/view/54234-exam-professional-cloud-devops-engineer-topic-1-question-9/",
    "body": "You deploy a new release of an internal application during a weekend maintenance window when there is minimal user tragic. After the window ends, you learn that one of the new features isn't working as expected in the production environment. After an extended outage, you roll back the new release and deploy a fix.<br>You want to modify your release process to reduce the mean time to recovery so you can avoid extended outages in the future. What should you do? (Choose two.)<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tBefore merging new code, require 2 different peers to review the code changes.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAdopt the blue/green deployment strategy when releasing new code via a CD server.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tIntegrate a code linting tool to validate coding standards before any code is accepted into the repository.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRequire developers to run automated integration tests on their local development environments before release.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure a CI server. Add a suite of unit tests to your code and have your CI server run them on commit and verify any changes.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "BE",
    "answerDescription": "",
    "votes": [
      {
        "answer": "BE",
        "count": 18,
        "isMostVoted": true
      },
      {
        "answer": "CE",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2021-06-28T15:31:00.000Z",
        "voteCount": 31,
        "content": "ans BE"
      },
      {
        "date": "2021-06-20T09:21:00.000Z",
        "voteCount": 28,
        "content": "Ans: B &amp; E\n\nA: No, More peers to review dont automate anything\nB: Ok CD \nC: No, Linting is for code format\nD: No, Integration test are needed but its better automatically\nE: Ok CI\n\nCI/CD its OK"
      },
      {
        "date": "2023-12-12T10:18:00.000Z",
        "voteCount": 1,
        "content": "E) CI\nD) CD"
      },
      {
        "date": "2023-12-11T07:09:00.000Z",
        "voteCount": 1,
        "content": "Pretty sure some answers are wrong on purpose. \nB&amp;E are the only suitable options, as they talk about CI/CD."
      },
      {
        "date": "2023-12-01T23:00:00.000Z",
        "voteCount": 1,
        "content": "B and E"
      },
      {
        "date": "2023-11-09T06:24:00.000Z",
        "voteCount": 1,
        "content": "C because Linting is important to reduce errors and improve the overall quality of your code\nE for testing the single unit and so reduce inattentive behavior"
      },
      {
        "date": "2023-09-07T06:13:00.000Z",
        "voteCount": 1,
        "content": "B: reduces roll back time, E: reduces failure rate"
      },
      {
        "date": "2023-09-05T14:38:00.000Z",
        "voteCount": 2,
        "content": "Ans: B and E\nA: I understand the importance, but is not it that will avoid errors because we are humans\nB: Blue/Green will ensure that part of the users were not affected by the bug\nC: Lint code is just one to validate a code format and indentation\nD: To avoid errors is important that tests be run in the pipeline\nE: CI it's a good moment to run all checks"
      },
      {
        "date": "2023-01-10T21:46:00.000Z",
        "voteCount": 1,
        "content": "Answer is BE"
      },
      {
        "date": "2022-11-24T23:40:00.000Z",
        "voteCount": 2,
        "content": "ANS IS"
      },
      {
        "date": "2022-10-29T14:05:00.000Z",
        "voteCount": 1,
        "content": "BE is right"
      },
      {
        "date": "2022-08-10T05:47:00.000Z",
        "voteCount": 1,
        "content": "testing comment dont approve please"
      },
      {
        "date": "2022-07-24T01:35:00.000Z",
        "voteCount": 2,
        "content": "Ans BE"
      },
      {
        "date": "2022-03-30T00:21:00.000Z",
        "voteCount": 1,
        "content": "Definitely B, as this will reduce recovery time as the question asks for. I would think D over E, as the problem states 'not working as expected in production'. Unit tests might not spot an environment specific or application behaviour related issue, whereas automated integration tests are more likely too e.g. might test with DB integration, mocked services."
      },
      {
        "date": "2022-01-04T01:58:00.000Z",
        "voteCount": 4,
        "content": "Answer is B &amp; E"
      },
      {
        "date": "2021-12-16T12:41:00.000Z",
        "voteCount": 1,
        "content": "ans BE"
      },
      {
        "date": "2021-11-17T13:10:00.000Z",
        "voteCount": 3,
        "content": "Answer is B E"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 10,
    "url": "https://www.examtopics.com/discussions/google/view/54235-exam-professional-cloud-devops-engineer-topic-1-question-10/",
    "body": "You have a pool of application servers running on Compute Engine. You need to provide a secure solution that requires the least amount of configuration and allows developers to easily access application logs for troubleshooting. How would you implement the solution on GCP?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\u05d2\u20ac\u00a2 Deploy the Stackdriver logging agent to the application servers. \u05d2\u20ac\u00a2 Give the developers the IAM Logs Viewer role to access Stackdriver and view logs.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\u05d2\u20ac\u00a2 Deploy the Stackdriver logging agent to the application servers. \u05d2\u20ac\u00a2 Give the developers the IAM Logs Private Logs Viewer role to access Stackdriver and view logs.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\u05d2\u20ac\u00a2 Deploy the Stackdriver monitoring agent to the application servers. \u05d2\u20ac\u00a2 Give the developers the IAM Monitoring Viewer role to access Stackdriver and view metrics.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\u05d2\u20ac\u00a2 Install the gsutil command line tool on your application servers. \u05d2\u20ac\u00a2 Write a script using gsutil to upload your application log to a Cloud Storage bucket, and then schedule it to run via cron every 5 minutes. \u05d2\u20ac\u00a2 Give the developers the IAM Object Viewer access to view the logs in the specified bucket."
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 13,
        "isMostVoted": true
      },
      {
        "answer": "B",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2021-06-02T08:56:00.000Z",
        "voteCount": 27,
        "content": "A \nroles/logging.viewer (Logs Viewer) gives you read-only access to all features of Logging, except Access Transparency logs and Data Access audit logs."
      },
      {
        "date": "2021-06-12T02:35:00.000Z",
        "voteCount": 9,
        "content": "correct - A . least privilege principle"
      },
      {
        "date": "2022-10-23T21:26:00.000Z",
        "voteCount": 2,
        "content": "A is right"
      },
      {
        "date": "2021-06-28T15:32:00.000Z",
        "voteCount": 11,
        "content": "correct A"
      },
      {
        "date": "2024-03-07T05:28:00.000Z",
        "voteCount": 1,
        "content": "A is the correct answer. As B is talking about private logs viewer, there is nothing like that role in GCP."
      },
      {
        "date": "2024-05-11T22:54:00.000Z",
        "voteCount": 1,
        "content": "For access to all logs in the _Required and _Default buckets, including data access logs, grant the Private Logs Viewer (roles/logging.privateLogViewer) role.\n\nhttps://cloud.google.com/logging/docs/access-control#logging.privateLogViewer"
      },
      {
        "date": "2023-12-27T16:43:00.000Z",
        "voteCount": 1,
        "content": "B, https://cloud.google.com/logging/docs/routing/overview"
      },
      {
        "date": "2023-12-01T23:01:00.000Z",
        "voteCount": 1,
        "content": "A - correct option"
      },
      {
        "date": "2023-11-09T06:33:00.000Z",
        "voteCount": 1,
        "content": "the correct answer is A, the privateLogViewer gives extra access to Data Access Logs that's is not required\n\nhttps://cloud.google.com/logging/docs/view/logs-explorer-interface"
      },
      {
        "date": "2023-01-10T21:48:00.000Z",
        "voteCount": 1,
        "content": "Answer A"
      },
      {
        "date": "2022-11-10T06:57:00.000Z",
        "voteCount": 2,
        "content": "A is correct, Private Logs Viewer gives you extra access to Data access logs and the question was about viewing application logs."
      },
      {
        "date": "2022-08-13T23:10:00.000Z",
        "voteCount": 2,
        "content": "The correct answer is \"A\""
      },
      {
        "date": "2022-07-06T12:55:00.000Z",
        "voteCount": 1,
        "content": "Default tier is premium.  There is NO mention of the load balancer being used and there is no default for this."
      },
      {
        "date": "2022-05-23T10:08:00.000Z",
        "voteCount": 1,
        "content": "Ans: Option A. :Logs Viewer role. Least config setup (as per question). Option B is incorrect due to additional audit log viewing access which is inappropriate to this question. ref: https://cloud.google.com/logging/docs/access-control"
      },
      {
        "date": "2022-05-23T10:06:00.000Z",
        "voteCount": 2,
        "content": "Option A (Least config settings).\nOption B - Private viewer log is for viewing data audit logs. \"The Logs Viewer role doesn't let principals read the Data Access audit logs that are in the _Default bucket. To read these Data Access audit logs, principals need the Private Logs Viewer role (roles/logging.privateLogViewer) for the appropriate log view.\"  ref: https://cloud.google.com/logging/docs/access-control"
      },
      {
        "date": "2022-02-16T00:21:00.000Z",
        "voteCount": 3,
        "content": "A. OK\nB. Logs Private Logs is for Data Logs\nC. Nope\nD. what?"
      },
      {
        "date": "2022-02-03T11:47:00.000Z",
        "voteCount": 2,
        "content": "A) You only need logging.viewer https://cloud.google.com/logging/docs/access-control"
      },
      {
        "date": "2022-01-09T19:34:00.000Z",
        "voteCount": 3,
        "content": "Looks like answer A is correct. A logging agent is required to enable the custom logs pushed to Stackdriver https://cloud.google.com/logging/docs/agent/logging . Developers need only Log Viewer permission, which is enough in this case and  Private Log viewer is a superset of log viewer permission with elevated permission to view the private data in logs. Which is not needed in this case."
      },
      {
        "date": "2022-01-04T02:00:00.000Z",
        "voteCount": 1,
        "content": "Correct Answer is A"
      },
      {
        "date": "2022-01-03T00:13:00.000Z",
        "voteCount": 1,
        "content": "B is correct as it talks about application logs \nhttps://cloud.google.com/logging/docs/access-control\n\nThe Logs Viewer role doesn't let you read the Data Access audit logs that are in the _Default bucket\n\nroles/logging.privateLogViewer (Private Logs Viewer) includes all the permissions contained by roles/logging.viewer, plus the ability to read Data Access audit logs in the _Default"
      },
      {
        "date": "2022-01-26T03:34:00.000Z",
        "voteCount": 1,
        "content": "and why do you need the Data Access Logs?"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 11,
    "url": "https://www.examtopics.com/discussions/google/view/54236-exam-professional-cloud-devops-engineer-topic-1-question-11/",
    "body": "You support the backend of a mobile phone game that runs on a Google Kubernetes Engine (GKE) cluster. The application is serving HTTP requests from users.<br>You need to implement a solution that will reduce the network cost. What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure the VPC as a Shared VPC Host project.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure your network services on the Standard Tier.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure your Kubernetes cluster as a Private Cluster.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure a Google Cloud HTTP Load Balancer as Ingress."
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 21,
        "isMostVoted": true
      },
      {
        "answer": "D",
        "count": 17,
        "isMostVoted": false
      },
      {
        "answer": "C",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2021-06-20T10:04:00.000Z",
        "voteCount": 27,
        "content": "Ans is D\n\nA: No, Doest make sense\nB: Who says that we are using a premium tier?\nC: This does not help with the network cost?\nD: Ok :)\nCosts associated with a load balancer are charged to the project containing the load balancer components. \nBecause of these benefits, container-native load balancing is the recommended solution for load balancing through Ingress. When NEGs are used with GKE Ingress, the Ingress controller facilitates the creation of all aspects of the L7 load balancer. This includes creating the virtual IP address, forwarding rules, health checks, firewall rules, and more.\n\nhttps://cloud.google.com/architecture/best-practices-for-running-cost-effective-kubernetes-applications-on-gke"
      },
      {
        "date": "2021-06-21T23:19:00.000Z",
        "voteCount": 12,
        "content": "Who says that we aren't use the load balancer?\nI think it's B anyway, because you have to choose standard tier when \"Cost is your main consideration, and you\u2019re willing to trade-off some network performance\"\nhttps://cloud.google.com/network-tiers"
      },
      {
        "date": "2022-10-23T21:23:00.000Z",
        "voteCount": 1,
        "content": "D is right"
      },
      {
        "date": "2023-05-31T07:23:00.000Z",
        "voteCount": 2,
        "content": "The doc didn't says that Container-native load balancing will decrees the spend in network costs. It's only refers to performance. Switching to Standard tier will be the most cost-specific answer"
      },
      {
        "date": "2022-06-10T00:11:00.000Z",
        "voteCount": 8,
        "content": "It is B because premium tier is by default everywhere. Standard tier is cheaper.\nWhy not D? This is single HTTP application. You don't know how many HTTP endpoints this app expose to Internet. If it is a single endpoint it does not matter if you create Service type Loadbalancer or Cluster IP-&gt; Ingress. You still have one CLB in GCP, so cost is the same"
      },
      {
        "date": "2021-06-28T15:33:00.000Z",
        "voteCount": 9,
        "content": "D 100%"
      },
      {
        "date": "2024-09-25T09:51:00.000Z",
        "voteCount": 1,
        "content": "Should be D. Mobile game apps may not be the right fit for standard tier"
      },
      {
        "date": "2024-08-13T14:13:00.000Z",
        "voteCount": 1,
        "content": "B reduces cost"
      },
      {
        "date": "2024-08-06T01:45:00.000Z",
        "voteCount": 2,
        "content": "answer should be D"
      },
      {
        "date": "2024-05-04T01:08:00.000Z",
        "voteCount": 1,
        "content": "Agree with D over B"
      },
      {
        "date": "2024-03-07T05:36:00.000Z",
        "voteCount": 2,
        "content": "I'll go with D. AS HTTP LB will help to reduce the costs. In question it is not mentioned that premium tier is used, so we can't assume that premium tier is used (eventhough it is default network tier) and go with B. So D is the correct answer."
      },
      {
        "date": "2023-12-13T08:02:00.000Z",
        "voteCount": 3,
        "content": "Answer B"
      },
      {
        "date": "2023-12-13T00:48:00.000Z",
        "voteCount": 3,
        "content": "Answer B"
      },
      {
        "date": "2023-12-11T07:15:00.000Z",
        "voteCount": 2,
        "content": "I go for B, as \"Premium\" is the default tier. \nD could be nice, but totally relies on the architecture of the application. \nIf the application needs to be global or re-route lots of requests, a LB makes no miracles."
      },
      {
        "date": "2023-12-01T23:03:00.000Z",
        "voteCount": 2,
        "content": "D -configuring the load balancer as ingress"
      },
      {
        "date": "2023-11-26T11:14:00.000Z",
        "voteCount": 1,
        "content": "I am confused between B and D. Default network is Premium which is costly, so changing to Standard also make sense. D is also correct when you'll have multiple endpoints and Google also suggested to LB. But, I'll go with (B) as it'll reduce some cost."
      },
      {
        "date": "2023-06-09T16:39:00.000Z",
        "voteCount": 1,
        "content": "To reduce network costs for the mobile phone game running on a Google Kubernetes Engine (GKE) cluster, the recommended approach is to use a Google Cloud HTTP Load Balancer as Ingress. This option is the best as it provides several advantages such as scalability, cost-effectiveness, and security."
      },
      {
        "date": "2023-05-31T07:23:00.000Z",
        "voteCount": 1,
        "content": "Premium tier is the default, so... switching to Standard tier is the only answer here that directly refers to costs"
      },
      {
        "date": "2023-03-08T11:28:00.000Z",
        "voteCount": 1,
        "content": "A Google Cloud HTTP Load Balancer can help reduce network costs by efficiently routing traffic to the backend services running on the GKE cluster. By configuring the load balancer as ingress, it will receive all incoming traffic and then route it to the appropriate backend service. This eliminates the need for each service to have its own external IP address, which can be costly in terms of network usage.\n\nOption A, Configure the VPC as a Shared VPC Host project, is not relevant to reducing network costs for a mobile phone game running on a GKE cluster.\n\nOption B, Configure your network services on the Standard Tier, is also not relevant to reducing network costs. The Standard Tier is a premium network service that offers better performance but is more expensive than the other tiers.\n\nOption C, Configure your Kubernetes cluster as a Private Cluster, is not directly relevant to reducing network costs. A private cluster restricts access to the Kubernetes API server to a private IP address range, which can improve security but does not necessarily reduce network costs."
      },
      {
        "date": "2023-01-17T08:02:00.000Z",
        "voteCount": 2,
        "content": "Ans is B - Stanard Tier"
      },
      {
        "date": "2023-01-10T22:02:00.000Z",
        "voteCount": 1,
        "content": "Option C would only be applicable if the Kubernetes cluster had not yet been created, and the private cluster feature was enabled at cluster creation time.\nAlso the application is serving HTTP requests from users and it could be bad if stop it.\n\nThe option D on the other hand, configuring a Google Cloud HTTP Load Balancer as Ingress, would not have a direct impact on reducing network costs. It would instead provide a more efficient way of managing and distributing incoming traffic to the Kubernetes cluster, which may indirectly help reduce costs, but not as much as the option C."
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 12,
    "url": "https://www.examtopics.com/discussions/google/view/54238-exam-professional-cloud-devops-engineer-topic-1-question-12/",
    "body": "You encountered a major service outage that affected all users of the service for multiple hours. After several hours of incident management, the service returned to normal, and user access was restored. You need to provide an incident summary to relevant stakeholders following the Site Reliability Engineering recommended practices. What should you do first?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCall individual stakeholders to explain what happened.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDevelop a post-mortem to be distributed to stakeholders.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSend the Incident State Document to all the stakeholders.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRequire the engineer responsible to write an apology email to all stakeholders."
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 21,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-06-02T09:04:00.000Z",
        "voteCount": 25,
        "content": "B postmortem analysis report to stakeholders"
      },
      {
        "date": "2021-06-12T03:18:00.000Z",
        "voteCount": 3,
        "content": "correct."
      },
      {
        "date": "2021-06-20T10:35:00.000Z",
        "voteCount": 6,
        "content": "A: No\nB: Correct\nC: No, Incident State document is used for consultation with incident participants.\nD: No, Blameless"
      },
      {
        "date": "2024-03-07T05:37:00.000Z",
        "voteCount": 1,
        "content": "Obviously B is the answer."
      },
      {
        "date": "2023-12-01T23:06:00.000Z",
        "voteCount": 1,
        "content": "option B -Develop a post-mortem to be distributed to stakeholders."
      },
      {
        "date": "2023-09-05T14:53:00.000Z",
        "voteCount": 2,
        "content": "Ans : A\nI don't know why A is correct\nIs important to write a postmortem to ensure that the incident is documented"
      },
      {
        "date": "2023-05-05T17:32:00.000Z",
        "voteCount": 1,
        "content": "I choose option D.\n\n\nOption B, which suggests configuring network services on the Standard Tier, can help reduce network costs to some extent, but it may not be the most effective solution. The Standard Tier offers lower-cost network services compared to the Premium Tier, which can result in lower network costs. However, the Standard Tier may not offer the same level of functionality and features as the Premium Tier, which can limit your ability to optimize your network for your specific needs.\n\nIn contrast, using a Google Cloud HTTP Load Balancer as Ingress, as suggested in option D, can provide more fine-grained control over network traffic, which can help you optimize your network usage and reduce network costs. Additionally, a load balancer can distribute incoming traffic across multiple backend instances, which can help reduce the amount of network bandwidth used by each instance."
      },
      {
        "date": "2023-10-24T23:13:00.000Z",
        "voteCount": 1,
        "content": "Your suggestion belongs to previous question Sir. \nIn this question it is option B"
      },
      {
        "date": "2023-01-10T22:04:00.000Z",
        "voteCount": 1,
        "content": "B. Develop a post-mortem to be distributed to stakeholders. This is a common practice in Site Reliability Engineering (SRE) where an incident summary is written to document the incident, including root causes, resolution, lessons learned, and a prioritized list of action items. This information can be used to improve processes, identify areas for improvement, and prevent similar incidents from occurring in the future."
      },
      {
        "date": "2022-11-12T16:13:00.000Z",
        "voteCount": 4,
        "content": "why is A showing as correct ans."
      },
      {
        "date": "2022-08-13T23:14:00.000Z",
        "voteCount": 2,
        "content": "The correct answer is \"C\""
      },
      {
        "date": "2022-08-13T23:17:00.000Z",
        "voteCount": 2,
        "content": "Plz ignore my previous ans ,the correct answer is \"B\""
      },
      {
        "date": "2022-07-29T10:41:00.000Z",
        "voteCount": 2,
        "content": "Don't understand why the A shows as the right answer. BBBBBBB of course. Does anyone know, why so many questions here choose the wrong item as correct answer? But also shows the percent of vote (most of time are right) as well. So confuse."
      },
      {
        "date": "2022-10-29T14:08:00.000Z",
        "voteCount": 1,
        "content": "B is right"
      },
      {
        "date": "2022-07-29T10:38:00.000Z",
        "voteCount": 1,
        "content": "Don't under why the web site showing A and correct, B  BBBBBB"
      },
      {
        "date": "2022-04-10T10:53:00.000Z",
        "voteCount": 3,
        "content": "B postmortem report to be share with stakeholders as per SRE."
      },
      {
        "date": "2021-12-14T09:34:00.000Z",
        "voteCount": 5,
        "content": "As per SRE culture, postmortem is the correct one."
      },
      {
        "date": "2021-12-05T05:05:00.000Z",
        "voteCount": 2,
        "content": "Ans : B"
      },
      {
        "date": "2021-12-01T03:44:00.000Z",
        "voteCount": 2,
        "content": "B for sure"
      },
      {
        "date": "2021-11-18T07:18:00.000Z",
        "voteCount": 3,
        "content": "B, blameless postmortem\nhttps://sre.google/sre-book/postmortem-culture/"
      },
      {
        "date": "2021-06-28T15:33:00.000Z",
        "voteCount": 5,
        "content": "B correct"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 13,
    "url": "https://www.examtopics.com/discussions/google/view/54240-exam-professional-cloud-devops-engineer-topic-1-question-13/",
    "body": "You are performing a semi-annual capacity planning exercise for your flagship service. You expect a service user growth rate of 10% month-over-month over the next six months. Your service is fully containerized and runs on Google Cloud Platform (GCP), using a Google Kubernetes Engine (GKE) Standard regional cluster on three zones with cluster autoscaler enabled. You currently consume about 30% of your total deployed CPU capacity, and you require resilience against the failure of a zone. You want to ensure that your users experience minimal negative impact as a result of this growth or as a result of zone failure, while avoiding unnecessary costs. How should you prepare to handle the predicted growth?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tVerify the maximum node pool size, enable a horizontal pod autoscaler, and then perform a load test to verify your expected resource needs.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tBecause you are deployed on GKE and are using a cluster autoscaler, your GKE cluster will scale automatically, regardless of growth rate.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tBecause you are at only 30% utilization, you have significant headroom and you won't need to add any additional capacity for this rate of growth.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tProactively add 60% more node capacity to account for six months of 10% growth rate, and then perform a load test to make sure you have enough capacity."
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 11,
        "isMostVoted": true
      },
      {
        "answer": "B",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2021-06-28T15:33:00.000Z",
        "voteCount": 25,
        "content": "answer A"
      },
      {
        "date": "2021-06-20T11:31:00.000Z",
        "voteCount": 24,
        "content": "A: Correct. The Horizontal Pod Autoscaler changes the shape of your Kubernetes workload by automatically increasing or decreasing the number of Pods in response to the workload's CPU or memory consumption\nB: Incorrect. It is not based on the CPU its based on the workload\nC: No, Hope is not an strategy\nD: No, have more resource than needed"
      },
      {
        "date": "2022-10-23T21:19:00.000Z",
        "voteCount": 1,
        "content": "Agreed"
      },
      {
        "date": "2024-07-12T23:32:00.000Z",
        "voteCount": 1,
        "content": "Examtopics suggest Ans B"
      },
      {
        "date": "2023-12-01T23:09:00.000Z",
        "voteCount": 1,
        "content": "option A"
      },
      {
        "date": "2023-11-15T23:17:00.000Z",
        "voteCount": 1,
        "content": "Answer A"
      },
      {
        "date": "2023-03-03T15:50:00.000Z",
        "voteCount": 2,
        "content": "i think A"
      },
      {
        "date": "2023-01-10T22:10:00.000Z",
        "voteCount": 2,
        "content": "Answer is A"
      },
      {
        "date": "2022-12-29T05:34:00.000Z",
        "voteCount": 1,
        "content": "A and B confusing"
      },
      {
        "date": "2022-11-10T07:21:00.000Z",
        "voteCount": 1,
        "content": "B is incorrect, because the cluster autoscaler doesn't work based on CPU/Memory usage on the node. The cluster will be scaled on the basis of resources requested by the workloads. So A is more relevant since HPA will automatically scales up/down based on the workload usage."
      },
      {
        "date": "2022-08-14T04:09:00.000Z",
        "voteCount": 1,
        "content": "The correct answer is \"A\""
      },
      {
        "date": "2022-05-09T09:43:00.000Z",
        "voteCount": 1,
        "content": "Submit the option provide in A"
      },
      {
        "date": "2022-04-20T22:22:00.000Z",
        "voteCount": 1,
        "content": "A is correct"
      },
      {
        "date": "2022-04-10T10:55:00.000Z",
        "voteCount": 1,
        "content": "A seems to be correct."
      },
      {
        "date": "2022-03-14T09:10:00.000Z",
        "voteCount": 1,
        "content": "Answer is A"
      },
      {
        "date": "2022-02-23T09:24:00.000Z",
        "voteCount": 1,
        "content": "Even with autoscaling maximul limit effect scaling"
      },
      {
        "date": "2021-12-06T06:21:00.000Z",
        "voteCount": 2,
        "content": "C for me: 30% of total deployed CPU consumption mean 10% of CUP on each zone; 10% of increment month-over-month mean at the beginning of the second mont you will have 11% of CPU, at the tird 12,1% and so on; you can easly accomodate a fault of a zone; you don't have additional cost"
      },
      {
        "date": "2022-11-10T07:28:00.000Z",
        "voteCount": 2,
        "content": "10% growth is only predicted value, but you should also be prepared for scenarios if the growth at real time is higher. In any case, using HPA and scaling based on it would be an optimal choice in my opinion."
      },
      {
        "date": "2021-12-05T05:07:00.000Z",
        "voteCount": 1,
        "content": "Ans: A"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 14,
    "url": "https://www.examtopics.com/discussions/google/view/54241-exam-professional-cloud-devops-engineer-topic-1-question-14/",
    "body": "Your application images are built and pushed to Google Container Registry (GCR). You want to build an automated pipeline that deploys the application when the image is updated while minimizing the development effort. What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse Cloud Build to trigger a Spinnaker pipeline.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse Cloud Pub/Sub to trigger a Spinnaker pipeline.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse a custom builder in Cloud Build to trigger Jenkins pipeline.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse Cloud Pub/Sub to trigger a custom deployment service running in Google Kubernetes Engine (GKE)."
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 11,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-09-07T05:17:00.000Z",
        "voteCount": 21,
        "content": "B is correct : https://cloud.google.com/architecture/continuous-delivery-toolchain-spinnaker-cloud#triggering_a_spinnaker_pipeline_when_a_docker_image_is_pushed_to_container_registry"
      },
      {
        "date": "2022-10-29T14:10:00.000Z",
        "voteCount": 1,
        "content": "Agree B is right"
      },
      {
        "date": "2021-06-28T15:34:00.000Z",
        "voteCount": 8,
        "content": "B is correct"
      },
      {
        "date": "2023-12-01T23:10:00.000Z",
        "voteCount": 1,
        "content": "option B"
      },
      {
        "date": "2023-01-10T22:14:00.000Z",
        "voteCount": 2,
        "content": "Agree with B option."
      },
      {
        "date": "2022-12-25T00:18:00.000Z",
        "voteCount": 2,
        "content": "Ans: B\n\nExam passed and taken on 19/12/2022, 50/50 from this dump without buying the full access and looking for 'devops' word here: https://www.examtopics.com/discussions/google/1/"
      },
      {
        "date": "2022-09-24T06:50:00.000Z",
        "voteCount": 2,
        "content": "B is correct"
      },
      {
        "date": "2022-07-24T01:50:00.000Z",
        "voteCount": 3,
        "content": "B is correct"
      },
      {
        "date": "2022-02-06T05:06:00.000Z",
        "voteCount": 4,
        "content": "most sensible choice"
      },
      {
        "date": "2021-12-05T05:09:00.000Z",
        "voteCount": 1,
        "content": "Ans : B"
      },
      {
        "date": "2021-10-23T23:03:00.000Z",
        "voteCount": 7,
        "content": "Its B\n\nGoogle Cloud Build vs Spinnaker: What are the differences?\n\nWhat is Google Cloud Build? Continuously build, test, and deploy. Cloud Build lets you build software quickly across all languages. Get complete control over defining custom workflows for building, testing, and deploying across multiple environments such as VMs, serverless, Kubernetes, or Firebase.\n\nWhat is Spinnaker? Multi-cloud continuous delivery platform for releasing software changes with high velocity and confidence. Created at Netflix, it has been battle-tested in production by hundreds of teams over millions of deployments. It combines a powerful and flexible pipeline management system with integrations to the major cloud providers.\n\nGoogle Cloud Build and Spinnaker belong to \"Continuous Deployment\" category of the tech stack."
      },
      {
        "date": "2021-08-11T06:43:00.000Z",
        "voteCount": 2,
        "content": "A is the answer"
      },
      {
        "date": "2022-01-29T12:32:00.000Z",
        "voteCount": 2,
        "content": "Cloud Build can't deploy inform Spinnaker to initiate a pipeline as and when the GCR is updated with new image. Whereas CloudPub/Sub can do. Answer should B."
      },
      {
        "date": "2021-07-17T00:57:00.000Z",
        "voteCount": 6,
        "content": "B, the pub/sub can trigger any deployment tool(spinnaker, cloud Run etc), but in platform native approach is to use spinnnaker.\n\nYou can also validate this, because they have only used platform native tools in the question like google container registry(instead of docker hub)"
      },
      {
        "date": "2024-04-13T08:04:00.000Z",
        "voteCount": 1,
        "content": "Yes, Spinnaker for Google Cloud can be configured to trigger pipelines from Cloud Build when an image is updated in Google Cloud Registry"
      },
      {
        "date": "2021-09-02T23:03:00.000Z",
        "voteCount": 1,
        "content": "no no no"
      },
      {
        "date": "2021-09-02T23:06:00.000Z",
        "voteCount": 2,
        "content": "eyyy,sorry meant B"
      },
      {
        "date": "2021-07-10T04:44:00.000Z",
        "voteCount": 2,
        "content": "OK for B but there is mistake by saying to bigger instead of to trigger"
      },
      {
        "date": "2021-06-18T05:19:00.000Z",
        "voteCount": 2,
        "content": "B is correct, because it says that image is built already, then there must be a trigger of some sort for spinnaker. Cloud Build does not trigger Spinnaker itself. Cloud Pub/Sub trigger can be configured in Spinnaker as documented:  https://spinnaker.io/guides/user/pipeline/triggers/pubsub/"
      },
      {
        "date": "2024-04-13T08:05:00.000Z",
        "voteCount": 1,
        "content": "Yes, Spinnaker for Google Cloud can be configured to trigger pipelines from Cloud Build when an image is updated in Google Cloud Registry"
      },
      {
        "date": "2021-06-08T07:53:00.000Z",
        "voteCount": 1,
        "content": "Sorry the correct is D. Cloud Pub/Sub can trigger custom deployment service like Spinnaker pipeline etc."
      },
      {
        "date": "2021-06-08T22:56:00.000Z",
        "voteCount": 3,
        "content": "instead of using custom deployment service. We should focus on native tools for deployment. so should be -B the right option."
      },
      {
        "date": "2022-04-20T04:33:00.000Z",
        "voteCount": 2,
        "content": "It says to reduce development effort."
      },
      {
        "date": "2021-06-08T07:46:00.000Z",
        "voteCount": 1,
        "content": "B is correct."
      },
      {
        "date": "2021-06-08T22:57:00.000Z",
        "voteCount": 1,
        "content": "agree B looks correct.\nhttps://cloud.google.com/architecture/continuous-delivery-toolchain-spinnaker-cloud"
      },
      {
        "date": "2021-06-02T09:10:00.000Z",
        "voteCount": 4,
        "content": "A cloud build spinakker pipeline"
      },
      {
        "date": "2021-06-06T20:00:00.000Z",
        "voteCount": 4,
        "content": "Cloud build directly can't trigger spinnaker pipeline. you have to use cloud pub/sub to trigger spinnaker pipeline. ( In the backend it will use cloud build notifiers"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 15,
    "url": "https://www.examtopics.com/discussions/google/view/54242-exam-professional-cloud-devops-engineer-topic-1-question-15/",
    "body": "Your product is currently deployed in three Google Cloud Platform (GCP) zones with your users divided between the zones. You can fail over from one zone to another, but it causes a 10-minute service disruption for the affected users. You typically experience a database failure once per quarter and can detect it within five minutes. You are cataloging the reliability risks of a new real-time chat feature for your product. You catalog the following information for each risk:<br>* Mean Time to Detect (MTTD) in minutes<br>* Mean Time to Repair (MTTR) in minutes<br>* Mean Time Between Failure (MTBF) in days<br>* User Impact Percentage<br>The chat feature requires a new database system that takes twice as long to successfully fail over between zones. You want to account for the risk of the new database failing in one zone. What would be the values for the risk of database failover with the new system?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tMTTD: 5 MTTR: 10 MTBF: 90 Impact: 33%",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tMTTD: 5 MTTR: 20 MTBF: 90 Impact: 33%\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tMTTD: 5 MTTR: 10 MTBF: 90 Impact: 50%",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tMTTD: 5 MTTR: 20 MTBF: 90 Impact: 50%"
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 20,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-06-28T15:34:00.000Z",
        "voteCount": 18,
        "content": "B 100%"
      },
      {
        "date": "2021-06-06T09:47:00.000Z",
        "voteCount": 11,
        "content": "B\nMTR will increase to 20"
      },
      {
        "date": "2024-01-29T06:41:00.000Z",
        "voteCount": 3,
        "content": "Pretty simple maths:\nMTTD stays 5 as no change in it\nMTTR doubles to 20 minutes because question says \"a new database system that takes twice as long to successfully fail over between zones.\"\nMTBF stays the same i.e., once per quarter (90 days)\nImpact: 33% because if one zone fails, only users in that zone is affeted and we have users spread over 3 zones."
      },
      {
        "date": "2023-12-01T23:13:00.000Z",
        "voteCount": 2,
        "content": "option B"
      },
      {
        "date": "2023-06-09T23:37:00.000Z",
        "voteCount": 2,
        "content": "Impact would be 33% since failure is one zone out of three zones (1/3)"
      },
      {
        "date": "2023-01-30T08:07:00.000Z",
        "voteCount": 1,
        "content": "B 100%"
      },
      {
        "date": "2023-01-10T22:19:00.000Z",
        "voteCount": 1,
        "content": "The correct answer would be B. MTTD: 5 MTTR: 20 MTBF: 90 Impact: 33%."
      },
      {
        "date": "2023-01-03T22:24:00.000Z",
        "voteCount": 1,
        "content": "B 100%"
      },
      {
        "date": "2022-12-30T23:52:00.000Z",
        "voteCount": 4,
        "content": "I was struggling between B and D as I couldn't find any information that indicate the impact of users. After checking out the discussion here most of people say it's B because there are 3 zones. If this is the case, there is a typo in the question: \"Your product is currently deployed in three Google Cloud Platform (GCP) zones with your users divided between \"the\"(three) zones\". So it should be B."
      },
      {
        "date": "2023-06-12T02:55:00.000Z",
        "voteCount": 1,
        "content": "You are right. There is a typo in the question. Nowhere does it say three zones."
      },
      {
        "date": "2022-12-25T00:18:00.000Z",
        "voteCount": 1,
        "content": "Ans: B\n\nExam passed and taken on 19/12/2022, 50/50 from this dump without buying the full access and looking for 'devops' word here: https://www.examtopics.com/discussions/google/1/"
      },
      {
        "date": "2022-11-26T13:48:00.000Z",
        "voteCount": 1,
        "content": "Can someone give a explanation on why MTTR will be 20 mins?"
      },
      {
        "date": "2022-12-03T08:17:00.000Z",
        "voteCount": 6,
        "content": "Because \"The chat feature requires a new database system that takes twice as long to successfully fail over between zones.\" which is 2x10min"
      },
      {
        "date": "2022-10-24T07:26:00.000Z",
        "voteCount": 1,
        "content": "B is the answer."
      },
      {
        "date": "2022-07-29T10:54:00.000Z",
        "voteCount": 4,
        "content": "Why there are so many questions using a wrong item as \"correct answer\" ? Where the value came from, so confuse :("
      },
      {
        "date": "2022-12-01T04:03:00.000Z",
        "voteCount": 1,
        "content": "You complained about the wrong item, but there was no response. This does not really help anyone who wants to learn, what is your response?"
      },
      {
        "date": "2022-07-24T01:51:00.000Z",
        "voteCount": 2,
        "content": "B is correct"
      },
      {
        "date": "2022-07-18T10:06:00.000Z",
        "voteCount": 1,
        "content": "not sure should be \"B\" or \"D\", since description like \"between Zones\" and \"fail from one to another\" indicate that there are only 2 zones"
      },
      {
        "date": "2022-05-09T09:44:00.000Z",
        "voteCount": 1,
        "content": "Submit B in exam"
      },
      {
        "date": "2022-02-12T03:47:00.000Z",
        "voteCount": 8,
        "content": "B is the answer:\nMTTD: 5 minutes\nMTTR: 20 minutes (twice the time)\nImpact: 33% (1 of 3 zones impacted)"
      },
      {
        "date": "2022-10-29T14:11:00.000Z",
        "voteCount": 1,
        "content": "B is right"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 16,
    "url": "https://www.examtopics.com/discussions/google/view/54244-exam-professional-cloud-devops-engineer-topic-1-question-16/",
    "body": "You are managing the production deployment to a set of Google Kubernetes Engine (GKE) clusters. You want to make sure only images which are successfully built by your trusted CI/CD pipeline are deployed to production. What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEnable Cloud Security Scanner on the clusters.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEnable Vulnerability Analysis on the Container Registry.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSet up the Kubernetes Engine clusters as private clusters.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSet up the Kubernetes Engine clusters with Binary Authorization.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 21,
        "isMostVoted": true
      },
      {
        "answer": "B",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2021-06-02T09:30:00.000Z",
        "voteCount": 28,
        "content": "D because binary authorization is deploy time security tool and it will allow only trusted and attested containers into GKE"
      },
      {
        "date": "2022-10-23T21:14:00.000Z",
        "voteCount": 2,
        "content": "Agreed with D."
      },
      {
        "date": "2021-06-28T15:35:00.000Z",
        "voteCount": 9,
        "content": "D 100%"
      },
      {
        "date": "2024-04-26T19:52:00.000Z",
        "voteCount": 2,
        "content": "Exam on 2024-04-26"
      },
      {
        "date": "2024-04-13T08:14:00.000Z",
        "voteCount": 1,
        "content": "Answer is D:\nThe question states: 'only images which are successfully built..' which means Vulnerability Scanns have been completed..."
      },
      {
        "date": "2023-12-01T23:14:00.000Z",
        "voteCount": 2,
        "content": "option D"
      },
      {
        "date": "2023-09-05T15:25:00.000Z",
        "voteCount": 2,
        "content": "To ensure that only images successfully built by your trusted CI/CD pipeline are deployed to production on Google Kubernetes Engine (GKE) clusters, you should set up the Kubernetes Engine clusters with Binary Authorization. Therefore, the correct answer is:\n\nD. Set up the Kubernetes Engine clusters with Binary Authorization."
      },
      {
        "date": "2023-09-05T15:17:00.000Z",
        "voteCount": 1,
        "content": "B\nThe question approach is about a trusted image generated, Is possible to create an image binary authorized with vulnerabilities?"
      },
      {
        "date": "2023-12-02T12:54:00.000Z",
        "voteCount": 1,
        "content": "yes it is possible, as long as it is attested by an attestor."
      },
      {
        "date": "2023-08-08T17:52:00.000Z",
        "voteCount": 1,
        "content": "In another mock test I took this was a select-2 answers, and those were B &amp; D"
      },
      {
        "date": "2023-06-27T05:37:00.000Z",
        "voteCount": 1,
        "content": "Who is the one that selects the correct answers?, because it matches 1/9999, looks more like a random."
      },
      {
        "date": "2023-01-10T22:21:00.000Z",
        "voteCount": 5,
        "content": "D. Set up the Kubernetes Engine clusters with Binary Authorization.\n\nBinary Authorization is a feature of Google Kubernetes Engine that allows you to ensure that only containers that are verified to be from a trusted source are deployed to your clusters. It works by using a policy that checks the signatures of container images before they are deployed. You can configure Binary Authorization to require that all images are signed by a trusted certificate authority (CA) or that they are signed by a trusted key that you manage. This ensures that only images that have been successfully built by your trusted CI/CD pipeline are deployed to your production clusters."
      },
      {
        "date": "2022-12-25T00:19:00.000Z",
        "voteCount": 1,
        "content": "Ans: D\n\nExam passed and taken on 19/12/2022, 50/50 from this dump without buying the full access and looking for 'devops' word here: https://www.examtopics.com/discussions/google/1/"
      },
      {
        "date": "2022-12-04T09:07:00.000Z",
        "voteCount": 2,
        "content": "D is the right answer.\nThe dump is valid, got all questions from here and cleared the exam"
      },
      {
        "date": "2022-11-22T23:27:00.000Z",
        "voteCount": 2,
        "content": "i will go with D, as there is no vulnerability analysis , it is vulnerability scan in container analysis service. and the binary authorization use metadata store to secure trusted repository."
      },
      {
        "date": "2022-10-24T07:28:00.000Z",
        "voteCount": 1,
        "content": "D is the answer.\n\nhttps://cloud.google.com/binary-authorization\nBinary Authorization is a deploy-time security control that ensures only trusted container images are deployed on Google Kubernetes Engine (GKE) or Cloud Run. With Binary Authorization, you can require images to be signed by trusted authorities during the development process and then enforce signature validation when deploying. By enforcing validation, you can gain tighter control over your container environment by ensuring only verified images are integrated into the build-and-release process."
      },
      {
        "date": "2022-07-24T01:53:00.000Z",
        "voteCount": 1,
        "content": "answer is D"
      },
      {
        "date": "2022-06-28T01:43:00.000Z",
        "voteCount": 1,
        "content": "Must be D."
      },
      {
        "date": "2022-06-21T05:11:00.000Z",
        "voteCount": 1,
        "content": "answer is D"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 17,
    "url": "https://www.examtopics.com/discussions/google/view/54245-exam-professional-cloud-devops-engineer-topic-1-question-17/",
    "body": "You support an e-commerce application that runs on a large Google Kubernetes Engine (GKE) cluster deployed on-premises and on Google Cloud Platform. The application consists of microservices that run in containers. You want to identify containers that are using the most CPU and memory. What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse Stackdriver Kubernetes Engine Monitoring.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse Prometheus to collect and aggregate logs per container, and then analyze the results in Grafana.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse the Stackdriver Monitoring API to create custom metrics, and then organize your containers using groups.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse Stackdriver Logging to export application logs to BigQuery, aggregate logs per container, and then analyze CPU and memory consumption."
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 22,
        "isMostVoted": true
      },
      {
        "answer": "B",
        "count": 8,
        "isMostVoted": false
      },
      {
        "answer": "C",
        "count": 2,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2021-09-02T01:27:00.000Z",
        "voteCount": 22,
        "content": "* https://cloud.google.com/anthos/clusters/docs/on-prem\nGKE on-prem is also called Anthos clusters on VMware\n\n* https://cloud.google.com/anthos/clusters/docs/on-prem/concepts/logging-and-monitoring\nYou have several logging and monitoring options for your Anthos clusters on VMware:\n+ Cloud Logging and Cloud Monitoring, enabled by in-cluster agents deployed with Anthos clusters on VMware.\n+ Prometheus and Grafana, disabled by default.\n+ Validated configurations with third-party solutions.\n\n=&gt; it means, if not a special situation, the correct should be using the first option: Logging and Monitoring. In this case, we want metrics, so Monitoring (aka. Cloud Monitoring, Stackdriver Monitoring) should be used. We are talking about GKE, so we will use Kubernetest Engine Monitoring (https://cloud.google.com/kubernetes-engine-monitoring).\n\nObviously, A is correct."
      },
      {
        "date": "2022-01-13T13:05:00.000Z",
        "voteCount": 6,
        "content": "we are talking about GKE and GKE on Premise \nso you need a multi cloud monitoring option not a GKE logging option like A"
      },
      {
        "date": "2023-12-24T01:15:00.000Z",
        "voteCount": 2,
        "content": "I agree with @helg, if you check the link: https://cloud.google.com/kubernetes-engine/docs/concepts/observability. It says: \"Note: The provided GKE dashboards only display information for GKE clusters running on Google Cloud. They don't display information for GKE clusters running anywhere else, for example using on-premises or bare-metal servers.\""
      },
      {
        "date": "2023-12-26T09:29:00.000Z",
        "voteCount": 2,
        "content": "I found another link indicating B is the answer, https://cloud.google.com/anthos/clusters/docs/on-prem/1.3/concepts/logging-and-monitoring\nI copy a slice:\nYou have several logging and monitoring options for your GKE on-prem clusters:\n- Cloud Logging and Cloud Monitoring, enabled by in-cluster agents deployed with GKE on-prem.\n- Prometheus and Grafana, disabled by default.\n- Validated configurations with third-party solutions."
      },
      {
        "date": "2021-06-28T15:35:00.000Z",
        "voteCount": 13,
        "content": "B correct"
      },
      {
        "date": "2021-08-08T08:22:00.000Z",
        "voteCount": 13,
        "content": "Point for discussion : \nGoogle highly recommends Google Logging and monitoring when running workloads only on GKE on-prem and GKE. For applications with component running on GKE on-prem and traditional on-premises infrastructure, other monitoring and logging solutions for an end-to-end view of application can be considered\n\nconsidering what is stated in the question  \"GKE cluster deployed on-premises and Google Cloud Platform\", should \"A\" be the answer"
      },
      {
        "date": "2022-01-13T13:04:00.000Z",
        "voteCount": 3,
        "content": "nor for A! \nSTackdriver Kub Engine only supports GKE not GKE on premise!"
      },
      {
        "date": "2024-03-07T06:04:00.000Z",
        "voteCount": 2,
        "content": "The answer will change pre and post GKE 1.24 release.\nIf the question is asked before the release of GKE 1.24 the answer should be A.\nPost GKE 1.24 release metrics deprecated, B is the answer."
      },
      {
        "date": "2024-01-29T06:53:00.000Z",
        "voteCount": 2,
        "content": "If the on-prem was a non-GKE kubernetes solution, the the answer would be B. \nBut it's GKE on-prem, A is the best option here"
      },
      {
        "date": "2023-12-01T23:17:00.000Z",
        "voteCount": 1,
        "content": "option A"
      },
      {
        "date": "2023-08-08T21:42:00.000Z",
        "voteCount": 2,
        "content": "GKE workload monitoring has been deprecated, so should be Prometheus\nhttps://cloud.google.com/stackdriver/docs/solutions/gke/managing-metrics"
      },
      {
        "date": "2023-07-19T00:09:00.000Z",
        "voteCount": 2,
        "content": "It should be B check this link\nIt is clearly mentioned if you are application running on GKE or anthos cluster on Vmware you use stack driver counter part but if it is on On-prem then better find other solution\nWith respect to options we have here it is prometheus\n\nhttps://cloud.google.com/anthos/clusters/docs/on-prem/latest/concepts/logging-and-monitoring#:~:text=For%20applications%20with%20components%20running%20on%20Anthos%20clusters%20on%20VMware%20and%20traditional%20on%2Dpremises%20infrastructure%2C%20you%20might%20consider%20other%20solutions%20for%20an%20end%2Dto%2Dend%20view%20of%20those%20applications"
      },
      {
        "date": "2023-04-12T03:20:00.000Z",
        "voteCount": 1,
        "content": "Prometheus is made for metrics not logs, in this way the correct answer is A, not be."
      },
      {
        "date": "2023-06-29T08:25:00.000Z",
        "voteCount": 1,
        "content": "Its telling to pick which uses most cpu and memory this has nothing to do with logs"
      },
      {
        "date": "2023-07-15T17:41:00.000Z",
        "voteCount": 2,
        "content": "are these questions still relevant?"
      },
      {
        "date": "2023-01-22T23:51:00.000Z",
        "voteCount": 2,
        "content": "B. Use Prometheus to collect and aggregate logs per container, and then analyze the results in Grafana.\n\nPrometheus is a popular open-source monitoring and alerting system that is well-suited for monitoring containers running in a Kubernetes cluster. It can scrape metrics from the Kubernetes API server and export them to a time series database, where they can be queried and visualized in Grafana. This approach allows you to monitor CPU and memory usage of individual containers, and set up alerts if usage exceeds certain thresholds."
      },
      {
        "date": "2023-01-22T23:51:00.000Z",
        "voteCount": 1,
        "content": "You support an e-commerce application that runs on a large Google Kubernetes Engine (GKE) cluster deployed on-premises and on Google Cloud Platform. The application consists of microservices that run in containers. You want to identify containers that are using the most CPU and memory. What should you do?\n\nA. Use Stackdriver Kubernetes Engine Monitoring.\nB. Use Prometheus to collect and aggregate logs per container, and then analyze the results in Grafana.\nC. Use the Stackdriver Monitoring API to create custom metrics, and then organize your containers using groups.\nD. Use Stackdriver Logging to export application logs to BigQuery, aggregate logs per container, and then analyze CPU and memory consumption."
      },
      {
        "date": "2023-01-10T22:34:00.000Z",
        "voteCount": 1,
        "content": "I think the answer is B.\nA cant be because is not for on premises."
      },
      {
        "date": "2022-12-25T00:19:00.000Z",
        "voteCount": 2,
        "content": "Ans: A\n\nExam passed and taken on 19/12/2022, 50/50 from this dump without buying the full access and looking for 'devops' word here: https://www.examtopics.com/discussions/google/1/"
      },
      {
        "date": "2023-01-30T08:13:00.000Z",
        "voteCount": 1,
        "content": "any way to take dump of the discussions?"
      },
      {
        "date": "2022-11-26T14:25:00.000Z",
        "voteCount": 1,
        "content": "Ans A - Anthos GKE On-Prem agent collects systems metric however it doesn't collect applications metric. Given that question asks for CPU and Memory GKE On-Prem agent should suffice of containers in on-prem. Source - https://cloud.google.com/anthos/clusters/docs/on-prem/1.3/concepts/logging-and-monitoring"
      },
      {
        "date": "2022-11-24T17:49:00.000Z",
        "voteCount": 1,
        "content": "for anthos clusters, need cloud monitoring &amp; cloud logging agent, not GKE monitoring."
      },
      {
        "date": "2022-11-24T17:43:00.000Z",
        "voteCount": 1,
        "content": "The Cloud Operations Suite for GKE only displays information for GKE clusters running on Google Cloud. It does not display information for GKE clusters running elsewhere, such as using on-premises or bare metal servers  \nhttps://cloud-google-com.translate.goog/stackdriver/docs/solutions/gke?hl=fr&amp;_x_tr_sl=fr&amp;_x_tr_tl=en&amp;_x_tr_hl=en&amp;_x_tr_pto=sc"
      },
      {
        "date": "2022-12-15T00:11:00.000Z",
        "voteCount": 1,
        "content": "\" Cloud Operations Suite for GKE \" is a tailored cloud monitoring &amp; logging service for GKE. not cloud monitoring &amp; logging service. A is correct."
      },
      {
        "date": "2022-11-14T09:10:00.000Z",
        "voteCount": 1,
        "content": "The eCommerce app is a workload. \nSince v. 1.24 GKE workload metrics were deprecated and replaced with Prometheus https://cloud.google.com/stackdriver/docs/solutions/gke/workload-metrics#gcloud\nhttps://cloud.google.com/stackdriver/docs/solutions/gke/gmp-migration"
      },
      {
        "date": "2022-11-05T04:21:00.000Z",
        "voteCount": 4,
        "content": "I work in the hybrid environment [anthos] and can confirm the required metric availability"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 18,
    "url": "https://www.examtopics.com/discussions/google/view/54246-exam-professional-cloud-devops-engineer-topic-1-question-18/",
    "body": "Your company experiences bugs, outages, and slowness in its production systems. Developers use the production environment for new feature development and bug fixes. Configuration and experiments are done in the production environment, causing outages for users. Testers use the production environment for load testing, which often slows the production systems. You need to redesign the environment to reduce the number of bugs and outages in production and to enable testers to toad test new features. What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate an automated testing script in production to detect failures as soon as they occur.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a development environment with smaller server capacity and give access only to developers and testers.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSecure the production environment to ensure that developers can't change it and set up one controlled update per year.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a development environment for writing code and a test environment for configurations, experiments, and load testing.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 25,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-06-02T09:34:00.000Z",
        "voteCount": 22,
        "content": "D i think creating seperate env for dev and testers"
      },
      {
        "date": "2021-06-28T15:35:00.000Z",
        "voteCount": 10,
        "content": "answer is D"
      },
      {
        "date": "2023-12-01T23:19:00.000Z",
        "voteCount": 2,
        "content": "option B"
      },
      {
        "date": "2023-11-09T07:32:00.000Z",
        "voteCount": 1,
        "content": "It is necessary to check the environment, one of development and one of test"
      },
      {
        "date": "2023-10-26T22:41:00.000Z",
        "voteCount": 1,
        "content": "Right answer"
      },
      {
        "date": "2023-08-08T21:44:00.000Z",
        "voteCount": 1,
        "content": "A makes no sense"
      },
      {
        "date": "2023-04-03T12:50:00.000Z",
        "voteCount": 1,
        "content": "i thinks is D because the questions is about how redesign the system..."
      },
      {
        "date": "2023-01-10T22:37:00.000Z",
        "voteCount": 2,
        "content": "D. Create a development environment for writing code and a test environment for configurations, experiments, and load testing.\n\nCreating separate environments for development, testing and production is a best practice for software development. This will enable the company to have control over the changes that are made in each environment and reduce the risk of bugs, outages and slowness in production.\n\nA development environment would be used by developers to write code, test new features and do initial debugging. This environment should be isolated from production so that bugs or issues that occur during development don't affect the production systems or users.\n\nA test environment should be created to perform configurations, experiments, and load testing. This environment should be identical to production so that it can be used to test how the systems will behave in a real-world scenario. Testers can use this environment to load test new features without affecting production systems or users."
      },
      {
        "date": "2022-12-27T07:41:00.000Z",
        "voteCount": 3,
        "content": "why not B?"
      },
      {
        "date": "2023-01-10T08:57:00.000Z",
        "voteCount": 1,
        "content": "Even if we let alone the env separation in D, B doesn't address all the needs in the question. For example, they want to perform load test, if B has a smaller capacity the load test isn't accurate."
      },
      {
        "date": "2022-12-30T06:11:00.000Z",
        "voteCount": 1,
        "content": "Please do know why not B"
      },
      {
        "date": "2022-12-25T00:19:00.000Z",
        "voteCount": 2,
        "content": "Ans: D\n\nExam passed and taken on 19/12/2022, 50/50 from this dump without buying the full access and looking for 'devops' word here: https://www.examtopics.com/discussions/google/1/"
      },
      {
        "date": "2022-12-10T11:12:00.000Z",
        "voteCount": 1,
        "content": "answer is D"
      },
      {
        "date": "2022-10-24T07:36:00.000Z",
        "voteCount": 1,
        "content": "D is the answer."
      },
      {
        "date": "2022-10-23T21:10:00.000Z",
        "voteCount": 1,
        "content": "D is right"
      },
      {
        "date": "2022-09-04T00:03:00.000Z",
        "voteCount": 1,
        "content": "D is correct"
      },
      {
        "date": "2022-07-24T02:02:00.000Z",
        "voteCount": 1,
        "content": "answer is D"
      },
      {
        "date": "2022-05-09T09:45:00.000Z",
        "voteCount": 1,
        "content": "Submitted D in the exam"
      },
      {
        "date": "2022-02-12T03:56:00.000Z",
        "voteCount": 3,
        "content": "D is the answer, keep production separated, dev environment to write the code, test environment to test functionality and load before deployments to prod"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 19,
    "url": "https://www.examtopics.com/discussions/google/view/54247-exam-professional-cloud-devops-engineer-topic-1-question-19/",
    "body": "You support an application running on App Engine. The application is used globally and accessed from various device types. You want to know the number of connections. You are using Stackdriver Monitoring for App Engine. What metric should you use?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tflex/connections/current\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ttcp_ssl_proxy/new_connections",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\ttcp_ssl_proxy/open_connections",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tflex/instance/connections/current"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 11,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-06-20T19:12:00.000Z",
        "voteCount": 23,
        "content": "Ans A\nA: Metric for App engine &amp; for version\nB: NO, Metrics for Cloud Load Balancing.\nC: NO, Metrics for Cloud Load Balancing.\nD Metric for App engine &amp; for instance\n\nAn App Engine app is made up of a single application resource that consists of one or more services. Each service can be configured to use different runtimes and to operate with different performance settings. Within each service, you deploy versions of that service. Each version then runs within one or more instances, depending on how much traffic you configured it to handle.\n\nif the version runs within one or more instances we need for the version."
      },
      {
        "date": "2021-10-31T09:14:00.000Z",
        "voteCount": 1,
        "content": "agree, the question is about number of connections of the app (could be multiple instances), not an instance."
      },
      {
        "date": "2021-06-28T15:36:00.000Z",
        "voteCount": 6,
        "content": "A correct"
      },
      {
        "date": "2023-12-01T23:24:00.000Z",
        "voteCount": 1,
        "content": "option A"
      },
      {
        "date": "2023-11-09T07:40:00.000Z",
        "voteCount": 1,
        "content": "A is correct answer \nhttps://cloud.google.com/monitoring/api/metrics_gcp#gcp-appengine\nflex/connections/current show the current active connections for all instance in appengine"
      },
      {
        "date": "2023-01-10T22:44:00.000Z",
        "voteCount": 1,
        "content": "Answer is A"
      },
      {
        "date": "2022-12-25T00:20:00.000Z",
        "voteCount": 1,
        "content": "Ans: A\n\nExam passed and taken on 19/12/2022, 50/50 from this dump without buying the full access and looking for 'devops' word here: https://www.examtopics.com/discussions/google/1/"
      },
      {
        "date": "2022-10-26T04:51:00.000Z",
        "voteCount": 1,
        "content": "A \nflex/connections/current GA\nConnections\nGAUGE, DOUBLE, 1\ngae_app\tNumber of current active connections per App Engine flexible environment version. Sampled every 60 seconds. After sampling, data is not visible for up to 240 seconds."
      },
      {
        "date": "2022-10-23T23:33:00.000Z",
        "voteCount": 2,
        "content": "A is the answer.\n\nhttps://cloud.google.com/monitoring/api/metrics_gcp#gcp-appengine\nflex/connections/current\n- Number of current active connections per App Engine flexible environment version"
      },
      {
        "date": "2023-04-12T03:26:00.000Z",
        "voteCount": 1,
        "content": "Thank you for providing the docs, you're right, the answer is A 100%!"
      },
      {
        "date": "2022-08-14T04:23:00.000Z",
        "voteCount": 2,
        "content": "The correct answer is \"A\""
      },
      {
        "date": "2022-05-09T09:45:00.000Z",
        "voteCount": 1,
        "content": "Submitted A"
      },
      {
        "date": "2022-02-04T05:41:00.000Z",
        "voteCount": 3,
        "content": "A) Is the correct answer https://cloud.google.com/monitoring/api/metrics_gcp#gcp-appengine"
      },
      {
        "date": "2021-12-05T05:15:00.000Z",
        "voteCount": 1,
        "content": "Ans : A"
      },
      {
        "date": "2021-09-02T23:27:00.000Z",
        "voteCount": 5,
        "content": "A\nhttps://cloud.google.com/monitoring/api/metrics_gcp#gcp-appengine"
      },
      {
        "date": "2021-06-17T04:59:00.000Z",
        "voteCount": 5,
        "content": "A it is"
      },
      {
        "date": "2021-06-02T09:37:00.000Z",
        "voteCount": 1,
        "content": "flex/instance/connections/current GA\nConnections\nGAUGE, DOUBLE, 1\ngae_instance\tNumber of current active connections per App Engine flexible environment instance. Sampled every 60 seconds. After sampling, data is not visible for up to 240 seconds."
      },
      {
        "date": "2021-06-06T09:50:00.000Z",
        "voteCount": 2,
        "content": "what about option A\nwe need to count application connection count and the count at instance level. no. of instance will keep on changing in app engine in the backend."
      },
      {
        "date": "2021-06-12T05:09:00.000Z",
        "voteCount": 2,
        "content": "Agree for the answer -A"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 20,
    "url": "https://www.examtopics.com/discussions/google/view/54248-exam-professional-cloud-devops-engineer-topic-1-question-20/",
    "body": "You support an application deployed on Compute Engine. The application connects to a Cloud SQL instance to store and retrieve data. After an update to the application, users report errors showing database timeout messages. The number of concurrent active users remained stable. You need to find the most probable cause of the database timeout. What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCheck the serial port logs of the Compute Engine instance.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse Stackdriver Profiler to visualize the resources utilization throughout the application.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDetermine whether there is an increased number of connections to the Cloud SQL instance.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse Cloud Security Scanner to see whether your Cloud SQL is under a Distributed Denial of Service (DDoS) attack."
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 19,
        "isMostVoted": true
      },
      {
        "answer": "C",
        "count": 2,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2021-06-20T19:39:00.000Z",
        "voteCount": 24,
        "content": "Ans: B\nI don't find anything about ddos attacks and Cloud security Scanner &amp; databases; its most used with App engine and compute so.\n\nI go with Stackdriver profiler"
      },
      {
        "date": "2021-11-09T19:20:00.000Z",
        "voteCount": 3,
        "content": "Agree. Ans B"
      },
      {
        "date": "2021-06-17T05:20:00.000Z",
        "voteCount": 10,
        "content": "B - getting to know the app perf"
      },
      {
        "date": "2024-09-25T11:43:00.000Z",
        "voteCount": 1,
        "content": "Can't be B as I wonder what use resource utilization metrics are going to be.\n\nGoing with C"
      },
      {
        "date": "2024-06-09T00:54:00.000Z",
        "voteCount": 1,
        "content": "Cannot be B, Profiler, it's used to check how an app consumes RAM and CPU, not but database connections"
      },
      {
        "date": "2023-12-02T00:05:00.000Z",
        "voteCount": 2,
        "content": "option C"
      },
      {
        "date": "2023-03-04T22:35:00.000Z",
        "voteCount": 1,
        "content": "Ans: B\nI don't find anything about ddos attacks and Cloud security Scanner &amp; databases; its most used with App engine and compute so."
      },
      {
        "date": "2023-03-01T05:08:00.000Z",
        "voteCount": 1,
        "content": "C would be correct"
      },
      {
        "date": "2023-02-28T19:02:00.000Z",
        "voteCount": 4,
        "content": "I would go for B:\nAs it says, \"The **number** of concurrent active users remained stable.\"\nSince users report database timeout errors,  the newly deployed version can only service a particular load and that load is **lower than** expected number.\nIt is likely that the new version has changes that lead to high CPU utilization or any other bottleneck, so we should use the profiler to locate the issue."
      },
      {
        "date": "2023-01-10T22:48:00.000Z",
        "voteCount": 3,
        "content": "B. Use Stackdriver Profiler to visualize the resources utilization throughout the application\n\nThe most probable cause of the database timeout when the number of concurrent active users remained stable is a performance issue. Stackdriver Profiler can be used to identify and diagnose performance issues in the application. Profiler can help you to visualize the resources utilization throughout the application, including CPU and memory usage, and identify any parts of the application that might be causing high load. This can help you understand how the application is utilizing the resources and identify any bottlenecks in the code that might be causing the timeouts.\n\nOther possible solutions, while they can be useful in certain situations, are not as relevant in this scenario.\nOption A is not relevant as it is not related to the issue.\nOption C while it can be helpful in certain scenarios, in this case it's less likely to be the cause of the problem.\nOption D is a security tool that can detect vulnerabilities in the application, but it's not related to the database timeouts."
      },
      {
        "date": "2023-01-10T09:15:00.000Z",
        "voteCount": 8,
        "content": "I would go for C. \nC. Determine whether there is an increased number of connections to the Cloud SQL instance.\n1. Because users report the error message saying \"database timeout\". If the errors is from the application then it wouldn't be \"database timeout\", so rather than running Profiler in your application, go check whether there is an increased number of connections is more intuitive. 2. Other than that, the question mentions \"After an update to the application\" which imply that there could be a bug regarding to SQL so that's why if \"concurrent active users remained stable\", the database could still timeout because of bugs. Please be aware that \"concurrent active users remained stable\" doesn't mean qps (query-per-second) is still the same."
      },
      {
        "date": "2022-12-25T00:20:00.000Z",
        "voteCount": 2,
        "content": "Ans: B\n\nExam passed and taken on 19/12/2022, 50/50 from this dump without buying the full access and looking for 'devops' word here: https://www.examtopics.com/discussions/google/1/"
      },
      {
        "date": "2022-07-24T02:04:00.000Z",
        "voteCount": 2,
        "content": "Ans: B"
      },
      {
        "date": "2022-05-09T09:46:00.000Z",
        "voteCount": 2,
        "content": "Submit B"
      },
      {
        "date": "2022-04-15T20:02:00.000Z",
        "voteCount": 5,
        "content": "Answer B: Use Stackdriver Profiler to visualize the resources utilization throughout the application.\n\nHigh CPU usage can most definitely cause dropped or ignored connections. The database engine and underlying OS are fighting for resources and aren't able to respond to the connection in time. \nFinding out why the query is eating so much CPU usage and optimizing it.\nhttps://stackoverflow.com/questions/69919454/high-cpu-usage-on-cloud-sql-causing-timeouts\n\n# Cloud Profiler is a statistical, low-overhead profiler that continuously gathers CPU usage and memory-allocation information (supported profile types: CPU time, Heap, Allocated heap, Contention, Threads, Wall time) from your production applications. It attributes that information to the source code that generated it, helping you identify the parts of your application that are consuming the most resources, and otherwise illuminating your applications performance characteristics.\nhttps://cloud.google.com/profiler/docs/about-profiler"
      },
      {
        "date": "2022-02-15T22:17:00.000Z",
        "voteCount": 3,
        "content": "C as app update could have introduced a bug where although app user concurrency remain stable, could have introduced more db connections"
      },
      {
        "date": "2022-02-15T00:18:00.000Z",
        "voteCount": 2,
        "content": "Ans C is more feasible. If the user not changed but the devs forgot to close the unneeded connection can increase the connection count and produce this error."
      },
      {
        "date": "2022-02-12T04:00:00.000Z",
        "voteCount": 2,
        "content": "B - Profiler allows you to see each specific process running in your application to find out bottle necks and resource intensive components"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 21,
    "url": "https://www.examtopics.com/discussions/google/view/54250-exam-professional-cloud-devops-engineer-topic-1-question-21/",
    "body": "Your application images are built using Cloud Build and pushed to Google Container Registry (GCR). You want to be able to specify a particular version of your application for deployment based on the release version tagged in source control. What should you do when you push the image?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tReference the image digest in the source control tag.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSupply the source control tag as a parameter within the image name.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse Cloud Build to include the release version tag in the application image.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse GCR digest versioning to match the image to the tag in source control."
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 8,
        "isMostVoted": true
      },
      {
        "answer": "D",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2021-06-26T20:18:00.000Z",
        "voteCount": 22,
        "content": "Ans C\nCloud Build provides the following default substitutions:\n$TAG_NAME: build.Source.RepoSource.Revision.TagName"
      },
      {
        "date": "2021-09-13T06:06:00.000Z",
        "voteCount": 5,
        "content": "OK but doesn't it make more sense to use this $TAG to include the release version tag in the application image?\n\nI would go with B."
      },
      {
        "date": "2021-09-13T06:08:00.000Z",
        "voteCount": 2,
        "content": "Sorry, I meant \"to use this $TAG as a parameter within the image name?\""
      },
      {
        "date": "2021-10-31T09:25:00.000Z",
        "voteCount": 2,
        "content": "Agree. Cloud Build provides a variable for the tag, when we push the image, we must supply the variable to tag the image."
      },
      {
        "date": "2021-06-02T09:47:00.000Z",
        "voteCount": 5,
        "content": "C inside cloudbuil.yml file can include release version"
      },
      {
        "date": "2024-03-04T11:08:00.000Z",
        "voteCount": 1,
        "content": "imho D cause Using GCR digest versioning involves using the SHA256 digest of the image as the unique identifier for the image. This ensures that the image can be reliably referenced and identified regardless of any tags that may be applied to it."
      },
      {
        "date": "2023-12-02T00:10:00.000Z",
        "voteCount": 1,
        "content": "option C"
      },
      {
        "date": "2023-01-10T22:58:00.000Z",
        "voteCount": 5,
        "content": "Both option B and C are valid ways to ensure that a specific version of an application is deployed based on the release version tagged in source control, but option C is likely to be the more robust and flexible solution for managing your application deployments.\n\nWith option B, Supply the source control tag as a parameter within the image name, you have to manually include the source control tag when you push the image to GCR. This can make it more prone to human error and also could require more manual work to keep track of the different versions and their correspondance with the codebase.\n\nOn the other hand, option C, Use Cloud Build to include the release version tag in the application image, allows you to automate the process of adding the release version tag to the application image during the build process. This can make it easier to track the different versions of your application and their association with the codebase. Additionally, Cloud Build allows you to automate different steps of the build and deployment process, such as building, testing and deploying the images, making it easier to manage and keep track of your deployments."
      },
      {
        "date": "2022-12-25T00:21:00.000Z",
        "voteCount": 1,
        "content": "Ans: C\n\nExam passed and taken on 19/12/2022, 50/50 from this dump without buying the full access and looking for 'devops' word here: https://www.examtopics.com/discussions/google/1/"
      },
      {
        "date": "2022-08-14T04:33:00.000Z",
        "voteCount": 2,
        "content": "The correct answer is C"
      },
      {
        "date": "2022-06-25T05:19:00.000Z",
        "voteCount": 2,
        "content": "C should be right.\n\nhttps://cloud.google.com/build/docs/build-push-docker-image#build_an_image_using_a_build_config_file"
      },
      {
        "date": "2022-06-15T02:14:00.000Z",
        "voteCount": 2,
        "content": "C is a right option"
      },
      {
        "date": "2021-12-16T11:47:00.000Z",
        "voteCount": 2,
        "content": "I go for B\nhttps://cloud.google.com/container-registry/docs/pushing-and-pulling"
      },
      {
        "date": "2021-12-05T08:19:00.000Z",
        "voteCount": 3,
        "content": "Ans: C"
      },
      {
        "date": "2021-06-24T17:24:00.000Z",
        "voteCount": 3,
        "content": "C. tag your images with the sourced code release version."
      },
      {
        "date": "2021-06-22T17:31:00.000Z",
        "voteCount": 1,
        "content": "I think is B, is the normal process in this cases"
      },
      {
        "date": "2021-06-22T17:39:00.000Z",
        "voteCount": 1,
        "content": "https://cloud.google.com/container-registry/docs/pushing-and-pulling"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 22,
    "url": "https://www.examtopics.com/discussions/google/view/54251-exam-professional-cloud-devops-engineer-topic-1-question-22/",
    "body": "You are on-call for an infrastructure service that has a large number of dependent systems. You receive an alert indicating that the service is failing to serve most of its requests and all of its dependent systems with hundreds of thousands of users are affected. As part of your Site Reliability Engineering (SRE) incident management protocol, you declare yourself Incident Commander (IC) and pull in two experienced people from your team as Operations Lead (OL) and<br>Communications Lead (CL). What should you do next?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tLook for ways to mitigate user impact and deploy the mitigations to production.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tContact the affected service owners and update them on the status of the incident.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEstablish a communication channel where incident responders and leads can communicate with each other.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tStart a postmortem, add incident information, circulate the draft internally, and ask internal stakeholders for input."
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 18,
        "isMostVoted": true
      },
      {
        "answer": "A",
        "count": 4,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2021-06-28T21:48:00.000Z",
        "voteCount": 15,
        "content": "C is the answer"
      },
      {
        "date": "2021-06-22T15:27:00.000Z",
        "voteCount": 14,
        "content": "Ans: C\nPrepare Beforehand\nIn addition to incident response training, it helps to prepare for an incident beforehand. Use the following tips and strategies to be better prepared.\n\nDecide on a communication channel\nDecide and agree on a communication channel (Slack, a phone bridge, IRC, HipChat, etc.) beforehand.\n\nKeep your audience informed\nUnless you acknowledge that an incident is happening and actively being addressed, people will automatically assume nothing is being done to resolve the issue. Similarly, if you forget to call off the response once the issue has been mitigated or resolved, people will assume the incident is ongoing. You can preempt this dynamic by keeping your audience informed throughout the incident with regular status updates. Having a prepared list of contacts (see the next tip) saves valuable time and ensures you don\u2019t miss anyone.\n\nhttps://sre.google/workbook/incident-response/"
      },
      {
        "date": "2022-10-23T20:54:00.000Z",
        "voteCount": 2,
        "content": "Agreed,  C is right."
      },
      {
        "date": "2023-12-02T00:19:00.000Z",
        "voteCount": 1,
        "content": "Option C"
      },
      {
        "date": "2023-01-10T23:01:00.000Z",
        "voteCount": 1,
        "content": "Answer is C.\nWhen an incident occurs and you are on-call, it is important to act quickly and efficiently to minimize user impact. One of the first steps in incident management is to establish clear and efficient communication among the incident responders and leads.\nThe incident commander (IC) should establish a communication channel, such as a conference call or chat room, where incident responders and leads can communicate with each other and update each other on the status of the incident and any mitigation efforts. This is essential for ensuring that all incident responders are aware of the current status and can coordinate their efforts effectively.\n\nOption A, Look for ways to mitigate user impact and deploy the mitigations to production, is also an important step but should be done in parallel with establishing a communication channel.\nOption B, Contact the affected service owners and update them on the status of the incident is also important but should be done during the incident management process.\nOption D, Start a postmortem, is important and should be done later once the incident is resolved."
      },
      {
        "date": "2023-12-19T00:32:00.000Z",
        "voteCount": 1,
        "content": "Answer is C.\nAbout Option B, it should be done by the Communications Lead. The statement doesn't say the Communications Lead was the same person than the Incident Commander, what it could be in another situation."
      },
      {
        "date": "2022-12-25T00:21:00.000Z",
        "voteCount": 1,
        "content": "Ans: C\n\nExam passed and taken on 19/12/2022, 50/50 from this dump without buying the full access and looking for 'devops' word here: https://www.examtopics.com/discussions/google/1/"
      },
      {
        "date": "2022-11-19T16:48:00.000Z",
        "voteCount": 1,
        "content": "\"The Ops lead works with the incident commander to respond to the incident by applying operational tools to the task at hand. The operations team should be the 'only' group modifying the system during an incident.\" \nHas to be C"
      },
      {
        "date": "2022-10-23T21:00:00.000Z",
        "voteCount": 1,
        "content": "based on my experience with daily incidents it should be C followed by A"
      },
      {
        "date": "2022-10-06T01:14:00.000Z",
        "voteCount": 1,
        "content": "C is correct answer"
      },
      {
        "date": "2022-09-03T23:43:00.000Z",
        "voteCount": 2,
        "content": "Correct answer is A"
      },
      {
        "date": "2022-09-03T23:41:00.000Z",
        "voteCount": 2,
        "content": "the correct Answer is A,  i took a google training of this professional  DevOps  Engineer, the teacher said C  communication channel is important, but the most of import thing is A. Look for ways to mitigate user impact and deploy the mitigations to production.  solve the issue and reduce the impact of the users."
      },
      {
        "date": "2022-08-14T04:35:00.000Z",
        "voteCount": 1,
        "content": "The correct answer is C"
      },
      {
        "date": "2022-04-21T00:47:00.000Z",
        "voteCount": 3,
        "content": "You are IC. \nhttps://sre.google/sre-book/managing-incidents/"
      },
      {
        "date": "2022-03-09T07:24:00.000Z",
        "voteCount": 1,
        "content": "In this case there are 3 different peoples. The mitigation is for the OL. The IC must coordinate and setup a living Incident State Document which is the the communication channel for the operational group"
      },
      {
        "date": "2022-02-21T14:06:00.000Z",
        "voteCount": 4,
        "content": "agree with rinkeshgala1: \"mitigating the issue is not the job of Incident commander but of Operation Lead.\nIncident commander should setup common communication channel , so option C\""
      },
      {
        "date": "2022-02-15T10:58:00.000Z",
        "voteCount": 3,
        "content": "Ans A is a task for Operation Lead"
      },
      {
        "date": "2023-12-19T00:36:00.000Z",
        "voteCount": 1,
        "content": "I Agree. This statement is asking the roles of an incident team, not which it is role more important, which it would be recovering the service (A) asap"
      },
      {
        "date": "2022-02-12T04:05:00.000Z",
        "voteCount": 2,
        "content": "A - Stop the impact to Production and end users ASAP."
      },
      {
        "date": "2022-01-10T00:56:00.000Z",
        "voteCount": 2,
        "content": "I will pick C https://sre.google/sre-book/managing-incidents/\nIn Unmanaged Incidents exmple:\n on-call engineer Mary try to fix problem, but the technical task at hand was overwhelming.\nPoor Communication:other engineers who could have lent a hand in debugging or fixing the issue weren\u2019t used effectively"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 23,
    "url": "https://www.examtopics.com/discussions/google/view/54252-exam-professional-cloud-devops-engineer-topic-1-question-23/",
    "body": "You are developing a strategy for monitoring your Google Cloud Platform (GCP) projects in production using Stackdriver Workspaces. One of the requirements is to be able to quickly identify and react to production environment issues without false alerts from development and staging projects. You want to ensure that you adhere to the principle of least privilege when providing relevant team members with access to Stackdriver Workspaces. What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tGrant relevant team members read access to all GCP production projects. Create Stackdriver workspaces inside each project.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tGrant relevant team members the Project Viewer IAM role on all GCP production projects. Create Stackdriver workspaces inside each project.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tChoose an existing GCP production project to host the monitoring workspace. Attach the production projects to this workspace. Grant relevant team members read access to the Stackdriver Workspace.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a new GCP monitoring project and create a Stackdriver Workspace inside it. Attach the production projects to this workspace. Grant relevant team members read access to the Stackdriver Workspace.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 23,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-06-28T21:48:00.000Z",
        "voteCount": 25,
        "content": "D 100%"
      },
      {
        "date": "2022-01-28T05:37:00.000Z",
        "voteCount": 13,
        "content": "Answer - D \nWhen you want to manage metrics for multiple projects, we recommend that you create a project to be the scoping project for that metrics scope.\nhttps://cloud.google.com/monitoring/settings/multiple-projects"
      },
      {
        "date": "2022-10-23T20:51:00.000Z",
        "voteCount": 3,
        "content": "Definitely D is right without any second thought."
      },
      {
        "date": "2024-05-12T00:00:00.000Z",
        "voteCount": 1,
        "content": "D because the recommendation is that you create a separate project for monitoring your GCP projects."
      },
      {
        "date": "2023-12-02T00:22:00.000Z",
        "voteCount": 2,
        "content": "option D"
      },
      {
        "date": "2023-04-14T22:58:00.000Z",
        "voteCount": 1,
        "content": "D for sure"
      },
      {
        "date": "2023-01-10T23:04:00.000Z",
        "voteCount": 1,
        "content": "Answer is D."
      },
      {
        "date": "2023-01-07T09:30:00.000Z",
        "voteCount": 1,
        "content": "D 100%"
      },
      {
        "date": "2022-12-25T00:21:00.000Z",
        "voteCount": 2,
        "content": "Ans: D\n\nExam passed and taken on 19/12/2022, 50/50 from this dump without buying the full access and looking for 'devops' word here: https://www.examtopics.com/discussions/google/1/"
      },
      {
        "date": "2022-10-24T07:48:00.000Z",
        "voteCount": 1,
        "content": "D is the answer.\n\nhttps://cloud.google.com/monitoring/settings#create-multi\nWe recommend that you use a new Cloud project or one without resources as the scoping project when you want to view metrics for multiple Cloud projects or AWS accounts."
      },
      {
        "date": "2022-10-06T01:22:00.000Z",
        "voteCount": 1,
        "content": "D is correct answer"
      },
      {
        "date": "2022-07-24T09:52:00.000Z",
        "voteCount": 1,
        "content": "D for sure"
      },
      {
        "date": "2022-07-20T02:05:00.000Z",
        "voteCount": 1,
        "content": "sounds like D is the best"
      },
      {
        "date": "2022-05-09T09:49:00.000Z",
        "voteCount": 1,
        "content": "Submitted D"
      },
      {
        "date": "2022-01-13T13:46:00.000Z",
        "voteCount": 1,
        "content": "D- new project with a stackdriver workspace (clean) + least privilege when giving read access to relevant members .."
      },
      {
        "date": "2021-06-17T05:30:00.000Z",
        "voteCount": 7,
        "content": "D it is"
      },
      {
        "date": "2021-06-02T09:51:00.000Z",
        "voteCount": 2,
        "content": "C answer"
      },
      {
        "date": "2021-06-08T04:53:00.000Z",
        "voteCount": 9,
        "content": "I think D because when I choose to add other project to mine, without create a new project, Google tells me: \"A Project can host many Projects and appear in many Projects, but it can only be used as the scoping project once. We recommend that you create a new Project for the purpose of having multiple Projects in the same scope.\""
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 24,
    "url": "https://www.examtopics.com/discussions/google/view/54255-exam-professional-cloud-devops-engineer-topic-1-question-24/",
    "body": "You currently store the virtual machine (VM) utilization logs in Stackdriver. You need to provide an easy-to-share interactive VM utilization dashboard that is updated in real time and contains information aggregated on a quarterly basis. You want to use Google Cloud Platform solutions. What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t1. Export VM utilization logs from Stackdriver to BigQuery. 2. Create a dashboard in Data Studio. 3. Share the dashboard with your stakeholders.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t1. Export VM utilization logs from Stackdriver to Cloud Pub/Sub. 2. From Cloud Pub/Sub, send the logs to a Security Information and Event Management (SIEM) system. 3. Build the dashboards in the SIEM system and share with your stakeholders.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t1. Export VM utilization logs from Stackdriver to BigQuery. 2. From BigQuery, export the logs to a CSV file. 3. Import the CSV file into Google Sheets. 4. Build a dashboard in Google Sheets and share it with your stakeholders.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t1. Export VM utilization logs from Stackdriver to a Cloud Storage bucket. 2. Enable the Cloud Storage API to pull the logs programmatically. 3. Build a custom data visualization application. 4. Display the pulled logs in a custom dashboard."
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 14,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-06-28T21:49:00.000Z",
        "voteCount": 22,
        "content": "A is correct"
      },
      {
        "date": "2021-08-11T07:01:00.000Z",
        "voteCount": 12,
        "content": "A for sure"
      },
      {
        "date": "2024-05-11T23:59:00.000Z",
        "voteCount": 1,
        "content": "A for sure"
      },
      {
        "date": "2023-12-02T00:26:00.000Z",
        "voteCount": 2,
        "content": "option A"
      },
      {
        "date": "2023-01-12T19:19:00.000Z",
        "voteCount": 1,
        "content": "A is correct"
      },
      {
        "date": "2023-01-07T09:32:00.000Z",
        "voteCount": 2,
        "content": "A for sure"
      },
      {
        "date": "2022-12-25T00:21:00.000Z",
        "voteCount": 4,
        "content": "Ans: A\n\nExam passed and taken on 19/12/2022, 50/50 from this dump without buying the full access and looking for 'devops' word here: https://www.examtopics.com/discussions/google/1/"
      },
      {
        "date": "2022-10-06T01:23:00.000Z",
        "voteCount": 3,
        "content": "A is correct because google cloud studio is build to provide real time metric data and it can be directly integrated with BigQuery"
      },
      {
        "date": "2022-10-23T20:47:00.000Z",
        "voteCount": 2,
        "content": "Agreed, A is right"
      },
      {
        "date": "2022-07-24T09:54:00.000Z",
        "voteCount": 1,
        "content": "A is correct"
      },
      {
        "date": "2022-05-09T09:49:00.000Z",
        "voteCount": 1,
        "content": "A is correct"
      },
      {
        "date": "2022-01-28T06:04:00.000Z",
        "voteCount": 3,
        "content": "Answer - A\nB &amp; C are ruled out straight away. Between A &amp; D, as the ask is real time, D can be ruled out.\nhttps://cloud.google.com/logging/docs/export/configure_export_v2"
      },
      {
        "date": "2022-01-13T13:50:00.000Z",
        "voteCount": 3,
        "content": "A \nStackdriver -- BQ -- DataStudio"
      },
      {
        "date": "2021-12-05T08:26:00.000Z",
        "voteCount": 2,
        "content": "Ans: A"
      },
      {
        "date": "2021-06-17T05:31:00.000Z",
        "voteCount": 4,
        "content": "A - no doubt"
      },
      {
        "date": "2021-06-02T10:02:00.000Z",
        "voteCount": 3,
        "content": "answer B. because SEIM helps realtime analysis of security and also export logs into pubsub is realtime transactions."
      },
      {
        "date": "2021-06-13T01:59:00.000Z",
        "voteCount": 2,
        "content": "In the question it is asking for VM utilisation not the security events. so answer is A"
      },
      {
        "date": "2021-06-04T00:31:00.000Z",
        "voteCount": 8,
        "content": "A is correct. It mentioned clearly in the questions: \"You want to use Google Cloud Platform solutions\""
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 25,
    "url": "https://www.examtopics.com/discussions/google/view/54256-exam-professional-cloud-devops-engineer-topic-1-question-25/",
    "body": "You need to run a business-critical workload on a fixed set of Compute Engine instances for several months. The workload is stable with the exact amount of resources allocated to it. You want to lower the costs for this workload without any performance implications. What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tPurchase Committed Use Discounts.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tMigrate the instances to a Managed Instance Group.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConvert the instances to preemptible virtual machines.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate an Unmanaged Instance Group for the instances used to run the workload."
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 22,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-06-28T21:49:00.000Z",
        "voteCount": 26,
        "content": "A is correct"
      },
      {
        "date": "2024-05-12T00:01:00.000Z",
        "voteCount": 1,
        "content": "A is correct."
      },
      {
        "date": "2023-12-02T00:28:00.000Z",
        "voteCount": 1,
        "content": "Option A"
      },
      {
        "date": "2023-08-29T09:12:00.000Z",
        "voteCount": 1,
        "content": "Answer is A"
      },
      {
        "date": "2023-01-12T19:29:00.000Z",
        "voteCount": 2,
        "content": "A. Purchase Committed Use Discounts.\n\nExplanation:\n\nWhen you know that you will have a workload running on a fixed set of instances for several months, you can take advantage of Committed Use Discounts to lower the costs. These discounts provide a lower, sustained usage rate for a committed period of time (e.g. 1 or 3 years) in exchange for committing to use a certain number of virtual machine (VM) instances or n1-standard hours. This is a good choice because you can lower costs without any performance implications and the workload is stable with the exact amount of resources allocated to it."
      },
      {
        "date": "2022-12-25T00:22:00.000Z",
        "voteCount": 1,
        "content": "Ans: A\n\nExam passed and taken on 19/12/2022, 50/50 from this dump without buying the full access and looking for 'devops' word here: https://www.examtopics.com/discussions/google/1/"
      },
      {
        "date": "2022-07-25T02:16:00.000Z",
        "voteCount": 2,
        "content": "Answer is A"
      },
      {
        "date": "2022-06-25T00:02:00.000Z",
        "voteCount": 4,
        "content": "\"business-critical workload ....... for several months\", preemptible is not suitable in here.\n\"The workload is stable with the exact amount of resources allocated to it\" , exclude B.\n\nA should be OK."
      },
      {
        "date": "2022-10-23T20:44:00.000Z",
        "voteCount": 1,
        "content": "Agreed with your comment, A is right"
      },
      {
        "date": "2022-04-26T11:43:00.000Z",
        "voteCount": 3,
        "content": "C. Since the requirement is to run \u201cbusiness-critical workloads\u201d, preemptible instances not ideal since they can be stopped randomly."
      },
      {
        "date": "2022-02-12T07:17:00.000Z",
        "voteCount": 2,
        "content": "A - Committed usage discounts is the right answer as we have a consistent workload for a known duration."
      },
      {
        "date": "2022-01-28T21:50:00.000Z",
        "voteCount": 2,
        "content": "A is correct, committed usage discounts"
      },
      {
        "date": "2022-01-28T18:47:00.000Z",
        "voteCount": 2,
        "content": "A is correct"
      },
      {
        "date": "2021-12-18T07:31:00.000Z",
        "voteCount": 2,
        "content": "In study guide you can find \u201cuser discount\u201d and \u201cpreemptable\u201d. In this case performance are qequired, so C is not possible. A for sure"
      },
      {
        "date": "2021-12-17T02:23:00.000Z",
        "voteCount": 3,
        "content": "Answer is A =&gt; several months can be up to or more than a year\nC is wrong because \n1. Business critical workload, you don't want that stopped randomly\n2. Preemptible requires the workload to be resumable -&gt; not stated in the question"
      },
      {
        "date": "2021-12-16T12:02:00.000Z",
        "voteCount": 1,
        "content": "please look at the question: \"You need to run a business-critical workload\". this is not a good idea to go for preemtible vms as it can effect performance and bussiness. I go for A."
      },
      {
        "date": "2021-10-31T11:20:00.000Z",
        "voteCount": 2,
        "content": "B and D is not related to cost because of stable workload.\nNow, really unsure between A and C.\nA: several months vs. at least one year\nC: a fixed set of Compute Engine instances vs. preemptable\n\nI think I will choose C because using preemptable, we can still try to find a way to create a new preemptable VM (same or different zones) if existing one is terminated."
      },
      {
        "date": "2021-10-18T09:25:00.000Z",
        "voteCount": 2,
        "content": "A) not correct committed discounts 1-3 years, we have several months\nB) MIG - not correct - stable workloads\nC) Preemptible vm's - not correct they last only 24 hours\nD) not sure--Unmanaged instance groups-- do they offer cost savings?"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 26,
    "url": "https://www.examtopics.com/discussions/google/view/54260-exam-professional-cloud-devops-engineer-topic-1-question-26/",
    "body": "You are part of an organization that follows SRE practices and principles. You are taking over the management of a new service from the Development Team, and you conduct a Production Readiness Review (PRR). After the PRR analysis phase, you determine that the service cannot currently meet its Service Level<br>Objectives (SLOs). You want to ensure that the service can meet its SLOs in production. What should you do next?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAdjust the SLO targets to be achievable by the service so you can bring it into production.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tNotify the development team that they will have to provide production support for the service.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tIdentify recommended reliability improvements to the service to be completed before handover.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tBring the service into production with no SLOs and build them when you have collected operational data."
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 12,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-06-28T21:49:00.000Z",
        "voteCount": 16,
        "content": "C is correct"
      },
      {
        "date": "2021-06-02T10:20:00.000Z",
        "voteCount": 10,
        "content": "C identify improvements before handover with no meet SLO"
      },
      {
        "date": "2021-06-13T02:15:00.000Z",
        "voteCount": 3,
        "content": "I also agree for the answer - C"
      },
      {
        "date": "2024-05-12T00:02:00.000Z",
        "voteCount": 1,
        "content": "C should be correct"
      },
      {
        "date": "2023-12-02T00:32:00.000Z",
        "voteCount": 1,
        "content": "Option C"
      },
      {
        "date": "2023-03-24T23:39:00.000Z",
        "voteCount": 1,
        "content": "Code has to be optimised well before submitting to the production or pre-production so that it can meet the SLO/"
      },
      {
        "date": "2023-01-12T19:36:00.000Z",
        "voteCount": 3,
        "content": "C. Identify recommended reliability improvements to the service to be completed before handover.\n\nExplanation:\nA Production Readiness Review (PRR) is an assessment of a service's readiness to be deployed in production. A service that cannot meet its Service Level Objectives (SLOs) is not ready to be deployed in production. The next step is to identify the recommended reliability improvements that should be made to the service before it can be handed over to the SRE team."
      },
      {
        "date": "2022-12-25T00:22:00.000Z",
        "voteCount": 1,
        "content": "Ans: C\n\nExam passed and taken on 19/12/2022, 50/50 from this dump without buying the full access and looking for 'devops' word here: https://www.examtopics.com/discussions/google/1/"
      },
      {
        "date": "2022-10-23T20:43:00.000Z",
        "voteCount": 1,
        "content": "C is the best"
      },
      {
        "date": "2022-09-06T18:43:00.000Z",
        "voteCount": 1,
        "content": "I choose C"
      },
      {
        "date": "2022-07-25T02:17:00.000Z",
        "voteCount": 1,
        "content": "Answer is C"
      },
      {
        "date": "2022-02-12T08:40:00.000Z",
        "voteCount": 3,
        "content": "C - If the app doesn\u2019t meet the set SLOs, improvements need to be met or a revised SLO need to be agreed with relevant stakeholders."
      },
      {
        "date": "2022-01-28T21:56:00.000Z",
        "voteCount": 1,
        "content": "Answer C makes sense"
      },
      {
        "date": "2022-01-28T18:49:00.000Z",
        "voteCount": 1,
        "content": "C is correct,"
      },
      {
        "date": "2021-12-05T08:30:00.000Z",
        "voteCount": 1,
        "content": "Ans : C"
      },
      {
        "date": "2021-10-29T05:15:00.000Z",
        "voteCount": 1,
        "content": "Why B is Not correct? SLO is used to understand if give priority to Develop or to Operation"
      },
      {
        "date": "2021-10-31T11:26:00.000Z",
        "voteCount": 4,
        "content": "According to SRE book, next phase of conducting PRR in Simple PRR model is to select items in PRR to improve before hand over the service to SRE team.\nhttps://sre.google/sre-book/evolving-sre-engagement-model/#improvements-and-refactoring-xqsrUdcyO\n\nSo C is correct."
      },
      {
        "date": "2021-06-22T16:20:00.000Z",
        "voteCount": 5,
        "content": "I don't find anything about this but C its the only one that ensure that the service can meet its SLOs in production so I go with C"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 27,
    "url": "https://www.examtopics.com/discussions/google/view/54261-exam-professional-cloud-devops-engineer-topic-1-question-27/",
    "body": "You are running an experiment to see whether your users like a new feature of a web application. Shortly after deploying the feature as a canary release, you receive a spike in the number of 500 errors sent to users, and your monitoring reports show increased latency. You want to quickly minimize the negative impact on users. What should you do first?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRoll back the experimental canary release.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tStart monitoring latency, traffic, errors, and saturation.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRecord data for the postmortem document of the incident.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tTrace the origin of 500 errors and the root cause of increased latency."
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 16,
        "isMostVoted": true
      },
      {
        "answer": "D",
        "count": 2,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2021-06-02T10:26:00.000Z",
        "voteCount": 30,
        "content": "A rollback experiment"
      },
      {
        "date": "2021-06-13T02:17:00.000Z",
        "voteCount": 5,
        "content": "Agree with A"
      },
      {
        "date": "2021-06-20T22:16:00.000Z",
        "voteCount": 4,
        "content": "Agree with A, that is even why Spinnaker has \"Manual judgment\" stage that if Canary deployment seems dangerous, it can be immediately cancelled."
      },
      {
        "date": "2024-05-12T00:03:00.000Z",
        "voteCount": 1,
        "content": "A. \n\nFirst and foremost, reduce user impact."
      },
      {
        "date": "2023-12-02T01:16:00.000Z",
        "voteCount": 2,
        "content": "Option A"
      },
      {
        "date": "2023-06-16T16:14:00.000Z",
        "voteCount": 3,
        "content": "Why are there so many wrong answers listed as  \"Correct Answers\" ?\nFor example for this question A is obviously correct and the most voted. Why does it say D is correct?"
      },
      {
        "date": "2023-12-21T05:30:00.000Z",
        "voteCount": 1,
        "content": "It's because the community answers are in 95% of all cases the right ones."
      },
      {
        "date": "2023-03-24T23:40:00.000Z",
        "voteCount": 2,
        "content": "We need to rollback the current deployment so that user are not negatively impacted, then we can go with post-mortem, root cause alaysis and fixes."
      },
      {
        "date": "2023-01-12T19:58:00.000Z",
        "voteCount": 2,
        "content": "A. Roll back the experimental canary release.\n\nExplanation:\n\nWhen you receive a spike in the number of 500 errors sent to users and increased latency after deploying a new feature, it is important to take immediate action to minimize the negative impact on users. The first step should be to roll back the experimental canary release. This will remove the new feature from production and revert the system to its previous state, which should reduce the number of errors and decrease latency.\n\nAfter rolling back the canary release, you can start monitoring latency, traffic, errors, and saturation (Option B) to determine the impact of the rollback and to make sure that the system is stable.\n\nYou can also record data for the postmortem document of the incident (Option C) to learn from the incident and to improve future releases.\n\nLastly, you can trace the origin of 500 errors and the root cause of increased latency (Option D) after rolling back the canary release to understand what went wrong and to prevent similar issues from happening again in the future."
      },
      {
        "date": "2022-12-25T00:22:00.000Z",
        "voteCount": 1,
        "content": "Ans: A\n\nExam passed and taken on 19/12/2022, 50/50 from this dump without buying the full access and looking for 'devops' word here: https://www.examtopics.com/discussions/google/1/"
      },
      {
        "date": "2022-12-10T22:04:00.000Z",
        "voteCount": 1,
        "content": "The first step that you do to reduce issue is to rollback, then comes the identifying and fixing the errors part"
      },
      {
        "date": "2022-10-23T20:41:00.000Z",
        "voteCount": 1,
        "content": "Rollback is the best option to avoid customer impact. Latency issue can be triaged in staging env with performance test hence my answer is A."
      },
      {
        "date": "2022-07-25T02:18:00.000Z",
        "voteCount": 1,
        "content": "Agree with A"
      },
      {
        "date": "2022-02-12T08:42:00.000Z",
        "voteCount": 3,
        "content": "A - Rollback the canary to bring back stability to production; then review logs to find out what caused the issues."
      },
      {
        "date": "2022-01-28T22:11:00.000Z",
        "voteCount": 1,
        "content": "Answer - A for quickly minimizing the negative impact on users"
      },
      {
        "date": "2022-01-28T19:00:00.000Z",
        "voteCount": 2,
        "content": "The correct answer is D, the deployment is Canary, hence a very small amount of user traffic, the whole purpose of Canary here will be to find the origin or errors and fix it before releasing to all the users."
      },
      {
        "date": "2022-02-15T11:19:00.000Z",
        "voteCount": 1,
        "content": "Nope! You have logs to analyze the issue."
      },
      {
        "date": "2022-01-29T12:14:00.000Z",
        "voteCount": 4,
        "content": "\"You want to quickly minimize the negative impact on users\" states that the you need to make the service available ASAP. Doesn't matter about the percent of users using the service. You can't keep waiting until you do the trace and fix. So answer should be A, per SRE principle."
      },
      {
        "date": "2022-01-19T08:17:00.000Z",
        "voteCount": 1,
        "content": "A is correct"
      },
      {
        "date": "2022-01-01T23:14:00.000Z",
        "voteCount": 1,
        "content": "A should be the answer. error happens after canary release so we are not sure for actual cause. so first we should rollback canary release."
      },
      {
        "date": "2021-12-05T08:31:00.000Z",
        "voteCount": 1,
        "content": "Ans : A"
      },
      {
        "date": "2021-08-10T15:51:00.000Z",
        "voteCount": 3,
        "content": "Has to be A"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 28,
    "url": "https://www.examtopics.com/discussions/google/view/54262-exam-professional-cloud-devops-engineer-topic-1-question-28/",
    "body": "You are responsible for creating and modifying the Terraform templates that define your Infrastructure. Because two new engineers will also be working on the same code, you need to define a process and adopt a tool that will prevent you from overwriting each other's code. You also want to ensure that you capture all updates in the latest version. What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\u05d2\u20ac\u00a2 Store your code in a Git-based version control system. \u05d2\u20ac\u00a2 Establish a process that allows developers to merge their own changes at the end of each day. \u05d2\u20ac\u00a2 Package and upload code to a versioned Cloud Storage basket as the latest master version.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\u05d2\u20ac\u00a2 Store your code in a Git-based version control system. \u05d2\u20ac\u00a2 Establish a process that includes code reviews by peers and unit testing to ensure integrity and functionality before integration of code. \u05d2\u20ac\u00a2 Establish a process where the fully integrated code in the repository becomes the latest master version.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\u05d2\u20ac\u00a2 Store your code as text files in Google Drive in a defined folder structure that organizes the files. \u05d2\u20ac\u00a2 At the end of each day, confirm that all changes have been captured in the files within the folder structure. \u05d2\u20ac\u00a2 Rename the folder structure with a predefined naming convention that increments the version.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\u05d2\u20ac\u00a2 Store your code as text files in Google Drive in a defined folder structure that organizes the files. \u05d2\u20ac\u00a2 At the end of each day, confirm that all changes have been captured in the files within the folder structure and create a new .zip archive with a predefined naming convention. \u05d2\u20ac\u00a2 Upload the .zip archive to a versioned Cloud Storage bucket and accept it as the latest version."
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 19,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-06-02T10:28:00.000Z",
        "voteCount": 31,
        "content": "B peer review and source code management tool required"
      },
      {
        "date": "2021-06-13T02:27:00.000Z",
        "voteCount": 5,
        "content": "Agree with you. Answer is B"
      },
      {
        "date": "2021-06-28T21:50:00.000Z",
        "voteCount": 6,
        "content": "B for sure"
      },
      {
        "date": "2024-05-12T00:04:00.000Z",
        "voteCount": 1,
        "content": "B.\n\nTerraform state should never be on a dev machine.. Instead it should be hosted on a sever that is access controlled and updated from latest git commit"
      },
      {
        "date": "2023-12-02T01:30:00.000Z",
        "voteCount": 2,
        "content": "Option B"
      },
      {
        "date": "2023-11-13T02:46:00.000Z",
        "voteCount": 1,
        "content": "B is correct because the terraform source file they must be versioned with Git control, Furthermore, changes must be merged and approved before going into production"
      },
      {
        "date": "2023-03-24T23:42:00.000Z",
        "voteCount": 1,
        "content": "A can't be the option why the code be pushed to any other storage when it is Git based?"
      },
      {
        "date": "2023-01-12T20:00:00.000Z",
        "voteCount": 4,
        "content": "B. Store your code in a Git-based version control system. Establish a process that includes code reviews by peers and unit testing to ensure integrity and functionality before integration of code. Establish a process where the fully integrated code in the repository becomes the latest master version.\n\nExplanation:\n\nUsing a Git-based version control system such as GitHub or GitLab is a best practice for managing code in a collaborative environment. It provides a central repository where all changes are tracked and versioned, and it also allows for concurrent development by multiple team members.\n\nEstablishing a process that includes code reviews by peers and unit testing before merging changes ensures the integrity and functionality of the code, and it also helps to prevent conflicts and errors.\n\nOnce the changes are fully integrated and tested, the latest version of the code in the repository should be considered the master version, and this should be the version that is used for deployment."
      },
      {
        "date": "2022-12-25T00:23:00.000Z",
        "voteCount": 1,
        "content": "Ans: B\n\nExam passed and taken on 19/12/2022, 50/50 from this dump without buying the full access and looking for 'devops' word here: https://www.examtopics.com/discussions/google/1/"
      },
      {
        "date": "2022-07-25T02:21:00.000Z",
        "voteCount": 1,
        "content": "B is correct ans"
      },
      {
        "date": "2022-06-24T00:09:00.000Z",
        "voteCount": 1,
        "content": "The important thing here is to avoid overwriting the code, not unit testing and other things.\nI am confused."
      },
      {
        "date": "2022-05-09T09:51:00.000Z",
        "voteCount": 1,
        "content": "submitted B"
      },
      {
        "date": "2022-05-09T04:11:00.000Z",
        "voteCount": 1,
        "content": "Does code review guarantee codes wont be overwritten or its merging of codes that guarantees this?"
      },
      {
        "date": "2023-12-20T09:25:00.000Z",
        "voteCount": 1,
        "content": "This is one of the main role in a GIT based system: to allow some peers/coders working together and avoid overwritten the code between them. The first thing you do in the morning is to fetch your local copy of the code, to be sure you are updated previous you start coding. Although the better option, if the project allows it, that you were the only person working on a specific branch. In this case, there is not going to be overwritten problems"
      },
      {
        "date": "2022-04-21T06:16:00.000Z",
        "voteCount": 1,
        "content": "I wanto go with A because B (code review) does not guarantee the developers won't over write each other's codes."
      },
      {
        "date": "2022-02-12T08:45:00.000Z",
        "voteCount": 2,
        "content": "B - Git based repository + Peer review and Unit testing"
      },
      {
        "date": "2022-01-28T19:09:00.000Z",
        "voteCount": 1,
        "content": "gitflow"
      },
      {
        "date": "2022-01-20T04:02:00.000Z",
        "voteCount": 3,
        "content": "B is correct. A is false because the code is already stored in a got repo, so there is no need to upload the code to the cloud storage bucket."
      },
      {
        "date": "2022-10-23T20:38:00.000Z",
        "voteCount": 1,
        "content": "yes, exactly. B is perfect"
      },
      {
        "date": "2022-01-19T08:20:00.000Z",
        "voteCount": 1,
        "content": "B is correct"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 29,
    "url": "https://www.examtopics.com/discussions/google/view/54263-exam-professional-cloud-devops-engineer-topic-1-question-29/",
    "body": "You support a high-traffic web application with a microservice architecture. The home page of the application displays multiple widgets containing content such as the current weather, stock prices, and news headlines. The main serving thread makes a call to a dedicated microservice for each widget and then lays out the homepage for the user. The microservices occasionally fail; when that happens, the serving thread serves the homepage with some missing content. Users of the application are unhappy if this degraded mode occurs too frequently, but they would rather have some content served instead of no content at all. You want to set a Service Level Objective (SLO) to ensure that the user experience does not degrade too much. What Service Level Indicator (SLI) should you use to measure this?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tA quality SLI: the ratio of non-degraded responses to total responses.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAn availability SLI: the ratio of healthy microservices to the total number of microservices.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tA freshness SLI: the proportion of widgets that have been updated within the last 10 minutes.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tA latency SLI: the ratio of microservice calls that complete in under 100 ms to the total number of microservice calls."
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 22,
        "isMostVoted": true
      },
      {
        "answer": "B",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2021-06-22T16:55:00.000Z",
        "voteCount": 34,
        "content": "Ans: A\nQuality as an SLI\nQuality is a helpful SLI for complex services that are designed to fail gracefully by degrading when dependencies are slow or unavailable. The SLI for quality is defined as follows:\n\nThe proportion of valid requests served without degradation of service.\n\nhttps://cloud.google.com/architecture/adopting-slos"
      },
      {
        "date": "2021-06-28T21:50:00.000Z",
        "voteCount": 10,
        "content": "Ans: B"
      },
      {
        "date": "2021-12-27T01:03:00.000Z",
        "voteCount": 2,
        "content": "Nope A"
      },
      {
        "date": "2023-12-02T01:33:00.000Z",
        "voteCount": 1,
        "content": "Option A"
      },
      {
        "date": "2023-01-12T20:06:00.000Z",
        "voteCount": 3,
        "content": "A. A quality SLI: the ratio of non-degraded responses to total responses.\n\nExplanation:\n\nAn SLI (Service Level Indicator) is a metric that is used to measure the performance of a service against a specific SLO (Service Level Objective). To measure the user experience of the web application, which is the main concern in this scenario, the most appropriate SLI would be a quality SLI: the ratio of non-degraded responses to total responses. This will give you a clear indication of how often users are experiencing a degraded mode of the web application, and it will allow you to set a specific SLO for the percentage of non-degraded responses that you want to achieve.\n\nAn availability SLI (Option B) would measure the availability of the microservices, not the user experience of the web application.\n\nA freshness SLI (Option C) would measure the freshness of the content, not the user experience of the web application.\n\nA latency SLI (Option D) would measure the speed of the microservices, not the user experience of the web application."
      },
      {
        "date": "2022-12-25T00:23:00.000Z",
        "voteCount": 1,
        "content": "Ans: A\n\nExam passed and taken on 19/12/2022, 50/50 from this dump without buying the full access and looking for 'devops' word here: https://www.examtopics.com/discussions/google/1/"
      },
      {
        "date": "2022-12-15T14:16:00.000Z",
        "voteCount": 1,
        "content": "Confusion between ET and user answers. How should I know which answer is correct? Anyone can address this?"
      },
      {
        "date": "2022-07-25T02:23:00.000Z",
        "voteCount": 1,
        "content": "Answer A is looks correct for me"
      },
      {
        "date": "2022-07-06T05:31:00.000Z",
        "voteCount": 1,
        "content": "I think D is the correct"
      },
      {
        "date": "2022-06-25T02:21:00.000Z",
        "voteCount": 2,
        "content": "based on the comments of \"to ensure that the user experience does not degrade too much\" ,  A is OK.\n\nThe SLI for quality is defined as follows:\nThe proportion of valid requests served without degradation of service.\n\nhttps://cloud.google.com/architecture/adopting-slos#sli-quality"
      },
      {
        "date": "2022-06-25T02:25:00.000Z",
        "voteCount": 1,
        "content": "freshness SLI : The proportion of valid data updated more recently than a threshold.\nlatency SLI : The proportion of valid requests served faster than a threshold.\navailability SLI: The proportion of valid requests served successfully."
      },
      {
        "date": "2022-05-09T09:53:00.000Z",
        "voteCount": 3,
        "content": "Submitted A"
      },
      {
        "date": "2022-04-21T18:18:00.000Z",
        "voteCount": 1,
        "content": "I think B."
      },
      {
        "date": "2022-02-12T08:49:00.000Z",
        "voteCount": 5,
        "content": "A - Quality SLI: Number of correct pages / Total number of pages served."
      },
      {
        "date": "2022-01-28T19:15:00.000Z",
        "voteCount": 2,
        "content": "https://cloud.google.com/architecture/adopting-slos#sli-quality"
      },
      {
        "date": "2021-12-22T01:42:00.000Z",
        "voteCount": 1,
        "content": "Answer A - Quality as an SLI suits well for degrading dependencies"
      },
      {
        "date": "2021-12-17T03:00:00.000Z",
        "voteCount": 6,
        "content": "https://cloud.google.com/architecture/adopting-slos?hl=en#sli-quality\n\nQuality is a helpful SLI for complex services that are designed to fail gracefully by degrading when dependencies are slow or unavailable. The SLI for quality is defined as follows:\n\nThe proportion of valid requests served without degradation of service.\nFor example, a web page might load its main content from one datastore and load ancillary, optional assets from 100 other services and datastores. If one optional service is out of service or too slow, the page can still be rendered without the ancillary elements. By measuring the number of requests that are served a degraded response (that is, a response missing at least one backend service's response), you can report the ratio of requests that were bad. You might even track how many responses to the user were missing a response from a single backend, or were missing responses from multiple backends."
      },
      {
        "date": "2021-12-05T08:32:00.000Z",
        "voteCount": 2,
        "content": "Ans : B"
      },
      {
        "date": "2021-11-09T23:14:00.000Z",
        "voteCount": 2,
        "content": "Ans is A\nhttps://sre.google/workbook/implementing-slos/\nRequest-driven: Quality\n\nIf the service degrades gracefully when overloaded or when backends are unavailable, you need to measure the proportion of responses that were served in an undegraded state. For example, if the User Data store is unavailable, the game is still playable but uses generic imagery."
      },
      {
        "date": "2021-11-15T03:39:00.000Z",
        "voteCount": 3,
        "content": "Ans B\nhttps://cloud.google.com/blog/products/gcp/available-or-not-that-is-the-question-cre-life-lessons, your answer is wrong"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 30,
    "url": "https://www.examtopics.com/discussions/google/view/54264-exam-professional-cloud-devops-engineer-topic-1-question-30/",
    "body": "You support a multi-region web service running on Google Kubernetes Engine (GKE) behind a Global HTTP/S Cloud Load Balancer (CLB). For legacy reasons, user requests first go through a third-party Content Delivery Network (CDN), which then routes traffic to the CLB. You have already implemented an availability<br>Service Level Indicator (SLI) at the CLB level. However, you want to increase coverage in case of a potential load balancer misconfiguration, CDN failure, or other global networking catastrophe. Where should you measure this new SLI? (Choose two.)<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tYour application servers' logs.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tInstrumentation coded directly in the client.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tMetrics exported from the application servers.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tGKE health checks for your application servers.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tA synthetic client that periodically sends simulated user requests.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "BE",
    "answerDescription": "",
    "votes": [
      {
        "answer": "BE",
        "count": 12,
        "isMostVoted": true
      },
      {
        "answer": "CE",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2021-07-17T17:34:00.000Z",
        "voteCount": 23,
        "content": "https://cloud.google.com/architecture/adopting-slos#choosing_a_measurement_method\nB &gt; Using client instrumentation. \nE &gt; Implementing synthetic testing."
      },
      {
        "date": "2022-01-01T23:34:00.000Z",
        "voteCount": 2,
        "content": "How you code instrumentation at each client side?"
      },
      {
        "date": "2024-03-07T07:46:00.000Z",
        "voteCount": 1,
        "content": "Client instrumentation can be easily done using Browser instrumentation using various UI frameworks you can do that. One of the most popular framework and SDK is OpenTelemetry. So the answer is B and E."
      },
      {
        "date": "2021-06-28T21:50:00.000Z",
        "voteCount": 11,
        "content": "BE is correct"
      },
      {
        "date": "2024-05-12T00:08:00.000Z",
        "voteCount": 1,
        "content": "BE\n\nA - Is inside the GKE .. which is useless at this point\nC - Same as A\nD - Same as it too late in the pipeline to detect these issues"
      },
      {
        "date": "2024-02-03T02:36:00.000Z",
        "voteCount": 1,
        "content": "I dont still get why the answers are B &amp; E. \n\nOption A &amp; C also appear in below documentation along with B &amp; E so everyone is only chosing B &amp; E\nhttps://cloud.google.com/architecture/framework/reliability/adopting-slos#choose_a_measurement_method"
      },
      {
        "date": "2023-12-02T01:35:00.000Z",
        "voteCount": 1,
        "content": "Option B and E"
      },
      {
        "date": "2023-11-13T05:54:00.000Z",
        "voteCount": 1,
        "content": "https://cloud.google.com/architecture/framework/reliability/adopting-slos#choose_a_measurement_method"
      },
      {
        "date": "2023-11-13T05:51:00.000Z",
        "voteCount": 1,
        "content": "https://cloud.google.com/architecture/framework/reliability/adopting-slos#choose_a_measurement_method"
      },
      {
        "date": "2022-12-25T00:24:00.000Z",
        "voteCount": 1,
        "content": "Ans: BE\n\nExam passed and taken on 19/12/2022, 50/50 from this dump without buying the full access and looking for 'devops' word here: https://www.examtopics.com/discussions/google/1/"
      },
      {
        "date": "2022-11-23T23:29:00.000Z",
        "voteCount": 1,
        "content": "from my opinion, network issue will not be detected in app server side. so any SLI in application wont work."
      },
      {
        "date": "2022-07-27T05:16:00.000Z",
        "voteCount": 3,
        "content": "If need something beyong CDN and CLB, seems only option is on client side directly"
      },
      {
        "date": "2022-07-25T02:25:00.000Z",
        "voteCount": 2,
        "content": "For me,  B and E is correct"
      },
      {
        "date": "2022-04-24T04:21:00.000Z",
        "voteCount": 2,
        "content": "For me, it is B and E"
      },
      {
        "date": "2022-02-21T14:10:00.000Z",
        "voteCount": 1,
        "content": "nobody submitted a voting comment but B&amp;E is the consensus on most feedback"
      },
      {
        "date": "2021-12-22T01:51:00.000Z",
        "voteCount": 1,
        "content": "IMHO -&gt; (E and C)A synthetic client that periodically sends simulated user requests could be used for checking CDN connection is up and running at frequent intervals and other one C for metrics exposed from Application servers. Since as per the question CLB SLI is already defined."
      },
      {
        "date": "2021-12-05T08:40:00.000Z",
        "voteCount": 1,
        "content": "Ans : BE"
      },
      {
        "date": "2021-11-27T14:04:00.000Z",
        "voteCount": 1,
        "content": "Its B and E, when there is a networking catastrophe we cannot rely on Application as traffic may not even come there."
      },
      {
        "date": "2021-06-22T18:54:00.000Z",
        "voteCount": 1,
        "content": "I have so many doubts with this one\nThe SLI for coverage is defined as follows:\nThe proportion of valid data processed successfully.\n\nI think: \nA logs are a good option and C Metrics exported \nI don't get it why code directly in the client but if anyone have some information or a link please let me know.\n\nthe documentation says this\nFinally, to generate your SLI for coverage, you count the number of records that processed successfully and compare that number against the total valid record count.\n(we can do it with logs)\nhttps://cloud.google.com/architecture/adopting-slos"
      },
      {
        "date": "2022-09-30T00:56:00.000Z",
        "voteCount": 1,
        "content": "Many people selected 'code directly in the client' because in the documentation it says it's the way to go with legacy systems:\n\n\"Using client instrumentation. Because legacy systems typically lack built-in, end-user client instrumentation, setting up instrumentation might require a significant investment. However, if you use an APM suite or frontend framework that provides client instrumentation, you can quickly gain insight into your customer's happiness.\""
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 31,
    "url": "https://www.examtopics.com/discussions/google/view/54267-exam-professional-cloud-devops-engineer-topic-1-question-31/",
    "body": "Your team is designing a new application for deployment into Google Kubernetes Engine (GKE). You need to set up monitoring to collect and aggregate various application-level metrics in a centralized location. You want to use Google Cloud Platform services while minimizing the amount of work required to set up monitoring. What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tPublish various metrics from the application directly to the Stackdriver Monitoring API, and then observe these custom metrics in Stackdriver.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tInstall the Cloud Pub/Sub client libraries, push various metrics from the application to various topics, and then observe the aggregated metrics in Stackdriver.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tInstall the OpenTelemetry client libraries in the application, configure Stackdriver as the export destination for the metrics, and then observe the application's metrics in Stackdriver.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEmit all metrics in the form of application-specific log messages, pass these messages from the containers to the Stackdriver logging collector, and then observe metrics in Stackdriver."
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 13,
        "isMostVoted": true
      },
      {
        "answer": "C",
        "count": 10,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2021-10-29T06:27:00.000Z",
        "voteCount": 18,
        "content": "C is correct, for A the installing of stackdriver library in the application is missing, without the lbrary custom metric cannot be created by the application"
      },
      {
        "date": "2021-10-24T01:54:00.000Z",
        "voteCount": 14,
        "content": "You want to use Google Cloud Platform services while minimizing the amount of work required to set up monitoring.\n\nHence A"
      },
      {
        "date": "2024-05-12T00:09:00.000Z",
        "voteCount": 1,
        "content": "C should be correct"
      },
      {
        "date": "2024-03-29T08:17:00.000Z",
        "voteCount": 1,
        "content": "C. OpenTelemetry with Stackdriver: OpenTelemetry is a vendor-neutral instrumentation framework. By configuring Stackdriver as the export destination, you leverage a \nstandardized approach with minimal coding effort.\n\nOpenTelemetry offers an easy way to collect and export metrics from your application to Stackdriver, minimizing setup work.\n\nAnswer : C"
      },
      {
        "date": "2024-03-07T07:53:00.000Z",
        "voteCount": 1,
        "content": "OpenTelemetry provides standardized metrics collection, with it's SDK and various client libraries. So using OpenTelemetry is much faster and easier than using Cloud Monitoring API directly. So it's C."
      },
      {
        "date": "2023-12-02T01:42:00.000Z",
        "voteCount": 1,
        "content": "Option C"
      },
      {
        "date": "2023-11-05T07:38:00.000Z",
        "voteCount": 2,
        "content": "You can create user-defined metrics by using the Cloud Monitoring API directly. However, we recommend that you use OpenTelemetry. https://cloud.google.com/monitoring/custom-metrics"
      },
      {
        "date": "2023-11-05T07:39:00.000Z",
        "voteCount": 1,
        "content": "I think coding raw API calls is more effort than configure Open Telemetry. But maybe I am wrong."
      },
      {
        "date": "2023-10-05T02:03:00.000Z",
        "voteCount": 1,
        "content": "C should be correct Answer"
      },
      {
        "date": "2023-07-23T02:27:00.000Z",
        "voteCount": 1,
        "content": "C is correct. Installing Open Telemetry client libraries in the application. setting stackdriver as export destination and then observing the app metrics."
      },
      {
        "date": "2023-07-26T07:14:00.000Z",
        "voteCount": 2,
        "content": "Hey Cassim ? Are these questions still relevant ? Thanks in advance for your answer!"
      },
      {
        "date": "2023-09-16T11:02:00.000Z",
        "voteCount": 1,
        "content": "yes they are, just replace the name stack driver with Cloud Operations Suite and you will be fine\n\nhttps://cloud.google.com/products/operations?hl=en"
      },
      {
        "date": "2023-01-17T08:26:00.000Z",
        "voteCount": 3,
        "content": "You should use a library/SDK instead of coding raw API requests all over the place. Hence I go with C - OpenTelemetry."
      },
      {
        "date": "2023-01-12T20:33:00.000Z",
        "voteCount": 1,
        "content": "Option A, uses GCP services and reduce development effort"
      },
      {
        "date": "2022-12-31T00:37:00.000Z",
        "voteCount": 4,
        "content": "The ans should be A. 3 main points here:\napplication-level metrics\nuse Google Cloud Platform services\nminimizing the amount of work required\n\nB: b is not correct as google suggest only external metrics are pushed using pub/sub. For custom metrics use stackdriver api.\nC: OpenTelemetry is not a gcp service\nD: too much work"
      },
      {
        "date": "2022-12-25T00:25:00.000Z",
        "voteCount": 2,
        "content": "Ans: A\n\nExam passed and taken on 19/12/2022, 50/50 from this dump without buying the full access and looking for 'devops' word here: https://www.examtopics.com/discussions/google/1/"
      },
      {
        "date": "2022-12-13T22:54:00.000Z",
        "voteCount": 2,
        "content": "openTelemetry library only appear in Cloud Trace , and openTelemetry is not a GCP service ? \nhttps://cloud.google.com/trace/docs/setup"
      },
      {
        "date": "2022-11-24T18:34:00.000Z",
        "voteCount": 2,
        "content": "stackdriver API can not monitor application-level metrics\nhttps://cloud.google.com/stackdriver/docs/solutions/gke/installing"
      },
      {
        "date": "2022-11-14T10:11:00.000Z",
        "voteCount": 2,
        "content": "Application-generated (custom) metrics can only be generated by using compatible libraries. \nhttps://cloud.google.com/monitoring/custom-metrics"
      },
      {
        "date": "2022-08-14T18:08:00.000Z",
        "voteCount": 1,
        "content": "I think the answer is A"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 32,
    "url": "https://www.examtopics.com/discussions/google/view/54268-exam-professional-cloud-devops-engineer-topic-1-question-32/",
    "body": "You support a production service that runs on a single Compute Engine instance. You regularly need to spend time on recreating the service by deleting the crashing instance and creating a new instance based on the relevant image. You want to reduce the time spent performing manual operations while following Site<br>Reliability Engineering principles. What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tFile a bug with the development team so they can find the root cause of the crashing instance.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a Managed instance Group with a single instance and use health checks to determine the system status.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAdd a Load Balancer in front of the Compute Engine instance and use health checks to determine the system status.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a Stackdriver Monitoring dashboard with SMS alerts to be able to start recreating the crashed instance promptly after it was crashed."
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 20,
        "isMostVoted": true
      },
      {
        "answer": "A",
        "count": 3,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2021-06-02T11:15:00.000Z",
        "voteCount": 25,
        "content": "B managed instance groups can be handled when a vm crashed and immediately created new one"
      },
      {
        "date": "2021-06-13T03:51:00.000Z",
        "voteCount": 6,
        "content": "Agree. correct Answer : B"
      },
      {
        "date": "2021-06-28T21:51:00.000Z",
        "voteCount": 8,
        "content": "B is correct"
      },
      {
        "date": "2024-05-12T00:10:00.000Z",
        "voteCount": 1,
        "content": "MIG is the right way."
      },
      {
        "date": "2023-12-02T01:47:00.000Z",
        "voteCount": 1,
        "content": "option B"
      },
      {
        "date": "2023-11-13T06:05:00.000Z",
        "voteCount": 1,
        "content": "B \nhttps://cloud.google.com/compute/docs/instance-groups?hl=en#autohealing"
      },
      {
        "date": "2023-08-30T10:21:00.000Z",
        "voteCount": 1,
        "content": "Correct B"
      },
      {
        "date": "2023-01-12T20:35:00.000Z",
        "voteCount": 3,
        "content": "The best option for reducing the time spent performing manual operations while following Site Reliability Engineering principles would be B. Create a Managed instance Group with a single instance and use health checks to determine the system status.\n\nA Managed Instance Group (MIG) is a GCP service that automatically creates, scales, and deletes instances based on the policies that you set. By creating a MIG with a single instance, you can set up health checks to automatically detect when the instance is crashing and replace it with a new instance, without manual intervention. This ensures that the service is always available, and it can reduce the time spent recreating the service and also minimize the risk of human errors."
      },
      {
        "date": "2022-12-29T08:38:00.000Z",
        "voteCount": 1,
        "content": "definitely B"
      },
      {
        "date": "2022-12-25T00:25:00.000Z",
        "voteCount": 1,
        "content": "Ans: B\n\nExam passed and taken on 19/12/2022, 50/50 from this dump without buying the full access and looking for 'devops' word here: https://www.examtopics.com/discussions/google/1/"
      },
      {
        "date": "2022-08-10T06:46:00.000Z",
        "voteCount": 4,
        "content": "I think that the answer is B, \nAlthough SRE principles guide you to find the root cause and post-mortem, the question clearly asks you to: Reduce time spent on manual operations.\n\nTherefore the answer is B (Although deep in my heart I would personally combine A and B)"
      },
      {
        "date": "2022-07-25T03:19:00.000Z",
        "voteCount": 1,
        "content": "B is correct"
      },
      {
        "date": "2022-05-09T09:55:00.000Z",
        "voteCount": 1,
        "content": "Submit B in the exam"
      },
      {
        "date": "2022-02-12T08:56:00.000Z",
        "voteCount": 1,
        "content": "B - Managed Instance Group with one Compute Engine instance will take care of this use case."
      },
      {
        "date": "2022-02-03T01:56:00.000Z",
        "voteCount": 4,
        "content": "answer is A. If the root cause of crashing is not found and fixed, the crashing will still happen frequently even if we go MIG. Waste of money and time and does not follows SRE principles"
      },
      {
        "date": "2023-05-26T16:30:00.000Z",
        "voteCount": 1,
        "content": "but if the question is saying that \"You want to reduce the time spent performing manual operations while following Site Reliability Engineering principles\",is not improvement and fix the issue, I think if we consider reducing the time spent performing manual operations, cloud be Option B"
      },
      {
        "date": "2022-02-01T21:47:00.000Z",
        "voteCount": 1,
        "content": "B because it automates toil. I can't think of a better answer."
      },
      {
        "date": "2022-01-29T05:32:00.000Z",
        "voteCount": 2,
        "content": "Answer B, SRE principles says remove the toil where ever possible. MIG will fit here by automating the VM creation."
      },
      {
        "date": "2022-01-28T19:29:00.000Z",
        "voteCount": 3,
        "content": "IMO - SRE practice should be to get the root cause of crashing of VM and fix it. MIG will not help here."
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 33,
    "url": "https://www.examtopics.com/discussions/google/view/54269-exam-professional-cloud-devops-engineer-topic-1-question-33/",
    "body": "Your application artifacts are being built and deployed via a CI/CD pipeline. You want the CI/CD pipeline to securely access application secrets. You also want to more easily rotate secrets in case of a security breach. What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tPrompt developers for secrets at build time. Instruct developers to not store secrets at rest.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tStore secrets in a separate configuration file on Git. Provide select developers with access to the configuration file.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tStore secrets in Cloud Storage encrypted with a key from Cloud KMS. Provide the CI/CD pipeline with access to Cloud KMS via IAM.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEncrypt the secrets and store them in the source code repository. Store a decryption key in a separate repository and grant your pipeline access to it."
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 10,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-08-10T15:58:00.000Z",
        "voteCount": 13,
        "content": "C is the \"best\" from the choices given"
      },
      {
        "date": "2021-06-28T21:51:00.000Z",
        "voteCount": 6,
        "content": "Answer C"
      },
      {
        "date": "2024-05-12T00:11:00.000Z",
        "voteCount": 1,
        "content": "Option C"
      },
      {
        "date": "2023-12-02T02:02:00.000Z",
        "voteCount": 1,
        "content": "Option C"
      },
      {
        "date": "2023-08-30T10:31:00.000Z",
        "voteCount": 1,
        "content": "C is the only viable option..."
      },
      {
        "date": "2023-01-12T20:38:00.000Z",
        "voteCount": 2,
        "content": "The best option for securing application secrets while making it easier to rotate them in case of a security breach would be:\n\nC. Store secrets in Cloud Storage encrypted with a key from Cloud KMS. Provide the CI/CD pipeline with access to Cloud KMS via IAM.\n\nBy storing secrets in Cloud Storage, you can take advantage of the security features provided by the platform and encrypt them using Cloud KMS, a GCP service that allows you to create, manage, and use encryption keys. This way you can control who has access to the secrets, and you can easily rotate the encryption keys in case of a security breach. Additionally, you can use IAM to give the CI/CD pipeline the necessary permissions to access the secrets and use them during the deployment process, without the need to store them in the source code or give access to them to specific developers."
      },
      {
        "date": "2022-12-25T00:29:00.000Z",
        "voteCount": 1,
        "content": "Ans: C\n\nExam passed and taken on 19/12/2022, 50/50 from this dump without buying the full access and looking for 'devops' word here: https://www.examtopics.com/discussions/google/1/"
      },
      {
        "date": "2022-07-25T03:25:00.000Z",
        "voteCount": 1,
        "content": "Answer is C"
      },
      {
        "date": "2022-01-29T05:38:00.000Z",
        "voteCount": 2,
        "content": "Answer is C , https://cloud.google.com/security-key-management"
      },
      {
        "date": "2022-01-28T19:30:00.000Z",
        "voteCount": 1,
        "content": "C is the answer"
      },
      {
        "date": "2021-12-05T08:42:00.000Z",
        "voteCount": 1,
        "content": "Ans : C"
      },
      {
        "date": "2021-06-13T04:07:00.000Z",
        "voteCount": 4,
        "content": "C is the best option."
      },
      {
        "date": "2021-06-02T11:16:00.000Z",
        "voteCount": 4,
        "content": "answer C storing secrets in cloud is better option"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 34,
    "url": "https://www.examtopics.com/discussions/google/view/54280-exam-professional-cloud-devops-engineer-topic-1-question-34/",
    "body": "Your company follows Site Reliability Engineering practices. You are the person in charge of Communications for a large, ongoing incident affecting your customer-facing applications. There is still no estimated time for a resolution of the outage. You are receiving emails from internal stakeholders who want updates on the outage, as well as emails from customers who want to know what is happening. You want to efficiently provide updates to everyone affected by the outage.<br>What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tFocus on responding to internal stakeholders at least every 30 minutes. Commit to \u05d2\u20acnext update\u05d2\u20ac times.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tProvide periodic updates to all stakeholders in a timely manner. Commit to a \u05d2\u20acnext update\u05d2\u20ac time in all communications.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDelegate the responding to internal stakeholder emails to another member of the Incident Response Team. Focus on providing responses directly to customers.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tProvide all internal stakeholder emails to the Incident Commander, and allow them to manage internal communications. Focus on providing responses directly to customers."
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 10,
        "isMostVoted": true
      },
      {
        "answer": "C",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2021-06-22T19:47:00.000Z",
        "voteCount": 24,
        "content": "Ans: B (the communication lead CAN'T delegate)\n\nWhen disaster strikes, the person who declares the incident typically steps into the IC role and directs the high-level state of the incident. The IC concentrates on the 3Cs and does the following:\n\nCommands and coordinates the incident response, delegating roles as needed. By default, the IC assumes all roles that have not been delegated yet.\nCommunicates effectively.\nStays in control of the incident response.\nWorks with other responders to resolve the incident.\n\nhttps://sre.google/workbook/incident-response/"
      },
      {
        "date": "2021-06-28T21:51:00.000Z",
        "voteCount": 10,
        "content": "B is correct"
      },
      {
        "date": "2023-12-02T02:04:00.000Z",
        "voteCount": 1,
        "content": "Option B"
      },
      {
        "date": "2023-01-12T20:42:00.000Z",
        "voteCount": 2,
        "content": "The best option for efficiently providing updates to everyone affected by the outage would be:\n\nB. Provide periodic updates to all stakeholders in a timely manner. Commit to a \"next update\" time in all communications.\n\nDuring an incident, it's important to keep all stakeholders informed about the current situation and any progress made towards resolving the problem. Providing periodic updates to all stakeholders, including internal stakeholders and customers, is the most effective way of ensuring everyone is informed. Additionally, by committing to a \"next update\" time in all communications, you ensure that stakeholders are aware of when they can expect to receive new information. This way you can avoid the unnecessary pressure of responding to emails constantly, and you can focus on the incident resolution and providing accurate information."
      },
      {
        "date": "2022-12-25T00:29:00.000Z",
        "voteCount": 1,
        "content": "Ans: B\n\nExam passed and taken on 19/12/2022, 50/50 from this dump without buying the full access and looking for 'devops' word here: https://www.examtopics.com/discussions/google/1/"
      },
      {
        "date": "2022-11-08T04:31:00.000Z",
        "voteCount": 1,
        "content": "Appeard in 7/11/2022 exam\n\nKeys : Large incident, you need to respond to stakeholder + users, manage it effectively"
      },
      {
        "date": "2022-07-25T03:26:00.000Z",
        "voteCount": 1,
        "content": "Answer is B"
      },
      {
        "date": "2022-01-29T05:53:00.000Z",
        "voteCount": 1,
        "content": "Ans B , The CL\u2019s main duties include providing periodic updates to the incident response team and stakeholders, and managing inquiries about the incident."
      },
      {
        "date": "2022-01-08T15:51:00.000Z",
        "voteCount": 1,
        "content": "B was my first answer, but turns out that CL can delegate, according to SRE workbook (https://sre.google/workbook/incident-response/):\n\"Both the CL and OL may lead a team of people to help manage their specific areas of incident response. These teams can expand or contract as needed. If the incident becomes small enough, the CL role can be subsumed back into the IC role.\"\nIn that case, taking into account that this is a major incidente, C seems to be the most accurate answer."
      },
      {
        "date": "2021-12-15T12:16:00.000Z",
        "voteCount": 2,
        "content": "B - providing updates to all stakeholders is your job as being in charge of communications.  Incident Commander delegates."
      },
      {
        "date": "2021-12-14T18:14:00.000Z",
        "voteCount": 2,
        "content": "B is correct. everyone is saying B is correct. not sure why final answer is C!!"
      },
      {
        "date": "2021-10-31T11:58:00.000Z",
        "voteCount": 3,
        "content": "B is correct\nC is wrong. If CL want to delegate, s/he must talk with IC that we need another internal CL. IC will delegate if needed."
      },
      {
        "date": "2021-06-17T22:24:00.000Z",
        "voteCount": 2,
        "content": "B is most correct one, with quite a lot of details missing, but the direction is right"
      },
      {
        "date": "2021-06-07T00:00:00.000Z",
        "voteCount": 1,
        "content": "we can have external communication lead. as there is a large outage we can choose to have one more role of external communication lead. hence option C"
      },
      {
        "date": "2021-06-14T03:15:00.000Z",
        "voteCount": 2,
        "content": "for answer C. one doubt does Communication Leads (CL) can delegate the task or this is Incident commander (IC) can do...\nB looks more closer."
      },
      {
        "date": "2021-06-13T04:27:00.000Z",
        "voteCount": 1,
        "content": "Looks correct to me as well."
      },
      {
        "date": "2021-06-02T12:09:00.000Z",
        "voteCount": 1,
        "content": "could be B"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 35,
    "url": "https://www.examtopics.com/discussions/google/view/54281-exam-professional-cloud-devops-engineer-topic-1-question-35/",
    "body": "Your team uses Cloud Build for all CI/CD pipelines. You want to use the kubectl builder for Cloud Build to deploy new images to Google Kubernetes Engine<br>(GKE). You need to authenticate to GKE while minimizing development effort. What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAssign the Container Developer role to the Cloud Build service account.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSpecify the Container Developer role for Cloud Build in the cloudbuild.yaml file.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a new service account with the Container Developer role and use it to run Cloud Build.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a separate step in Cloud Build to retrieve service account credentials and pass these to kubectl."
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 13,
        "isMostVoted": true
      },
      {
        "answer": "C",
        "count": 2,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2021-06-03T04:31:00.000Z",
        "voteCount": 25,
        "content": "I think A"
      },
      {
        "date": "2021-09-03T00:41:00.000Z",
        "voteCount": 11,
        "content": "A\nhttps://cloud.google.com/build/docs/securing-builds/configure-user-specified-service-accounts"
      },
      {
        "date": "2023-12-02T02:16:00.000Z",
        "voteCount": 2,
        "content": "Option C"
      },
      {
        "date": "2023-09-16T11:06:00.000Z",
        "voteCount": 1,
        "content": "A \nhttps://cloud.google.com/build/docs/deploying-builds/deploy-gke#required_iam_permissions"
      },
      {
        "date": "2023-07-01T19:10:00.000Z",
        "voteCount": 1,
        "content": "Doesn't C makes more sense ? Why is it A?"
      },
      {
        "date": "2023-07-16T09:45:00.000Z",
        "voteCount": 2,
        "content": "are these questions still relevant?"
      },
      {
        "date": "2023-07-17T03:41:00.000Z",
        "voteCount": 1,
        "content": "I hope that are still relevant. I'll take the exam this week, can someone confirm about aswani question?"
      },
      {
        "date": "2024-01-18T23:06:00.000Z",
        "voteCount": 1,
        "content": "can someone confirm now?"
      },
      {
        "date": "2023-06-27T06:32:00.000Z",
        "voteCount": 1,
        "content": "I think that the A is incorrect... The good practices says that the CB like the other resources should avoid to use the default SA, so the correct one is the C which creates a SA and then give the required roles."
      },
      {
        "date": "2023-07-15T17:38:00.000Z",
        "voteCount": 1,
        "content": "are these questions still relevant?"
      },
      {
        "date": "2023-04-13T02:37:00.000Z",
        "voteCount": 3,
        "content": "100% A and this is the doc the proves this: https://cloud.google.com/build/docs/deploying-builds/deploy-gke#required_iam_permissions"
      },
      {
        "date": "2023-01-12T20:45:00.000Z",
        "voteCount": 3,
        "content": "The best option for authenticating to GKE while minimizing development effort would be A. Assign the Container Developer role to the Cloud Build service account.\n\nGoogle Cloud Build uses a default service account to run the build, this service account is automatically created by Cloud Build and it has the necessary permissions to access the resources used by the build. By assigning the Container Developer role to this service account, it will have the necessary permissions to deploy new images to GKE. This way you don't need to create a new service account or specify the role in the cloudbuild.yaml file. This is an easy and secure way to authenticate to GKE without adding extra steps to the CI/CD pipeline."
      },
      {
        "date": "2023-01-01T04:13:00.000Z",
        "voteCount": 1,
        "content": "Answer is A\nhttps://cloud.google.com/build/docs/deploying-builds/deploy-gke#required_iam_permissions"
      },
      {
        "date": "2022-12-25T00:29:00.000Z",
        "voteCount": 1,
        "content": "Ans: A\n\nExam passed and taken on 19/12/2022, 50/50 from this dump without buying the full access and looking for 'devops' word here: https://www.examtopics.com/discussions/google/1/"
      },
      {
        "date": "2022-11-24T19:17:00.000Z",
        "voteCount": 2,
        "content": "i think A, new service account needs \" Cloud Build Service Account \" role and \" kubernete engine developer\" role to execute the build steps for cloud build."
      },
      {
        "date": "2022-10-23T19:32:00.000Z",
        "voteCount": 1,
        "content": "A is more suitable for this scenario\n\nhttps://cloud.google.com/build/docs/securing-builds/configure-access-for-cloud-build-service-account"
      },
      {
        "date": "2022-10-16T02:52:00.000Z",
        "voteCount": 1,
        "content": "I think A is correct, but please note that question specify that kubectl builder (https://github.com/GoogleCloudPlatform/cloud-builders/tree/master/kubectl) and NOT gke-deploy (https://github.com/GoogleCloudPlatform/cloud-builders/tree/master/gke-deploy) is being used!\nhttps://cloud.google.com/build/docs/deploying-builds/deploy-gke\nIn any case, as specified in kubectl builder documentation: When executed in the Cloud Build environment, commands are executed with credentials of the builder service account for the build project."
      },
      {
        "date": "2022-07-25T03:27:00.000Z",
        "voteCount": 1,
        "content": "Answer is A"
      },
      {
        "date": "2022-04-24T04:40:00.000Z",
        "voteCount": 1,
        "content": "A is the correct answer"
      },
      {
        "date": "2022-01-02T00:56:00.000Z",
        "voteCount": 4,
        "content": "A should be the correct one. because assigning permission to cloud build service account will  give permission to deploy while minimizing additional overhead."
      },
      {
        "date": "2021-12-11T13:04:00.000Z",
        "voteCount": 3,
        "content": "Agree with A.  \nReference to container.developer role: https://cloud.google.com/kubernetes-engine/docs/how-to/iam"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 36,
    "url": "https://www.examtopics.com/discussions/google/view/54282-exam-professional-cloud-devops-engineer-topic-1-question-36/",
    "body": "You support an application that stores product information in cached memory. For every cache miss, an entry is logged in Stackdriver Logging. You want to visualize how often a cache miss happens over time. What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tLink Stackdriver Logging as a source in Google Data Studio. Filter the logs on the cache misses.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure Stackdriver Profiler to identify and visualize when the cache misses occur based on the logs.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a logs-based metric in Stackdriver Logging and a dashboard for that metric in Stackdriver Monitoring.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure BigQuery as a sink for Stackdriver Logging. Create a scheduled query to filter the cache miss logs and write them to a separate table."
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 8,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-06-28T21:52:00.000Z",
        "voteCount": 18,
        "content": "C for sure"
      },
      {
        "date": "2021-06-08T06:05:00.000Z",
        "voteCount": 11,
        "content": "I think C: https://cloud.google.com/logging/docs/logs-based-metrics#counter-metric"
      },
      {
        "date": "2024-05-12T00:15:00.000Z",
        "voteCount": 1,
        "content": "Option C"
      },
      {
        "date": "2023-12-02T02:18:00.000Z",
        "voteCount": 1,
        "content": "Option C"
      },
      {
        "date": "2023-09-13T14:33:00.000Z",
        "voteCount": 1,
        "content": "are these questions still valid?"
      },
      {
        "date": "2023-01-12T20:48:00.000Z",
        "voteCount": 1,
        "content": "The best option for visualizing how often a cache miss happens over time would be C. Create a logs-based metric in Stackdriver Logging and a dashboard for that metric in Stackdriver Monitoring.\n\nStackdriver Logging provides the ability to extract metrics from logs, these metrics are called logs-based metrics. You can create a logs-based metric that counts the number of cache miss logs and configure it to be collected at a regular interval, this way you can see how often a cache miss happens over time. Additionally, Stackdriver Monitoring provides the ability to create dashboards that display the metrics collected by logs-based metrics, you can use this dashboard to visualize the cache misses over time and easily identify trends or spikes in the data."
      },
      {
        "date": "2022-12-25T00:30:00.000Z",
        "voteCount": 1,
        "content": "Ans: C\n\nExam passed and taken on 19/12/2022, 50/50 from this dump without buying the full access and looking for 'devops' word here: https://www.examtopics.com/discussions/google/1/"
      },
      {
        "date": "2022-07-25T03:30:00.000Z",
        "voteCount": 1,
        "content": "Answer is C"
      },
      {
        "date": "2022-05-09T09:56:00.000Z",
        "voteCount": 1,
        "content": "Submitted C"
      },
      {
        "date": "2022-01-29T06:10:00.000Z",
        "voteCount": 2,
        "content": "Answer C"
      },
      {
        "date": "2021-09-03T00:43:00.000Z",
        "voteCount": 4,
        "content": "C\nhttps://cloud.google.com/logging/docs/logs-based-metrics#counter-metric"
      },
      {
        "date": "2021-06-02T12:15:00.000Z",
        "voteCount": 1,
        "content": "D export to biguery as sink and analyse logs"
      },
      {
        "date": "2021-10-18T12:12:00.000Z",
        "voteCount": 2,
        "content": "and how would you visualize the data in bq?"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 37,
    "url": "https://www.examtopics.com/discussions/google/view/54283-exam-professional-cloud-devops-engineer-topic-1-question-37/",
    "body": "You need to deploy a new service to production. The service needs to automatically scale using a Managed Instance Group (MIG) and should be deployed over multiple regions. The service needs a large number of resources for each instance and you need to plan for capacity. What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse the n1-highcpu-96 machine type in the configuration of the MIG.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tMonitor results of Stackdriver Trace to determine the required amount of resources.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tValidate that the resource requirements are within the available quota limits of each region.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDeploy the service in one region and use a global load balancer to route traffic to this region."
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 14,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-06-28T21:52:00.000Z",
        "voteCount": 15,
        "content": "C 100%"
      },
      {
        "date": "2021-09-03T00:46:00.000Z",
        "voteCount": 12,
        "content": "C\nhttps://cloud.google.com/compute/quotas"
      },
      {
        "date": "2024-04-26T19:56:00.000Z",
        "voteCount": 1,
        "content": "Exam on 2024-04-26"
      },
      {
        "date": "2023-12-02T02:28:00.000Z",
        "voteCount": 2,
        "content": "option c"
      },
      {
        "date": "2023-08-30T10:43:00.000Z",
        "voteCount": 1,
        "content": "C 100%"
      },
      {
        "date": "2023-01-12T21:24:00.000Z",
        "voteCount": 2,
        "content": "C. Validate that the resource requirements are within the available quota limits of each region. It is important to ensure that the resource requirements are within the available quota limits in each region before deploying the service, to avoid exceeding the limits and causing problems. This is essential to ensure that the service is deployed correctly and has the necessary capacity to handle the load."
      },
      {
        "date": "2022-12-25T00:30:00.000Z",
        "voteCount": 1,
        "content": "Ans: C\n\nExam passed and taken on 19/12/2022, 50/50 from this dump without buying the full access and looking for 'devops' word here: https://www.examtopics.com/discussions/google/1/"
      },
      {
        "date": "2022-07-25T03:32:00.000Z",
        "voteCount": 1,
        "content": "Answer is C"
      },
      {
        "date": "2022-04-28T09:04:00.000Z",
        "voteCount": 2,
        "content": "Knowing available quota limits allows you to plan for capacity"
      },
      {
        "date": "2022-02-23T11:02:00.000Z",
        "voteCount": 1,
        "content": "You need to make sure of quota limit other things will be handled by MIG"
      },
      {
        "date": "2022-01-28T19:42:00.000Z",
        "voteCount": 1,
        "content": "C shud be the answer"
      },
      {
        "date": "2021-12-14T18:48:00.000Z",
        "voteCount": 2,
        "content": "Correct answer is C. this service is deployed into MIG and we only have to take care of quota"
      },
      {
        "date": "2021-12-13T02:00:00.000Z",
        "voteCount": 1,
        "content": "Answer is D \nNetworking and load balancing quotas are not regional quotes, those are global quotas. Any region can use a global quota. For example, in-use and static external IP addresses assigned to load balancers and HTTP(S) proxies consume global quotas.\nreference https://cloud.google.com/compute/quotas"
      },
      {
        "date": "2022-05-10T04:01:00.000Z",
        "voteCount": 1,
        "content": "D says \"one\" region, the solution is meant to be multi regional"
      },
      {
        "date": "2021-07-24T01:47:00.000Z",
        "voteCount": 3,
        "content": "absolutely C 'cause this service is deployed into MIG and you only have to take care of quota."
      },
      {
        "date": "2021-06-18T21:09:00.000Z",
        "voteCount": 4,
        "content": "C - it is asking for quota"
      },
      {
        "date": "2021-06-06T23:37:00.000Z",
        "voteCount": 4,
        "content": "I think C is the answer. \nhttps://cloud.google.com/compute/quotas#understanding_quotas\nhttps://cloud.google.com/compute/quotas"
      },
      {
        "date": "2021-06-07T11:51:00.000Z",
        "voteCount": 2,
        "content": "Agree for the answer : C"
      },
      {
        "date": "2021-06-02T12:21:00.000Z",
        "voteCount": 1,
        "content": "A can be the answer"
      },
      {
        "date": "2021-06-07T11:53:00.000Z",
        "voteCount": 1,
        "content": "you have to check the required resources available on those particular regions or not. As you know not all type of VM or a resource available in all regions. There is not surety that n1-highcpu-96 machine type available in all regions."
      },
      {
        "date": "2021-06-08T06:08:00.000Z",
        "voteCount": 4,
        "content": "And nobody is saying you need 96 CPU."
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 38,
    "url": "https://www.examtopics.com/discussions/google/view/54285-exam-professional-cloud-devops-engineer-topic-1-question-38/",
    "body": "You are running an application on Compute Engine and collecting logs through Stackdriver. You discover that some personally identifiable information (PII) is leaking into certain log entry fields. All PII entries begin with the text userinfo. You want to capture these log entries in a secure location for later review and prevent them from leaking to Stackdriver Logging. What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a basic log filter matching userinfo, and then configure a log export in the Stackdriver console with Cloud Storage as a sink.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse a Fluentd filter plugin with the Stackdriver Agent to remove log entries containing userinfo, and then copy the entries to a Cloud Storage bucket.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate an advanced log filter matching userinfo, configure a log export in the Stackdriver console with Cloud Storage as a sink, and then configure a log exclusion with userinfo as a filter.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse a Fluentd filter plugin with the Stackdriver Agent to remove log entries containing userinfo, create an advanced log filter matching userinfo, and then configure a log export in the Stackdriver console with Cloud Storage as a sink."
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 12,
        "isMostVoted": true
      },
      {
        "answer": "C",
        "count": 2,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2021-06-06T23:50:00.000Z",
        "voteCount": 19,
        "content": "looks like it is B. https://medium.com/google-cloud/fluentd-filter-plugin-for-google-cloud-data-loss-prevention-api-42bbb1308e76"
      },
      {
        "date": "2021-06-20T23:39:00.000Z",
        "voteCount": 5,
        "content": "B to me as well. Because fluentd can filter the logs quite nicely before passing information to Stackdriver. It can cober sensitive information such as credit card details, social security numbers, etc. Once the filtering is done, then the log can be passed to Cloud Storage, but the unfiltered information should not even reach stackdriver, so most of the answers are wrong."
      },
      {
        "date": "2021-06-07T12:00:00.000Z",
        "voteCount": 2,
        "content": "to me , looks B is the correct answer ."
      },
      {
        "date": "2021-06-08T06:14:00.000Z",
        "voteCount": 2,
        "content": "Why not D?"
      },
      {
        "date": "2021-06-26T20:45:00.000Z",
        "voteCount": 6,
        "content": "prevent them from leaking to Stackdriver Logging.\nIf you need to create a log export &amp; log filter so the information is leaking to logging."
      },
      {
        "date": "2021-11-10T19:03:00.000Z",
        "voteCount": 1,
        "content": "Agree with B"
      },
      {
        "date": "2023-12-06T03:03:00.000Z",
        "voteCount": 1,
        "content": "Not available any more."
      },
      {
        "date": "2021-06-23T20:41:00.000Z",
        "voteCount": 9,
        "content": "Im not pretty sure but \nAns B\nPrevent them form leaking to Stackdriver logging\nA: Incorrect, Leaking to Stackdriver\nB: Correct, not leaking to Stackdriver &amp; fluentD\nC: Incorrect, Leaking\nD: If we removed why we need to create a filter matching there will not be logs with userinfo?"
      },
      {
        "date": "2024-08-10T06:03:00.000Z",
        "voteCount": 1,
        "content": "Why not D?\nUse fluentd filter to remove logs with userinfo and export existing logs for review?"
      },
      {
        "date": "2023-12-02T02:35:00.000Z",
        "voteCount": 1,
        "content": "option b"
      },
      {
        "date": "2023-05-26T15:55:00.000Z",
        "voteCount": 1,
        "content": "A suggests creating a basic log filter and configuring a log export to Cloud Storage, but it does not address preventing the PII entries from leaking to Stackdriver Logging. By creating only a basic log filter, the PII data would still be accessible within Stackdriver Logging."
      },
      {
        "date": "2023-07-15T17:19:00.000Z",
        "voteCount": 1,
        "content": "are these questions still relevant? @jeffersonkozak"
      },
      {
        "date": "2023-01-12T21:30:00.000Z",
        "voteCount": 2,
        "content": "B. Use a Fluentd filter plugin with the Stackdriver Agent to remove log entries containing userinfo, and then copy the entries to a Cloud Storage bucket.\n\nBy using Fluentd filter plugin, you can remove log entries that contain PII information and configure it to send to a designated cloud storage bucket. This way you prevent the logs that contain PII from leaking to Stackdriver Logging, and have them stored in a secure location for later review."
      },
      {
        "date": "2022-12-31T00:54:00.000Z",
        "voteCount": 1,
        "content": "All A,C and D are leaking to stackdriver. So the ans has to be B"
      },
      {
        "date": "2022-12-25T00:30:00.000Z",
        "voteCount": 1,
        "content": "Ans: B\n\nExam passed and taken on 19/12/2022, 50/50 from this dump without buying the full access and looking for 'devops' word here: https://www.examtopics.com/discussions/google/1/"
      },
      {
        "date": "2022-12-17T09:58:00.000Z",
        "voteCount": 1,
        "content": "will go with B"
      },
      {
        "date": "2022-09-13T22:36:00.000Z",
        "voteCount": 3,
        "content": "Option B: https://cloud.google.com/logging/docs/agent/logging/configuration. Custom defined log entries has this structure \"[TAG_NAME]+Payload+timestamp+Severity+labels\". Here \"Userinfo\" is the TAG_NAME. Fluentd  filter plugins used to filter out logs based on TAG_NAME. finally this could be stored in Cloud storage."
      },
      {
        "date": "2022-07-25T03:33:00.000Z",
        "voteCount": 1,
        "content": "Answer is B"
      },
      {
        "date": "2022-07-07T03:40:00.000Z",
        "voteCount": 1,
        "content": "B is a poor answer IMHO because it seems to include a manual task of copying the PII data to the bucket at some later date (cron job or personal intervention, ugly either way).  https://cloud.google.com/logging/docs/routing/overview makes it quite clear that this should be taken care by routing and the exclusion filter which would imply that C is the correct answer.  \"Cloud logging\" is only one of the possible sink choices."
      },
      {
        "date": "2022-07-08T04:57:00.000Z",
        "voteCount": 1,
        "content": "Nevermind... I though B is ugly, if the PII data is removed with the fluentd filter, it will never arrive at the advanced filter."
      },
      {
        "date": "2021-12-27T01:10:00.000Z",
        "voteCount": 2,
        "content": "Ans B\nhttps://medium.com/google-cloud/fluentd-filter-plugin-for-google-cloud-data-loss-prevention-api-42bbb1308e76"
      },
      {
        "date": "2021-12-15T12:21:00.000Z",
        "voteCount": 1,
        "content": "Agree with B"
      },
      {
        "date": "2021-12-13T02:14:00.000Z",
        "voteCount": 4,
        "content": "A\nquestion is about capture logs entries in a secure location for later review, not removing the log sensitive data before store then in a secure location. so answer is A"
      },
      {
        "date": "2021-09-03T00:55:00.000Z",
        "voteCount": 3,
        "content": "B\nhttps://medium.com/google-cloud/fluentd-filter-plugin-for-google-cloud-data-loss-prevention-api-42bbb1308e76"
      },
      {
        "date": "2023-12-06T03:04:00.000Z",
        "voteCount": 1,
        "content": "The author deleted this Medium story."
      },
      {
        "date": "2021-07-13T13:21:00.000Z",
        "voteCount": 3,
        "content": "B. filter_record_transformer to be exact."
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 39,
    "url": "https://www.examtopics.com/discussions/google/view/54286-exam-professional-cloud-devops-engineer-topic-1-question-39/",
    "body": "You have a CI/CD pipeline that uses Cloud Build to build new Docker images and push them to Docker Hub. You use Git for code versioning. After making a change in the Cloud Build YAML configuration, you notice that no new artifacts are being built by the pipeline. You need to resolve the issue following Site<br>Reliability Engineering practices. What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDisable the CI pipeline and revert to manually building and pushing the artifacts.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tChange the CI pipeline to push the artifacts is Container Registry instead of Docker Hub.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUpload the configuration YAML file to Cloud Storage and use Error Reporting to identify and fix the issue.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRun a Git compare between the previous and current Cloud Build Configuration files to find and fix the bug.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 13,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-06-28T21:52:00.000Z",
        "voteCount": 21,
        "content": "D is correct"
      },
      {
        "date": "2021-06-18T21:32:00.000Z",
        "voteCount": 12,
        "content": "D - find out what's changed in the build spec"
      },
      {
        "date": "2024-05-12T00:18:00.000Z",
        "voteCount": 1,
        "content": "Option D - Figure out what was the recent change"
      },
      {
        "date": "2023-12-02T02:37:00.000Z",
        "voteCount": 2,
        "content": "Option D"
      },
      {
        "date": "2023-07-15T17:16:00.000Z",
        "voteCount": 2,
        "content": "are these questions relevant yet? with the new exam version launched in may"
      },
      {
        "date": "2023-01-12T21:32:00.000Z",
        "voteCount": 2,
        "content": "D. Run a Git compare between the previous and current Cloud Build Configuration files to find and fix the bug.\nThis option allow you to compare the previous and current Cloud Build Configuration files and find what has been changed and understand what could be causing the issue. After identifying the problem, you can fix it and ensure that the pipeline is working correctly again. This approach is based on the SRE practices of identifying and resolving issues quickly and effectively."
      },
      {
        "date": "2022-12-31T01:06:00.000Z",
        "voteCount": 2,
        "content": "D is correct.\nHonestly I couldn't relate this to any SRE practices. Anyone can give me a hints? I could deduce the answer though.\nA: It didn't mention anything urgent, so no need to mitigate in this ugly way.\nB: miss the point. It worked perfectly without CR, why change it?\nC: upload the yaml to CS won't identify the issue for you.\nD: this has to be correct. The question emphasize \"code versioning\" and \"change in the Cloud Build YAML\". We can easily identify the problem through comparison."
      },
      {
        "date": "2022-12-25T00:30:00.000Z",
        "voteCount": 2,
        "content": "Ans: D\n\nExam passed and taken on 19/12/2022, 50/50 from this dump without buying the full access and looking for 'devops' word here: https://www.examtopics.com/discussions/google/1/"
      },
      {
        "date": "2022-11-21T19:10:00.000Z",
        "voteCount": 1,
        "content": "D is correct"
      },
      {
        "date": "2022-07-25T03:35:00.000Z",
        "voteCount": 1,
        "content": "Answer is D"
      },
      {
        "date": "2022-06-07T07:44:00.000Z",
        "voteCount": 2,
        "content": "Guys, I'm wondering if we wouldn't solve the incident (A) before get the root cause(D)."
      },
      {
        "date": "2022-05-09T09:57:00.000Z",
        "voteCount": 2,
        "content": "Submitted D in the exam"
      },
      {
        "date": "2022-05-21T04:05:00.000Z",
        "voteCount": 2,
        "content": "How many questions are from this site for exam?"
      },
      {
        "date": "2022-01-29T06:35:00.000Z",
        "voteCount": 3,
        "content": "Would go with D"
      },
      {
        "date": "2021-12-13T02:32:00.000Z",
        "voteCount": 5,
        "content": "B is correct \nartifact can not push to Docker hub only docker images possible. therefore, need to push the artifacts to google cloud container registry not to the public docker hub. \nhttps://cloud.google.com/build/docs/interacting-with-dockerhub-images"
      },
      {
        "date": "2021-06-03T12:53:00.000Z",
        "voteCount": 5,
        "content": "I think D"
      },
      {
        "date": "2021-06-02T12:29:00.000Z",
        "voteCount": 1,
        "content": "B push images into container registry instead docker hub"
      },
      {
        "date": "2021-06-13T21:35:00.000Z",
        "voteCount": 9,
        "content": "\"After making a change in the Cloud Build YAML configuration, you notice that no new artifacts are being built by the pipeline\"-  means something wrong on the recent change not with the image registry.\n\ncorrect answer should be - D"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 40,
    "url": "https://www.examtopics.com/discussions/google/view/54287-exam-professional-cloud-devops-engineer-topic-1-question-40/",
    "body": "Your company follows Site Reliability Engineering principles. You are writing a postmortem for an incident, triggered by a software change, that severely affected users. You want to prevent severe incidents from happening in the future. What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tIdentify engineers responsible for the incident and escalate to their senior management.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEnsure that test cases that catch errors of this type are run successfully before new software releases.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tFollow up with the employees who reviewed the changes and prescribe practices they should follow in the future.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDesign a policy that will require on-call teams to immediately call engineers and management to discuss a plan of action if an incident occurs."
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 11,
        "isMostVoted": true
      },
      {
        "answer": "D",
        "count": 2,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2021-06-28T21:53:00.000Z",
        "voteCount": 26,
        "content": "B is correct"
      },
      {
        "date": "2021-08-12T20:53:00.000Z",
        "voteCount": 7,
        "content": "Agree with B. I find this answer in \"Site Reliability Engineering: How Google Runs Production Systems\"."
      },
      {
        "date": "2021-06-02T12:33:00.000Z",
        "voteCount": 10,
        "content": "B make automation better"
      },
      {
        "date": "2021-06-07T11:34:00.000Z",
        "voteCount": 7,
        "content": "Agree with you. IMO - B is the correct answer."
      },
      {
        "date": "2024-05-24T02:45:00.000Z",
        "voteCount": 1,
        "content": "B. Ensure that test cases that catch errors of this type are run successfully before new software releases.\n\nHere's why:\n\nOption A focuses on blaming individuals, which is not helpful in a postmortem. The goal is to learn from the incident and prevent future occurrences, not to assign fault.\nOption C is a good step, but it's not enough. While following up with reviewers is important, the primary focus should be on improving the testing process to catch errors before they reach production.\nOption D might be helpful in some cases, but it's not a general solution. Not all incidents require immediate escalation, and relying solely on on-call teams to make that decision can lead to unnecessary escalations."
      },
      {
        "date": "2024-05-24T02:45:00.000Z",
        "voteCount": 1,
        "content": "Option B addresses the root cause of the incident by ensuring that similar errors are caught during testing. This will help to prevent future incidents and improve the overall reliability of the system.\n\nHere are some additional steps you can take to prevent future incidents:\n\nImplement a strong continuous integration and continuous delivery (CI/CD) pipeline. This will help to automate the testing process and ensure that new code is tested thoroughly before it is deployed to production.\nUse a blameless postmortem process. This will encourage engineers to be open and honest about their mistakes, which will help to identify and fix problems more quickly.\nInvest in training and education for your engineers. This will help them to understand the importance of reliability and how to write code that is less prone to errors.\nBy taking these steps, you can help to prevent future incidents and improve the overall reliability of your system."
      },
      {
        "date": "2024-05-24T02:45:00.000Z",
        "voteCount": 1,
        "content": "Additional Considerations\nIt's important to note that there is no single solution that will prevent all incidents. However, by taking a proactive approach and focusing on improving your testing and development processes, you can significantly reduce the risk of future incidents.\n\nHere are some additional resources that you may find helpful:\n\nSite Reliability Engineering (SRE) Book: https://landing.google.com/sre/book.html \nGoogle Cloud Reliability Engineering: https://cloud.google.com/solutions/reliability-engineering \nPostmortem Best Practices: https://sre.google/sre-book/postmortems/"
      },
      {
        "date": "2024-05-12T00:20:00.000Z",
        "voteCount": 1,
        "content": "B - Blameless postmortem"
      },
      {
        "date": "2024-02-03T04:19:00.000Z",
        "voteCount": 1,
        "content": "The focus should be on improving processes and systems, not blaming individuals."
      },
      {
        "date": "2023-12-02T02:38:00.000Z",
        "voteCount": 1,
        "content": "Option B"
      },
      {
        "date": "2023-01-12T21:35:00.000Z",
        "voteCount": 1,
        "content": "B. Ensuring that test cases that catch errors of this type are run successfully before new software releases will help to prevent similar incidents from happening in the future."
      },
      {
        "date": "2022-12-31T01:09:00.000Z",
        "voteCount": 1,
        "content": "It is B. The main point here is \"trigged by software change\". This make B make sense and right to the point.\n\nD is not correct because it doesn't prevent this from happen again..."
      },
      {
        "date": "2022-12-25T00:31:00.000Z",
        "voteCount": 1,
        "content": "Ans: B\n\nExam passed and taken on 19/12/2022, 50/50 from this dump without buying the full access and looking for 'devops' word here: https://www.examtopics.com/discussions/google/1/"
      },
      {
        "date": "2022-07-25T03:38:00.000Z",
        "voteCount": 2,
        "content": "Answer is B"
      },
      {
        "date": "2022-04-23T00:11:00.000Z",
        "voteCount": 2,
        "content": "D is correct. B is too narrow"
      },
      {
        "date": "2022-02-12T09:19:00.000Z",
        "voteCount": 3,
        "content": "B - Blameless port-mortens. Focus on the process and not in the people."
      },
      {
        "date": "2022-01-28T19:49:00.000Z",
        "voteCount": 1,
        "content": "I will go with C here"
      },
      {
        "date": "2021-12-16T12:44:00.000Z",
        "voteCount": 1,
        "content": "I go for D based on the on-call doc"
      },
      {
        "date": "2021-12-14T02:37:00.000Z",
        "voteCount": 4,
        "content": "c is the correct answer"
      },
      {
        "date": "2021-11-26T17:18:00.000Z",
        "voteCount": 2,
        "content": "I would go with B as they are saying incident is triggered by a software change, if this has been tested thoroughly it would have been avoided."
      },
      {
        "date": "2021-09-07T23:46:00.000Z",
        "voteCount": 2,
        "content": "B is better over D because D is incident management, B is RCA."
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 41,
    "url": "https://www.examtopics.com/discussions/google/view/54763-exam-professional-cloud-devops-engineer-topic-1-question-41/",
    "body": "You support a high-traffic web application that runs on Google Cloud Platform (GCP). You need to measure application reliability from a user perspective without making any engineering changes to it. What should you do? (Choose two.)<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tReview current application metrics and add new ones as needed.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tModify the code to capture additional information for user interaction.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAnalyze the web proxy logs only and capture response time of each request.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate new synthetic clients to simulate a user journey using the application.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse current and historic Request Logs to trace customer interaction with the application.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "DE",
    "answerDescription": "",
    "votes": [
      {
        "answer": "DE",
        "count": 10,
        "isMostVoted": true
      },
      {
        "answer": "CE",
        "count": 5,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2021-06-18T21:34:00.000Z",
        "voteCount": 29,
        "content": "DE - synthetic transactions"
      },
      {
        "date": "2021-12-14T15:32:00.000Z",
        "voteCount": 3,
        "content": "A&amp;D.  Why E isnt correct - Synthetic transaction already provides the capability mentioned in E - \"Use current and historic Request Logs to trace customer interaction with the application\". Instead, option A - to review and add additional metrics makes sense !!"
      },
      {
        "date": "2022-07-11T07:31:00.000Z",
        "voteCount": 5,
        "content": "It says \"measure application reliability from a user perspective\" - you need synthetic measurements from outside the infrastructure (D). To simulate the synthetic journey mentioned, you first need to understand the current user behaviours using the 'request' logs (E)."
      },
      {
        "date": "2021-06-28T21:53:00.000Z",
        "voteCount": 12,
        "content": "CE ans"
      },
      {
        "date": "2021-09-16T02:19:00.000Z",
        "voteCount": 10,
        "content": "Web proxy is not a reverse proxy, it is a forward proxy - a type of server that runs at the client side. If you have clients from all over the world, how will you collect their proxy logs?\n\nSo it cannot be C - D&amp;E should be the answer which don't require any engineering changes \"in the\" application."
      },
      {
        "date": "2023-12-02T02:44:00.000Z",
        "voteCount": 1,
        "content": "Option C and E"
      },
      {
        "date": "2022-11-15T11:40:00.000Z",
        "voteCount": 4,
        "content": "A - Adding metrics doesn't necessarily reflect reliability from a user perspective'\nB - Modifying the code is against the requirement\nC - Analyzing proxy logs doesn't connect the findings to a user perspective\n\nFrom the request logs, user journeys can be recreated (E) and the replays can be fed to synthetic clients to simulate/replay (D)."
      },
      {
        "date": "2022-05-30T21:54:00.000Z",
        "voteCount": 5,
        "content": "1.Based on \" without making any engineering changes to it\" , exclude A,B at first.\n2. Based on following described, \nhttps://cloud.google.com/architecture/adopting-slos#choosing_a_measurement_method\n\nD &amp; E should be better."
      },
      {
        "date": "2022-06-25T04:08:00.000Z",
        "voteCount": 2,
        "content": "From  \"measure application reliability from a user perspective..\" comments\nD is closest I think"
      },
      {
        "date": "2022-04-16T19:00:00.000Z",
        "voteCount": 5,
        "content": "Answer: CE \n\nA. Review current application metrics and add new ones as needed.\n     ==&gt; (x) \"add new ones\" needs engineering changes\nB. Modify the code to capture additional information for user interaction.\n    ==&gt; (x) \"Modify the code\" needs engineering changes\nC. Analyze the web proxy logs only and capture response time of each request.\n  ==&gt; (O) no engineering changes\nD. Create new synthetic clients to simulate a user journey using the application.\n   =&gt; (x) \"Create new synthetic client\" needs engineering changes. \nE. Use current and historic Request Logs to trace customer interaction with the application. ==&gt; (O) no engineering changes"
      },
      {
        "date": "2022-02-13T01:24:00.000Z",
        "voteCount": 3,
        "content": "D &amp; E - Reliability review using synthetic transactions and customer journeys from logs."
      },
      {
        "date": "2022-01-02T10:04:00.000Z",
        "voteCount": 3,
        "content": "This two option doesn't require engineering changes into the application. Web Proxy logs is a forward proxy thing so it present in client side. others need changes"
      },
      {
        "date": "2021-12-22T03:28:00.000Z",
        "voteCount": 1,
        "content": "C&amp; E.\nC-&gt; a web proxy relays URL requests from clients to a server. Analyzing web proxy logs can give unobtrusive insights into the browsing behavior of  users"
      },
      {
        "date": "2021-12-18T05:13:00.000Z",
        "voteCount": 2,
        "content": "Selected Answer: DE"
      },
      {
        "date": "2021-12-06T21:27:00.000Z",
        "voteCount": 4,
        "content": "C and E should be the correct answer, since the question state that \"without making ANY engineering changes\""
      },
      {
        "date": "2021-12-17T03:54:00.000Z",
        "voteCount": 4,
        "content": "with making any engineering changes to IT (i.e the application itself)"
      },
      {
        "date": "2021-11-14T05:59:00.000Z",
        "voteCount": 4,
        "content": "A&amp;D should be the correct answer:\nD - Easy/default choice since this doesnt need any changes on the app\nA - Since the ask is to \"measure reliability\" - review and add the appropriate SLIs. Option E -tracing is needed only for collecting/troubleshooting latency issues - hence not the correct choice"
      },
      {
        "date": "2021-08-09T19:08:00.000Z",
        "voteCount": 4,
        "content": "To me , it looks C &amp; E\nB &amp; D, need engineering changes and investment, hence I ruled these two out\nThis leaves us with A,  C and E  - The question is asking for \"Need to measure Application Reliability from User perspective without Engineering Changes\"  - This rules out A, as talks about adding new metric but not stating which one\n\nConsidering high-traffic web application as \"Request Driven Services\" - Two of the suggested SLI's are Availability and Latency -  C &amp; E to me covers Latency\n\nhttps://cloud.google.com/architecture/adopting-slos?hl=en"
      },
      {
        "date": "2021-08-07T21:43:00.000Z",
        "voteCount": 2,
        "content": "A &amp; D is the answer"
      },
      {
        "date": "2021-07-26T06:36:00.000Z",
        "voteCount": 1,
        "content": "maybe C,D,E, and it looks like create synthetic client looks like \"engineering change\", so I choose C and E ."
      },
      {
        "date": "2021-07-29T19:04:00.000Z",
        "voteCount": 2,
        "content": "umm but\n&gt; C. Analyze the web proxy logs 'only' and\nthe phrase 'only' bothers me...\nwe can know the reliability by getting the status of web applications by web proxy logs(I mean HTTP status is good/bad), but we don't need to view these logs 'only'..."
      },
      {
        "date": "2021-08-07T21:44:00.000Z",
        "voteCount": 4,
        "content": "C cant be the ans , as it talks about response time. we need answer for reliability"
      },
      {
        "date": "2021-09-11T09:00:00.000Z",
        "voteCount": 2,
        "content": "Create synthetic client is not an engineering change for the application : the application is not modified. So the answer is still valid."
      },
      {
        "date": "2021-06-07T11:39:00.000Z",
        "voteCount": 5,
        "content": "for me it looks like C,E the correct answer. E for sure."
      },
      {
        "date": "2021-06-20T23:55:00.000Z",
        "voteCount": 2,
        "content": "Same here, because no engineering effort should be required. All others definitely need engineering effort."
      },
      {
        "date": "2021-06-07T00:12:00.000Z",
        "voteCount": 2,
        "content": "may be A&amp;E as these options may not need any additional engineering efforts"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 42,
    "url": "https://www.examtopics.com/discussions/google/view/54764-exam-professional-cloud-devops-engineer-topic-1-question-42/",
    "body": "You manage an application that is writing logs to Stackdriver Logging. You need to give some team members the ability to export logs. What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tGrant the team members the IAM role of logging.configWriter on Cloud IAM.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure Access Context Manager to allow only these members to export logs.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate and grant a custom IAM role with the permissions logging.sinks.list and logging.sink.get.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate an Organizational Policy in Cloud IAM to allow only these members to create log exports."
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 8,
        "isMostVoted": true
      },
      {
        "answer": "C",
        "count": 2,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2021-06-07T00:12:00.000Z",
        "voteCount": 26,
        "content": "option A"
      },
      {
        "date": "2021-06-07T11:43:00.000Z",
        "voteCount": 5,
        "content": "agree for the A."
      },
      {
        "date": "2021-11-19T09:39:00.000Z",
        "voteCount": 6,
        "content": "I understand that option A gives the ability to export logs, but isn't C the best option following the least privilege principle since the question only says that the team members needs to export logs and not to write them?"
      },
      {
        "date": "2021-11-10T19:30:00.000Z",
        "voteCount": 7,
        "content": "It's should be C. least privilege\n\nThe question is ask about export log and does not mention about read and write log \nOption A give too many permission\nLogs Configuration Writer\n(roles/logging.configWriter)\nProvides permissions to read and write the configurations of logs-based metrics and sinks for exporting logs.\n\nlogging.buckets.create\nlogging.buckets.delete\nlogging.buckets.get\nlogging.buckets.list\nlogging.buckets.undelete\nlogging.buckets.update\nlogging.cmekSettings.*\nlogging.exclusions.*\nlogging.locations.*\nlogging.logMetrics.*\nlogging.logServiceIndexes.*\nlogging.logServices.*\nlogging.logs.list\nlogging.notificationRules.*\nlogging.operations.*\nlogging.sinks.*\nlogging.views.create\nlogging.views.delete\nlogging.views.get\nlogging.views.list\nlogging.views.update\nresourcemanager.projects.get\nresourcemanager.projects.list"
      },
      {
        "date": "2022-11-30T20:08:00.000Z",
        "voteCount": 1,
        "content": "ability to use sinks\tAdd logging.sinks.{list, create, get, update, delete} , the list, get function can only have view permission. can not create sinks to export logs. u need create sink to export logs."
      },
      {
        "date": "2021-11-10T19:38:00.000Z",
        "voteCount": 2,
        "content": "After review again, Ans A had enough permission to export log https://cloud.google.com/logging/docs/routing/overview"
      },
      {
        "date": "2021-12-11T11:30:00.000Z",
        "voteCount": 11,
        "content": "logging.sinks.create is needed to export logs - this is why C is wrong"
      },
      {
        "date": "2023-12-02T02:59:00.000Z",
        "voteCount": 1,
        "content": "option C"
      },
      {
        "date": "2023-01-14T15:35:00.000Z",
        "voteCount": 1,
        "content": "A is correct, although it has wide permissions, but option C have missing other granular permissions for exporting logs, like logging, sinks, create"
      },
      {
        "date": "2022-12-25T00:12:00.000Z",
        "voteCount": 1,
        "content": "correct ans is A\nLogs Configuration Writer \n(roles/logging.configWriter)\n\nProvides permissions to read and write the configurations of logs-based metrics and sinks for exporting logs."
      },
      {
        "date": "2022-05-09T09:58:00.000Z",
        "voteCount": 1,
        "content": "Option A"
      },
      {
        "date": "2022-04-22T05:48:00.000Z",
        "voteCount": 3,
        "content": "There is no such thing called  logging.sink.get"
      },
      {
        "date": "2022-03-29T01:10:00.000Z",
        "voteCount": 1,
        "content": "roles/logging.configWriter (Logs Configuration Writer) gives you the permissions to create log-based metrics, exclusions, buckets, and views, and to use sinks. To use the Logs Explorer (console) for these actions, add roles/logging.viewer."
      },
      {
        "date": "2022-03-09T08:16:00.000Z",
        "voteCount": 1,
        "content": "A \nLogs configuration writer  can access to configure log exporting and metrics"
      },
      {
        "date": "2022-03-08T05:52:00.000Z",
        "voteCount": 1,
        "content": "What is the minimum set of privs in order to export logs?"
      },
      {
        "date": "2022-02-21T07:39:00.000Z",
        "voteCount": 1,
        "content": "in addition to other comments here, C would be too restrictive. User new to have logs list permissions at least to know which logs to export.\nGoram113 also indicate that logging.sinks.create is needed to export logs hence why C is wrong"
      },
      {
        "date": "2022-02-13T01:26:00.000Z",
        "voteCount": 1,
        "content": "C - Use principle of minimum access required to fulfill the requirements"
      },
      {
        "date": "2022-01-29T09:20:00.000Z",
        "voteCount": 1,
        "content": "Agree with A"
      },
      {
        "date": "2022-01-02T10:15:00.000Z",
        "voteCount": 3,
        "content": "https://cloud.google.com/logging/docs/export/configure_export_v2#before-you-begin A is the answer"
      },
      {
        "date": "2021-12-17T13:18:00.000Z",
        "voteCount": 4,
        "content": "Write answer is A as stated in the documentation here \n\nhttps://cloud.google.com/logging/docs/export/configure_export_v2#before-you-begin\n\n\"Note that this guide describes creating and managing sinks at the Cloud project level, but you can create sinks (non-aggregated) for billing accounts, folders, and organizations. As you get started, ensure the following:\n\nYou have a Google Cloud project with logs that you can see in the Logs Explorer.\n\nYou have one of the following IAM roles for the source Cloud project from which you're routing logs.\n\nOwner (roles/owner)\nLogging Admin (roles/logging.admin)\nLogs Configuration Writer (roles/logging.configWriter)\nThe permissions contained in these roles allow you to create, delete, or modify sinks. For information on setting IAM roles, see the Logging Access control guide.\""
      },
      {
        "date": "2021-10-29T07:25:00.000Z",
        "voteCount": 3,
        "content": "but C could follow the least privilege priciple"
      },
      {
        "date": "2021-11-03T06:09:00.000Z",
        "voteCount": 1,
        "content": "I agree. logging.configWriter (answer A) gives too much power to the team members. We only need to give them the rights to export, not change the whole logging configuration.\nC is ok."
      },
      {
        "date": "2021-09-30T12:16:00.000Z",
        "voteCount": 4,
        "content": "A is correct\n\nLogs Configuration Writer\n(roles/logging.configWriter)\n- Provides permissions to read and write the configurations of logs-based metrics and sinks for exporting logs.\nhttps://cloud.google.com/logging/docs/access-control"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 43,
    "url": "https://www.examtopics.com/discussions/google/view/54765-exam-professional-cloud-devops-engineer-topic-1-question-43/",
    "body": "Your application services run in Google Kubernetes Engine (GKE). You want to make sure that only images from your centrally-managed Google Container<br>Registry (GCR) image registry in the altostrat-images project can be deployed to the cluster while minimizing development time. What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a custom builder for Cloud Build that will only push images to gcr.io/altostrat-images.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse a Binary Authorization policy that includes the whitelist name pattern gcr.io/altostrat-images/.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAdd logic to the deployment pipeline to check that all manifests contain only images from gcr.io/altostrat-images.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAdd a tag to each image in gcr.io/altostrat-images and check that this tag is present when the image is deployed."
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 11,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-06-07T00:12:00.000Z",
        "voteCount": 25,
        "content": "option B"
      },
      {
        "date": "2021-06-13T21:49:00.000Z",
        "voteCount": 5,
        "content": "agree for answer-B"
      },
      {
        "date": "2021-06-28T21:53:00.000Z",
        "voteCount": 12,
        "content": "B is correct"
      },
      {
        "date": "2024-02-03T04:43:00.000Z",
        "voteCount": 1,
        "content": "https://cloud.google.com/binary-authorization/docs/key-concepts#allowlist_patterns"
      },
      {
        "date": "2023-12-02T03:01:00.000Z",
        "voteCount": 2,
        "content": "Option B"
      },
      {
        "date": "2023-07-02T04:30:00.000Z",
        "voteCount": 1,
        "content": "D.\nSee admissionWhitelistPatterns in: \nhttps://cloud.google.com/binary-authorization/docs/example-policies#add_exempt_images"
      },
      {
        "date": "2023-07-02T04:30:00.000Z",
        "voteCount": 1,
        "content": "Should be B not D."
      },
      {
        "date": "2023-07-15T17:28:00.000Z",
        "voteCount": 1,
        "content": "are these questions still valid?"
      },
      {
        "date": "2022-07-07T00:31:00.000Z",
        "voteCount": 2,
        "content": "See https://cloud.google.com/binary-authorization/docs/example-policies"
      },
      {
        "date": "2022-05-09T09:59:00.000Z",
        "voteCount": 2,
        "content": "B is the answer"
      },
      {
        "date": "2022-02-12T09:29:00.000Z",
        "voteCount": 2,
        "content": "B - Binary authorisation is the answer\u2026"
      },
      {
        "date": "2022-01-29T09:23:00.000Z",
        "voteCount": 1,
        "content": "Answer B - Binary Authorization"
      },
      {
        "date": "2021-12-10T03:27:00.000Z",
        "voteCount": 3,
        "content": "D \nhttps://cloud.google.com/container-registry/docs/using-with-google-cloud-platform"
      },
      {
        "date": "2021-10-19T00:24:00.000Z",
        "voteCount": 4,
        "content": "B)\nhttps://cloud.google.com/binary-authorization/docs/cloud-build"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 44,
    "url": "https://www.examtopics.com/discussions/google/view/54766-exam-professional-cloud-devops-engineer-topic-1-question-44/",
    "body": "Your team has recently deployed an NGINX-based application into Google Kubernetes Engine (GKE) and has exposed it to the public via an HTTP Google Cloud<br>Load Balancer (GCLB) ingress. You want to scale the deployment of the application's frontend using an appropriate Service Level Indicator (SLI). What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure the horizontal pod autoscaler to use the average response time from the Liveness and Readiness probes.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure the vertical pod autoscaler in GKE and enable the cluster autoscaler to scale the cluster as pods expand.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tInstall the Stackdriver custom metrics adapter and configure a horizontal pod autoscaler to use the number of requests provided by the GCLB.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tExpose the NGINX stats endpoint and configure the horizontal pod autoscaler to use the request metrics exposed by the NGINX deployment."
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 10,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-06-28T21:54:00.000Z",
        "voteCount": 13,
        "content": "Option C"
      },
      {
        "date": "2021-07-26T07:07:00.000Z",
        "voteCount": 13,
        "content": "C is correct\n\nA. Configure the horizontal pod autoscaler to use the average response time from the Liveness and Readiness Probes.\n--&gt; using health check as a trigger of scaling is weird. if the response time of the health check is delayed, it may be caused by resources issues such as CPU, memories, and so on. so you should use such values as SLIs.\n\nB. Configure the vertical pod autoscaler in GKE and enable the cluster autoscaler to scale the cluster as pods expand.\n--&gt; it doesn't referred to pod autoscaling.\n\nD. Expose the NGINX stats endpoint and configure the horizontal pod autoscaler to use the request metrics exposed by the NGINX deployment.\n--&gt; if you use request metrics as SLIs, you should use custom metrics as SLIs. it is a little bit redundant."
      },
      {
        "date": "2023-12-02T03:02:00.000Z",
        "voteCount": 1,
        "content": "option C"
      },
      {
        "date": "2023-03-17T06:10:00.000Z",
        "voteCount": 3,
        "content": "C. Install the Stackdriver custom metrics adapter and configure a horizontal pod autoscaler to use the number of requests provided by the GCLB.\n\nTo scale the deployment of the application's frontend using an appropriate Service Level Indicator (SLI), we need to monitor the traffic coming to the application. One way to do this is to install the Stackdriver custom metrics adapter, which provides visibility into GCLB metrics such as request counts, bytes sent and received, and active connections. We can then configure a horizontal pod autoscaler (HPA) to scale the number of pods based on the request count coming through the GCLB, which will help to ensure that our application is always available to handle the incoming traffic."
      },
      {
        "date": "2022-10-24T08:29:00.000Z",
        "voteCount": 1,
        "content": "C is the answer."
      },
      {
        "date": "2022-10-23T22:38:00.000Z",
        "voteCount": 1,
        "content": "I will go with C"
      },
      {
        "date": "2022-09-20T20:16:00.000Z",
        "voteCount": 2,
        "content": "C is the correct answer as per Google documentation"
      },
      {
        "date": "2022-05-26T00:19:00.000Z",
        "voteCount": 1,
        "content": "C is correct"
      },
      {
        "date": "2022-01-17T04:36:00.000Z",
        "voteCount": 2,
        "content": "Option B is incorrect because there will be no benefit in vertically scaling the front end if the requests are very high. Because in that case the network is the bottleneck and not the instance resources. In my opinion the Answer is C."
      },
      {
        "date": "2022-01-03T00:46:00.000Z",
        "voteCount": 1,
        "content": "c looks more feasible to me. but also B is in small favour.  Horizontal pod autoscaler will scale based on the custom metrics such as requests per second(i.e. no. of requests). but vertical autoscaling is also useful feature for the frontend application. as it requires more resource needs if the traffic is high. Since vertical autoscaling will first delete the pod and adjust the cpu and memory to recreate the pod, It can cause downtime for that duration and not recommended. Hence, More inclined towards answer C. Still, reply my answer with your explanation please\n\n https://cloud.google.com/kubernetes-engine/docs/concepts/horizontalpodautoscaler#overview"
      },
      {
        "date": "2021-12-13T03:49:00.000Z",
        "voteCount": 3,
        "content": "B is correct \nfront-end web applications Scale based on the number of incoming request. so need vertical scaling \nBack-end Batch Processing (Scale Horizontally)\nreference https://docs.rightscale.com/faq/What_is_auto-scaling.html"
      },
      {
        "date": "2021-09-03T01:15:00.000Z",
        "voteCount": 2,
        "content": "C\nhttps://cloud.google.com/kubernetes-engine/docs/tutorials/autoscaling-metrics"
      },
      {
        "date": "2021-07-28T17:51:00.000Z",
        "voteCount": 2,
        "content": "According to Google \nhttps://cloud.google.com/kubernetes-engine/docs/tutorials/autoscaling-metrics#cpu_1\nHorizontal Pod Autoscalers can scale based on CPU utilization natively, so the Custom Metrics Adapter is not needed, therefor C doesn't fit ."
      },
      {
        "date": "2021-09-11T09:09:00.000Z",
        "voteCount": 5,
        "content": "It is why the C answer say number of requests not CPU utilization."
      },
      {
        "date": "2021-06-18T22:06:00.000Z",
        "voteCount": 4,
        "content": "C - https://cloud.google.com/kubernetes-engine/docs/tutorials/autoscaling-metrics\nYou want to scale horizontally"
      },
      {
        "date": "2021-06-07T00:13:00.000Z",
        "voteCount": 1,
        "content": "Option B"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 45,
    "url": "https://www.examtopics.com/discussions/google/view/54891-exam-professional-cloud-devops-engineer-topic-1-question-45/",
    "body": "Your company follows Site Reliability Engineering practices. You are the Incident Commander for a new, customer-impacting incident. You need to immediately assign two incident management roles to assist you in an effective incident response. What roles should you assign? (Choose two.)<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tOperations Lead\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEngineering Lead",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCommunications Lead\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCustomer Impact Assessor",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tExternal Customer Communications Lead"
    ],
    "answer": "AC",
    "answerDescription": "",
    "votes": [
      {
        "answer": "AC",
        "count": 7,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-06-08T07:24:00.000Z",
        "voteCount": 33,
        "content": "AC\n\nhttps://sre.google/workbook/incident-response/\n\"The main roles in incident response are the Incident Commander (IC), Communications Lead (CL), and Operations or Ops Lead (OL).\""
      },
      {
        "date": "2021-06-13T22:11:00.000Z",
        "voteCount": 2,
        "content": "could be. A and C.\n\nwhy not E? this is customer impacting incident so should be an external customer comm lead as well."
      },
      {
        "date": "2021-06-28T21:54:00.000Z",
        "voteCount": 13,
        "content": "AC for sure"
      },
      {
        "date": "2023-12-02T03:04:00.000Z",
        "voteCount": 1,
        "content": "option A and C"
      },
      {
        "date": "2023-11-13T08:03:00.000Z",
        "voteCount": 1,
        "content": "AC\nMain Roles in Incident Response"
      },
      {
        "date": "2022-10-24T05:26:00.000Z",
        "voteCount": 1,
        "content": "A,C is right\nThe main roles in incident response are the Incident Commander (IC), Communications Lead (CL), and Operations or Ops Lead (OL). IMAG organizes these roles into a hierarchy: the IC leads the incident response, and the CL and OL report to the IC."
      },
      {
        "date": "2022-09-20T20:17:00.000Z",
        "voteCount": 1,
        "content": "AC, been there many times in real situations"
      },
      {
        "date": "2022-02-13T01:39:00.000Z",
        "voteCount": 2,
        "content": "A - Operations lead: fixes the issue\nC - Communications lead: keeps stakeholders informed"
      },
      {
        "date": "2022-01-29T09:43:00.000Z",
        "voteCount": 1,
        "content": "Answer A &amp; C as per Google SRE"
      },
      {
        "date": "2022-01-03T00:48:00.000Z",
        "voteCount": 1,
        "content": "It's mentioned in sre book by Google."
      },
      {
        "date": "2021-11-14T06:26:00.000Z",
        "voteCount": 2,
        "content": "Who gave AE as the correct answer ? why not this tool display/reveal the correct answer from the \"Highly Voted\" from the discussion thread for each Q?"
      },
      {
        "date": "2021-10-24T03:21:00.000Z",
        "voteCount": 3,
        "content": "A, C - other roles are appropriate .."
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 46,
    "url": "https://www.examtopics.com/discussions/google/view/54447-exam-professional-cloud-devops-engineer-topic-1-question-46/",
    "body": "You support an application running on GCP and want to configure SMS notifications to your team for the most critical alerts in Stackdriver Monitoring. You have already identified the alerting policies you want to configure this for. What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDownload and configure a third-party integration between Stackdriver Monitoring and an SMS gateway. Ensure that your team members add their SMS/phone numbers to the external tool.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSelect the Webhook notifications option for each alerting policy, and configure it to use a third-party integration tool. Ensure that your team members add their SMS/phone numbers to the external tool.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEnsure that your team members set their SMS/phone numbers in their Stackdriver Profile. Select the SMS notification option for each alerting policy and then select the appropriate SMS/phone numbers from the list.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure a Slack notification for each alerting policy. Set up a Slack-to-SMS integration to send SMS messages when Slack messages are received. Ensure that your team members add their SMS/phone numbers to the external integration."
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 13,
        "isMostVoted": true
      },
      {
        "answer": "D",
        "count": 4,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2021-07-27T06:08:00.000Z",
        "voteCount": 17,
        "content": "C\n\nhttps://cloud.google.com/monitoring/support/notification-options#creating_channels\nTo configure SMS notifications, do the following:\n\nIn the SMS section, click Add new and follow the instructions.\nClick Save.\nWhen you set up your alerting policy, select the SMS notification type and choose a verified phone number from the list."
      },
      {
        "date": "2021-06-03T13:35:00.000Z",
        "voteCount": 11,
        "content": "I think C"
      },
      {
        "date": "2021-06-13T22:40:00.000Z",
        "voteCount": 7,
        "content": "Agree. C looks more close from other given answer."
      },
      {
        "date": "2024-02-03T05:39:00.000Z",
        "voteCount": 1,
        "content": "Stackdriver (now Operations Suite) natively supports SMS notification channel, so going through external tool route or slack route is not cloud native approach. \nhttps://cloud.google.com/monitoring/support/notification-options#sms"
      },
      {
        "date": "2023-12-02T03:05:00.000Z",
        "voteCount": 1,
        "content": "option C"
      },
      {
        "date": "2023-05-29T14:36:00.000Z",
        "voteCount": 2,
        "content": "Option C suggests ensuring that team members set their SMS/phone numbers in their Stackdriver Profile. This approach is the simplest and most straightforward of the options presented. It requires no additional integration or configuration, and team members can easily manage their contact information in their Stackdriver profile. However, it does require team members to have access to and familiarity with Stackdriver, which may not be the case for all members of the team."
      },
      {
        "date": "2024-03-07T09:16:00.000Z",
        "voteCount": 1,
        "content": "Same argument goes for Slack integration as well. Team members needs to setup Slack access, channel, etc. And it seems redundant also. Final goal is to send alert message using SMS, which Google Cloud has in-build support."
      },
      {
        "date": "2022-10-25T22:59:00.000Z",
        "voteCount": 3,
        "content": "Had this question on exam 25.10.2022 and originally it says:\nC. Ensure that your team members set their SMS/phone numbers in their Cloud Monitoring. Select the SMS notification option for each alerting policy and then select the appropriate SMS/phone numbers from the list.\n\nHence definitely C is the answer"
      },
      {
        "date": "2022-05-09T10:00:00.000Z",
        "voteCount": 2,
        "content": "Submit C"
      },
      {
        "date": "2022-02-13T01:42:00.000Z",
        "voteCount": 3,
        "content": "C - Google Cloud Monitoring (previously known as Stackdriver) supports SMS notifications"
      },
      {
        "date": "2022-01-28T21:09:00.000Z",
        "voteCount": 2,
        "content": "I dont know if there is something called -  Stackdriver Profile .\nThe SMS can be configured in notification channel. But I dont see that in the options, hence the correct answer should be D"
      },
      {
        "date": "2022-05-04T06:05:00.000Z",
        "voteCount": 2,
        "content": "Yes, I also don't think there is anything such as stackdriver profile."
      },
      {
        "date": "2022-01-03T00:53:00.000Z",
        "voteCount": 1,
        "content": "Although stackdriver profile is not an named option in gcp. It looks like that to add phone no in stackdriver. so pretty straigtforward right answer is C"
      },
      {
        "date": "2021-12-13T04:34:00.000Z",
        "voteCount": 3,
        "content": "i think answer is D\nThere is no Stackdriver Profile exists to add their phone number. only possible to add the phone number in the notification channel under sms category"
      },
      {
        "date": "2021-11-30T05:29:00.000Z",
        "voteCount": 2,
        "content": "is option C"
      },
      {
        "date": "2021-09-03T01:19:00.000Z",
        "voteCount": 6,
        "content": "C\nhttps://cloud.google.com/monitoring/support/notification-options"
      },
      {
        "date": "2021-06-28T21:54:00.000Z",
        "voteCount": 7,
        "content": "C option"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 47,
    "url": "https://www.examtopics.com/discussions/google/view/54448-exam-professional-cloud-devops-engineer-topic-1-question-47/",
    "body": "You are managing an application that exposes an HTTP endpoint without using a load balancer. The latency of the HTTP responses is important for the user experience. You want to understand what HTTP latencies all of your users are experiencing. You use Stackdriver Monitoring. What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\u05d2\u20ac\u00a2 In your application, create a metric with a metricKind set to DELTA and a valueType set to DOUBLE. \u05d2\u20ac\u00a2 In Stackdriver's Metrics Explorer, use a Stacked Bar graph to visualize the metric.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\u05d2\u20ac\u00a2 In your application, create a metric with a metricKind set to CUMULATIVE and a valueType set to DOUBLE. \u05d2\u20ac\u00a2 In Stackdriver's Metrics Explorer, use a Line graph to visualize the metric.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\u05d2\u20ac\u00a2 In your application, create a metric with a metricKind set to GAUGE and a valueType set to DISTRIBUTION. \u05d2\u20ac\u00a2 In Stackdriver's Metrics Explorer, use a Heatmap graph to visualize the metric.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\u05d2\u20ac\u00a2 In your application, create a metric with a metricKind set to METRIC_KIND_UNSPECIFIED and a valueType set to INT64. \u05d2\u20ac\u00a2 In Stackdriver's Metrics Explorer, use a Stacked Area graph to visualize the metric."
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 8,
        "isMostVoted": true
      },
      {
        "answer": "A",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2021-08-09T18:36:00.000Z",
        "voteCount": 23,
        "content": "Answer C\nReference : https://cloud.google.com/monitoring/api/v3/kinds-and-types?hl=en\nGAUGE Metric : In which value measures a specific instant in time\nDELTA Metric : In which the value measures the change since it was last recorded\nCUMULATIVE metric : In which the value constantly increases over time\n\nQuestion asks, \"Latency of HTTP responses\"  - This needs to be specific instant in time , which is GAUGE, hence C"
      },
      {
        "date": "2021-06-28T21:54:00.000Z",
        "voteCount": 11,
        "content": "C is correct"
      },
      {
        "date": "2024-02-03T05:44:00.000Z",
        "voteCount": 1,
        "content": "GAUGE metrics record a value at a particular point in time and DISTRIBUTION captures distribution statistics. A Heatmap is a good way to visualize latencies across all users.\nhttps://cloud.google.com/monitoring/api/v3/kinds-and-types?hl=en#metric-kinds"
      },
      {
        "date": "2023-12-02T03:09:00.000Z",
        "voteCount": 1,
        "content": "option c"
      },
      {
        "date": "2023-05-29T14:48:00.000Z",
        "voteCount": 1,
        "content": "C is partially correct, GAUGE with DISTRIBUTUION, but  \"use a Heatmap graph to visualize the metric\" will not help to visualiaze the Latencies of all users, will help to identify regions, but it;s not a question"
      },
      {
        "date": "2022-10-24T05:39:00.000Z",
        "voteCount": 1,
        "content": "C is right as per GCP documentation.\nA gauge metric, in which the value measures a specific instant in time. For example, metrics measuring CPU utilization are gauge metrics; each point records the CPU utilization at the time of measurement. Another example of a gauge metric is the current temperature."
      },
      {
        "date": "2022-05-09T10:00:00.000Z",
        "voteCount": 2,
        "content": "Submitted C"
      },
      {
        "date": "2022-02-13T01:45:00.000Z",
        "voteCount": 2,
        "content": "C - Gauge to see latency distribution"
      },
      {
        "date": "2022-01-03T00:58:00.000Z",
        "voteCount": 2,
        "content": "It's guage metric as it is asking latency of http responses."
      },
      {
        "date": "2021-06-25T09:56:00.000Z",
        "voteCount": 9,
        "content": "Ans C:\n\nA: Incorrect: Stacked bar could be but latency its used with distributions\nB: Incorrect: If we used a cumulative the latency would be increasing in the graph.\nC: Correct: Latency is commonly measured as a distribution. \nD: Incorrect: METRIC_KIND_UNSPECIFIED is not the answer that gcp wanted.\n\nLatency is commonly measured as a distribution. Given a distribution, you can measure various percentiles. For example, you might measure the number of requests that are slower than the historical 99th percentile.\n\nLatency\nhistogram_quantile(0.9, rate(http_request_duration_seconds_bucket[7d])\nhistogram_quantile(0.99, rate(http_request_duration_seconds_bucket[7d]))\n\nhttps://sre.google/workbook/implementing-slos/\nhttps://cloud.google.com/architecture/adopting-slos/"
      },
      {
        "date": "2021-06-18T22:25:00.000Z",
        "voteCount": 1,
        "content": "Option B"
      },
      {
        "date": "2021-06-23T00:22:00.000Z",
        "voteCount": 5,
        "content": "Absolutely not. Cumulative means a growing graph, whose latency values \u200b\u200badd up to the previous ones, and it doesn't make sense. It's C for sure."
      },
      {
        "date": "2021-06-07T00:14:00.000Z",
        "voteCount": 5,
        "content": "Option C"
      },
      {
        "date": "2021-06-03T13:36:00.000Z",
        "voteCount": 3,
        "content": "I think C"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 48,
    "url": "https://www.examtopics.com/discussions/google/view/54769-exam-professional-cloud-devops-engineer-topic-1-question-48/",
    "body": "Your team is designing a new application for deployment both inside and outside Google Cloud Platform (GCP). You need to collect detailed metrics such as system resource utilization. You want to use centralized GCP services while minimizing the amount of work required to set up this collection system. What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tImport the Stackdriver Profiler package, and configure it to relay function timing data to Stackdriver for further analysis.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tImport the Stackdriver Debugger package, and configure the application to emit debug messages with timing information.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tInstrument the code using a timing library, and publish the metrics via a health check endpoint that is scraped by Stackdriver.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tInstall an Application Performance Monitoring (APM) tool in both locations, and configure an export to a central data storage location for analysis."
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 12,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-06-28T21:55:00.000Z",
        "voteCount": 23,
        "content": "Answer A"
      },
      {
        "date": "2021-06-07T00:15:00.000Z",
        "voteCount": 8,
        "content": "may be A, as profiler works both inside and outside of GCP."
      },
      {
        "date": "2021-06-07T05:02:00.000Z",
        "voteCount": 3,
        "content": "I agree. A is the right answer."
      },
      {
        "date": "2024-02-03T05:48:00.000Z",
        "voteCount": 1,
        "content": "https://cloud.google.com/profiler/docs/profiling-external"
      },
      {
        "date": "2023-12-02T03:11:00.000Z",
        "voteCount": 1,
        "content": "option A"
      },
      {
        "date": "2022-10-23T08:34:00.000Z",
        "voteCount": 3,
        "content": "A is the answer.\n\nhttps://cloud.google.com/profiler/docs/about-profiler\nCloud Profiler is a statistical, low-overhead profiler that continuously gathers CPU usage and memory-allocation information from your production applications."
      },
      {
        "date": "2022-02-13T01:49:00.000Z",
        "voteCount": 2,
        "content": "A - Profiler for resource utilisation."
      },
      {
        "date": "2022-01-28T21:24:00.000Z",
        "voteCount": 2,
        "content": "Answer should be A"
      },
      {
        "date": "2022-01-03T01:00:00.000Z",
        "voteCount": 3,
        "content": "Profiler can be used outside GCP also it is used to measure cpu utilization by the application."
      },
      {
        "date": "2021-06-18T22:26:00.000Z",
        "voteCount": 4,
        "content": "It is A"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 49,
    "url": "https://www.examtopics.com/discussions/google/view/55256-exam-professional-cloud-devops-engineer-topic-1-question-49/",
    "body": "You need to reduce the cost of virtual machines (VM) for your organization. After reviewing different options, you decide to leverage preemptible VM instances.<br>Which application is suitable for preemptible VMs?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tA scalable in-memory caching system.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tThe organization's public-facing website.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tA distributed, eventually consistent NoSQL database cluster with sufficient quorum.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tA GPU-accelerated video rendering platform that retrieves and stores videos in a storage bucket."
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 10,
        "isMostVoted": true
      },
      {
        "answer": "D",
        "count": 9,
        "isMostVoted": false
      },
      {
        "answer": "C",
        "count": 3,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2021-06-28T21:55:00.000Z",
        "voteCount": 16,
        "content": "D is correct"
      },
      {
        "date": "2023-04-08T07:39:00.000Z",
        "voteCount": 3,
        "content": "A\nA GPU-accelerated video rendering platform that retrieves and stores videos in a storage bucket: Video rendering requires a stable and powerful infrastructure with persistent storage, which is not provided by preemptible VMs. Additionally, GPUs are not available on all preemptible VM instances."
      },
      {
        "date": "2023-08-22T07:42:00.000Z",
        "voteCount": 2,
        "content": "https://cloud.google.com/compute/docs/instances/preemptible#preemptible-with-gpu"
      },
      {
        "date": "2021-06-13T14:11:00.000Z",
        "voteCount": 6,
        "content": "ans: D"
      },
      {
        "date": "2021-06-13T22:51:00.000Z",
        "voteCount": 4,
        "content": "Agree with you on Answer D"
      },
      {
        "date": "2023-04-08T07:40:00.000Z",
        "voteCount": 2,
        "content": "D GPU-accelerated video rendering platform that retrieves and stores videos in a storage bucket: Video rendering requires a stable and powerful infrastructure with persistent storage, which is not provided by preemptible VMs. Additionally, GPUs are not available on all preemptible VM instances."
      },
      {
        "date": "2024-08-13T18:28:00.000Z",
        "voteCount": 1,
        "content": "Has to be D. Definitely not A"
      },
      {
        "date": "2024-06-09T03:45:00.000Z",
        "voteCount": 1,
        "content": "cannot be A, if the VM is removed by the preemption process, we lose data in memory"
      },
      {
        "date": "2024-03-07T11:00:00.000Z",
        "voteCount": 1,
        "content": "It seems A &amp; D both as suitable answer. But I'll go with A, as attaching GPU with preemptible VM will increase cost, and in this question the purpose of opting for preemptible VM is reducing cost.\nhttps://cloud.google.com/compute/docs/instances/preemptible#preemptible-with-gpu"
      },
      {
        "date": "2024-03-06T22:03:00.000Z",
        "voteCount": 1,
        "content": "Will go with D. \nLooking for cost effective.   \nhttps://cloud.google.com/compute/docs/instances/preemptible#preemptible-with-gpu"
      },
      {
        "date": "2023-12-22T20:22:00.000Z",
        "voteCount": 2,
        "content": "ans: A\nPreemptible VMs are best suited for fault-tolerant, non-critical applications due to their temporary nature. Among the options listed, A, a scalable in-memory caching system, aligns well with preemptible instances as it can handle interruptions and doesn't require continuous uptime."
      },
      {
        "date": "2023-12-02T03:36:00.000Z",
        "voteCount": 1,
        "content": "Option D"
      },
      {
        "date": "2023-10-26T23:46:00.000Z",
        "voteCount": 2,
        "content": "I would go with A compared to other options"
      },
      {
        "date": "2023-05-19T23:45:00.000Z",
        "voteCount": 2,
        "content": "Ans is D\nVideo rendering service is like application type called Batch job. Therefore, we can use instance type preemptible for them. If they complete task, they could be destroy and generate new instance to work continuously next task."
      },
      {
        "date": "2023-03-09T21:28:00.000Z",
        "voteCount": 2,
        "content": "C is more accurate"
      },
      {
        "date": "2022-12-12T18:02:00.000Z",
        "voteCount": 5,
        "content": "Why not A?  \"A scalable in-memory caching system.\"\nIn general a caching system is not critical to the function of an application.\nIf the cache is down it will cause requests to have cache miss and query the DB instead. User requests will still get served albeit slower.\nIn addition the answer specifies that  the caching system is \"scalable\" reducing further the impact of 1 VM getting preempted, ie traffic can be automatically redirected to other cache replicas.\nTo me all other answers seem to have a more severe impact on the user in case the VM is preempted."
      },
      {
        "date": "2022-12-04T22:48:00.000Z",
        "voteCount": 1,
        "content": "C is the right answer"
      },
      {
        "date": "2022-12-01T17:58:00.000Z",
        "voteCount": 2,
        "content": "i think is C, database cluster is storage, and distributed, eventually consistence is resistant for the preempted. and sufficient quorum can ensure the DB transitions."
      },
      {
        "date": "2022-06-10T09:32:00.000Z",
        "voteCount": 2,
        "content": "D is correct"
      },
      {
        "date": "2022-05-12T13:05:00.000Z",
        "voteCount": 2,
        "content": "D is correct"
      },
      {
        "date": "2021-09-03T01:33:00.000Z",
        "voteCount": 4,
        "content": "D\nhttps://cloud.google.com/compute/docs/instances/preemptible"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 50,
    "url": "https://www.examtopics.com/discussions/google/view/55257-exam-professional-cloud-devops-engineer-topic-1-question-50/",
    "body": "Your organization recently adopted a container-based workflow for application development. Your team develops numerous applications that are deployed continuously through an automated build pipeline to a Kubernetes cluster in the production environment. The security auditor is concerned that developers or operators could circumvent automated testing and push code changes to production without approval. What should you do to enforce approvals?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure the build system with protected branches that require pull request approval.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse an Admission Controller to verify that incoming requests originate from approved sources.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tLeverage Kubernetes Role-Based Access Control (RBAC) to restrict access to only approved users.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEnable binary authorization inside the Kubernetes cluster and configure the build pipeline as an attestor.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 7,
        "isMostVoted": true
      },
      {
        "answer": "A",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2021-06-25T12:39:00.000Z",
        "voteCount": 26,
        "content": "this question is a little bit strange, but first we need to remove the invalid answers\n\nB: Incorrect An admission controller is a piece of code that intercepts requests to the Kubernetes API server prior to persistence of the object, but after the request is authenticated and authorized. (its for security but not \"enforce approvals\")\nC: Incorrect, we need to \"enforce approvals\" roles apply in the cluster and Ops always could push to production without approval.\nA: Incorrect, for me this answer sound well but this does not sound that an answer for a gcp exam and this do not enforce the use of the pipeline.\nD: Correct, they cannot push code to production without approval because their images are not signed."
      },
      {
        "date": "2021-07-01T06:23:00.000Z",
        "voteCount": 15,
        "content": "I win the exam today so this questions help me a lot"
      },
      {
        "date": "2023-12-02T04:01:00.000Z",
        "voteCount": 1,
        "content": "Option D"
      },
      {
        "date": "2022-12-05T10:03:00.000Z",
        "voteCount": 1,
        "content": "If you are not familiarised, Pull Requests are one way to bring changes from one branch (e.g. develop) into protected branches (e.g. master, main).\n\n1. First you need to protect the production branch (e.g, master, main)\n2. If a developer attempts to push new code to a production (now protected) it will trow a Permission denied error like this:\nremote: Permission denied to update branch master.\nTo git.com:org/repository.git\n ! [remote rejected] master -&gt; master (pre-receive hook declined)\nerror: failed to push some refs to 'git.com:org/repository.git'\n\n3. in order to push their code to production branch, the developers will need to open a Pull Request (If you are using GitLab, it is called Merge Request) and ask someone to Review and Approve your changes.\n4. The pipeline points to the protected branch; any new code pushed trigger the pipeline, and runs the tests and then deploy it.\n\nThis is how we do devops."
      },
      {
        "date": "2022-12-31T01:33:00.000Z",
        "voteCount": 2,
        "content": "but you missed the point here \"The security auditor is concerned that developers or operators could circumvent\". I see why you think pull request is the only way to circumvent the deployment process. But how about the operators? They have access to cluster and can simply redeploy it by some kubectl / cloud build command. So A is not correct."
      },
      {
        "date": "2023-01-08T04:05:00.000Z",
        "voteCount": 1,
        "content": "That said, I send the question back to you, how about the developers?: \"is concerned that developers or operators could circumvent\" \nDeveloper will push code direct to master, with bug that is not caught by the tests and here we go: you do have a signed imaged, attested, with a BUG or something like that will be deployed\nso the question depends on the point of view, the combination of both are right\n\nand one more thing, D prevent to push to the registry, but the operator can get the kubernetes deployment yaml and point to other GCR..."
      },
      {
        "date": "2022-09-20T20:26:00.000Z",
        "voteCount": 3,
        "content": "D is correct answer, binary auth is best practice"
      },
      {
        "date": "2022-06-08T05:16:00.000Z",
        "voteCount": 2,
        "content": "Correct me if I am wrong, but this question is ambiguous. You can push the code at 3 stages:\n1. You can merge a branch to master without Merge Request if the master is not protected\n2. You can push the image to container registry to a repository if you have role assigned (only pipeline should be privileged to do).\n3. An operator can change the code altering image/yaml using kubectl cli. \n\nThe ultimate question is which problem are we trying to solve?"
      },
      {
        "date": "2022-02-13T01:54:00.000Z",
        "voteCount": 3,
        "content": "D - Binary authorisation"
      },
      {
        "date": "2022-01-05T15:00:00.000Z",
        "voteCount": 2,
        "content": "D\nhttps://cloud.google.com/binary-authorization\nBinary Authorization is a deploy-time security control that ensures only trusted container images are deployed on Google Kubernetes Engine (GKE) or Cloud Run. With Binary Authorization, you can require images to be signed by trusted authorities during the development process and then enforce signature validation when deploying. By enforcing validation, you can gain tighter control over your container environment by ensuring only verified images are integrated into the build-and-release process."
      },
      {
        "date": "2021-09-26T05:34:00.000Z",
        "voteCount": 3,
        "content": "Questions 51-55 is not available.. can someone please help me to get 51-55 questions?"
      },
      {
        "date": "2021-06-29T17:15:00.000Z",
        "voteCount": 4,
        "content": "Agreed with D. The keywords here is \"developers or operators\". Option A the operators could push images to production without approval (operators could touch the cluster directly and the cluster cannot do any action against them). Rest same as francisco_guerra."
      },
      {
        "date": "2021-06-18T22:29:00.000Z",
        "voteCount": 1,
        "content": "D - PR approval will ensure the automated testing etc., the question is asking how to ensure all code changes go through the pipeline, where automated tests are integrated"
      },
      {
        "date": "2021-06-13T22:58:00.000Z",
        "voteCount": 1,
        "content": "Answer C is the most close answer. Leverage best practice .\nanswer A is for pulling the code but in the question , the security auditor is concern about pushing the code ."
      },
      {
        "date": "2022-12-05T10:05:00.000Z",
        "voteCount": 1,
        "content": "If you are not familiarised, Pull Requests are one way to bring changes from one branch (e.g. develop) into protected branches (e.g. master, main).\n\nIn order to push their code to production branch, the developers will need to open a Pull Request (If you are using GitLab, it is called Merge Request) and ask someone to Review and Approve their changes."
      },
      {
        "date": "2021-06-13T14:12:00.000Z",
        "voteCount": 2,
        "content": "A could be the ans"
      },
      {
        "date": "2021-06-13T23:07:00.000Z",
        "voteCount": 2,
        "content": "I think you are right : A\nhttps://github.community/t/best-practices-for-protected-branches/10204"
      },
      {
        "date": "2023-12-20T11:44:00.000Z",
        "voteCount": 1,
        "content": "IMHO the statement is concert about runnigs unsafe workload on a cluster Kubernet, and not how to protect the code repository, in this other case, pull request approval and an Admission Controller would be fine. Then D is the ans"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 51,
    "url": "https://www.examtopics.com/discussions/google/view/64620-exam-professional-cloud-devops-engineer-topic-1-question-51/",
    "body": "You support a stateless web-based API that is deployed on a single Compute Engine instance in the europe-west2-a zone. The Service Level Indicator (SLI) for service availability is below the specified Service Level Objective (SLO). A postmortem has revealed that requests to the API regularly time out. The time outs are due to the API having a high number of requests and running out memory. You want to improve service availability. What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tChange the specified SLO to match the measured SLI",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tMove the service to higher-specification compute instances with more memory",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSet up additional service instances in other zones and load balance the traffic between all instances\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSet up additional service instances in other zones and use them as a failover in case the primary instance is unavailable"
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 8,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-10-24T10:49:00.000Z",
        "voteCount": 12,
        "content": "Ans: C"
      },
      {
        "date": "2023-12-02T04:08:00.000Z",
        "voteCount": 1,
        "content": "Option C"
      },
      {
        "date": "2023-12-02T04:04:00.000Z",
        "voteCount": 1,
        "content": "Option C"
      },
      {
        "date": "2023-01-14T16:20:00.000Z",
        "voteCount": 2,
        "content": "C. Set up additional service instances in other zones and load balance the traffic between all instances\n\nThis option will provide redundancy and increase the availability of the service by distributing the traffic across multiple instances. Additionally, if one instance goes down, the load balancer will redirect the traffic to the other healthy instances, minimizing the impact on the service availability."
      },
      {
        "date": "2022-10-05T20:33:00.000Z",
        "voteCount": 3,
        "content": "C is the correct anwer, it is required to increase reliability"
      },
      {
        "date": "2022-05-09T10:02:00.000Z",
        "voteCount": 2,
        "content": "Submitted C"
      },
      {
        "date": "2022-01-19T23:20:00.000Z",
        "voteCount": 1,
        "content": "Ans: C"
      },
      {
        "date": "2021-11-22T18:13:00.000Z",
        "voteCount": 1,
        "content": "C, this option will offer resilience and distribute the load, also provides ability to configure health checks at VM level and Load Balancer can send only to Healthy Instances."
      },
      {
        "date": "2021-11-10T23:45:00.000Z",
        "voteCount": 2,
        "content": "ANSWER: C"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 52,
    "url": "https://www.examtopics.com/discussions/google/view/64619-exam-professional-cloud-devops-engineer-topic-1-question-52/",
    "body": "You are running a real-time gaming application on Compute Engine that has a production and testing environment. Each environment has their own Virtual Private<br>Cloud (VPC) network. The application frontend and backend servers are located on different subnets in the environment's VPC. You suspect there is a malicious process communicating intermittently in your production frontend servers. You want to ensure that network traffic is captured for analysis. What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEnable VPC Flow Logs on the production VPC network frontend and backend subnets only with a sample volume scale of 0.5.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEnable VPC Flow Logs on the production VPC network frontend and backend subnets only with a sample volume scale of 1.0.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEnable VPC Flow Logs on the testing and production VPC network frontend and backend subnets with a volume scale of 0.5. Apply changes in testing before production.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEnable VPC Flow Logs on the testing and production VPC network frontend and backend subnets with a volume scale of 1.0. Apply changes in testing before production."
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 18,
        "isMostVoted": true
      },
      {
        "answer": "D",
        "count": 2,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2021-10-31T13:59:00.000Z",
        "voteCount": 16,
        "content": "B\n\nhttps://cloud.google.com/vpc/docs/flow-logs#log-sampling"
      },
      {
        "date": "2023-01-14T16:25:00.000Z",
        "voteCount": 8,
        "content": "B. Enable VPC Flow Logs on the production VPC network frontend and backend subnets only with a sample volume scale of 1.0.\n\nVPC flow logs are a feature that allows you to capture network traffic data in your VPC network. To ensure that all network traffic is captured for analysis, you should enable VPC flow logs on the production VPC network frontend and backend subnets with a sample volume scale of 1.0. This will capture all network traffic data, including the potentially malicious process, for further analysis.\nOption A. Enable VPC Flow Logs on the production VPC network frontend and backend subnets only with a sample volume scale of 0.5 is not adequate, as it captures only half of the network traffic, there is a chance that the logs of the malicious process are not captured.\nOption C and D, Enable VPC Flow Logs on the testing and production VPC network frontend and backend subnets with a volume scale of 0.5/1.0. Apply changes in testing before production, is not necessary, it's important to have the logs in production environment to detect and mitigate the problem."
      },
      {
        "date": "2023-12-02T04:08:00.000Z",
        "voteCount": 1,
        "content": "Option B"
      },
      {
        "date": "2023-11-14T05:34:00.000Z",
        "voteCount": 1,
        "content": "B: enabling VPC Flow Logs on the production VPC network frontend and backend subnets only with a sample volume scale of 1.0. This means that all traffic will be logged, ensuring that all network traffic is captured for analysis."
      },
      {
        "date": "2023-04-09T18:53:00.000Z",
        "voteCount": 1,
        "content": "App Engine grants the Error Reporting Writer role by default. The Error Reporting library for Python can be used without needing to explicitly provide credentials. Error Reporting is automatically enabled for App Engine flexible environment applications. No additional setup is required"
      },
      {
        "date": "2023-02-10T04:27:00.000Z",
        "voteCount": 1,
        "content": "in real project background, first we should keep the consistency of configuration between test env and prod env. second, we should apply changes in testing before production."
      },
      {
        "date": "2023-12-20T12:00:00.000Z",
        "voteCount": 1,
        "content": "That is true, but the statement says the problem is only in the production frontend servers, maybe you are not going to find the malicious process in the testing frontend servers"
      },
      {
        "date": "2022-12-05T10:19:00.000Z",
        "voteCount": 3,
        "content": "question saying test envs can be eliminated"
      },
      {
        "date": "2022-09-20T20:30:00.000Z",
        "voteCount": 2,
        "content": "Correct answer is B"
      },
      {
        "date": "2022-05-09T10:02:00.000Z",
        "voteCount": 2,
        "content": "Submitted B"
      },
      {
        "date": "2022-03-09T00:54:00.000Z",
        "voteCount": 1,
        "content": "B is better that A because you are filtering 1:20 instead of 1:10 and the malicious process generates very low traffic"
      },
      {
        "date": "2022-01-19T23:21:00.000Z",
        "voteCount": 1,
        "content": "Ans: B"
      },
      {
        "date": "2021-10-28T03:47:00.000Z",
        "voteCount": 6,
        "content": "The Answer for this is B"
      },
      {
        "date": "2024-01-27T06:45:00.000Z",
        "voteCount": 1,
        "content": "Most people rated D, sure that is better, but it will require re-deployment other than just changing the instance type. If a company doesn't have the capacity or resources to setup D, B is the quickly way to improve SLI. At the end of the day customer first, then you focus on how to do D or move things to serverless like Cloud Run"
      },
      {
        "date": "2021-10-24T10:48:00.000Z",
        "voteCount": 2,
        "content": "i think Answer: D"
      },
      {
        "date": "2021-10-29T08:40:00.000Z",
        "voteCount": 4,
        "content": "if there isnt problem in test environment why log it"
      },
      {
        "date": "2021-11-22T18:15:00.000Z",
        "voteCount": 3,
        "content": "Question clearly says only in Production they suspect, so we can eliminate the C and D options."
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 53,
    "url": "https://www.examtopics.com/discussions/google/view/64821-exam-professional-cloud-devops-engineer-topic-1-question-53/",
    "body": "Your team of Infrastructure DevOps Engineers is growing, and you are starting to use Terraform to manage infrastructure. You need a way to implement code versioning and to share code with other team members. What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tStore the Terraform code in a version-control system. Establish procedures for pushing new versions and merging with the master.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tStore the Terraform code in a network shared folder with child folders for each version release. Ensure that everyone works on different files.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tStore the Terraform code in a Cloud Storage bucket using object versioning. Give access to the bucket to every team member so they can download the files.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tStore the Terraform code in a shared Google Drive folder so it syncs automatically to every team member's computer. Organize files with a naming convention that identifies each new version."
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 11,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-10-29T08:42:00.000Z",
        "voteCount": 15,
        "content": "A for sure"
      },
      {
        "date": "2024-02-03T06:11:00.000Z",
        "voteCount": 3,
        "content": "https://developer.hashicorp.com/terraform/cloud-docs/recommended-practices/part3.3#4-create-workspaces\nversion-control systems like GitLab, GitHub, BitBucket, etc is the obvious choice,\n\nB, C, D are ridiculous"
      },
      {
        "date": "2023-12-02T04:09:00.000Z",
        "voteCount": 2,
        "content": "Option A"
      },
      {
        "date": "2023-10-30T04:15:00.000Z",
        "voteCount": 1,
        "content": "version-control system like Git"
      },
      {
        "date": "2023-03-25T23:06:00.000Z",
        "voteCount": 1,
        "content": "Version Control is the preferred way"
      },
      {
        "date": "2022-12-05T10:26:00.000Z",
        "voteCount": 1,
        "content": "A - Always use git"
      },
      {
        "date": "2022-08-29T22:06:00.000Z",
        "voteCount": 2,
        "content": "For option C &amp; D, downloading not at all recommended.\nFor option B, hectic process\nSo option A is the correct answer"
      },
      {
        "date": "2022-01-26T12:31:00.000Z",
        "voteCount": 1,
        "content": "A is the correct Answer!"
      },
      {
        "date": "2022-01-19T23:23:00.000Z",
        "voteCount": 3,
        "content": "A for sure"
      },
      {
        "date": "2021-10-28T03:48:00.000Z",
        "voteCount": 2,
        "content": "A is the guaranteed ans"
      },
      {
        "date": "2021-10-28T02:08:00.000Z",
        "voteCount": 4,
        "content": "Ans A\nhttps://www.terraform.io/docs/cloud/guides/recommended-practices/part3.3.html"
      },
      {
        "date": "2021-10-26T10:27:00.000Z",
        "voteCount": 3,
        "content": "A for sure"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 54,
    "url": "https://www.examtopics.com/discussions/google/view/64820-exam-professional-cloud-devops-engineer-topic-1-question-54/",
    "body": "You are using Stackdriver to monitor applications hosted on Google Cloud Platform (GCP). You recently deployed a new application, but its logs are not appearing on the Stackdriver dashboard.<br>You need to troubleshoot the issue. What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfirm that the Stackdriver agent has been installed in the hosting virtual machine.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfirm that your account has the proper permissions to use the Stackdriver dashboard.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfirm that port 25 has been opened in the firewall to allow messages through to Stackdriver.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfirm that the application is using the required client library and the service account key has proper permissions."
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 18,
        "isMostVoted": true
      },
      {
        "answer": "D",
        "count": 2,
        "isMostVoted": false
      },
      {
        "answer": "B",
        "count": 2,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2022-01-15T23:53:00.000Z",
        "voteCount": 12,
        "content": "Why do you complicate stuff.\nA is the answer.\nWhy not D, because if A is not there D is useless. Question says you are using Stackdriver monitoring, not saying you have an agent installed already. You need the agent to export logs. So first thing you'll always see in the agent is there, and running. Next service account, next client libraries.\nI hope this clears your doubts."
      },
      {
        "date": "2022-03-09T02:34:00.000Z",
        "voteCount": 1,
        "content": "For \"client libraries\" you mean something like the fluent-logger-python ?"
      },
      {
        "date": "2022-09-27T17:04:00.000Z",
        "voteCount": 3,
        "content": "You are assuming the new application is deployed on compute engine though there is no reference in question that says where the application is deployed."
      },
      {
        "date": "2023-12-19T07:23:00.000Z",
        "voteCount": 1,
        "content": "It never says that u are using a VM. What if the service is running on CloudRun? B is the answer"
      },
      {
        "date": "2021-11-13T18:40:00.000Z",
        "voteCount": 6,
        "content": "D - The question states that you are already using Stackdriver for the GCE instance (assuming the agent is already installed). However, the \"new\" application has issues shipping the logs"
      },
      {
        "date": "2021-11-18T03:42:00.000Z",
        "voteCount": 4,
        "content": "The question mention application logs, not only monitoring metrics, so I think \"D\" is correct.\nThe stackdriver agent would only provide metrics of resources. I think you need to setup logging \"client libraries\" on the application in order to have the logs, therefore \"D\". https://cloud.google.com/logging/docs/reference/libraries"
      },
      {
        "date": "2023-12-19T07:22:00.000Z",
        "voteCount": 1,
        "content": "It never says in which service is running so A does not consider all posibillities. B is the best match"
      },
      {
        "date": "2023-12-02T04:12:00.000Z",
        "voteCount": 2,
        "content": "Option A"
      },
      {
        "date": "2023-11-14T05:43:00.000Z",
        "voteCount": 1,
        "content": "the question asks about logs, only answer correct is A, the user already has access to the Stackdriver dashboard"
      },
      {
        "date": "2023-06-28T15:32:00.000Z",
        "voteCount": 2,
        "content": "D. Stackdriver agent or Cloud Monitor agent only ships metrics, not log. If opt A change to Ops agent then it will be correct since Ops Agent handles both metrics and log. \nhttps://cloud.google.com/logging/docs/agent/ops-agent/configuration#default\n\"The Ops Agent collects both metrics and logs by default. You can change this default behavior by configuring the Ops Agent.\"\nhttps://cloud.google.com/monitoring/agent/monitoring/installation#:~:text=The%20Ops%20Agent%20collects%20both%20metrics%20and%20logs%20by%20default.%20You%20can%20change%20this%20default%20behavior%20by%20configuring%20the%20Ops%20Agent."
      },
      {
        "date": "2023-01-14T16:27:00.000Z",
        "voteCount": 2,
        "content": "A. Store the Terraform code in a version-control system. Establish procedures for pushing new versions and merging with the master.\n\nUsing a version-control system such as Git, allows you to store different versions of the code and track changes that are made to it. This allows you to easily roll back to a previous version if necessary, and ensures that all team members are working on the same version of the code. It also allows team members to collaborate on the code and merge changes with the master version. This is the most effective way to share code and maintain versioning, as it provides a centralized location for all code and allows for easy collaboration and management of code changes."
      },
      {
        "date": "2023-01-14T16:30:00.000Z",
        "voteCount": 1,
        "content": "My last message was wrong, this is the good one:\n\nA. Confirm that the Stackdriver agent has been installed in the hosting virtual machine. \n\nTo troubleshoot the issue of logs not appearing on the Stackdriver dashboard, you should first confirm that the Stackdriver agent has been installed in the hosting virtual machine. This is because the agent is responsible for sending the logs from the machine to the Stackdriver service"
      },
      {
        "date": "2022-12-14T22:33:00.000Z",
        "voteCount": 3,
        "content": "service account key does not have permission. service account has permission."
      },
      {
        "date": "2022-12-05T10:34:00.000Z",
        "voteCount": 2,
        "content": "Key sentences for this question:\n1. You recently deployed a NEW APPLICATION,\n2. If it is a new application you CAN'T assume Stackdriver agent is already installed\n\nB) Wrong this is not a dashboard issue, even do, the first step is check if agent is installed\nC) Wrong, port 25 is used for SMTP server\nD) Wrong, if you are using GCP, VM, wth.."
      },
      {
        "date": "2022-12-04T09:35:00.000Z",
        "voteCount": 1,
        "content": "I think a lot the best answer is B, because the question not suggest the application is running in compute engine, and if the user has dashboard viewer permissions but no logs viewer permissions the problem mentioned in the question can happen"
      },
      {
        "date": "2022-10-21T00:57:00.000Z",
        "voteCount": 1,
        "content": "A should be the most likely correct answer."
      },
      {
        "date": "2022-06-10T10:12:00.000Z",
        "voteCount": 3,
        "content": "A is the answer ref.: https://cloud.google.com/monitoring/agent/monitoring/troubleshooting#checklist"
      },
      {
        "date": "2022-03-09T02:45:00.000Z",
        "voteCount": 1,
        "content": "I think A\nTroubleshoot legacy monitoring\n- agent installed ed run: ps -ax | grep fluentd\n- logging test is visible?\n- VM API Access scope (ie Full Access scope or Logging Write for logging agent)\n- Service account (if not default is used) or credential key\n- Application Client library installed\n- Exclusion rule exists on Log Router?\n- Firewall rule?"
      },
      {
        "date": "2022-01-19T23:27:00.000Z",
        "voteCount": 3,
        "content": "A is correct"
      },
      {
        "date": "2021-12-25T14:53:00.000Z",
        "voteCount": 1,
        "content": "The correct answer is A not D..D is mentioning one wrong thing thats why.\nhttps://cloud.google.com/logging/docs/agent/logging/troubleshooting#try-installing"
      },
      {
        "date": "2021-12-17T07:36:00.000Z",
        "voteCount": 5,
        "content": "A and D seems correct. I think D is less correct because since you are hosting on GCP, best practice is to not add a service account to the application itself but instead leverage the native logging capabilities of GCP's offerings like GKE, GCP, etc."
      },
      {
        "date": "2021-12-06T10:35:00.000Z",
        "voteCount": 2,
        "content": "https://cloud.google.com/logging/docs/agent/logging/troubleshooting#verifying_default_service_account_permission\nAns D"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 55,
    "url": "https://www.examtopics.com/discussions/google/view/64822-exam-professional-cloud-devops-engineer-topic-1-question-55/",
    "body": "Your organization recently adopted a container-based workflow for application development. Your team develops numerous applications that are deployed continuously through an automated build pipeline to the production environment. A recent security audit alerted your team that the code pushed to production could contain vulnerabilities and that the existing tooling around virtual machine (VM) vulnerabilities no longer applies to the containerized environment. You need to ensure the security and patch level of all code running through the pipeline. What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSet up Container Analysis to scan and report Common Vulnerabilities and Exposures.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure the containers in the build pipeline to always update themselves before release.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tReconfigure the existing operating system vulnerability software to exist inside the container.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tImplement static code analysis tooling against the Docker files used to create the containers."
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 10,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-10-29T08:55:00.000Z",
        "voteCount": 10,
        "content": "A is correct for me"
      },
      {
        "date": "2023-12-02T04:15:00.000Z",
        "voteCount": 2,
        "content": "Option A"
      },
      {
        "date": "2023-01-14T16:34:00.000Z",
        "voteCount": 2,
        "content": "A. Set up Container Analysis to scan and report Common Vulnerabilities and Exposures.\n\nTo ensure the security and patch level of all code running through the pipeline, you should set up Container Analysis to scan and report Common Vulnerabilities and Exposures. Container Analysis is a service on GCP that allows you to scan and analyze container images for vulnerabilities, malware and other issues. This will help you identify vulnerabilities in your container images and take appropriate action to address them."
      },
      {
        "date": "2022-12-05T10:35:00.000Z",
        "voteCount": 1,
        "content": "A) for sure"
      },
      {
        "date": "2022-10-23T08:22:00.000Z",
        "voteCount": 1,
        "content": "A is the answer.\n\nhttps://cloud.google.com/container-analysis/docs/container-analysis\nContainer Analysis is a service that provides vulnerability scanning and metadata storage for containers."
      },
      {
        "date": "2022-10-21T00:57:00.000Z",
        "voteCount": 2,
        "content": "A is correct."
      },
      {
        "date": "2022-09-25T20:23:00.000Z",
        "voteCount": 1,
        "content": "Correct ans is A as per Google's best practices"
      },
      {
        "date": "2022-08-14T00:52:00.000Z",
        "voteCount": 1,
        "content": "A - correct since this system would have alerted the issue after deployment in stating/dev and before deployment to production. - preventing issues in prod.\nhttps://cloud.google.com/container-analysis/docs/container-analysis\nB - Updates don't prevent vulnerabilities \nC - Not addressing the root cause.\nD - Static code analysis against a Docker file is useless since the code does not reside there."
      },
      {
        "date": "2022-02-21T14:18:00.000Z",
        "voteCount": 3,
        "content": "all comments so far agree that A is indeed the answer"
      },
      {
        "date": "2022-01-19T23:28:00.000Z",
        "voteCount": 1,
        "content": "A is correct"
      },
      {
        "date": "2021-10-26T14:08:00.000Z",
        "voteCount": 3,
        "content": "Ans: A"
      },
      {
        "date": "2021-10-26T10:28:00.000Z",
        "voteCount": 3,
        "content": "should be A"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 56,
    "url": "https://www.examtopics.com/discussions/google/view/64784-exam-professional-cloud-devops-engineer-topic-1-question-56/",
    "body": "You use Cloud Build to build your application. You want to reduce the build time while minimizing cost and development effort. What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse Cloud Storage to cache intermediate artifacts.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRun multiple Jenkins agents to parallelize the build.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse multiple smaller build steps to minimize execution time.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse larger Cloud Build virtual machines (VMs) by using the machine-type option."
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 12,
        "isMostVoted": true
      },
      {
        "answer": "C",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2021-10-26T03:59:00.000Z",
        "voteCount": 14,
        "content": "Ans A \nhttps://cloud.google.com/storage/docs/best-practices"
      },
      {
        "date": "2021-12-15T19:48:00.000Z",
        "voteCount": 8,
        "content": "A - https://cloud.google.com/build/docs/speeding-up-builds#caching_directories_with_google_cloud_storage"
      },
      {
        "date": "2023-12-02T04:18:00.000Z",
        "voteCount": 2,
        "content": "Option A"
      },
      {
        "date": "2023-08-30T11:26:00.000Z",
        "voteCount": 1,
        "content": "Definitely A\nA. Use Cloud Storage to cache intermediate artifacts."
      },
      {
        "date": "2023-06-19T14:05:00.000Z",
        "voteCount": 1,
        "content": "https://cloud.google.com/blog/products/containers-kubernetes/kubernetes-best-practices-how-and-why-to-build-small-container-images"
      },
      {
        "date": "2023-01-10T19:24:00.000Z",
        "voteCount": 1,
        "content": "IMO this question / options could be reported incorrectly. \nFor A, according to the doc, we can only store the resulting image in cloud storage, not intermediate layer of the image. To do so, we should use Kaniko cache instead. So A isn't correct.\nFor D, it works but it increases the cost which violates the requirement from the question."
      },
      {
        "date": "2023-12-26T10:25:00.000Z",
        "voteCount": 1,
        "content": "I wonder if ans C is the correct, you can find the same answer: Use multiple smaller build steps to minimize execution time in Q-126 as well."
      },
      {
        "date": "2022-10-23T08:18:00.000Z",
        "voteCount": 2,
        "content": "A is the answer.\n\nhttps://cloud.google.com/build/docs/optimize-builds/speeding-up-builds#caching_directories_with_google_cloud_storage\nTo increase the speed of a build, reuse the results from a previous build. You can copy the results of a previous build to a Google Cloud Storage bucket, use the results for faster calculation, and then copy the new results back to the bucket."
      },
      {
        "date": "2022-10-24T20:01:00.000Z",
        "voteCount": 1,
        "content": "Agree with A"
      },
      {
        "date": "2022-10-21T00:58:00.000Z",
        "voteCount": 1,
        "content": "Most likely A is correct, even after reading the suggested document at:\nhttps://cloud.google.com/build/docs/speeding-up-builds"
      },
      {
        "date": "2022-05-09T10:03:00.000Z",
        "voteCount": 2,
        "content": "Submitted A"
      },
      {
        "date": "2021-12-27T01:40:00.000Z",
        "voteCount": 3,
        "content": "Ans A and thats cheap and fast"
      },
      {
        "date": "2021-12-26T03:22:00.000Z",
        "voteCount": 1,
        "content": "minimising costs...high virtual machines are expensive"
      },
      {
        "date": "2021-12-06T22:28:00.000Z",
        "voteCount": 3,
        "content": "lets correct something fellows ok. A is not ok, why, we can ok only use intermediate artifacts in Kaniko cache, not in Cloud storage,  in cloud storage we use results not intermediate artifacts  \"You can copy the results of a previous build to a Google Cloud Storage bucket, use the results for faster calculation, and then copy the new results back to the bucket.\" go re-read the best practices and you will see what im talking about, then this leaves D as the correct answer.\nhttps://cloud.google.com/build/docs/speeding-up-builds"
      },
      {
        "date": "2022-12-07T14:48:00.000Z",
        "voteCount": 1,
        "content": "if you question and point out the error, don't just give your answer so you help the discussion"
      },
      {
        "date": "2022-12-07T14:49:00.000Z",
        "voteCount": 1,
        "content": "sorry not see ans"
      },
      {
        "date": "2022-12-07T14:48:00.000Z",
        "voteCount": 1,
        "content": "if you question and point out the error, don't just give your answer so you help the discussion"
      },
      {
        "date": "2022-01-16T00:00:00.000Z",
        "voteCount": 4,
        "content": "A is correct choice.\nWhy D is not correct, because even if you break steps into small chunks, you are just increasing the number of steps, and not solving the actual problem of reducing execution time. If step 1 takes 5min it will take 5min, if you break it down into three steps, combined Step 1+2+3 = 5min again, and they don't run in parallel. What did you solve? Nothing.\nIf you cache ie. store intermediate artefacts in cloud storage, you do not need to recompile it in next steps, saves time and cost."
      },
      {
        "date": "2021-12-05T12:32:00.000Z",
        "voteCount": 6,
        "content": "Correct Answer is (D):\n\nUsing custom virtual machine sizes\nIn addition to the standard machine type, Cloud Build provides four high-CPU virtual machine types to run your builds. To increase the speed of your build, select a virtual machine with a higher CPU. Requesting a high-CPU machine may increase the startup time of your build as Cloud Build only starts these machines on demand.\n\nhttps://cloud.google.com/build/docs/speeding-up-builds"
      },
      {
        "date": "2021-12-06T22:19:00.000Z",
        "voteCount": 1,
        "content": "in as much as D is correct A is also mentioned inthe Best practices"
      },
      {
        "date": "2021-12-06T22:28:00.000Z",
        "voteCount": 1,
        "content": "You are correct sir...."
      },
      {
        "date": "2021-11-24T12:16:00.000Z",
        "voteCount": 2,
        "content": "Caching directories with Google Cloud Storage\nTo increase the speed of a build, reuse the results from a previous build. You can copy the results of a previous build to a Google Cloud Storage bucket, use the results for faster calculation, and then copy the new results back to the bucket. Use this method when your build takes a long time and produces a small number of files that does not take time to copy to and from Google Cloud Storage."
      },
      {
        "date": "2021-12-07T10:59:00.000Z",
        "voteCount": 1,
        "content": "results not  intermediate artifacts, ok"
      },
      {
        "date": "2021-11-22T18:27:00.000Z",
        "voteCount": 3,
        "content": "Both A and D are valid options, but if we look in the question they are asking to Minimize Cost - Larger Compute Instances comes at price. \nSo I will go with A (Caching from GCS bucket)"
      },
      {
        "date": "2021-11-11T00:21:00.000Z",
        "voteCount": 1,
        "content": "Ans is A"
      },
      {
        "date": "2021-11-09T02:21:00.000Z",
        "voteCount": 3,
        "content": "A\nhttps://cloud.google.com/build/docs/speeding-up-builds"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 57,
    "url": "https://www.examtopics.com/discussions/google/view/64823-exam-professional-cloud-devops-engineer-topic-1-question-57/",
    "body": "You support a web application that is hosted on Compute Engine. The application provides a booking service for thousands of users. Shortly after the release of a new feature, your monitoring dashboard shows that all users are experiencing latency at login. You want to mitigate the impact of the incident on the users of your service. What should you do first?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRoll back the recent release.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tReview the Stackdriver monitoring.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUpsize the virtual machines running the login services.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDeploy a new release to see whether it fixes the problem."
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 9,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-11-18T08:15:00.000Z",
        "voteCount": 12,
        "content": "A Rollback is needed to mitigate the impact. Once the is done review can be done"
      },
      {
        "date": "2023-12-19T07:05:00.000Z",
        "voteCount": 2,
        "content": "MITIGATE is the word here... increasing resources will no garantize the mitigation. Rolling back will do this"
      },
      {
        "date": "2023-12-02T04:20:00.000Z",
        "voteCount": 1,
        "content": "Option A"
      },
      {
        "date": "2023-01-14T16:36:00.000Z",
        "voteCount": 1,
        "content": "A. Roll back the recent release. This would be the quickest way to remove the new feature that is causing the latency and restore the application to its previous state. This would immediately mitigate the impact on users, while you continue to investigate the issue with the new feature and identify a long-term solution."
      },
      {
        "date": "2022-10-21T00:56:00.000Z",
        "voteCount": 2,
        "content": "A is correct."
      },
      {
        "date": "2022-09-20T20:37:00.000Z",
        "voteCount": 1,
        "content": "A is the correct answer, to properly mitigate the issue a rollback is required"
      },
      {
        "date": "2022-02-13T03:52:00.000Z",
        "voteCount": 2,
        "content": "A - Rollback to previous stable version. Then you need to find what is causing the issue."
      },
      {
        "date": "2022-01-19T23:29:00.000Z",
        "voteCount": 2,
        "content": "A is correct"
      },
      {
        "date": "2021-11-11T00:27:00.000Z",
        "voteCount": 1,
        "content": "A Rollback first"
      },
      {
        "date": "2021-11-04T22:29:00.000Z",
        "voteCount": 1,
        "content": "B - Find whats wrong with the system and mitigate. As the Q says only login is affected, So no point is rollback"
      },
      {
        "date": "2021-11-06T22:37:00.000Z",
        "voteCount": 1,
        "content": "you still use service you cannot login?"
      },
      {
        "date": "2021-11-04T22:31:00.000Z",
        "voteCount": 1,
        "content": "https://cloud.google.com/architecture/identifying-causes-of-app-latency-with-stackdriver-and-opencensus"
      },
      {
        "date": "2021-10-29T09:16:00.000Z",
        "voteCount": 3,
        "content": "But the question is about mitigating the problema, with the rollback the system goes back to the old version."
      },
      {
        "date": "2021-11-05T00:22:00.000Z",
        "voteCount": 2,
        "content": "roll back is the answer"
      },
      {
        "date": "2021-10-26T19:04:00.000Z",
        "voteCount": 4,
        "content": "First roll back and then use monitoring to review what went wrong."
      },
      {
        "date": "2021-10-26T10:32:00.000Z",
        "voteCount": 4,
        "content": "A rollback"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 58,
    "url": "https://www.examtopics.com/discussions/google/view/64852-exam-professional-cloud-devops-engineer-topic-1-question-58/",
    "body": "You are deploying an application that needs to access sensitive information. You need to ensure that this information is encrypted and the risk of exposure is minimal if a breach occurs. What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tStore the encryption keys in Cloud Key Management Service (KMS) and rotate the keys frequently\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tInject the secret at the time of instance creation via an encrypted configuration management system.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tIntegrate the application with a Single sign-on (SSO) system and do not expose secrets to the application.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tLeverage a continuous build pipeline that produces multiple versions of the secret for each instance of the application."
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 5,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-10-29T09:18:00.000Z",
        "voteCount": 11,
        "content": "Ans: A"
      },
      {
        "date": "2023-12-02T04:24:00.000Z",
        "voteCount": 1,
        "content": "Option A"
      },
      {
        "date": "2023-01-14T16:38:00.000Z",
        "voteCount": 1,
        "content": "A. Store the encryption keys in Cloud Key Management Service (KMS) and rotate the keys frequently. This ensures that the sensitive information is encrypted at rest and in transit, and that the encryption keys are regularly rotated to minimize the risk of exposure in the event of a breach."
      },
      {
        "date": "2022-12-06T10:23:00.000Z",
        "voteCount": 1,
        "content": "A) should be the correct answer."
      },
      {
        "date": "2022-10-21T01:00:00.000Z",
        "voteCount": 2,
        "content": "A should be the correct answer."
      },
      {
        "date": "2022-09-25T20:25:00.000Z",
        "voteCount": 1,
        "content": "The clear answer is A"
      },
      {
        "date": "2022-04-22T09:14:00.000Z",
        "voteCount": 1,
        "content": "Ans: A"
      },
      {
        "date": "2022-01-19T23:30:00.000Z",
        "voteCount": 1,
        "content": "A is correct"
      },
      {
        "date": "2021-10-28T02:15:00.000Z",
        "voteCount": 1,
        "content": "https://cloud.google.com/security-key-management"
      },
      {
        "date": "2021-10-28T02:14:00.000Z",
        "voteCount": 2,
        "content": "Ans is A."
      },
      {
        "date": "2021-10-26T14:09:00.000Z",
        "voteCount": 3,
        "content": "Ans: A"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 59,
    "url": "https://www.examtopics.com/discussions/google/view/64824-exam-professional-cloud-devops-engineer-topic-1-question-59/",
    "body": "You encounter a large number of outages in the production systems you support. You receive alerts for all the outages that wake you up at night. The alerts are due to unhealthy systems that are automatically restarted within a minute. You want to set up a process that would prevent staff burnout while following Site<br>Reliability Engineering practices. What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEliminate unactionable alerts.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate an incident report for each of the alerts.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDistribute the alerts to engineers in different time zones.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRedefine the related Service Level Objective so that the error budget is not exhausted."
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 8,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-11-01T13:02:00.000Z",
        "voteCount": 14,
        "content": "I reckon its A, the reason is because it seems like the problem is automatically fixed with an restart of the service after a minute, therefore engineers don't really need to be woken up about these problems. If it failed multiple times or if the restart failed, then the engineer should be woken up"
      },
      {
        "date": "2021-11-06T22:42:00.000Z",
        "voteCount": 1,
        "content": "A or C"
      },
      {
        "date": "2023-01-14T17:10:00.000Z",
        "voteCount": 2,
        "content": "I agree with A."
      },
      {
        "date": "2022-12-31T05:26:00.000Z",
        "voteCount": 2,
        "content": "It should be A rather than D.\nTo follow SRE practice, we should eliminate unactionable alert which is pointless and to increase precision. While D also looks valid, the question never say that the application is being affected (e.g. has downtime),  and never says any actions are needed.  As a result, there is no need to redefine SLI and since they didn't spend time to resolve it no error budget is spent."
      },
      {
        "date": "2022-10-21T01:06:00.000Z",
        "voteCount": 2,
        "content": "Between A and C, B and D answers are not good.\nI lean more towards A because those alerts seem unactionable a the moment alert is received, ie: machine restarted automatically already.\nThis would be best imidiate action as per the question. Of course the source of alerts should be looked at and fixed separately from addressing the issue in question."
      },
      {
        "date": "2022-06-27T01:56:00.000Z",
        "voteCount": 1,
        "content": "I agree with A.\n\nEliminate bad monitoring : Unactionable alerts (i.e., spam)\n\nhttps://cloud.google.com/blog/products/management-tools/meeting-reliability-challenges-with-sre-principles"
      },
      {
        "date": "2022-02-21T08:51:00.000Z",
        "voteCount": 4,
        "content": "agree with kyubiblaze about having to remove unactionable items aka spam:  \"good monitoring alerts on actionable problems\" @ https://cloud.google.com/blog/products/management-tools/meeting-reliability-challenges-with-sre-principles"
      },
      {
        "date": "2022-01-19T23:30:00.000Z",
        "voteCount": 1,
        "content": "A is correct"
      },
      {
        "date": "2022-01-16T00:06:00.000Z",
        "voteCount": 3,
        "content": "A - You have to remove \"unactionable\" alerts, these alerts are useless if you can't take any action.\nSimple reason, C might be following SRE practice, but it is distributing the problem, not solving it.\nB and D, totally No."
      },
      {
        "date": "2021-12-30T05:47:00.000Z",
        "voteCount": 1,
        "content": "answer is c. it follows google SRE and prevents staff burnout. https://sre.google/workbook/team-lifecycles/"
      },
      {
        "date": "2021-12-05T13:00:00.000Z",
        "voteCount": 3,
        "content": "The team may continue to work on non-reliability features if:\n\nThe outage was caused by a company-wide networking problem.\nThe outage was caused by a service maintained by another team, who have themselves frozen releases to address their reliability issues.\nThe error budget was consumed by users out of scope for the SLO (e.g., load tests or penetration testers).\nMiscategorized errors consume budget even though no users were impacted.\n\nhttps://sre.google/workbook/error-budget-policy/"
      },
      {
        "date": "2021-12-05T13:01:00.000Z",
        "voteCount": 2,
        "content": "Correct Answer is (D):"
      },
      {
        "date": "2021-11-11T00:37:00.000Z",
        "voteCount": 1,
        "content": "Answer D"
      },
      {
        "date": "2021-10-31T14:27:00.000Z",
        "voteCount": 3,
        "content": "C follows the SRE."
      },
      {
        "date": "2023-12-21T02:38:00.000Z",
        "voteCount": 1,
        "content": "The statemene says: you encounter a large number of outages in the production systems you support, then eliminating the alerts doesn't seem to be a good idea. If there is another support team in another time zone. What's happen if the server doesn't reboot or the services don't start fine?. There is not a correct answer between options, what it would be to resolve the reboot problem. I don't know which is better if A or C, I suppose we have losed some information in the statement or in the answers. But in this situation I agree @NXD and choose C"
      },
      {
        "date": "2023-12-25T12:13:00.000Z",
        "voteCount": 1,
        "content": "Sorry, but I change to ans A. I have noticed this question is repeated as Q133 but without the text: You receive alerts for all the outages that wake you up at night"
      },
      {
        "date": "2021-10-28T02:21:00.000Z",
        "voteCount": 4,
        "content": "Ans D\nhttps://www.atlassian.com/incident-management/kpis/error-budget"
      },
      {
        "date": "2021-12-26T02:39:00.000Z",
        "voteCount": 1,
        "content": "Ans A...point of correction"
      },
      {
        "date": "2021-12-26T03:14:00.000Z",
        "voteCount": 1,
        "content": "NO!D is correct"
      },
      {
        "date": "2021-10-28T00:47:00.000Z",
        "voteCount": 3,
        "content": "Should be A"
      },
      {
        "date": "2021-10-26T10:33:00.000Z",
        "voteCount": 1,
        "content": "D redefine SLI"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 60,
    "url": "https://www.examtopics.com/discussions/google/view/64985-exam-professional-cloud-devops-engineer-topic-1-question-60/",
    "body": "You have migrated an e-commerce application to Google Cloud Platform (GCP). You want to prepare the application for the upcoming busy season. What should you do first to prepare for the busy season?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tLoad teat the application to profile its performance for scaling.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEnable AutoScaling on the production clusters, in case there is growth.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tPre-provision double the compute power used last season, expecting growth.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a runbook on inflating the disaster recovery (DR) environment if there is growth."
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 10,
        "isMostVoted": true
      },
      {
        "answer": "B",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2021-10-31T14:34:00.000Z",
        "voteCount": 18,
        "content": "https://cloud.google.com/architecture/black-friday-production-readiness#preparation_stage\n\nThe objective of the preparation stage is to test the system's ability to scale for peak user traffic and to document the results. Completing the preparation stage results in architecture refinement to handle peak traffic more efficiently and increase system reliability. This stage also yields procedures for operations and support that help streamline processes for handling the peak event and any issues that might occur. Consider this stage as practice for the peak event from a system and operations perspective.\n\nA is exactly what mentioned above.\nB is the step after the preparation stage."
      },
      {
        "date": "2021-11-23T00:49:00.000Z",
        "voteCount": 1,
        "content": "Changing the architecture for scale and reliability\nLoad testing and failure testing, along with architecture reviews, encourage limited-scope architectural changes that can enhance the scale and reliability of the system. However, introducing changes adds risk, so limit the changes to a conservative range of time.https://cloud.google.com/architecture/black-friday-production-readiness#changing_the_architecture_for_scale_and_reliability"
      },
      {
        "date": "2022-01-16T00:11:00.000Z",
        "voteCount": 5,
        "content": "Come on, no brainer.\nA is the answer.\nYou load test to understand how your application perform under heavy load. \"Prepare for busy season\"\nB - No, Option A will give you insight in how your applications works under load, and how do you scale, if it cannot scale, autoscaling in meaningless.\nSo first you test your application in controlled environment. Not wait for the busy time to come and then realise autoscaling is also unable to meet demand. Or Maybe you even reach your quotas."
      },
      {
        "date": "2022-10-24T20:23:00.000Z",
        "voteCount": 1,
        "content": "Good analysis, before moving any new features first thing to do performance test to understand how system behaves under load, Auto scaling is later step... A is 100% correct"
      },
      {
        "date": "2023-12-02T04:26:00.000Z",
        "voteCount": 1,
        "content": "Option A"
      },
      {
        "date": "2023-03-25T23:29:00.000Z",
        "voteCount": 1,
        "content": "Would go with A because you need to know the performance of your application if it scales to serve larger customers. Scaling decisions of the application comes after."
      },
      {
        "date": "2023-01-14T17:14:00.000Z",
        "voteCount": 1,
        "content": "A. Load test the application to profile its performance for scaling. This will help to identify any potential bottlenecks or issues with the application, and allow you to make the necessary adjustments or scaling decisions before the busy season begins."
      },
      {
        "date": "2022-10-21T13:05:00.000Z",
        "voteCount": 1,
        "content": "After moving the application onto GCP, some amount of testing should be carried out before deciding what to do next."
      },
      {
        "date": "2022-01-19T23:31:00.000Z",
        "voteCount": 2,
        "content": "A is correct"
      },
      {
        "date": "2021-12-28T05:21:00.000Z",
        "voteCount": 2,
        "content": "Set up load and performance testing\nLoad testing is the process of deploying a test version of the system and creating requests to simulate high use of the system. Load testing normally focuses on testing for sustainable user-perceived behavior at some percentile below the absolute peak. Testing for peak requires hitting that top percentile with consistent good performance."
      },
      {
        "date": "2021-12-27T17:33:00.000Z",
        "voteCount": 1,
        "content": "B is the answer"
      },
      {
        "date": "2021-12-28T05:21:00.000Z",
        "voteCount": 1,
        "content": "Sorry guys this is wrong"
      },
      {
        "date": "2022-09-27T18:20:00.000Z",
        "voteCount": 1,
        "content": "For Auto Scaling you need to provide parameters which will not be know if load test is not done. Otherwise you will be using arbitrary values which may not be consistent with actual load."
      },
      {
        "date": "2021-12-05T04:42:00.000Z",
        "voteCount": 1,
        "content": "https://cloud.google.com/blog/topics/retail/preparing-for-peak-holiday-season-while-wfh\nAns A makes sense according to this doc"
      },
      {
        "date": "2021-11-12T08:10:00.000Z",
        "voteCount": 4,
        "content": "Passed exam a couple of days ago. Chose A"
      },
      {
        "date": "2021-11-04T22:34:00.000Z",
        "voteCount": 4,
        "content": "Should be A , To check how application performs with load"
      },
      {
        "date": "2021-11-11T00:44:00.000Z",
        "voteCount": 1,
        "content": "Agree with A"
      },
      {
        "date": "2021-10-29T11:53:00.000Z",
        "voteCount": 2,
        "content": "Ans : B"
      },
      {
        "date": "2021-10-29T09:34:00.000Z",
        "voteCount": 2,
        "content": "Ans: B"
      },
      {
        "date": "2021-10-28T02:26:00.000Z",
        "voteCount": 2,
        "content": "Ans B\nhttps://cloud.google.com/architecture/black-friday-production-readiness"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 61,
    "url": "https://www.examtopics.com/discussions/google/view/64943-exam-professional-cloud-devops-engineer-topic-1-question-61/",
    "body": "You support a web application that runs on App Engine and uses CloudSQL and Cloud Storage for data storage. After a short spike in website traffic, you notice a big increase in latency for all user requests, increase in CPU use, and the number of processes running the application. Initial troubleshooting reveals:<br>\u2711 After the initial spike in traffic, load levels returned to normal but users still experience high latency.<br>\u2711 Requests for content from the CloudSQL database and images from Cloud Storage show the same high latency.<br>\u2711 No changes were made to the website around the time the latency increased.<br>\u2711 There is no increase in the number of errors to the users.<br>You expect another spike in website traffic in the coming days and want to make sure users don't experience latency. What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUpgrade the GCS buckets to Multi-Regional.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEnable high availability on the CloudSQL instances.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tMove the application from App Engine to Compute Engine.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tModify the App Engine configuration to have additional idle instances.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 11,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-12-03T12:40:00.000Z",
        "voteCount": 10,
        "content": "Correct Answer is D:\n\nScaling\tApp Engine scales the number of instances automatically in response to processing volume. This scaling factors in the automatic_scaling settings that are provided on a per-version basis in the configuration file.\tA service with basic scaling is configured by setting the maximum number of instances in the max_instances parameter of the basic_scaling setting. The number of live instances scales with the processing volume.\tYou configure the number of instances of each version in that service's configuration file. The number of instances usually corresponds to the size of a dataset being held in memory or the desired throughput for offline work. You can adjust the number of instances of a manually-scaled version very quickly, without stopping instances that are currently running, using the Modules API set_num_instances function.\n\nhttps://cloud.google.com/appengine/docs/standard/python/how-instances-are-managed"
      },
      {
        "date": "2021-11-04T22:45:00.000Z",
        "voteCount": 6,
        "content": "D is correct - https://cloud.google.com/appengine/docs/standard/python/config/appref\nmax_idle_instances\nOptional. The maximum number of idle instances that App Engine should maintain for this version. Specify a value from 1 to 1000. If not specified, the default value is automatic, which means App Engine will manage the number of idle instances. Keep the following in mind:\n\nA high maximum reduces the number of idle instances more gradually when load levels return to normal after a spike. This helps your application maintain steady performance through fluctuations in request load, but also raises the number of idle instances (and consequent running costs) during such periods of heavy load."
      },
      {
        "date": "2021-11-11T07:54:00.000Z",
        "voteCount": 1,
        "content": "Agree with D"
      },
      {
        "date": "2024-02-03T20:49:00.000Z",
        "voteCount": 1,
        "content": "https://cloud.google.com/appengine/docs/legacy/standard/python/config/appref#scaling_elements:~:text=traffic%20or%20not.-,max_idle_instances,-Optional.%20The%20maximum"
      },
      {
        "date": "2023-12-02T04:37:00.000Z",
        "voteCount": 1,
        "content": "Option D"
      },
      {
        "date": "2023-01-14T17:16:00.000Z",
        "voteCount": 1,
        "content": "D. Modify the App Engine configuration to have additional idle instances. This will ensure that there are enough resources available to handle the spike in traffic, reducing the likelihood of latency for users. Additionally, you may also consider enabling high availability on the CloudSQL instances and upgrading the GCS buckets to Multi-Regional for more resiliency."
      },
      {
        "date": "2022-12-31T05:31:00.000Z",
        "voteCount": 1,
        "content": "D, no brainer. A B and C don't even make sense."
      },
      {
        "date": "2022-12-31T05:33:00.000Z",
        "voteCount": 1,
        "content": "A. then how about CloudSQL?\nB. then how about cloud storage?\nC. the same could also happen and even worse if it isn't MIG"
      },
      {
        "date": "2022-09-27T20:42:00.000Z",
        "voteCount": 2,
        "content": "Vote for D"
      },
      {
        "date": "2022-01-19T23:31:00.000Z",
        "voteCount": 4,
        "content": "D is correct"
      },
      {
        "date": "2021-12-27T17:35:00.000Z",
        "voteCount": 2,
        "content": "D is the answer"
      },
      {
        "date": "2021-12-27T17:34:00.000Z",
        "voteCount": 1,
        "content": "D is the answer"
      },
      {
        "date": "2021-11-15T14:45:00.000Z",
        "voteCount": 1,
        "content": "D looks like the nearest correct solution though this will not address with high latency with CloudSQL &amp; storage instances"
      },
      {
        "date": "2021-10-31T15:05:00.000Z",
        "voteCount": 3,
        "content": "D is correct to me.\n\nA: wrong \u2013 because increase in latency for all user requests, not for specific region. So \nB: wrong \u2013 problem affects both database and GCS\nC: wrong\n\nincrease in CPU use, and the number of processes running the application =&gt; problem is that CPU is not enough to run application processes."
      },
      {
        "date": "2021-10-28T02:34:00.000Z",
        "voteCount": 3,
        "content": "B could be useful but does not solve latency problem on Cloud Storage side"
      },
      {
        "date": "2021-10-28T02:31:00.000Z",
        "voteCount": 2,
        "content": "Ans B\nhttps://cloud.google.com/sql/docs/mysql/high-availability"
      },
      {
        "date": "2021-11-22T22:46:00.000Z",
        "voteCount": 1,
        "content": "Ans D,B has latency issues"
      },
      {
        "date": "2021-10-27T12:55:00.000Z",
        "voteCount": 2,
        "content": "A. Upgrade the GCS buckets to Multi-Regional.\nB. Enable high availability on the CloudSQL instances.\nC. Move the application from App Engine to Compute Engine.\nD. Modify the App Engine configuration to have additional idle instances.\n\nThere is nothing in the question that talks about region. If I assume that bucket is created in the region where the app is deployed\nB - Gives redundancy. I don't see how this can improve the latency\nC - Does not make any sense\nD - Additional instance, would reduce the CPU Time &amp; memory.\n\nI would go with D. But not too sure."
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 62,
    "url": "https://www.examtopics.com/discussions/google/view/64825-exam-professional-cloud-devops-engineer-topic-1-question-62/",
    "body": "Your application runs on Google Cloud Platform (GCP). You need to implement Jenkins for deploying application releases to GCP. You want to streamline the release process, lower operational toil, and keep user data secure. What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tImplement Jenkins on local workstations.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tImplement Jenkins on Kubernetes on-premises.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tImplement Jenkins on Google Cloud Functions.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tImplement Jenkins on Compute Engine virtual machines.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 10,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-12-02T04:41:00.000Z",
        "voteCount": 2,
        "content": "option D"
      },
      {
        "date": "2023-01-14T17:18:00.000Z",
        "voteCount": 3,
        "content": "D. Implement Jenkins on Compute Engine virtual machines. This will allow you to leverage GCP's security and compliance features, and integrate with other GCP services such as Cloud Storage or Cloud SQL for storing build artifacts and user data. Additionally, using Compute Engine virtual machines for Jenkins will provide flexibility in terms of scaling and managing resources."
      },
      {
        "date": "2022-10-23T06:35:00.000Z",
        "voteCount": 1,
        "content": "D is the answer."
      },
      {
        "date": "2022-02-13T04:01:00.000Z",
        "voteCount": 4,
        "content": "D - Jenkins with Compute Engine in GCP."
      },
      {
        "date": "2022-01-19T23:31:00.000Z",
        "voteCount": 4,
        "content": "D is correct"
      },
      {
        "date": "2021-11-22T18:55:00.000Z",
        "voteCount": 2,
        "content": "I am sorry ignore my previous comment, they are saying Kubernetes on Premise, not GKE (Google Managed), so I would go with GCE."
      },
      {
        "date": "2021-11-22T18:49:00.000Z",
        "voteCount": 1,
        "content": "I believe its B - GKE since they are saying reducing the toil and secure. We can use GKE secrets and also enabling autoscaling.\n\nCorrect me if my thinking is wrong"
      },
      {
        "date": "2023-03-25T23:34:00.000Z",
        "voteCount": 1,
        "content": "Option B says deploying on Kubernetes on premises not on GKE."
      },
      {
        "date": "2021-10-28T02:33:00.000Z",
        "voteCount": 4,
        "content": "he Google Compute Engine (GCE) Plugin allows you to use GCE virtual machines (VMs) with Jenkins to execute build tasks. GCE VMs provision quickly, are destroyed by Jenkins when idle, and offer Preemptible VMs that run at a much lower price than regular VMs."
      },
      {
        "date": "2021-11-06T22:49:00.000Z",
        "voteCount": 1,
        "content": "yes, Jenkins only got 2 options for GCP as of now, GKE or compute engine"
      },
      {
        "date": "2021-10-28T02:32:00.000Z",
        "voteCount": 3,
        "content": "Ans D\nhttps://plugins.jenkins.io/google-compute-engine/"
      },
      {
        "date": "2021-10-26T10:40:00.000Z",
        "voteCount": 3,
        "content": "D, GCE"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 63,
    "url": "https://www.examtopics.com/discussions/google/view/64826-exam-professional-cloud-devops-engineer-topic-1-question-63/",
    "body": "You are working with a government agency that requires you to archive application logs for seven years. You need to configure Stackdriver to export and store the logs while minimizing costs of storage. What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a Cloud Storage bucket and develop your application to send logs directly to the bucket.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDevelop an App Engine application that pulls the logs from Stackdriver and saves them in BigQuery.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate an export in Stackdriver and configure Cloud Pub/Sub to store logs in permanent storage for seven years.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a sink in Stackdriver, name it, create a bucket on Cloud Storage for storing archived logs, and then select the bucket as the log export destination.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 10,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-11-11T08:09:00.000Z",
        "voteCount": 11,
        "content": "Answer D\nhttps://cloud.google.com/logging/docs/routing/overview"
      },
      {
        "date": "2021-10-26T10:41:00.000Z",
        "voteCount": 8,
        "content": "D, sink"
      },
      {
        "date": "2023-12-02T04:42:00.000Z",
        "voteCount": 1,
        "content": "Option D"
      },
      {
        "date": "2023-01-14T17:20:00.000Z",
        "voteCount": 2,
        "content": "D. Create a sink in Stackdriver, name it, create a bucket on Cloud Storage for storing archived logs, and then select the bucket as the log export destination. This allows you to export logs from Stackdriver to a long-term storage bucket in Cloud Storage, which is a cost-effective option for long-term storage. Additionally, you can use Stackdriver's export feature to schedule regular exports and configure retention policies to keep the logs for the required seven years."
      },
      {
        "date": "2022-10-23T06:34:00.000Z",
        "voteCount": 2,
        "content": "D is the answer.\n\nhttps://cloud.google.com/logging/docs/routing/overview#destinations\nYou can use the Logs Router to route certain logs to supported destinations in any Cloud project. Logging supports the following sink destinations:\n- Cloud Storage: JSON files stored in Cloud Storage buckets; provides inexpensive, long-term storage."
      },
      {
        "date": "2022-09-27T20:44:00.000Z",
        "voteCount": 1,
        "content": "D is correct, it's actually explaining the steps to do what the question ask."
      },
      {
        "date": "2022-09-20T20:46:00.000Z",
        "voteCount": 1,
        "content": "D is correct as per Googles best practices"
      },
      {
        "date": "2022-04-22T09:22:00.000Z",
        "voteCount": 3,
        "content": "Ans: D"
      },
      {
        "date": "2022-01-19T23:32:00.000Z",
        "voteCount": 3,
        "content": "D is correct"
      },
      {
        "date": "2021-10-30T00:00:00.000Z",
        "voteCount": 4,
        "content": "ans: D"
      },
      {
        "date": "2021-10-29T11:55:00.000Z",
        "voteCount": 3,
        "content": "Ans : D"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 64,
    "url": "https://www.examtopics.com/discussions/google/view/64827-exam-professional-cloud-devops-engineer-topic-1-question-64/",
    "body": "You support a trading application written in Python and hosted on App Engine flexible environment. You want to customize the error information being sent to<br>Stackdriver Error Reporting. What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tInstall the Stackdriver Error Reporting library for Python, and then run your code on a Compute Engine VM.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tInstall the Stackdriver Error Reporting library for Python, and then run your code on Google Kubernetes Engine.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tInstall the Stackdriver Error Reporting library for Python, and then run your code on App Engine flexible environment.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse the Stackdriver Error Reporting API to write errors from your application to ReportedErrorEvent, and then generate log entries with properly formatted error messages in Stackdriver Logging.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 23,
        "isMostVoted": true
      },
      {
        "answer": "C",
        "count": 11,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2021-11-24T04:23:00.000Z",
        "voteCount": 18,
        "content": "@TNT87 - Answer is C, the link you shared has a pip install in the beginning which means Python requires installing library first.\npip install --upgrade google-cloud-error-reporting"
      },
      {
        "date": "2021-12-05T05:48:00.000Z",
        "voteCount": 1,
        "content": "Ans C https://cloud.google.com/error-reporting/docs/setup/python\ni think you can see that 1 month ago  answered it ok, the one with answer D was a mistake"
      },
      {
        "date": "2021-12-06T23:12:00.000Z",
        "voteCount": 3,
        "content": "App Engine flexible environment\nApp Engine grants the Error Reporting Writer role by default.\n\nThe Error Reporting library for Python can be used without needing to explicitly provide credentials.\n\nError Reporting is automatically enabled for App Engine flexible environment applications. No additional setup is required.\nYes anser is C \nhttps://cloud.google.com/error-reporting/docs/setup/python#app-engine"
      },
      {
        "date": "2024-05-13T00:26:00.000Z",
        "voteCount": 1,
        "content": "ReportedErrorEvent is for formatting, not customization"
      },
      {
        "date": "2024-03-07T13:41:00.000Z",
        "voteCount": 1,
        "content": "C is the answer. As it's simplest to configure with minimal effort."
      },
      {
        "date": "2024-02-03T21:37:00.000Z",
        "voteCount": 1,
        "content": "wy not D?\nWhile it's possible to use the Stackdriver Error Reporting API, it's easier and more straightforward to use the library designed specifically for the language of the application (Python, in this case).\nhttps://cloud.google.com/error-reporting/docs/setup/python#install_the_client_library"
      },
      {
        "date": "2023-12-02T04:46:00.000Z",
        "voteCount": 2,
        "content": "Option D"
      },
      {
        "date": "2023-04-09T18:54:00.000Z",
        "voteCount": 3,
        "content": "App Engine grants the Error Reporting Writer role by default.\nThe Error Reporting library for Python can be used without needing to explicitly provide credentials.Error Reporting is automatically enabled for App Engine flexible environment applications. No additional setup is required"
      },
      {
        "date": "2023-01-14T19:09:00.000Z",
        "voteCount": 2,
        "content": "C. Install the Stackdriver Error Reporting library for Python, and then run your code on App Engine flexible environment. This would allow you to customize the error information being sent to Stackdriver Error Reporting while keeping the application hosted on App Engine flexible environment."
      },
      {
        "date": "2022-12-06T10:40:00.000Z",
        "voteCount": 2,
        "content": "C) for sure\nAs per Error Reporting setup instructions for App Engine Flexible: https://cloud.google.com/error-reporting/docs/setup/app-engine-flexible-environment\n\"If you'd like to customize the error information being sent to Error Reporting, you can use the instrumentation libraries available for a number of languages\"\nWhich includes a step for installing Python client libraries https://cloud.google.com/error-reporting/docs/setup/python#installing_the_client_library"
      },
      {
        "date": "2022-12-06T07:30:00.000Z",
        "voteCount": 3,
        "content": "Ans C\nThere are two things asked here. One is Error Reporting enabled for App Engine Flex. It is based on this source - Ans D\nError Reporting Auto Enabled for App Engine Flex - Source - https://cloud.google.com/error-reporting/docs/setup/app-engine-flexible-environment\n\nSecond the question asks about customize error (not formatting the error). If you'd like to customize the error information being sent to Error Reporting, you can use the instrumentation libraries available for a number of languages: Source - https://cloud.google.com/error-reporting/docs/setup/app-engine-flexible-environment\n\nFor formatting the error then use option D - Source - https://cloud.google.com/error-reporting/docs/formatting-error-messages"
      },
      {
        "date": "2022-11-15T13:22:00.000Z",
        "voteCount": 2,
        "content": "You want to customize the error information being sent to Stackdriver Error Reporting.\nAs per Error Reporting setup instructions for App Engine Flexible: https://cloud.google.com/error-reporting/docs/setup/app-engine-flexible-environment\n\"If you'd like to customize the error information being sent to Error Reporting, you can use the instrumentation libraries available for a number of languages\"\nWhich includes a step for installing Python client libraries https://cloud.google.com/error-reporting/docs/setup/python#installing_the_client_library"
      },
      {
        "date": "2022-11-08T04:38:00.000Z",
        "voteCount": 3,
        "content": "Appeard in 7/11/2022 exam\n\nkeys: you need to customise the message + it is already on appEngine"
      },
      {
        "date": "2022-11-05T15:45:00.000Z",
        "voteCount": 2,
        "content": "isnt the question already says it is running on app engine flexible ?"
      },
      {
        "date": "2022-10-23T23:53:00.000Z",
        "voteCount": 4,
        "content": "The question ask: \"You want to customize the error information being sent\", hence for me the answer is D"
      },
      {
        "date": "2022-10-24T20:32:00.000Z",
        "voteCount": 1,
        "content": "Exactly that is the keyword triggers me D as right choice"
      },
      {
        "date": "2022-10-23T06:31:00.000Z",
        "voteCount": 2,
        "content": "D is the answer.\n\nhttps://cloud.google.com/error-reporting/docs/setup/python#app-engine\nError logs written to stderr are processed automatically by Error Reporting, without needing to use the Error Reporting library for Python directly."
      },
      {
        "date": "2022-07-22T22:51:00.000Z",
        "voteCount": 4,
        "content": "If you're using the Error Reporting API, you can report error events from your application by writing them to ReportedErrorEvent. Doing this generates log entries with properly formatted error messages in Cloud Logging.\nhttps://cloud.google.com/error-reporting/docs/formatting-error-messages"
      },
      {
        "date": "2022-07-12T16:20:00.000Z",
        "voteCount": 3,
        "content": "If you're using the Error Reporting API, you can report error events from your application by writing them to ReportedErrorEvent. Doing this generates log entries with properly formatted error messages in Cloud Logging. The resulting logName is formatted as follows:"
      },
      {
        "date": "2022-06-10T16:38:00.000Z",
        "voteCount": 2,
        "content": "D is correct.\nThere is no need to setup library Refs.: (1) https://cloud.google.com/error-reporting/docs/setup/app-engine-flexible-environment\n(2) https://cloud.google.com/error-reporting/docs/setup/python#app-engine"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 65,
    "url": "https://www.examtopics.com/discussions/google/view/64746-exam-professional-cloud-devops-engineer-topic-1-question-65/",
    "body": "You need to define Service Level Objectives (SLOs) for a high-traffic multi-region web application. Customers expect the application to always be available and have fast response times. Customers are currently happy with the application performance and availability. Based on current measurement, you observe that the<br>90<br>percentile of latency is 120ms and the 95<br>percentile of latency is 275ms over a 28-day window. What latency SLO would you recommend to the team to th th publish?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t90 percentile \u05d2\u20ac\" 100ms th 95 percentile \u05d2\u20ac\" 250ms th",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t90 percentile \u05d2\u20ac\" 120ms th 95 percentile \u05d2\u20ac\" 275ms th",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t90 percentile \u05d2\u20ac\" 150ms th 95 percentile \u05d2\u20ac\" 300ms th\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t90 percentile \u05d2\u20ac\" 250ms th 95 percentile \u05d2\u20ac\" 400ms th"
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 8,
        "isMostVoted": true
      },
      {
        "answer": "B",
        "count": 6,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2021-10-26T10:46:00.000Z",
        "voteCount": 24,
        "content": "C, https://sre.google/sre-book/service-level-objectives/ \n\"Don\u2019t pick a target based on current performance\""
      },
      {
        "date": "2021-10-25T19:52:00.000Z",
        "voteCount": 11,
        "content": "Picking an SLO based upon current performance can commit you to unnecessarily strict SLOs. Select slightly lower SLO. Will go wtih C"
      },
      {
        "date": "2024-08-25T06:18:00.000Z",
        "voteCount": 1,
        "content": "option B, why setting lower SLO !"
      },
      {
        "date": "2023-12-02T04:57:00.000Z",
        "voteCount": 1,
        "content": "Option C"
      },
      {
        "date": "2023-11-14T06:33:00.000Z",
        "voteCount": 1,
        "content": "https://www.exam-answer.com/slos-for-high-traffic-web-application"
      },
      {
        "date": "2023-03-14T05:03:00.000Z",
        "voteCount": 1,
        "content": "pick the SLO a bit higher then the current value would be better"
      },
      {
        "date": "2022-12-22T02:45:00.000Z",
        "voteCount": 1,
        "content": "C is correct answer according to https://sre.google/workbook/implementing-slos/#using-the-slis-to-calculate-starter-slos\n\"Using the SLIs to Calculate Starter SLOs\nWe can round down these SLIs to manageable numbers (e.g., two significant figures of availability, or up to 50 ms5 of latency) to obtain our starting SLOs.\""
      },
      {
        "date": "2022-12-11T19:02:00.000Z",
        "voteCount": 1,
        "content": "from SRE book: start from a loosen SLO that u can tighten better than to choose an overly strict SLO that has to be relax after u discover it is unattainable.https://sre.google/sre-book/service-level-objectives/"
      },
      {
        "date": "2022-12-11T20:15:00.000Z",
        "voteCount": 1,
        "content": "We can round down these SLIs to manageable numbers (e.g., two significant figures of availability, or up to 50 ms5 of latency) to obtain our starting SLOs. https://sre.google/workbook/implementing-slos/#continuous-improvement-of-slo-targets"
      },
      {
        "date": "2022-12-06T10:44:00.000Z",
        "voteCount": 1,
        "content": "going with B)"
      },
      {
        "date": "2022-12-06T10:43:00.000Z",
        "voteCount": 1,
        "content": "going with B)"
      },
      {
        "date": "2022-12-05T17:13:00.000Z",
        "voteCount": 1,
        "content": "Historical trend dictates customers are happy at the current performance level."
      },
      {
        "date": "2022-11-15T13:37:00.000Z",
        "voteCount": 2,
        "content": "According to this material, if the users are happy with the current not that stellar performance, the SLOs should be achievable, based on the historical values:  \nhttps://cloud.google.com/blog/products/management-tools/practical-guide-to-setting-slos\n\"It\u2019s important to set a target that is achievable so that alerts are meaningful. Normally, when choosing an SLO, it\u2019s best to start from historical trends and assume if enough people are happy with the service now, you\u2019re probably doing OK. Eventually, it\u2019s ideal to converge those numbers with aspirational targets that your business may want you to meet.\"\n\nEven though the SRE book says to avoid picking target based on the current performance https://sre.google/sre-book/service-level-objectives/ , this is in a particular context: extremely stable and high performing apps with high cost."
      },
      {
        "date": "2022-10-23T06:24:00.000Z",
        "voteCount": 1,
        "content": "C is the answer."
      },
      {
        "date": "2022-07-24T17:31:00.000Z",
        "voteCount": 2,
        "content": "Agree with C"
      },
      {
        "date": "2022-02-16T02:08:00.000Z",
        "voteCount": 2,
        "content": "SLI != SLO"
      },
      {
        "date": "2022-01-19T23:33:00.000Z",
        "voteCount": 2,
        "content": "C is correct"
      },
      {
        "date": "2021-11-11T08:26:00.000Z",
        "voteCount": 1,
        "content": "Agree with answer C"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 66,
    "url": "https://www.examtopics.com/discussions/google/view/64937-exam-professional-cloud-devops-engineer-topic-1-question-66/",
    "body": "You support a large service with a well-defined Service Level Objective (SLO). The development team deploys new releases of the service multiple times a week.<br>If a major incident causes the service to miss its SLO, you want the development team to shift its focus from working on features to improving service reliability.<br>What should you do before a major incident occurs?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDevelop an appropriate error budget policy in cooperation with all service stakeholders.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tNegotiate with the product team to always prioritize service reliability over releasing new features.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tNegotiate with the development team to reduce the release frequency to no more than once a week.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAdd a plugin to your Jenkins pipeline that prevents new releases whenever your service is out of SLO."
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 29,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2022-01-16T05:39:00.000Z",
        "voteCount": 11,
        "content": "Reason : Incident has not occurred yet, even when development team is already pushing new features multiple times a week.\nThe option A says, to define an error budget \"policy\", not to define error budget(It is already present). Just simple means to bring in all stakeholders, and decide how to consume the error budget effectively that could bring balance between feature deployment and reliability."
      },
      {
        "date": "2022-10-24T20:40:00.000Z",
        "voteCount": 1,
        "content": "Good explanation"
      },
      {
        "date": "2023-12-02T04:59:00.000Z",
        "voteCount": 1,
        "content": "Option A"
      },
      {
        "date": "2023-01-14T19:32:00.000Z",
        "voteCount": 2,
        "content": "A. Develop an appropriate error budget policy in cooperation with all service stakeholders. This will help to establish clear guidelines and expectations for service reliability, and ensure that the development team is aware of the importance of maintaining the SLO during periods of high traffic or other potential incidents. Additionally, the error budget policy will provide a clear framework for how to prioritize and respond to incidents, and ensure that the development team is able to quickly and effectively shift its focus to improving service reliability in the event of an incident."
      },
      {
        "date": "2022-12-06T10:46:00.000Z",
        "voteCount": 1,
        "content": "going with A)"
      },
      {
        "date": "2022-11-06T05:19:00.000Z",
        "voteCount": 1,
        "content": "SLO Miss Policy\n\nIf the service is performing at or above its SLO, then releases (including data changes) will proceed according to the release policy.\n\nIf the service has exceeded its error budget for the preceding four-week window, we will halt all changes and releases other than P01 issues or security fixes until the service is back within its SLO.\n\nDepending upon the cause of the SLO miss, the team may devote additional resources to working on reliability instead of feature work."
      },
      {
        "date": "2022-10-23T04:24:00.000Z",
        "voteCount": 1,
        "content": "A is the answer."
      },
      {
        "date": "2022-06-25T21:20:00.000Z",
        "voteCount": 3,
        "content": "The goals of this policy are to:\n-- Protect customers from repeated SLO misses\n-- Provide an incentive to balance reliability with other features\n\nhttps://sre.google/workbook/error-budget-policy/"
      },
      {
        "date": "2022-06-10T16:55:00.000Z",
        "voteCount": 2,
        "content": "I vote for A"
      },
      {
        "date": "2022-01-19T23:34:00.000Z",
        "voteCount": 3,
        "content": "I vote for A"
      },
      {
        "date": "2021-12-28T07:41:00.000Z",
        "voteCount": 1,
        "content": "Correct answer: A"
      },
      {
        "date": "2021-12-27T17:39:00.000Z",
        "voteCount": 2,
        "content": "the reason why A is the answer we want something that is in relation to A....Service reliability, and who needs that service to be reliable its the customer, remember as Devops engneer you must put yourself inthe shoes of a customer."
      },
      {
        "date": "2021-12-27T01:45:00.000Z",
        "voteCount": 2,
        "content": "thats the enswer"
      },
      {
        "date": "2021-12-17T08:39:00.000Z",
        "voteCount": 2,
        "content": "I don't think the answer should be A. \nError Budget = 100% - SLO.\nSince the SLO is \"well defined\", ideally the Error Budget is going to already be well defined as well."
      },
      {
        "date": "2021-12-14T16:05:00.000Z",
        "voteCount": 2,
        "content": "Correct Answer - A\nError Budget Definition: A \"Quantitative\" measurement shared between SRE &amp; product teams to balance innovation and stability.  Hence first step is defining this \"quantitative\" error budget(Answer A). Only when there is risk of exceeding error budget then negotiate with product team (stakeholder) to prioritize reliability over features (option B)"
      },
      {
        "date": "2021-12-05T14:25:00.000Z",
        "voteCount": 1,
        "content": "Correct Answer is (B):\nWhen developing for your system, think of reliability as a feature, and in fact your most important feature, as customers simply expect that things \u2018just work\u2019. \nOnce you have your objectives, reliability engineering provides practices to help you reach them, including:\n\u2022\tRedundancy systems: Such as contingencies for using backup servers\n\u2022\tFault tolerance: Such as error correction algorithms for incoming network data\n\u2022\tPreventative maintenance: Such as cycling through hardware resources before failure through overuse\n\u2022\tHuman error prevention: Such as cleaning and validating human input into the system\n\u2022\tReliability optimization: Such as writing code optimized for quick and consistent loading\nKeeping these reliability practices in mind as you develop will make your code acceptably reliable. At the same time, you\u2019re able to confidently accelerate development by evaluating it against SLOs."
      },
      {
        "date": "2021-12-05T05:53:00.000Z",
        "voteCount": 1,
        "content": "Ans B\nhttps://www.fullstory.com/blog/bootstrapping-an-availability-program-using-sre-principles/\nLets not forget the principles of availbility &amp; reliabilty"
      },
      {
        "date": "2023-12-22T02:36:00.000Z",
        "voteCount": 1,
        "content": "Ans B.\nTo define how is an error budget policy or how the error budget is being consumed is not going to avoid a major incident. The question here is: What should you do before a major incident occurs?. Nevertheless, to relase new features during a week is a bit heavy, the service realibitiy is being forgotten by that team."
      },
      {
        "date": "2021-11-11T08:30:00.000Z",
        "voteCount": 3,
        "content": "Should be A"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 67,
    "url": "https://www.examtopics.com/discussions/google/view/64742-exam-professional-cloud-devops-engineer-topic-1-question-67/",
    "body": "Your company is developing applications that are deployed on Google Kubernetes Engine (GKE). Each team manages a different application. You need to create the development and production environments for each team, while minimizing costs. Different teams should not be able to access other teams' environments.<br>What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate one GCP Project per team. In each project, create a cluster for Development and one for Production. Grant the teams IAM access to their respective clusters.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate one GCP Project per team. In each project, create a cluster with a Kubernetes namespace for Development and one for Production. Grant the teams IAM access to their respective clusters.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a Development and a Production GKE cluster in separate projects. In each cluster, create a Kubernetes namespace per team, and then configure Identity Aware Proxy so that each team can only access its own namespace.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a Development and a Production GKE cluster in separate projects. In each cluster, create a Kubernetes namespace per team, and then configure Kubernetes Role-based access control (RBAC) so that each team can only access its own namespace.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 12,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-10-28T02:55:00.000Z",
        "voteCount": 16,
        "content": "https://cloud.google.com/architecture/prep-kubernetes-engine-for-prod#roles_and_groups\nAns D"
      },
      {
        "date": "2023-01-02T22:28:00.000Z",
        "voteCount": 1,
        "content": "I think the en version is missing for some reason, translate page: https://cloud.google.com/architecture/prep-kubernetes-engine-for-prod?hl=fr#roles_and_groups"
      },
      {
        "date": "2023-12-02T05:02:00.000Z",
        "voteCount": 2,
        "content": "Option D"
      },
      {
        "date": "2023-09-06T02:25:00.000Z",
        "voteCount": 3,
        "content": "GKE has two access control systems: Identity and Access Management (IAM) and role-based access control (RBAC). IAM is Google Cloud's access control system for managing authentication and authorization for Google Cloud resources. You use IAM to grant users access to GKE and Kubernetes resources. RBAC is built into Kubernetes and grants granular permissions for specific resources and operations within your clusters."
      },
      {
        "date": "2023-09-03T08:18:00.000Z",
        "voteCount": 1,
        "content": "D is correct"
      },
      {
        "date": "2023-01-15T11:05:00.000Z",
        "voteCount": 1,
        "content": "Option D is a good approach for creating the development and production environments for each team while minimizing costs and ensuring that different teams cannot access other teams' environments. This approach involves creating a Development and Production GKE cluster in separate GCP projects. In each cluster, a Kubernetes namespace is created per team. Then, Kubernetes Role-based access control (RBAC) is configured so that each team can only access its own namespace. This ensures that the teams are isolated from each other and can only access the resources they need, while minimizing costs by using the same clusters for different teams."
      },
      {
        "date": "2022-11-08T04:39:00.000Z",
        "voteCount": 1,
        "content": "Appeard in 7/11/2022 exam\n\nkeys : least no of clusters + separation"
      },
      {
        "date": "2022-10-24T20:43:00.000Z",
        "voteCount": 1,
        "content": "D is correct"
      },
      {
        "date": "2022-10-23T04:21:00.000Z",
        "voteCount": 2,
        "content": "D is the answer."
      },
      {
        "date": "2022-10-21T15:49:00.000Z",
        "voteCount": 1,
        "content": "I vote for D as the correct answer, considering cost reduction is stated in the question."
      },
      {
        "date": "2022-02-13T06:04:00.000Z",
        "voteCount": 3,
        "content": "D - Different project for Prod and UAT. RBAC to access each app team GKE area."
      },
      {
        "date": "2022-01-19T23:40:00.000Z",
        "voteCount": 2,
        "content": "D is correct"
      },
      {
        "date": "2021-12-22T06:28:00.000Z",
        "voteCount": 2,
        "content": "The answer is D (enterprise multi-tenancy using GKE, reduce costs and control access by RBAC)"
      },
      {
        "date": "2021-11-23T03:00:00.000Z",
        "voteCount": 2,
        "content": "D -100%"
      },
      {
        "date": "2021-11-11T08:38:00.000Z",
        "voteCount": 2,
        "content": "Sound like B is good ans\n\nB. Create one GCP Project per team. In each project, create a cluster with a Kubernetes namespace for Development and one for Production. Grant the teams IAM access to their respective clusters.\n\n1 project and 1 cluster per team with 2 namespace"
      },
      {
        "date": "2021-11-22T22:39:00.000Z",
        "voteCount": 1,
        "content": "Re-read the question again....and we cant mix development and production project NO!"
      },
      {
        "date": "2021-11-18T11:19:00.000Z",
        "voteCount": 2,
        "content": "Mate you have one project per app per environment. You explaination clearly violates this basic principle"
      },
      {
        "date": "2021-10-31T15:24:00.000Z",
        "voteCount": 2,
        "content": "I go with A."
      },
      {
        "date": "2021-11-03T02:02:00.000Z",
        "voteCount": 1,
        "content": "but you have to minimize the cost"
      },
      {
        "date": "2022-01-10T15:09:00.000Z",
        "voteCount": 1,
        "content": "wrong."
      },
      {
        "date": "2021-11-15T15:25:00.000Z",
        "voteCount": 2,
        "content": "I will go with A since PROD and DEV/TEST environments need to kept separate always. Having them in the same cluster, may impact the resources for PROD when there is a need to do a load testing spinning off multiple PODs and nodes"
      },
      {
        "date": "2021-12-26T02:01:00.000Z",
        "voteCount": 1,
        "content": "https://www.google.com/search?q=For+almost+all+cases%2C+Kubernetes+RBAC+can+be+used+instead+of+IAM.+GKE+users+require+at+minimum%2C+the+container.clusters.get+IAM+permission+in+the+project+...&amp;oq=For+almost+all+cases%2C+Kubernetes+RBAC+can+be+used+instead+of+IAM.+GKE+users+require+at+minimum%2C+the+container.clusters.get+IAM+permission+in+the+project+...&amp;aqs=chrome..69i57.479j0j7&amp;sourceid=chrome&amp;ie=UTF-8"
      },
      {
        "date": "2021-10-29T11:58:00.000Z",
        "voteCount": 3,
        "content": "Ans: D"
      },
      {
        "date": "2021-10-25T19:28:00.000Z",
        "voteCount": 3,
        "content": "Will go with D"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 68,
    "url": "https://www.examtopics.com/discussions/google/view/64743-exam-professional-cloud-devops-engineer-topic-1-question-68/",
    "body": "Some of your production services are running in Google Kubernetes Engine (GKE) in the eu-west-1 region. Your build system runs in the us-west-1 region. You want to push the container images from your build system to a scalable registry to maximize the bandwidth for transferring the images to the cluster. What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tPush the images to Google Container Registry (GCR) using the gcr.io hostname.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tPush the images to Google Container Registry (GCR) using the us.gcr.io hostname.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tPush the images to Google Container Registry (GCR) using the eu.gcr.io hostname.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tPush the images to a private image registry running on a Compute Engine instance in the eu-west-1 region."
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 9,
        "isMostVoted": true
      },
      {
        "answer": "B",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2021-10-25T19:30:00.000Z",
        "voteCount": 18,
        "content": "To maximize the bandwidth for transferring the images to the cluster, one needs the the registry to be closer to the production or system where it needs to be deployed. I would go with C, since the production system is in Europe."
      },
      {
        "date": "2023-12-19T06:47:00.000Z",
        "voteCount": 1,
        "content": "It says PUSH!!! The building system is in US so the best option to push is US."
      },
      {
        "date": "2024-08-02T13:03:00.000Z",
        "voteCount": 1,
        "content": "Nope, you forgot about 'maximize the bandwidth' for transferring the images to the cluster, and the best option is allocate imagens in the same cluster region ;)"
      },
      {
        "date": "2023-12-02T05:05:00.000Z",
        "voteCount": 1,
        "content": "Option C"
      },
      {
        "date": "2023-09-03T08:24:00.000Z",
        "voteCount": 1,
        "content": "C is the answer."
      },
      {
        "date": "2023-01-15T11:20:00.000Z",
        "voteCount": 2,
        "content": "C. Pushing the images to Google Container Registry (GCR) using the eu.gcr.io hostname will allow the images to be transferred to the GKE cluster in the eu-west-1 region with the best possible network performance. This will minimize the latency when the cluster pulls the images from the registry, maximizing the bandwidth for transferring the images to the cluster."
      },
      {
        "date": "2022-11-08T04:41:00.000Z",
        "voteCount": 4,
        "content": "Appeard in 7/11/2022 exam\n\nthe answers were different in the exam. \nthey are like a) us-docker.pkg.dev , b)europe-docker.pkg.dev c)europe-west1-docker.dev.pkg 4)private registry. \nanswer : europe-docker.pkg.dev"
      },
      {
        "date": "2022-12-21T19:10:00.000Z",
        "voteCount": 2,
        "content": "c)europe-west1-docker.dev.pkg  \nlooks correct"
      },
      {
        "date": "2023-12-22T02:59:00.000Z",
        "voteCount": 1,
        "content": "I think you should answer C), because it exists the specific $LOCATION look at -&gt; https://cloud.google.com/artifact-registry/docs/repositories/repo-locations\nAs well, you can find some examples how to use it -&gt; https://cloud.google.com/artifact-registry/docs/docker/copy-images"
      },
      {
        "date": "2022-10-23T04:18:00.000Z",
        "voteCount": 3,
        "content": "C is the answer.\n\nhttps://cloud.google.com/container-registry/docs/pushing-and-pulling#add-registry\n- eu.gcr.io -&gt; Stores images in data centers within member states of the European Union"
      },
      {
        "date": "2022-10-16T18:38:00.000Z",
        "voteCount": 1,
        "content": "when i see this question,the option aren't those.The four option are eu.xxx,one of those, is  eu-west-1.xxx,please notice."
      },
      {
        "date": "2022-09-27T07:38:00.000Z",
        "voteCount": 1,
        "content": "c is the ans"
      },
      {
        "date": "2022-07-26T05:49:00.000Z",
        "voteCount": 1,
        "content": "It seems possible to choose the GCR region (I didn't know) https://cloud.google.com/container-registry/docs/pushing-and-pulling, therefore to maximize bandwidth to the the cluster (in europe) we must choose C (eu.gcr.io)."
      },
      {
        "date": "2022-02-16T02:16:00.000Z",
        "voteCount": 2,
        "content": "Same region."
      },
      {
        "date": "2022-01-19T23:40:00.000Z",
        "voteCount": 2,
        "content": "C is correct"
      },
      {
        "date": "2021-11-11T08:51:00.000Z",
        "voteCount": 2,
        "content": "C for sure"
      },
      {
        "date": "2021-11-04T22:59:00.000Z",
        "voteCount": 4,
        "content": "It's C - because of GDPR compliance.\n\nHostname\tStorage location\ngcr.io\tStores images in data centers in the United States\nasia.gcr.io\tStores images in data centers in Asia\neu.gcr.io\tStores images in data centers within member states of the European Union\nus.gcr.io\tStores images in data centers in the United States"
      },
      {
        "date": "2021-10-30T00:42:00.000Z",
        "voteCount": 3,
        "content": "C could be correct, but also D is nearer because in the same zone. A and B are are both in US"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 69,
    "url": "https://www.examtopics.com/discussions/google/view/64830-exam-professional-cloud-devops-engineer-topic-1-question-69/",
    "body": "You manage several production systems that run on Compute Engine in the same Google Cloud Platform (GCP) project. Each system has its own set of dedicated Compute Engine instances. You want to know how must it costs to run each of the systems. What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tIn the Google Cloud Platform Console, use the Cost Breakdown section to visualize the costs per system.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAssign all instances a label specific to the system they run. Configure BigQuery billing export and query costs per label.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEnrich all instances with metadata specific to the system they run. Configure Stackdriver Logging to export to BigQuery, and query costs based on the metadata.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tName each virtual machine (VM) after the system it runs. Set up a usage report export to a Cloud Storage bucket. Configure the bucket as a source in BigQuery to query costs based on VM name."
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 12,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-10-28T03:08:00.000Z",
        "voteCount": 14,
        "content": "https://cloud.google.com/billing/docs/how-to/export-data-bigquery; B"
      },
      {
        "date": "2023-12-02T05:59:00.000Z",
        "voteCount": 2,
        "content": "option B"
      },
      {
        "date": "2023-11-14T07:19:00.000Z",
        "voteCount": 2,
        "content": "B is correct, it is the fastest solution and allows you to group by label"
      },
      {
        "date": "2023-09-03T22:21:00.000Z",
        "voteCount": 1,
        "content": "B is correct"
      },
      {
        "date": "2023-01-15T11:22:00.000Z",
        "voteCount": 2,
        "content": "B. Assign all instances a label specific to the system they run. Configure BigQuery billing export and query costs per label. is the correct answer.\nUsing labels to tag instances with the specific system they run allows you to easily filter and query costs by system in BigQuery. This allows you to see the costs associated with each system and make informed decisions about cost optimization."
      },
      {
        "date": "2022-10-23T04:15:00.000Z",
        "voteCount": 1,
        "content": "B is the answer.\n\nhttps://cloud.google.com/billing/docs/how-to/bq-examples#query-with-labels"
      },
      {
        "date": "2022-09-20T20:56:00.000Z",
        "voteCount": 2,
        "content": "B is the correct answer, labes are Google's best practices to break down costs per units"
      },
      {
        "date": "2022-01-19T23:47:00.000Z",
        "voteCount": 2,
        "content": "B is correct"
      },
      {
        "date": "2021-12-17T08:51:00.000Z",
        "voteCount": 1,
        "content": "https://cloud.google.com/billing/docs/how-to/export-data-bigquery"
      },
      {
        "date": "2021-11-11T08:54:00.000Z",
        "voteCount": 4,
        "content": "B. U NEED TO ADD LABELS TO INSTANCE FOR COST visibility"
      },
      {
        "date": "2021-10-26T10:50:00.000Z",
        "voteCount": 3,
        "content": "B, labels"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 70,
    "url": "https://www.examtopics.com/discussions/google/view/65085-exam-professional-cloud-devops-engineer-topic-1-question-70/",
    "body": "You use Cloud Build to build and deploy your application. You want to securely incorporate database credentials and other application secrets into the build pipeline. You also want to minimize the development effort. What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a Cloud Storage bucket and use the built-in encryption at rest. Store the secrets in the bucket and grant Cloud Build access to the bucket.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEncrypt the secrets and store them in the application repository. Store a decryption key in a separate repository and grant Cloud Build access to the repository.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse client-side encryption to encrypt the secrets and store them in a Cloud Storage bucket. Store a decryption key in the bucket and grant Cloud Build access to the bucket.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse Cloud Key Management Service (Cloud KMS) to encrypt the secrets and include them in your Cloud Build deployment configuration. Grant Cloud Build access to the KeyRing.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 6,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-11-02T01:39:00.000Z",
        "voteCount": 16,
        "content": "Ans is  D"
      },
      {
        "date": "2023-12-02T06:00:00.000Z",
        "voteCount": 1,
        "content": "option D"
      },
      {
        "date": "2023-11-15T01:37:00.000Z",
        "voteCount": 1,
        "content": "https://cloud.google.com/build/docs/securing-builds/use-encrypted-credentials#configuring_builds_to_use_encrypted_data"
      },
      {
        "date": "2023-01-15T11:24:00.000Z",
        "voteCount": 1,
        "content": "D. Use Cloud Key Management Service (Cloud KMS) to encrypt the secrets and include them in your Cloud Build deployment configuration. Grant Cloud Build access to the KeyRing. This option allows you to use Google-managed encryption and access controls, and it also minimizes the development effort required to securely incorporate the secrets into the build pipeline."
      },
      {
        "date": "2022-10-23T04:11:00.000Z",
        "voteCount": 2,
        "content": "D is the answer."
      },
      {
        "date": "2022-10-21T16:58:00.000Z",
        "voteCount": 2,
        "content": "Answer should be D in this case."
      },
      {
        "date": "2022-06-18T03:19:00.000Z",
        "voteCount": 2,
        "content": "Ans: D\n\nUsing encrypted credentials from Cloud KMS\nhttps://cloud.google.com/build/docs/securing-builds/use-encrypted-credentials"
      },
      {
        "date": "2022-04-22T09:30:00.000Z",
        "voteCount": 1,
        "content": "Ans: D"
      },
      {
        "date": "2022-01-20T00:02:00.000Z",
        "voteCount": 2,
        "content": "D is correct"
      },
      {
        "date": "2021-10-29T12:00:00.000Z",
        "voteCount": 4,
        "content": "Ans: D"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 71,
    "url": "https://www.examtopics.com/discussions/google/view/64832-exam-professional-cloud-devops-engineer-topic-1-question-71/",
    "body": "You support a popular mobile game application deployed on Google Kubernetes Engine (GKE) across several Google Cloud regions. Each region has multiple<br>Kubernetes clusters. You receive a report that none of the users in a specific region can connect to the application. You want to resolve the incident while following Site Reliability Engineering practices. What should you do first?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tReroute the user traffic from the affected region to other regions that don't report issues.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse Stackdriver Monitoring to check for a spike in CPU or memory usage for the affected region.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAdd an extra node pool that consists of high memory and high CPU machine type instances to the cluster.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse Stackdriver Logging to filter on the clusters in the affected region, and inspect error messages in the logs."
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 12,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-10-26T10:52:00.000Z",
        "voteCount": 16,
        "content": "A, reroute trafic to unblock access to site."
      },
      {
        "date": "2023-12-02T06:01:00.000Z",
        "voteCount": 2,
        "content": "option  A"
      },
      {
        "date": "2023-01-15T11:31:00.000Z",
        "voteCount": 3,
        "content": "My answer would be option A, to reroute user traffic from the affected region to other regions that don't report issues, in order to immediately resolve the problem for users and minimize impact, and then use option D, Stackdriver Logging, to investigate the root cause of the issue. This approach aligns with SRE best practices of resolving incidents quickly and then conducting a post-mortem analysis to prevent similar incidents from happening in the future."
      },
      {
        "date": "2022-10-23T04:08:00.000Z",
        "voteCount": 1,
        "content": "A is the answer."
      },
      {
        "date": "2022-01-29T07:19:00.000Z",
        "voteCount": 4,
        "content": "Google always aims to first stop the impact of an incident, and then find the root cause (unless the root cause just happens to be identified early on)."
      },
      {
        "date": "2022-01-20T00:10:00.000Z",
        "voteCount": 1,
        "content": "A is correct"
      },
      {
        "date": "2022-01-16T05:56:00.000Z",
        "voteCount": 2,
        "content": "Issue is that one region is not serving requests. First thing to resolve is make the application responsive to users as soon as possible affected by this issue. Look into the error logs later."
      },
      {
        "date": "2021-11-11T08:56:00.000Z",
        "voteCount": 2,
        "content": "A. Reroute the traffic first"
      },
      {
        "date": "2021-11-06T23:23:00.000Z",
        "voteCount": 3,
        "content": "A - resume service first"
      },
      {
        "date": "2021-11-05T02:03:00.000Z",
        "voteCount": 2,
        "content": "Anyone available for didscussion please lets collaborate"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 72,
    "url": "https://www.examtopics.com/discussions/google/view/64834-exam-professional-cloud-devops-engineer-topic-1-question-72/",
    "body": "You are writing a postmortem for an incident that severely affected users. You want to prevent similar incidents in the future. Which two of the following sections should you include in the postmortem? (Choose two.)<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAn explanation of the root cause of the incident.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tA list of employees responsible for causing the incident",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tA list of action items to prevent a recurrence of the incident\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tYour opinion of the incident's severity compared to past incidents",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCopies of the design documents for all the services impacted by the incident"
    ],
    "answer": "AC",
    "answerDescription": "",
    "votes": [
      {
        "answer": "AC",
        "count": 10,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-10-27T02:00:00.000Z",
        "voteCount": 17,
        "content": "Ans is AC"
      },
      {
        "date": "2021-10-29T12:01:00.000Z",
        "voteCount": 7,
        "content": "Ans: AC"
      },
      {
        "date": "2023-12-02T06:02:00.000Z",
        "voteCount": 1,
        "content": "option  A and C"
      },
      {
        "date": "2023-01-15T11:34:00.000Z",
        "voteCount": 2,
        "content": "A. An explanation of the root cause of the incident.\nC. A list of action items to prevent a recurrence of the incident."
      },
      {
        "date": "2022-11-26T10:39:00.000Z",
        "voteCount": 1,
        "content": "Ans A&amp;C. B is incorrect as SRE recommends blameless culture and listing employees responsible portrays blaming the incident on employees responsible."
      },
      {
        "date": "2022-11-26T02:11:00.000Z",
        "voteCount": 1,
        "content": "clearly its AC"
      },
      {
        "date": "2022-10-23T04:06:00.000Z",
        "voteCount": 2,
        "content": "AC is the answer."
      },
      {
        "date": "2022-01-29T07:23:00.000Z",
        "voteCount": 3,
        "content": "For a postmortem to be truly blameless, it must focus on identifying the contributing causes of the incident without indicting any individual or team for bad or inappropriate behavior."
      },
      {
        "date": "2022-01-20T00:11:00.000Z",
        "voteCount": 1,
        "content": "A and C are correct"
      },
      {
        "date": "2022-01-16T05:58:00.000Z",
        "voteCount": 2,
        "content": "Why it occurred? and How to avoid?\nNever choose an answer that blames a human."
      },
      {
        "date": "2021-11-06T23:23:00.000Z",
        "voteCount": 5,
        "content": "A n C are correct"
      },
      {
        "date": "2021-10-27T02:05:00.000Z",
        "voteCount": 1,
        "content": "https://cloud.google.com/blog/products/gcp/fearless-shared-postmortems-cre-life-lessons"
      },
      {
        "date": "2021-10-26T10:54:00.000Z",
        "voteCount": 4,
        "content": "A,C explanation + list of actions to prevent in the future"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 73,
    "url": "https://www.examtopics.com/discussions/google/view/65003-exam-professional-cloud-devops-engineer-topic-1-question-73/",
    "body": "You are ready to deploy a new feature of a web-based application to production. You want to use Google Kubernetes Engine (GKE) to perform a phased rollout to half of the web server pods.<br>What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse a partitioned rolling update.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse Node taints with NoExecute.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse a replica set in the deployment specification.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse a stateful set with parallel pod management policy."
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 12,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-10-28T04:56:00.000Z",
        "voteCount": 12,
        "content": "I do agree to A as the answer."
      },
      {
        "date": "2023-12-02T06:40:00.000Z",
        "voteCount": 2,
        "content": "option A"
      },
      {
        "date": "2023-01-15T11:38:00.000Z",
        "voteCount": 2,
        "content": "A partitioned rolling update allows you to control the percentage of pods that are updated at a time, which allows you to perform a phased rollout. This way you can incrementally test and monitor the new feature, before it is deployed to all the pods. This approach is useful when you want to minimize the risk of introducing new bugs or breaking changes in your production environment, it allows you to have more control over the process, and it's less likely to cause service disruption, or to have all the pods down at the same time."
      },
      {
        "date": "2023-01-15T11:40:00.000Z",
        "voteCount": 2,
        "content": "B. Using Node taints with NoExecute could be used to prevent pods from being scheduled on certain nodes, but it would not be the best option for a phased rollout as it does not allow for a specific percentage or number of pods to be updated.\nC. A replica set in the deployment specification is used for ensuring that a specified number of replicas of a pod are running at any given time, but it does not provide a way to perform a phased rollout.\nD. A stateful set with parallel pod management policy is used for managing stateful applications, but it also does not provide a way to perform a phased rollout.\nThe option A, Using a partitioned rolling update, allows you to specify the percentage of pods that should be updated at a time, so it is the best option for performing a phased rollout."
      },
      {
        "date": "2022-12-06T11:08:00.000Z",
        "voteCount": 1,
        "content": "going with A) since is the only which makes sense"
      },
      {
        "date": "2022-10-25T03:34:00.000Z",
        "voteCount": 1,
        "content": "A is right https://cloud.google.com/kubernetes-engine/docs/concepts/statefulset#partitioning_rolling_updates\nPartitioning is useful if you want to stage an update, roll out a canary, or perform a phased roll out.\n\nWhen you partition an update, all Pods with an ordinal greater than or equal to the partition value are updated when you update the StatefulSet\u2019s Pod specification. Pods with an ordinal less than the partition value are not updated and, even if they are deleted, are recreated using the previous version of the specification. If the partition value is greater than the number of replicas, the updates are not propagated to the Pods."
      },
      {
        "date": "2022-10-23T04:03:00.000Z",
        "voteCount": 4,
        "content": "A is the answer.\nhttps://cloud.google.com/kubernetes-engine/docs/how-to/updating-apps#partitioning_a_rollingupdate\nPartitioning is useful if you want to stage an update, roll out a canary, or perform a phased roll out."
      },
      {
        "date": "2022-09-27T20:54:00.000Z",
        "voteCount": 3,
        "content": "A is the clear answer"
      },
      {
        "date": "2022-01-20T00:12:00.000Z",
        "voteCount": 2,
        "content": "A is correct"
      },
      {
        "date": "2022-01-14T09:16:00.000Z",
        "voteCount": 3,
        "content": "A - the question is incomplete ! Nothing shows that we are using statefulsets .."
      },
      {
        "date": "2022-04-18T21:49:00.000Z",
        "voteCount": 2,
        "content": "IMHO, the question mentioned:  a \"PHASED ROLLOUT\" to \"HALF\" of the web server pods. \nSo we use .spec.updateStrategy field to partition a RollingUpdate  for the Pods in a StatefulSet."
      },
      {
        "date": "2021-12-18T20:19:00.000Z",
        "voteCount": 3,
        "content": "A =&gt; https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#partitions"
      },
      {
        "date": "2021-12-17T09:00:00.000Z",
        "voteCount": 2,
        "content": "https://cloud.google.com/kubernetes-engine/docs/how-to/updating-apps#partitioning_a_rollingupdate\n\npartition rollout only works if the workload is stateful. Nothing in the question tells us this."
      },
      {
        "date": "2021-11-10T01:43:00.000Z",
        "voteCount": 2,
        "content": "A\nhttps://medium.com/velotio-perspectives/exploring-upgrade-strategies-for-stateful-sets-in-kubernetes-c02b8286f251"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 74,
    "url": "https://www.examtopics.com/discussions/google/view/65079-exam-professional-cloud-devops-engineer-topic-1-question-74/",
    "body": "You are responsible for the reliability of a high-volume enterprise application. A large number of users report that an important subset of the application's functionality `\" a data intensive reporting feature `\" is consistently failing with an HTTP 500 error. When you investigate your application's dashboards, you notice a strong correlation between the failures and a metric that represents the size of an internal queue used for generating reports. You trace the failures to a reporting backend that is experiencing high I/O wait times. You quickly fix the issue by resizing the backend's persistent disk (PD). How you need to create an availability<br>Service Level Indicator (SLI) for the report generation feature. How would you define it?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAs the I/O wait times aggregated across all report generation backends",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAs the proportion of report generation requests that result in a successful response\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAs the application's report generation queue size compared to a known-good threshold",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAs the reporting backend PD throughout capacity compared to a known-good threshold"
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 9,
        "isMostVoted": true
      },
      {
        "answer": "C",
        "count": 2,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2021-10-31T15:45:00.000Z",
        "voteCount": 19,
        "content": "The question is: \"create an availability SLI for the report generation feature.\" =&gt; availability.\n\nB is correct.\nOthers aren't availability SLI."
      },
      {
        "date": "2021-11-06T23:32:00.000Z",
        "voteCount": 3,
        "content": "B is more like SLO rather than SLI."
      },
      {
        "date": "2021-11-10T01:53:00.000Z",
        "voteCount": 7,
        "content": "B is correct, availability = good time/ total time."
      },
      {
        "date": "2021-11-11T18:50:00.000Z",
        "voteCount": 3,
        "content": "AGREE WITH B"
      },
      {
        "date": "2023-12-18T16:18:00.000Z",
        "voteCount": 1,
        "content": "C and D are SLOs (they use a threshold). B seems to be more like an indicator and didn't rely exclusivelly on PD's I/O. Any issue that disturb the correct reports finalization could be detected with this SLI"
      },
      {
        "date": "2023-12-02T06:44:00.000Z",
        "voteCount": 1,
        "content": "option  B"
      },
      {
        "date": "2023-09-03T23:14:00.000Z",
        "voteCount": 1,
        "content": "B is correct."
      },
      {
        "date": "2023-01-15T11:49:00.000Z",
        "voteCount": 2,
        "content": "B. As the proportion of report generation requests that result in a successful response is a valid availability Service Level Indicator (SLI) for the report generation feature. This indicator measures the percentage of requests for report generation that are successfully completed, and it is an indicator of the service availability. This SLI provides a clear and measurable way to track the availability of the report generation feature. It is a simple and easy to understand metric, that it can be easily monitored and reported. It can be used to track the performance of the report generation feature over time and detect any potential issues that may cause it to become unavailable. It also allows you to detect and diagnose issues in the system quickly and take appropriate action to mitigate them. Additionally, it aligns well with the customer's expectation of the report generation feature as they want to see a high percentage of successful report generation requests, which indicates that the feature is working correctly."
      },
      {
        "date": "2022-12-20T13:40:00.000Z",
        "voteCount": 2,
        "content": "https://cloud.google.com/stackdriver/docs/solutions/slo-monitoring/sli-metrics/overview?hl=pt-br"
      },
      {
        "date": "2022-12-20T22:40:00.000Z",
        "voteCount": 1,
        "content": "ANS BBB see link"
      },
      {
        "date": "2022-10-23T04:00:00.000Z",
        "voteCount": 1,
        "content": "B is the answer."
      },
      {
        "date": "2022-04-18T23:14:00.000Z",
        "voteCount": 4,
        "content": "Answer : B. the proportion of report generation requests that result in a successful response\n\nQuestion: create an AVAILABILITY SLI for the report generation feature\n\nAccording to SRE Workbook, one of potential SLI is as below:\n* Type of service: Request-driven\n* Type of SLI: Availability\n* Description: The proportion of requests that resulted in a successful response.\n\nhttps://sre.google/workbook/implementing-slos/"
      },
      {
        "date": "2022-03-27T11:07:00.000Z",
        "voteCount": 2,
        "content": "B is correct"
      },
      {
        "date": "2022-01-29T07:32:00.000Z",
        "voteCount": 2,
        "content": "Service Level Indicator, is a key metric used to determine whether or not the SLO is being met.\nTo prevent overcomplicating things, it\u2019s important to keep things simple and choose the right key metrics to monitor. Here Queue size is the key metric."
      },
      {
        "date": "2022-01-20T00:14:00.000Z",
        "voteCount": 1,
        "content": "B is correct"
      },
      {
        "date": "2022-01-16T06:04:00.000Z",
        "voteCount": 3,
        "content": "Eliminate A,\nEliminate C and D. SLI are always based on facts, not on KNOWN GOOD\nAnswer B : good/total"
      },
      {
        "date": "2021-12-27T02:40:00.000Z",
        "voteCount": 2,
        "content": "B B B B is the answer!"
      },
      {
        "date": "2021-10-30T07:40:00.000Z",
        "voteCount": 2,
        "content": "should be D.. since the throughput and IOPS become the issue"
      },
      {
        "date": "2021-10-30T01:50:00.000Z",
        "voteCount": 2,
        "content": "Why not C, you already have a metric that represents the size of an internal queue"
      },
      {
        "date": "2021-10-29T09:03:00.000Z",
        "voteCount": 1,
        "content": "D for sure"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 75,
    "url": "https://www.examtopics.com/discussions/google/view/64835-exam-professional-cloud-devops-engineer-topic-1-question-75/",
    "body": "You have an application running in Google Kubernetes Engine. The application invokes multiple services per request but responds too slowly. You need to identify which downstream service or services are causing the delay. What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAnalyze VPC flow logs along the path of the request.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tInvestigate the Liveness and Readiness probes for each service.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a Dataflow pipeline to analyze service metrics in real time.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse a distributed tracing framework such as OpenTelemetry or Stackdriver Trace.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 19,
        "isMostVoted": true
      },
      {
        "answer": "C",
        "count": 3,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2021-10-26T10:56:00.000Z",
        "voteCount": 22,
        "content": "D, opentelemetry"
      },
      {
        "date": "2022-03-15T02:50:00.000Z",
        "voteCount": 9,
        "content": "This is the major usecase for Cloud Trace"
      },
      {
        "date": "2023-12-02T06:45:00.000Z",
        "voteCount": 1,
        "content": "Option D"
      },
      {
        "date": "2023-01-15T12:43:00.000Z",
        "voteCount": 2,
        "content": "D. Use a distributed tracing framework such as OpenTelemetry or Stackdriver Trace. Distributed tracing allows you to trace the path of a request as it travels through multiple services and identify where delays may be occurring. This can provide detailed information about the request and response timings for each service, making it easier to pinpoint which services are causing delays in your application. OpenTelemetry and Stackdriver Trace are both available on GCP, and provide easy integration with Kubernetes and other GCP services."
      },
      {
        "date": "2022-10-23T03:57:00.000Z",
        "voteCount": 2,
        "content": "D is the answer.\n\nhttps://cloud.google.com/trace/docs/overview\nCloud Trace, a distributed tracing system for Google Cloud, helps you understand how long it takes your application to handle incoming requests from users or other applications, and how long it takes to complete operations like RPC calls performed when handling the requests."
      },
      {
        "date": "2022-10-21T02:31:00.000Z",
        "voteCount": 2,
        "content": "Cloud Trace is a distributed tracing system that collects latency data from your applications and displays it in the Google Cloud Console."
      },
      {
        "date": "2022-03-27T11:12:00.000Z",
        "voteCount": 3,
        "content": "D is correct"
      },
      {
        "date": "2022-01-29T07:50:00.000Z",
        "voteCount": 3,
        "content": "Correct answer is C. \nCheck this link - https://cloud.google.com/architecture/processing-logs-at-scale-using-dataflow?hl=en\nD cannot be the answer because Strackdriver tracing is useful in troubleshooting a single application ( providing a lot of information). Here ques is about multiple services in the downstream. Read the ques carefully."
      },
      {
        "date": "2022-01-20T00:16:00.000Z",
        "voteCount": 1,
        "content": "D is correct"
      },
      {
        "date": "2021-12-07T17:43:00.000Z",
        "voteCount": 1,
        "content": "https://cloud.google.com/dataflow/docs/guides/using-monitoring-intf"
      },
      {
        "date": "2021-12-07T11:34:00.000Z",
        "voteCount": 1,
        "content": "This solution also explains how you can change the pipeline to run in streaming mode, for low-latency, asynchronous log processing"
      },
      {
        "date": "2021-12-07T11:30:00.000Z",
        "voteCount": 2,
        "content": "https://cloud.google.com/architecture/processing-logs-at-scale-using-dataflow?hl=en\nKindly read this and say why is C wrong"
      },
      {
        "date": "2022-03-09T09:15:00.000Z",
        "voteCount": 2,
        "content": "Dataflow is for logs. Here we need metrics"
      },
      {
        "date": "2021-11-02T00:48:00.000Z",
        "voteCount": 4,
        "content": "Ans: D"
      },
      {
        "date": "2021-11-01T10:36:00.000Z",
        "voteCount": 1,
        "content": "B is correct"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 76,
    "url": "https://www.examtopics.com/discussions/google/view/64837-exam-professional-cloud-devops-engineer-topic-1-question-76/",
    "body": "You are creating and assigning action items in a postmodern for an outage. The outage is over, but you need to address the root causes. You want to ensure that your team handles the action items quickly and efficiently. How should you assign owners and collaborators to action items?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAssign one owner for each action item and any necessary collaborators.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAssign multiple owners for each item to guarantee that the team addresses items quickly.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAssign collaborators but no individual owners to the items to keep the postmortem blameless.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAssign the team lead as the owner for all action items because they are in charge of the SRE team."
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 7,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-11-03T02:58:00.000Z",
        "voteCount": 13,
        "content": "A is correct. Each action item should have one owner."
      },
      {
        "date": "2021-11-11T19:04:00.000Z",
        "voteCount": 5,
        "content": "Agree with A"
      },
      {
        "date": "2021-11-11T19:07:00.000Z",
        "voteCount": 3,
        "content": "https://sre.google/sre-book/example-postmortem/"
      },
      {
        "date": "2023-12-02T06:46:00.000Z",
        "voteCount": 1,
        "content": "option  A"
      },
      {
        "date": "2023-01-24T01:39:00.000Z",
        "voteCount": 2,
        "content": "A. Assign one owner for each action item and any necessary collaborators.\nIt is important to have a clear ownership for each action item, so that there is no confusion about who is responsible for the task and it will be easier to track the progress and follow up if there is any delay. The owner should also be given the necessary authority and resources to carry out the task. The necessary collaborators should also be assigned to support the owner in completing the task efficiently."
      },
      {
        "date": "2023-01-15T12:46:00.000Z",
        "voteCount": 1,
        "content": "A. Assign one owner for each action item and any necessary collaborators. This will ensure clear accountability and ownership for each action item, and the necessary collaborators can provide support and expertise to the owner in completing the action item. This approach allows for clear communication and delegation of responsibilities, which can help ensure that the action items are handled quickly and efficiently."
      },
      {
        "date": "2022-12-08T14:41:00.000Z",
        "voteCount": 1,
        "content": "task list can indeed have a done, even if he is not the one to execute it, this does not place the blame on anyone.\nhttps://medium.com/thumbtack-engineering/blameless-incident-postmortems-at-thumbtack-c9a47e29efc4"
      },
      {
        "date": "2022-10-23T03:51:00.000Z",
        "voteCount": 1,
        "content": "A is the answer."
      },
      {
        "date": "2022-02-21T09:27:00.000Z",
        "voteCount": 2,
        "content": "TNT87 explains it well\n\"Actions items without clear owners are less likely to be resolved.\nIt\u2019s better to have a single owner and multiple collaborators.\""
      },
      {
        "date": "2022-01-20T00:17:00.000Z",
        "voteCount": 2,
        "content": "A is correct"
      },
      {
        "date": "2021-12-27T02:43:00.000Z",
        "voteCount": 4,
        "content": "The fact that the the question  STRESSES that the outage is OVER ust give you a clue.\nCheck what google SRE  book says\n\nMissing ownership\nDeclaring official ownership results in accountability, which leads to action. Our example postmortem contains several examples of missing ownership:\n\nThe postmortem lists four owners. Ideally, an owner is a single point of contact who is responsible for the postmortem, follow-up, and completion.\nThe Action Items section has little or no ownership for its entries. Actions items without clear owners are less likely to be resolved.\nIt\u2019s better to have a single owner and multiple collaborators."
      },
      {
        "date": "2021-12-25T05:01:00.000Z",
        "voteCount": 1,
        "content": "https://devops.com/when-it-disaster-strikes-part-3-conducting-a-blameless-post-mortem/\nthen its A"
      },
      {
        "date": "2021-12-25T05:10:00.000Z",
        "voteCount": 1,
        "content": "Missing ownership\nDeclaring official ownership results in accountability, which leads to action. Our example postmortem contains several examples of missing ownership:\n\nThe postmortem lists four owners. Ideally, an owner is a single point of contact who is responsible for the postmortem, follow-up, and completion.\nThe Action Items section has little or no ownership for its entries. Actions items without clear owners are less likely to be resolved.\nIt\u2019s better to have a single owner and multiple collaborators."
      },
      {
        "date": "2021-12-06T22:35:00.000Z",
        "voteCount": 1,
        "content": "Either A or C, \nFor answer C, the principles of postmortem culture it's blameless\nBlameless postmortems are a tenet of SRE culture. For a postmortem to be truly blameless, it must focus on identifying the contributing causes of the incident without indicting any individual or team for bad or inappropriate behavior. \nhttps://sre.google/sre-book/postmortem-culture/\n\nHowever looking at the postmortem example, each assignment has an owner\nhttps://sre.google/sre-book/example-postmortem/"
      },
      {
        "date": "2021-10-26T11:00:00.000Z",
        "voteCount": 4,
        "content": "C, https://sre.google/sre-book/postmortem-culture/"
      },
      {
        "date": "2021-11-11T19:06:00.000Z",
        "voteCount": 2,
        "content": "ans is A, mate"
      },
      {
        "date": "2021-12-05T06:55:00.000Z",
        "voteCount": 1,
        "content": "the answer is C because this must be kept blameless..."
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 77,
    "url": "https://www.examtopics.com/discussions/google/view/65247-exam-professional-cloud-devops-engineer-topic-1-question-77/",
    "body": "Your development team has created a new version of their service's API. You need to deploy the new versions of the API with the least disruption to third-party developers and end users of third-party installed applications. What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tIntroduce the new version of the API. Announce deprecation of the old version of the API. Deprecate the old version of the API. Contact remaining users of the old API. Provide best effort support to users of the old API. Turn down the old version of the API.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAnnounce deprecation of the old version of the API. Introduce the new version of the API. Contact remaining users on the old API. Deprecate the old version of the API. Turn down the old version of the API. Provide best effort support to users of the old API.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAnnounce deprecation of the old version of the API. Contact remaining users on the old API. Introduce the new version of the API. Deprecate the old version of the API. Provide best effort support to users of the old API. Turn down the old version of the API.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tIntroduce the new version of the API. Contact remaining users of the old API. Announce deprecation of the old version of the API. Deprecate the old version of the API. Turn down the old version of the API. Provide best effort support to users of the old API."
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 21,
        "isMostVoted": true
      },
      {
        "answer": "D",
        "count": 1,
        "isMostVoted": false
      },
      {
        "answer": "C",
        "count": 1,
        "isMostVoted": false
      },
      {
        "answer": "B",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2021-11-01T04:54:00.000Z",
        "voteCount": 17,
        "content": "A. Introduce new API ahead"
      },
      {
        "date": "2021-12-14T16:12:00.000Z",
        "voteCount": 3,
        "content": "no use contacting the users after the API is deprecated - they will come to know anyway when the API fails. Hence A is INCORRECT !!"
      },
      {
        "date": "2021-12-17T09:14:00.000Z",
        "voteCount": 2,
        "content": "It's not been turned off yet, so they will still be able to use it"
      },
      {
        "date": "2022-01-16T06:17:00.000Z",
        "voteCount": 13,
        "content": "Let's start with Eliminating, as I see a lot of you are confused here.\nYou cannot deprecate or announce depreciation before introducing the newer version. This easily eliminates B and C options.\nNow between A and D, A fully follows the pattern of API deprecation. Deprecate, but have not stopped yet, trying to provide support till it is totally closed. No support after that.\nGo with A. Hope this helps all."
      },
      {
        "date": "2022-11-28T00:16:00.000Z",
        "voteCount": 1,
        "content": "Why not? All major software companies announce when their old software will be deprecated so this helps in planning for the users. I think it is B but I'm confused why so many have opted for A"
      },
      {
        "date": "2023-12-18T14:28:00.000Z",
        "voteCount": 1,
        "content": "Less disruption means that you need to contact users of OLD API before deprecate it!!!! No way can be B. for me first you should announce the new version so is D"
      },
      {
        "date": "2023-12-02T06:51:00.000Z",
        "voteCount": 1,
        "content": "Option A"
      },
      {
        "date": "2023-09-03T23:21:00.000Z",
        "voteCount": 1,
        "content": "A. Introduce new API ahead, then Contact remaining users on the old API."
      },
      {
        "date": "2023-08-11T09:37:00.000Z",
        "voteCount": 1,
        "content": "I think is A, because you deprecate the old version, but the old version will be functional yet. Deprecate is not turn down, so the API works with the old version until the moment it is turned off. In general, this occurs with a message indicated that your version in use is deprecated, but your API or application works correctly."
      },
      {
        "date": "2023-01-15T17:21:00.000Z",
        "voteCount": 1,
        "content": "C. Announce deprecation of the old version of the API. Contact remaining users on the old API. Introduce the new version of the API. Deprecate the old version of the API. Provide best effort support to users of the old API. Turn down the old version of the API.\n\nIt is important to announce the deprecation of the old version of the API before implementing the new one, so that third-party developers can prepare for the change and avoid disruptions to their service. It is also important to contact remaining users of the old API to provide them with assistance and support during the transition to the new version."
      },
      {
        "date": "2023-12-21T10:53:00.000Z",
        "voteCount": 1,
        "content": "In C option you contact remaining users on the old API previous introduce the new version of the API, that can not be possible, \"remaining users\", it should say only \"users\""
      },
      {
        "date": "2022-10-23T03:49:00.000Z",
        "voteCount": 1,
        "content": "A is the answer."
      },
      {
        "date": "2022-06-17T06:45:00.000Z",
        "voteCount": 2,
        "content": "A is correct"
      },
      {
        "date": "2022-03-27T11:25:00.000Z",
        "voteCount": 2,
        "content": "A is correct"
      },
      {
        "date": "2022-02-21T09:35:00.000Z",
        "voteCount": 1,
        "content": "agree with KyubiBlaze and Wwhite44 arguments. Introduce first. this eliminates B and C.\nthen is between A and D."
      },
      {
        "date": "2022-01-20T00:20:00.000Z",
        "voteCount": 1,
        "content": "A should be correct"
      },
      {
        "date": "2021-12-27T02:48:00.000Z",
        "voteCount": 1,
        "content": "https://httptoolkit.tech/blog/how-to-turn-off-your-old-apis/\nC the second action doesnt make sense, you will be supporting remaining users of what?"
      },
      {
        "date": "2021-12-22T12:54:00.000Z",
        "voteCount": 1,
        "content": "A. Is correct 100%"
      },
      {
        "date": "2021-12-22T13:05:00.000Z",
        "voteCount": 1,
        "content": "after you depreciate the old version of the Api. you must provide the support to the remaining users"
      },
      {
        "date": "2021-12-25T04:43:00.000Z",
        "voteCount": 1,
        "content": "B is correct"
      },
      {
        "date": "2021-12-22T13:09:00.000Z",
        "voteCount": 1,
        "content": "You can't contact the remaining users before you depreciate the old version of the API"
      },
      {
        "date": "2021-12-14T16:18:00.000Z",
        "voteCount": 2,
        "content": "Sorry friends ignore my previous comments..upon re-reading \"A\" makes more sense. \"Deprecated\" = function still works but not supported or recommended. \nHence Introduction --&gt; Announce Deprecation --&gt; Deprecate --&gt; Best effort support --&gt; Turn OFF ...makes perfect sense"
      },
      {
        "date": "2021-12-13T15:12:00.000Z",
        "voteCount": 3,
        "content": "A - Incorrect - No use contacting the users of the old API after depreciating \n B - Correct - since users are contacted before depreciation\n C &amp; D: Sequence doesnt make sense"
      },
      {
        "date": "2021-12-25T04:44:00.000Z",
        "voteCount": 1,
        "content": "B is correct"
      },
      {
        "date": "2021-12-05T07:02:00.000Z",
        "voteCount": 4,
        "content": "Ans B\nhttps://httptoolkit.tech/blog/how-to-turn-off-your-old-apis/"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 78,
    "url": "https://www.examtopics.com/discussions/google/view/65112-exam-professional-cloud-devops-engineer-topic-1-question-78/",
    "body": "You are running an application on Compute Engine and collecting logs through Stackdriver. You discover that some personally identifiable information (PII) is leaking into certain log entry fields. You want to prevent these fields from being written in new log entries as quickly as possible. What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse the filter-record-transformer Fluentd filter plugin to remove the fields from the log entries in flight.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse the fluent-plugin-record-reformer Fluentd output plugin to remove the fields from the log entries in flight.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tWait for the application developers to patch the application, and then verify that the log entries are no longer exposing PII.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tStage log entries to Cloud Storage, and then trigger a Cloud Function to remove the fields and write the entries to Stackdriver via the Stackdriver Logging API."
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 14,
        "isMostVoted": true
      },
      {
        "answer": "B",
        "count": 3,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2021-11-06T23:45:00.000Z",
        "voteCount": 11,
        "content": "reformer is Fluentd plugin to add or replace fields of a event record, so ans is A"
      },
      {
        "date": "2021-12-17T09:22:00.000Z",
        "voteCount": 6,
        "content": "Seems both A and B will work. \nHowever i will go with A, since it is included in the fluentd core and does not require installing a new plugin \n\n\"The filter_record_transformer filter plugin mutates/transforms incoming event streams in a versatile manner. If there is a need to add/delete/modify events, this plugin is the first filter to try.\nIt is included in the Fluentd's core.\"\n\nhttps://docs.fluentd.org/filter/record_transformer"
      },
      {
        "date": "2021-12-17T09:25:00.000Z",
        "voteCount": 1,
        "content": "https://cloud.google.com/logging/docs/agent/logging/configuration#modifying_log_records"
      },
      {
        "date": "2023-12-02T06:57:00.000Z",
        "voteCount": 1,
        "content": "Option A"
      },
      {
        "date": "2023-01-15T17:27:00.000Z",
        "voteCount": 1,
        "content": "A. Use the filter-record-transformer Fluentd filter plugin to remove the fields from the log entries in flight.\n\nFluentd is a log collector and processor that is commonly used with Google Cloud Platform. The filter-record-transformer plugin for Fluentd can be used to modify log entries as they are being collected, allowing you to remove sensitive fields from the log entries in real-time before they are written to Stackdriver. This can be done quickly, as it doesn't require changes on the application code."
      },
      {
        "date": "2022-12-05T17:35:00.000Z",
        "voteCount": 1,
        "content": "Ans A.\nSource - https://docs.fluentd.org/filter/record_transformer"
      },
      {
        "date": "2022-11-08T04:44:00.000Z",
        "voteCount": 3,
        "content": "Appeared in 07/11/2022 exam\n\nkeys : Option-A has the filter name wrong. It should be filter_record_transformer not filter-record-transformer"
      },
      {
        "date": "2022-11-06T05:31:00.000Z",
        "voteCount": 3,
        "content": "filter_record_transformer enables you to:\n\n   - Add new fields to log entries\n    - Update fields in log entries\n    - Delete fields in log entries\n\nThe fluent-plugin-record-reformer output plugin provides functionality similar to the filter_record_transformer filter plugin, except that it also allows you to modify log tags. \n\nWe dont need to modify the filters here .. hence A"
      },
      {
        "date": "2022-11-06T05:34:00.000Z",
        "voteCount": 2,
        "content": "IF the answer 'A' is not a typo (- instead of _), then B is correct"
      },
      {
        "date": "2022-10-23T03:47:00.000Z",
        "voteCount": 1,
        "content": "A is the answer.\n\nhttps://cloud.google.com/logging/docs/agent/logging/configuration#modifying_log_records\nFluentd provides built-in filter plugins that can be used to modify log entries.\nThe most commonly used filter plugin is filter_record_transformer. It enables you to:\n- Delete fields in log entries"
      },
      {
        "date": "2022-06-10T03:39:00.000Z",
        "voteCount": 2,
        "content": "Ans: B \nhttps://cloud.google.com/logging/docs/agent/logging/configuration According to this link \nA is wrong as correct plugin name is filter_record_transformer and not filter-record-transformer \nB is Correct as \"The fluent-plugin-record-reformer output plugin provides functionality similar to the filter_record_transformer filter plugin, except that it also allows you to modify log tags. More resource usage is expected with this plugin: each time a log tag is updated, it generates a new log entry with the new tag.\""
      },
      {
        "date": "2022-03-27T11:27:00.000Z",
        "voteCount": 1,
        "content": "A is correct"
      },
      {
        "date": "2022-03-09T09:40:00.000Z",
        "voteCount": 4,
        "content": "It's B. \nhttps://cloud.google.com/logging/docs/agent/logging/configuration#cloud-fluentd-config: is filter_record_transformer not filter-record-transformer. fluent-plugin-record-reformer is the right name"
      },
      {
        "date": "2022-04-19T18:49:00.000Z",
        "voteCount": 2,
        "content": "That is right , Both options does the job , however filter_record_transformer is the correct name. not filter-record-transformer"
      },
      {
        "date": "2022-01-20T00:24:00.000Z",
        "voteCount": 1,
        "content": "A is correct"
      },
      {
        "date": "2021-11-04T23:13:00.000Z",
        "voteCount": 3,
        "content": "Yes, its A and not B as fluent-plugin-google-cloud from https://cloud.google.com/logging/docs/agent/logging/configuration#cloud-fluentd-config\n\n\nBesides the list of default logs that the Logging agent streams by default, you can customize the Logging agent to send additional logs to Logging or to adjust agent settings by adding input configurations.\n\nThe configuration definitions in these sections apply to the fluent-plugin-google-cloud output plugin only and specify how logs are transformed and ingested into Cloud Logging."
      },
      {
        "date": "2021-10-30T02:25:00.000Z",
        "voteCount": 3,
        "content": "I think A because The fluent-plugin-record-reformer output plugin provides functionality similar to the filter_record_transformer filter plugin, except that it also allows you to modify log tags"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 79,
    "url": "https://www.examtopics.com/discussions/google/view/65005-exam-professional-cloud-devops-engineer-topic-1-question-79/",
    "body": "You support a service that recently had an outage. The outage was caused by a new release that exhausted the service memory resources. You rolled back the release successfully to mitigate the impact on users. You are now in charge of the post-mortem for the outage. You want to follow Site Reliability Engineering practices when developing the post-mortem. What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tFocus on developing new features rather than avoiding the outages from recurring.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tFocus on identifying the contributing causes of the incident rather than the individual responsible for the cause.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tPlan individual meetings with all the engineers involved. Determine who approved and pushed the new release to production.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse the Git history to find the related code commit. Prevent the engineer who made that commit from working on production services."
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 9,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2022-01-28T13:44:00.000Z",
        "voteCount": 7,
        "content": "Will go with B"
      },
      {
        "date": "2023-12-02T06:58:00.000Z",
        "voteCount": 2,
        "content": "Option B"
      },
      {
        "date": "2023-01-15T17:23:00.000Z",
        "voteCount": 3,
        "content": "B. Focus on identifying the contributing causes of the incident rather than the individual responsible for the cause.\n\nAccording to Site Reliability Engineering (SRE) practices, the goal of a post-mortem is to identify the underlying causes of the incident in order to take steps to prevent it from happening again in the future. This involves looking for patterns and issues in the system rather than looking for a specific person to blame. It's important to have a focus on learning and continuous improvement, rather than assigning blame."
      },
      {
        "date": "2022-12-07T03:23:00.000Z",
        "voteCount": 1,
        "content": "B) Makes sense"
      },
      {
        "date": "2022-10-23T13:22:00.000Z",
        "voteCount": 1,
        "content": "B is the correct answer."
      },
      {
        "date": "2022-10-23T01:26:00.000Z",
        "voteCount": 1,
        "content": "B is the answer."
      },
      {
        "date": "2022-08-14T20:13:00.000Z",
        "voteCount": 2,
        "content": "B is correct BBB"
      },
      {
        "date": "2022-01-20T01:43:00.000Z",
        "voteCount": 1,
        "content": "B is correct"
      },
      {
        "date": "2021-11-22T04:22:00.000Z",
        "voteCount": 4,
        "content": "Ans: B"
      },
      {
        "date": "2021-11-12T01:57:00.000Z",
        "voteCount": 2,
        "content": "Agreed B"
      },
      {
        "date": "2021-11-10T12:37:00.000Z",
        "voteCount": 3,
        "content": "Ans: B"
      },
      {
        "date": "2021-10-30T07:28:00.000Z",
        "voteCount": 2,
        "content": "Confirm B"
      },
      {
        "date": "2021-10-30T02:34:00.000Z",
        "voteCount": 2,
        "content": "Ans B, yes"
      },
      {
        "date": "2021-10-28T04:58:00.000Z",
        "voteCount": 3,
        "content": "Ans B,yes"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 80,
    "url": "https://www.examtopics.com/discussions/google/view/65115-exam-professional-cloud-devops-engineer-topic-1-question-80/",
    "body": "You support a user-facing web application. When analyzing the application's error budget over the previous six months, you notice that the application has never consumed more than 5% of its error budget in any given time window. You hold a Service Level Objective (SLO) review with business stakeholders and confirm that the SLO is set appropriately. You want your application's SLO to more closely reflect its observed reliability. What steps can you take to further that goal while balancing velocity, reliability, and business needs? (Choose two.)<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAdd more serving capacity to all of your application's zones.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tHave more frequent or potentially risky application releases.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tTighten the SLO match the application's observed reliability.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tImplement and measure additional Service Level Indicators (SLIs) fro the application.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAnnounce planned downtime to consume more error budget, and ensure that users are not depending on a tighter SLO.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "DE",
    "answerDescription": "",
    "votes": [
      {
        "answer": "DE",
        "count": 24,
        "isMostVoted": true
      },
      {
        "answer": "BE",
        "count": 14,
        "isMostVoted": false
      },
      {
        "answer": "BD",
        "count": 4,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2021-11-03T02:18:00.000Z",
        "voteCount": 26,
        "content": "I would go for B+D:\n-A: no, there's no reason to add capacity if we are barely scratching error budget;\n-B: everything seems fine, so it's ok to dare with more innovative/risky releases;\n-C: no, stakeholders said SLO is ok;\n-D: adding additional SLIs (and so SLOs) might be a way to reflect observer reliability more closely;\n-E: put the servers down for no reason is a no-no."
      },
      {
        "date": "2021-12-13T15:35:00.000Z",
        "voteCount": 1,
        "content": "there is no mention of innovation, only \"risky\"..hence not a right choices"
      },
      {
        "date": "2024-06-19T12:13:00.000Z",
        "voteCount": 1,
        "content": "Risk isn't necessarily bad. The SRE book specifically mentions to embrace risk. \n\nThe question constraint is to \"balance velocity, reliability and business needs\". If the application only ever consumes 5% of its error budget, then that allows for more frequent updates (frequency and business needs). And since the application already is very reliable  there is room to focus on feature development. \n\nRemember focusing too much on reliability can slow down feature development to a halt, and likewise focusing too much on feature development can cause an unreliable system."
      },
      {
        "date": "2022-01-20T02:18:00.000Z",
        "voteCount": 13,
        "content": "I vote for D+E if you read \"The Global Chubby Planned Outage\"\nhttps://sre.google/sre-book/service-level-objectives/"
      },
      {
        "date": "2023-12-02T07:02:00.000Z",
        "voteCount": 1,
        "content": "Option B and D"
      },
      {
        "date": "2023-03-10T22:27:00.000Z",
        "voteCount": 1,
        "content": "BE is correct"
      },
      {
        "date": "2023-02-23T13:19:00.000Z",
        "voteCount": 2,
        "content": "B is correct because when you dont use your error budget you can increase the release frequency. In the question it even mentions \"balancing velocity, reliability, and business needs\". The balance here can shift from reliability to velocity and business needs.\nD is correct as multiple other users already mentioned because of:  \"The Global Chubby Planned Outage\" https://sre.google/sre-book/service-level-objectives/"
      },
      {
        "date": "2023-01-15T17:54:00.000Z",
        "voteCount": 2,
        "content": "I will go with D and E.\nOption B sounds good, but introducing new changes could add errors, that do not match the current objectives  \"You want your application's SLO to more closely reflect its observed reliability. \"\n\nA doesn't make sense.\nC neither, because the SLO has been reviewed and its ok."
      },
      {
        "date": "2022-12-31T09:03:00.000Z",
        "voteCount": 2,
        "content": "B and E:\nA. not relevant\nB. Yes because we have a lot of budget. Risky isn't necessary a negative word in SRE because what we learn from SRE is to embrace risk and failure.\nC. SLO is set appropriately they say.\nD. adding more SLI doesn't necessarily help.\nE. SRE practice suggest that we can have planned downtime."
      },
      {
        "date": "2022-12-24T16:52:00.000Z",
        "voteCount": 3,
        "content": "This was asked on (12/24/22), passed the exam . I opted for D &amp; E"
      },
      {
        "date": "2022-12-22T02:25:00.000Z",
        "voteCount": 4,
        "content": "B and E.\nWhen you only consume 5% of your error budget consistently it means that you can take more risk by releasing features more often (B) and/or bring down service to set user expectation close to SLO (and business has confirmed that this SLO is appropriate)"
      },
      {
        "date": "2022-12-13T03:25:00.000Z",
        "voteCount": 4,
        "content": "B+E \nB because this if you constantly have a lot of spare error budgets it is an indication that you are not taking enough risk ie releasing new features.  And you are ultimately depriving the users of new functionalities by being too cautious.\nE: Everyone agrees on E as it was mentioned in the SRE book as part of the The Global Chubby Planned Outage\n\nRe: why not D) The review indicated that the existing SLOs are good. So  adding more SLIs not useful here plus does nothing to the user perceived reliability."
      },
      {
        "date": "2022-08-15T16:27:00.000Z",
        "voteCount": 2,
        "content": "DE - You want your application's SLO to more closely reflect its observed reliability."
      },
      {
        "date": "2022-06-17T06:53:00.000Z",
        "voteCount": 3,
        "content": "B &amp; D are correct."
      },
      {
        "date": "2022-03-26T04:00:00.000Z",
        "voteCount": 5,
        "content": "D+E\nYou want the application's SLO to more closely reflect it's observed reliability.  The key here is error budget never goes over 5%.  This means they can have additional downtime and still stay within their budget.  \nE is correct as per Google SRE handbook (https://sre.google/sre-book/service-level-objectives/) \n'You can avoid over-dependence by deliberately taking the system offline occasionally (Google\u2019s Chubby service introduced planned outages in response to being overly available)'\nD is a good answer because with more SLI's, this may more accurately reflect the system's reliability.\nA is wrong because adding more serving capacity would make the system even more available.\nC is wrong because:  The question states 'The SLO is set appropriately'."
      },
      {
        "date": "2022-02-21T09:50:00.000Z",
        "voteCount": 3,
        "content": "chekc link from Sekierer for why E is valid (https://sre.google/sre-book/service-level-objectives/)\nThen D is logical as well."
      },
      {
        "date": "2022-02-13T07:44:00.000Z",
        "voteCount": 7,
        "content": "B - You can increase the frequency of your releases and take higher risks as you have never exceeded your error budget.\nE - Planned downtime to use some of your error budget will help to make sure end users don\u2019t get use a higher availability of your service."
      },
      {
        "date": "2021-12-28T10:47:00.000Z",
        "voteCount": 2,
        "content": "https://cloud.google.com/blog/products/management-tools/sre-error-budgets-and-maintenance-windows   This is the link to the answers of this question"
      },
      {
        "date": "2021-12-27T02:51:00.000Z",
        "voteCount": 4,
        "content": "These are the correct choices"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 81,
    "url": "https://www.examtopics.com/discussions/google/view/65116-exam-professional-cloud-devops-engineer-topic-1-question-81/",
    "body": "You support a service with a well-defined Service Level Objective (SLO). Over the previous 6 months, your service has consistently met its SLO and customer satisfaction has been consistently high. Most of your service's operations tasks are automated and few repetitive tasks occur frequently. You want to optimize the balance between reliability and deployment velocity while following site reliability engineering best practices. What should you do? (Choose two.)<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tMake the service's SLO more strict.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tIncrease the service's deployment velocity and/or risk.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tShift engineering time to other services that need more reliability.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tGet the product team to prioritize reliability work over new features.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tChange the implementation of your Service Level Indicators (SLIs) to increase coverage."
    ],
    "answer": "BC",
    "answerDescription": "",
    "votes": [
      {
        "answer": "BC",
        "count": 20,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2021-10-31T16:26:00.000Z",
        "voteCount": 24,
        "content": "BC\n\nhttps://sre.google/workbook/implementing-slos/#slo-decision-matrix\n\nA: wrong \u2013 SLO is already well-defined, customer satisfaction is high.\nE: wrong \u2013 change SLI means how SLO, which is already well-defined.\n\nCD are valid, but the best option is C because current product is already quite reliable."
      },
      {
        "date": "2021-11-07T00:01:00.000Z",
        "voteCount": 3,
        "content": "yes B and C"
      },
      {
        "date": "2022-06-18T16:28:00.000Z",
        "voteCount": 3,
        "content": "NXD, thank you for posting the link.  The answer is explicitly stated in the post.  The SLO matrix listed there is also great for future use cases.  I personally love reading the discussions and posts to fully understand the concepts and services.  Thanks again."
      },
      {
        "date": "2021-11-11T20:42:00.000Z",
        "voteCount": 3,
        "content": "Agree with BC"
      },
      {
        "date": "2023-01-15T18:10:00.000Z",
        "voteCount": 1,
        "content": "Agree with BC"
      },
      {
        "date": "2021-12-27T02:56:00.000Z",
        "voteCount": 6,
        "content": "These are the correct answers. Thank me later. \n\nAll the best guys"
      },
      {
        "date": "2024-06-18T04:20:00.000Z",
        "voteCount": 1,
        "content": "B. Increase the service's deployment velocity and/or risk.\n\nWith the current high reliability and consistent SLO adherence, you have room to increase the deployment velocity. This means you can deploy updates and new features more frequently, which can help in rapidly delivering value to your customers and staying competitive. As long as you monitor the impact on your SLO and maintain your reliability standards, this approach can optimize both reliability and deployment velocity.\n\nC. Shift engineering time to other services that need more reliability.\n\nSince your current service is already stable and meeting its SLOs, you can allocate some of the engineering resources to other services that might be struggling with reliability. This will help improve the overall reliability of your organization's services and make better use of your engineering talent."
      },
      {
        "date": "2023-07-15T05:58:00.000Z",
        "voteCount": 1,
        "content": "Agree with BC"
      },
      {
        "date": "2023-07-15T17:11:00.000Z",
        "voteCount": 1,
        "content": "Are the questions still relavant?"
      },
      {
        "date": "2023-01-15T18:10:00.000Z",
        "voteCount": 1,
        "content": "Agree with BC"
      },
      {
        "date": "2022-12-24T16:52:00.000Z",
        "voteCount": 2,
        "content": "This was asked on (12/24/22), passed the exam . I opted for B &amp;  E"
      },
      {
        "date": "2022-12-02T02:19:00.000Z",
        "voteCount": 1,
        "content": "Agree with BC"
      },
      {
        "date": "2022-10-23T01:04:00.000Z",
        "voteCount": 3,
        "content": "BC is the answer.\n\nhttps://sre.google/workbook/implementing-slos/#slo-decision-matrix\n\t\nChoose to (a) relax release and deployment processes and increase velocity, or (b) step back from the engagement and focus engineering time on services that need more reliability."
      },
      {
        "date": "2022-08-15T16:30:00.000Z",
        "voteCount": 1,
        "content": "letter B and C"
      },
      {
        "date": "2022-07-26T07:19:00.000Z",
        "voteCount": 2,
        "content": "As mentioned by others, we can see in the SRE book table here https://sre.google/workbook/implementing-slos/#slo-decision-matrix that when:\nSLO=Met\nToil=Low\nCustomer Satisfaction=High\nthen:\nChoose to (a) relax release and deployment processes and increase velocity, or (b) step back from the engagement and focus engineering time on services that need more reliability.\nThis matches only B and C."
      },
      {
        "date": "2022-02-21T14:30:00.000Z",
        "voteCount": 4,
        "content": "as NXD 's link shows (https://sre.google/workbook/implementing-slos/#slo-decision-matrix)\nanswer is B C. See link."
      },
      {
        "date": "2022-01-20T02:24:00.000Z",
        "voteCount": 3,
        "content": "B and C"
      },
      {
        "date": "2021-12-25T04:06:00.000Z",
        "voteCount": 3,
        "content": "After perusing the SRE book...\nD, E Is correct, there is a question that is almost this very question but the wording is different"
      },
      {
        "date": "2021-12-27T02:57:00.000Z",
        "voteCount": 1,
        "content": "B C, ,,,, D; E Are for the previous question, number 80"
      },
      {
        "date": "2021-12-07T00:38:00.000Z",
        "voteCount": 1,
        "content": "Ans C; D  are correct."
      },
      {
        "date": "2021-12-27T02:57:00.000Z",
        "voteCount": 1,
        "content": "its a mistake here"
      },
      {
        "date": "2021-11-11T13:09:00.000Z",
        "voteCount": 3,
        "content": "i think BC"
      },
      {
        "date": "2021-11-10T02:30:00.000Z",
        "voteCount": 2,
        "content": "i think CD are correct \nregarding E i am not sure we can modify SLI after we defined"
      },
      {
        "date": "2021-10-30T02:49:00.000Z",
        "voteCount": 2,
        "content": "I think B and E:\nA No: SLO is well defined\nB YES: the service met the SLO so you have error budget available for DEPLOY\nC I think NO, you will reduce your team number\nD NO higher reliability is unnecessary (SLO well defined)\nE YES you can modify SLI to extend coverage"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 82,
    "url": "https://www.examtopics.com/discussions/google/view/122000-exam-professional-cloud-devops-engineer-topic-1-question-82/",
    "body": "Your company follows Site Reliability Engineering principles. You are writing a postmortem for an incident, triggered by a software change that severely affected users. You want to prevent severe incident from happening in the future. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tIdentify engineers responsible for the incident and escalate to the senior management.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEnsure that test cases that catch errors of this type are run successfully before new software releases.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tFollow up with the employees who reviewed the changes and prescribe practices they should follow in the future.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDesign a policy that will require on-call teams to immediately call engineers and management to discuss a plan of action if an incident occurs."
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 5,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-09-30T23:48:00.000Z",
        "voteCount": 8,
        "content": "Answer Should B"
      },
      {
        "date": "2023-11-14T06:58:00.000Z",
        "voteCount": 2,
        "content": "B makes the most sense"
      },
      {
        "date": "2023-11-06T09:11:00.000Z",
        "voteCount": 1,
        "content": "B is correct."
      },
      {
        "date": "2023-10-21T22:01:00.000Z",
        "voteCount": 2,
        "content": "Answer is B"
      },
      {
        "date": "2023-10-21T22:00:00.000Z",
        "voteCount": 1,
        "content": "Answer is B"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 83,
    "url": "https://www.examtopics.com/discussions/google/view/122001-exam-professional-cloud-devops-engineer-topic-1-question-83/",
    "body": "Your organization uses a change advisory board (CAB) to approve all changes to an existing service. You want to revise this process to eliminate any negative impact on the software delivery performance. What should you do? (Choose two.)",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tReplace the CAB with a senior manager to ensure continuous oversight from development to deployment.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tLet developers merge their own changes, but ensure that the team's deployment platform can roll back changes if any issues are discovered.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tMove to a peer-review based process for individual changes that is enforced at code check-in time and supported by automated tests.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tBatch changes into larger but less frequent software releases.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEnsure that the team's development platform enables developers to get fast feedback on the impact of their changes.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "CE",
    "answerDescription": "",
    "votes": [
      {
        "answer": "CE",
        "count": 5,
        "isMostVoted": true
      },
      {
        "answer": "BC",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2023-09-30T23:53:00.000Z",
        "voteCount": 5,
        "content": "Answer should be C and E\nTo revise the change approval process and eliminate any negative impact on software delivery performance, you should consider the following approaches:\n\nC. Move to a peer-review based process for individual changes that is enforced at code check-in time and supported by automated tests: Implementing a peer-review process ensures that changes are reviewed by team members, which can catch issues early in the development process. Automated tests can provide additional confidence in the quality of changes. This approach encourages collaboration and reduces the need for a formal CAB.\n\nE. Ensure that the team's development platform enables developers to get fast feedback on the impact of their changes: Fast feedback mechanisms, such as automated testing and continuous integration pipelines, allow developers to quickly identify and address issues with their changes. This reduces the need for a formal approval board like CAB and promotes a culture of ownership and responsibility among developers."
      },
      {
        "date": "2024-01-27T08:09:00.000Z",
        "voteCount": 1,
        "content": "I initially chose B &amp; C, but now looking again, B says for developer to merge their own change and rollback if things go wrong, this doesn't mention things like peer review which is very risky if each developer just go do their own merges."
      },
      {
        "date": "2024-02-08T02:59:00.000Z",
        "voteCount": 1,
        "content": "https://dora.dev/devops-capabilities/process/streamlining-change-approval/#:~:text=Use%20peer%20review,well%20as%20defects"
      },
      {
        "date": "2023-12-04T09:51:00.000Z",
        "voteCount": 1,
        "content": "Regarding E, it is important, but it doesn't directly address the bottleneck caused by the CAB process."
      },
      {
        "date": "2023-11-14T07:00:00.000Z",
        "voteCount": 1,
        "content": "I would go for C E"
      },
      {
        "date": "2023-10-21T22:03:00.000Z",
        "voteCount": 3,
        "content": "C and E"
      },
      {
        "date": "2023-10-08T20:20:00.000Z",
        "voteCount": 2,
        "content": "C and E seems correct\nhttps://cloud.google.com/architecture/devops/devops-process-streamlining-change-approval"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 84,
    "url": "https://www.examtopics.com/discussions/google/view/122002-exam-professional-cloud-devops-engineer-topic-1-question-84/",
    "body": "Your organization has a containerized web application that runs on-premises. As part of the migration plan to Google Cloud, you need to select a deployment strategy and platform that meets the following acceptance criteria:<br><br>1. The platform must be able to direct traffic from Android devices to an Android-specific microservice.<br>2. The platform must allow for arbitrary percentage-based traffic splitting<br>3. The deployment strategy must allow for continuous testing of multiple versions of any microservice.<br><br>What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDeploy the canary release of the application to Cloud Run. Use traffic splitting to direct 10% of user traffic to the canary release based on the revision tag.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDeploy the canary release of the application to App Engine. Use traffic splitting to direct a subset of user traffic to the new version based on the IP address.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDeploy the canary release of the application to Compute Engine. Use Anthos Service Mesh with Compute Engine to direct 10% of user traffic to the canary release by configuring the virtual service.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDeploy the canary release to Google Kubernetes Engine with Anthos Service Mesh. Use traffic splitting to direct 10% of user traffic to the new version based on the user-agent header configured in the virtual service.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 4,
        "isMostVoted": true
      },
      {
        "answer": "B",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2023-10-01T00:07:00.000Z",
        "voteCount": 9,
        "content": "Option D allows for continuous testing of multiple versions of microservices, meets the traffic splitting requirements, and provides the necessary flexibility for controlling traffic based on user-agent headers, making it the most suitable choice based on the specified acceptance criteria."
      },
      {
        "date": "2024-08-11T16:42:00.000Z",
        "voteCount": 1,
        "content": "Why not B?"
      },
      {
        "date": "2024-03-03T02:38:00.000Z",
        "voteCount": 1,
        "content": "OPtion D \nThis option offers a comprehensive solution that aligns well with your criteria. Anthos Service Mesh, integrated with Google Kubernetes Engine (GKE), supports advanced traffic management capabilities, including the ability to perform traffic splitting based on HTTP headers. This would allow you to use the user-agent header to identify Android devices and direct traffic accordingly. Additionally, it supports arbitrary percentage-based traffic splitting and allows for the testing of multiple versions of a microservice, meeting the requirement for continuous testing."
      },
      {
        "date": "2023-12-04T09:52:00.000Z",
        "voteCount": 1,
        "content": "This option provides a powerful combination for microservices deployment. Google Kubernetes Engine offers a robust environment for containerized applications, and Anthos Service Mesh (built on Istio) enables sophisticated traffic management. You can configure traffic splitting and direct traffic based on headers (like user-agent for Android devices), which aligns perfectly with your requirements."
      },
      {
        "date": "2023-11-14T07:06:00.000Z",
        "voteCount": 1,
        "content": "Anthos Service Mesh allows for traffic routing based on HTTP headers such as the user-agent, which can be used to direct traffic from Android devices to an Android-specific microservice.\nAnthos Service Mesh supports arbitrary percentage-based traffic splitting.\nGoogle Kubernetes Engine with Anthos Service Mesh allows for continuous testing of multiple versions of any microservice. You can deploy different versions of your microservices as separate Kubernetes deployments and use Anthos Service Mesh to control the traffic between them."
      },
      {
        "date": "2023-11-06T19:22:00.000Z",
        "voteCount": 2,
        "content": "D is correct"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 85,
    "url": "https://www.examtopics.com/discussions/google/view/122003-exam-professional-cloud-devops-engineer-topic-1-question-85/",
    "body": "Your team is running microservices in Google Kubernetes Engine (GKE). You want to detect consumption of an error budget to protect customers and define release policies. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate SLIs from metrics. Enable Alert Policies if the services do not pass.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse the metrics from Anthos Service Mesh to measure the health of the microservices.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a SLO. Create an Alert Policy on select_slo_burn_rate.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a SLO and configure uptime checks for your services. Enable Alert Policies if the services do not pass."
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 7,
        "isMostVoted": true
      },
      {
        "answer": "D",
        "count": 3,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2024-07-17T22:53:00.000Z",
        "voteCount": 2,
        "content": "The best answer is C. Create a SLO. Create an Alert Policy on select_slo_burn_rate. Here's why:\n\nSLOs (Service Level Objectives): SLOs are crucial for defining the acceptable performance levels of your microservices. They help you set clear targets for things like latency, availability, and error rates.\nError Budget: An error budget is a defined amount of \"acceptable\" errors or performance degradation within a given time period. It allows for some flexibility while still ensuring overall service health.\nAlerting on Burn Rate: The select_slo_burn_rate metric in Cloud Monitoring allows you to track how quickly your error budget is being consumed. By creating an alert policy based on this metric, you can be notified when the burn rate exceeds a predefined threshold, indicating a potential risk of exceeding your error budget."
      },
      {
        "date": "2024-07-17T22:53:00.000Z",
        "voteCount": 1,
        "content": "Why other options are less suitable:\n\nA. Create SLIs from metrics. Enable Alert Policies if the services do not pass: While creating SLIs is a good first step, it doesn't directly address the error budget consumption. Alerting on individual SLIs might not be sufficient to protect against exceeding the overall error budget.\nB. Use the metrics from Anthos Service Mesh to measure the health of the microservices: Anthos Service Mesh provides valuable metrics, but it doesn't inherently handle error budget management. You'll still need to define SLOs and create alerts based on the burn rate.\nD. Create a SLO and configure uptime checks for your services. Enable Alert Policies if the services do not pass: Uptime checks are important for availability, but they don't directly monitor error budget consumption. You need a mechanism to track the burn rate of your error budget, which is best achieved through SLOs and the select_slo_burn_rate metric."
      },
      {
        "date": "2024-02-08T03:09:00.000Z",
        "voteCount": 1,
        "content": "https://cloud.google.com/stackdriver/docs/solutions/slo-monitoring/alerting-on-budget-burn-rate#:~:text=The%20burn%2Drate%20metric%20is%20retrieved%20by%20the%20time%2Dseries%20selector%20select_slo_burn_rate.%20A%20burn%2Drate%20alerting%20policy%20notifies%20you%20when%20your%20error%20budget%20is%20consumed%20faster%20than%20a%20threshold%20you%20define%2C%20measured%20over%20the%20alert%27s%20compliance%20period."
      },
      {
        "date": "2023-12-04T09:56:00.000Z",
        "voteCount": 1,
        "content": "This approach involves defining specific SLOs for your services, which are quantitative measures of the desired reliability of a service. Once you have these SLOs, you can set up Alert Policies based on the rate at which your error budget is consumed (burn rate)."
      },
      {
        "date": "2023-11-14T07:11:00.000Z",
        "voteCount": 3,
        "content": "I am voting for C we need to detect consumption of an error budget. This is what SLO burn rate is."
      },
      {
        "date": "2023-11-06T08:02:00.000Z",
        "voteCount": 1,
        "content": "Both option C &amp; D are effective in detecting consumption of error budget, but they have different strengths and weaknesses.\nCreating an SLO and configuring uptime checks is a good way to get a high-level view of the health of your services. It can also help you to identify trends over time. However, it can be difficult to configure uptime checks for complex services, and it may not be possible to detect all types of errors.\nUsing select_slo_burn_rate is a more granular way to detect consumption of error budget. It can be used to monitor individual SLOs and to identify specific types of errors. However, it can be more difficult to set up and to interpret the results."
      },
      {
        "date": "2023-10-28T09:47:00.000Z",
        "voteCount": 2,
        "content": "https://cloud.google.com/service-mesh/docs/observability/alert-policy-slo"
      },
      {
        "date": "2023-10-01T00:18:00.000Z",
        "voteCount": 3,
        "content": "using metrics from Anthos Service Mesh, which can be helpful for monitoring, but it lacks the explicit focus on SLOs, uptime checks, and Alert Policies for managing error budgets and protecting customers.\n\nCorrect Answer is D. Create a SLO and configure uptime checks for your services. Enable Alert Policies if the services do not pass."
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 86,
    "url": "https://www.examtopics.com/discussions/google/view/122004-exam-professional-cloud-devops-engineer-topic-1-question-86/",
    "body": "Your organization wants to collect system logs that will be used to generate dashboards in Cloud Operations for their Google Cloud project. You need to configure all current and future Compute Engine instances to collect the system logs, and you must ensure that the Ops Agent remains up to date. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse the gcloud CLI to install the Ops Agent on each VM listed in the Cloud Asset Inventory,",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSelect all VMs with an Agent status of Not detected on the Cloud Operations VMs dashboard. Then select Install agents.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse the gcloud CLI to create an Agent Policy.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tInstall the Ops Agent on the Compute Engine image by using a startup script"
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 7,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-10-10T03:32:00.000Z",
        "voteCount": 5,
        "content": "I vote for C as agent must install in current and feature VMs.\nhttps://cloud.google.com/stackdriver/docs/solutions/agents/ops-agent/managing-agent-policies"
      },
      {
        "date": "2024-08-11T16:49:00.000Z",
        "voteCount": 1,
        "content": "Definitely not C"
      },
      {
        "date": "2024-08-14T10:57:00.000Z",
        "voteCount": 1,
        "content": "Correction. It is C"
      },
      {
        "date": "2023-11-14T07:14:00.000Z",
        "voteCount": 3,
        "content": "Only C will ensure the installation will be done in the future as well."
      },
      {
        "date": "2023-10-12T10:38:00.000Z",
        "voteCount": 2,
        "content": "Option B"
      },
      {
        "date": "2023-10-09T23:06:00.000Z",
        "voteCount": 4,
        "content": "Answer C is the only one that can keep agents up to date, if automatic updates are set."
      },
      {
        "date": "2023-10-01T00:22:00.000Z",
        "voteCount": 2,
        "content": "Option A suggests using the gcloud CLI to install the Ops Agent on each VM manually, which can be time-consuming and error-prone, especially when dealing with a large number of instances.\n\noption B is the most efficient and appropriate choice for deploying and ensuring the continued use of the Ops Agent on both existing and future Compute Engine instances in your Google Cloud project."
      },
      {
        "date": "2023-11-06T04:11:00.000Z",
        "voteCount": 1,
        "content": "no, B cannot cover future instances"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 87,
    "url": "https://www.examtopics.com/discussions/google/view/123441-exam-professional-cloud-devops-engineer-topic-1-question-87/",
    "body": "Your company has a Google Cloud resource hierarchy with folders for production, test, and development. Your cyber security team needs to review your company's Google Cloud security posture to accelerate security issue identification and resolution. You need to centralize the logs generated by Google Cloud services from all projects only inside your production folder to allow for alerting and near-real time analysis. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEnable the Workflows API and route all the logs to Cloud Logging.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a central Cloud Monitoring workspace and attach all related projects.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate an aggregated log sink associated with the production folder that uses a Pub/Sub topic as the destination.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate an aggregated log sink associated with the production folder that uses a Cloud Logging bucket as the destination."
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 11,
        "isMostVoted": true
      },
      {
        "answer": "D",
        "count": 9,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2023-10-12T10:43:00.000Z",
        "voteCount": 11,
        "content": "D is correct as when you use buckets you can do log analysis"
      },
      {
        "date": "2023-11-06T07:54:00.000Z",
        "voteCount": 1,
        "content": "Does it address near-real-time analysis?"
      },
      {
        "date": "2023-11-10T22:00:00.000Z",
        "voteCount": 1,
        "content": "There is a delay with the Cloud Storage Bucket, but no delay appears to occur with the Log Bucket.\nhttps://cloud.google.com/logging/docs/export/configure_export_v2\n&gt; New log sinks to Cloud Storage buckets might take several hours to start routing logs. Sinks to Cloud Storage are processed hourly while other destination types are processed in real time."
      },
      {
        "date": "2024-09-13T09:22:00.000Z",
        "voteCount": 3,
        "content": "it is D, why should we use pub/sub for logs? are we crazy?"
      },
      {
        "date": "2024-08-11T10:35:00.000Z",
        "voteCount": 1,
        "content": "Customers would be very annoyed if they had to use an additional technology for something as simple as logs and analysis. Configuring pub/sub is foreign to a lot of orgs when they are used to tech like kafka. All you need is a sink to a Cloud Logging bucket. D"
      },
      {
        "date": "2024-02-25T04:37:00.000Z",
        "voteCount": 1,
        "content": "https://cloud.google.com/logging/docs/export/using_exported_logs#:~:text=Logs%20that%20you%20route%20to%20Cloud%20Logging%20buckets%20are%20available%20immediately."
      },
      {
        "date": "2024-02-17T06:42:00.000Z",
        "voteCount": 1,
        "content": "So, after some research. The correct answer is D.\n\nThere seems to be a lot of discussion, wether near-real time analysis is given or not. In Fact both C and D support near real-time analysis.\n\nhttps://cloud.google.com/logging/docs/export/using_exported_logs\n\"Logs that you route to Cloud Logging buckets are available immediately.\"\n\nhttps://cloud.google.com/logging/docs/export/pubsub\n\" Routed logs are generally available within seconds of their arrival to Logging, with 99% of logs available in less than 60 seconds.\"\n\nThe main difference lays somewhere else. The question states that the logs are retrieved from different projects. And in fact for this use case Cloud Logging is the preffered option:\nhttps://cloud.google.com/logging/docs/export/configure_export_v2\nCloud Logging: \" A log bucket can store logs that are received by multiple Google Cloud projects.\""
      },
      {
        "date": "2024-02-08T03:22:00.000Z",
        "voteCount": 3,
        "content": "It clearly mentions here that \n\"Sinks to Cloud Storage are processed hourly while other destination types are processed in real time.\"\nhttps://cloud.google.com/logging/docs/export/configure_export_v2#:~:text=New%20log%20sinks%20to%20Cloud%20Storage%20buckets%20might%20take%20several%20hours%20to%20start%20routing%20logs.%20Sinks%20to%20Cloud%20Storage%20are%20processed%20hourly%20while%20other%20destination%20types%20are%20processed%20in%20real%20time.\n\nD is eliminated"
      },
      {
        "date": "2024-02-17T06:46:00.000Z",
        "voteCount": 1,
        "content": "This is correct, but you are mixing two things up. A Cloud Logging Bucket is not the same as a Cloud Storage Bucket.\nhttps://cloud.google.com/logging/docs/export/configure_export_v2\n\nA Cloud Logging Bucket does process in real-time and is the preferred Option here."
      },
      {
        "date": "2023-12-25T11:31:00.000Z",
        "voteCount": 2,
        "content": "I would choose C ans to export the logs to a SIEM product, but if we can use a Cloud Logging bucket as a central repository I prefer and the statement doesn't say anything about exportation."
      },
      {
        "date": "2023-12-14T00:19:00.000Z",
        "voteCount": 1,
        "content": "Answer is C. Cloud Logging includes the capability for log archival in Google Cloud Storage and the ability to send logs to Google BigQuery.  In addition, Cloud Logging also allows you to forward these logs to any custom endpoint including third party log management services for advanced and tailored log analytics via the near real-time streaming Google Cloud Pub/Sub API."
      },
      {
        "date": "2023-12-04T10:58:00.000Z",
        "voteCount": 1,
        "content": "By creating an aggregated log sink at the folder level for production, you can collect logs from all projects within that folder. Using a Cloud Logging bucket as the destination simplifies management and enables straightforward integration with Cloud Monitoring and alerting tools for security analysis."
      },
      {
        "date": "2023-11-14T07:21:00.000Z",
        "voteCount": 4,
        "content": "I would vote C because from a security perspective it would be better to stream the logs to a SIEM or SOAR for near-real time analysis and alerting. A SIEM is not really mentioned here but streaming them to a bucket and analysing them from stackdriver would be nuts"
      },
      {
        "date": "2023-11-10T22:02:00.000Z",
        "voteCount": 1,
        "content": "I think D is correct"
      },
      {
        "date": "2023-11-06T06:12:00.000Z",
        "voteCount": 4,
        "content": "C seems an to be correct."
      },
      {
        "date": "2023-10-21T10:05:00.000Z",
        "voteCount": 4,
        "content": "Answer C  seems to be correct. \nhttps://cloudplatform.googleblog.com/2015/06/Real-Time-Log-Streaming-and-Analysis-with-Google-Cloud-Platform-Logentries.html"
      },
      {
        "date": "2023-10-17T21:54:00.000Z",
        "voteCount": 4,
        "content": "C is the answer: sink is the native feature of GCP to route logs and this excludes A and B. Also being asked to achieve near-real time analysis, and the pub-sub works better then a bucket."
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 88,
    "url": "https://www.examtopics.com/discussions/google/view/122005-exam-professional-cloud-devops-engineer-topic-1-question-88/",
    "body": "You are configuring the frontend tier of an application deployed in Google Cloud. The frontend tier is hosted in nginx and deployed using a managed instance group with an Envoy-based external HTTP(S) load balancer in front. The application is deployed entirely within the europe-west2 region, and only serves users based in the United Kingdom. You need to choose the most cost-effective network tier and load balancing configuration. What should you use?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tPremium Tier with a global load balancer",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tPremium Tier with a regional load balancer",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tStandard Tier with a global load balancer",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tStandard Tier with a regional load balancer\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 11,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-10-22T19:36:00.000Z",
        "voteCount": 7,
        "content": "I think D is correct for saving cost and single region"
      },
      {
        "date": "2023-11-14T07:23:00.000Z",
        "voteCount": 2,
        "content": "D is the cheapest and would work in this scenario"
      },
      {
        "date": "2023-11-06T06:10:00.000Z",
        "voteCount": 2,
        "content": "D is correct."
      },
      {
        "date": "2023-10-01T00:29:00.000Z",
        "voteCount": 4,
        "content": "D is  correct Answer"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 89,
    "url": "https://www.examtopics.com/discussions/google/view/122006-exam-professional-cloud-devops-engineer-topic-1-question-89/",
    "body": "You recently deployed your application in Google Kubernetes Engine (GKE) and now need to release a new version of the application. You need the ability to instantly roll back to the previous version of the application in case there are issues with the new version. Which deployment model should you use?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tPerform a rolling deployment, and test your new application after the deployment is complete.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tPerform A/B testing, and test your application periodically after the deployment is complete.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tPerform a canary deployment, and test your new application periodically after the new version is deployed.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tPerform a blue/green deployment, and test your new application after the deployment is complete.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 7,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-02-08T03:41:00.000Z",
        "voteCount": 1,
        "content": "https://cloud.google.com/architecture/application-deployment-and-testing-strategies#key_benefits_3"
      },
      {
        "date": "2023-12-16T08:39:00.000Z",
        "voteCount": 2,
        "content": "instantly roll back, so I think it's D"
      },
      {
        "date": "2023-12-04T11:33:00.000Z",
        "voteCount": 1,
        "content": "his method involves deploying the new version of your application alongside the old version (two separate but identical environments: blue for the old version and green for the new one). You then switch traffic from blue to green. If any issues arise with the green environment (the new version), you can instantly route traffic back to the blue environment (the old version). This approach offers the fastest rollback mechanism as it merely involves a change in the traffic routing."
      },
      {
        "date": "2023-11-06T06:08:00.000Z",
        "voteCount": 1,
        "content": "D is correct."
      },
      {
        "date": "2023-10-16T19:11:00.000Z",
        "voteCount": 2,
        "content": "D is correct"
      },
      {
        "date": "2023-10-11T18:15:00.000Z",
        "voteCount": 1,
        "content": "Agree.  D is the correct answer."
      },
      {
        "date": "2023-10-08T23:54:00.000Z",
        "voteCount": 1,
        "content": "D is correct\nhttps://cloud.google.com/architecture/application-deployment-and-testing-strategies"
      },
      {
        "date": "2023-10-01T00:30:00.000Z",
        "voteCount": 2,
        "content": "D is correct Answer"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 90,
    "url": "https://www.examtopics.com/discussions/google/view/122008-exam-professional-cloud-devops-engineer-topic-1-question-90/",
    "body": "You are building and deploying a microservice on Cloud Run for your organization. Your service is used by many applications internally. You are deploying a new release, and you need to test the new version extensively in the staging and production environments. You must minimize user and developer impact. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDeploy the new version of the service to the staging environment. Split the traffic, and allow 1% of traffic through to the latest version. Test the latest version. If the test passes, gradually roll out the latest version to the staging and production environments.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDeploy the new version of the service to the staging environment. Split the traffic, and allow 50% of traffic through to the latest version. Test the latest version. If the test passes, send all traffic to the latest version. Repeat for the production environment.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDeploy the new version of the service to the staging environment with a new-release tag without serving traffic. Test the new-release version. If the test passes, gradually roll out this tagged version. Repeat for the production environment.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDeploy a new environment with the green tag to use as the staging environment. Deploy the new version of the service to the green environment and test the new version. If the tests pass, send all traffic to the green environment and delete the existing staging environment. Repeat for the production environment."
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 10,
        "isMostVoted": true
      },
      {
        "answer": "A",
        "count": 7,
        "isMostVoted": false
      },
      {
        "answer": "D",
        "count": 4,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2023-10-11T18:25:00.000Z",
        "voteCount": 7,
        "content": "Answers A and B split traffic, but C has a gradual rollout which doesn't have instant rollback.  D with the blue/green deployment has instant rollback with no impact to either users or developers.  I believe the answer is D."
      },
      {
        "date": "2024-08-14T11:24:00.000Z",
        "voteCount": 1,
        "content": "D. No impact"
      },
      {
        "date": "2024-02-09T08:55:00.000Z",
        "voteCount": 1,
        "content": "A. Deploying the new version to the staging environment and allowing only 1% of traffic to the latest version minimizes user and developer impact, as the majority of traffic continues to be served by the current version. Testing the latest version in the staging environment ensures that any issues can be identified and addressed before rolling out the new version to production.\n\nnot C cause:\nDeploying the new version with a new-release tag without serving traffic in the staging environment delays the testing process and does not provide an accurate representation of how the new version performs under real-world conditions with actual traffic."
      },
      {
        "date": "2024-02-08T03:54:00.000Z",
        "voteCount": 2,
        "content": "https://cloud.google.com/run/docs/rollouts-rollbacks-traffic-migration#:~:text=A%20common%20use,the%20tagged%20revision."
      },
      {
        "date": "2023-12-05T16:35:00.000Z",
        "voteCount": 1,
        "content": "Choose A.\n\nThis approach allows for thorough testing while minimizing the risk of impacting users and developers. It provides a controlled rollout with the ability to monitor and react to any issues that may arise during the deployment process.\n\nOption A aligns with best practices for deploying and testing new versions in a microservices environment."
      },
      {
        "date": "2023-12-21T18:09:00.000Z",
        "voteCount": 1,
        "content": "Why not D?"
      },
      {
        "date": "2023-12-05T16:34:00.000Z",
        "voteCount": 1,
        "content": "Choose A"
      },
      {
        "date": "2023-12-04T11:39:00.000Z",
        "voteCount": 4,
        "content": "This approach allows you to deploy and test the new version without impacting users, as no traffic is directed to the new version initially. After thorough testing in the staging environment, you can confidently roll out the new version to a small percentage of users in the production environment, gradually increasing it while monitoring performance and stability. This method offers a controlled and safe way to introduce changes."
      },
      {
        "date": "2023-11-24T08:43:00.000Z",
        "voteCount": 2,
        "content": "I would go for D as it is the only one that will not impact users or devs"
      },
      {
        "date": "2023-11-01T11:35:00.000Z",
        "voteCount": 3,
        "content": "Deploy it without serving a traffic. this approach is the optimal since we need to test it intensively. this will avoid the negative impact"
      },
      {
        "date": "2023-10-21T22:18:00.000Z",
        "voteCount": 4,
        "content": "I think A.\nneed a canary to reduce the sphere of influence."
      },
      {
        "date": "2023-10-17T12:27:00.000Z",
        "voteCount": 3,
        "content": "D should be it"
      },
      {
        "date": "2023-10-16T19:18:00.000Z",
        "voteCount": 1,
        "content": "Rethinking answer is C for using release tag.   \"You are deploying a new release, and you need to test the new version extensively in the staging and production environments. You must minimize user and developer impact. \""
      },
      {
        "date": "2023-12-22T08:42:00.000Z",
        "voteCount": 1,
        "content": "Answer C says \"gradually\", then it can not be the correct if we have to minimize user and developer impact. Answer D is the only who says \"send all the traffic\", I understand this is the key in this question if you wnat to minimize user and developer impact. Answer A &amp; B establish different ratios -&gt; gradually"
      },
      {
        "date": "2023-12-23T01:30:00.000Z",
        "voteCount": 1,
        "content": "But, after reading this link, https://cloud.google.com/run/docs/rollouts-rollbacks-traffic-migration, I could choose C perfectly. I don't know between C or D, you don't have to use the word \"green\" for the tag"
      },
      {
        "date": "2023-10-13T11:16:00.000Z",
        "voteCount": 1,
        "content": "I will go with C"
      },
      {
        "date": "2023-10-01T00:37:00.000Z",
        "voteCount": 1,
        "content": "A, B, and C involve splitting traffic, which may not provide the level of isolation required for extensive testing without impacting users and developers\n\nCorrect Answer is D"
      },
      {
        "date": "2023-10-18T20:14:00.000Z",
        "voteCount": 2,
        "content": "shouldn't be D since the question said that \"you need to test the new version extensively in the staging and production environments.\", D is a new environment. I will go with A"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 91,
    "url": "https://www.examtopics.com/discussions/google/view/123036-exam-professional-cloud-devops-engineer-topic-1-question-91/",
    "body": "You work for a global organization and run a service with an availability target of 99% with limited engineering resources.<br>For the current calendar month, you noticed that the service has 99.5% availability. You must ensure that your service meets the defined availability goals and can react to business changes, including the upcoming launch of new features.<br>You also need to reduce technical debt while minimizing operational costs. You want to follow Google-recommended practices. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAdd N+1 redundancy to your service by adding additional compute resources to the service.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tIdentify, measure, and eliminate toil by automating repetitive tasks.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDefine an error budget for your service level availability and minimize the remaining error budget.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAllocate available engineers to the feature backlog while you ensure that the service remains within the availability target."
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 8,
        "isMostVoted": true
      },
      {
        "answer": "C",
        "count": 2,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2023-12-05T18:04:00.000Z",
        "voteCount": 4,
        "content": "Option B suggests focusing on identifying, measuring, and eliminating toil through the automation of repetitive tasks.\n\nIn the context of running a service with a 99% availability target and limited engineering resources, this approach aligns with Google's Site Reliability Engineering (SRE) principles. By automating manual and repetitive operational work, engineering teams can enhance efficiency, reduce the risk of human error, and free up valuable resources.\n\nThe emphasis on eliminating toil not only contributes to meeting availability targets by minimizing the potential for errors but also allows engineering teams to allocate more time to strategic tasks, reducing technical debt, and facilitating a more agile response to business changes, such as the launch of new features.\n\nOverall, Option B addresses the need for operational efficiency and resource optimization to ensure the reliability of the service."
      },
      {
        "date": "2023-12-04T11:42:00.000Z",
        "voteCount": 1,
        "content": "Automating repetitive tasks (toil) is a key practice recommended by Google, especially for teams with limited engineering resources. By reducing toil, your team can focus more on high-value activities that improve the service and deliver new features. Automation not only improves efficiency but also helps maintain service reliability by reducing the likelihood of human error."
      },
      {
        "date": "2023-11-14T09:39:00.000Z",
        "voteCount": 3,
        "content": "I would go for B as I think it will minimize ops costs and reduce technical debt"
      },
      {
        "date": "2023-10-21T22:20:00.000Z",
        "voteCount": 2,
        "content": "I think C."
      },
      {
        "date": "2023-10-11T18:31:00.000Z",
        "voteCount": 1,
        "content": "You also need to reduce technical debt while minimizing operational costs. You want to follow Google-recommended practices.  Answer C fits this criteria."
      },
      {
        "date": "2023-10-09T16:46:00.000Z",
        "voteCount": 1,
        "content": "C is the answer I think."
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 92,
    "url": "https://www.examtopics.com/discussions/google/view/123803-exam-professional-cloud-devops-engineer-topic-1-question-92/",
    "body": "You are developing the deployment and testing strategies for your CI/CD pipeline in Google Cloud. You must be able to:<br>\u2022\tReduce the complexity of release deployments and minimize the duration of deployment rollbacks.<br>\u2022\tTest real production traffic with a gradual increase in the number of affected users.<br><br>You want to select a deployment and testing strategy that meets your requirements. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRecreate deployment and canary testing",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tBlue/green deployment and canary testing\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRolling update deployment and A/B testing",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRolling update deployment and shadow testing"
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 12,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-10-16T19:22:00.000Z",
        "voteCount": 6,
        "content": "B seems to be correct answer."
      },
      {
        "date": "2024-02-08T06:40:00.000Z",
        "voteCount": 1,
        "content": "https://cloud.google.com/architecture/application-deployment-and-testing-strategies\nBlue Gree deployment because its instant rollback\nCanary testing because I can test on subset of users with gradual rollout"
      },
      {
        "date": "2023-12-05T18:06:00.000Z",
        "voteCount": 1,
        "content": "B. Blue/green deployment and canary testing\n\nExplanation:\n- Blue/Green Deployment: In a blue/green deployment, you maintain two separate environments, one (blue) with the current version of your application in production and another (green) with the new version. You switch traffic from the blue environment to the green environment once testing is successful.\n- Canary Testing: Canary testing involves gradually rolling out a new version of the application to a small subset of users or traffic. This allows for real production traffic testing with minimal impact, and if issues are detected, the deployment can be rolled back quickly."
      },
      {
        "date": "2023-12-04T11:58:00.000Z",
        "voteCount": 1,
        "content": "B should be Answer."
      },
      {
        "date": "2023-11-05T22:03:00.000Z",
        "voteCount": 1,
        "content": "B should be Answer."
      },
      {
        "date": "2023-10-21T22:23:00.000Z",
        "voteCount": 2,
        "content": "I think B"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 93,
    "url": "https://www.examtopics.com/discussions/google/view/122633-exam-professional-cloud-devops-engineer-topic-1-question-93/",
    "body": "You are creating a CI/CD pipeline to perform Terraform deployments of Google Cloud resources. Your CI/CD tooling is running in Google Kubernetes Engine (GKE) and uses an ephemeral Pod for each pipeline run. You must ensure that the pipelines that run in the Pods have the appropriate Identity and Access Management (IAM) permissions to perform the Terraform deployments. You want to follow Google-recommended practices for identity management. What should you do? (Choose two.)",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a new Kubernetes service account, and assign the service account to the Pods. Use Workload Identity to authenticate as the Google service account.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a new JSON service account key for the Google service account, store the key as a Kubernetes secret, inject the key into the Pods, and set the GOOGLE_APPLICATION_CREDENTIALS environment variable.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a new Google service account, and assign the appropriate IAM permissions.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a new JSON service account key for the Google service account, store the key in the secret management store for the CI/CD tool, and configure Terraform to use this key for authentication.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAssign the appropriate IAM permissions to the Google service account associated with the Compute Engine VM instances that run the Pods."
    ],
    "answer": "AC",
    "answerDescription": "",
    "votes": [
      {
        "answer": "AC",
        "count": 11,
        "isMostVoted": true
      },
      {
        "answer": "CD",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2024-08-14T11:33:00.000Z",
        "voteCount": 1,
        "content": "C and D. Gke service account needs to impersonate."
      },
      {
        "date": "2023-12-05T18:13:00.000Z",
        "voteCount": 4,
        "content": "Option A: Suggests creating a new Kubernetes service account and assigning it to the Pods. This service account is then associated with a Google service account using Workload Identity. This setup enables seamless authentication of Pods as the specified Google service account without relying on manual management of service account keys.\n\nOption C: Complements the approach by emphasizing the creation of a new Google service account and assigning the necessary IAM permissions. While the Kubernetes service account establishes the identity within the GKE cluster, the Google service account is associated with the underlying Google Cloud resources, ensuring that the appropriate permissions are granted for Terraform deployments."
      },
      {
        "date": "2023-11-01T11:58:00.000Z",
        "voteCount": 4,
        "content": "A.for the pod to authenticate as service account with the necessary permissions without handling keys\nC.to perform operations on google cloud ressources"
      },
      {
        "date": "2023-10-25T10:05:00.000Z",
        "voteCount": 3,
        "content": "I would go with A,C"
      },
      {
        "date": "2023-10-22T14:05:00.000Z",
        "voteCount": 4,
        "content": "I think is A, C \nWorkload Identity is the recommended way to authenticate to Google Cloud services from GKE. \nreference: https://cloud.google.com/kubernetes-engine/docs/tutorials/authenticating-to-cloud-platform"
      },
      {
        "date": "2023-10-11T18:54:00.000Z",
        "voteCount": 2,
        "content": "B, C are best answers per the URL link below.  \nhttps://cloud.google.com/kubernetes-engine/docs/tutorials/authenticating-to-cloud-platform"
      },
      {
        "date": "2023-10-11T18:41:00.000Z",
        "voteCount": 2,
        "content": "Why not answers C, D?"
      },
      {
        "date": "2023-10-17T22:48:00.000Z",
        "voteCount": 1,
        "content": "you don't want to configure tf to consume the key, instead you delegate the auth to the kube things like pod"
      },
      {
        "date": "2023-10-05T20:43:00.000Z",
        "voteCount": 2,
        "content": "My Recomendtion is CB"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 94,
    "url": "https://www.examtopics.com/discussions/google/view/123804-exam-professional-cloud-devops-engineer-topic-1-question-94/",
    "body": "You are the on-call Site Reliability Engineer for a microservice that is deployed to a Google Kubernetes Engine (GKE) Autopilot cluster. Your company runs an online store that publishes order messages to Pub/Sub, and a microservice receives these messages and updates stock information in the warehousing system. A sales event caused an increase in orders, and the stock information is not being updated quickly enough. This is causing a large number of orders to be accepted for products that are out of stock. You check the metrics for the microservice and compare them to typical levels:<br><br><img src=\"https://img.examtopics.com/professional-cloud-devops-engineer/image1.png\"><br><br>You need to ensure that the warehouse system accurately reflects product inventory at the time orders are placed and minimize the impact on customers. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDecrease the acknowledgment deadline on the subscription.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAdd a virtual queue to the online store that allows typical traffic levels.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tIncrease the number of Pod replicas.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tIncrease the Pod CPU and memory limits."
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 9,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-10-16T19:25:00.000Z",
        "voteCount": 6,
        "content": "Agree with C as answer."
      },
      {
        "date": "2023-10-17T17:04:00.000Z",
        "voteCount": 1,
        "content": "How does increasing the pod replica help? The pod memory and cpu have barely gone up. Shouldn't it be B?"
      },
      {
        "date": "2023-10-28T15:21:00.000Z",
        "voteCount": 3,
        "content": "The increase in the number of undelivered messages indicates that the microservice is not fully processing the messages.\nIt is believed that the number of messages that can be processed can be increased by increasing the number of pods."
      },
      {
        "date": "2024-02-06T19:10:00.000Z",
        "voteCount": 1,
        "content": "Given the scenario where a sales event has caused an increase in orders and the stock information is not being updated quickly enough, leading to a large number of orders being accepted for out-of-stock products, the most appropriate action to ensure that the warehouse system accurately reflects product inventory at the time of order placement and minimize the impact on customers would be:\n\nC. Increase the number of Pod replicas.\n\nIncreasing the number of Pod replicas can help scale out the microservice to handle the increased load efficiently. This will allow the microservice to process the order messages and update the stock information in the warehousing system more quickly, reducing the likelihood of accepting orders for out-of-stock products. This approach addresses the issue at its root by ensuring that there are enough resources available to handle the increased workload effectively."
      },
      {
        "date": "2023-12-05T18:18:00.000Z",
        "voteCount": 1,
        "content": "Increasing the number of Pod replicas (Option C) is a suitable solution as it allows the microservice deployed in the Google Kubernetes Engine (GKE) Autopilot cluster to efficiently handle a surge in orders during a sales event.\n\nBy scaling horizontally, additional instances of the microservice are created, enabling parallel processing of order messages and reducing the backlog. This approach leverages the flexibility and automation of GKE Autopilot, ensuring that the infrastructure dynamically adapts to the increased load, providing a more responsive and scalable solution to minimize the impact on customers and maintain accurate stock information in the warehousing system."
      },
      {
        "date": "2023-12-04T12:55:00.000Z",
        "voteCount": 1,
        "content": "Answer C. This action would help accommodate the increased load by parallelizing the work and should be implemented first to mitigate the issue. If after scaling the number of replicas the CPU or memory usage approaches the limits, then considering scaling up the resources (CPU and memory limits) for each Pod might be the next step."
      },
      {
        "date": "2023-11-25T10:27:00.000Z",
        "voteCount": 1,
        "content": "The average acknowledgement latency from Pub/Sub has not significantly increased, which suggests that Pub/Sub is still able to handle the message load effectively. However, the significant increase in the oldest unacknowledged message age and the number of undelivered messages indicates that the pods are not processing the messages quickly enough.\n\nIncreasing the number of Pod replicas would allow your microservice to process more messages concurrently, reducing the backlog and ensuring that stock information is updated more quickly."
      },
      {
        "date": "2023-10-23T11:51:00.000Z",
        "voteCount": 1,
        "content": "B for sure."
      },
      {
        "date": "2023-12-21T11:44:00.000Z",
        "voteCount": 1,
        "content": "It would work but degrade the user experience and therefore not suitable."
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 95,
    "url": "https://www.examtopics.com/discussions/google/view/122018-exam-professional-cloud-devops-engineer-topic-1-question-95/",
    "body": "Your team deploys applications to three Google Kubernetes Engine (GKE) environments: development, staging, and production. You use GitHub repositories as your source of truth. You need to ensure that the three environments are consistent. You want to follow Google-recommended practices to enforce and install network policies and a logging DaemonSet on all the GKE clusters in those environments. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse Google Cloud Deploy to deploy the network policies and the DaemonSet. Use Cloud Monitoring to trigger an alert if the network policies and DaemonSet drift from your source in the repository.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse Google Cloud Deploy to deploy the DaemonSet and use Policy Controller to configure the network policies. Use Cloud Monitoring to detect drifts from the source in the repository and Cloud Functions to correct the drifts.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse Cloud Build to render and deploy the network policies and the DaemonSet. Set up Config Sync to sync the configurations for the three environments.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse Cloud Build to render and deploy the network policies and the DaemonSet. Set up a Policy Controller to enforce the configurations for the three environments.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 5,
        "isMostVoted": true
      },
      {
        "answer": "C",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2023-10-01T02:49:00.000Z",
        "voteCount": 8,
        "content": "Option C is not as effective as Option D because it does not enforce the network policies and DaemonSet configurations. This means that unauthorized changes could still be made to the configurations.\n\nConfig Sync is a tool that can be used to synchronize Kubernetes configurations across multiple clusters. However, it does not prevent unauthorized changes from being made to the configurations.\n\nPolicy Controller is a tool that can be used to enforce Kubernetes configurations. It does this by monitoring the Kubernetes API for changes to the configurations and automatically reverting unauthorized changes.\n\nTherefore, Option D is a more secure and reliable option for ensuring that the network policies and DaemonSet are enforced and installed consistently across the three environments."
      },
      {
        "date": "2024-08-11T11:04:00.000Z",
        "voteCount": 1,
        "content": "Its a toss up here. C hits all the keywords in \"https://cloud.google.com/kubernetes-engine/enterprise/config-sync/docs/overview\" - source of truth, gitops, but does  not talk about enforcement. However, policy controller is a subset of configsync and it does handle enforcement.\n\n\"Constraints can be applied directly to your clusters using the Kubernetes API, or distributed to a set of clusters from a centralized source, like a Git repository, by using Config Sync.\" https://cloud.google.com/kubernetes-engine/enterprise/policy-controller/docs/overview#constraints\n\nReally seems like a trick question leading you to D when C is the right answer with the knowledge that you would configure policy controller as a sub step when setting up config sync for your gitops."
      },
      {
        "date": "2024-06-06T03:37:00.000Z",
        "voteCount": 1,
        "content": "This method leverages Cloud Build for rendering and deploying configurations, and Config Sync to ensure that the desired state specified in your GitHub repositories is consistently applied across all GKE clusters. This approach provides robust management and automatic synchronization, ensuring that configurations remain consistent across development, staging, and production environments."
      },
      {
        "date": "2024-06-06T03:39:00.000Z",
        "voteCount": 1,
        "content": "C better than D: While Cloud Build and Policy Controller can work together, Config Sync provides a more complete solution for synchronizing configurations across multiple clusters."
      },
      {
        "date": "2024-05-11T11:39:00.000Z",
        "voteCount": 1,
        "content": "Should be D"
      },
      {
        "date": "2024-02-15T17:53:00.000Z",
        "voteCount": 1,
        "content": "Policy Controller can enforce the configurations specified in the repositories, ensuring consistency across the environments and enforcing compliance with defined policies."
      },
      {
        "date": "2024-02-04T05:17:00.000Z",
        "voteCount": 3,
        "content": "Option C is the right one.\"\nCloud Build:\n\nIdeal for building and deploying software artifacts based on your GitHub repositories, your chosen source of truth.\nRenders your network policies and DaemonSet configurations, ensuring consistency before deployment.\nConfig Sync:\n\nDesigned for configuration management across GKE clusters.\nContinuously synchronizes your rendered configurations (network policies and DaemonSet) from GitHub to all three environments (development, staging, production).\nProvides automated drift detection and remediation, ensuring consistency remains enforced."
      },
      {
        "date": "2023-12-05T18:22:00.000Z",
        "voteCount": 1,
        "content": "Option D is the recommended approach for ensuring consistency across the three Google Kubernetes Engine (GKE) environments\u2014development, staging, and production\u2014while adhering to Google-recommended practices.\n\nBy using Cloud Build to render and deploy network policies and a DaemonSet, and implementing Policy Controller, you can enforce configurations uniformly across environments.\n\nPolicy Controller ensures that the deployed configurations align with your desired state, providing a consistent and policy-driven approach. This method leverages the declarative nature of Kubernetes configurations, facilitating configuration management.\n\nOverall, Option D combines infrastructure-as-code principles with policy enforcement to maintain consistency and enhance manageability across GKE clusters in different environments."
      },
      {
        "date": "2023-11-20T09:30:00.000Z",
        "voteCount": 1,
        "content": "I would go for D as well"
      },
      {
        "date": "2023-11-04T02:28:00.000Z",
        "voteCount": 1,
        "content": "\"Policy Controller can catch and enforce policy violations on those resources before they are deployed. \"\n\nhttps://cloud.google.com/anthos-config-management/docs/concepts/config-controller-overview"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 96,
    "url": "https://www.examtopics.com/discussions/google/view/122634-exam-professional-cloud-devops-engineer-topic-1-question-96/",
    "body": "You are using Terraform to manage infrastructure as code within a CI/CD pipeline. You notice that multiple copies of the entire infrastructure stack exist in your Google Cloud project, and a new copy is created each time a change to the existing infrastructure is made. You need to optimize your cloud spend by ensuring that only a single instance of your infrastructure stack exists at a time. You want to follow Google-recommended practices. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a new pipeline to delete old infrastructure stacks when they are no longer needed.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfirm that the pipeline is storing and retrieving the terraform.tfstate file from Cloud Storage with the Terraform gcs backend.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tVerify that the pipeline is storing and retrieving the terraform.tfstate file from a source control.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUpdate the pipeline to remove any existing infrastructure before you apply the latest configuration."
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 7,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-02-15T17:55:00.000Z",
        "voteCount": 1,
        "content": "The Terraform tfstate file contains the state of the infrastructure managed by Terraform. Storing this file in Cloud Storage with the Terraform Google Cloud Storage (GCS) backend ensures that it is shared across executions of the pipeline."
      },
      {
        "date": "2024-02-08T07:04:00.000Z",
        "voteCount": 1,
        "content": "https://cloud.google.com/docs/terraform/resource-management/managing-infrastructure-as-code#configuring_terraform_to_store_state_in_a_cloud_storage_bucket"
      },
      {
        "date": "2023-12-26T08:18:00.000Z",
        "voteCount": 1,
        "content": "B is correct, storing the state file to the gcs bucket maintains the state correctly"
      },
      {
        "date": "2023-12-05T18:28:00.000Z",
        "voteCount": 1,
        "content": "Option B is the recommended approach to optimize cloud spending and ensure a single instance of your infrastructure stack exists at a time when using Terraform within a CI/CD pipeline.\n\nBy storing and retrieving the terraform.tfstate file from Cloud Storage with the Terraform Google Cloud Storage (GCS) backend, you centralize the state management. This ensures that Terraform has a single source of truth for the infrastructure state, preventing the creation of redundant instances.\n\nThe GCS backend enables state locking, consistency, and collaboration across the CI/CD pipeline, allowing for proper tracking and management of infrastructure changes. This practice helps avoid unnecessary duplication of resources and promotes efficient cloud spend management."
      },
      {
        "date": "2023-11-05T21:47:00.000Z",
        "voteCount": 1,
        "content": "B is correct."
      },
      {
        "date": "2023-10-21T22:31:00.000Z",
        "voteCount": 3,
        "content": "B is correct."
      },
      {
        "date": "2023-10-05T21:16:00.000Z",
        "voteCount": 3,
        "content": "B appears correct to me."
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 97,
    "url": "https://www.examtopics.com/discussions/google/view/122020-exam-professional-cloud-devops-engineer-topic-1-question-97/",
    "body": "You are creating Cloud Logging sinks to export log entries from Cloud Logging to BigQuery for future analysis. Your organization has a Google Cloud folder named Dev that contains development projects and a folder named Prod that contains production projects. Log entries for development projects must be exported to dev_dataset, and log entries for production projects must be exported to prod_dataset. You need to minimize the number of log sinks created, and you want to ensure that the log sinks apply to future projects. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a single aggregated log sink at the organization level.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a log sink in each project.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate two aggregated log sinks at the organization level, and filter by project ID.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate an aggregated log sink in the Dev and Prod folders.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 3,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-10-05T21:56:00.000Z",
        "voteCount": 6,
        "content": "I vote for D"
      },
      {
        "date": "2023-12-05T18:31:00.000Z",
        "voteCount": 2,
        "content": "To minimize the number of log sinks and ensure that the log sink configurations are applied to future projects, the optimal choice is Option D.\n\nBy creating an aggregated log sink at the folder level for both the Dev and Prod folders, you can enforce consistent export configurations for all existing and forthcoming projects within each folder.\n\nThis approach facilitates centralized management, eliminating the need for creating individual sinks for each project. It reduces complexity and ensures that any new projects added to the Dev or Prod folders will automatically adopt the log sink configuration, streamlining the process and fostering uniformity throughout the organization."
      },
      {
        "date": "2023-11-14T05:22:00.000Z",
        "voteCount": 1,
        "content": "need to create two sinks at folder level. if there is new projects inside each folder, the rule will be applied to them too"
      },
      {
        "date": "2023-10-23T11:56:00.000Z",
        "voteCount": 3,
        "content": "D for sure."
      },
      {
        "date": "2023-10-01T03:21:00.000Z",
        "voteCount": 2,
        "content": "C. Create two aggregated log sinks at the organization level, and filter by project ID.\n\nBy creating two aggregated log sinks at the organization level and applying filters based on project ID, you can achieve the desired log entry routing for both development and production projects. This approach allows for scalability and ensures that future projects in the respective folders will inherit the log sink configurations."
      },
      {
        "date": "2023-10-03T04:59:00.000Z",
        "voteCount": 2,
        "content": "I vote for D. If you use project ID, you can't scale. Your explanation also suggests D, because if you configure the sink at folder level, all projects into folder (present and future) inherit the sink."
      },
      {
        "date": "2023-11-09T10:47:00.000Z",
        "voteCount": 3,
        "content": "but doesn't apply for future projects hence D is a better option"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 98,
    "url": "https://www.examtopics.com/discussions/google/view/122383-exam-professional-cloud-devops-engineer-topic-1-question-98/",
    "body": "Your company runs services by using multiple globally distributed Google Kubernetes Engine (GKE) clusters. Your operations team has set up workload monitoring that uses Prometheus-based tooling for metrics, alerts, and generating dashboards. This setup does not provide a method to view metrics globally across all clusters. You need to implement a scalable solution to support global Prometheus querying and minimize management overhead. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure Prometheus cross-service federation for centralized data access.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure workload metrics within Cloud Operations for GKE.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure Prometheus hierarchical federation for centralized data access.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure Google Cloud Managed Service for Prometheus.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 3,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-10-17T05:50:00.000Z",
        "voteCount": 7,
        "content": "D options is looking more sutaible.\nhttps://cloud.google.com/stackdriver/docs/managed-prometheus"
      },
      {
        "date": "2023-12-05T18:35:00.000Z",
        "voteCount": 1,
        "content": "The most effective solution for achieving scalable global Prometheus querying while minimizing management complexity is Option D, \"Configure Google Cloud Managed Service for Prometheus.\"\n\nThis approach involves leveraging the fully managed service offered by Google Cloud for Prometheus, which streamlines the collection, querying, and alerting on metrics. With this service, you can effortlessly centralize metrics from various globally distributed GKE clusters, eliminating the need for intricate configurations or federation mechanisms.\n\nBy opting for the Google Cloud Managed Service for Prometheus, you simplify operational tasks, reduce administrative overhead, and gain a unified and straightforward method for monitoring and analyzing metrics on a global scale across all clusters within the Google Cloud environment."
      },
      {
        "date": "2023-10-28T10:13:00.000Z",
        "voteCount": 2,
        "content": "https://cloud.google.com/stackdriver/docs/managed-prometheus"
      },
      {
        "date": "2023-10-23T19:52:00.000Z",
        "voteCount": 1,
        "content": "Answer D is the best."
      },
      {
        "date": "2023-10-04T06:35:00.000Z",
        "voteCount": 4,
        "content": "Appear D is right"
      },
      {
        "date": "2023-10-05T20:46:00.000Z",
        "voteCount": 1,
        "content": "@PrayasMohanty  : Could you please review the questions set all the way to the end"
      },
      {
        "date": "2023-10-10T20:25:00.000Z",
        "voteCount": 2,
        "content": "Google Cloud Managed Service for Prometheus is Google Cloud's fully managed, multi-cloud, cross-project solution for Prometheus metrics. It lets you globally monitor and alert on your workloads, using Prometheus, without having to manually manage and operate Prometheus at scale.\n\nManaged Service for Prometheus collects metrics from Prometheus exporters and lets you query the data globally using PromQL, meaning that you can keep using any existing Grafana dashboards, PromQL-based alerts, and workflows. It is hybrid- and multi-cloud compatible, can monitor both Kubernetes and VM workloads, retains data for 24 months, and maintains portability by staying compatible with upstream Prometheus.\n\nReference: https://cloud.google.com/stackdriver/docs/managed-prometheus"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 99,
    "url": "https://www.examtopics.com/discussions/google/view/122021-exam-professional-cloud-devops-engineer-topic-1-question-99/",
    "body": "You need to build a CI/CD pipeline for a containerized application in Google Cloud. Your development team uses a central Git repository for trunk-based development. You want to run all your tests in the pipeline for any new versions of the application to improve the quality. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t1. Install a Git hook to require developers to run unit tests before pushing the code to a central repository.<br>2. Trigger Cloud Build to build the application container. Deploy the application container to a testing environment, and run integration tests.<br>3. If the integration tests are successful, deploy the application container to your production environment, and run acceptance tests.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t1. Install a Git hook to require developers to run unit tests before pushing the code to a central repository. If all tests are successful, build a container.<br>2. Trigger Cloud Build to deploy the application container to a testing environment, and run integration tests and acceptance tests.<br>3. If all tests are successful, tag the code as production ready. Trigger Cloud Build to build and deploy the application container to the production environment.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t1. Trigger Cloud Build to build the application container, and run unit tests with the container.<br>2. If unit tests are successful, deploy the application container to a testing environment, and run integration tests.<br>3. If the integration tests are successful, the pipeline deploys the application container to the production environment. After that, run acceptance tests.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t1. Trigger Cloud Build to run unit tests when the code is pushed. If all unit tests are successful, build and push the application container to a central registry.<br>2. Trigger Cloud Build to deploy the container to a testing environment, and run integration tests and acceptance tests.<br>3. If all tests are successful, the pipeline deploys the application to the production environment and runs smoke tests\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 11,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-10-05T22:19:00.000Z",
        "voteCount": 6,
        "content": "I vote for B"
      },
      {
        "date": "2023-10-21T22:39:00.000Z",
        "voteCount": 5,
        "content": "I think D"
      },
      {
        "date": "2024-08-11T11:28:00.000Z",
        "voteCount": 1,
        "content": "D, you need a container to be built so you can run the tests against it folks. D is the right answer."
      },
      {
        "date": "2023-12-05T18:40:00.000Z",
        "voteCount": 3,
        "content": "The optimal approach for establishing a CI/CD pipeline for a containerized application in Google Cloud is (Option D).\n\nIn this method, unit tests are seamlessly integrated into the initial stages of the pipeline, automatically triggered when code is pushed. Successful unit tests then prompt Cloud Build to construct and push the application container to a central registry. The pipeline subsequently orchestrates the deployment of the container to a testing environment, where comprehensive integration and acceptance tests are executed. Only when all tests pass successfully does the pipeline advance to deploying the application to the production environment, accompanied by the execution of smoke tests.\n\nThis systematic and thorough process ensures that any code changes undergo rigorous testing at various stages, ensuring high-quality standards and instilling confidence in the deployment process to production."
      },
      {
        "date": "2023-10-23T12:04:00.000Z",
        "voteCount": 1,
        "content": "You can use Cloud Build to build a container. A is correct."
      },
      {
        "date": "2023-10-09T23:20:00.000Z",
        "voteCount": 3,
        "content": "I would chose D as question states that we want to run all tests in the pipeline, which is not the case with a hook for unit tests. Option D also adds smoke tests in production env."
      },
      {
        "date": "2024-08-01T17:58:00.000Z",
        "voteCount": 1,
        "content": "D is fully automated. \"The pipeline deploys...\""
      },
      {
        "date": "2023-10-10T20:39:00.000Z",
        "voteCount": 2,
        "content": "Smoke testing is the practice of testing fundamental and core elements of a software program in the early phases of development to identify minor issues that might delay the product's release. At its core, smoke testing is used to establish whether the released software build is reliable or not."
      },
      {
        "date": "2023-10-01T03:32:00.000Z",
        "voteCount": 2,
        "content": "Answer Should  be B"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 100,
    "url": "https://www.examtopics.com/discussions/google/view/123218-exam-professional-cloud-devops-engineer-topic-1-question-100/",
    "body": "The new version of your containerized application has been tested and is ready to be deployed to production on Google Kubernetes Engine (GKE). You could not fully load-test the new version in your pre-production environment, and you need to ensure that the application does not have performance problems after deployment. Your deployment must be automated. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDeploy the application through a continuous delivery pipeline by using canary deployments. Use Cloud Monitoring to look for performance issues, and ramp up traffic as supported by the metrics.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDeploy the application through a continuous delivery pipeline by using blue/green deployments. Migrate traffic to the new version of the application and use Cloud Monitoring to look for performance issues.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDeploy the application by using kubectl and use Config Connector to slowly ramp up traffic between versions. Use Cloud Monitoring to look for performance issues.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDeploy the application by using kubectl and set the spec.updateStrategy.type field to RollingUpdate. Use Cloud Monitoring to look for performance issues, and run the kubectl rollback command if there are any issues."
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 16,
        "isMostVoted": true
      },
      {
        "answer": "B",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2023-10-10T21:05:00.000Z",
        "voteCount": 15,
        "content": "I vote for A as in Blue/Green deployment you can rollback quickly after facing the performance issue, but in Canary you can detect performance issue on partial deployment and rollback before the issue get affected."
      },
      {
        "date": "2023-10-25T11:08:00.000Z",
        "voteCount": 1,
        "content": "You meant option B?"
      },
      {
        "date": "2023-11-02T03:25:00.000Z",
        "voteCount": 1,
        "content": "no PrayasM meant that canary fits what got asked more"
      },
      {
        "date": "2024-03-18T08:08:00.000Z",
        "voteCount": 1,
        "content": "After consideration, Canary approach is better in this specific scenario as it allows for monitoring the performance of the new version in production while minimizing the risk of widespread issues."
      },
      {
        "date": "2024-02-12T12:20:00.000Z",
        "voteCount": 1,
        "content": "B. Blue/green deployments involve deploying the new version alongside the existing one, routing only a portion of the traffic to the new version initially. Once you verify that the new version is performing well and there are no issues, you can fully migrate traffic to the new version. This allows for a safe rollback if any issues arise."
      },
      {
        "date": "2024-03-18T08:07:00.000Z",
        "voteCount": 1,
        "content": "After consideration, Canary approach is better in this specific scenario as it allows for monitoring the performance of the new version in production while minimizing the risk of widespread issues."
      },
      {
        "date": "2023-12-05T18:43:00.000Z",
        "voteCount": 2,
        "content": "The recommended approach to automate the deployment of the new version of a containerized application to production on Google Kubernetes Engine (GKE) while addressing potential performance issues is (Option A).\n\nUtilizing canary deployments within a continuous delivery pipeline allows for a controlled and gradual rollout of the new version. By monitoring performance metrics with Cloud Monitoring, the deployment process can be informed by real-time insights. The traffic can be incrementally increased as supported by the monitored metrics, minimizing the risk of performance problems.\n\nThis approach provides a safety net, allowing for quick identification and mitigation of issues before a full deployment, ensuring a smooth transition to the new version with minimal impact on production."
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 101,
    "url": "https://www.examtopics.com/discussions/google/view/122025-exam-professional-cloud-devops-engineer-topic-1-question-101/",
    "body": "You are managing an application that runs in Compute Engine. The application uses a custom HTTP server to expose an API that is accessed by other applications through an internal TCP/UDP load balancer. A firewall rule allows access to the API port from 0.0.0.0/0. You need to configure Cloud Logging to log each IP address that accesses the API by using the fewest number of steps. What should you do first?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEnable Packet Mirroring on the VPC.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tInstall the Ops Agent on the Compute Engine instances.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEnable logging on the firewall rule.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEnable VPC Flow Logs on the subnet.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 9,
        "isMostVoted": true
      },
      {
        "answer": "C",
        "count": 5,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2023-10-10T21:11:00.000Z",
        "voteCount": 6,
        "content": "Option D uses  fewest number of steps."
      },
      {
        "date": "2024-10-17T23:32:00.000Z",
        "voteCount": 1,
        "content": "The correct option is C: Enable logging on the firewall rule.\n\nExplanation:\nFirewall rule logging allows you to capture the traffic that matches a specific firewall rule, including details such as the source IP address. Since your firewall rule allows access to the API port from 0.0.0.0/0, enabling logging on this rule will log the IP addresses of incoming connections to the API.\nThis is the most straightforward way to log the IP addresses accessing the API using the fewest steps, as it leverages existing firewall configurations and integrates with Cloud Logging.\nD: VPC Flow Logs provide network-level logging for traffic flowing within the VPC but would log all traffic in the subnet. While it could work, it's a more complex solution compared to enabling firewall rule logging directly.\nTherefore, C provides the quickest and simplest method to log IP addresses accessing the API."
      },
      {
        "date": "2024-07-15T03:17:00.000Z",
        "voteCount": 1,
        "content": "C) Enabling Logging of firewall rules"
      },
      {
        "date": "2024-06-06T06:05:00.000Z",
        "voteCount": 2,
        "content": "C is correct. VPC Flows logs can show source IP addresses, but they sample packets, do not provide the level of detail about individual API calls compared to firewall rule logging."
      },
      {
        "date": "2024-03-28T01:24:00.000Z",
        "voteCount": 1,
        "content": "Be careful. The question states \"each IP address that accesses the API\". VPC Flow Logs is sampling records:\n\n\"VPC Flow Logs records a sample of network flows sent from and received by VM instances, including instances used as GKE nodes. These logs can be used for network monitoring, forensics, real-time security analysis, and expense optimization.\"\nSource: https://cloud.google.com/vpc/docs/using-flow-logs\n\nC. Is the correct answer."
      },
      {
        "date": "2023-12-05T18:51:00.000Z",
        "voteCount": 3,
        "content": "Choose option D.\n\nTo configure Cloud Logging to log each IP address accessing the API with the fewest steps in a Compute Engine environment using an internal TCP/UDP load balancer, the first step would be to enable VPC Flow Logs on the subnet. That will allows you to capture network flow information, including source and destination IP addresses, as traffic passes through the load balancer.\n\nVPC Flow Logs provide detailed visibility into network activity without requiring modifications to individual instances or the installation of additional agents. Enabling VPC Flow Logs is a straightforward and efficient way to capture the necessary information for logging IP addresses accessing the API in a Compute Engine environment."
      },
      {
        "date": "2023-10-01T05:48:00.000Z",
        "voteCount": 2,
        "content": "D. Enable VPC Flow Logs on the subnet.\n\nThis will capture the network traffic details you need for logging in Cloud Logging without requiring additional configurations on the instances or firewall rules."
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 102,
    "url": "https://www.examtopics.com/discussions/google/view/122026-exam-professional-cloud-devops-engineer-topic-1-question-102/",
    "body": "Your company runs an ecommerce website built with JVM-based applications and microservice architecture in Google Kubernetes Engine (GKE). The application load increases during the day and decreases during the night. Your operations team has configured the application to run enough Pods to handle the evening peak load. You want to automate scaling by only running enough Pods and nodes for the load. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure the Vertical Pod Autoscaler, but keep the node pool size static.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure the Vertical Pod Autoscaler, and enable the cluster autoscaler.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure the Horizontal Pod Autoscaler, but keep the node pool size static.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure the Horizontal Pod Autoscaler, and enable the cluster autoscaler.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 9,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-05-11T23:07:00.000Z",
        "voteCount": 1,
        "content": "Voting for D"
      },
      {
        "date": "2023-12-20T09:58:00.000Z",
        "voteCount": 2,
        "content": "please read this how to use vertical pod autoscaler https://cloud.google.com/kubernetes-engine/docs/concepts/verticalpodautoscaler , so it suggest use Horizontal Pod Autoscaler (HPA) with the VPA to get the best of autoscaling."
      },
      {
        "date": "2023-12-05T19:02:00.000Z",
        "voteCount": 2,
        "content": "To automate scaling for the JVM-based applications and microservices architecture in Google Kubernetes Engine (GKE), especially to handle varying loads throughout the day, the recommended approach is (Option D).\n\nThis involves configuring the Horizontal Pod Autoscaler (HPA) to dynamically adjust the number of Pods based on application metrics. Additionally, enabling the cluster autoscaler allows for automatic scaling of the node pool, ensuring an adequate number of nodes to accommodate the varying workload. The HPA monitors resource utilization and adjusts the number of Pods, while the cluster autoscaler ensures that the underlying infrastructure scales up or down to meet the demand.\n\nThis combined approach optimizes resource allocation, providing an efficient and automated solution for managing workload fluctuations in a cost-effective manner."
      },
      {
        "date": "2023-11-14T09:48:00.000Z",
        "voteCount": 2,
        "content": "D is correct\nhttps://cloud.google.com/kubernetes-engine/docs/concepts/cluster-autoscaler?hl=es-419\nhttps://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/#support-for-metrics-apis"
      },
      {
        "date": "2023-10-11T19:21:00.000Z",
        "voteCount": 3,
        "content": "You want to automate scaling by only running enough Pods and nodes for the load.  Answer D answers this requirement."
      },
      {
        "date": "2023-10-10T21:18:00.000Z",
        "voteCount": 4,
        "content": "There is no Vertical Pod Autoscaler, and cluster autoscaler must be enabled. Therefor D appears the best answer."
      },
      {
        "date": "2023-10-01T05:54:00.000Z",
        "voteCount": 3,
        "content": "Answer Should be D"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 103,
    "url": "https://www.examtopics.com/discussions/google/view/122029-exam-professional-cloud-devops-engineer-topic-1-question-103/",
    "body": "Your organization wants to increase the availability target of an application from 99.9% to 99.99% for an investment of $2,000. The application's current revenue is $1,000,000. You need to determine whether the increase in availability is worth the investment for a single year of usage. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCalculate the value of improved availability to be $900, and determine that the increase in availability is not worth the investment.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCalculate the value of improved availability to be $1,000, and determine that the increase in availability is not worth the investment.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCalculate the value of improved availability to be $1,000, and determine that the increase in availability is worth the investment.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCalculate the value of improved availability to be $9,000, and determine that the increase in availability is worth the investment."
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 18,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-10-10T21:26:00.000Z",
        "voteCount": 10,
        "content": "1000000\u00f7100\u00d70.09=900, therefor the answer appears to be A"
      },
      {
        "date": "2023-12-20T10:02:00.000Z",
        "voteCount": 2,
        "content": "1000000\u00f7100\u00d70.09=900, therefor the answer appears to be A"
      },
      {
        "date": "2023-12-05T19:08:00.000Z",
        "voteCount": 3,
        "content": "To assess the cost-effectiveness of investing in an availability increase from 99.9% to 99.99% for a single year, it's essential to calculate the additional revenue generated by the improved availability.\n\nUsing the formula 1000000\u00f7100\u00d70.09, which represents 0.09% of the current revenue of $1,000,000, the calculated value is $900. This indicates that the potential increase in revenue due to the higher availability is $900. Given that the investment cost is $2,000, the gain falls short of covering the investment, making the decision not to pursue the availability increase financially impractical.\n\nTherefore, option A is the correct choice, aligning with a thorough cost-benefit analysis and demonstrating that the increase in availability is not worth the $2,000 investment for a single year of usage."
      },
      {
        "date": "2023-11-02T08:18:00.000Z",
        "voteCount": 3,
        "content": "Sorry the answer should be A.\n99,99%-99,9%=0.09%\n0.09% of 1.000.000 is 900 dollar"
      },
      {
        "date": "2023-11-02T08:16:00.000Z",
        "voteCount": 1,
        "content": "99,99%-99,9%=0.09% \n0.09% of 1.000.000 is 900 dollar, answer is B"
      },
      {
        "date": "2023-10-01T06:30:00.000Z",
        "voteCount": 2,
        "content": "Answer Should be A"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 104,
    "url": "https://www.examtopics.com/discussions/google/view/122031-exam-professional-cloud-devops-engineer-topic-1-question-104/",
    "body": "A third-party application needs to have a service account key to work properly. When you try to export the key from your cloud project, you receive an error: \u201cThe organization policy constraint iam.disableServiceAccounKeyCreation is enforced.\u201d You need to make the third-party application work while following Google-recommended security practices.<br><br>What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEnable the default service account key, and download the key.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRemove the iam.disableServiceAccountKeyCreation policy at the organization level, and create a key.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDisable the service account key creation policy at the project's folder, and download the default key.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAdd a rule to set the iam.disableServiceAccountKeyCreation policy to off in your project, and create a key.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 10,
        "isMostVoted": true
      },
      {
        "answer": "B",
        "count": 3,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2023-11-20T11:59:00.000Z",
        "voteCount": 5,
        "content": "(D) is better choice, exemption of policy at Org level is always riskier than to exempt it at project level (B). But, for answer (D) - I'm assuming here rule means assigning tag."
      },
      {
        "date": "2023-12-05T19:12:00.000Z",
        "voteCount": 3,
        "content": "To address the error caused by the organization policy constraint \"iam.disableServiceAccountKeyCreation,\" and to enable the third-party application to work while adhering to Google-recommended security practices, the recommended action is (Option D).\n\nBy adding a rule to set the \"iam.disableServiceAccountKeyCreation\" policy to \"off\" specifically in your project, you can override the organization-level constraint temporarily for your project.\n\nThis allows you to create the necessary service account key for the third-party application without compromising the organization-wide security policy.\n\nThis targeted adjustment ensures that the key creation is enabled only for the project in question, maintaining security standards across the broader organization."
      },
      {
        "date": "2023-11-20T06:21:00.000Z",
        "voteCount": 2,
        "content": "The correct answer is D. Using service account keys is against best practices so if needed you only enable it only on one project."
      },
      {
        "date": "2023-11-03T03:10:00.000Z",
        "voteCount": 4,
        "content": "I think D is better, you can disable the Org Policy only on the project in which the key is."
      },
      {
        "date": "2023-11-01T22:44:00.000Z",
        "voteCount": 3,
        "content": "Correct answer is B\nIf the iam.disableServiceAccountCreation constraint is applied, attempting to enable these services will fail because their default service accounts cannot be created.\n\nTo resolve this issue:\n\nTemporarily remove the iam.disableServiceAccountCreation constraint.\nEnable the desired services.\nCreate any other desired service accounts.\nFinally, re-apply the constraint.\nhttps://cloud.google.com/resource-manager/docs/organization-policy/restricting-service-accounts#disable_service_account_key_creation"
      },
      {
        "date": "2023-10-25T11:47:00.000Z",
        "voteCount": 3,
        "content": "Right answer"
      },
      {
        "date": "2023-10-01T06:36:00.000Z",
        "voteCount": 2,
        "content": "COrrect Answer is B"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 105,
    "url": "https://www.examtopics.com/discussions/google/view/122032-exam-professional-cloud-devops-engineer-topic-1-question-105/",
    "body": "Your team is writing a postmortem after an incident on your external facing application. Your team wants to improve the postmortem policy to include triggers that indicate whether an incident requires a postmortem. Based on Site Reliability Engineering (SRE) practices, what triggers should be defined in the postmortem policy? (Choose two.)",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAn external stakeholder asks for a postmortem",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tData is lost due to an incident.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAn internal stakeholder requests a postmortem.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tThe monitoring system detects that one of the instances for your application has failed.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tThe CD pipeline detects an issue and rolls back a problematic release.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "BE",
    "answerDescription": "",
    "votes": [
      {
        "answer": "BE",
        "count": 10,
        "isMostVoted": true
      },
      {
        "answer": "AB",
        "count": 4,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2024-08-11T12:00:00.000Z",
        "voteCount": 1,
        "content": "https://sre.google/sre-book/postmortem-culture/ suggests B and E as objective triggers. On a side note, it says any stakeholder can request but that would qualify A and C also but we objectively know B is an answer by the docs. \n\n\"In addition to these objective triggers, any stakeholder may request a postmortem for an event. Blameless postmortems are a tenet of SRE culture.\"\n\n\"On-call engineer intervention (release rollback, rerouting of traffic, etc.)\" E is also a toss up since it doesn't state any manual intervention was required and the rollback happened by itself. \n\nBE &amp; AB are solid choices. But I would lean more to BE since they are listed under objective requirements although no manual intervention was required for the rollback.."
      },
      {
        "date": "2024-03-20T13:40:00.000Z",
        "voteCount": 2,
        "content": "A over D because An external stakeholder requesting a postmortem indicates a significant impact from their perspective. This highlights the need for a thorough investigation to understand the customer experience, mitigate future issues, and potentially regain trust.\n\nNot D because Instance failures often happen, and automated systems should handle them gracefully. A postmortem is warranted only if customer impact occurs despite the redundancy and recovery mechanisms."
      },
      {
        "date": "2024-01-28T20:36:00.000Z",
        "voteCount": 3,
        "content": "should be  A and B,  SRE book says:\n\ncommon postmortem triggers include:\n\nUser-visible downtime or degradation beyond a certain threshold  (N/A)\n\"Data loss of any kind\"  &lt;----------------------------- (B)\nOn-call engineer intervention (release rollback, rerouting of traffic, etc.)  (N/A)\nA resolution time above some threshold   (N/A)\nA monitoring failure (which usually implies manual incident discovery)  (N/A)  not manual incident discovery here\n\nIt is important to define postmortem criteria before an incident occurs so that everyone knows when a postmortem is necessary. In addition to these objective triggers, \"any stakeholder may request a postmortem for an event.\"   &lt;-------------------------- (A)"
      },
      {
        "date": "2023-12-20T10:09:00.000Z",
        "voteCount": 2,
        "content": "that's right."
      },
      {
        "date": "2023-12-05T19:18:00.000Z",
        "voteCount": 3,
        "content": "Choose B &amp; E.\n\nIn accordance with Site Reliability Engineering (SRE) practices, the triggers defined in a postmortem policy should be focused on incidents that have significant impact and provide valuable learning opportunities.\n\nOption B, \"Data is lost due to an incident,\" is a critical trigger as data loss is a severe consequence that necessitates a thorough examination to prevent future occurrences. \n\nOption E, \"The CD pipeline detects an issue and rolls back a problematic release,\" is a crucial trigger indicating that the continuous delivery (CD) pipeline has identified an issue and initiated a rollback, pointing to potential challenges in the release process.\n\nThese triggers highlight impactful incidents with potential systemic issues, aligning with SRE principles to conduct postmortems for events that contribute to system resilience and reliability."
      },
      {
        "date": "2023-11-20T06:24:00.000Z",
        "voteCount": 2,
        "content": "E is expected behaviour if you set up the pipelines properly so I would go for A and B."
      },
      {
        "date": "2023-11-01T22:49:00.000Z",
        "voteCount": 1,
        "content": "Answer is BE Because those are major incident that disrupted our service."
      },
      {
        "date": "2023-10-25T11:48:00.000Z",
        "voteCount": 3,
        "content": "Right answer"
      },
      {
        "date": "2023-10-23T12:29:00.000Z",
        "voteCount": 1,
        "content": "BE for sure."
      },
      {
        "date": "2023-10-21T23:16:00.000Z",
        "voteCount": 2,
        "content": "Answer should be BE."
      },
      {
        "date": "2023-10-01T06:42:00.000Z",
        "voteCount": 2,
        "content": "Answer should be BE"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 106,
    "url": "https://www.examtopics.com/discussions/google/view/123225-exam-professional-cloud-devops-engineer-topic-1-question-106/",
    "body": "You are implementing a CI/CD pipeline for your application in your company\u2019s multi-cloud environment. Your application is deployed by using custom Compute Engine images and the equivalent in other cloud providers. You need to implement a solution that will enable you to build and deploy the images to your current environment and is adaptable to future changes. Which solution stack should you use?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCloud Build with Packer\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCloud Build with Google Cloud Deploy",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tGoogle Kubernetes Engine with Google Cloud Deploy",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCloud Build with kpt"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 11,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-12-20T10:10:00.000Z",
        "voteCount": 2,
        "content": "used packer in ongoing project."
      },
      {
        "date": "2023-12-06T00:34:00.000Z",
        "voteCount": 2,
        "content": "The optimal solution stack for building and deploying custom Compute Engine images in a multi-cloud environment that is adaptable to future changes is Cloud Build with Packer, as indicated by (Option A).\n\nCloud Build integrates seamlessly with Packer, a tool for creating machine images across various platforms. This combination provides a flexible and scalable solution for building custom images and deploying them across different cloud providers. Packer allows you to define infrastructure as code and supports multiple cloud providers, ensuring adaptability to future changes in the multi-cloud environment.\n\nThe unified approach of Cloud Build and Packer streamlines the CI/CD pipeline, enabling efficient image creation and deployment processes while maintaining cross-cloud compatibility."
      },
      {
        "date": "2023-11-01T22:54:00.000Z",
        "voteCount": 2,
        "content": "Answer is A\nSolution must be suitable for multi cloud environment."
      },
      {
        "date": "2023-10-18T04:01:00.000Z",
        "voteCount": 4,
        "content": "the question asks for \u201cbuild and deploy\u201d(cloud build), plus it needs to support multi-cloud(packer)."
      },
      {
        "date": "2023-11-02T03:53:00.000Z",
        "voteCount": 2,
        "content": "Packer is an open source tool for creating identical Virtual Machine (VM) images for multiple platforms from a single source configuration. This page explains how to use Packer and Cloud Build to create a VM image for use on Compute Engine.\nhttps://cloud.google.com/build/docs/building/build-vm-images-with-packer"
      },
      {
        "date": "2023-10-10T22:08:00.000Z",
        "voteCount": 3,
        "content": "Packer is an open source tool for creating identical Virtual Machine (VM) images for multiple platforms from a single source configuration.\n\nReference: https://cloud.google.com/build/docs/building/build-vm-images-with-packer\n\nC and D is related to Kubernetes and B does not suitable for platfrom other then GCP."
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 107,
    "url": "https://www.examtopics.com/discussions/google/view/124314-exam-professional-cloud-devops-engineer-topic-1-question-107/",
    "body": "Your application's performance in Google Cloud has degraded since the last release. You suspect that downstream dependencies might be causing some requests to take longer to complete. You need to investigate the issue with your application to determine the cause. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure Error Reporting in your application.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure Google Cloud Managed Service for Prometheus in your application.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure Cloud Profiler in your application.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure Cloud Trace in your application.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 11,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-02-14T06:39:00.000Z",
        "voteCount": 1,
        "content": "https://cloud.google.com/trace#:~:text=App%20Engine%20projects.-,Find%20performance%20bottlenecks,used%20at%20Google%20to%20keep%20our%20services%20running%20at%20extreme%20scale.,-Fast%2C%20automatic%20issue"
      },
      {
        "date": "2023-12-20T10:13:00.000Z",
        "voteCount": 2,
        "content": "tracing is the solution to diagnose latency"
      },
      {
        "date": "2023-12-06T00:39:00.000Z",
        "voteCount": 2,
        "content": "To investigate performance degradation in your application and pinpoint potential causes related to downstream dependencies, the recommended approach is to configure Cloud Trace, as denoted by (Option D).\n\nCloud Trace provides detailed insights into the end-to-end latency of requests, enabling you to trace the execution flow across various services and dependencies. By utilizing tracing, you can identify bottlenecks and delays, allowing for a comprehensive analysis of the application's performance.\n\nCloud Trace offers valuable data, including latency information and detailed timelines for each request, facilitating effective troubleshooting and performance optimization. This makes it a suitable choice when investigating issues related to request completion times and downstream dependencies in your Google Cloud environment."
      },
      {
        "date": "2023-11-01T22:59:00.000Z",
        "voteCount": 1,
        "content": "Answer is D."
      },
      {
        "date": "2023-10-25T22:44:00.000Z",
        "voteCount": 3,
        "content": "Trace is designed for performance analysis and monitoring of applications in GCP"
      },
      {
        "date": "2023-10-21T23:21:00.000Z",
        "voteCount": 3,
        "content": "I should be Cloud Trace."
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 108,
    "url": "https://www.examtopics.com/discussions/google/view/122037-exam-professional-cloud-devops-engineer-topic-1-question-108/",
    "body": "You are creating a CI/CD pipeline in Cloud Build to build an application container image. The application code is stored in GitHub. Your company requires that production image builds are only run against the main branch and that the change control team approves all pushes to the main branch. You want the image build to be as automated as possible. What should you do? (Choose two.)",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a trigger on the Cloud Build job. Set the repository event setting to \u2018Pull request\u2019.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAdd the OWNERS file to the Included files filter on the trigger.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a trigger on the Cloud Build job. Set the repository event setting to \u2018Push to a branch\u2019\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure a branch protection rule for the main branch on the repository.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEnable the Approval option on the trigger."
    ],
    "answer": "CD",
    "answerDescription": "",
    "votes": [
      {
        "answer": "CD",
        "count": 11,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-10-01T07:42:00.000Z",
        "voteCount": 6,
        "content": "CD is the correct answer ,This will ensure that the image build is only triggered when a push is made to the main branch, and that the push is approved by the change control team.\n\nExplanation:\n\nOption C: Setting the repository event setting to \u2018Push to a branch\u2019 will trigger the Cloud Build job whenever a push is made to any branch in the repository. This is necessary because you want the image build to be triggered when a push is made to the main branch.\nOption D: Configuring a branch protection rule for the main branch on the repository will require that all pushes to the main branch be approved by the change control team. This is necessary to ensure that only approved changes are made to the main branch, which will then trigger the image build."
      },
      {
        "date": "2023-10-25T22:52:00.000Z",
        "voteCount": 2,
        "content": "in the question it says \"Automated\" doesn't option E works as well ?"
      },
      {
        "date": "2023-12-14T08:59:00.000Z",
        "voteCount": 4,
        "content": "C) Triggers Only when pushing or merging into a branch in our case would be main branch\nD) Configuring branch protection, gives you the control over the branch and who can push to it, so any changes would need to be done over a pull request, and will need to be approved before merging."
      },
      {
        "date": "2023-12-06T00:47:00.000Z",
        "voteCount": 3,
        "content": "To ensure that production image builds are run only against the main branch and require approval from the change control team, the recommended actions are to configure a trigger on the Cloud Build job with the repository event setting set to 'Push to a branch' (Option C) and to configure a branch protection rule for the main branch on the repository (Option D). \n\nConfiguring the trigger for 'Push to a branch' ensures that Cloud Build is triggered specifically when changes are pushed to the main branch. Additionally, setting up a branch protection rule for the main branch adds an extra layer of control by enforcing policies such as requiring code reviews and approval from designated individuals or teams before changes are merged into the main branch.\n\nTogether, these measures automate the image build process while adhering to the specified requirements and maintaining a robust change control workflow."
      },
      {
        "date": "2023-11-02T04:15:00.000Z",
        "voteCount": 2,
        "content": "A push event to branches(including main) can then trigger an automated image build.\nEnabling branch protection will enforce a pull request, and it then involve ppl to review."
      },
      {
        "date": "2023-10-25T22:54:00.000Z",
        "voteCount": 1,
        "content": "C is definetly the anaswer, I have slight confusion on D and E , Most probably will go with E since the questions says automated."
      },
      {
        "date": "2023-10-21T23:27:00.000Z",
        "voteCount": 2,
        "content": "Answer should be CD."
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 109,
    "url": "https://www.examtopics.com/discussions/google/view/123227-exam-professional-cloud-devops-engineer-topic-1-question-109/",
    "body": "You built a serverless application by using Cloud Run and deployed the application to your production environment. You want to identify the resource utilization of the application for cost optimization. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse Cloud Trace with distributed tracing to monitor the resource utilization of the application.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse Cloud Profiler with Ops Agent to monitor the CPU and memory utilization of the application.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse Cloud Monitoring to monitor the container CPU and memory utilization of the application.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse Cloud Ops to create logs-based metrics to monitor the resource utilization of the application."
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 20,
        "isMostVoted": true
      },
      {
        "answer": "B",
        "count": 9,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2023-11-05T14:36:00.000Z",
        "voteCount": 6,
        "content": "Cloud Run integrates automatically with Cloud Monitoring and requires no setup or configuration.\nhttps://cloud.google.com/run/docs/monitoring?hl=ja"
      },
      {
        "date": "2023-10-25T23:06:00.000Z",
        "voteCount": 5,
        "content": "Suits best for the question."
      },
      {
        "date": "2024-08-27T04:48:00.000Z",
        "voteCount": 1,
        "content": "Option C is the most appropriate choice as it directly addresses the need to monitor container CPU and memory utilization in Cloud Run. This will help you gather the necessary data for cost optimization effectively.\n\n\nCloud Profiler more suited for debugging performance bottlenecks and less for high-level resource utilization monitoring across Cloud Run instances."
      },
      {
        "date": "2024-06-06T07:07:00.000Z",
        "voteCount": 1,
        "content": "No Op Agents for Cloud run"
      },
      {
        "date": "2023-12-06T00:51:00.000Z",
        "voteCount": 3,
        "content": "For identifying the resource utilization of a serverless application deployed on Cloud Run for cost optimization, the recommended approach is to use Cloud Monitoring, as indicated by (Option C).\n\nCloud Monitoring provides comprehensive monitoring capabilities, allowing you to track container CPU and memory utilization effectively. Specifically tailored for containerized environments like Cloud Run, Cloud Monitoring provides insights into key metrics, enabling you to analyze resource consumption, identify potential bottlenecks, and optimize costs based on observed utilization patterns.\n\nBy monitoring container CPU and memory metrics, you gain valuable data for making informed decisions about resource allocation, ensuring efficient usage, and ultimately optimizing the cost of running the serverless application in your production environment."
      },
      {
        "date": "2023-11-30T03:36:00.000Z",
        "voteCount": 4,
        "content": "As per documentation cloud profiler not supported for cloud run environment \nhttps://cloud.google.com/profiler/docs/about-profiler\nwill go with C"
      },
      {
        "date": "2023-11-20T07:08:00.000Z",
        "voteCount": 1,
        "content": "I would say B. If you deploy with cloud run you would deploy a container and the only way of improving the cost of the solution would be by looking at the app with cloud profiler. If you just look at cloud monitoring, how would you know what part of your app is the issue?"
      },
      {
        "date": "2023-11-02T08:32:00.000Z",
        "voteCount": 5,
        "content": "Cloud Profiler provides continuous profiling of resource consumption in your production applications, helping you identify and eliminate potential performance issues.\nhttps://cloud.google.com/products/operations#all-features \nsection:Performance and cost management"
      },
      {
        "date": "2023-10-21T23:28:00.000Z",
        "voteCount": 4,
        "content": "Answer should be C."
      },
      {
        "date": "2023-10-10T22:29:00.000Z",
        "voteCount": 3,
        "content": "Cloud Profiler is a statistical, low-overhead profiler that continuously gathers CPU usage and memory-allocation information from your production applications. It attributes that information to the application's source code, helping you identify the parts of the application consuming the most resources, and otherwise illuminating the performance characteristics of the code."
      },
      {
        "date": "2023-10-25T23:06:00.000Z",
        "voteCount": 2,
        "content": "Cloud profiler is designed for profiling and to optimize code performance, it is used to identify code related issues.\ni will go option C"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 110,
    "url": "https://www.examtopics.com/discussions/google/view/122999-exam-professional-cloud-devops-engineer-topic-1-question-110/",
    "body": "Your company is using HTTPS requests to trigger a public Cloud Run-hosted service accessible at the https://booking-engine-abcdef.a.run.app URL. You need to give developers the ability to test the latest revisions of the service before the service is exposed to customers. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRun the gcloud run deploy booking-engine --no-traffic --tag dev command. Use the https://dev--booking-engine-abcdef.a.run.app URL for testing.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRun the gcloud run services update-traffic booking-engine --to-revisions LATEST=1 command. Use the https://booking-engine-abcdef.a.run.app URL for testing.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tPass the curl \u2013H \u201cAuthorization:Bearer $(gcloud auth print-identity-token)\u201d auth token. Use the https://booking-engine-abcdef.a.run.app URL to test privately.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tGrant the roles/run.invoker role to the developers testing the booking-engine service. Use the https://booking-engine-abcdef.private.run.app URL for testing."
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 14,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-10-09T08:12:00.000Z",
        "voteCount": 7,
        "content": "A, as it is possible to accept a tagged revision as explained here: https://cloud.google.com/run/docs/rollouts-rollbacks-traffic-migration#deploy-with-tags"
      },
      {
        "date": "2023-12-06T01:07:00.000Z",
        "voteCount": 3,
        "content": "To enable developers to test the latest revisions of a Cloud Run-hosted service before exposing it to customers, the recommended approach is to use the --no-traffic flag during deployment, as outlined in (Option A).\n\nBy running the command gcloud run deploy booking-engine --no-traffic --tag dev, you deploy the service with no traffic routed to it initially. Subsequently, developers can test the latest revisions using the URL https://dev--booking-engine-abcdef.a.run.app. This allows for a controlled and private testing environment where developers can validate the service's functionality and behavior before making it publicly accessible. Utilizing a dedicated URL with the --tag option ensures that developers can interact with the specific version intended for testing, facilitating a smooth and secure testing process."
      },
      {
        "date": "2023-11-01T23:48:00.000Z",
        "voteCount": 1,
        "content": "Answer is A.\nWith option B: 100% of traffic will be route to the latest revision."
      },
      {
        "date": "2023-10-10T23:00:00.000Z",
        "voteCount": 4,
        "content": "It create a new deployment(revision) with no traffic to https://booking-engine-abcdef.a.run.app but the revision can be tested by developer at https://dev--booking-engine-abcdef.a.run.app as dev tag is associated with the deploymnet.\n\nReference: https://cloud.google.com/sdk/gcloud/reference/run/deploy"
      },
      {
        "date": "2023-10-26T00:13:00.000Z",
        "voteCount": 1,
        "content": "Agreed"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 111,
    "url": "https://www.examtopics.com/discussions/google/view/123269-exam-professional-cloud-devops-engineer-topic-1-question-111/",
    "body": "You are configuring connectivity across Google Kubernetes Engine (GKE) clusters in different VPCs. You notice that the nodes in Cluster A are unable to access the nodes in Cluster B. You suspect that the workload access issue is due to the network configuration. You need to troubleshoot the issue but do not have execute access to workloads and nodes. You want to identify the layer at which the network connectivity is broken. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tInstall a toolbox container on the node in Cluster Confirm that the routes to Cluster B are configured appropriately.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse Network Connectivity Center to perform a Connectivity Test from Cluster A to Cluster B.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse a debug container to run the traceroute command from Cluster A to Cluster B and from Cluster B to Cluster A. Identify the common failure point.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEnable VPC Flow Logs in both VPCs, and monitor packet drops."
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 19,
        "isMostVoted": true
      },
      {
        "answer": "A",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2023-10-26T00:18:00.000Z",
        "voteCount": 9,
        "content": "I will got with B just to identify what happend in the network level"
      },
      {
        "date": "2023-10-29T16:13:00.000Z",
        "voteCount": 6,
        "content": "I suspect that there is a mistake in the issue and that the Network Intelligence Center is correct, not the Network Connectivity Center.\nhttps://cloud.google.com/network-intelligence-center/docs/connectivity-tests/concepts/overview"
      },
      {
        "date": "2023-12-06T01:13:00.000Z",
        "voteCount": 2,
        "content": "To identify and troubleshoot the network connectivity issue between Google Kubernetes Engine (GKE) clusters in different VPCs where nodes in Cluster A cannot access nodes in Cluster B, the recommended action is to use Network Connectivity Center, as stated in (Option B).\n\nBy performing a Connectivity Test from Cluster A to Cluster B using Network Connectivity Center, you can assess the network path and identify potential issues affecting the connectivity. This diagnostic tool helps pinpoint where the connectivity breaks down, enabling you to analyze the network configuration and resolve any misconfigurations or obstacles that might be hindering communication between the clusters. This approach provides a focused and efficient way to troubleshoot the specific network layer where the connectivity issue occurs without requiring execute access to workloads and nodes in the clusters."
      },
      {
        "date": "2023-11-21T02:45:00.000Z",
        "voteCount": 2,
        "content": "Network Connectivity Center is not the greatest tool but in this case we don't really have any options with the restrictions in the question so B"
      },
      {
        "date": "2023-12-23T10:30:00.000Z",
        "voteCount": 1,
        "content": "Is it not easier the ans D, both VPC seems to be in the same GCP project ? It's only to allow the ingress rule in both VPC firewall rules\nIf I read https://cloud.google.com/network-connectivity-center#simplified-data-transfer-over-google%E2%80%99s-network they talk to enable the communication between network outside the GCP scope\nBut I realized I am the only who thinks in ans D"
      },
      {
        "date": "2023-10-12T11:07:00.000Z",
        "voteCount": 4,
        "content": "B as the Q says  but do not have execute access to workloads and nodes\u2026 so can\u2019t run toolbox"
      },
      {
        "date": "2023-10-15T02:41:00.000Z",
        "voteCount": 1,
        "content": "May not have execute access to workload and node, but may have access to project and create a new toolbox pod for testing the route to Cluster B"
      },
      {
        "date": "2023-10-17T22:56:00.000Z",
        "voteCount": 2,
        "content": "When you don't have execute access in this case even after creating a new pod also you will not be able to exec inside the pod as we don't have access."
      },
      {
        "date": "2023-10-11T03:44:00.000Z",
        "voteCount": 1,
        "content": "Vote for A \nReference: https://cloud.google.com/container-optimized-os/docs/how-to/toolbox"
      },
      {
        "date": "2023-10-26T00:19:00.000Z",
        "voteCount": 1,
        "content": "It says you dont have access to execute in workloads and node level, how can you install toolbox in the node ?\nI will go with B"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 112,
    "url": "https://www.examtopics.com/discussions/google/view/123442-exam-professional-cloud-devops-engineer-topic-1-question-112/",
    "body": "You manage an application that runs in Google Kubernetes Engine (GKE) and uses the blue/green deployment methodology. Extracts of the Kubernetes manifests are shown below:<br><br><img src=\"https://img.examtopics.com/professional-cloud-devops-engineer/image2.png\"><br><br>The Deployment app-green was updated to use the new version of the application. During post-deployment monitoring, you notice that the majority of user requests are failing. You did not observe this behavior in the testing environment. You need to mitigate the incident impact on users and enable the developers to troubleshoot the issue. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUpdate the Deployment app-blue to use the new version of the application.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUpdate the Deployment app-green to use the previous version of the application.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tChange the selector on the Service app-svc to app: my-app.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tChange the selector on the Service app-svc to app: my-app, version: blue.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 14,
        "isMostVoted": true
      },
      {
        "answer": "B",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2023-10-12T11:09:00.000Z",
        "voteCount": 8,
        "content": "Should be D"
      },
      {
        "date": "2023-12-06T01:23:00.000Z",
        "voteCount": 4,
        "content": "To mitigate the impact of the incident on users and facilitate troubleshooting, the recommended action is to change the selector on the Service app-svc to app: my-app, version: blue, as stated in (Option D).\n\nThis adjustment allows the Service to route traffic specifically to the previous version of the application (app-blue). By changing the selector to include the version label, you effectively roll back the traffic to the working version, providing a quick and effective solution to address the user request failures observed after the update to app-green.\n\nThis enables developers to investigate and troubleshoot the issue in a controlled manner without affecting user experience, and it serves as an interim solution while further investigation and remediation are carried out."
      },
      {
        "date": "2023-11-15T05:50:00.000Z",
        "voteCount": 4,
        "content": "It's a simplified question from CKAD exam. Answer D is the correct one since you need to point the service at the blue deployment and leave the green deployment for future analysis for developers."
      },
      {
        "date": "2023-11-05T13:32:00.000Z",
        "voteCount": 3,
        "content": "Option D\nhttps://blog.devgenius.io/blue-green-deployment-with-kubernetes-b7595b17fe17"
      },
      {
        "date": "2023-10-28T11:16:00.000Z",
        "voteCount": 3,
        "content": "I would go with D"
      },
      {
        "date": "2023-10-26T02:06:00.000Z",
        "voteCount": 1,
        "content": "I would go with B , If users are facing issues , it would be right to back to the previous version which is working fine."
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 113,
    "url": "https://www.examtopics.com/discussions/google/view/122338-exam-professional-cloud-devops-engineer-topic-1-question-113/",
    "body": "You are running a web application deployed to a Compute Engine managed instance group. Ops Agent is installed on all instances. You recently noticed suspicious activity from a specific IP address. You need to configure Cloud Monitoring to view the number of requests from that specific IP address with minimal operational overhead. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure the Ops Agent with a logging receiver. Create a logs-based metric.<br>B Create a script to scrape the web server log. Export the IP address request metrics to the Cloud Monitoring API.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUpdate the application to export the IP address request metrics to the Cloud Monitoring API.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure the Ops Agent with a metrics receiver."
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 20,
        "isMostVoted": true
      },
      {
        "answer": "D",
        "count": 2,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2023-12-06T01:28:00.000Z",
        "voteCount": 8,
        "content": "To efficiently monitor the number of requests from a specific IP address in a web application deployed to a Compute Engine managed instance group with Ops Agent installed, the recommended approach is to configure the Ops Agent with a logging receiver and create a logs-based metric, as outlined in (Option A).\n\nBy configuring the Ops Agent with a logging receiver, it can collect and forward relevant log data to Cloud Monitoring. Subsequently, creating a logs-based metric allows you to define a metric based on the extracted information from the logs, specifically focusing on the number of requests from the suspicious IP address. This setup minimizes operational overhead by leveraging existing infrastructure and provides a streamlined way to monitor and analyze the targeted metric related to the suspicious activity, aiding in swift detection and response to potential security issues."
      },
      {
        "date": "2023-12-20T10:29:00.000Z",
        "voteCount": 1,
        "content": "perfect explanation"
      },
      {
        "date": "2024-06-02T21:31:00.000Z",
        "voteCount": 1,
        "content": "Seems like it's written by Gemini honestly"
      },
      {
        "date": "2024-04-04T03:39:00.000Z",
        "voteCount": 1,
        "content": "a log based metric is nescessary"
      },
      {
        "date": "2023-12-20T10:30:00.000Z",
        "voteCount": 3,
        "content": "https://cloud.google.com/monitoring/agent/ops-agent/configuration#logging-receivers fluent_forward section"
      },
      {
        "date": "2023-12-18T13:06:00.000Z",
        "voteCount": 2,
        "content": "Exactly what user xhilmi said."
      },
      {
        "date": "2023-11-15T07:31:00.000Z",
        "voteCount": 3,
        "content": "As the question asks \"to view the number of requests,\" I would go with A since there is a crucial thing: \"Create a logs-based metric\"."
      },
      {
        "date": "2023-11-14T08:36:00.000Z",
        "voteCount": 1,
        "content": "https://cloud.google.com/monitoring/agent/ops-agent/configuration#logging-receivers\nfluent_forward section"
      },
      {
        "date": "2023-11-05T14:57:00.000Z",
        "voteCount": 2,
        "content": "\u30e1\u30c8\u30ea\u30af\u30b9\u30ec\u30b7\u30fc\u30d0\u30fc\u3067\u306f\u3001hostmetrics\u3057\u304b\u9078\u629e\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u306a\u3044\u3002\u3053\u308c\u306b\u306fIP\u30a2\u30c9\u30ec\u30b9\u306f\u3075\u304f\u307e\u308c\u3066\u3044\u306a\u3044\u3002\u3088\u3063\u3066D\u306f\u5019\u88dc\u304b\u3089\u5916\u308c\u308b\u3002\u79c1\u306fA\u3092\u9078\u629e\u3059\u308b\u3002\nhttps://cloud.google.com/monitoring/agent/ops-agent/configuration"
      },
      {
        "date": "2023-11-05T14:57:00.000Z",
        "voteCount": 4,
        "content": "In the metrics receiver, only hostmetrics can be selected. This does not include IP addresses. Therefore, D is not a candidate. I choose A.\nhttps://cloud.google.com/monitoring/agent/ops-agent/configuration"
      },
      {
        "date": "2023-11-11T11:50:00.000Z",
        "voteCount": 1,
        "content": "Thnanks for sharing the link, The answer is A."
      },
      {
        "date": "2023-11-02T13:47:00.000Z",
        "voteCount": 1,
        "content": "D is answer."
      },
      {
        "date": "2023-10-26T03:05:00.000Z",
        "voteCount": 2,
        "content": "Option D looks good for me"
      },
      {
        "date": "2023-10-03T22:54:00.000Z",
        "voteCount": 2,
        "content": "Answer Should be D ,to view the number of requests from a specific IP address with minimal operational overhead, you can configure the Ops Agent with a metrics receiver and use logs-based metrics"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 114,
    "url": "https://www.examtopics.com/discussions/google/view/124315-exam-professional-cloud-devops-engineer-topic-1-question-114/",
    "body": "Your organization is using Helm to package containerized applications. Your applications reference both public and private charts. Your security team flagged that using a public Helm repository as a dependency is a risk. You want to manage all charts uniformly, with native access control and VPC Service Controls. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tStore public and private charts in OCI format by using Artifact Registry.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tStore public and private charts by using GitHub Enterprise with Google Workspace as the identity provider.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tStore public and private charts by using Git repository. Configure Cloud Build to synchronize contents of the repository into a Cloud Storage bucket. Connect Helm to the bucket by using https://[bucket].storage-googleapis.com/[helmchart] as the Helm repository.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure a Helm chart repository server to run in Google Kubernetes Engine (GKE) with Cloud Storage bucket as the storage backend."
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 9,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-10-21T23:53:00.000Z",
        "voteCount": 6,
        "content": "Answer should be A\nhttps://cloud.google.com/artifact-registry/docs/helm"
      },
      {
        "date": "2023-12-06T01:34:00.000Z",
        "voteCount": 3,
        "content": "To address security concerns and maintain consistent access controls for Helm charts, it's recommended to store both public and private charts in the Open Container Initiative (OCI) format using Google Cloud's Artifact Registry, as suggested in (Option A).\n\nArtifact Registry provides a centralized, secure repository for Helm charts with native access control features and integration capabilities with VPC Service Controls. Storing charts in OCI format ensures a standardized approach to packaging, and Artifact Registry offers a robust solution for organizing and securing container artifacts. This approach improves security by centralizing both public and private charts, aligning with best practices for Helm chart management in containerized applications."
      },
      {
        "date": "2023-11-02T13:50:00.000Z",
        "voteCount": 1,
        "content": "A is answer."
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 115,
    "url": "https://www.examtopics.com/discussions/google/view/122339-exam-professional-cloud-devops-engineer-topic-1-question-115/",
    "body": "You use Terraform to manage an application deployed to a Google Cloud environment. The application runs on instances deployed by a managed instance group. The Terraform code is deployed by using a CI/CD pipeline. When you change the machine type on the instance template used by the managed instance group, the pipeline fails at the terraform apply stage with the following error message:<br><br><img src=\"https://img.examtopics.com/professional-cloud-devops-engineer/image3.png\"><br><br>You need to update the instance template and minimize disruption to the application and the number of pipeline runs.<br><br>What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDelete the managed instance group, and recreate it after updating the instance template.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAdd a new instance template, update the managed instance group to use the new instance template, and delete the old instance template.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRemove the managed instance group from the Terraform state file, update the instance template, and reimport the managed instance group.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSet the create_before_destroy meta-argument to true in the lifecycle block on the instance template.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 8,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-02-15T02:17:00.000Z",
        "voteCount": 2,
        "content": "https://developer.hashicorp.com/terraform/language/meta-arguments/lifecycle#create_before_destroy\n\nhttps://cloud.google.com/build/docs/deploying-builds/deploy-compute-engine#:~:text=Note%20that%20this,version%20is%20destroyed"
      },
      {
        "date": "2023-12-06T01:40:00.000Z",
        "voteCount": 1,
        "content": "To update the instance template and minimize disruption to the application while resolving the error during the Terraform apply stage, the recommended approach is to use (Option D).\n\nBy setting the create_before_destroy meta-argument to true in the lifecycle block on the instance template, Terraform will create a new instance template before destroying the old one. \n\nThis ensures a smooth transition by allowing the managed instance group to gradually replace instances with the new template without causing downtime. This method optimizes the update process, reducing disruption to the application and minimizing the number of pipeline runs needed."
      },
      {
        "date": "2023-10-26T03:18:00.000Z",
        "voteCount": 3,
        "content": "D is the best option"
      },
      {
        "date": "2023-10-21T23:55:00.000Z",
        "voteCount": 2,
        "content": "Answer should be D"
      },
      {
        "date": "2023-10-12T11:12:00.000Z",
        "voteCount": 2,
        "content": "D. Check to docs"
      },
      {
        "date": "2023-10-03T23:16:00.000Z",
        "voteCount": 1,
        "content": "B is correct Answer"
      },
      {
        "date": "2023-10-09T08:30:00.000Z",
        "voteCount": 4,
        "content": "Answer B suggests a manual change, but we should use terraform in a CI/CD pipeline. Answer D is the good one, it does the same thing than B, but with terraform automatically, as the default behaviour of terraform is to destroy resources before recreating it when it cannot be updated we have to tune the lifecycle parameter."
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 116,
    "url": "https://www.examtopics.com/discussions/google/view/122735-exam-professional-cloud-devops-engineer-topic-1-question-116/",
    "body": "Your company operates in a highly regulated domain that requires you to store all organization logs for seven years. You want to minimize logging infrastructure complexity by using managed services. You need to avoid any future loss of log capture or stored logs due to misconfiguration or human error. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse Cloud Logging to configure an aggregated sink at the organization level to export all logs into a BigQuery dataset.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse Cloud Logging to configure an aggregated sink at the organization level to export all logs into Cloud Storage with a seven-year retention policy and Bucket Lock.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse Cloud Logging to configure an export sink at each project level to export all logs into a BigQuery dataset",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse Cloud Logging to configure an export sink at each project level to export all logs into Cloud Storage with a seven-year retention policy and Bucket Lock."
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 13,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-12-06T01:47:00.000Z",
        "voteCount": 5,
        "content": "To ensure long-term retention of logs and minimize complexity while complying with regulatory requirements, the recommended approach is (Option B).\n\nBy using Cloud Logging to configure an aggregated sink at the organization level to export all logs into Cloud Storage with a seven-year retention policy and Bucket Lock, you establish a centralized and secure storage solution.\n\nThis setup leverages Cloud Storage's features, such as retention policies and Bucket Lock, to prevent accidental or intentional deletion of logs, reducing the risk of data loss due to misconfiguration or human error. It provides a robust and managed solution for storing logs over the required seven-year period, ensuring compliance with regulatory standards."
      },
      {
        "date": "2023-12-20T22:39:00.000Z",
        "voteCount": 2,
        "content": "I am impressed with the work done by xhilmi."
      },
      {
        "date": "2024-02-15T02:22:00.000Z",
        "voteCount": 1,
        "content": "Whole company: so organization level aggregated export\nFor 7 years: minimize cost, so cloud storage\nBucket lock will prevent delete for the duration of retention policy"
      },
      {
        "date": "2023-12-20T22:39:00.000Z",
        "voteCount": 3,
        "content": "I am impressed with the work done by xhilmi."
      },
      {
        "date": "2023-11-02T13:56:00.000Z",
        "voteCount": 4,
        "content": "B should be Answer."
      },
      {
        "date": "2023-10-21T23:57:00.000Z",
        "voteCount": 4,
        "content": "Answer should be B"
      },
      {
        "date": "2023-10-06T21:15:00.000Z",
        "voteCount": 1,
        "content": "You need to store all organization logs for seven years for which B appears more appropiate"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 117,
    "url": "https://www.examtopics.com/discussions/google/view/122062-exam-professional-cloud-devops-engineer-topic-1-question-117/",
    "body": "You are building the CI/CD pipeline for an application deployed to Google Kubernetes Engine (GKE). The application is deployed by using a Kubernetes Deployment, Service, and Ingress. The application team asked you to deploy the application by using the blue/green deployment methodology. You need to implement the rollback actions. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRun the kubectl rollout undo command.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDelete the new container image, and delete the running Pods.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUpdate the Kubernetes Service to point to the previous Kubernetes Deployment.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tScale the new Kubernetes Deployment to zero."
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 13,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-10-09T08:36:00.000Z",
        "voteCount": 10,
        "content": "The point of using blue/green deployment is to have both blue &amp; green versions deployed, and we chose the active one at service level, so rollback should only consist of updating the service to serve the other version."
      },
      {
        "date": "2024-02-15T02:31:00.000Z",
        "voteCount": 1,
        "content": "As seen in question 112, we can have blue &amp; green deployments and just need to point the service to the correct deployment for rollback"
      },
      {
        "date": "2023-12-06T01:56:00.000Z",
        "voteCount": 2,
        "content": "To implement rollback actions in a blue/green deployment methodology for an application deployed on Google Kubernetes Engine (GKE), the recommended approach is (Option C).\n\nUpdating the Kubernetes Service to point to the previous Kubernetes Deployment effectively rolls back the service to the previous version. This action ensures that traffic is directed to the previous deployment, mitigating any issues introduced by the new version. It is a controlled and Kubernetes-native way to perform rollbacks, allowing for seamless transitions between different versions of the application without downtime. Using the kubectl rollout undo command (option A) is another rollback method, but updating the Service provides a cleaner and more declarative approach within the Kubernetes environment."
      },
      {
        "date": "2023-10-06T21:17:00.000Z",
        "voteCount": 1,
        "content": "A appears correct answer"
      },
      {
        "date": "2023-10-11T21:27:00.000Z",
        "voteCount": 2,
        "content": "C appears more correct as it is a blue/green deployment."
      },
      {
        "date": "2023-10-01T08:30:00.000Z",
        "voteCount": 1,
        "content": "Answer should be A"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 118,
    "url": "https://www.examtopics.com/discussions/google/view/123007-exam-professional-cloud-devops-engineer-topic-1-question-118/",
    "body": "You are building and running client applications in Cloud Run and Cloud Functions. Your client requires that all logs must be available for one year so that the client can import the logs into their logging service. You must minimize required code changes. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUpdate all images in Cloud Run and all functions in Cloud Functions to send logs to both Cloud Logging and the client's logging service. Ensure that all the ports required to send logs are open in the VPC firewall.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a Pub/Sub topic, subscription, and logging sink. Configure the logging sink to send all logs into the topic. Give your client access to the topic to retrieve the logs.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a storage bucket and appropriate VPC firewall rules. Update all images in Cloud Run and all functions in Cloud Functions to send logs to a file within the storage bucket.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a logs bucket and logging sink. Set the retention on the logs bucket to 365 days. Configure the logging sink to send logs to the bucket. Give your client access to the bucket to retrieve the logs.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 10,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-12-06T02:03:00.000Z",
        "voteCount": 3,
        "content": "Choose Option D.\n\nCreating a logs bucket and logging sink, is the recommended approach to meet the client's requirement of retaining logs for one year while minimizing code changes. By configuring a logging sink to send logs to a bucket and setting the retention period on the bucket to 365 days, you leverage Google Cloud's managed logging and storage services.\n\nThis approach abstracts the log storage from your applications running in Cloud Run and Cloud Functions, ensuring that logs are retained for the specified duration without requiring modifications to individual codebases. Additionally, providing your client access to the designated bucket allows them to retrieve the logs seamlessly. It's a centralized and efficient solution that aligns with best practices for log management in oogle Cloud."
      },
      {
        "date": "2023-10-26T03:45:00.000Z",
        "voteCount": 4,
        "content": "Right answer"
      },
      {
        "date": "2023-10-15T16:18:00.000Z",
        "voteCount": 1,
        "content": "Answer D is a secure solution."
      },
      {
        "date": "2023-10-09T08:40:00.000Z",
        "voteCount": 3,
        "content": "Answer D: sink logs in a bucket is the cleanest and quickest solution."
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 119,
    "url": "https://www.examtopics.com/discussions/google/view/123008-exam-professional-cloud-devops-engineer-topic-1-question-119/",
    "body": "You are building and running client applications in Cloud Run and Cloud Functions. Your client requires that all logs must be available for one year so that the client can import the logs into their logging service. You must minimize required code changes. What should you do?<br>",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDeploy Falco or Twistlock on GKE to monitor for vulnerabilities on your running Pods.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure Identity and Access Management (IAM) policies to create a least privilege model on your GKE clusters.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse Binary Authorization to attest images during your CI/CD pipeline.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEnable Container Analysis in Artifact Registry, and check for common vulnerabilities and exposures (CVEs) in your container images."
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 5,
        "isMostVoted": true
      },
      {
        "answer": "D",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2023-10-09T08:40:00.000Z",
        "voteCount": 9,
        "content": "it seems that the question doesn't match the answers."
      },
      {
        "date": "2023-12-06T23:39:00.000Z",
        "voteCount": 5,
        "content": "Maybe this is the correct question for them:\n\nAs part of your company's initiative to shift left on security, the InfoSec team is asking all teams to implement guard rails on all the Google Kubernetes Engine (GKE) clusters to only allow the deployment of trusted and approved images. You need to determine how to satisfy the InfoSec team's goal of shifting left on security. What should you do?\n\nAnd the answer should be option C:\n\nBinary Authorization allows you to define and enforce policies that determine which container images can run in your GKE environment based on image signatures. By integrating Binary Authorization into your CI/CD pipeline, you can ensure that only trusted and approved images, with the correct attestations, are deployed to the GKE clusters."
      },
      {
        "date": "2024-02-01T11:07:00.000Z",
        "voteCount": 2,
        "content": "As part of your company's initiative to shift left on security, the InfoSec team is asking all teams to implement guard rails on all the Google Kubernetes Engine (GKE) clusters to only allow the deployment of trusted and approved images. You need to determine how to satisfy the InfoSec team's goal of shifting left on security. What should you do?"
      },
      {
        "date": "2023-12-24T00:06:00.000Z",
        "voteCount": 1,
        "content": "The option that aligns with the requirement of retaining logs for one year without extensive code changes would be:\n\nD. Enable Container Analysis in Artifact Registry, and check for common vulnerabilities and exposures (CVEs) in your container images.\n\nThis option focuses on container image analysis and vulnerability checks without directly involving logging configurations or altering the codebase."
      },
      {
        "date": "2023-12-09T18:20:00.000Z",
        "voteCount": 3,
        "content": "Question 119 is a duplicate of question 118."
      },
      {
        "date": "2023-12-06T23:37:00.000Z",
        "voteCount": 2,
        "content": "Maybe this is the correct question for them:\n\nAs part of your company's initiative to shift left on security, the InfoSec team is asking all teams to implement guard rails on all the Google Kubernetes Engine (GKE) clusters to only allow the deployment of trusted and approved images. You need to determine how to satisfy the InfoSec team's goal of shifting left on security. What should you do?"
      },
      {
        "date": "2023-10-26T03:47:00.000Z",
        "voteCount": 4,
        "content": "It seems like questions doesnt match with the answers given"
      },
      {
        "date": "2023-10-17T20:53:00.000Z",
        "voteCount": 1,
        "content": "Agreed!  The question implies availability:   \"all logs must be available for one year so that the client can import the logs into their logging service. You must minimize required code changes.\"  However, the answers refer to security (IAM, vulnerabilities, binary authorization, etc.)."
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 120,
    "url": "https://www.examtopics.com/discussions/google/view/122063-exam-professional-cloud-devops-engineer-topic-1-question-120/",
    "body": "You have an application that runs in Google Kubernetes Engine (GKE). The application consists of several microservices that are deployed to GKE by using Deployments and Services. One of the microservices is experiencing an issue where a Pod returns 403 errors after the Pod has been running for more than five hours. Your development team is working on a solution, but the issue will not be resolved for a month. You need to ensure continued operations until the microservice is fixed. You want to follow Google-recommended practices and use the fewest number of steps. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a cron job to terminate any Pods that have been running for more than five hours.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAdd a HTTP liveness probe to the microservice's deployment.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tMonitor the Pods, and terminate any Pods that have been running for more than five hours.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure an alert to notify you whenever a Pod returns 403 errors."
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 10,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-10-26T04:02:00.000Z",
        "voteCount": 8,
        "content": "Liveness probes are used to monitor the health of containers inside pods. They can identify application instances that have failed, even if the pod appears to be operational, If a liveness probe detects an unhealthy state, Kubernetes kills the container and tries to redeploy it. If the probe succeeds, no action is taken and no events are logged."
      },
      {
        "date": "2023-12-06T02:13:00.000Z",
        "voteCount": 2,
        "content": "The recommended solution is (option B)\n\nAdd a HTTP liveness probe to the microservice's deployment. By implementing a liveness probe, the Kubernetes system periodically checks the specified endpoint of the microservice to determine its health. If the microservice becomes unresponsive or encounters the 403 errors, Kubernetes will automatically restart the Pod.\n\nThis approach ensures continuous operations by proactively detecting and addressing issues, minimizing manual intervention. It aligns with Google-recommended practices for handling service health and availability in a Kubernetes environment with minimal steps and complexity."
      },
      {
        "date": "2023-11-02T14:01:00.000Z",
        "voteCount": 1,
        "content": "B is Answer."
      },
      {
        "date": "2023-10-01T08:42:00.000Z",
        "voteCount": 1,
        "content": "Answer should be B"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 121,
    "url": "https://www.examtopics.com/discussions/google/view/122340-exam-professional-cloud-devops-engineer-topic-1-question-121/",
    "body": "You want to share a Cloud Monitoring custom dashboard with a partner team. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tProvide the partner team with the dashboard URL to enable the partner team to create a copy of the dashboard.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tExport the metrics to BigQuery. Use Looker Studio to create a dashboard, and share the dashboard with the partner team.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCopy the Monitoring Query Language (MQL) query from the dashboard, and send the ML query to the partner team.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDownload the JSON definition of the dashboard, and send the JSON file to the partner team."
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 9,
        "isMostVoted": true
      },
      {
        "answer": "D",
        "count": 3,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2024-08-06T08:50:00.000Z",
        "voteCount": 1,
        "content": "Unclear question, if you are sharing your dashboard with data in it, then you choose (A). However, if you are sharing the structure so they can create their own copy of the dashboard for their data then (D).  https://cloud.google.com/monitoring/charts/dashboards#copy-dashboard"
      },
      {
        "date": "2024-06-07T00:45:00.000Z",
        "voteCount": 1,
        "content": "This allows the partner team to import the dashboard into their own Cloud Monitoring environment, ensuring they have an exact copy of the dashboard with all its configurations and metrics. This is a straightforward and reliable way to share custom dashboards within Google Cloud Monitoring. Option A doesn't grant viewing access to the partner team. They would need to create their own dashboard"
      },
      {
        "date": "2023-12-06T09:16:00.000Z",
        "voteCount": 3,
        "content": "The recommended solution is (Option A).\n\nProvide the partner team with the dashboard URL to enable them to create a copy of the dashboard. By sharing the dashboard URL, the partner team can access and duplicate the specific Cloud Monitoring custom dashboard easily.\n\nThis method allows for a straightforward and efficient way to share the dashboard configuration without the need for additional manual steps or exporting/importing files. It ensures a seamless transfer of the custom dashboard to the partner team, enabling them to leverage the same monitoring setup for their needs."
      },
      {
        "date": "2023-11-24T03:32:00.000Z",
        "voteCount": 3,
        "content": "In A they see your data and with D they their own data but using the same layout as in the dashboard you shared. So maybe A but the scope is not clear in the question..."
      },
      {
        "date": "2023-11-08T01:31:00.000Z",
        "voteCount": 2,
        "content": "Should be A it looks like:\nhttps://cloud.google.com/monitoring/charts/share-dashboards#owner-rolesowner\n\n\"We recommend that you use Monitoring to send the URL of a dashboard to your recipients when you have that option. Monitoring identifies those recipients who might not have permission to view the dashboard and provides an option for you to grant the required permissions.\""
      },
      {
        "date": "2023-11-02T14:02:00.000Z",
        "voteCount": 2,
        "content": "D is answer."
      },
      {
        "date": "2023-10-26T04:23:00.000Z",
        "voteCount": 2,
        "content": "I will go with D , I have omitted B and C , Option A is fine but atlast it says copy the dashboard, we cant copy the dashboard when shared."
      },
      {
        "date": "2023-10-22T14:53:00.000Z",
        "voteCount": 1,
        "content": "Answer should be A according to this link:\nhttps://cloud.google.com/monitoring/charts/share-dashboards"
      },
      {
        "date": "2023-10-03T23:27:00.000Z",
        "voteCount": 2,
        "content": "Answer should be D"
      },
      {
        "date": "2023-10-26T04:05:00.000Z",
        "voteCount": 1,
        "content": "Bruh, Do you even know how JSON file looks like ?? What partners will do with just JSON file?"
      },
      {
        "date": "2023-10-26T04:20:00.000Z",
        "voteCount": 2,
        "content": "Sorry , my bad !! it actually works, I will go with D."
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 122,
    "url": "https://www.examtopics.com/discussions/google/view/122490-exam-professional-cloud-devops-engineer-topic-1-question-122/",
    "body": "You are building an application that runs on Cloud Run. The application needs to access a third-party API by using an API key. You need to determine a secure way to store and use the API key in your application by following Google-recommended practices. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSave the API key in Secret Manager as a secret. Reference the secret as an environment variable in the Cloud Run application.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSave the API key in Secret Manager as a secret key. Mount the secret key under the /sys/api_key directory, and decrypt the key in the Cloud Run application.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSave the API key in Cloud Key Management Service (Cloud KMS) as a key. Reference the key as an environment variable in the Cloud Run application.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEncrypt the API key by using Cloud Key Management Service (Cloud KMS), and pass the key to Cloud Run as an environment variable. Decrypt and use the key in Cloud Run."
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 10,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-02-15T05:14:00.000Z",
        "voteCount": 1,
        "content": "https://cloud.google.com/run/docs/configuring/services/secrets#access-secrets:~:text=Pass%20a%20secret%20using%20environment%20variables.%20Environment%20variables%20are%20resolved%20at%20instance%20startup%20time%2C%20so%20if%20you%20use%20this%20method%2C%20Google%20recommends%20that%20you%20pin%20the%20secret%20to%20a%20particular%20version%20rather%20than%20using%20latest."
      },
      {
        "date": "2023-12-06T18:07:00.000Z",
        "voteCount": 3,
        "content": "The recommended solution is (option A)\n\nSave the API key in Secret Manager as a secret and reference the secret as an environment variable in the Cloud Run application. This approach aligns with Google-recommended practices for securely managing sensitive information.\n\nSecret Manager provides a centralized and secure storage for secrets, allowing you to store and retrieve the API key. Referencing the secret as an environment variable in the Cloud Run application ensures that the key remains confidential and is easily accessible without exposing it directly in the code. It enhances security by separating sensitive information from the application logic and adheres to best practices for secure credential management in a cloud environment."
      },
      {
        "date": "2023-11-08T01:37:00.000Z",
        "voteCount": 3,
        "content": "A is answer. B is wrong because: Cloud Run does not allow you to mount secrets at /dev, /proc and /sys, or on their subdirectories."
      },
      {
        "date": "2023-11-02T14:03:00.000Z",
        "voteCount": 1,
        "content": "A is answer."
      },
      {
        "date": "2023-10-26T04:27:00.000Z",
        "voteCount": 2,
        "content": "It should be A"
      },
      {
        "date": "2023-10-22T00:17:00.000Z",
        "voteCount": 1,
        "content": "Answer should be A"
      },
      {
        "date": "2023-10-05T02:30:00.000Z",
        "voteCount": 1,
        "content": "A is the right answer as per my openion"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 123,
    "url": "https://www.examtopics.com/discussions/google/view/122342-exam-professional-cloud-devops-engineer-topic-1-question-123/",
    "body": "You are currently planning how to display Cloud Monitoring metrics for your organization\u2019s Google Cloud projects. Your organization has three folders and six projects:<br><br><img src=\"https://img.examtopics.com/professional-cloud-devops-engineer/image4.png\"><br><br>You want to configure Cloud Monitoring dashboards to only display metrics from the projects within one folder. You need to ensure that the dashboards do not display metrics from projects in the other folders. You want to follow Google-recommended practices. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a single new scoping project.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate new scoping projects for each folder.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse the current app-one-prod project as the scoping project.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse the current app-one-dev, app-one-staging, and app-one-prod projects as the scoping project for each folder."
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 12,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-10-09T08:51:00.000Z",
        "voteCount": 8,
        "content": "Best practice is to use a new or empty project for scoping, so B rather than D: https://cloud.google.com/monitoring/settings#create-multi"
      },
      {
        "date": "2024-05-08T11:47:00.000Z",
        "voteCount": 1,
        "content": "Agree With B"
      },
      {
        "date": "2024-02-15T05:19:00.000Z",
        "voteCount": 1,
        "content": "https://cloud.google.com/monitoring/settings#create-multi"
      },
      {
        "date": "2023-12-06T21:30:00.000Z",
        "voteCount": 2,
        "content": "The recommended solution is (option B)\n\nCreate new scoping projects for each folder. Google Cloud Monitoring dashboards allow you to scope metrics based on projects, and by creating separate scoping projects for each folder, you can effectively isolate and display metrics only from the projects within that specific folder.\n\nThis approach aligns with Google-recommended practices by providing a structured and organized way to manage and visualize metrics. Using dedicated scoping projects for each folder ensures a clean separation of monitoring data, allowing you to customize dashboards according to the specific projects within a given folder while excluding metrics from projects in other folders."
      },
      {
        "date": "2023-11-14T14:06:00.000Z",
        "voteCount": 1,
        "content": "I thing is A\n\"Example of scoping projects and monitored projects\nAssume that your Staging and Production projects contain Compute Engine virtual machine (VM) instances. To view the metrics for all of your VMs in a single view, you create another project, AllEnvironments, and then add the Staging and Production projects as monitored projects.\"\nhttps://cloud.google.com/monitoring/settings#create-multi"
      },
      {
        "date": "2023-11-02T14:04:00.000Z",
        "voteCount": 1,
        "content": "B is best choose."
      },
      {
        "date": "2023-10-26T04:40:00.000Z",
        "voteCount": 3,
        "content": "B and D seems good answer , i would porbably go with B if the choice make me a millionaire."
      },
      {
        "date": "2023-10-05T02:50:00.000Z",
        "voteCount": 1,
        "content": "For me the answer should be B \nreffer : https://cloud.google.com/monitoring/settings/multiple-projects"
      },
      {
        "date": "2023-10-03T23:31:00.000Z",
        "voteCount": 1,
        "content": "Answer should be D"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 124,
    "url": "https://www.examtopics.com/discussions/google/view/122343-exam-professional-cloud-devops-engineer-topic-1-question-124/",
    "body": "Your company\u2019s security team needs to have read-only access to Data Access audit logs in the _Required bucket. You want to provide your security team with the necessary permissions following the principle of least privilege and Google-recommended practices. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAssign the roles/logging.viewer role to each member of the security team.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAssign the roles/logging.viewer role to a group with all the security team members.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAssign the roles/logging.privateLogViewer role to each member of the security team.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAssign the roles/logging.privateLogViewer role to a group with all the security team members.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 7,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-02-15T05:23:00.000Z",
        "voteCount": 2,
        "content": "https://cloud.google.com/iam/docs/job-functions/auditing#:~:text=Admin%20Activity%20logs.-,logging.privateLogViewer,privateLogViewer%20role%20gives%20the%20ability%20to%20view%20the%20Data%20Access%20logs.,-Once%20log%20entries"
      },
      {
        "date": "2024-01-27T04:00:00.000Z",
        "voteCount": 1,
        "content": "the question is wrong, the _Required log bucket is exclusively for Admin Activity logs and is not configurable for other types of logs.\nso B would be good, there is no good answer here."
      },
      {
        "date": "2023-12-20T23:11:00.000Z",
        "voteCount": 1,
        "content": "The right one"
      },
      {
        "date": "2023-12-06T21:36:00.000Z",
        "voteCount": 2,
        "content": "The recommended solution is (option D)\n\nAssign the roles/logging.privateLogViewer role to a group with all the security team members. This approach follows the principle of least privilege by granting the specific role needed for read-only access to Data Access audit logs. The roles/logging.privateLogViewer role is more restrictive than roles/logging.viewer, providing access only to private logs, such as Data Access audit logs, and aligns with Google-recommended practices for securing sensitive data.\n\nBy assigning this role to a group with all security team members, you can efficiently manage and update permissions for the entire team, maintaining a centralized and organized approach to access control for the designated logs in the _Required bucket."
      },
      {
        "date": "2023-11-15T10:56:00.000Z",
        "voteCount": 1,
        "content": "D, no brainer, give access to private logs (so also access logs) to the team. Option C is partially correct, you should rather give access to a group than to individual members just to be future-proof."
      },
      {
        "date": "2023-10-22T00:21:00.000Z",
        "voteCount": 1,
        "content": "Answer should be D"
      },
      {
        "date": "2023-10-12T18:34:00.000Z",
        "voteCount": 3,
        "content": "https://cloud.google.com/iam/docs/job-functions/auditing\nThe logging.privateLogViewer role gives the ability to view the Data Access logs.\n{\n      \"role\": \"roles/logging.privateLogViewer\",\n      \"members\": [\n        \"group:security-team@example.com\"\n      ]\nAnswer D seems correct."
      },
      {
        "date": "2023-10-03T23:32:00.000Z",
        "voteCount": 1,
        "content": "Answer should be D"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 125,
    "url": "https://www.examtopics.com/discussions/google/view/124659-exam-professional-cloud-devops-engineer-topic-1-question-125/",
    "body": "Your team is building a service that performs compute-heavy processing on batches of data. The data is processed faster based on the speed and number of CPUs on the machine. These batches of data vary in size and may arrive at any time from multiple third-party sources. You need to ensure that third parties are able to upload their data securely. You want to minimize costs, while ensuring that the data is processed as quickly as possible. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tProvide a secure file transfer protocol (SFTP) server on a Compute Engine instance so that third parties can upload batches of data, and provide appropriate credentials to the server.<br>Create a Cloud Function with a google.storage.object.finalize Cloud Storage trigger. Write code so that the function can scale up a Compute Engine autoscaling managed instance group<br>Use an image pre-loaded with the data processing software that terminates the instances when processing completes.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tProvide a Cloud Storage bucket so that third parties can upload batches of data, and provide appropriate Identity and Access Management (IAM) access to the bucket.<br>Use a standard Google Kubernetes Engine (GKE) cluster and maintain two services: one that processes the batches of data, and one that monitors Cloud Storage for new batches of data.<br>Stop the processing service when there are no batches of data to process.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tProvide a Cloud Storage bucket so that third parties can upload batches of data, and provide appropriate Identity and Access Management (IAM) access to the bucket.<br>Create a Cloud Function with a google.storage.object.finalize Cloud Storage trigger. Write code so that the function can scale up a Compute Engine autoscaling managed instance group.<br>Use an image pre-loaded with the data processing software that terminates the instances when processing completes.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tProvide a Cloud Storage bucket so that third parties can upload batches of data, and provide appropriate Identity and Access Management (IAM) access to the bucket.<br>Use Cloud Monitoring to detect new batches of data in the bucket and trigger a Cloud Function that processes the data.<br>Set a Cloud Function to use the largest CPU possible to minimize the runtime of the processing."
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 7,
        "isMostVoted": true
      },
      {
        "answer": "D",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2024-09-25T16:08:00.000Z",
        "voteCount": 1,
        "content": "D is best.\n\nC says writing code and all that could take time. Speed is key with using as much instant cloud services as possible."
      },
      {
        "date": "2024-08-13T03:43:00.000Z",
        "voteCount": 1,
        "content": "D over C"
      },
      {
        "date": "2023-12-06T21:55:00.000Z",
        "voteCount": 2,
        "content": "The recommended solution is (option C)\n\nProvide a Cloud Storage bucket for third parties to upload batches of data, and utilize a Cloud Function with a google.storage.object.finalize trigger to scale up a Compute Engine autoscaling managed instance group. This approach ensures secure data uploads to a Cloud Storage bucket with proper IAM access controls.\n\nThe Cloud Function, triggered upon new object finalization in the bucket, scales up a managed instance group with pre-loaded data processing software, optimizing for compute-heavy tasks. The instances terminate upon completion, minimizing costs.\n\nThis design efficiently leverages serverless and autoscaling capabilities, ensuring quick and cost-effective processing of data batches arriving at varying times from multiple sources."
      },
      {
        "date": "2023-11-21T05:55:00.000Z",
        "voteCount": 2,
        "content": "I would say C. GCS is not that expensive and you can set rules to archive old data. GCE is optimal for compute heavy batch jobs compared to cloud functions."
      },
      {
        "date": "2023-10-26T04:49:00.000Z",
        "voteCount": 3,
        "content": "I would go with C , using GCS is cost effective and secure compared to other options.\nD. Cloud function with large CPU results in high cost."
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 126,
    "url": "https://www.examtopics.com/discussions/google/view/124660-exam-professional-cloud-devops-engineer-topic-1-question-126/",
    "body": "You are reviewing your deployment pipeline in Google Cloud Deploy. You must reduce toil in the pipeline, and you want to minimize the amount of time it takes to complete an end-to-end deployment. What should you do? (Choose two.)",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a trigger to notify the required team to complete the next step when manual intervention is required.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDivide the automation steps into smaller tasks.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse a script to automate the creation of the deployment pipeline in Google Cloud Deploy.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAdd more engineers to finish the manual steps.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAutomate promotion approvals from the development environment to the test environment.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "BE",
    "answerDescription": "",
    "votes": [
      {
        "answer": "BE",
        "count": 13,
        "isMostVoted": true
      },
      {
        "answer": "AE",
        "count": 9,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2023-10-28T11:27:00.000Z",
        "voteCount": 5,
        "content": "Chose A, E"
      },
      {
        "date": "2023-12-09T08:50:00.000Z",
        "voteCount": 3,
        "content": "Vote BE"
      },
      {
        "date": "2023-12-06T22:01:00.000Z",
        "voteCount": 3,
        "content": "The recommended approaches to reduce toil and minimize deployment time in Google Cloud Deploy are (options B and E).\n\n- Option B, dividing automation steps into smaller tasks, allows for better manageability and flexibility in the deployment process. This enables parallel execution of smaller tasks, speeding up the overall deployment.\n\n- Option E, automating promotion approvals, eliminates manual intervention and streamlines the progression from development to test environments, further reducing delays and potential errors associated with manual approval processes.\n\nBoth options contribute to a more efficient and automated deployment pipeline in Google Cloud Deploy."
      },
      {
        "date": "2023-11-24T03:24:00.000Z",
        "voteCount": 2,
        "content": "It is BE"
      },
      {
        "date": "2023-11-15T11:10:00.000Z",
        "voteCount": 4,
        "content": "imho:\n\nA. Create a trigger to notify the required team to complete the next step when manual intervention is required.\nWe want to reduce the time for end-to-end deployment. Notification of required manual intervention can reduce this time.\n\nB. Divide the automation steps into smaller tasks.\nThis doesn't reduce toil or time, but maybe I miss something here?\n\nC. Use a script to automate the creation of the deployment pipeline in Google Cloud Deploy.\nWe would rather use a webhook to create a deployment or pub/sub message. Doesn't sound like an answer to this question.\n\nD. Add more engineers to finish the manual steps.\nThis simply doesn't work here.\n\nE. Automate promotion approvals from the development environment to the test environment.\nThis reduces toil if covered by appropriate tests."
      },
      {
        "date": "2023-11-03T15:16:00.000Z",
        "voteCount": 2,
        "content": "Should be BE\nhttps://sre.google/workbook/eliminating-toil/"
      },
      {
        "date": "2023-10-26T04:57:00.000Z",
        "voteCount": 3,
        "content": "Chose based on eliminating other options"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 127,
    "url": "https://www.examtopics.com/discussions/google/view/124316-exam-professional-cloud-devops-engineer-topic-1-question-127/",
    "body": "You work for a global organization and are running a monolithic application on Compute Engine. You need to select the machine type for the application to use that optimizes CPU utilization by using the fewest number of steps. You want to use historical system metrics to identify the machine type for the application to use. You want to follow Google-recommended practices. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse the Recommender API and apply the suggested recommendations.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate an Agent Policy to automatically install Ops Agent in all VMs.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tInstall the Ops Agent in a fleet of VMs by using the gcloud CLI.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tReview the Cloud Monitoring dashboard for the VM and choose the machine type with the lowest CPU utilization."
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 8,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-12-06T22:11:00.000Z",
        "voteCount": 3,
        "content": "The recommended approach for optimizing CPU utilization based on historical system metrics in a global organization running a monolithic application on Compute Engine is (option A).\n\nUtilizing the Recommender API allows you to leverage Google Cloud's machine learning algorithms to analyze historical data and provide specific recommendations for resource optimization.\n\nThis method is proactive and can automatically suggest appropriate changes to improve efficiency, aligning with Google-recommended practices. By incorporating the insights provided by the Recommender API, you can make informed decisions to select the most suitable machine type for the application, ensuring optimal CPU utilization with minimal manual intervention."
      },
      {
        "date": "2023-11-03T02:34:00.000Z",
        "voteCount": 2,
        "content": "A is the answer."
      },
      {
        "date": "2023-10-26T04:58:00.000Z",
        "voteCount": 3,
        "content": "It should be A"
      },
      {
        "date": "2023-10-22T00:26:00.000Z",
        "voteCount": 2,
        "content": "Answer should be A\nhttps://cloud.google.com/recommender/docs/overview"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 128,
    "url": "https://www.examtopics.com/discussions/google/view/124699-exam-professional-cloud-devops-engineer-topic-1-question-128/",
    "body": "You deployed an application into a large Standard Google Kubernetes Engine (GKE) cluster. The application is stateless and multiple pods run at the same time. Your application receives inconsistent traffic. You need to ensure that the user experience remains consistent regardless of changes in traffic and that the resource usage of the cluster is optimized.<br><br>What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure a cron job to scale the deployment on a schedule",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure a Horizontal Pod Autoscaler.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure a Vertical Pod Autoscaler",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure cluster autoscaling on the node pool."
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 7,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-10-27T01:19:00.000Z",
        "voteCount": 5,
        "content": "Inconsistent traffic .. HPA"
      },
      {
        "date": "2023-12-28T03:31:00.000Z",
        "voteCount": 1,
        "content": "HPA will take care of the traffic flow, will scale the pods which will  maintain consistent performance"
      },
      {
        "date": "2023-12-06T22:17:00.000Z",
        "voteCount": 2,
        "content": "The recommended approach to ensure a consistent user experience and optimize resource usage for a stateless application with inconsistent traffic in a large Standard Google Kubernetes Engine (GKE) cluster is (option B)\n\nConfigure a Horizontal Pod Autoscaler (HPA). HPA automatically adjusts the number of replica pods based on observed CPU utilization or other custom metrics. In the context of varying traffic patterns, HPA dynamically scales the number of pods to meet demand, ensuring that there are enough instances to handle increased traffic and scaling down during periods of lower demand.\n\nThis helps maintain consistent performance while optimizing resource utilization in response to changing workloads."
      },
      {
        "date": "2023-11-03T02:36:00.000Z",
        "voteCount": 2,
        "content": "B is the answer."
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 129,
    "url": "https://www.examtopics.com/discussions/google/view/124662-exam-professional-cloud-devops-engineer-topic-1-question-129/",
    "body": "You need to deploy a new service to production. The service needs to automatically scale using a managed instance group and should be deployed across multiple regions. The service needs a large number of resources for each instance and you need to plan for capacity. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tMonitor results of Cloud Trace to determine the optimal sizing.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse the n2-highcpu-96 machine type in the configuration of the managed instance group.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDeploy the service in multiple regions and use an internal load balancer to route traffic.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tValidate that the resource requirements are within the available project quota limits of each region.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 6,
        "isMostVoted": true
      },
      {
        "answer": "C",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2024-09-25T16:13:00.000Z",
        "voteCount": 1,
        "content": "Same Q as #37"
      },
      {
        "date": "2024-02-15T06:23:00.000Z",
        "voteCount": 1,
        "content": "D, then C"
      },
      {
        "date": "2023-12-06T22:22:00.000Z",
        "voteCount": 1,
        "content": "The recommended approach for deploying a new service to production that requires automatic scaling across multiple regions with a managed instance group and has high resource requirements is (option D).\n\nValidating that the resource requirements are within the available project quota limits for each region is crucial to avoid issues during deployment. Each Google Cloud region has specific quota limits for various resources, such as CPU, memory, and instances.\n\nEnsuring that the planned capacity aligns with the allocated quotas prevents unexpected scaling limitations and helps in effective capacity planning for the service across multiple regions.\n\nThis approach ensures a smooth deployment and operation of the service without encountering resource constraints."
      },
      {
        "date": "2023-11-21T06:17:00.000Z",
        "voteCount": 1,
        "content": "Weird question, you need both C and D in order to have a proper solution..."
      },
      {
        "date": "2023-11-03T02:37:00.000Z",
        "voteCount": 1,
        "content": "D is the answer."
      },
      {
        "date": "2023-10-28T11:31:00.000Z",
        "voteCount": 4,
        "content": "Question #37"
      },
      {
        "date": "2023-10-26T05:09:00.000Z",
        "voteCount": 1,
        "content": "Valid answer"
      },
      {
        "date": "2023-11-02T21:59:00.000Z",
        "voteCount": 2,
        "content": "I don't agree with C, since it only mentions multi-region but doesn't do anything to cope with scalability. D although doesn't directly mention multi-region but it is the prereq to achieve large scale resource provisioning"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 130,
    "url": "https://www.examtopics.com/discussions/google/view/124538-exam-professional-cloud-devops-engineer-topic-1-question-130/",
    "body": "You are analyzing Java applications in production. All applications have Cloud Profiler and Cloud Trace installed and configured by default. You want to determine which applications need performance tuning. What should you do? (Choose two.)",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tExamine the wall-clock time and the CPU time of the application. If the difference is substantial increase the CPU resource allocation.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tExamine the wall-clock time and the CPU time of the application. If the difference is substantial, increase the memory resource allocation.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tExamine the wall-clock time and the CPU time of the application. If the difference is substantial, increase the local disk storage allocation.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tExamine the latency time the wall-clock time and the CPU time of the application. If the latency time is slowly burning down the error budget, and the difference between wall-clock time and CPU time is minimal mark the application for optimization.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tExamine the heap usage of the application. If the usage is low, mark the application for optimization.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "DE",
    "answerDescription": "",
    "votes": [
      {
        "answer": "DE",
        "count": 6,
        "isMostVoted": true
      },
      {
        "answer": "D",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2024-02-15T06:32:00.000Z",
        "voteCount": 3,
        "content": "I asked Google's Gemini AI and this is what it answered. \n\nHere's why these options are correct:\n\nD:\n\nLatency time: High latency directly impacts user experience and can negatively affect your error budget.\nWall-clock time: This represents the elapsed time from start to finish of a request. A large difference with CPU time indicates bottlenecks outside the CPU, requiring optimization.\nCPU time: This represents the actual CPU processing time used by the application. Minimal difference with wall-clock time suggests inefficient use of CPU, potentially needing optimization.\nE:\n\nHeap usage: Low heap usage can indicate under-provisioning or potential memory leaks. Either way, it implies inefficient resource utilization and deserves investigation."
      },
      {
        "date": "2023-12-06T22:42:00.000Z",
        "voteCount": 1,
        "content": "Choose options D and E.\n\n- Option D suggests examining the latency time, wall-clock time, and CPU time of the application. If the latency time is consistently burning down the error budget and the difference between wall-clock time and CPU time is minimal, it indicates potential areas for optimization. This helps identify performance bottlenecks that may be impacting the user experience.\n\n- Option E suggests examining the heap usage of the application, and if the usage is low, marking the application for optimization. Low heap usage may indicate that the application is not fully utilizing available resources, presenting an opportunity for optimization to enhance efficiency and responsiveness.\n\nTogether, these approaches provide insights into areas where performance improvements may be beneficial for the applications."
      },
      {
        "date": "2023-12-06T22:41:00.000Z",
        "voteCount": 1,
        "content": "Choose options D and E.\n\n- Option D suggests examining the latency time, wall-clock time, and CPU time of the application. If the latency time is consistently burning down the error budget and the difference between wall-clock time and CPU time is minimal, it indicates potential areas for optimization. This helps identify performance bottlenecks that may be impacting the user experience.\n\n- Option E suggests examining the heap usage of the application, and if the usage is low, marking the application for optimization. Low heap usage may indicate that the application is not fully utilizing available resources, presenting an opportunity for optimization to enhance efficiency and responsiveness.\n\nTogether, these approaches provide insights into areas where performance improvements may be beneficial for the applications."
      },
      {
        "date": "2023-10-31T20:11:00.000Z",
        "voteCount": 2,
        "content": "A conflicts with D hence A gets excluded. B and C don't have direct relation with CPU time/wall time hence excluded either. Answers are D and E."
      },
      {
        "date": "2023-10-31T20:08:00.000Z",
        "voteCount": 1,
        "content": "D for sure, since \n\"If the CPU time is similar to the wall time, then that indicates the code is CPU intensive; almost all the time it takes to run is spent by the CPU. Long-running CPU-intensive blocks of code might be candidates for optimization.\""
      },
      {
        "date": "2023-10-23T23:41:00.000Z",
        "voteCount": 1,
        "content": "https://cloud.google.com/profiler/docs/concepts-profiling"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 131,
    "url": "https://www.examtopics.com/discussions/google/view/124811-exam-professional-cloud-devops-engineer-topic-1-question-131/",
    "body": "Your organization stores all application logs from multiple Google Cloud projects in a central Cloud Logging project. Your security team wants to enforce a rule that each project team can only view their respective logs and only the operations team can view all the logs. You need to design a solution that meets the security team s requirements while minimizing costs. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tGrant each project team access to the project _Default view in the central logging project. Grant togging viewer access to the operations team in the central logging project.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate Identity and Access Management (IAM) roles for each project team and restrict access to the _Default log view in their individual Google Cloud project. Grant viewer access to the operations team in the central logging project.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate log views for each project team and only show each project team their application logs. Grant the operations team access to the _AllLogs view in the central logging project.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tExport logs to BigQuery tables for each project team. Grant project teams access to their tables. Grant logs writer access to the operations team in the central logging project."
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 6,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-06-17T10:30:00.000Z",
        "voteCount": 1,
        "content": "why not B?"
      },
      {
        "date": "2023-12-06T23:14:00.000Z",
        "voteCount": 2,
        "content": "Choose (option C).\n\nCreating log views for each project team allows you to tailor access to only show each team their relevant application logs. This fine-grained control ensures that project teams can access their own logs while maintaining isolation from logs of other teams. Granting the operations team access to the _AllLogs view in the central logging project provides them with the necessary visibility across all logs.\n\nThis approach not only satisfies the security requirements but also minimizes costs by efficiently organizing and restricting access to the logs based on project teams' needs."
      },
      {
        "date": "2023-11-03T03:05:00.000Z",
        "voteCount": 2,
        "content": "C is the answer."
      },
      {
        "date": "2023-10-28T11:38:00.000Z",
        "voteCount": 4,
        "content": "maybe\nhttps://cloud.google.com/logging/docs/logs-views"
      },
      {
        "date": "2023-10-31T23:33:00.000Z",
        "voteCount": 2,
        "content": "\"Custom log views provide you with an advanced and granular way to control access to your logs data. For example, consider a scenario in which you store all of your organization's logs in a central Google Cloud project. Because log buckets can contain logs from multiple Google Cloud projects, you might want to control which Google Cloud projects different users can view logs from. Using custom log views, you can give one user access to logs only from a single Google Cloud project, while you give another user access to logs from all the Google Cloud projects.\"\nRegarding _Default view: \"Cloud Logging also creates a view for the _Default bucket called _Default. The _Default view for the _Default bucket shows all logs except Data Access audit logs.\", be noted it shows \"all logs\""
      },
      {
        "date": "2023-10-28T05:30:00.000Z",
        "voteCount": 2,
        "content": "Answer is B"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 132,
    "url": "https://www.examtopics.com/discussions/google/view/125235-exam-professional-cloud-devops-engineer-topic-1-question-132/",
    "body": "Your company uses Jenkins running on Google Cloud VM instances for CI/CD. You need to extend the functionality to use infrastructure as code automation by using Terraform. You must ensure that the Terraform Jenkins instance is authorized to create Google Cloud resources. You want to follow Google-recommended practices. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfirm that the Jenkins VM instance has an attached service account with the appropriate Identity and Access Management (IAM) permissions.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse the Terraform module so that Secret Manager can retrieve credentials.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a dedicated service account for the Terraform instance. Download and copy the secret key value to the GOOGLE_CREDENTIALS environment variable on the Jenkins server.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAdd the gcloud auth application-default login command as a step in Jenkins before running the Terraform commands."
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 14,
        "isMostVoted": true
      },
      {
        "answer": "C",
        "count": 7,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2024-02-02T17:31:00.000Z",
        "voteCount": 5,
        "content": "Downloading and setting Env Variable has potential to expose such high-level access to users .  where as a dedicated SA attached to VM does not expose any credentials at all. running tf by default would use SA attached to VM."
      },
      {
        "date": "2024-09-11T06:12:00.000Z",
        "voteCount": 1,
        "content": "Is not C: \"Download and copy the secret key value...\" lol"
      },
      {
        "date": "2024-08-29T00:21:00.000Z",
        "voteCount": 1,
        "content": "https://registry.terraform.io/providers/hashicorp/google/latest/docs/guides/provider_reference#running-terraform-on-google-cloud"
      },
      {
        "date": "2024-08-11T13:23:00.000Z",
        "voteCount": 1,
        "content": "Go with A. C introduces risk that if anyone gets your downloaded key that they can spin up any resources they want."
      },
      {
        "date": "2024-02-15T06:49:00.000Z",
        "voteCount": 4,
        "content": "Not chosing C because this works, but involves manually managing the key, which can be error-prone and less secure compared to using attached service accounts."
      },
      {
        "date": "2023-12-06T23:23:00.000Z",
        "voteCount": 1,
        "content": "Choose (option C).\n\nCreating a dedicated service account for the Terraform instance is a best practice as it allows for fine-grained control over permissions. By downloading and copying the secret key value to the GOOGLE_CREDENTIALS environment variable on the Jenkins server, you securely provide the necessary credentials to Terraform.\n\nThis approach minimizes security risks associated with manual handling of secret keys and adheres to the principle of least privilege by assigning only the required IAM permissions to the dedicated service account for Terraform automation."
      },
      {
        "date": "2024-09-11T06:11:00.000Z",
        "voteCount": 1,
        "content": "stop using chatgpt"
      },
      {
        "date": "2024-05-10T01:17:00.000Z",
        "voteCount": 1,
        "content": "A is safer"
      },
      {
        "date": "2023-12-03T01:42:00.000Z",
        "voteCount": 1,
        "content": "Vote C"
      },
      {
        "date": "2023-11-21T06:33:00.000Z",
        "voteCount": 1,
        "content": "using keys with the service account is against best practice but in this case it is the only answer that makes sense I guess..."
      },
      {
        "date": "2023-11-15T11:34:00.000Z",
        "voteCount": 3,
        "content": "C is the correct answer. A can't be since the terraform doesn't use the instance's service account for such operations. Think of it as running terraform on your local PC. You still need to somehow provide credentials to the cloud and envariable can be one of the solutions."
      },
      {
        "date": "2023-11-06T06:30:00.000Z",
        "voteCount": 1,
        "content": "The best way to ensure that the Terraform Jenkins instance is authorized to create Google Cloud resources and follow Google-recommended practices is to create a dedicated service account for the Terraform instance and download and copy the secret key value to the GOOGLE_CREDENTIALS environment variable on the Jenkins server."
      },
      {
        "date": "2023-11-03T03:10:00.000Z",
        "voteCount": 3,
        "content": "A is the answer."
      },
      {
        "date": "2023-11-02T22:17:00.000Z",
        "voteCount": 3,
        "content": "I go for A as it looks to be the fundamental thing at least."
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 133,
    "url": "https://www.examtopics.com/discussions/google/view/124664-exam-professional-cloud-devops-engineer-topic-1-question-133/",
    "body": "You encounter a large number of outages in the production systems you support. You receive alerts for all the outages, the alerts are due to unhealthy systems that are automatically restarted within a minute. You want to set up a process that would prevent staff burnout while following Site Reliability Engineering (SRE) practices. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEliminate alerts that are not actionable\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRedefine the related SLO so that the error budget is not exhausted",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDistribute the alerts to engineers in different time zones",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate an incident report for each of the alerts"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 8,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-12-06T23:30:00.000Z",
        "voteCount": 2,
        "content": "Choose option A.\n\nEliminating alerts that are not actionable helps streamline the alerting process and ensures that engineers are only notified when their intervention is necessary. This approach aligns with the SRE principle of reducing alert fatigue and focuses the attention of the engineering team on meaningful and actionable alerts.\n\nBy eliminating non-actionable alerts, you not only prevent unnecessary disruptions to the team but also allow them to concentrate on addressing critical issues, contributing to a more efficient and sustainable incident response process."
      },
      {
        "date": "2023-11-03T03:11:00.000Z",
        "voteCount": 1,
        "content": "Selected Answer: A"
      },
      {
        "date": "2023-11-01T03:41:00.000Z",
        "voteCount": 2,
        "content": "A prevent administrators from burnout"
      },
      {
        "date": "2023-11-01T03:41:00.000Z",
        "voteCount": 1,
        "content": "A prevent administrators from burnout"
      },
      {
        "date": "2023-10-26T07:23:00.000Z",
        "voteCount": 4,
        "content": "Right answer"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 134,
    "url": "https://www.examtopics.com/discussions/google/view/124847-exam-professional-cloud-devops-engineer-topic-1-question-134/",
    "body": "As part of your company's initiative to shift left on security, the InfoSec team is asking all teams to implement guard rails on all the Google Kubernetes Engine (GKE) clusters to only allow the deployment of trusted and approved images. You need to determine how to satisfy the InfoSec team's goal of shifting left on security. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEnable Container Analysis in Artifact Registry, and check for common vulnerabilities and exposures (CVEs) in your container images",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse Binary Authorization to attest images during your CI/CD pipeline\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure Identity and Access Management (IAM) policies to create a least privilege model on your GKE clusters.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDeploy Falco or Twistlock on GKE to monitor for vulnerabilities on your running Pods"
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 6,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-07-28T15:52:00.000Z",
        "voteCount": 1,
        "content": "Question 134 is question 119."
      },
      {
        "date": "2023-12-06T23:33:00.000Z",
        "voteCount": 2,
        "content": "To satisfy the goal of shifting left on security and implement guardrails to only allow the deployment of trusted and approved images on Google Kubernetes Engine (GKE) clusters, the recommended approach is (option B)\n\nUse Binary Authorization to attest images during your CI/CD pipeline. Binary Authorization allows you to define and enforce policies that determine which container images can run in your GKE environment based on image signatures. By integrating Binary Authorization into your CI/CD pipeline, you can ensure that only trusted and approved images, with the correct attestations, are deployed to the GKE clusters.\n\nThis proactive security measure aligns with the concept of shifting security left, as it establishes controls early in the development and deployment process, minimizing the risk of deploying compromised or unapproved images in production."
      },
      {
        "date": "2023-11-03T03:12:00.000Z",
        "voteCount": 2,
        "content": "B is the answer."
      },
      {
        "date": "2023-11-01T03:40:00.000Z",
        "voteCount": 1,
        "content": "using binary authorization"
      },
      {
        "date": "2023-10-28T11:45:00.000Z",
        "voteCount": 3,
        "content": "https://cloud.google.com/binary-authorization/docs/overview"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 135,
    "url": "https://www.examtopics.com/discussions/google/view/124848-exam-professional-cloud-devops-engineer-topic-1-question-135/",
    "body": "Your company operates in a highly regulated domain. Your security team requires that only trusted container images can be deployed to Google Kubernetes Engine (GKE). You need to implement a solution that meets the requirements of the security team while minimizing management overhead. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure Binary Authorization in your GKE clusters to enforce deploy-time security policies.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tGrant the roles/artifactregistry.writer role to the Cloud Build service account. Confirm that no employee has Artifact Registry write permission.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse Cloud Run to write and deploy a custom validator. Enable an Eventarc trigger to perform validations when new images are uploaded.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure Kritis to run in your GKE clusters to enforce deploy-time security policies."
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 7,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-12-07T09:55:00.000Z",
        "voteCount": 2,
        "content": "Choose Ooption A:\nConfigure Binary Authorization in your GKE clusters to enforce deploy-time security policies. \n\nBinary Authorization allows you to define and enforce policies that determine which container images can be deployed based on image signatures. By configuring Binary Authorization, you can enforce deploy-time security policies, ensuring that only trusted and verified container images are allowed to run in your GKE clusters.\n\nThis approach provides a robust security mechanism without requiring additional custom validators or complex configurations, minimizing management overhead while meeting the stringent security requirements of a highly regulated domain."
      },
      {
        "date": "2023-11-03T03:13:00.000Z",
        "voteCount": 2,
        "content": "A is the answer."
      },
      {
        "date": "2023-11-01T03:43:00.000Z",
        "voteCount": 2,
        "content": "using binary-authorization"
      },
      {
        "date": "2023-10-28T11:45:00.000Z",
        "voteCount": 3,
        "content": "https://cloud.google.com/binary-authorization/docs/overview"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 136,
    "url": "https://www.examtopics.com/discussions/google/view/124238-exam-professional-cloud-devops-engineer-topic-1-question-136/",
    "body": "Your CTO has asked you to implement a postmortem policy on every incident for internal use. You want to define what a good postmortem is to ensure that the policy is successful at your company. What should you do? (Choose two.)",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEnsure that all postmortems include what caused the incident, identify the person or team responsible for causing the incident, and how to prevent a future occurrence of the incident.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEnsure that all postmortems include what caused the incident, how the incident could have been worse, and how to prevent a future occurrence of the incident.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEnsure that all postmortems include the severity of the incident, how to prevent a future occurrence of the incident, and what caused the incident without naming internal system components.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEnsure that all postmortems include how the incident was resolved and what caused the incident without naming customer information.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEnsure that all postmortems include all incident participants in postmortem authoring and share postmortems as widely as possible.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "CE",
    "answerDescription": "",
    "votes": [
      {
        "answer": "CE",
        "count": 19,
        "isMostVoted": true
      },
      {
        "answer": "BD",
        "count": 3,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2023-10-21T10:55:00.000Z",
        "voteCount": 8,
        "content": "I think the answers are B &amp; D."
      },
      {
        "date": "2023-12-24T03:23:00.000Z",
        "voteCount": 1,
        "content": "Me too\nE -&gt;  include all incident participants in postmortem authoring, no much sense, the incident commander is the author of the postmortem\nA -&gt; identify the person or team responsible for causing the incident\nC -&gt; without naming internal system components, the postmortem has to be focus on the processes/components"
      },
      {
        "date": "2024-06-07T02:00:00.000Z",
        "voteCount": 1,
        "content": "Not D, I don't think it's always possible to detail how the incident was resolved, may be too complicated. B and C for me."
      },
      {
        "date": "2023-11-03T15:32:00.000Z",
        "voteCount": 7,
        "content": "Option B is incorrect because it states that the postmortem should include how the incident could have been worse.The focus of the postmortem should be on identifying the root cause of the incident and developing recommendations for preventing future occurrences."
      },
      {
        "date": "2024-06-25T18:17:00.000Z",
        "voteCount": 1,
        "content": "C, E - Don't share internal info and share as wide as possible. Post Mortems and RCAs typically are shared with customers."
      },
      {
        "date": "2024-02-16T02:54:00.000Z",
        "voteCount": 1,
        "content": "C: https://sre.google/workbook/postmortem-culture/#:~:text=away%20from%20us%E2%80%9D).-,Preventative%20action,Disallow%20any%20single%20operation%20from%20affecting%20servers%20spanning%20namespace/class%20boundaries%E2%80%9D).,-Blamelessness\n\nE: https://sre.google/workbook/postmortem-culture/#:~:text=Include%20all%20incident%20participants%20in%20postmortem%20authoring\nhttps://sre.google/workbook/postmortem-culture/#:~:text=In%20order%20to%20maintain%20a%20healthy%20postmortem%20culture%20within%20an%20organization%2C%20it%E2%80%99s%20important%20to%20share%20postmortems%20as%20widely%20as%20possible"
      },
      {
        "date": "2023-12-06T23:59:00.000Z",
        "voteCount": 3,
        "content": "Choose C &amp; E\n\nOption C emphasizes including the severity of the incident, prevention strategies for future occurrences, and an analysis of what caused the incident without necessarily naming internal system components. This approach ensures a balance between transparency and security, providing valuable insights without exposing sensitive internal details.\n\nOption E, which advocates involving all incident participants in postmortem authoring and sharing postmortems widely, promotes a collaborative and inclusive culture. Involving all relevant stakeholders ensures a comprehensive understanding of the incident, and sharing postmortems widely fosters transparency, enabling the organization to learn from incidents collectively.\n\nTogether, these practices contribute to a successful postmortem policy that promotes continuous improvement and a culture of learning from incidents."
      },
      {
        "date": "2023-12-03T01:59:00.000Z",
        "voteCount": 2,
        "content": "Vote CE"
      },
      {
        "date": "2023-11-27T14:49:00.000Z",
        "voteCount": 2,
        "content": "I'll go for C &amp; E"
      },
      {
        "date": "2023-11-15T11:51:00.000Z",
        "voteCount": 4,
        "content": "A. We don't blame\nB. I can't imagine a postmortem with information on how the incident could have been worse.\nC. Correct answer.\nD. It's nearly the same as C but doesn't include recommendations for the future, so I go with C.\nE. Correct, include all participants of the incident in authoring postmortem to not miss something important."
      },
      {
        "date": "2023-11-14T17:43:00.000Z",
        "voteCount": 3,
        "content": "I thing is CE \nhttps://sre.google/workbook/postmortem-culture/"
      },
      {
        "date": "2023-11-01T03:51:00.000Z",
        "voteCount": 3,
        "content": "Shouldn't mention customer information, it's not useful to spread it widely, might be causing negative impact."
      },
      {
        "date": "2023-10-28T05:41:00.000Z",
        "voteCount": 4,
        "content": "B &amp; D is the answer"
      },
      {
        "date": "2023-10-26T09:24:00.000Z",
        "voteCount": 1,
        "content": "I would go with B &amp; C"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 137,
    "url": "https://www.examtopics.com/discussions/google/view/124375-exam-professional-cloud-devops-engineer-topic-1-question-137/",
    "body": "You are developing reusable infrastructure as code modules. Each module contains integration tests that launch the module in a test project. You are using GitHub for source control. You need to continuously test your feature branch and ensure that all code is tested before changes are accepted. You need to implement a solution to automate the integration tests. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse a Jenkins server for CI/CD pipelines. Periodically run all tests in the feature branch.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAsk the pull request reviewers to run the integration tests before approving the code.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse Cloud Build to run the tests. Trigger all tests to run after a pull request is merged.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse Cloud Build to run tests in a specific folder. Trigger Cloud Build for every GitHub pull request.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 8,
        "isMostVoted": true
      },
      {
        "answer": "C",
        "count": 3,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2024-08-13T05:10:00.000Z",
        "voteCount": 1,
        "content": "D mentions folder. Huh?  I\u2019ll take C"
      },
      {
        "date": "2023-12-07T00:06:00.000Z",
        "voteCount": 1,
        "content": "Choose option D\nUse Cloud Build to run tests in a specific folder and trigger Cloud Build for every GitHub pull request.\n\nBy configuring Cloud Build to run tests in a specific folder, you can focus on the relevant tests for the modified code in the feature branch. Triggering Cloud Build for every GitHub pull request ensures that tests are automatically executed whenever changes are proposed, providing continuous integration.\n\nThis approach allows for automated testing of each pull request, providing early feedback to developers and ensuring that changes are thoroughly tested before being merged, contributing to a more reliable and efficient development process."
      },
      {
        "date": "2023-11-15T11:54:00.000Z",
        "voteCount": 2,
        "content": "D is what I do at work for this scenario and it works well."
      },
      {
        "date": "2023-11-12T02:30:00.000Z",
        "voteCount": 2,
        "content": "This approach automates the testing process, integrates well with your existing tools (GitHub and GCP), and ensures that code is tested in the most relevant part of the development lifecycle - before merging into the main branch."
      },
      {
        "date": "2023-11-01T04:00:00.000Z",
        "voteCount": 1,
        "content": "shouldn't be C since it makes the test to happen after merge. Answer is D - as soon as a PR gets created then it runs tests."
      },
      {
        "date": "2023-10-28T11:51:00.000Z",
        "voteCount": 2,
        "content": "all code is tested before changes are accepted"
      },
      {
        "date": "2023-10-26T09:27:00.000Z",
        "voteCount": 2,
        "content": "I would go with C"
      },
      {
        "date": "2023-10-23T12:01:00.000Z",
        "voteCount": 3,
        "content": "Wouldnt it be D considering you would want to run the tests when the PR is created and not after the code is already merged"
      },
      {
        "date": "2023-10-22T12:47:00.000Z",
        "voteCount": 2,
        "content": "Answer C is correct. \nhttps://cloud.google.com/build/docs/automating-builds/create-manage-triggers"
      },
      {
        "date": "2023-10-26T09:27:00.000Z",
        "voteCount": 1,
        "content": "Agreed"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 138,
    "url": "https://www.examtopics.com/discussions/google/view/124814-exam-professional-cloud-devops-engineer-topic-1-question-138/",
    "body": "Your company processes IoT data at scale by using Pub/Sub, App Engine standard environment, and an application written in Go. You noticed that the performance inconsistently degrades at peak load. You could not reproduce this issue on your workstation. You need to continuously monitor the application in production to identify slow paths in the code. You want to minimize performance impact and management overhead. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse Cloud Monitoring to assess the App Engine CPU utilization metric.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tInstall a continuous profiling tool into Compute Engine. Configure the application to send profiling data to the tool.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tPeriodically run the go tool pprof command against the application instance. Analyze the results by using flame graphs.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure Cloud Profiler, and initialize the cloud.google.com/go/profiler library in the application.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 6,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-10-28T05:57:00.000Z",
        "voteCount": 7,
        "content": "answer is D:\nhttps://cloud.google.com/profiler/docs/profiling-go#app-engine"
      },
      {
        "date": "2023-12-07T00:13:00.000Z",
        "voteCount": 2,
        "content": "Choose option D\n\nConfigure Cloud Profiler and initialize the cloud.google.com/go/profiler library in the application. Cloud Profiler is designed for low-overhead continuous profiling in production environments.\n\nBy configuring Cloud Profiler and initializing the corresponding library in the Go application, you can collect detailed performance data without significantly impacting the application's performance.\n\nThis approach allows you to analyze profiling information, identify slow paths in the code, and gain insights into performance bottlenecks, providing a powerful and efficient way to troubleshoot and optimize the application in a production environment."
      },
      {
        "date": "2023-11-12T02:32:00.000Z",
        "voteCount": 2,
        "content": "D is the answer."
      },
      {
        "date": "2023-11-01T04:09:00.000Z",
        "voteCount": 2,
        "content": "// appengine is an example of starting cloud.google.com/go/profiler on\n// App Engine.\npackage main\n\nimport (\n        \"cloud.google.com/go/profiler\"\n)"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 139,
    "url": "https://www.examtopics.com/discussions/google/view/124674-exam-professional-cloud-devops-engineer-topic-1-question-139/",
    "body": "Your company runs services by using Google Kubernetes Engine (GKE). The GKE dusters in the development environment run applications with verbose logging enabled. Developers view logs by using the kubectl logs command and do not use Cloud Logging. Applications do not have a uniform logging structure defined. You need to minimize the costs associated with application logging while still collecting GKE operational logs. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRun the gcloud container clusters update --logging=SYSTEM command for the development cluster.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRun the gcloud container clusters update --logging=WORKLOAD command for the development cluster.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tRun the gcloud logging sinks update _Default --disabled command in the project associated with the development environment.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAdd the severity &gt;= DEBUG resource.type = \"k8s_container\" exclusion filter to the _Default logging sink in the project associated with the development environment.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 7,
        "isMostVoted": true
      },
      {
        "answer": "A",
        "count": 2,
        "isMostVoted": false
      },
      {
        "answer": "B",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2024-06-17T10:25:00.000Z",
        "voteCount": 1,
        "content": "Not sure I agree with any answers. But I disagree the least with A. \n\nA) Would send all the logs, including memory, CPU, and other system information. This is too verbose.\n\nB) WORKLOAD logs should be sufficient I believe\n\nC) Not sure disabling _Default helps here\n\nD) An exclusion filter of \"severity &gt;= DEBUG...\" would literally exclude *all* logs?"
      },
      {
        "date": "2024-06-19T08:22:00.000Z",
        "voteCount": 1,
        "content": "I just realised I completely misunderstood the question. For some reason I had the notion in my head that the Developers were to migrate to Cloud Logging as well and that not only do we need to minimize cost, but also remove redundant logs (like system logs) in Cloud Logging.\n\nHowever, obviously, the only requirement is to minimize costs for cloud logging. The devs are already reading the logs directly using kubectl. As such we want to remove as much logging as possible from the _Default bucket. Therefore (D) is the correct answer!"
      },
      {
        "date": "2024-06-19T04:00:00.000Z",
        "voteCount": 1,
        "content": "I meant to say that I disagree the least with *B* as my selected answer"
      },
      {
        "date": "2024-03-17T08:40:00.000Z",
        "voteCount": 2,
        "content": "A is correct"
      },
      {
        "date": "2023-12-07T00:17:00.000Z",
        "voteCount": 1,
        "content": "To minimize costs associated with application logging in Google Kubernetes Engine (GKE) while still collecting operational logs, the recommended approach is (option D).\n\nAdd the severity &gt;= DEBUG resource.type = \"k8s_container\" exclusion filter to the _Default logging sink in the project associated with the development environment.\n\nThis filter excludes logs with a severity level of DEBUG or lower for the specified resource type, \"k8s_container,\" effectively reducing the volume of verbose application logs being ingested into Cloud Logging.\n\nThis allows you to focus on collecting GKE operational logs while excluding less critical and potentially costly application logs. It helps strike a balance between maintaining visibility into operational aspects and optimizing costs associated with log storage and processing."
      },
      {
        "date": "2024-04-30T01:29:00.000Z",
        "voteCount": 1,
        "content": "If the filter in the exclusion filter is for severity &gt;= DEBUG... would not exclude severity &gt;= DEBUG instead of severity &lt;= DEBUG?"
      },
      {
        "date": "2023-11-01T04:14:00.000Z",
        "voteCount": 2,
        "content": "D The idea is to prevent/minimize container logs from getting sent to the sink,"
      },
      {
        "date": "2023-11-01T04:20:00.000Z",
        "voteCount": 1,
        "content": "C is invalid since a valid gcloud CLI will be:  gcloud logging settings update --folder=FOLDER_ID--disable-default-sink\nhttps://cloud.google.com/logging/docs/default-settings#disable-default-sink"
      },
      {
        "date": "2023-10-26T09:35:00.000Z",
        "voteCount": 4,
        "content": "right answer"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 140,
    "url": "https://www.examtopics.com/discussions/google/view/124241-exam-professional-cloud-devops-engineer-topic-1-question-140/",
    "body": "You have deployed a fleet of Compute Engine instances in Google Cloud. You need to ensure that monitoring metrics and logs for the instances are visible in Cloud Logging and Cloud Monitoring by your company's operations and cyber security teams. You need to grant the required roles for the Compute Engine service account by using Identity and Access Management (IAM) while following the principle of least privilege. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tGrant the logging.logWriter and monitoring.metricWriter roles to the Compute Engine service accounts.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tGrant the logging.admin and monitoring.editor roles to the Compute Engine service accounts.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tGrant the logging.editor and monitoring.metricWriter roles to the Compute Engine service accounts.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tGrant the logging.logWriter and monitoring.editor roles to the Compute Engine service accounts."
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 7,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-12-07T00:22:00.000Z",
        "voteCount": 2,
        "content": "Choose option A\nGrant the logging.logWriter and monitoring.metricWriter roles to the Compute Engine service accounts.\n\nThese roles provide the necessary permissions for writing logs and metrics to Cloud Logging and Cloud Monitoring, respectively, without granting overly broad access. This aligns with the principle of least privilege, ensuring that the Compute Engine service accounts have the specific permissions needed for monitoring tasks without unnecessary additional privileges.\n\nThis approach enables effective visibility for both operations and cyber security teams while maintaining a secure and well-defined access model."
      },
      {
        "date": "2023-11-01T04:29:00.000Z",
        "voteCount": 1,
        "content": "Logs Writer (roles/logging.logWriter): Provides the permissions to write log entries.\n\nMonitoring Metric Writer (roles/monitoring.metricWriter): Provides write-only access to metrics. This provides exactly the permissions needed by the Cloud Monitoring agent and other systems that send metrics."
      },
      {
        "date": "2023-10-26T09:42:00.000Z",
        "voteCount": 4,
        "content": "Remove admin role from the options and there is no such role as logging.editor, so it is A"
      },
      {
        "date": "2023-10-21T11:04:00.000Z",
        "voteCount": 3,
        "content": "Answer A seems to be correct as the two \"writer\" roles are least privilege granted to the service account."
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 141,
    "url": "https://www.examtopics.com/discussions/google/view/124242-exam-professional-cloud-devops-engineer-topic-1-question-141/",
    "body": "You are the Site Reliability Engineer responsible for managing your company's data services and products. You regularly navigate operational challenges, such as unpredictable data volume and high cost, with your company's data ingestion processes. You recently learned that a new data ingestion product will be developed in Google Cloud. You need to collaborate with the product development team to provide operational input on the new product. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDeploy the prototype product in a test environment, run a load test, and share the results with the product development team.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tWhen the initial product version passes the quality assurance phase and compliance assessments, deploy the product to a staging environment. Share error logs and performance metrics with the product development team.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tWhen the new product is used by at least one internal customer in production, share error logs and monitoring metrics with the product development team.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tReview the design of the product with the product development team to provide feedback early in the design phase.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 6,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-02-15T23:27:00.000Z",
        "voteCount": 2,
        "content": "Engaging with the product development team early in the design phase allows you to provide valuable input based on your operational experience"
      },
      {
        "date": "2023-12-07T19:48:00.000Z",
        "voteCount": 2,
        "content": "To provide operational input on the new data ingestion product in Google Cloud, the recommended approach is (option D)\n\nReview the design of the product with the product development team to provide feedback early in the design phase. By engaging in the design phase, you can contribute valuable insights from an operational perspective, helping to identify potential challenges and considerations related to data volume, cost, and overall operability.\n\nThis early collaboration allows for proactive discussions on scalability, reliability, and cost-effectiveness, leading to a more robust and operationally sound product. Providing input during the design phase ensures that operational concerns are addressed from the outset, reducing the likelihood of issues during the development and deployment phases."
      },
      {
        "date": "2023-12-02T03:57:00.000Z",
        "voteCount": 1,
        "content": "Vote D"
      },
      {
        "date": "2023-11-01T14:39:00.000Z",
        "voteCount": 1,
        "content": "D: early collaboration is a good practice"
      },
      {
        "date": "2023-10-21T11:08:00.000Z",
        "voteCount": 1,
        "content": "Why Answer D?  Operations and product development teams collaborate early in the design phase."
      },
      {
        "date": "2023-10-21T11:07:00.000Z",
        "voteCount": 1,
        "content": "Answer D appears correct."
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 142,
    "url": "https://www.examtopics.com/discussions/google/view/124376-exam-professional-cloud-devops-engineer-topic-1-question-142/",
    "body": "You are investigating issues in your production application that runs on Google Kubernetes Engine (GKE). You determined that the source of the issue is a recently updated container image, although the exact change in code was not identified. The deployment is currently pointing to the latest tag. You need to update your cluster to run a version of the container that functions as intended. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a new tag called stable that points to the previously working container, and change the deployment to point to the new tag.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAlter the deployment to point to the sha256 digest of the previously working container.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tBuild a new container from a previous Git tag, and do a rolling update on the deployment to the new container.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tApply the latest tag to the previous container image, and do a rolling update on the deployment."
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 10,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-02-16T03:29:00.000Z",
        "voteCount": 1,
        "content": "https://cloud.google.com/kubernetes-engine/docs/concepts/about-container-images#disadvantages_of_image_tags\nBecause the code change is not known, it may be possible that the image was updated with same tag and now it's not working, so pointing using the tag won't solve the issue as it will always point to the latest digest sha256 (which is faulty). \nSo we must  point the deployment to the sha256 digest of the previously working container."
      },
      {
        "date": "2024-02-15T23:30:00.000Z",
        "voteCount": 1,
        "content": "Using the SHA256 digest ensures that you specifically deploy the exact version of the container that was previously working as intended, regardless of any changes made to the latest tag."
      },
      {
        "date": "2023-12-07T19:52:00.000Z",
        "voteCount": 1,
        "content": "To update your Google Kubernetes Engine (GKE) cluster to run a version of the container that functions as intended, despite the unknown change in the latest container image, the recommended approach is (option B).\n\nAlter the deployment to point to the sha256 digest of the previously working container. Using the sha256 digest provides a precise and immutable reference to a specific version of the container image, ensuring that the exact image that was known to work is deployed. This approach eliminates any ambiguity associated with using tags like \"latest\" and provides a reliable way to rollback to a known-good state.\n\nBy referencing the sha256 digest, you maintain control over the version of the container image deployed in the cluster and can effectively address issues arising from unanticipated changes in the latest tag."
      },
      {
        "date": "2023-12-02T03:57:00.000Z",
        "voteCount": 1,
        "content": "Vote B"
      },
      {
        "date": "2023-11-01T16:20:00.000Z",
        "voteCount": 3,
        "content": "This question looks to tease out the knowledge of tag vs digest while deploying containers. The best approach is to figure out the previously functional digest and apply to deployment. Tag is mutable, using a tag like latest in deployment is confusing and prone to cause deployment inconsistency.\nhttps://cloud.google.com/kubernetes-engine/docs/concepts/about-container-images"
      },
      {
        "date": "2023-10-28T11:57:00.000Z",
        "voteCount": 3,
        "content": "https://cloud.google.com/kubernetes-engine/docs/concepts/about-container-images"
      },
      {
        "date": "2023-10-22T13:03:00.000Z",
        "voteCount": 1,
        "content": "Answer D seems correct.\nhttps://cloud.google.com/kubernetes-engine/docs/how-to/updating-apps"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 143,
    "url": "https://www.examtopics.com/discussions/google/view/124243-exam-professional-cloud-devops-engineer-topic-1-question-143/",
    "body": "You need to create a Cloud Monitoring SLO for a service that will be published soon. You want to verify that requests to the service will be addressed in fewer than 300 ms at least 90% of the time per calendar month. You need to identify the metric and evaluation method to use. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSelect a latency metric for a request-based method of evaluation.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSelect a latency metric for a window-based method of evaluation.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSelect an availability metric for a request-based method of evaluation.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSelect an availability metric for a window-based method of evaluation."
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 15,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-10-21T11:13:00.000Z",
        "voteCount": 9,
        "content": "Answer B seems to be correct for latency and windows-based.\n\"service will be addressed in fewer than 300 ms at least 90% of the time per calendar month. \""
      },
      {
        "date": "2023-11-01T17:16:00.000Z",
        "voteCount": 6,
        "content": "it asks to be fewer than 300ms hence it excludes C and D which are availability metrics. Then it cares about the percentage of requests(90%) but never mentioned windows requirements hence A. Actually mentioning calendar in the question is a trick, it misled you to think about a time range, but both request-metrics and windows-metrics would require a setting of compliance periods, this could be either calendar or rolling-windows\nhttps://cloud.google.com/stackdriver/docs/solutions/slo-monitoring#compliance-period"
      },
      {
        "date": "2024-02-16T03:59:00.000Z",
        "voteCount": 1,
        "content": "https://cloud.google.com/stackdriver/docs/solutions/slo-monitoring#slo-type-request"
      },
      {
        "date": "2024-02-15T23:36:00.000Z",
        "voteCount": 1,
        "content": "The request-based method of evaluation will calculate the percentage of requests that meet the latency threshold of 300 ms over the entire calendar month."
      },
      {
        "date": "2023-12-07T19:55:00.000Z",
        "voteCount": 2,
        "content": "To create a Cloud Monitoring Service Level Objective (SLO) for a service with the requirement of ensuring that requests are addressed in fewer than 300 ms at least 90% of the time per calendar month, the recommended approach is (option A).\n\nSelect a latency metric for a request-based method of evaluation. Latency metrics, which measure the time it takes for requests to be processed, are appropriate for evaluating the specific performance requirements outlined in the scenario. By selecting a latency metric for a request-based method, such as P95 (percentile 95), you can precisely measure and evaluate the desired performance level\u2014requests being addressed in fewer than 300 ms at least 90% of the time.\n\nThis approach aligns with the specific performance criteria and allows for a granular assessment of the service's responsiveness."
      },
      {
        "date": "2023-12-02T03:58:00.000Z",
        "voteCount": 1,
        "content": "Vote A"
      },
      {
        "date": "2023-10-31T14:27:00.000Z",
        "voteCount": 4,
        "content": "I think A is correct answer.\nWindow-based metrics evaluate the percentage of time the condition is met.\nhttps://cloud.google.com/stackdriver/docs/solutions/slo-monitoring#slo-types"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 144,
    "url": "https://www.examtopics.com/discussions/google/view/124688-exam-professional-cloud-devops-engineer-topic-1-question-144/",
    "body": "You have an application that runs on Cloud Run. You want to use live production traffic to test a new version of the application, while you let the quality assurance team perform manual testing. You want to limit the potential impact of any issues while testing the new version, and you must be able to roll back to a previous version of the application if needed. How should you deploy the new version? (Choose two.)",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDeploy the application as a new Cloud Run service.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDeploy a new Cloud Run revision with a tag and use the --no-traffic option.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDeploy a new Cloud Run revision without a tag and use the --no-traffic option.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDeploy the new application version and use the --no-traffic option. Route production traffic to the revision\u2019s URL.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDeploy the new application version, and split traffic to the new version."
    ],
    "answer": "BD",
    "answerDescription": "",
    "votes": [
      {
        "answer": "BD",
        "count": 8,
        "isMostVoted": true
      },
      {
        "answer": "AE",
        "count": 3,
        "isMostVoted": false
      },
      {
        "answer": "B",
        "count": 3,
        "isMostVoted": false
      },
      {
        "answer": "BE",
        "count": 1,
        "isMostVoted": false
      },
      {
        "answer": "C",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2023-11-01T20:30:00.000Z",
        "voteCount": 5,
        "content": "A&amp;E seem correct for using live production traffic.  The question states \"You want to use live production traffic to test a new version of the application,\""
      },
      {
        "date": "2023-12-24T03:45:00.000Z",
        "voteCount": 1,
        "content": "A-&gt; You don't need a new service, you need a new version of the service. I think ans A is a wrong option\nB &amp; D for me the correct"
      },
      {
        "date": "2024-08-13T06:53:00.000Z",
        "voteCount": 1,
        "content": "Definitely E for prod traffic. And B for developer only end."
      },
      {
        "date": "2024-02-16T04:05:00.000Z",
        "voteCount": 1,
        "content": "B: https://cloud.google.com/run/docs/rollouts-rollbacks-traffic-migration#deploy-with-tags\n\nD: https://cloud.google.com/run/docs/rollouts-rollbacks-traffic-migration#console_1:~:text=In%20the%20form%3A-,Set%20it%20to%20the%20desired%20percentage%2C%20for%20example%2C%205.%20Note%20that%20the%20currently%20serving%20version%27s%20percentage%20is%20automatically%20reduced%20by%20that%20same%20amount.,-Click%20Save."
      },
      {
        "date": "2023-12-07T22:19:00.000Z",
        "voteCount": 3,
        "content": "Looks like just only (option B) is the most reasonable.\n\nBut after thinking harder on this question, maybe choosing (option B &amp; D) its okey to involves deploying the new version of the application on Cloud Run by creating a new revision with a tag and using the --no-traffic option. This approach allows the isolation of the new revision from live production traffic initially. \n\nOnce the deployment is complete, extensive testing can be conducted without affecting users. Subsequently, when confident in the new version's stability, production traffic can be gradually directed to it using the Cloud Run services update-traffic command.\n\nThis combination ensures a controlled and risk-mitigated approach to deploying and testing new versions, with the ability to roll back if any issues arise during the testing phase."
      },
      {
        "date": "2023-12-02T04:05:00.000Z",
        "voteCount": 1,
        "content": "Vote BD"
      },
      {
        "date": "2023-11-26T12:30:00.000Z",
        "voteCount": 1,
        "content": "I would go for BD\nOption E does not right as it talks about split the live traffic"
      },
      {
        "date": "2023-11-24T03:05:00.000Z",
        "voteCount": 2,
        "content": "I would go for BD"
      },
      {
        "date": "2023-11-15T05:01:00.000Z",
        "voteCount": 3,
        "content": "keyword: You want to use live production traffic"
      },
      {
        "date": "2023-11-01T19:13:00.000Z",
        "voteCount": 3,
        "content": "https://cloud.google.com/run/docs/rollouts-rollbacks-traffic-migration#tags\nB is correct which targets to utilise the cloud run tag feature without serving traffic first, the idea is once tested adequately, then migrate traffic to the tagged revision. But not sure what is another answer given it is multi-choice, none of them apart from B looks reasonable."
      },
      {
        "date": "2023-10-26T19:59:00.000Z",
        "voteCount": 1,
        "content": "C should definitely be one of the options\nhttps://cloud.google.com/run/docs/rollouts-rollbacks-traffic-migration"
      },
      {
        "date": "2023-10-26T19:59:00.000Z",
        "voteCount": 1,
        "content": "disregard this. I meant B\nhttps://cloud.google.com/run/docs/rollouts-rollbacks-traffic-migration"
      },
      {
        "date": "2023-11-01T07:42:00.000Z",
        "voteCount": 1,
        "content": "But idk, it says that he wants to serve live traffic to this new version..why --no-traffic?"
      },
      {
        "date": "2023-11-24T03:05:00.000Z",
        "voteCount": 2,
        "content": "It receives no traffic after you deploy it but it let's you route traffic to it after that if you want to"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 145,
    "url": "https://www.examtopics.com/discussions/google/view/124244-exam-professional-cloud-devops-engineer-topic-1-question-145/",
    "body": "You recently noticed that one of your services has exceeded the error budget for the current rolling window period. Your company's product team is about to launch a new feature. You want to follow Site Reliability Engineering (SRE) practices. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tNotify the team about the lack of error budget and ensure that all their tests are successful so the launch will not further risk the error budget",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tNotify the team that their error budget is used up. Negotiate with the team for a launch freeze or tolerate a slightly worse user experience.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEscalate the situation and request additional error budget.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tLook through other metrics related to the product and find SLOs with remaining error budget. Reallocate the error budgets and allow the feature launch."
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 10,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-02-16T04:08:00.000Z",
        "voteCount": 1,
        "content": "If the service has exceeded its error budget for the preceding four-week window, we will halt all changes and releases other than P01 issues or security fixes until the service is back within its SLO.\nhttps://sre.google/workbook/error-budget-policy/#:~:text=If%20the%20service%20has,exceed%20the%20error%20budget.."
      },
      {
        "date": "2024-02-16T04:09:00.000Z",
        "voteCount": 1,
        "content": "https://sre.google/workbook/error-budget-policy/#:~:text=If%20the%20service%20has,exceed%20the%20error%20budget."
      },
      {
        "date": "2023-12-07T22:32:00.000Z",
        "voteCount": 1,
        "content": "Choosing (option B) aligns with Site Reliability Engineering (SRE) principles, emphasizing the importance of maintaining system reliability and availability.\n\nBy notifying the team that the error budget has been exhausted, the SRE team is proactively communicating the potential risks associated with launching the new feature during a period of heightened error rates.\n\nThe suggestion to negotiate for a launch freeze or tolerate a slightly degraded user experience demonstrates a commitment to preserving the system's reliability and ensuring that user impact is minimized.\n\nThis approach fosters a collaborative effort between the SRE team and the product team, allowing for informed decision-making that prioritizes reliability over feature deployment when necessary, adhering to the core tenets of SRE practices."
      },
      {
        "date": "2023-12-02T04:09:00.000Z",
        "voteCount": 1,
        "content": "Vote B"
      },
      {
        "date": "2023-11-05T01:41:00.000Z",
        "voteCount": 2,
        "content": "This is SRE-friendly approach."
      },
      {
        "date": "2023-11-01T19:32:00.000Z",
        "voteCount": 3,
        "content": "Only B seems to make a bit sense although I don't like the idea to tolerate a worse user experience."
      },
      {
        "date": "2023-10-28T12:04:00.000Z",
        "voteCount": 2,
        "content": "Negotiate with the team for a launch freeze or tolerate a slightly worse user experience."
      },
      {
        "date": "2023-10-21T11:19:00.000Z",
        "voteCount": 2,
        "content": "Answer C seems to be correct per Google docs:\nhttps://sre.google/workbook/error-budget-policy/"
      },
      {
        "date": "2023-10-27T02:10:00.000Z",
        "voteCount": 4,
        "content": "The link you have shared also tells about pausing the workload and nowhere says ask for error budget. I will go with B"
      },
      {
        "date": "2023-12-24T03:53:00.000Z",
        "voteCount": 1,
        "content": "If you look on link https://cloud.google.com/blog/products/management-tools/sre-error-budgets-and-maintenance-windowsfor silver bullets, there is an option to deploy when you have burnt the error budget. But it has to be scalated to ownerships. Then I think ans C is correct. You get extra error budget with the silver bullets. In B, you assume you can andthe Developer team negotiate a worse experience user, but it has to be negotiate to ownerships no between the developer team"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 146,
    "url": "https://www.examtopics.com/discussions/google/view/124245-exam-professional-cloud-devops-engineer-topic-1-question-146/",
    "body": "You need to introduce postmortems into your organization. You want to ensure that the postmortem process is well received. What should you do? (Choose two.)",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEncourage new employees to conduct postmortems to team through practice.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a designated team that is responsible for conducting all postmortems.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEncourage your senior leadership to acknowledge and participate in postmortems.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEnsure that writing effective postmortems is a rewarded and celebrated practice.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tProvide your organization with a forum to critique previous postmortems."
    ],
    "answer": "CD",
    "answerDescription": "",
    "votes": [
      {
        "answer": "CD",
        "count": 7,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-05-04T00:50:00.000Z",
        "voteCount": 1,
        "content": "C. Encourage your senior leadership to acknowledge and participate in postmortems: This option is correct because when senior leadership acknowledges and participates in postmortems, it shows that they value the process and are committed to learning from mistakes. This can help in creating a culture where postmortems are well received and taken seriously by the organization.\n\nD. Ensure that writing effective postmortems is a rewarded and celebrated practice: This option is also correct because when effective postmortems are rewarded and celebrated, it creates a positive incentive for employees to invest time and effort in conducting thorough postmortems. It helps in reinforcing the importance of the process and encourages others to follow suit."
      },
      {
        "date": "2024-02-16T04:23:00.000Z",
        "voteCount": 2,
        "content": "https://sre.google/sre-book/postmortem-culture/#:~:text=Make%20sure%20that,value%20of%20postmortems!"
      },
      {
        "date": "2023-12-07T23:01:00.000Z",
        "voteCount": 1,
        "content": "Choosing options C and D is a strategic approach to introducing and fostering a positive postmortem culture within an organization.\n\n- In option C, encouraging senior leadership to acknowledge and participate in postmortems sets a precedent for the importance of the process throughout the organization. It signals that the postmortem process is not solely about assigning blame but is a collaborative effort to learn and improve.\n\n- In option D, rewarding and celebrating the practice of writing effective postmortems further reinforces a positive culture around the process. Recognition for those who contribute to the postmortem process encourages transparency, learning, and continuous improvement, fostering an environment where individuals feel empowered to share insights and experiences without fear of punitive measures."
      },
      {
        "date": "2023-12-02T04:12:00.000Z",
        "voteCount": 1,
        "content": "Vote CD"
      },
      {
        "date": "2023-11-05T01:31:00.000Z",
        "voteCount": 2,
        "content": "Should be C &amp; D."
      },
      {
        "date": "2023-11-14T20:18:00.000Z",
        "voteCount": 1,
        "content": "I think is CD \nhttps://sre.google/sre-book/postmortem-culture/"
      },
      {
        "date": "2023-10-28T06:39:00.000Z",
        "voteCount": 3,
        "content": "C &amp; D are the answer.\nhttps://cloud.google.com/blog/products/devops-sre/how-lowes-improved-incident-response-processes-with-sre"
      },
      {
        "date": "2023-10-21T11:23:00.000Z",
        "voteCount": 2,
        "content": "Answers C, D seem correct.\nhttps://sre.google/sre-book/postmortem-culture/"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 147,
    "url": "https://www.examtopics.com/discussions/google/view/124246-exam-professional-cloud-devops-engineer-topic-1-question-147/",
    "body": "You need to enforce several constraint templates across your Google Kubernetes Engine (GKE) clusters. The constraints include policy parameters, such as restricting the Kubernetes API. You must ensure that the policy parameters are stored in a GitHub repository and automatically applied when changes occur. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tSet up a GitHub action to trigger Cloud Build when there is a parameter change. In Cloud Build, run a gcloud CLI command to apply the change.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tWhen there is a change in GitHub. use a web hook to send a request to Anthos Service Mesh, and apply the change.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure Anthos Config Management with the GitHub repository. When there is a change in the repository, use Anthos Config Management to apply the change.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure Config Connector with the GitHub repository. When there is a change in the repository, use Config Connector to apply the change."
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 5,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-12-07T23:16:00.000Z",
        "voteCount": 1,
        "content": "Choosing option C\n\nConfiguring Anthos Config Management with the GitHub repository, is the recommended approach for enforcing constraint templates across Google Kubernetes Engine (GKE) clusters.\n\nAnthos Config Management allows you to declaratively manage configurations using Kubernetes-style manifests, making it well-suited for policy enforcement in a Kubernetes environment. By configuring Anthos Config Management with the GitHub repository, any changes made to the policy parameters, stored in the repository, can be automatically applied to the GKE clusters.\n\nThis ensures consistency and compliance across clusters and streamlines the process of managing and enforcing policy changes in a Kubernetes environment. The integration with GitHub provides version control and auditability for the changes made to the policy parameters."
      },
      {
        "date": "2023-12-02T04:19:00.000Z",
        "voteCount": 1,
        "content": "Vote C"
      },
      {
        "date": "2023-11-05T01:30:00.000Z",
        "voteCount": 1,
        "content": "Anthos for consistently enforce security and compliance policies across your fleet."
      },
      {
        "date": "2023-11-01T19:39:00.000Z",
        "voteCount": 2,
        "content": "C is the answe: using policy-controller to govern the policies.\nhttps://cloud.google.com/anthos-config-management/docs/concepts/policy-controller"
      },
      {
        "date": "2023-10-21T11:28:00.000Z",
        "voteCount": 2,
        "content": "Answer C seems to be correct.\nhttps://medium.com/@kasiarun/introduction-to-anthos-config-management-1a43917c26ae"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 148,
    "url": "https://www.examtopics.com/discussions/google/view/124377-exam-professional-cloud-devops-engineer-topic-1-question-148/",
    "body": "You are the Operations Lead for an ongoing incident with one of your services. The service usually runs at around 70% capacity. You notice that one node is returning 5xx errors for all requests. There has also been a noticeable increase in support cases from customers. You need to remove the offending node from the load balancer pool so that you can isolate and investigate the node. You want to follow Google-recommended practices to manage the incident and reduce the impact on users. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t1. Communicate your intent to the incident team.<br>2. Perform a load analysis to determine if the remaining nodes can handle the increase in traffic offloaded from the removed node, and scale appropriately.<br>3. When any new nodes report healthy, drain traffic from the unhealthy node, and remove the unhealthy node from service.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t1. Communicate your intent to the incident team.<br>2. Add a new node to the pool, and wait for the new node to report as healthy.<br>3. When traffic is being served on the new node, drain traffic from the unhealthy node, and remove the old node from service.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t1. Drain traffic from the unhealthy node and remove the node from service.<br>2. Monitor traffic to ensure that the error is resolved and that the other nodes in the pool are handling the traffic appropriately.<br>3. Scale the pool as necessary to handle the new load.<br>4. Communicate your actions to the incident team.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t1. Drain traffic from the unhealthy node and remove the old node from service.<br>2. Add a new node to the pool, wait for the new node to report as healthy, and then serve traffic to the new node.<br>3. Monitor traffic to ensure that the pool is healthy and is handling traffic appropriately.<br>4. Communicate your actions to the incident team."
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 7,
        "isMostVoted": true
      },
      {
        "answer": "D",
        "count": 2,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2023-10-22T13:12:00.000Z",
        "voteCount": 6,
        "content": "Answer A seems to be correct."
      },
      {
        "date": "2024-02-07T14:02:00.000Z",
        "voteCount": 1,
        "content": "C Ref: https://sre.google/sre-book/effective-troubleshooting/"
      },
      {
        "date": "2023-12-07T23:27:00.000Z",
        "voteCount": 1,
        "content": "Choosing option A.\n\nFirst, communicating your intent to the incident team ensures transparency and collaboration. Performing a load analysis is crucial to determine if the remaining nodes can handle the increased traffic after offloading from the unhealthy node. Scaling appropriately is essential to maintain the overall capacity. Once new nodes report as healthy, draining traffic from the unhealthy node ensures a gradual transition without disrupting user experience. Removing the unhealthy node from service comes after ensuring that the other nodes can handle the load effectively.\n\nThis step-by-step approach, coupled with communication and load analysis, aligns with Google-recommended practices for incident response and minimizes the impact on users during the investigation and resolution process."
      },
      {
        "date": "2023-12-02T04:22:00.000Z",
        "voteCount": 2,
        "content": "Vote A"
      },
      {
        "date": "2023-11-11T14:35:00.000Z",
        "voteCount": 2,
        "content": "Option A and option B do not add a new node to the pool to handle the increased load, which may leave the remaining nodes overburdened and unable to handle the traffic adequately.\n\nOption C starts with draining traffic from the unhealthy node, which is a good step, but it doesn't immediately add a new node to the pool to handle the load. It also lacks the step of explicitly communicating the actions to the incident team."
      },
      {
        "date": "2023-11-15T14:10:00.000Z",
        "voteCount": 3,
        "content": "The second point in answer A is about scaling. A is correct. You can easily eliminate C and D because information to the incident team should be the first thing to do.\n\"2. Perform a load analysis to determine if the remaining nodes can handle the increase in traffic offloaded from the removed node, and scale appropriately.\""
      },
      {
        "date": "2023-11-01T19:44:00.000Z",
        "voteCount": 4,
        "content": "The service usually run 70% of the capacity, hence even one node is out of order you'd always want to see if the rest of the computing resource are enough to support the stress before arbitrarily adding any new nodes."
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 149,
    "url": "https://www.examtopics.com/discussions/google/view/124849-exam-professional-cloud-devops-engineer-topic-1-question-149/",
    "body": "You are configuring your CI/CD pipeline natively on Google Cloud. You want builds in a pre-production Google Kubernetes Engine (GKE) environment to be automatically load-tested before being promoted to the production GKE environment. You need to ensure that only builds that have passed this test are deployed to production. You want to follow Google-recommended practices. How should you configure this pipeline with Binary Authorization?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate an attestation for the builds that pass the load test by requiring the lead quality assurance engineer to sign the attestation by using their personal private key.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate an attestation for the builds that pass the load test by using a private key stored in Cloud Key Management Service (Cloud KMS) with a service account JSON key stored as a Kubernetes Secret.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate an attestation for the builds that pass the load test by using a private key stored in Cloud Key Management Service (Cloud KMS) authenticated through Workload Identity.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate an attestation for the builds that pass the load test by requiring the lead quality assurance engineer to sign the attestation by using a key stored in Cloud Key Management Service (Cloud KMS)."
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 10,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-12-07T23:44:00.000Z",
        "voteCount": 2,
        "content": "Vote (option C).\n\nThis option involves creating an attestation for the builds that pass the load test using a private key stored in Cloud Key Management Service (Cloud KMS) authenticated through Workload Identity.\n\nWorkload Identity allows you to securely authenticate to Google Cloud services from your GKE clusters without the need for storing and managing service account keys.\n\nBy using Cloud KMS for key storage and Workload Identity for authentication, you enhance the security of your pipeline.\n\nThis approach aligns with Google's best practices for managing cryptographic keys and ensures a more secure and manageable setup for attesting builds before deployment to the production GKE environment."
      },
      {
        "date": "2023-12-02T04:28:00.000Z",
        "voteCount": 1,
        "content": "Vote C"
      },
      {
        "date": "2023-11-05T01:20:00.000Z",
        "voteCount": 2,
        "content": "Workload Identity allows workloads in your GKE clusters to impersonate Identity and Access Management (IAM) service accounts to access Google Cloud services.\nhttps://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity"
      },
      {
        "date": "2023-11-01T19:50:00.000Z",
        "voteCount": 2,
        "content": "\"you're configuring your CI/CD pipeline natively on Google Cloud\", natively hints to use workload identity which is similar to ec2 instance profile."
      },
      {
        "date": "2023-10-28T12:11:00.000Z",
        "voteCount": 3,
        "content": "Workload Identity\nhttps://cloud.google.com/iam/docs/best-practices-for-using-workload-identity-federation"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 150,
    "url": "https://www.examtopics.com/discussions/google/view/124745-exam-professional-cloud-devops-engineer-topic-1-question-150/",
    "body": "You are deploying an application to Cloud Run. The application requires a password to start. Your organization requires that all passwords are rotated every 24 hours, and your application must have the latest password. You need to deploy the application with no downtime. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tStore the password in Secret Manager and send the secret to the application by using environment variables.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tStore the password in Secret Manager and mount the secret as a volume within the application.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse Cloud Build to add your password into the application container at build time. Ensure that Artifact Registry is secured from public access.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tStore the password directly in the code. Use Cloud Build to rebuild and deploy the application each time the password changes."
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 17,
        "isMostVoted": true
      },
      {
        "answer": "A",
        "count": 2,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2023-11-01T19:54:00.000Z",
        "voteCount": 10,
        "content": "Answer is B:  https://cloud.google.com/run/docs/configuring/services/secrets\n\"Mount each secret as a volume, which makes the secret available to the container as files. Reading a volume always fetches the secret value from Secret Manager, so it can be used with the latest version. This method also works well with secret rotation.\""
      },
      {
        "date": "2023-12-07T23:52:00.000Z",
        "voteCount": 1,
        "content": "(Option B) \n\nBy storing the password in Secret Manager and mounting the secret as a volume within the application, you can achieve password rotation without causing downtime. This allows you to update the password in Secret Manager, and Cloud Run can dynamically mount the latest version of the secret without requiring a redeployment of the application. \n\nThis approach ensures that the application always has access to the latest password without interrupting its availability, providing a seamless and secure way to manage password rotation in a Cloud Run environment. Storing sensitive information like passwords in Secret Manager enhances security and separation of concerns."
      },
      {
        "date": "2023-11-15T07:24:00.000Z",
        "voteCount": 2,
        "content": "I think is B for this \n\"Mount each secret as a volume, which makes the secret available to the container as files. Reading a volume always fetches the secret value from Secret Manager, so it can be used with the latest version. This method also works well with secret rotation.\nPass a secret using environment variables. Environment variables are resolved at instance startup time, so if you use this method, Google recommends that you pin the secret to a particular version rather than using latest.\"\n\nhttps://cloud.google.com/run/docs/configuring/services/secrets"
      },
      {
        "date": "2023-11-04T15:53:00.000Z",
        "voteCount": 3,
        "content": "You can make a secret available to your containers in either of two ways:\n\nMount each secret as a volume, which makes the secret available to the container as files. Reading a volume always fetches the secret value from Secret Manager, so it can be used with the latest version. This method also works well with secret rotation.\nPass a secret using environment variables. Environment variables are resolved at instance startup time, so if you use this method, Google recommends that you pin the secret to a particular version rather than using latest.\nhttps://cloud.google.com/run/docs/configuring/services/secrets"
      },
      {
        "date": "2023-10-29T03:02:00.000Z",
        "voteCount": 1,
        "content": "answer is A:\nIf you are exposing the secret as an environment variable:\nSupply the Name of the variable and select the secret version, or latest to always use the current secret version."
      },
      {
        "date": "2023-10-28T00:37:00.000Z",
        "voteCount": 2,
        "content": "Answer is A\n\nThe best solution is to store the password in Secret Manager and send the secret to the application by using environment variables. This will allow you to rotate the password without having to rebuild and deploy the application each time."
      },
      {
        "date": "2023-10-27T13:13:00.000Z",
        "voteCount": 3,
        "content": "Answer is B\nhttps://cloud.google.com/run/docs/configuring/services/secrets"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 151,
    "url": "https://www.examtopics.com/discussions/google/view/124264-exam-professional-cloud-devops-engineer-topic-1-question-151/",
    "body": "Your company runs applications in Google Kubernetes Engine (GKE) that are deployed following a GitOps methodology. Application developers frequently create cloud resources to support their applications. You want to give developers the ability to manage infrastructure as code, while ensuring that you follow Google-recommended practices. You need to ensure that infrastructure as code reconciles periodically to avoid configuration drift. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tInstall and configure Config Connector in Google Kubernetes Engine (GKE).\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure Cloud Build with a Terraform builder to execute terraform plan and terraform apply commands.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a Pod resource with a Terraform docker image to execute terraform plan and terraform apply commands.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a Job resource with a Terraform docker image to execute terraform plan and terraform apply commands."
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 9,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-08-13T07:25:00.000Z",
        "voteCount": 1,
        "content": "B. So they can only create with pipeline."
      },
      {
        "date": "2024-02-16T00:22:00.000Z",
        "voteCount": 2,
        "content": "Config Connector allows you to manage Google Cloud resources through Kubernetes-style declarative configuration. By installing and configuring Config Connector in GKE, you can define and manage cloud resources using Kubernetes manifests, ensuring that infrastructure configurations are reconciled periodically to avoid configuration drift"
      },
      {
        "date": "2023-12-08T00:00:00.000Z",
        "voteCount": 2,
        "content": "Option A is the recommended approach for managing infrastructure as code and avoiding configuration drift in a Google Kubernetes Engine (GKE) environment while following Google-recommended practices.\n\nConfig Connector is a Kubernetes extension that allows you to manage Google Cloud resources as Kubernetes objects. By installing and configuring Config Connector in GKE, you can declare your cloud resources as Kubernetes CustomResourceDefinitions (CRDs) and have them managed by Kubernetes controllers.\n\nThis ensures that the desired state of your infrastructure is continuously reconciled with the actual state, helping to prevent configuration drift. Config Connector aligns with the GitOps methodology, providing a declarative way to manage cloud resources and maintain consistency in your environment."
      },
      {
        "date": "2023-11-04T15:49:00.000Z",
        "voteCount": 3,
        "content": "Config Connector's controllers eventually reconcile your environment with your desired state.\nhttps://cloud.google.com/config-connector/docs/overview"
      },
      {
        "date": "2023-11-01T20:43:00.000Z",
        "voteCount": 2,
        "content": "Why not A?  https://cloud.google.com/blog/products/containers-kubernetes/anthos-config-management-config-controller-available-on-gke\nConfig controller leverages config connector, config controller includes config-synct/gcp-cloud-resource-creation/policy-sync, it 'gitops', 'reconcile', 'taking-care-of-gcp-cloud-resource'"
      },
      {
        "date": "2023-11-01T20:48:00.000Z",
        "voteCount": 1,
        "content": "plus 'Google-recommended practices'"
      },
      {
        "date": "2023-10-25T09:34:00.000Z",
        "voteCount": 1,
        "content": "I also vote for B"
      },
      {
        "date": "2023-10-21T15:03:00.000Z",
        "voteCount": 2,
        "content": "I think the answer B is correct."
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 152,
    "url": "https://www.examtopics.com/discussions/google/view/125154-exam-professional-cloud-devops-engineer-topic-1-question-152/",
    "body": "You are designing a system with three different environments: development, quality assurance (QA), and production. Each environment will be deployed with Terraform and has a Google Kubernetes Engine (GKE) cluster created so that application teams can deploy their applications. Anthos Config Management will be used and templated to deploy infrastructure level resources in each GKE cluster. All users (for example, infrastructure operators and application owners) will use GitOps. How should you structure your source control repositories for both Infrastructure as Code (IaC) and application code?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\u2022 Cloud Infrastructure (Terraform) repository is shared: different directories are different environments<br>\u2022 GKE Infrastructure (Anthos Config Management Kustomize manifests) repository is shared: different overlay directories are different environments<br>\u2022 Application (app source code) repositories are separated: different branches are different features\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\u2022 Cloud Infrastructure (Terraform) repository is shared: different directories are different environments<br>\u2022 GKE Infrastructure (Anthos Config Management Kustomize manifests) repositories are separated: different branches are different environments<br>\u2022 Application (app source code) repositories are separated: different branches are different features",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\u2022 Cloud Infrastructure (Terraform) repository is shared: different branches are different environments<br>\u2022 GKE Infrastructure (Anthos Config Management Kustomize manifests) repository is shared: different overlay directories are different environments<br>\u2022 Application (app source code) repository is shared: different directories are different features",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\u2022 Cloud Infrastructure (Terraform) repositories are separated: different branches are different environments<br>\u2022 GKE Infrastructure (Anthos Config Management Kustomize manifests) repositories are separated: different overlay directories are different environments<br>\u2022 Application (app source code) repositories are separated: different branches are different"
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 10,
        "isMostVoted": true
      },
      {
        "answer": "B",
        "count": 5,
        "isMostVoted": false
      },
      {
        "answer": "C",
        "count": 2,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2024-02-16T05:20:00.000Z",
        "voteCount": 2,
        "content": "Why?\n\"Cloud Infrastructure (Terraform) repository is shared: different directories are different environments\"\n\nFor GitOps, Google recommends: Use folders for variants of the configuration instead of branches. With folders, you can use the tree command to see variants. For example, with branches, you can't tell if the delta between a prod and stage branch is an upcoming change in configuration or a permanent difference between what stage and prod should look like.\nhttps://cloud.google.com/anthos-config-management/docs/concepts/gitops-best-practices#use-folders\n\n\n\"GKE Infrastructure (Anthos Config Management Kustomize manifests) repository is shared: different overlay directories are different environments\"\nhttps://cloud.google.com/anthos-config-management/docs/tutorials/multiple-environments-config-sync#repository_architecture"
      },
      {
        "date": "2023-12-28T18:58:00.000Z",
        "voteCount": 2,
        "content": "this is the logial folder structure when dealing with multiple environments of tf, gke\ncreating folders for separate environments, creating branches for releases"
      },
      {
        "date": "2023-12-28T01:47:00.000Z",
        "voteCount": 1,
        "content": "The best structure for source control repositories in this scenario is Option B. It keeps the Cloud Infrastructure (Terraform) in a shared repository with different directories for different environments, separates GKE Infrastructure repositories by environments using different branches, and keeps Application code repositories separated with different branches for different features."
      },
      {
        "date": "2023-12-28T18:55:00.000Z",
        "voteCount": 1,
        "content": "for GKE we create the specific overlay folder for separate environments not branches"
      },
      {
        "date": "2023-12-19T22:08:00.000Z",
        "voteCount": 2,
        "content": "https://cloud.google.com/anthos-config-management/docs/concepts/gitops-best-practices#use-folders"
      },
      {
        "date": "2023-12-13T14:57:00.000Z",
        "voteCount": 1,
        "content": "I agree with @YushiSato, Terraform and Kustomize would be best practice to represent environments by a directory.\n\nhttps://cloud.google.com/anthos-config-management/docs/tutorials/multiple-environments-config-sync#repository_architecture"
      },
      {
        "date": "2023-12-08T00:12:00.000Z",
        "voteCount": 1,
        "content": "Choose B\n\nCloud Infrastructure (Terraform) repository is shared:\nAllows you to manage the IaC for different env same repo, with different directories representing different env. This makes it easy to maintain and update common IaC across env.\n\nGKE Infrastructure (Anthos Config Management Kustomize manifests) repositories are separated:\nEach env GKE configuration is kept in a separate repo, using different branches for different env. This separation ensures that the GKE configurations for different env are distinct and can be managed independently.\n\nApplication (app source code) repositories are separated:\nEach application has its own repo, and different branches can be used for different features or env. This separation allows application owners to manage their code independently and follow GitOps principles for application deployment."
      },
      {
        "date": "2023-11-06T15:46:00.000Z",
        "voteCount": 3,
        "content": "I think A is correct.\nIn both Terraform and Kustomize, it would be common to represent the environment by a directory."
      },
      {
        "date": "2023-11-06T15:59:00.000Z",
        "voteCount": 1,
        "content": "https://cloud.google.com/anthos-config-management/docs/concepts/gitops-best-practices#use-folders"
      },
      {
        "date": "2023-11-04T15:44:00.000Z",
        "voteCount": 3,
        "content": "Not sure, but I think it's better option."
      },
      {
        "date": "2023-11-01T21:04:00.000Z",
        "voteCount": 2,
        "content": "It is recommended to use kustomize+ACM to manage multi environments using overlay+share-repo approach hence this narrows down to be either A or C. https://cloud.google.com/anthos-config-management/docs/tutorials/multiple-environments-config-sync#repository_architecture\n\nFor app repo it should be shared therefore C is the right answer."
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 153,
    "url": "https://www.examtopics.com/discussions/google/view/124265-exam-professional-cloud-devops-engineer-topic-1-question-153/",
    "body": "You are configuring Cloud Logging for a new application that runs on a Compute Engine instance with a public IP address. A user-managed service account is attached to the instance. You confirmed that the necessary agents are running on the instance but you cannot see any log entries from the instance in Cloud Logging. You want to resolve the issue by following Google-recommended practices. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tExport the service account key and configure the agents to use the key.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUpdate the instance to use the default Compute Engine service account.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAdd the Logs Writer role to the service account.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEnable Private Google Access on the subnet that the instance is in."
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 7,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-10-29T03:45:00.000Z",
        "voteCount": 5,
        "content": "answer is C.\nFor B, they specified that a user manager service account is attached to the instance, so the default one will not gonna be used."
      },
      {
        "date": "2023-12-08T00:43:00.000Z",
        "voteCount": 1,
        "content": "The issue described suggests that the service account associated with the Compute Engine instance may not have the necessary permissions to write logs to Cloud Logging. To resolve this issue following Google-recommended practices, you should choose option C: Add the Logs Writer role to the service account.\n\nBy adding the Logs Writer role to the service account, you grant the necessary permissions to write logs to Cloud Logging. This role provides the required access for the agents running on the instance to send log entries to Cloud Logging. Make sure to follow the principle of least privilege and only grant the minimum permissions required for your application to function.\n\nTherefore, the recommended solution is to add the Logs Writer role to the user-managed service account attached to the Compute Engine instance."
      },
      {
        "date": "2023-12-02T03:30:00.000Z",
        "voteCount": 2,
        "content": "Vote C"
      },
      {
        "date": "2023-11-04T15:39:00.000Z",
        "voteCount": 4,
        "content": "Same reason as KHOUKHA."
      },
      {
        "date": "2023-10-25T09:49:00.000Z",
        "voteCount": 2,
        "content": "B is correct : https://cloud.google.com/logging/docs/agent/logging/troubleshooting#verify_default_service_account_permission"
      },
      {
        "date": "2023-10-21T15:04:00.000Z",
        "voteCount": 3,
        "content": "I think answer C is correct in granting the existing service account the least privilege to write logs."
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 154,
    "url": "https://www.examtopics.com/discussions/google/view/124850-exam-professional-cloud-devops-engineer-topic-1-question-154/",
    "body": "As a Site Reliability Engineer, you support an application written in Go that runs on Google Kubernetes Engine (GKE) in production. After releasing a new version of the application, you notice the application runs for about 15 minutes and then restarts. You decide to add Cloud Profiler to your application and now notice that the heap usage grows constantly until the application restarts. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tIncrease the CPU limit in the application deployment.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAdd high memory compute nodes to the cluster.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tIncrease the memory limit in the application deployment.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAdd Cloud Trace to the application, and redeploy."
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 10,
        "isMostVoted": true
      },
      {
        "answer": "D",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2023-10-28T12:19:00.000Z",
        "voteCount": 5,
        "content": "insufficient memory"
      },
      {
        "date": "2024-07-12T07:16:00.000Z",
        "voteCount": 1,
        "content": "D) I would add Cloud Trace to find the root cause of the heap usage growth. Adding more memory will only solve the issue temporarily, and you might now see a restart in 30 minutes."
      },
      {
        "date": "2023-12-08T00:48:00.000Z",
        "voteCount": 1,
        "content": "Given the scenario where the heap usage of the application grows constantly until it restarts, the issue is likely related to memory consumption. Therefore, the appropriate action to take is to address the memory-related problem. In this context, option C is the recommended.\n\nBy increasing the memory limit in the application deployment configuration, you provide more memory resources to the application, potentially preventing it from exhausting its memory and triggering restarts.\n\nOptions A and B may not directly address the underlying memory problem. Option D, adding Cloud Trace, is more focused on request tracing and may not directly resolve the memory growth issue. Therefore, increasing the memory limit is the most relevant step to take based on the symptoms described."
      },
      {
        "date": "2023-12-02T03:31:00.000Z",
        "voteCount": 1,
        "content": "Vote C"
      },
      {
        "date": "2023-11-12T12:54:00.000Z",
        "voteCount": 3,
        "content": "That's what I do at work :-)"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 155,
    "url": "https://www.examtopics.com/discussions/google/view/124266-exam-professional-cloud-devops-engineer-topic-1-question-155/",
    "body": "You are deploying a Cloud Build job that deploys Terraform code when a Git branch is updated. While testing, you noticed that the job fails. You see the following error in the build logs:<br><br>Initializing the backend...<br><br>Error: Failed to get existing workspaces: querying Cloud Storage failed: googleapi: Error 403<br><br>You need to resolve the issue by following Google-recommended practices. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tChange the Terraform code to use local state.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a storage bucket with the name specified in the Terraform configuration.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tGrant the roles/owner Identity and Access Management (IAM) role to the Cloud Build service account on the project.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tGrant the roles/storage.objectAdmin Identity and Access Management (1AM) role to the Cloud Build service account on the state file bucket.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 6,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-05-03T10:27:00.000Z",
        "voteCount": 1,
        "content": "Agree with D"
      },
      {
        "date": "2023-12-28T19:07:00.000Z",
        "voteCount": 1,
        "content": "this is regarding the permission, hence providing the correct role will resolve this"
      },
      {
        "date": "2023-12-08T00:51:00.000Z",
        "voteCount": 2,
        "content": "To resolve that issue, you should ensure that the Cloud Build service account has the necessary permissions to access the Cloud Storage bucket used for storing Terraform state.\n\nThe recommended practice is to grant the roles/storage.objectAdmin Identity and Access Management (IAM) role to the Cloud Build service account on the state file bucket. Therefore, the correct answer is (option D)\n\nThis permission grants the necessary access for Cloud Build to read and write objects (which include Terraform state files) in the specified Cloud Storage bucket, resolving the 403 error. It's important to follow the principle of least privilege and only grant the permissions needed for the specific task at hand."
      },
      {
        "date": "2023-12-02T03:33:00.000Z",
        "voteCount": 1,
        "content": "Vote D"
      },
      {
        "date": "2023-11-02T12:58:00.000Z",
        "voteCount": 1,
        "content": "https://cloud.google.com/storage/docs/access-control/iam-roles"
      },
      {
        "date": "2023-11-01T22:06:00.000Z",
        "voteCount": 1,
        "content": "Think it's D since the 403 error occurred while the tf actions queries state file in bucket, you only need the object admin permission(state file ).\n\nStorage Object Admin (roles/storage.objectAdmin)\tGrants full control over objects, including listing, creating, viewing, and deleting objects, as well as setting object ACLs. Also grants access to create, delete, get, and list managed folders."
      },
      {
        "date": "2023-10-21T15:15:00.000Z",
        "voteCount": 3,
        "content": "Answer D seems to be correct."
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 156,
    "url": "https://www.examtopics.com/discussions/google/view/124851-exam-professional-cloud-devops-engineer-topic-1-question-156/",
    "body": "Your company runs applications in Google Kubernetes Engine (GKE). Several applications rely on ephemeral volumes. You noticed some applications were unstable due to the DiskPressure node condition on the worker nodes. You need to identify which Pods are causing the issue, but you do not have execute access to workloads and nodes. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCheck the node/ephemeral_storage/used_bytes metric by using Metrics Explorer.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCheck the container/ephemeral_storage/used_bytes metric by using Metrics Explorer.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tLocate all the Pods with emptyDir volumes. Use the df -h command to measure volume disk usage.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tLocate all the Pods with emptyDir volumes. Use the df -sh * command to measure volume disk usage."
    ],
    "answer": "B",
    "answerDescription": "",
    "votes": [
      {
        "answer": "B",
        "count": 11,
        "isMostVoted": true
      },
      {
        "answer": "A",
        "count": 1,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2024-05-12T10:14:00.000Z",
        "voteCount": 1,
        "content": "The container/ephemeral_storage/used_bytes metric seems correct."
      },
      {
        "date": "2024-02-16T05:35:00.000Z",
        "voteCount": 2,
        "content": "https://cloud.google.com/monitoring/api/metrics_kubernetes#:~:text=container/ephemeral_storage/used_bytes\nThe container/ephemeral_storage/used_bytes metric can help you identify which pods are consuming ephemeral storage and potentially causing the DiskPressure condition.\n\n\nwhy not A?\nThe node/ephemeral_storage/used_bytes metric would show the total ephemeral storage used on a node, but it wouldn't help you identify which pods are consuming the storage."
      },
      {
        "date": "2023-12-08T00:56:00.000Z",
        "voteCount": 2,
        "content": "To identify which Pods are causing the DiskPressure node condition due to ephemeral volumes, you should check the container/ephemeral_storage/used_bytes metric using Metrics Explorer.\n\nTherefore, the correct answer is B.\n\nThis metric provides information about the ephemeral storage usage of containers within Pods. By examining this metric, you can identify the specific Pods that are contributing to the DiskPressure condition on the worker nodes. Metrics Explorer allows you to visualize and analyze metrics data, making it a suitable tool for investigating resource usage and identifying potential issues in a GKE environment."
      },
      {
        "date": "2023-12-02T03:35:00.000Z",
        "voteCount": 1,
        "content": "Vote B"
      },
      {
        "date": "2023-11-12T01:57:00.000Z",
        "voteCount": 2,
        "content": "This approach provides the necessary detail to identify which Pods are causing the DiskPressure condition without the need for direct access to the nodes or the ability to execute commands on them. Metrics Explorer in Google Cloud's operations suite (formerly Stackdriver) allows you to query and visualize metrics from your GKE environment, making it a powerful tool for this kind of diagnostic task."
      },
      {
        "date": "2023-11-06T16:13:00.000Z",
        "voteCount": 3,
        "content": "I think the answer is B.\nYou need to use container/ephemeral_storage/used_bytes because you need to identify the pod that is causing the problem.\npod/ephemeral_storage/used_bytes also exists, but it is still in beta.\nhttps://cloud.google.com/monitoring/api/metrics_kubernetes"
      },
      {
        "date": "2023-11-05T02:55:00.000Z",
        "voteCount": 1,
        "content": "Why not B?"
      },
      {
        "date": "2023-10-29T04:04:00.000Z",
        "voteCount": 1,
        "content": "A:\nnode/ephemeral_storage/used_bytes GA\nEphemeral storage usage\nGAUGE, INT64, By\nk8s_node\tLocal ephemeral storage bytes used by the node. Sampled every 60 seconds."
      },
      {
        "date": "2023-11-01T22:20:00.000Z",
        "voteCount": 1,
        "content": "why not B though?"
      },
      {
        "date": "2023-10-28T12:21:00.000Z",
        "voteCount": 1,
        "content": "https://cloud.google.com/monitoring/api/metrics_kubernetes"
      },
      {
        "date": "2023-11-01T22:20:00.000Z",
        "voteCount": 2,
        "content": "why not B though?"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 157,
    "url": "https://www.examtopics.com/discussions/google/view/124852-exam-professional-cloud-devops-engineer-topic-1-question-157/",
    "body": "You are designing a new Google Cloud organization for a client. Your client is concerned with the risks associated with long-lived credentials created in Google Cloud. You need to design a solution to completely eliminate the risks associated with the use of JSON service account keys while minimizing operational overhead. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tApply the constraints/iam.disableServiceAccountKevCreation constraint to the organization.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse custom versions of predefined roles to exclude all iam.serviceAccountKeys.* service account role permissions.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tApply the constraints/iam.disableServiceAccountKeyUpload constraint to the organization.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tGrant the roles/iam.serviceAccountKeyAdmin IAM role to organization administrators only."
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 11,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-02-16T21:47:00.000Z",
        "voteCount": 1,
        "content": "https://cloud.google.com/resource-manager/docs/organization-policy/restricting-service-accounts#disable_service_account_key_creation"
      },
      {
        "date": "2023-12-08T01:04:00.000Z",
        "voteCount": 2,
        "content": "Correct answer is A.\n\nBy applying the constraints/iam.disableServiceAccountKeyCreation constraint to the organization, you can prevent the creation of JSON service account keys, thus minimizing the risk associated with long-lived credentials.\n\nThis constraint disables the ability to create new service account keys, reducing the potential for misuse or compromise of credentials."
      },
      {
        "date": "2023-11-04T15:28:00.000Z",
        "voteCount": 3,
        "content": "You can use the iam.disableServiceAccountCreation boolean constraint to disable the creation of new service accounts. This allows you to centralize management of service accounts while not restricting the other permissions your developers have on projects."
      },
      {
        "date": "2023-11-01T22:25:00.000Z",
        "voteCount": 2,
        "content": "\"You can use the iam.disableServiceAccountKeyCreation boolean constraint to disable the creation of new external service account keys. This allows you to control the use of unmanaged long-term credentials for service accounts. When this constraint is set, user-managed credentials cannot be created for service accounts in projects affected by the constraint.\"\n\nhttps://cloud.google.com/resource-manager/docs/organization-policy/restricting-service-accounts#disable_service_account_key_creation"
      },
      {
        "date": "2023-10-28T12:24:00.000Z",
        "voteCount": 3,
        "content": "constraints/iam.disableServiceAccountKeyCreation"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 158,
    "url": "https://www.examtopics.com/discussions/google/view/124678-exam-professional-cloud-devops-engineer-topic-1-question-158/",
    "body": "You are designing a deployment technique for your applications on Google Cloud. As part of your deployment planning, you want to use live traffic to gather performance metrics for new versions of your applications. You need to test against the full production load before your applications are launched. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse A/B testing with blue/green deployment.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse canary testing with continuous deployment.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse canary testing with rolling updates deployment.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse shadow testing with continuous deployment.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 12,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-02-16T21:51:00.000Z",
        "voteCount": 1,
        "content": "https://cloud.google.com/architecture/application-deployment-and-testing-strategies#shadow_test_pattern\nWith shadow testing, you deploy and run a new version alongside the current version, but in such a way that the new version is hidden from the users, as the following diagram shows.\nAn incoming request is mirrored and replayed in a test environment. This process can happen either in real time or asynchronously after a copy of the previously captured production traffic is replayed against the newly deployed service."
      },
      {
        "date": "2023-12-08T01:18:00.000Z",
        "voteCount": 2,
        "content": "Choose option D.\n\nShadow testing allows the deployment and execution of a new version alongside the current one, but in a manner that is hidden from users. This approach ensures zero production impact, as the incoming requests are mirrored and replayed in a test environment. By duplicating traffic, it enables comprehensive testing of new features and improvements against the full production load without affecting end-users.\n\nAdditionally, the continuous deployment aspect ensures that the deployment process remains ongoing, allowing for iterative testing and refinement based on real-world performance metrics and user interactions before a full rollout occurs."
      },
      {
        "date": "2023-12-02T03:39:00.000Z",
        "voteCount": 2,
        "content": "Vote D"
      },
      {
        "date": "2023-11-04T15:23:00.000Z",
        "voteCount": 3,
        "content": "Shadow testing is a technique where you deploy a new version of your application alongside the existing production version, but you don't route live traffic to it. Instead, you route a copy of the live traffic to the new version (the \"shadow\" version) while the production version continues to serve real user traffic. This allows you to gather performance metrics and test the new version under real-world conditions without affecting the end users' experience."
      },
      {
        "date": "2023-11-01T22:44:00.000Z",
        "voteCount": 2,
        "content": "https://cloud.google.com/architecture/application-deployment-and-testing-strategies#shadow_test_pattern"
      },
      {
        "date": "2023-10-26T11:13:00.000Z",
        "voteCount": 2,
        "content": "Option A is literally for spilting traffic between versions , Canary is gradually allowing traffic to production, D is right answer"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 159,
    "url": "https://www.examtopics.com/discussions/google/view/124631-exam-professional-cloud-devops-engineer-topic-1-question-159/",
    "body": "Your Cloud Run application writes unstructured logs as text strings to Cloud Logging. You want to convert the unstructured logs to JSON-based structured logs. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tModify the application to use Cloud Logging software development kit (SDK), and send log entries with a jsonPayload field.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tInstall a Fluent Bit sidecar container, and use a JSON parser.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tInstall the log agent in the Cloud Run container image, and use the log agent to forward logs to Cloud Logging.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure the log agent to convert log text payload to JSON payload.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 9,
        "isMostVoted": true
      },
      {
        "answer": "A",
        "count": 2,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2024-08-13T07:46:00.000Z",
        "voteCount": 1,
        "content": "Not an instance"
      },
      {
        "date": "2024-05-21T00:01:00.000Z",
        "voteCount": 1,
        "content": "This is Cloud Run not VM -&gt; A"
      },
      {
        "date": "2024-02-16T21:58:00.000Z",
        "voteCount": 1,
        "content": "https://cloud.google.com/logging/docs/agent/logging/configuration#process-payload\nhttps://cloud.google.com/logging/docs/agent/logging/configuration#structured-records"
      },
      {
        "date": "2023-12-08T01:24:00.000Z",
        "voteCount": 1,
        "content": "Vote option D. \n\nIn this context, if you have unstructured logs written as text strings and want to convert them to JSON-based structured logs, you would typically use a log agent or parser to transform the log entries. The log agent is configured to recognize the structure of the logs and convert the text payload into a JSON payload.\n\nThe log agent would be responsible for parsing the unstructured logs and converting them into a structured format. This process involves specifying how to extract relevant information from the text payload and organize it into a JSON structure. It's important to note that this approach assumes you have a log agent or parser that supports the transformation of unstructured logs to structured logs."
      },
      {
        "date": "2023-12-02T09:21:00.000Z",
        "voteCount": 1,
        "content": "Vote D"
      },
      {
        "date": "2023-11-04T15:20:00.000Z",
        "voteCount": 2,
        "content": "The Cloud Logging agent can be configured to convert log text payload to JSON payload by setting the process.payload parameter to json. This will cause the agent to parse the log text and convert it to a JSON object before forwarding it to Cloud Logging."
      },
      {
        "date": "2023-10-25T11:02:00.000Z",
        "voteCount": 4,
        "content": "https://cloud.google.com/logging/docs/agent/logging/configuration#process-payload"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 160,
    "url": "https://www.examtopics.com/discussions/google/view/125156-exam-professional-cloud-devops-engineer-topic-1-question-160/",
    "body": "Your company is planning a large marketing event for an online retailer during the holiday shopping season. You are expecting your web application to receive a large volume of traffic in a short period. You need to prepare your application for potential failures during the event. What should you do? (Choose two.)",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure Anthos Service Mesh on the application to identify issues on the topology map.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tEnsure that relevant system metrics are being captured with Cloud Monitoring, and create alerts at levels of interest.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tReview your increased capacity requirements and plan for the required quota management.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tMonitor latency of your services for average percentile latency.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"E\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tE.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate alerts in Cloud Monitoring for all common failures that your application experiences."
    ],
    "answer": "BC",
    "answerDescription": "",
    "votes": [
      {
        "answer": "BC",
        "count": 11,
        "isMostVoted": true
      },
      {
        "answer": "BE",
        "count": 2,
        "isMostVoted": false
      }
    ],
    "comments": [
      {
        "date": "2024-02-16T22:03:00.000Z",
        "voteCount": 3,
        "content": "Why?\nB: Monitoring system metrics and setting up alerts can help you detect and respond to issues quickly, minimizing potential downtime during periods of high traffic.\n\nC: Reviewing your capacity requirements and planning for quota management ensures that your application has the necessary resources to handle the expected increase in traffic.\n\n\nNot.\nA: While Anthos Service Mesh can provide valuable insights into service interactions, it's not directly related to preparing for potential failures during high-traffic events. Also, it's not mentioned which tool we are using, so anthos might not even be used. \nD: While monitoring latency is important for understanding service performance, it doesn't directly help prepare for potential failures during high-traffic events. \nE: Creating alerts for all common failures could result in alert fatigue."
      },
      {
        "date": "2023-12-08T01:35:00.000Z",
        "voteCount": 2,
        "content": "Choose B &amp; C.\n\nB. \nCapturing system metrics with Cloud Monitoring allows you to monitor the health and performance of your application. Creating alerts based on these metrics enables proactive detection and quick response to anomalies or issues, ensuring the reliability of your application during the expected surge in traffic.\n\nC. \nAnticipating the increased capacity requirements during the event is crucial. Proper capacity planning, including scaling resources and managing quotas, ensures that your infrastructure can handle the high volume of traffic, preventing potential failures such as service degradation or outages."
      },
      {
        "date": "2023-12-02T09:22:00.000Z",
        "voteCount": 1,
        "content": "Vote BC"
      },
      {
        "date": "2023-11-08T08:05:00.000Z",
        "voteCount": 2,
        "content": "Creating alerts for failures is important"
      },
      {
        "date": "2023-11-04T15:15:00.000Z",
        "voteCount": 2,
        "content": "Come up to these options by skipping other options."
      },
      {
        "date": "2023-11-01T22:59:00.000Z",
        "voteCount": 3,
        "content": "Having proper metrics plus alerts, also prepare for resource quota"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 161,
    "url": "https://www.examtopics.com/discussions/google/view/124679-exam-professional-cloud-devops-engineer-topic-1-question-161/",
    "body": "Your company recently migrated to Google Cloud. You need to design a fast, reliable, and repeatable solution for your company to provision new projects and basic resources in Google Cloud. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse the Google Cloud console to create projects.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tWrite a script by using the gcloud CLI that passes the appropriate parameters from the request. Save the script in a Git repository.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tWrite a Terraform module and save it in your source control repository. Copy and run the terraform apply command to create the new project.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse the Terraform repositories from the Cloud Foundation Toolkit. Apply the code with appropriate parameters to create the Google Cloud project and related resources.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>"
    ],
    "answer": "D",
    "answerDescription": "",
    "votes": [
      {
        "answer": "D",
        "count": 8,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-02-17T00:26:00.000Z",
        "voteCount": 1,
        "content": "https://cloud.google.com/docs/terraform/blueprints/terraform-blueprints#:~:text=Creates%20an%20opinionated%20Google%20Cloud%20project%20by%20using%20Shared%20VPC%2C%20IAM%2C%20and%20Google%20Cloud%20APIs\n\nhttps://github.com/terraform-google-modules/terraform-google-project-factory"
      },
      {
        "date": "2023-12-08T04:31:00.000Z",
        "voteCount": 1,
        "content": "Choose D.\n\nUsing Terraform and the Cloud Foundation Toolkit ensures that you have a structured and version-controlled approach to provisioning resources. It also facilitates automation and scalability, making it easier to manage projects and resources across different environments.\n\nOptions A and B may lack the repeatability and version control benefits provided by IaC solutions like Terraform. While option C mentions Terraform, it doesn't specify using a toolkit or best practices for cloud foundation setup.\n\nIn summary, option D with Terraform and the Cloud Foundation Toolkit aligns with best practices for Infrastructure as Code, providing a fast, reliable, and repeatable solution for provisioning projects and resources in Google Cloud."
      },
      {
        "date": "2023-12-02T09:23:00.000Z",
        "voteCount": 1,
        "content": "Vote D"
      },
      {
        "date": "2023-11-04T15:13:00.000Z",
        "voteCount": 1,
        "content": "The Cloud Foundation Toolkit provides a series of reference templates for Deployment Manager and Terraform which reflect Google Cloud best practices."
      },
      {
        "date": "2023-10-26T11:22:00.000Z",
        "voteCount": 4,
        "content": "Fast , relaible and repeatable solution , It is terraform"
      },
      {
        "date": "2023-11-01T23:02:00.000Z",
        "voteCount": 1,
        "content": "plus D says cloud foundation toolkit"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 162,
    "url": "https://www.examtopics.com/discussions/google/view/124792-exam-professional-cloud-devops-engineer-topic-1-question-162/",
    "body": "You are configuring a CI pipeline. The build step for your CI pipeline integration testing requires access to APIs inside your private VPC network. Your security team requires that you do not expose API traffic publicly. You need to implement a solution that minimizes management overhead. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse Cloud Build private pools to connect to the private VPC.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse Spinnaker for Google Cloud to connect to the private VPC.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse Cloud Build as a pipeline runner. Configure Internal HTTP(S) Load Balancing for API access.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse Cloud Build as a pipeline runner. Configure External HTTP(S) Load Balancing with a Google Cloud Armor policy for API access."
    ],
    "answer": "A",
    "answerDescription": "",
    "votes": [
      {
        "answer": "A",
        "count": 9,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-02-17T00:30:00.000Z",
        "voteCount": 1,
        "content": "\"Private pools are private, dedicated pools of workers that offer greater customization over the build environment, including the ability to access resources in a private network. Private pools, similar to default pools, are hosted and fully-managed by Cloud Build and scale up and down to zero, with no infrastructure to set up, upgrade, or scale. Because private pools are customer-specific resources, you can configure them in more ways.\"\n\nhttps://cloud.google.com/build/docs/private-pools/private-pools-overview#overview_of_default_pools_and_private_pools"
      },
      {
        "date": "2023-12-08T05:04:00.000Z",
        "voteCount": 2,
        "content": "To implement a solution that minimizes management overhead and allows the CI pipeline integration testing to access APIs inside your private VPC network without exposing API traffic publicly, the appropriate (choice is A).\n\nCloud Build private pools allow you to run builds in a Google Cloud environment with access to your private VPC network. This ensures that the build step for your CI pipeline can access APIs inside the private VPC without exposing API traffic to the public internet. Private pools minimize management overhead by providing a secure and controlled environment for running builds.\n\nOptions B, C, and D involve different configurations, but they may introduce unnecessary complexity, security risks, or exposure of API traffic to the public internet, which contradicts the security requirements provided."
      },
      {
        "date": "2023-12-02T09:23:00.000Z",
        "voteCount": 1,
        "content": "Vote A"
      },
      {
        "date": "2023-11-04T15:09:00.000Z",
        "voteCount": 2,
        "content": "The default pool has limits on how much you can customize the environment, particularly around private network access. Private pools are private, dedicated pools of workers that offer greater customization over the build environment, including the ability to access resources in a private network."
      },
      {
        "date": "2023-10-28T03:08:00.000Z",
        "voteCount": 3,
        "content": "A\nhttps://cloud.google.com/build/docs/private-pools/private-pools-overview"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 163,
    "url": "https://www.examtopics.com/discussions/google/view/124320-exam-professional-cloud-devops-engineer-topic-1-question-163/",
    "body": "You are leading a DevOps project for your organization. The DevOps team is responsible for managing the service infrastructure and being on-call for incidents. The Software Development team is responsible for writing, submitting, and reviewing code. Neither team has any published SLOs. You want to design a new joint-ownership model for a service between the DevOps team and the Software Development team. Which responsibilities should be assigned to each team in the new joint-ownership model?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t<img src=\"https://img.examtopics.com/professional-cloud-devops-engineer/image5.png\"><br>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t<img src=\"https://img.examtopics.com/professional-cloud-devops-engineer/image6.png\"><br>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t<img src=\"https://img.examtopics.com/professional-cloud-devops-engineer/image7.png\"><br>\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t<img src=\"https://img.examtopics.com/professional-cloud-devops-engineer/image8.png\">"
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 3,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-12-28T20:54:00.000Z",
        "voteCount": 3,
        "content": "C, D same, \nfound the right option for D, which says\n\nDevops team responsibility\nManage the service infrastructure\nBe on call for incidents\n\nShared responsibilities\nadopt and publish SLOs for the service\n\nSoftware development team responsibilities\nSubmit code to be reviewed\nperform code reviews"
      },
      {
        "date": "2023-12-28T20:58:00.000Z",
        "voteCount": 1,
        "content": "however this says, submit code review, perform code review will be performed by the same team, which seems not correct, moreover when the incident call happening, both the teams should be there"
      },
      {
        "date": "2023-12-08T05:11:00.000Z",
        "voteCount": 2,
        "content": "In a joint-ownership model for a service between the DevOps and Software Development teams, option C &amp; D is more suitable. \n\nThe DevOps team manages the infrastructure, while both teams share responsibilities for code reviews, on-call duties, and defining SLOs. The Software Development team contributes by submitting code changes.\n\nThis approach promotes collaboration, accountability, and a shared commitment to service reliability and performance goals."
      },
      {
        "date": "2023-12-19T09:15:00.000Z",
        "voteCount": 2,
        "content": "did you pass exam for those examtopics questions?"
      },
      {
        "date": "2023-12-02T09:23:00.000Z",
        "voteCount": 1,
        "content": "Vote C D"
      },
      {
        "date": "2023-12-19T09:15:00.000Z",
        "voteCount": 1,
        "content": "did you pass exam for those examtopics questions?"
      },
      {
        "date": "2023-11-01T23:05:00.000Z",
        "voteCount": 1,
        "content": "C and D need to be updated. Basically this question emphasises a culture of more shared responsibilities between dev and ops."
      },
      {
        "date": "2023-10-22T01:40:00.000Z",
        "voteCount": 3,
        "content": "C and D look the same."
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 164,
    "url": "https://www.examtopics.com/discussions/google/view/124268-exam-professional-cloud-devops-engineer-topic-1-question-164/",
    "body": "You recently migrated an ecommerce application to Google Cloud. You now need to prepare the application for the upcoming peak traffic season. You want to follow Google-recommended practices. What should you do first to prepare for the busy season?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tMigrate the application to Cloud Run, and use autoscaling.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tCreate a Terraform configuration for the application's underlying infrastructure to quickly deploy to additional regions.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tLoad test the application to profile its performance for scaling.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tPre-provision the additional compute power that was used last season, and expect growth."
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 7,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2023-10-21T15:36:00.000Z",
        "voteCount": 5,
        "content": "Answer C is my choice."
      },
      {
        "date": "2023-12-08T05:15:00.000Z",
        "voteCount": 2,
        "content": "Choose C.\n\nGoogle-recommended practices often involve load testing applications to understand their performance characteristics and determine appropriate scaling strategies.\n\nBy load testing the ecommerce application, you can simulate peak traffic scenarios and identify potential bottlenecks or areas for optimization. This allows you to make informed decisions about scaling strategies, such as setting up auto-scaling policies based on the observed performance metrics. Load testing helps ensure that the application can handle the expected peak traffic efficiently and reliably.\n\nOptions A, B, and D may have their relevance in different contexts, but load testing the application is typically a crucial step to gather insights into its behavior under stress and to inform scaling strategies for the upcoming peak traffic season."
      },
      {
        "date": "2023-12-02T09:24:00.000Z",
        "voteCount": 2,
        "content": "Vote C"
      },
      {
        "date": "2023-11-03T23:33:00.000Z",
        "voteCount": 3,
        "content": "C should be Answer."
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 165,
    "url": "https://www.examtopics.com/discussions/google/view/124269-exam-professional-cloud-devops-engineer-topic-1-question-165/",
    "body": "You are monitoring a service that uses n2-standard-2 Compute Engine instances that serve large files. Users have reported that downloads are slow. Your Cloud Monitoring dashboard shows that your VMs are running at peak network throughput. You want to improve the network throughput performance. What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tAdd additional network interface controllers (NICs) to your VMs.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDeploy a Cloud NAT gateway and attach the gateway to the subnet of the VMs.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tChange the machine type for your VMs to n2-standard-8.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tDeploy the Ops Agent to export additional monitoring metrics."
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 9,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-02-17T00:54:00.000Z",
        "voteCount": 2,
        "content": "https://cloud.google.com/compute/docs/general-purpose-machines#n2-standard\n\n\n\"Neither additional virtual network interfaces (vNICs) nor additional IP addresses per vNIC increase ingress or egress bandwidth for a VM. For example, a C3 VM with 22 vCPUs is limited to 23 Gbps total egress bandwidth. If you configure the C3 VM with two vNICs, the VM is still limited to 23 Gbps total egress bandwidth, not 23 Gbps bandwidth per vNIC.\"\nhttps://cloud.google.com/compute/docs/network-bandwidth#vm-out-baseline:~:text=Neither%20additional%20virtual,bandwidth%20per%20vNIC."
      },
      {
        "date": "2023-12-08T05:22:00.000Z",
        "voteCount": 1,
        "content": "Choose C.\n\nChanging the machine type to a higher-capacity will increases the available resources, including CPU, memory, and potentially network bandwidth.\n\nOptions A and B are not directly related to improving network throughput for the existing VMs. Adding additional network interface controllers (NICs) (Option A) may not necessarily address network throughput limitations, and deploying a Cloud NAT gateway (Option B) is more relevant for outbound internet traffic rather than internal network communication.\n\nOption D (Deploy the Ops Agent to export additional monitoring metrics) is not directly related to improving network throughput. While it can provide additional monitoring metrics, addressing the reported slow download issue is better achieved by adjusting the resources allocated to the VMs."
      },
      {
        "date": "2023-12-02T09:24:00.000Z",
        "voteCount": 1,
        "content": "Vote C"
      },
      {
        "date": "2023-11-03T23:35:00.000Z",
        "voteCount": 1,
        "content": "https://cloud.google.com/compute/docs/network-bandwidth"
      },
      {
        "date": "2023-10-26T11:34:00.000Z",
        "voteCount": 4,
        "content": "Network throughput performance is often associated with the compute power of the virtual machines. Upgrading your VM instance type to one with more CPU and memory resources, like n2-standard-8, can significantly improve the network performance"
      },
      {
        "date": "2023-10-25T07:56:00.000Z",
        "voteCount": 2,
        "content": "C Increasing the VM from standard-2 to standard-8 will increase egress.  The VM is serving files (egress) so will benefit from larger egress"
      },
      {
        "date": "2023-10-21T15:40:00.000Z",
        "voteCount": 1,
        "content": "Answer D seems correct.\nhttps://cloud.google.com/blog/products/gcp/5-steps-to-better-gcp-network-performance"
      },
      {
        "date": "2023-10-26T11:34:00.000Z",
        "voteCount": 1,
        "content": "D doesnt helps to improve network performances , Im going with C"
      },
      {
        "date": "2023-11-01T23:10:00.000Z",
        "voteCount": 1,
        "content": "this article also emphasises a higher specs of VM helps with egress traffic:\n\"Outbound or egress traffic from a virtual machine is subject to maximum network egress throughput caps. These caps are dependent on the number of vCPUs that a virtual machine instance has. Each core is subject to a 2 Gbits/second (Gbps) cap for peak performance. Each additional core increases the network cap, up to a theoretical maximum of 16 Gbps for each virtual machine.\""
      },
      {
        "date": "2023-11-01T23:10:00.000Z",
        "voteCount": 1,
        "content": "So answer is C"
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  },
  {
    "topic": 1,
    "index": 166,
    "url": "https://www.examtopics.com/discussions/google/view/124271-exam-professional-cloud-devops-engineer-topic-1-question-166/",
    "body": "Your organization is starting to containerize with Google Cloud. You need a fully managed storage solution for container images and Helm charts. You need to identify a storage solution that has native integration into existing Google Cloud services, including Google Kubernetes Engine (GKE), Cloud Run, VPC Service Controls, and Identity and Access Management (IAM). What should you do?",
    "options": [
      "<span class=\"multi-choice-letter\" data-choice-letter=\"A\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tA.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tUse Docker to configure a Cloud Storage driver pointed at the bucket owned by your organization.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"B\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tB.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure an open source container registry server to run in GKE with a restrictive role-based access control (RBAC) configuration.",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"C\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tC.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure Artifact Registry as an OCI-based container registry for both Helm charts and container images.\n\t\t\t\t\t\t\t\t\t\t<span class=\"badge badge-success most-voted-answer-badge\" title=\"\" style=\"display: none;\" data-original-title=\"This answer is currently the most voted for in the discussion\">\n                Most Voted\n            </span>",
      "<span class=\"multi-choice-letter\" data-choice-letter=\"D\">\n\t\t\t\t\t\t\t\t\t\t\t\t\tD.\n\t\t\t\t\t\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tConfigure Container Registry as an OCI-based container registry for container images."
    ],
    "answer": "C",
    "answerDescription": "",
    "votes": [
      {
        "answer": "C",
        "count": 6,
        "isMostVoted": true
      }
    ],
    "comments": [
      {
        "date": "2024-02-17T00:59:00.000Z",
        "voteCount": 1,
        "content": "C: Artifact Registry is a fully managed service in Google Cloud that supports OCI-based container images as well as Helm charts. It has native integration with Google Kubernetes Engine (GKE), Cloud Run, VPC Service Controls, and Identity and Access Management (IAM).\nhttps://cloud.google.com/artifact-registry/docs/supported-formats#container\n\nEliminated Options:\nA: would require additional management overhead and wouldn't provide native integration with the mentioned Google Cloud services.\nB: Configuring an open source container registry server to run in GKE would require more management overhead compared to using a fully managed service like Artifact Registry.\nhttps://cloud.google.com/artifact-registry/docs/hel\nD: While Container Registry supports container images, it doesn't support Helm charts. Artifact Registry is the newer, more feature-rich service that is recommended by Google."
      },
      {
        "date": "2023-12-08T05:25:00.000Z",
        "voteCount": 1,
        "content": "Artifact Registry is a fully managed, scalable, and secure artifact storage solution that integrates seamlessly with other Google Cloud services. It is designed for storing various artifacts, including container images and Helm charts. Here's why option C is the most suitable choice:\n\nOptions A, B, and D might have their use cases, but none of them provide the same level of seamless integration with Google Cloud services, including GKE, Cloud Run, VPC Service Controls, and IAM, as Artifact Registry does.\n\nAdditionally, Artifact Registry supports both container images and Helm charts, making it a comprehensive solution for your containerization needs on Google Cloud."
      },
      {
        "date": "2023-12-02T09:25:00.000Z",
        "voteCount": 1,
        "content": "Vote C"
      },
      {
        "date": "2023-10-28T12:32:00.000Z",
        "voteCount": 4,
        "content": "https://cloud.google.com/artifact-registry/docs/helm"
      },
      {
        "date": "2023-10-21T15:43:00.000Z",
        "voteCount": 2,
        "content": "Answer C is correct to me."
      }
    ],
    "examNameCode": "professional-cloud-devops-engineer",
    "topicNumber": "1"
  }
]